<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 12 Nov 2020 20:18:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 12 Nov 2020 20:18:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Free WebRTC Android, iOS and JavaScript SDKs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057259">thread link</a>) | @Iwontgo
<br/>
November 11, 2020 | https://antmedia.io/free-webrtc-android-ios-sdk/ | <a href="https://web.archive.org/web/*/https://antmedia.io/free-webrtc-android-ios-sdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<div>
<article id="post-31205">
<div>
<div>
<section>
<div>
<div> <p>Developers all around the world, we have great news for you.</p> <p>We decided to offer you Ant Media Server iOS and Android SDKs for free. You can easily integrate it into your applications.</p> <p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/ios-icon.jpg" alt="Free WebRTC Android / iOS SDK 1" title="Free WebRTC Android / iOS SDK 1"> <img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/android-icon.jpg" alt="Free WebRTC Android / iOS SDK 2" title="Free WebRTC Android / iOS SDK 2"></p></div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/great-news.jpg" alt="Free WebRTC Android / iOS SDK 3" title="Free WebRTC Android / iOS SDK 3"></p></div></section>
<section>
<h2>Here are <span>Ant Media Server</span> <br>iOS and Android SDKs features</h2>
<div>
<div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/community.jpg" alt="Free WebRTC Android / iOS SDK 4" title="Free WebRTC Android / iOS SDK 4"></p> <p>Compatible with Community and Enterprise Edition</p></div><div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/webrtc.jpg" alt="Free WebRTC Android / iOS SDK 5" title="Free WebRTC Android / iOS SDK 5"></p> <p>WebRTC Publish and WebRTC Playback with sub-second latency*</p></div><div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/h264.jpg" alt="Free WebRTC Android / iOS SDK 6" title="Free WebRTC Android / iOS SDK 6"></p> <p>WebRTC Playback For H.265 streams is supported in Android SDK</p></div></div><p><small>*WebRTC Publishing is supported with Community Edition. WebRTC Publishing and Playing are supported with Enterprise Edition</small></p>
</section>
<section>
<h2>Get Started Now</h2>
<div>
<div>
<p>If you wonder how to use WebRTC SDKs, you can check out the <a href="https://antmedia.io/how-to-use-webrtc-sdk-in-native-ios-app/">iOS</a> and <a href="https://antmedia.io/how-to-create-webrtc-websocket-connection-in-android/">Android</a> installation guide.</p></div></div></section></div></div></article></div></div></div></div></div>]]>
            </description>
            <link>https://antmedia.io/free-webrtc-android-ios-sdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057259</guid>
            <pubDate>Wed, 11 Nov 2020 10:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I’ll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I’ll call the ‘feature ID’.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (“Is a certain feature present or not”) or can be the
amount of DSP memory etc.</p>

<p>Here’s a very non-exhaustive list of codes that I’ve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It’s a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That’s the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable “Option 05 - Video Triggering”, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it’s great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called “MathPak”. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It’s now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I’m now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It’s a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It’s now clear why option 1M doesn’t get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of “D2” memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there’s a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it’s a board that’s easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they’re now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn’t be a problem.</p>

<p>They’re cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished…</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that’s wired to the board: it’s used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I’m most comfortable doing it that way.
Afterwards I Ohm’ed out most of the pins, and I’m glad I did because
there were some open connections.</p>

<p>The end result isn’t perfect, but it’s good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it’s time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it’s
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it’s really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn’t able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our own x86 shellcode emulator and how it works]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don’t affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn’t have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn’t even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they’re loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn’t matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between “=” and “{ get; } =” for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here’s an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it’s not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it’s body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Jiří Činčura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies – Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes “<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, “It’s not unchecked free speech. Instead, it’s unchecked curation by media and social media companies with the goal of engagement.” There’s some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: “Try teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you’ll discover that the vast majority of people have pretty poor personal epistemic hygiene—it’s not much required in most people, most of the time, in most jobs.”</p>
<p>From what I can tell, we evolved to form tribes, not to be “right:” Jonathan’s Haidt’s <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I’ve not seen any substantial rebuttals of it. We don’t naturally take to tracking the question, “How do I know what I know?” Instead, we naturally seem to want to find “facts” or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I’d prefer not to get super specific for reasons of privacy, I’ve had many conversations that take the following form: “How do you know article x is accurate?” “Google told me.” “How does Google work?” “I don’t know.” “What does it take to make a claim on the Internet.” “Um. A phone, I guess?” A lot of people—maybe most—will uncritically take as fact whatever happens to be served up by Google (it’s always Google and never Duck Duck Go or Bing), and most undergrads whose work I’ve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads’s lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that’s being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast—so vast that I don’t think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We’re all living in bubbles. I don’t think I did, either, before I saw the epistemic hygiene most undergrads practice, or don’t practice. This is not a “kids these days” rant, either: many of them have never really been taught to ask themselves, “How do I know what I know?” Many have never really learned anything about the scientific method. It’s not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor’s degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like “What is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?” is not zero, again obviously, but it’s not a huge part of the population. And many very “smart” people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I’m not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn’t call it “epistemology.” Editors would ask, “How do you know that?” or “Who told you that?” or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don’t care about the question, “How do you know what you know?” and they’ll be fairly surprised if it’s asked, implicitly or explicitly. Some people are intrigued by it but most aren’t, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the “elite schools” thing drives a lot of the media discourse around education. One of the things I like about Professor X’s book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn’t going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse’s life likely won’t be affected. There’s no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn’t going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you’re really on team x is to state or repeat falsehoods that show you’re on team x, rather than on team “What is really true?”</p>
<p>I don’t want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people’s problems with epistemology, and in a way that can have immediate, negative personal consequences—but not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn’t read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don’t realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don’t know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data—but the number of people deeply interested in data and data’s veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you’re probably in a nerd bubble: usually, anything involving the word “epistemology” sends people to sleep or, alternately, scurrying for something like “You won’t believe what this celebrity wore/said/did” instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person’s disinformation is another person’s teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it’s not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language — Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn’t get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I’ll talk about how I’m learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let’s get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app — <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I’ve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I’m not moving to a Spanish speaking country anytime soon, I didn’t feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don’t need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day — browsing the web and reading articles online.</p>



<p>After a quick test ride, here’s:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value — habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don’t need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here’s:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you’d typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you’ve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word “event” into its Spanish counterpart — evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I’ve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page’s design.</p>



<p>Here’s an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you’re using Fluent, it’ll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word “derrame” with a yellow tint (because it’s masculine), and “incluso” with a neutral grey-ish colour (because it’s gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word’s definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don’t know the meaning of the translated word, I can read the definition on the card.</p>



<p>There’s one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as “I know this” and Toucan will leave those words in the source language — English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word “coffee” as learnt will set Toucan to translate tricky words like “hot coffee” or “nice coffee” in your future reads.</p>



<p>This is how I’ll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack “Get Around the City” will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan’s “Get Around the City” language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here’s a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing “Many” will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting “Less”.</p>



<p>With “Less”, I get around 5–7 words translated in an article of 4–5 min read time.</p>



<p>Also:</p>



<p>With “Less” translations are distributed evenly in the article. Thus, the highlights don’t steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here’s what I recommend:</p>



<p>Start with “Less” → As you become comfortable with the translations → Move to “More”.</p>



<p>With a gradual transition, it’ll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you’d like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here’s another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we’re giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here’s a gist:</p>



<ul><li>They don’t sell user data for ads.</li><li>The extensions don’t store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it’s privacy policy might be. The business needs to make money.</p>



<p>Here’s how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word “productivity”, then every time someone hovers over the translated word for “productivity”, they’ll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here’s how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It’s always wise to fine-tune privacy settings so that we don’t leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan’s premium subscription, let’s see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you’re reading this, it’s likely you know how to code – and even if you’re still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren’t born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job – I want to offer you a single piece of advice that may act as your career’s guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn’t on the code you’re writing but rather why you’re writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you’ll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don’t serve anyone’s mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don’t matter. These things don’t drive value for anyone. No matter how many “experienced” engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer’s only skillset. Remember that at the end of the day, it doesn’t matter if your code is ugly, fancy, verbose or concise – the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him – telling him what’s important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh’s greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it – and he promises it doesn’t involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I’ve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy’s sake. But every once in a while you’ll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they’ve had.</li></ul>
<p>I will add a big caveat though: I think every person’s optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn’t work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I’ve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means “How full is your mind’s RAM?”. </p>
<p>Whenever you’re thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you’re carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here’s what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn’t have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you’ll want to check a certain link again in the future, bookmark it under an intuitive path. Don’t find yourself looking for it through your twitter feed.</li><li>If something’s on your mind and it’s not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‘You have to write that article!’ I just added an item on my Trello backlog that said ‘article on productivity’ and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I’d rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it’s just “What did I do today? Oh ok I’ll check today’s cards”. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>…Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.”</p><cite><em>―&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called “Atomic Habits”. I won’t lie, I haven’t read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don’t try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you’re extremely accountable to them. Is the day ending and you haven’t done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don’t finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you’re accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don’t overestimate yourself. It’s better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can’t keep up with them. </p>
<p>Did you underestimate your time management skills and now you’re doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don’t want to optimize for minimum free time. It sounds obvious, but I’ve caught myself and others doing this without realizing it.</p>
<p>The devil doesn’t always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the “unclutter” rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm’s reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You’ll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don’t use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking “ok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?”. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it’s that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they’re all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don’t feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don’t take notes if you don’t think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn’t apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there’s this trend in the internet of “write everything down, take all the notes!” and I think we’re tending towards an excessive “pro-notes-taking” bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I’m open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won’t be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn’t need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they’ll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is “things that I am likely to forget and look up again in the future, but I don’t care to learn by heart right now”. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think “oh, $FRIEND_X surely would find this very funny” and just write it down. And then I may send it to them through IM, but let’s be honest I could forget… until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven’t mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn’t make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I’ve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it’s really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven’t yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it’s a matter of scale and the effects won’t be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal …</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that’s not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‘clubs’ are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‘federations’ that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there’s the rise of the ‘stadium’ model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project—because every developer is relying on like hundreds of different projects—it's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it’s specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there’s less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you’ve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about…but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that’s actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we’re dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom’s definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‘club’-style communities. You might have the ‘stadium’ type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‘clubs’ or ‘federations’ depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That’s a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that’s controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else…</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It’s as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don’t mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them — we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple — every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> — similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple 👇</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> — If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. 😒</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. 💡</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exodus of Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25052818">thread link</a>) | @Reedx
<br/>
November 10, 2020 | https://breakingground.us/exodus/ | <a href="https://web.archive.org/web/*/https://breakingground.us/exodus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4180">
					
					
					
					
					<div>
					<p>On the day the sun didn’t rise in San Francisco, the early warning signs came through the screen. The 6:30 a.m. Zoom always requires unnatural light, making the outlines of faces fuzzy. The natural morning light, combined with the “Touch Up My Appearance” feature on 2020’s preferred video conferencing system, hides the marks of age and sleeplessness that most of us seek to mask. But by 9:00, the fluorescent light was still dominating the screen, and the darkness outside our windows had turned to infernal orange.</p>
<p>The scientific explanation for our sunless day in September is pretty dull. The clouds of soot from the largest California wildfire in history intermixed with the Bay Area’s perennial fog, turning the usual sepia hue of dirty global cities into an apocalyptic blood-orange sky. Though Twitter blamed the hellscape on far more menacing forces, the direct cause of our Blade Runner Day was mostly carbon clinging to the blue-light hues while letting the red pierce through.</p>
<p>If we were more like ancient peoples, many joked, we would assume the gods were enraged. We’d be running for the hills to escape their wrath, or at least head straight for our prepper bunkers. That we are unlike ancient people is actually the only myth, as this is exactly the exodus that is happening in Silicon Valley right now—and will continue for the next few years as true believers deliver themselves from this promised land.</p>
<p><a href="https://breakingground.us/from-ashes/">It’s time to build</a>, yes. But it’s also time to leave.</p>
<p>The battle over tech’s supremacy has been waged and all of our premonitions came true: We wanted flying cars and got vertical take-off innovation hubs from every car maker in America. Software has not only eaten the world, but feasted on your screen-weary eyes. It has swallowed your children, your church, your bank, and your politics, and somehow it all feels inevitable. That these feats of human progress—of instant connectivity in a now homebound world—became the scapegoat of our time is another symptom of the era’s end, cueing the quiet exodus of builders who had bigger aspirations than the same-day shipping that keeps our households afloat.</p>
<p>Now, Silicon Valley is witnessing a reckoning, but it’s not the long-awaited one predicted by the New York press, or the antitrust bonanza that Washington longs for because too many people seem satisfied getting their news from Facebook. The reckoning is more of a realization that tech exceeded expectations and somehow squandered the fruit of its own garden, and that a city on a hill that could have supported so much innovation was not Florence in the Renaissance nor the Athenian Academy with MacBooks. Rather, it became a government-sponsored needle exchange, a haven for the homeless and forgotten that put government’s paralysis on display downtown on Market Street.</p>
<blockquote><p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p></blockquote>
<p>San Francisco had four times as many deaths from overdose this year as it did from the COVID-19 virus.</p>
<p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p>
<p>* * *</p>
<p>The computer revolution of the late twentieth century has yet to be named as an epoch, but we can assume that nomenclature will begin in the coming years, alongside the battle for what it all really meant.</p>
<p>What we now call our “technological age” was supposed to be a full-throated and enduring argument for the future, not unlike previous epochs in history that pushed art, science, philosophy, and religion forward in dizzying ways that run counter to ordinary time. The Enlightenment. The Renaissance. The French Revolution. These movements now sit as categories on our bookshelves with clear beginnings and ends, and more importantly, clear hubs and cities of frenetic building that drove the ethos forward. Many books assume that contemporary critics or philosophers were blissfully ignorant to the unraveling of their revolutions, but we should not assume that contemporaries did not feel the same twilight setting. The figurative orange skies always creep in before dawn.</p>


<p>Which brings us to the supposed death of Silicon Valley, a fate that has long been predicted but with data now finally catching up. San Francisco apartment rents in 2020 have deflated by 20 percent after an up-up-and-away decade that made the city truly unlivable. Home inventory has reached a fifteen-year high in a city blighted by restrictive housing policy that makes construction cranes as miraculous as stumbling upon a burning bush. The growth in online sales-tax collection, according to the <em>San Francisco Chronicle</em>, is the lowest of all counties in the state of California. And public tech companies, such as Pinterest, paid upwards of $90 million to break its lease in downtown San Francisco. Some would argue this is a clear end to Bay Area tech dominance, while others would point to the many new unicorns that popped up this year despite the once-in-a-century pandemic. No one’s living here, yet somehow the companies are still growing.</p>
<p>Silicon Valley doesn’t really have cultural critics to weigh in on whether this era is officially over, but we do have venture capitalists. And our Nostradomuses are telling us that change is afoot.</p>
<p><em>Do we really need this office? The founders all have left.</em></p>
<p><em>Their entire partnership is now living in Montana. It’s only a two-hour flight away!</em></p>
<p><em>Denver seems like a good option, but Reno has no state income tax.</em></p>
<p>The weirdness of this exodus is that it is not driven by fear. Technologists weren’t <em>really </em>driven out by plague or fire or San Francisco’s insatiable need for higher tax revenue. Those ills were always apparent, and yet people stayed to carry the torch.</p>
<p>The exodus of tech’s true believers may be that the covenant is finally fulfilled. That when America—along with the rest of the world—met their darkest hour and turned inward, the technology that was long ridiculed as frivolous or dangerous led us to relative normalcy. The Zooms. The Tiger Kings. The Signal chats. The Slack jokes. An election news cycle that plowed ruthlessly forward on Twitter. Though inconvenient, mothers and fathers set their children in front of screens to occupy them for <em>just</em> long enough to survive a terrible year. And maybe, just maybe, the same-day-shipping racket that made Jeff Bezos the richest man alive was actually a feat of human genius that held the country together when public infrastructure and the social fabric were fraying at the seams. Perhaps our lowly software revolution was actually the fruition of a long-held California dream, when the physical world forced us inside and virtual life prevailed.</p>
<blockquote><p>Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p></blockquote>
<p>For that triumph, the nerds can now smell the impending scapegoating of their success. And like so many of history’s prophets and heretics, those who believe most fervently in the promise of technology are beginning their long march away from the Valley.</p>
<p>And they will substitute the virtual world for the physical space that once defined this movement. Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p>
<p>Silicon Valley is over. The exodus is just beginning.</p>
					</div> <!-- .entry-content -->

				
				</article></div>]]>
            </description>
            <link>https://breakingground.us/exodus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052818</guid>
            <pubDate>Tue, 10 Nov 2020 22:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 10 Most Important SQL Commands to Know]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052742">thread link</a>) | @jackmcclelland
<br/>
November 10, 2020 | https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <figure><img src="https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/SQL-Cheat-Sheet.png 600w, https://blog.arctype.com/content/images/size/w1000/2020/11/SQL-Cheat-Sheet.png 1000w, https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png 1440w"></figure><p>As companies and organizations find themselves dealing with rapidly increasing amounts of data, there's a growing need for developers to effectively use databases to handle this data. SQL, which stands for Structured Query Language, is a programming language that helps manage data stored in relational databases (a popular type of database).</p><p>SQL commands can help a developer create tables, add and modify data in these tables, search the database, and more. This article will cover a list of ten basic SQL commands that are essential to know for developers working with SQL. You'll find for each SQL command a code snipped and brief description of what the code runs.</p><p>Whether you're a beginner or a pro at SQL, consider trying out <a href="http://arctype.com/"><strong>Arctype</strong></a>, a redesigned SQL client for PostgreSQL and MySQL developers and teams. It's free, fast, and easy-to-use: <a href="http://arctype.com/" rel="noopener noreferrer">http://arctype.com/</a></p><p>Let's get right into it! Here are ten basic building blocks of SQL programming.</p><hr><!--kg-card-begin: markdown--><h2 id="createtable">CREATE TABLE</h2>
<pre><code>CREATE TABLE table_name (
  column_1 datatype_1, 
  column_2 datatype_2, 
  column_3 datatype_3
);
</code></pre>
<!--kg-card-end: markdown--><p>This command allows you to create a new database or table; the example above adds a new table with a title and column names.</p><!--kg-card-begin: markdown--><h2 id="altertable">ALTER TABLE</h2>
<pre><code>ALTER TABLE table_name 
ADD column_name datatype;
</code></pre>
<!--kg-card-end: markdown--><p>Run this command to modify (add, drop, rename, etc) the structure (not the data) in your database; the example above adds a new column to a table with a specified datatype.</p><!--kg-card-begin: markdown--><h2 id="delete">DELETE</h2>
<pre><code>DELETE FROM table_name
WHERE some_condition = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command can delete data from your table based on conditions specified with the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="drop">DROP</h2>
<p><code>DROP TABLE table_name;</code></p>
<!--kg-card-end: markdown--><p>Similar to the create command, DROP deletes a database or table. Be careful when using this command – the code above will delete your whole table, including all data, indexes, and more.</p><!--kg-card-begin: markdown--><p><code>ALTER TABLE table_name DROP COLUMN column_name;</code></p>
<!--kg-card-end: markdown--><p>The ALTER TABLE and DROP statement above will remove a specific column from a table.</p><!--kg-card-begin: markdown--><h2 id="insertinto">INSERT INTO</h2>
<pre><code>INSERT INTO table_name (column_1, column_2, column_3) 
VALUES (value_1, value_2, value_3);
</code></pre>
<!--kg-card-end: markdown--><p>To add new records to your table, use the INSERT INTO command. You can use this command on one or more rows.</p><!--kg-card-begin: markdown--><h2 id="select">SELECT</h2>
<pre><code>SELECT column_name 
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Every query begins with SELECT; this is how you grab data from your database. It's the most fundamental SQL query. After the SELECT command, you can use the keyword FROM to specify a table, the keyword WHERE to select with conditions, and the keyword ORDER BY to sort your results.</p><!--kg-card-begin: markdown--><h2 id="update">UPDATE</h2>
<pre><code>UPDATE table_name
SET some_column = some_value
WHERE some_column = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command lets you edit data in your table by updating data based on conditions specified after the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="as">AS</h2>
<pre><code>SELECT column_name AS 'Alias'
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>The AS keyword allows you to use a temporary alias when referring to a column or table.</p><!--kg-card-begin: markdown--><h2 id="count">COUNT</h2>
<pre><code>SELECT COUNT(column_name)
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Use the COUNT() function to add up the number of rows where the specified column is not NULL.</p><!--kg-card-begin: markdown--><h2 id="between">BETWEEN</h2>
<pre><code>SELECT column_name(s)
FROM table_name
WHERE column_name BETWEEN value_1 AND value_2;
</code></pre>
<!--kg-card-end: markdown--><p>This operator filters the results to be within a specified range (numbers, text, dates, etc).</p><hr><p>These building blocks will get you started programming with SQL, which is a great language useful and definitely worth learning in 2020. Check out the <a href="https://insights.stackoverflow.com/survey/2020">StackOverflow Developers Survey 2020</a>, where 65k developers answered questions about the programming languages and tools they run: SQL was top three in the most popular technologies question!</p><figure><img src="https://blog.arctype.com/content/images/2020/11/devdev.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/devdev.png 600w, https://blog.arctype.com/content/images/2020/11/devdev.png 900w" sizes="(min-width: 720px) 720px"><figcaption>If you're curious you can check out the rest of the results of the survey here at the URL here: <a href="https://insights.stackoverflow.com/survey/2020" rel="noopener noreferrer">https://insights.stackoverflow.com/survey/2020</a></figcaption></figure><p>Database programming languages are popular and have active developer communities, and are becoming increasingly important as organizations seek to process the thousands of terabytes of data generated each day. If you're working with databases in SQL or are planning on doing so, check out the newly-designed <a href="http://arctype.com/"><strong>Arctype</strong></a> SQL client. It's faster and easier-to-use than many of the clients out there right now and is designed with your needs in mind as a modern developer.</p><p>Thanks for checking out my article covering these ten basic SQL commands! Let me know if you have any questions, or would like me to write a follow-up post with more intermediate SQL commands to check out. Happy coding!</p>
            </div></div>]]>
            </description>
            <link>https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052742</guid>
            <pubDate>Tue, 10 Nov 2020 22:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantopian's open-source investment dream died]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25052699">thread link</a>) | @ugwigr
<br/>
November 10, 2020 | https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Back in 2011, John Fawcett and Jean Bredeche had the dream of democratizing investing. They envisioned a platform that would make quantitative analysis and investment accessible and understandable for anyone who was keen to give it a try, kicking down doors for the everyman that had mostly been open to hedge funds or super-rich angel investors until that point.</p>
<p>Quantopian was launched off the back of that dream. A platform that taught users about quant investment and gave them a platform to write and save their own code, Quantopian was supposed to be the first crowd-sourced hedge fund. For years, users iterated on each other’s code as a community developed on the platform, full of users with and without financial backgrounds. These users would pit their algorithms against one-another, and Quantopian would go on to use the winning equations to manage investor assets, giving the winners some returns.&nbsp;</p>
<p>Fawcett and Bredeche would go on to raise $48.8 million for Quantopian in the meantime. In 2016, Steven Cohen announced that he would be teaming up with Quantopian to the tune of $250 million, relying on some of the user models Quantopian managed and investing in Quantopian itself.</p>
<p><span>In February, the first cracks in the city wall took hold. For at least two years, Fawcett said in </span><a href="https://www.bizjournals.com/boston/news/2020/02/20/fintech-firm-quantopian-is-returning-investors.html"><span>an interview</span></a><span>, Quantopian’s low-risk, market-neutral strategy model hadn’t been yielding results. Fawcett and Bedeche announced that the company would be returning investor money and switching strategies in an attempt to keep things afloat, </span><a href="https://www.quantopian.com/posts/quantopian-strategic-pivot"><span>asking that users</span></a><span> now develop models beyond the market-neutral ones the company had relied on for years.</span></p>
<p>Now, the dream is dead.</p>
<p><span>This week, Quantopian </span><a href="https://www.quantopian.com/posts/quantopians-community-services-are-closing"><span>abruptly announced</span></a><span> that it would be shutting down its community services and that users would lose access to all their materials if not saved locally by November 14. No reason was given for the shutdown.&nbsp;</span><span>Quants across the finance community expressed equal parts shock and disappointment that Quantopian had </span><a href="https://www.linkedin.com/posts/dr-tom-starke-a0a9a3b3_tribute-to-quantopian-activity-6728150978325045248-Lrsf/"><span>come crashing down</span></a><span>.&nbsp;</span></p>
<p>“Our mission was to break open quant finance and make it accessible to everyone,” Fawcett wrote in a blog post on Quantopian’s website. "You helped realize this mission and came together to form the biggest community of quants the world has ever seen. For that, I am extremely proud and grateful. I sincerely hope that Quantopian is just one milestone in your journey through quantitative finance.”</p>
<p>The announcement was met with mixed reception. Some users gave tearful goodbyes to the platform and expressed interest in crowdfunding the site, while others expressed outrage at the seemingly abrupt decision.&nbsp;</p>
<hr>
<blockquote>
<h2>"Was there a heads-up so we could retrieve our results? backtests? :("</h2>
</blockquote>

<blockquote>
<h2>"My god no. is there any way to save the quantopian community site ??? why is this site closing down???"</h2>
<h2>"0-day notice! Are you kidding me &gt; where is all the code ???"</h2>
</blockquote>
<hr>
<p>Fawcett gave no answers. Users wondered the extent to which Quantopian would disappear; would the lectures and learning resources be preserved online somewhere? Would they be able to recover assets of theirs which had already been taken down? Where would they go to chat and organize with other quants and finance junkies?&nbsp;</p>
<p>The name Quantopian gave itself proved to be an ominous foreshadowing of its eventual fate. All utopias must fall, and Quantopian’s democratic dream had turned to sand and fallen through users' fingers before they could come to grips with what was happening.&nbsp;</p>
<p><span>In 2020, Quantopian’s dream of “democratizing finance” isn’t unique. Trading app Robinhood touts </span><a href="https://robinhood.com/us/en/support/articles/our-mission/#:~:text=Robinhood's%20mission%20is%20to%20democratize,for%20newcomers%20and%20experts%20alike."><span>the exact same mission</span></a><span>, and it’s trying to pick up where Quantopian left off. Yesterday, Fawcett announced that Quantopian and Robinhood would be </span><a href="https://www.quantopian.com/posts/were-joining-robinhood"><span>coming together</span></a><span> in what he described as a natural fit for the two companies.&nbsp;</span></p>
<p><span>“</span><span>Quantopian has always stood for greater access and deeper education, so we are fundamentally aligned with Robinhood’s mission to democratize finance for all,” Fawcett wrote. “Our merry band of Quantopians should fit right in as we work together to further expand access to financial information and education, and inspire greater participation in the financial markets.”</span></p>
<p>Fawcett offered little details as to how this deal would take form, but one thing was clear: the Quantopian of old would no longer exist.</p>
<p>These platforms are more than the sum of their parts, and Quantopian’s community structure — the factor which most makes it unmistakably itself — will not be preserved by Robinhood.&nbsp;</p>
<p>Robinhood has grown to considerable size and been downloaded by an ever-increasing number of users during the COVID-19 pandemic who are using it to invest and, hopefully, make a little extra money during trying times. Or, if they’re lucky enough, make it big.&nbsp;</p>
<p><span>But although Robinhood shares the same mission as Quantopian at first glance, it is propped up on something much uglier than Quantopian ever was. Robinhood lacks a community element, and what implementations it has tried have had </span><a href="https://fortune.com/2020/08/10/robinhood-popularity-data-robintrack-stock-market-trading-tracker/"><span>disastrous impacts</span></a><span>. A read through the replies to Quantopian’s shutdown announcement reveal the deep histories users had on the platform.</span></p>
<p>“Within a few months after joining in 2016, I'd learned Python, programmed all of my Excel-based strategies, entered and won Contest 22, [and] started live trading in IB,” user Roman Parker wrote. “With no relevant degree or experience, I was interviewing at large NYC funds. Q was changing my life.”</p>
<hr>
<blockquote>
<h2>"Never in my life have i seen a place where so many smart people were willing to share so much information with me without expecting anything in return. I am and will forever be grateful for what you have done for me." — Quantopian user Mattias Lamonte</h2>
</blockquote>

<hr>
<p>The communities that have sprouted up around Robinhood’s success are much darker. Communities like r/wallstreetbets and viral videos like the infamous “<a href="https://www.youtube.com/watch?v=A-tNkuYV4_Q">wsb yolo</a>,” which shows a man losing tens of thousands of dollars on the app in real time, keep sincerity at an arm’s length and sustain themselves with desperate humor. Though the output of Quantopian’s community was ultimately gobbled up by Quantopian itself and its investors, what Quantopian provided to its users was collaboration and experience. Robinhood’s frenzy is about who can win big, and who can lose bigger.</p>
<p><span>Even if the business end couldn’t keep itself afloat, the utopia existed, for a time, for the site’s users, many of whom had their lives and careers changed by Quantopian’s open platform and its catalog of resources. Today, other services like Quantiacs and QuantConnect operate off similar models to Quantopian’s. The first to do something isn’t always the best to do it, and perhaps one of these companies will perfect what Quantopian initially set out to do.</span></p>
<p>These lives wouldn't have been impacted if Quantopian had not put out the rallying call, but ultimately, users didn't need Quantopian as much as Quantopian needed them.&nbsp;Quantopian gave them the first rocks and sticks, and the community used it to build cities. In the end, it was the failure of the company itself, not those who used its tools, to deliver on the promise that attracted such a large community to begin with.</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052699</guid>
            <pubDate>Tue, 10 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Tech Is More Fun]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052491">thread link</a>) | @amzans
<br/>
November 10, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That’s why I wouldn’t bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It’s a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear’s tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052491</guid>
            <pubDate>Tue, 10 Nov 2020 21:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051897">thread link</a>) | @csomar
<br/>
November 10, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven’t been using Rust for production much; maybe a bit more than a year. The static type checks means I’m getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn’t have a running syslog service by default.</p>

<p>Now that’s fine, the program functioned correctly. But I don’t care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let’s take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don’t want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that’s it. This code now compiles and runs correctly. If syslog is running, it’ll write logs to syslog and the terminal. Otherwise, it’ll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it’s perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>100</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>100</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051897</guid>
            <pubDate>Tue, 10 Nov 2020 21:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messenger App Tutorial with Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051678">thread link</a>) | @szsoppa
<br/>
November 10, 2020 | https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1 | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In a series of articles <strong>(don't forget to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a>!)</strong>, we'll convince you that Phoenix LiveView will revolutionize the way you create reactive UIs!</p>
<h2>Why Phoenix?</h2>
<p>The thing about Elixir, on top of Erlang/OTP, is that it offers a great mix of making life easy and being a scalable and reliable platform that will not let you down when your estimated traffic of 4000 users becomes 4,000,000 users.</p>
<p><strong>Phoenix Framework</strong> is Elixir's answer to the never-ending question of how to build rich web applications, and it's got a lot of tools that make the job easy - one of the latest being <strong>Phoenix LiveView</strong>.</p>
<p>Long story short, <strong>LiveView is a tool that lets an Elixir developer create reactive UIs without writing a single line of JS code</strong>. Which is great, given that many Elixir developers do not exactly consider themselves fluent at JS, or - just like myself - are not exactly in love with JS.</p>
<h2>Lessons learnt from reactive UI libraries</h2>
<p>Many JavaScript frameworks, both contemporary and not-so-contemporary ones, rely on manipulating the page's DOM for dynamic content updates.</p>
<p>Historically, for instance, developers using BackboneJS would define a <code>Backbone.View</code> to represent an <em>atomic chunk of user interface</em>, behind which there's a <code>Backbone.Model</code>, encapsulating the business logic of data.</p>
<p>Backbone remained unopinionated about how views were to be rendered, so it had no built-in tools to make the re-rendering of views on model changes efficient - the whole structure of a view had to be built from scratch and replaced, which tended to yield inefficient views.</p>
<p>In contrast, modern frameworks such as ReactJS or Vue.js don't care about how the data model layer works at all (loosely coupled data stores such as Redux are often used for this) - but they have a <strong>virtual DOM</strong> concept - long story short, a pattern of incrementally upgrading only those elements that need to be changed, based on changes in the state of particular components and their children.</p>
<p><strong>The challenge, though, is pretty much down to how to exchange data between the UI and the backend.</strong> You will usually need to implement a JSON API or a GraphQL service, or perhaps you could develop a WebSocket-based solution using Phoenix Channels.</p>
<p>Either way, the <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank">Pareto 80/20 principle</a> will imminently catch you, and when you get to the 20% of work needed to finish off your message-passing code, it'll soon become a <em>framework within a framework</em>.</p>
<h2>Why, where &amp; how LiveView excels</h2>
<p>Phoenix LiveView's concept is both groundbreaking and familiar, in different ways.</p>
<p>It is familiar in that it lets you define UI elements as nestable components composed of pure HTML markup, and it builds upon the experience of reactive UI frameworks in implementing mechanisms that calculate diffs between consecutive UI states to ensure efficient updates.</p>
<p>It is groundbreaking in the way it maintains the states of components and manages their updates - <strong>in Phoenix LiveView, components are stateful on the server, and their events and updates are communicated via a bidirectional WebSocket connection</strong>.</p>
<p><strong>Phoenix LiveView is built on top of Elixir processes and Phoenix Channels</strong> - every LiveView instance is a BEAM process, acting very much like a <a href="https://hexdocs.pm/elixir/GenServer.html" target="_blank">GenServer</a>, receiving messages and updating its state.</p>
<p>While modern JS frameworks such as React have server-side rendering capabilities, it is usually not convenient to do this in a non-NodeJS backend server. Rendering content via JavaScript often results in SEO issues, and some trickery is needed for search engines to index the page correctly. <strong>In Phoenix LiveView, the initial render is static as in the classic HTML request-response cycle</strong>, so you'll get good <a href="https://developers.google.com/web/tools/lighthouse" target="_blank">Lighthouse scores</a> and it won't hurt your SEO.</p>
<p>Erlang easily maintains thousands of processes concurrently, and Phoenix authors have even <a href="https://phoenixframework.org/blog/the-road-to-2-million-websocket-connections" target="_blank">managed to make it handle 2 million WebSocket connections</a> on a single (albeit pretty strong) machine. With the server using Elixir's strengths to manage LiveView states, <strong>the client-side logic can be thin and simple</strong>.</p>
<p>In fact, as stated in the introduction, <strong>in most LiveView-powered apps you won't write a single line of JS code</strong>. In many cases, when interacting with an element whose update is supposed to fetch data for a new UI state from the server, the workflow using a reactive JS framework would be:</p>
<ol>
<li>Handle the element's <code>change</code> event
</li>
<li>Send a request to the server containing the actual changes
</li>
<li>Receive response and update state store based on response data
</li>
<li>Let the view layer re-render the changed DOM elements
</li>
</ol>
<p>This involves annotating HTML elements so that they can be identified by JS code, writing browser-side scripts to handle the element's state change event, send a payload to the server, which processes the request as part of a Phoenix controller action.</p>
<p><strong>With Phoenix LiveView, you only write HTML and Elixir code, with the JS part being handled by a script bundled with the LiveView package.</strong></p>
<h2>Phoenix LiveView basic usage</h2>
<p>The basic idea behind Phoenix LiveView is very simple and straightforward. <strong>Be sure to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> to learn more!</strong></p>
<p>LiveView is an Elixir behaviour, and your most basic LiveView definition will consist of two callback implementations:</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:render/1" target="_blank"><code>render/1</code></a> function, containing the template of how your component is represented in HTML, with elements of the component's state interpolated. This is much like defining an ordinary view. The special <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#sigil_L/2" target="_blank"><code>~L</code> sigil</a> is used to interpolate <code>assigns</code> into your EEx syntax, and convert it into an HTML-safe structure.
</li>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:mount/2" target="_blank"><code>mount/2</code></a> function, wiring up socket assigns and establishing the LiveView's initial state.
</li>
</ul>
<pre><code>  <span><span>defmodule</span> <span>YourappWeb.CounterLive</span></span> <span>do</span>
    <span>use</span> Phoenix.LiveView

    <span><span>def</span> <span>render</span></span>(assigns) <span>do</span>
      ~L<span>""</span><span>"
      &lt;a href='#' phx-click='increment'&gt;
        I was clicked &lt;%= @counter %&gt; times!
      &lt;/a&gt;
      "</span><span>""</span>
    <span>end</span>

    <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
      {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
    <span>end</span>
  <span>end</span></code></pre>
<p>However, the whole fun of using LiveView is managing its state, and the next two callbacks will come in handy.</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_event/3" target="_blank"><code>handle_event/3</code></a> function, handling events coming <strong>from the browser</strong>. Noticed the <code>phx-click</code> attribute in our template's link? This is the name of an event that will be transported to the LiveView process via WebSockets. We'll define a function clause that will match to the event's name.
</li>
</ul>
<pre><code>  <span><span>def</span> <span>handle_event</span></span>(<span>"increment"</span>, params, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, assign(socket, <span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  It will mutate the LiveView's state to have a new, incremented value of the counter, and the <code>render/1</code> function will be called with the new assigns.</p>
<p>  The second argument, here named <code>params</code>, is of special interest as well, because - in the case of a <code>phx-click</code> event - it contains the event's metadata:</p>
<pre><code>  %{
    <span>"altKey"</span> =&gt; <span>false</span>,
    <span>"ctrlKey"</span> =&gt; <span>false</span>,
    <span>"metaKey"</span> =&gt; <span>false</span>,
    <span>"pageX"</span> =&gt; <span>399</span>,
    <span>"pageY"</span> =&gt; <span>197</span>,
    <span>"screenX"</span> =&gt; <span>399</span>,
    <span>"screenY"</span> =&gt; <span>558</span>,
    <span>"shiftKey"</span> =&gt; <span>false</span>,
    <span>"x"</span> =&gt; <span>399</span>,
    <span>"y"</span> =&gt; <span>197</span>
  }</code></pre>
<p>  We trust that you won't now hesitate to try it out with a <code>&lt;form&gt;</code> tag and a <code>phx-change</code> attribute to see what event metadata are passed when a form element's value is changed. Either way, <strong>we'll explore this in more detail in later episodes of this tutorial - stay tuned and <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> so that you don't miss out</strong>!</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_info/2" target="_blank"><code>handle_info/2</code></a> callback, handling events coming from <strong>anywhere but the browser</strong>. This means events sent from external sources <em>(remember a LiveView is just an Elixir process, so you can do whatever's needed in order for it to receive messages!)</em>, or events sent from the LiveView to itself. For instance, it takes this to increment the counter every 5 seconds:
</li>
</ul>
<pre><code>  <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
    if connected?(socket), <span>do:</span> <span>:timer</span>.send_interval(<span>5000</span>, <span>self</span>(), <span>:increment</span>)

    {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
  <span>end</span>

  <span><span>def</span> <span>handle_info</span></span>(<span>:increment</span>, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, socket |&gt; assign(<span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  To reduce code repetition, you could make <code>handle_event/3</code> send a message to <code>self()</code> that triggers the same <code>handle_info/2</code> routine.</p>
<p>You can now access your LiveView as a standalone route - to do this, put this in your <code>router.ex</code>:</p>
<pre><code><span>import</span> Phoenix.LiveView.Router

scope <span>"/"</span>, YourappWeb <span>do</span>
 live <span>"/counter"</span>, CounterLive
<span>end</span></code></pre>
<p>...or render the LiveView within any other template:</p>
<pre><code>&lt;%= Phoenix.LiveView.live_render(<span>@conn</span>, YourappWeb.CounterLive) %&gt;</code></pre>
<h2>The Curious Messenger Roadmap<a name="series" target="_blank"></a></h2>
<p>We'll make you familiar with how to wield the Phoenix LiveView sword, and you'll build a fully-fledged Messenger replacement, which will make you (almost) forget about any other instant messaging app you had ever used before...</p>
<p>Phoenix LiveView is obviously only part of the story, and there's a lot more ground that we'll cover. We'll do a few episodes, each of which touches a different set of concerns that we'll have to consider when designing the app.</p>
<ul>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-2" target="_blank">At the beginning, we'll bootstrap the app and install all needed dependencies, design the app's database and context structure, with all of the app's business logic in mind.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-3" target="_blank">Then we'll implement the app's user authentication feature using Pow, a great library integrating all the tools you need to let users sign up and log into the application. Next, we'll go on to implement the actual awesome Curious Messenger features, and here's where most of the <strong>Phoenix LiveView</strong> magic will shine. We'll show you how to create a live-updated view of your contact list and of each of your conversations.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-4" target="_blank">Obviously, we'll also elaborate on what can go wrong when using LiveView, because the worst assumption one can make is that people's network connections are perfect. We'll see for ourselves that Phoenix LiveView is not the Holy Grail of reactive UI building solutions and that this approach has several shortcomings that need to be kept in mind.</a>
</li>
<li>Finally, we'll fine-tune the Curious Messenger app, adding some customizable settings and push notifications <em>(did we actually say there'll be no JS? We lied.)</em> so that you never miss out on any message from …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</a></em></p>]]>
            </description>
            <link>https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051678</guid>
            <pubDate>Tue, 10 Nov 2020 20:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flaws of “Subscription Fatigue”, “SVOD Fatigue”, and the “Streaming Wars”]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25051292">thread link</a>) | @bschne
<br/>
November 10, 2020 | https://www.matthewball.vc/all/misnomers | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/misnomers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-96dbb3b03808a860d80e"><div><p>When we consider the state of tech-media in 2020, there are a few common narratives. The most inescapable is the “Streaming Wars”. In November, I argued that <a href="https://www.matthewball.vc/all/minedmedia">this term was a misnomer</a>. Digital/streaming/OTT video is really just <em>a</em> battle in a much larger war: the “ecosystem war”. And for the most part, this war is fought asymmetrically. Apple and Amazon both sell digital media devices, third-party media content, and their own original content, for example. However, Apple isn’t an e-retailer nor a diversified enterprise cloud services provider, and Amazon doesn’t even have a smartphone, personal computer, watch or non-video app store. I’ll come back to this idea, but understanding the differences between these companies and their motivations is helpful when considering two other popular phases that are unhelpful at best and misleading at worst: “subscription fatigue” and “SVOD fatigue”.</p><p><strong>“Subscription Fatigue”</strong></p><p>The “subscription economy”, by definition, presumes that the overall “economy” – from products, to services, content, transportation, labor and more – is shifting over to “subscriptions”. Thus, to claim that consumers have “subscription fatigue” is to say that they have “spending fatigue”.</p><p>As always, most consumers will say they wish they spent less money, bought fewer things, and enjoyed lower prices. However, it makes little sense to say that the decision to buy TV subscriptions, radio subscriptions, toothbrush subscriptions, video gaming subscriptions, dog food subscriptions, car subscriptions, or productivity software subscriptions should drive “subscription fatigue” or mean each subscription competes with one another. For decades, consumers have bought TV, music, toothbrushes, video games, dog food, cars and Microsoft Office. What’s new is that they all have similar models – digitally-based, predominantly D2C subscriptions. This changes nothing about the individual value or baseline need for them.</p><p>Of course, the “subscription economy” does mean that step one of a recession will be to “re-evaluate all subscriptions”. However, this does not mean subscription <em>fatigue</em> should be considered a real “thing”, let alone a defining element of modern-day competition. Furthermore, payment model – upfront v. recurring, subscription v. á la carte, online v. offline – is irrelevant to what’s “re-evaluated” and not. Some subscriptions are “necessities”, like toilet paper, while others are concerned with discretionary spend, such as Office 365 or Netflix or Tinder. This latter group isn’t competitive because they’re “subscriptions”, but because there is, as always, finite spending money for non-essential items. </p><p>To this end, it’s important to highlight subscriptions are often a <em>preferred</em> buying path for consumers. Most would rather (or can only afford) $10 a month for a multi-year license to Microsoft Office for $300. Subscriptions also meaningfully reduce the cognitive burden of repeat decision making. No longer do you need to “track” your toothbrush for wear, risk “running out” of toilet paper and then be forced to overpay for a small-volume purchase, or need to scan and hoard coupons to ensure a great deal. Similarly, many consumers would rather marginally overpay for an all-you-can-eat subscription than optimize for specific tiers of use. In fact, most of us have caustic responses to per unit pricing, often to the point of irrationality (e.g. $40 for 35 loads of laundry detergent v. $1.00 per load). Amazon Prime is based on the <em>need</em> to get shipping fees out of the way once, versus fight them over and over and over and over, even if the effective shipping cost went up for a consumer, or the lack of shipping costs led to unnecessary purchases.</p><p>The rise of fully flexible monthly commitments also means that consumers no longer have to worry about having made a bad decision and being stuck with it. In this sense, every subscription is still á la carte, but unlike in the analog era, the default outcome of “doing nothing” is to keep getting value you enjoy rather than running out of a thing you need. </p><p><em>(Note that none of this means that a digital subscription business is a “good” one. Many sub-categories of CPGs and foodstuffs, not to mention music or fitness equipment, weren’t good business before the shift to subscription. The fact they shifted to subscriptions doesn’t inherently change this, just as it doesn’t mean they suddenly compete with all other subscriptions).</em></p><p><strong>“SVOD Fatigue”</strong></p><p>Of course, the nuances of “subscription fatigue” is separate from the question of “Subscription <em>VOD</em> fatigue”. It is obvious consumers don’t need 20 Netflixes. However, they’re not being asked to buy 20 Netflixes. It’s wrong to treat Fox Nation, Netflix, ESPN, and Twitch as competitors, let alone interchangeable “units of SVOD”. They serve very different functions and offer very different content. Just as Spotify and the <em>New York Times</em> and Amazon Prime shipping each do.</p><p>Amazon and Apple TV+, meanwhile, aren’t Netflixes – not in monetization, content volumes, or strategy. Now, if Amazon or Apple’s SVOD services can monetize so dramatically better through the Prime and iOS ecosystem than Netflix can via direct consumer spend and a singular focus, they can, in theory, “kill” Netflix – should they so choose – but that has nothing to do with SVOD fatigue nor the number of viable SVODs.</p><p>The question of SVOD fatigue isn’t about “how many SVODs will the average household have”. It’s really about “how many different roles are there to be played in video”. And the answer here is mostly path dependent – it depends on the innovation, risk taking, and discovery that happens in the marketplace, as well as timing. No one knew “live streaming video games” was an opportunity until Twitch, for example. And while Twitch likely steals <em>time</em> away from the video ecosystem, the viability of the Twitch subscription doesn’t mean that the number of viable OTT services has reduced.</p><p><strong>The Question</strong></p><p>All of which is to say what matters in SVOD is simple and not unique to SVOD: <span>A service will succeed if (1) it addresses a real, outstanding customer want/need; (2) at an appropriate price or value to the consumer; and (3) while generating sustainable economics</span>. </p><p>Quibi is a good example here. The company believes that there is an outstanding need for a new type of content, focused on a different time and place, under a different viewing behavior and focused on a specific audience. If it is right, and it can build up a defensible leadership position before other players replicate it, a new subscription will be possible and it doesn’t matter how many SVODs a customer already has (just as whether they have NYT or Spotify doesn’t matter). But of course, if you ask consumers “do you wish you had fewer subscriptions” or “fewer SVODs”, they will say yes – especially if they don’t really know what the new “thing” is. Note, too, that Pay-TV studies have been promising that 10%–30% of subscribers will cancel each year. They never do… because enough value remains. </p><p>More broadly, this three-point framework is well established (it actually has nothing to do with video). Over the past forty years, we have seen countless examples of “networks” launching into hyper-saturated marketplaces with hyper-specific but unproven (and often openly derided) theses regarding outstanding consumer wants and needs. Almost all of these have succeeded. In fact, they usually spawned several direct competitors – showing that the unmet want was even larger than originally anticipated. &nbsp;</p><p>For example…</p><ul data-rte-list="default"><li><p><em>1972: HBO launched a network focused on the most valuable TV time, Sunday night, with an unprecedented monetization model (á la carte consumer spend and no advertising), and focused only on reruns of Hollywood movies. It was ultimately bought by 25% of TV homes, became the most profitable network in the world and the market leader in quality. And this was despite the launches of Showtime (1976), Starz (1994) and Epix (2009).</em></p></li><li><p><em>1977: Nickelodeon launched 24/7 content only for kids. No longer was kids content relegated just to afternoon and Sunday morning blocks. In the 2000s, Nickelodeon became the most watched cable network, despite having spun-off several other Nick-branded channels and seen the launch of The Disney Channel in 1983.</em></p></li><li><p><em>1979: ESPN launched a 24/7 sports channel, ultimately with the highest programming budget in the world. In 2019, it brought in more than $2.5B in profits, with an annual revenue of roughly $9B. In 2009, Fox launched its own suite of 24/7 Fox-branded sports networks.</em></p></li><li><p><em>1980: CNN launched a 24/7 news channel. Today, it generates an estimated $800MM a year in cash flow on $2B in revenue, and several other 24/7 networks exist.</em></p></li><li><p><em>1981: MTV launched a 24/7 music video and culture channel that focused only on young audiences. The result was the first new Hollywood film/TV conglomerate in decades. Within years, MTV had launched several other 24/7 networks, while competitors launched even more focused versions, such as CMT.</em></p></li><li><p><em>1983: BET launched a 24/7 network focused on black American audiences. In 2001, the company was sold to Viacom for $3B. Several other black-focused networks exist today. </em></p></li><li><p><em>1996: Fox News launched a 24/7 news channel… only for half of news watchers. It now generates more than $1.5B in cash on $2.5B+ revenue</em></p></li></ul><p>Of course, this sort of logic can be used to justify faulty assumptions around what opportunity exists, where, how large it might be, how durable it is, etc. In addition, these specifics gaps were open because of technological limitations. A network like ABC could only air one thing at a time – and therefore there were structural impediments to serving “everyone”. Netflix, meanwhile, can air anything, at any time, to every viewer, and on an individual basis.</p><p>But the crucial point here is that it’s wrong to think about the “number” of subscription video services, just as it was wrong to think about how “many” networks were in the cable bundle in 1980, 1985, 1990, and so on. In fact, it’s incredibly close …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/misnomers">https://www.matthewball.vc/all/misnomers</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/misnomers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051292</guid>
            <pubDate>Tue, 10 Nov 2020 20:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-Scale Geo-Replicated Conflict-Free Replicated Data Types [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051115">thread link</a>) | @simonebrunozzi
<br/>
November 10, 2020 | https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf | <a href="https://web.archive.org/web/*/https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051115</guid>
            <pubDate>Tue, 10 Nov 2020 20:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 questions for writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050838">thread link</a>) | @flreln
<br/>
November 10, 2020 | https://vasilishynkarenka.com/8questions/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/8questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg" alt="8 questions for writing">
            </figure>

            <section>
                <div>
                    <p>You cannot write productively if you do not have a plan.</p><p>That’s why most people struggle with writing: they have an idea to communicate but no specific plan of action to express their thought. As a result, they either procrastinate and never begin writing in the first place, or they hit writer’s block and spend hours staring at a blinking cursor on the top of a blank page.</p><p>The reason why people don’t plan writing is counterintuitive. They <em>think</em> they know how to write because they know the alphabet. But just like learning how to drive Toyota Prius in the suburbs doesn’t make you Michael Schumacher on track, knowing how to write symbols doesn’t make you a professional writer. You need to learn the skill.</p><p>The secret to good writing, as to any kind of knowledge work, is deliberate planning. If you do not have a plan, writing becomes a mysterious process you do only when you’re inspired. But if you document what you’re going to do, writing turns into a professional act with less opportunity for sloth. And the best way to plan writing is to ask questions.</p><p>If you think about something proactively, you run two mental processes at once. First, you keep the subject of your thought in your working memory. And second, you actively search through your mind for the object of interest. That’s a problem, given how much effort it takes to stay focused on a task.</p><p>But if you present yourself with a question, you change that. When you write the question down and look at it, you stay focused for longer. You benefit from your sensory channels to stay engaged, and you also run one mental process instead of two.</p><p>That’s why I’ve built a simple routine of asking myself a set of questions about what I’m planning to write. I apply it whenever I experience an itch like, “Oh, I could write an article about this!” After running the process for two months, I’ve empirically discovered how important it is to capture the idea right at the moment when it’s being formed. If I don’t turn my thought into an objective artifact that I can revisit later, I lose it.</p><p>Here are five reasons why questions work so well for writing:</p><ol><li>Good questions are like an advanced Google Search query to your mind. They have high suggestive value because the parameters that you pass to a question light up relevant areas of memory for you. If you do not have a question in mind and just roam through ideas, you’re like a first-time Google user who blindly presses “I’m Feeling Lucky” all the time.</li><li>Questions exist in the physical world. When you write a question down, you can get back to it later and think about it again. If you do not write your thought down, it will fly away from your unstable working memory, and you may never get into the same situation that triggered that thought in the first place. As it’s tough to trace back the system one thinking [1], you’re way better off writing things down.</li><li>Questions are discovery satellites for new knowledge. The best thing about questions is that you can ask yourself something you do not yet know. When you write down a problem with no answer, you may revisit it later and add new information as you develop more understanding. More interesting and less obvious is that asking yourself questions for which you have no answers triggers curiosity and programs your subconscious to think about it in the background.</li><li>Questions convince yourself that your work is important. This may sound trivial at first, but I’ve discovered that if I don’t have a decent argument why what I’m writing is important, I produce bad writing or get stuck in writer’s block. And it’s way easier to stay convinced that what you’re doing matters if you documented the reasons on paper – you can get back to your questions and get inspired when things get tough.</li><li>Questions help you avoid obvious mistakes. In many professions, checklists are a must. If you’re a pilot or a surgeon, you spend years mastering simple procedures because you don’t have time to do system two thinking when you have a problem in the field. You need to have already thought. I believe writers benefit from checklists even more because writing is considered to be a creative act, and most creative tasks usually benefit from systemic approaches and vice versa.</li></ol><p>Below are the questions I routinely ask myself when I’m profiling an idea.</p><h2 id="1-why-do-i-want-to-write-this-article">1. Why do I want to write this article?</h2><p>When you answer that question, you will discover the <em>actual</em> problem that you want to solve with the piece. Often, the problem will be different from the original idea of the article. If you have experience with the topic, you’ll likely see a better solution, a different angle of attack you can use to solve a reader’s problem.</p><p>For example, when I started <a href="https://vasilishynkarenka.com/learning/">my work on learning</a>, the original idea was to produce a theoretical piece describing the research that I’ve done. But when I answered the first question, I realized that my work aims to help a reader improve their learning process, and the best way to do that would be to write a description of my own process and embed principles into it of preaching theories.</p><p>The answer will often contradict the initial idea that you’ve come up with. That’s fine – just update the idea. What you must avoid doing is continuing with the initial plan if you’ve clearly discovered a better one after answering the question. Even if you already have the draft done, you must rewrite the whole thing because your job as a writer is to not waste reader’s time.</p><p>Here’s how I defined the “why” for this work:</p><blockquote>Q: Why do I want to write this article?<br>A: I want to help people improve their writing process by adding a simple routine of asking questions.</blockquote><p>The “why” question is also a test for abstractions. If you do not have a concise answer, you will find yourself attempting to write an all-covering piece. Avoid that mistake and define the purpose of the work first.</p><p>If you cannot answer the question, do not write this article.</p><h2 id="2-what-do-i-want-to-write-about">2. What do I want to write about?</h2><p>The answer to the question determines the subject of your article. The subject is what the article is about, the broader topic of the work [2]. For example:</p><ul><li>“I wanna write about productivity.”</li><li>“I want to write about learning.”</li><li>“I want to write a post about habits.”</li></ul><p>Here’s my subject for this post:</p><blockquote>Q: What do I want to write about?<br>A: I want to write about the writing process.</blockquote><p>When you answer the second question, you will grasp the category of knowledge you’re dealing with and enrich your writing.</p><p>Categories are a form of abstraction that we use to deal with complexity. Imagine a fridge. What I just did is I put some mental image in your head. But the refrigerator that you see is not some specific fridge, like the one you have in the kitchen, although it might be close. The fridge’s image in your head is an abstract fridge that combines details of fridges you have seen in the past. That’s what a category is.</p><p>The most value of categories comes from enrichment. When you see a new, tall, metallic rectangular object with two sections and a handle, you can’t help but guess it’s a fridge, because its properties match with the properties of fridges you have seen before. But you not only deduce the category of the unknown object based on how its features compare with the category representation that you know. You also <em>enrich</em> the concrete object with the features you expect an item of this category to have. In the fridge that you imagined, you’d expect to have some shelves inside, maybe a pack of eggs, or a cold bottle of Guiness. Without knowing it for sure, you pre-suppose to find this stuff in a new fridge that you see because of enrichment.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@alexacea?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandru Acea</a> on <a href="https://unsplash.com/s/photos/fridge?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption></figure><p>Once you understand the category of your work, you will be able to pull different ideas from the category level to enrich your article and better serve the reader. For example, suppose you’re writing a piece on fitness habits. In that case, you may jump to the category level and understand that fitness is about fitness habits <em>and</em> nutrition, <em>and</em> sleep. You could also level up to the habits category and see if there’s anything to pull from there – any similarities between building a habit of jogging and learning to play the piano? And if you have something to say on those things and it fits the context of your work, you can enrich your work.</p><p>The process of jumping between categories may sound complicated. I’d recommend taking a piece of paper and a pen to draw things when you’re getting started. The paper will make it easier to see the category literally “above” the object because of spatial cognition [3], and you will discover other objects from that category (i.e., nutrition, sleep) because of the white space effect when your mind fills in the missing details for you.</p><p>With experience, the process of jumping across categories of knowledge, and looking at a thing from different angles becomes automatic. It integrates into your perception so well that you don’t even notice it happening. Like a chess grandmaster, you just <em>know</em> a good move.</p><h2 id="3-what-do-i-want-to-say-about-the-subject">3. What do I want to say about the subject?</h2><p>The third question determines your theme. The theme is what you have to say about the subject you’re writing about. For example, here’s a subject-theme pair for this work:</p><p>Subject:</p><blockquote>Q: What do I want to write about? <br>A: I want to write about the writing process.</blockquote><p>Theme:</p><blockquote>Q: What do I want to say about the subject?<br>A: I want to convince my reader that asking yourself simple questions about an article helps a) flesh out the idea better and b) notice more ideas for writing. To make the process easier, one could use shortcuts and think of an article as a set of blocks rather than one big monolithic piece.</blockquote><p>The purpose of selecting your theme is to limit what you’re writing about and outline a course of work. As you may have noticed, there are many things one can say about the writing process. If I attempted to write a piece on the “writing process” as …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/8questions/">https://vasilishynkarenka.com/8questions/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/8questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050838</guid>
            <pubDate>Tue, 10 Nov 2020 19:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft Array API Standard Released for Public Comment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050558">thread link</a>) | @travisoliphant
<br/>
November 10, 2020 | https://data-apis.org/blog/array_api_standard_release/ | <a href="https://web.archive.org/web/*/https://data-apis.org/blog/array_api_standard_release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post" itemprop="articleBody">
    
    <p>Array and tensor libraries - from NumPy, TensorFlow and PyTorch to Dask, JAX,
MXNet and beyond - could benefit greatly from a uniform API for creating and
working with multi-dimensional arrays (a.k.a tensors), as we discussed in
<a href="https://data-apis.org/blog/announcing_the_consortium/">our previous blog post</a>.
Today we’re pleased to announce a first version of our array API standard
(<a href="https://data-apis.github.io/array-api/latest">document</a>,
<a href="https://github.com/data-apis/array-api/">repo</a>) for review by the
wider community. Getting to this point took slightly longer than we had
initially announced because, well, it’s 2020 and hence nothing quite goes
according to plan.</p>
<p>The current status of the standard is that it is a coherent story (or at
least, we hope it is) that gives readers enough context about goals and scope
to understand and review the design decisions already taken and APIs it
contains. However, <em>it is not yet complete and we can still change direction
and make significant changes based on community feedback</em>. This is important
— no one likes a “take it or leave it” approach, and more eyes can make the
final result better. There’s still a few TODOs in places, and a couple of key
sections to be finished. The most important of those are the API for device
support, and the Python API for the
<a href="https://data-apis.github.io/array-api/latest/design_topics/data_interchange.html">data interchange protocol</a>
(proposed to be based on <a href="https://github.com/dmlc/dlpack">DLPack</a>).</p>
<p>It is worth repeating the main goal of this standard: make it easier to
switch from one array library to another one, or to support multiple array
libraries as compute backends in downstream packages. We’d also like to
emphasize that if some functionality is <em>not</em> present in the API standard,
that does <em>not</em> mean it’s unimportant, or that we’re asking existing array
libraries to deprecate it. Instead it simply means that that functionality at
present isn’t supported - likely due to it not being present in all or most
current array libraries, or not being used widely enough to have been
included so far. The <a href="https://data-apis.github.io/array-api/latest/use_cases.html">use cases section</a>
of the standard may provide more insight into important goals.</p>
<h2 id="some-key-design-topics">Some key design topics</h2>
<p>Two topics stood out so far in terms of complexity and choices that were hard
to make in such a way that they’d work well for all existing libraries:
mutability &amp; copy/view behaviour, and dtype casting rules.</p>
<h5 id="the-standard-will-contain-common-mutable-operations-such-as-slice-assignment-but-will-generally-avoid-in-place-mutation-in-apis-like-the-out-keyword">The standard will contain common mutable operations such as slice assignment, but will generally avoid in-place mutation in APIs like the <code>out</code> keyword</h5>
<p>NumPy, PyTorch, CuPy and MXNet provide strided arrays, and rely heavily on
mutating values in existing arrays and on the concept of a “view” for
performance. TensorFlow, JAX and Dask on the other hand have no or limited
support, given that they rely on an execution graph and/or JIT compiler which
provides constraints on how much mutability can be supported. The design
decisions described <a href="https://data-apis.github.io/array-api/latest/design_topics/copies_views_and_mutation.html">here</a>
will allow the most heavily used types of mutability - inplace operators,
item assignment and slice assignment - to be retained, while avoiding the use
of the <code>out=</code> keyword which is problematic to support for some libraries and
arguably a suboptimal API to begin with.</p>
<p>For libraries like SciPy and scikit-learn, the supported features are essential.
Code like this, from scikit-learn’s <code>ForestClassifier</code>:</p>
<div><pre><code data-lang="python"><span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_outputs_</span><span>):</span>
    <span>predictions</span><span>[</span><span>k</span><span>][</span><span>unsampled_indices</span><span>,</span> <span>:]</span> <span>+=</span> <span>p_estimator</span><span>[</span><span>k</span><span>]</span>
</code></pre></div><p>or this, from SciPy’s <code>optimize.linprog</code>:</p>
<div><pre><code data-lang="python"><span>r</span> <span>=</span> <span>b</span> <span>-</span> <span>A</span><span>@x</span>
<span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>r</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>*=</span> <span>-</span><span>1</span>
</code></pre></div><p>is quite common and we see it as fundamental to how users work with array libraries.
<code>out=</code> is less essential though, and leaving it out is important for JAX,
TensorFlow, Dask, and future libraries designed on immutable data structures.</p>
<h5 id="casting-rules-for-mixed-type-families-will-not-be-specified-and-are-implementation-specific">Casting rules for mixed type families will not be specified and are implementation specific</h5>
<p>Casting rules are relatively straightforward when all involved dtypes are of
the same kind (e.g. all integer), but when mixing for example integers and
floats it quickly becomes clear that array libraries don’t agree with each
other. One may get exceptions, or dtypes with different precision. Therefore
we had to make the choice to leave the rules for “mixed kind dtype casting”
undefined - when users want to write portable code, they should avoid this
situation or use explicit casts to obtain the same results from different
array libraries. An example as simple as this one:</p>
<div><pre><code data-lang="python"><span>x</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span>  <span># will be integer</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>ones</span><span>(</span><span>5</span><span>,</span> <span>dtype</span><span>=</span><span>float16</span><span>)</span>
<span>(</span><span>x</span> <span>*</span> <span>y</span><span>)</span><span>.</span><span>dtype</span>
</code></pre></div><p>will show the issue. NumPy will produce <code>float64</code> here, PyTorch will produce
<code>float16</code>, and TensorFlow will raise <code>InvalidArgumentError</code> because it does not
support mixing integer and float dtypes.</p>
<p>See <a href="https://data-apis.github.io/array-api/latest/API_specification/type_promotion.html">this section of the standard</a>
for more details on casting rules.</p>
<h2 id="a-portable-test-suite">A portable test suite</h2>
<p>With the array API standard document we are also working on a
<a href="https://github.com/data-apis/array-api-tests">test suite</a>. This test suite
will be implemented with Pytest and Hypothesis, and won’t rely on any
particular array implementation, and is meant to test compliance with the API
standard.</p>
<p>It is still very much a work-in-progress, but the aim is to complete it by
the time the community review of the API standard wraps up. However, the
community is encouraged to check out the current work on the test suite on
<a href="https://github.com/data-apis/array-api-tests">GitHub</a> and try it out and
comment on it. The
<a href="https://github.com/data-apis/array-api-tests/blob/master/README.md">README</a>
in the test suite repo contains more information on how to run it and
contribute to it.</p>
<p>The test suite will be runnable with any existing library. This can be done
by specifying the array implementation namespace to be tested via an
environment variable:</p>
<div><pre><code data-lang="bash">$ <span>ARRAY_API_TESTS_MODULE</span><span>=</span>jax.numpy pytest
</code></pre></div><p>The test suite will also support vendoring so that array libraries can easily
include it in their own test suites.</p>
<p>The result of running the test suite will be an overview of the level of
compliance with the standard. We expect it will take time for libraries to
get to 100%; anything less shouldn’t just mean “fail”, 98% would be a major
step towards portable code compared to today.</p>
<h2 id="people--projects">People &amp; projects</h2>
<p>So who was involved in getting the API standard to this point, and which
libraries do we hope will adopt this standard? The answer to the latter is
“all existing and new array and tensor libraries with a Python API”. As for
who was involved, we were lucky to get contributions from creators and senior
maintainers of almost every project of interest - here’s a brief description:</p>
<ul>
<li>NumPy: Stephan Hoyer and Ralf Gommers are both long-time NumPy maintainers.
In addition we got to consult regularly with Travis Oliphant, creator of
NumPy, on the history behind some decisions made early on in NumPy’s life.</li>
<li>TensorFlow: Alexandre Passos was a technical lead on the TensorFlow team,
and has been heavily involved until a few weeks ago. Paige Bailey is the
product manager for TensorFlow APIs at Google Research. Edward Loper and
Ashish Agarwal, TensorFlow maintainers, replaced Alexandre recently as
Consortium members.</li>
<li>PyTorch: Adam Paszke is one of the co-creators of PyTorch. Ralf Gommers
leads a team of engineers contributing to PyTorch.</li>
<li>MXNet: Sheng Zha is a long-time MXNet maintainer. Markus Weimer is an
Apache PMC member and mentor for the MXNet incubation process into the
Apache Foundation.</li>
<li>JAX: Stephan Hoyer and Adam Paszke are two maintainers of JAX.</li>
<li>XArray: Stephan Hoyer is one of the co-creators, and still a maintainer, of Xarray.</li>
<li>Dask: Tom Augspurger is a senior Dask maintainer.</li>
<li>CuPy: we have no active participant from CuPy. However we have talked to
the CuPy team at Preferred Networks, who are supportive of the goals and
committed to following NumPy’s lead on APIs.</li>
<li>ONNX: Sheng Zha is an ONNX Steering Committee member.</li>
</ul>
<p>Many other people have made contributions so far, including the Consortium
members listed at <a href="https://github.com/data-apis/governance">https://github.com/data-apis/governance</a>.</p>
<h2 id="next-steps-to-a-first-complete-standard">Next steps to a first complete standard</h2>
<p>We are now looking for feedback from the wider community, and in particular
maintainers of array libraries. For each of those libraries, a Consortium
member involved in the library will be soliciting feedback from their own
project. We’d like to get to the point where it’s clear for each library that
there are no blockers to adoption and that the overall shape of the API
standard is considered valuable enough to support.</p>
<p>In addition, given that this API standard is completely new and drafting
something like it hasn’t been attempted before in this community, we’d love
to get meta feedback - is anything missing or in need of shaping in the
standard document, the goal and scope, ways to participate, or any other such
topic?</p>
<p>To provide feedback on the array API standard, please open issues or pull
requests on <a href="https://github.com/data-apis/array-api">https://github.com/data-apis/array-api</a>. For larger discussions
and meta-feedback, please open GitHub Discussion topics at
<a href="https://github.com/data-apis/consortium-feedback/discussions">https://github.com/data-apis/consortium-feedback/discussions</a>.</p>


</div></div>]]>
            </description>
            <link>https://data-apis.org/blog/array_api_standard_release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050558</guid>
            <pubDate>Tue, 10 Nov 2020 19:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Benefits of Being a Stoic]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25050456">thread link</a>) | @davefreiburger
<br/>
November 10, 2020 | https://gradually.co/the-benefits-of-being-a-stoic/ | <a href="https://web.archive.org/web/*/https://gradually.co/the-benefits-of-being-a-stoic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-893">
				<!-- <a href="https://gradually.co/the-benefits-of-being-a-stoic/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Benefits of Being a Stoic</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 10, 2020						</span>

						<img width="640" height="340" src="https://gradually.co/wp-content/uploads/2020/11/GD24-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://linkmix.co/1611480" target="_blank">
									[Image source: Eric Gerlach/Giphy]								</a></p><h5>
									<a href="http://nautil.us/issue/92/frontiers/the-joys-of-being-a-stoic" target="_blank">
										The Joys of Being a Stoic									</a>
									 &nbsp;by Massimo Pigliucci									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“If there is nothing you can do about a particular situation, why beat yourself up about it?” — Massimo Pigliucci</span></li>
<li><span>Stoicism shouldn’t be about suppressing your emotions. Moreso, Stoicism is about adjusting your unhealthy emotions (anger) to a more mindful embrace of healthier ones (joy).&nbsp;</span></li>
<li><span>Stoicism receives a great deal of pushback regarding the negative effects of not acknowledging pain and the silent endurance and lack of emotion.&nbsp;</span></li>
<li><span>Massimo quotes Epictetus (Greek Philosopher), “Some things are within our power, while others are not. Within our power are opinion, motivation, desire, aversion, and, in a word, whatever is of our own doing; not within our power are our body, our property, reputation, office, and, in a word, whatever is not of our own doing.”&nbsp;</span></li>
<li><span>Massimo adds, “…the idea is to internalize our goals: Instead of focusing, as it comes natural, on outcomes, let’s pay attention to our intentions and efforts. The Stoics think that the only truly good thing for us is our own character, and that therefore the only truly bad things are whatever may undermine our character. Everything else (including health, wealth, reputation, etc.) has value, but does not define who we are.”</span></li>
<li><span>The four virtues:</span></li>
</ul>
<ol>
<li>
<ol>
<li><i><span>Practical wisdom</span></i><span> — the knowledge of what is truly good or bad for me. Will this undermine my character or not?&nbsp;</span></li>
<li><i><span>Courage</span></i><span> — doing something that frightens us.</span></li>
<li><i><span>Justice</span></i><span> — as treating other people, like my coworker, fairly and with respect.</span></li>
<li><i><span>Temperance</span></i><span> — we should do things in the right measure, neither too much nor too little.&nbsp;</span></li>
</ol>
</li>
</ol>
<ul>
<li><span>“Apply the dichotomy of control and the four virtues to everything you do and, as Epictetus promises, you will never be unhappy. You will be free, and you will live a life truly worth living.” — Massimo Pigliucci</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Massimo mentions that the four virtues help us form a sort of moral compass. Allowing people to navigate the world and weather the storm of whatever that’s thrown at us. Moral compass or not, Stoicism or not, knowing your own virtues that help you navigate the world seems like an exercise worth doing. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/the-benefits-of-being-a-stoic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050456</guid>
            <pubDate>Tue, 10 Nov 2020 19:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049619">thread link</a>) | @rolph
<br/>
November 10, 2020 | https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-23</span>. Modified on <span id="moddate">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><b>Update 2020-10-25:</b> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generation don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub, but of course I also have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of important Open Source code reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture so many things are turned into "crap"? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
<p>Other relevant reading: <a href="https://jacquesmattheij.com/what-is-wrong-with-microsoft-buying-github/">What is wrong with Microsoft buying GitHub</a></p>
</article></div>]]>
            </description>
            <link>https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049619</guid>
            <pubDate>Tue, 10 Nov 2020 18:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Innocent badgers behind “awful” and “disgusting” looting of Viking graves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049599">thread link</a>) | @Bologo
<br/>
November 10, 2020 | https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4973" role="main"><div><div><div><p>On November 4, various media reported on the looting of Viking graves in the Norwegian town of <a href="https://en.wikipedia.org/wiki/Oppdal">Oppdal</a>. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>Malevolent grave robbers had allegedly ravaged a sacred Viking burial ground. Local newspapers attributed the misdeed to wanton vandals, greedy thieves, or both. The intruders had apparently drilled deep holes into 17 of the Viking graves.</p><p>“It’s awful!” <a href="https://www.adressa.no/nyheter/trondelag/2020/11/06/Anmeldte-vikinggrav-plyndring-i-Oppdal-n%C3%A5-har-saken-tatt-en-uventet-vending-22955618.ece">said Thora Nyborg</a>, a curator at the NTNU University Museum in Trondheim, according to local newspaper <em>OPP </em>(paywalled link <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">here</a>). “Many organic objects have been lost, and more objects might be lost now that air has been allowed into the graves.”</p><p>Archaeology website AncientPages.com <a href="https://www.ancientpages.com/2020/11/06/disgusting-vandalism-and-looting-of-viking-graves-in-norway/">called the vandalism “disgusting.</a>” And commenters on the Facebook page The Heathen Underground <a href="https://www.facebook.com/heathenunderground/photos/pb.728159570530461.-2207520000../3763552250324496/?type=3&amp;eid=ARAk94RGYvhaVzFmr5C9yKMCmQ32q4-ZklASGYAnOI05bhST6Muv28ZWrAJzOp3mR3HLyVKKIZUIXIxy">said it was all “very sad.”</a></p><h2>Looting of Viking graves a blessedly rare event</h2><p>Their indignation was understandable. After all, the <a href="https://www.visitnorway.com/listings/the-burial-site-at-vang/204434/">Vang burial site</a>, and its more than 800 burial mounds, is Northern Europe’s largest remaining burial site from the Iron Age. As such, it is a site of major historical importance.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The local newspaper <em>OPP </em>even suggested that the holes, which were of varying depths, <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">had been dug using a special drill</a> (paywalled link), indicating a wicked degree of cunning on the part of the graverobbers.</p><p>Furthermore, except for an isolated case in 2014, there had been no looting at this major Viking burial ground since the 19th century.</p><h2>Badgers behind the looting of Viking graves</h2><p>But on November 6, events took a different turn. The <a href="https://www.psychnewsdaily.com/300-cocaine-packages-wash-ashore-on-dutch-beach-drug-tourists-look-for-more/">police</a> had suddenly closed the case, said Sjur Vammervold, a cultural consultant for the municipality of Oppdal.</p><p>The reason was that the suspect turned out to be impossible to prosecute. “It seems that a badger was behind it,” <a href="https://www.dagbladet.no/kultur/gravplyndrer-avslort/73037518">Vammervold told local newspaper <em>Dagbladet</em></a>.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>“At least now we know that people weren’t responsible,” he said. “The badger is quite innocent, and probably had no plans to rob any graves,” he added.</p><p>Vammervold said that while the badger hypothesis has not yet been proven, at this point it seems the most likely explanation.</p><p>“Based on how badgers dig holes, they are probably behind this,” he said of the short legged <a href="https://www.psychnewsdaily.com/category/animal-psychology/" target="_blank" rel="noreferrer noopener">animals</a>.</p><p>Most of the burial sites at Vang date from the Late Iron Age (400 – 1050 AD), which includes the <a href="https://en.wikipedia.org/wiki/Viking_Age">Viking Age</a> (793 – 1066 AD). Archaeologists have made many important discoveries there.</p><hr><p><strong>Photo credit: </strong><a href="https://pixabay.com/users/andyballard-1141862/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">andy ballard</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049599</guid>
            <pubDate>Tue, 10 Nov 2020 18:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meet the world's first Kafka data catalog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049235">thread link</a>) | @lefterisdvr
<br/>
November 10, 2020 | https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From data stagnating in warehouses to a growing number of real-time applications, in this article we explain why we need a new class of Data Catalogs: this time for real-time data.&nbsp;</p><p>The 2010s brought us organizations <i>“doing big data”</i>. Teams were encouraged to dump it into a data lake and leave it for others to harvest.&nbsp;</p><p>But data lakes soon became data swamps. There were no best practices, no visibility into service levels or quality of data, no data contracts, no naming conventions or standardizations.&nbsp;</p><p>Just as quickly as data had arrived, it was impossible to find or trust.&nbsp;</p><p>If you were mature you might have deployed an enterprise Data Catalog that discovered data across your data stores. If you were less mature this would have been a manual process of documentation.&nbsp;</p><p>Either way, this wouldn’t prepare you for what was to come in the world of data and <a href="https://lenses.io/dataops/">DataOps</a>.&nbsp;</p><h3>

New streaming data, same problem, bigger stakes</h3><p>
As a developer or data engineer, you still have a problem finding data. Answering simple questions such as: Where do I have customer data? How about surnames and phone numbers or credit cards?&nbsp;</p><p>Why is this?&nbsp;</p><p>It’s because the challenge to catalog data got harder. Data isn’t sitting in data warehouses any longer. It’s streaming. And it is data generated by applications run within engineering, not business teams. </p><p>A lot of applications.</p><p>Engineering teams haven’t got time nor can they be expected to follow traditional data governance practices.</p><p>And yet, if there is no way to know what data there is across different teams and how to find it - it may as well not exist.</p><p>Much of DataOps is about self-service to remove friction from delivery. Pure luck in speaking to the right person at the right time or endless back-and-forths to understand what data exists, how it looks, etc isn't right. </p><p>This won’t work in 2020.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tMpPZhid4mgL7MmbBaKiQ/e3b84596b166d1eba6bd5b303c891726/dataops-workspace.png" alt="DataOps container for your data platform"></p><p>For real-time data, there is no alternative but to automate the data management processes. This includes the discovery of data entities, data lineage, classification and quality.&nbsp;</p><p>Automation will mean teams are free to develop new data-intensive applications without centralized data governance or manual procedures.&nbsp; What data is generated can be immediately socialized across a business for other teams to benefit from.</p><h3>Commandments of Cataloguing data
</h3><p>Metadata is Queen. </p><p>If you can collect it from your different data infrastructure and applications you’re on the right path. Then to make it valuable you need to serve this information in the right measure, and you can start to answer the right questions:&nbsp;</p><ul><li><p> <!-- -->What data exists and its profile?</p></li><li><p> <!-- -->What is its quality?</p></li><li><p> <!-- -->What service levels can I expect?</p></li><li><p> <!-- -->What is its data provenance?</p></li><li><p> <!-- -->How might other services be impacted?</p></li><li><p> <!-- -->How compliant is it?</p></li></ul><p>Being able to answer these sorts of questions is fundamentally important to the success of real-time data projects.&nbsp;</p><p>Gartner agrees:<i> </i></p><p><i>“By 2021, organizations that offer a curated catalog of internal and external data to diverse users will realize twice the business value from their data and analytics investments than those that do not”</i></p><p><b><i>Source: Augmented Data Catalogs: Now an Enterprise Must-Have for Data and Analytics Leaders,” Ehtisham Zaidi &amp; Guido de Simoni, Sept.12, 2019</i></b>

</p><h3>Enter the Lenses real-time Data Catalog
</h3><p>Lenses.io delivers the first and only <a href="https://lenses.io/usecases/discover">Data Catalog for streaming data</a>.</p><p><img src="https://downloads.ctfassets.net/tnuaj0t7r912/3wE5igSRxlgeTTNk7Qy4zc/6cfe43a2e8a7d7ef49c29b02d4d462c0/lenses.io_4.0_real_time_data_catalog.gif" alt="Lenses.io - Real time data catalog for Apache Kafka"></p><p>
It's an easy, secure and intuitive way to identify your data:</p><ul><li><p> <!-- -->It works in real-time</p></li><li><p> <!-- -->It continuously and automatically identifies all your streaming data</p></li><li><p> <!-- -->It works across any data serialization format</p></li><li><p> <!-- -->It enables your team to mask and protect all <a href="https://help.lenses.io/using-lenses/data/data-policies/">sensitive data</a>.</p></li></ul><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7BkMWioUDyPJTjE08BZ25P/f8bf542b6892bc0551133aeac7ae6a66/lenses.io_4.0_data_policies.gif" alt="lenses.io 4.0 data policies - data masking for Apache Kafka"></p><p>Lenses not only provides a Google Search experience over streaming data, but also a Google Maps experience. </p><p>In addition to monitoring your pipelines (Kafka Connect, Flink, Spark Streaming etc.) and your microservices<b>,</b> Lenses will highlight which applications are consuming or producing such “sensitive” data.</p><p>Next, we’ll explain the thought process and key principles behind our real-time Data Catalog.</p><h3>Like Google but for Apache Kafka metadata

</h3><p>Building a real-time Data Catalog was a natural progression for our team. We’ve been giving visibility into Apache Kafka environments and applications that run on Kafka for years.&nbsp;&nbsp;</p><p>This was mainly developed to help engineers gain insight into their Kafka streams. Very useful when it came to debugging applications and inspecting message payload with SQL, partitioning information, overseeing infrastructure health or viewing consumer lag.</p><h3>It all starts with SQL
</h3><p>The SQL engine to explore topic data is particularly important. </p><p>To understand the data and its structure we connected to an AVRO schema registry or deserialized proprietary messages. This meant we had visibility into the metadata and payload of all data sitting in Kafka.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3H4HgRJRB2kIecDBxWrloU/be23f75b16a743698c0224577526af79/_Blog_-Data-Catalog---4.0-release---Alternative.jpg" alt="Lenses.io data catalog for Apache Kafka architecture"></p><p>
Last year we extended the capabilities to explore data in Elasticsearch with the same SQL engine and built a framework to connect to multiple different data stores in the future: Postgres, Redis, Cassandra.&nbsp;</p><p>We also register stream processing applications that run on our <a href="https://docs.lenses.io/4.0/sql/">streaming SQL engine</a> over Kubernetes.&nbsp;&nbsp;</p><p>We allow developers to register their external applications either as a REST endpoint or with a client for JVM-based applications.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/VoX7OrBtso7pnE7dh66T5/d773f7955ba1d66ca978402f26ae8eb9/lenses-api-docs-external-apps.png" alt="Lenses API docs external apps"></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3iy2qCN9vTVzNpf5rDkwV6/6b1caba28603be4dc8680fc8f5670a01/topology-client-properties.png" alt="topology-client-properties"></p><p>This builds us an App Catalog and a Topology of all the dependencies between different flows and applications. Allowing us to build the data lineage of different data sets.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tYvPfHqG2xHjfo7NfpVZ1/7394b4b2e3f409c1c12ff8c07b85fde6/_Blog_-Data-Catalog---4.0-release---Alternative_01.jpg" alt="Apache Kafka pipeline topology and data lineage lenses.io"></p><p>It also allows us to answer a few important questions:</p><ul><li><p> <!-- -->What applications generated this data?</p></li><li><p> <!-- -->How much can I trust the quality of the data and at what service levels?</p></li><li><p> <!-- -->What downstream applications consume this data to understand service disruption impact?</p></li></ul><p>The Topology, App Catalog and SQL Engine therefore give us the ability to maintain a metadata catalog of data flowing across a data platform.&nbsp;</p><p>Most importantly, this data is updated automatically and in real-time. </p><p>As engineering teams develop a new product, whether it be a consumer-facing microservice application or data processing pipeline, the data and topology will be discovered automatically, including payload and all metadata.&nbsp;&nbsp;</p><p>Or if an application writes to an Elasticsearch index, that too will automatically be picked up.</p><p>No need to manually maintain a catalog.&nbsp;</p><p>This information can then be presented and found in a free-text search fashion a la Google:&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/6xN1yqyFKhCyNTlik17Vb/caa0832fc2c1061daf9767bfd3823b73/image__25_.png" alt="Lenses.io - real time data catalog - searching metadata in Apache Kafka and Elasticsearch"></p><p>The catalog is protected with the same unified namespace-based security model that protects all data access in Lenses.&nbsp;</p><p>It opens up new use cases around how data can be accessed and drastically reduces the time or the duplicate effort compared to current methods of finding data.&nbsp;</p><p>Here are two examples.&nbsp;</p><h3>1. Scoping a new project
</h3><p>A business analyst is able to scope the feasibility of a new innovative stock management application by exploring what data can be used across multiple different lines of business, including service levels, quality and compliance requirements.</p><p>The analyst starts typing keywords such as <i>stock*</i> to find all metadata (indexes, documentation, field names, streamings) and generating applications that match.&nbsp;</p><p>They can drill down to the payload to explore the data or view in the context of a topology to understand upstream and downstream applications connected to the data. An analyst can only view data they have been granted access to, and/or may have certain sensitive fields masked in accordance with compliance requirements.&nbsp;</p><h3>2. Data access audit</h3><p>
An auditor needs to explore all data entities holding possible password information. </p><p>The auditor saves themselves weeks of data gathering and manual reporting by searching <i>pass*</i> to find all entities. They validate the Lenses user group namespaces for these entities to understand which users have access and understands the applications processing this information via a Topology.&nbsp;</p><p>This same process can help meet any number of compliance controls including GDPR, HIPPA, SOX, SEC and PCI.&nbsp;</p><p>You can try out these use cases (or your own) by exploring our real-time data catalog for free in a sandbox environment at <a href="https://portal.lenses.io/">portal.lenses.io</a> or see all deployment options at <a href="https://lenses.io/start">lenses.io/start</a></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049235</guid>
            <pubDate>Tue, 10 Nov 2020 18:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rev.ng decompiler nightly builds have been released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048645">thread link</a>) | @agiantleap
<br/>
November 10, 2020 | https://rev.ng/blog/the-road-ahead/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/the-road-ahead/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In this blog post we will briefly describe today's release, provide an overview of the components of rev.ng and introduce you the next steps the rev.ng project intends to take towards the 1.0 release.</p>
<p>We are inviting small groups of people to get access to nightly builds.
If you already registered, be patient and monitor our <a href="https://twitter.com/_revng">Twitter account</a>. Otherwise, <a href="https://rev.ng/register-for-nightly.html">register now</a>.</p>
<h2>Nightly builds release</h2>
<p>Today, we start releasing nightly builds of all the rev.ng components including <code>revng</code> (binary lifter and translator), <code>revng-c</code> (the decompiler) and <code>cold-revng</code> (the user interface).</p>
<p>rev.ng is an ambitious project which took the long route in several aspects.
We think this will prove to be a winning strategy to build an innovative product.</p>
<p>We're now starting to see the end of the tunnel that leads us to become a mature tool for binary analysis, but we're not there yet.
Nightly builds are our way to invite you to join us along the last mile of the journey.</p>
<h3>What to expect</h3>
<p>rev.ng can currently handle binaries compiled for Linux targeting x86-64, i386, ARM, AArch64, MIPS and SystemZ.
Here's a few things you can do with the current release.</p>
<h4>1. Try out the UI using test files</h4>
<p>The package we distribute includes a set of pre-lifted files.
You can open them in the UI right away.</p>
<div><pre><span></span><span>EXAMPLES</span><span>=</span>root/share/revng/qa/tests/runtime/x86_64/abi-enforced-for-decompilation
./revng ui <span>$EXAMPLES</span>/calc.bc
</pre></div>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/calc.mp4" type="video/mp4">
</video>
          
          
            <h4>2. Lift, translate and run ls</h4>
<p>You can also give a try to the binary translator.
For instance, you can lift <a href="https://rev.ng/downloads/ls-ubuntu-16.04"><code>ls</code></a> to LLVM IR, recompile it, and run it again:</p>
<div><pre><span></span>wget <span>'https://rev.ng/downloads/ls-ubuntu-16.04'</span>
chmod +x ls-ubuntu-16.04
./ls-ubuntu-16.04 --color<span>=</span>always -lhn
./revng translate ls-ubuntu-16.04
./ls-ubuntu-16.04.translated --color<span>=</span>always -lhn
</pre></div>

<p>Please note that translation support for non-x86-64 input architectures is working but has some limitations.</p>
<h4>3. Decompile ls</h4>
<p>The rev.ng UI also provides a wizard for decompilation.</p>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/ls.mp4" type="video/mp4">
</video><h3>What not to expect</h3>
<p>The builds are to be considered unstable and under heavy development, therefore keep in mind to:</p>
<ol>
<li>read the <code>README.md</code>
</li>
<li>perform frequent updates</li>
<li>expect suboptimal decompiled code and crashes</li>
<li>report anything unexpected/slow</li>
<li>expect rapid improvements</li>
</ol>
<p>For those, who have access to the nightly builds, the <a href="https://github.com/revng/help">revng/help</a> repository will contain a shortlist of known issues we're working on.</p>
<h2>Overview of the rev.ng components</h2>
<p>rev.ng is divided in several components, some of them are open source.</p>
<p>Let's start with the ones we forked from existing projects:</p>
<ul>
<li>
<code>qemu</code>: our fork provides a dynamic library able to produce tiny code instructions from a raw sequence of bytes.</li>
<li>
<code>llvm</code>: our LLVM 10 fork with minor changes.</li>
<li>
<code>qtcreator</code>: the base of our UI.</li>
</ul>
<p>The following projects are the open source parts of the rev.ng project:</p>
<ul>
<li>
<code>revng</code>. The core of rev.ng: the binary lifter and translator. Given a binary program, it lifts to tiny code instructions and then to LLVM IR. Produces an LLVM module, and, optionally recompiles it.</li>
<li>
<code>orchestra</code>. Our almighty meta-build system. It handles all the dependencies for you, fetches them from our binary archives or builds them from source. Don't try to build rev.ng by yourself, use <code>orchestra</code>.</li>
<li>
<code>revng-qa</code>. A repository for our test programs.</li>
</ul>
<p>The following projects will be released under a commercial license and are currently released as binaries only:</p>
<ul>
<li>
<code>revng-c</code>. Takes <code>revng</code> output and decompiles it to C.</li>
<li>
<code>caliban</code>. A project providing an API to perform high-level actions on binaries, on top of which the UI and, in the future, our scripting engine are built.</li>
<li>
<code>cold-revng</code>. The UI, a QtCreator plugin.</li>
</ul>
<h2>Roadmap towards the release</h2>
<p>In the following, we report a list of tasks to accomplish and components to develop/finalize in order to get to the final release.
You can expect one or more blog posts or some other form of publication for each item.</p>
<ul>
<li>
 Release the nightly builds</li>
<li>
 Create a <a href="https://github.com/revng/help">GitHub repository</a> to support nightly builds' users</li>
<li>
 Completely move the development of open source projects to GitHub</li>
<li>Requirements for tagging the beta:<ul>
<li>
 CFG combing</li>
<li>
 Improved ABI Analysis</li>
<li>
 Type Shrinking Analysis</li>
<li>
 Data Layout Analysis</li>
<li>
 Value Manipulation Analysis</li>
<li>
 Define a <em>data model</em> for the analyzed program and how to change it</li>
<li>
 Identify libraries using strings (BigMatch)</li>
<li>
 Full PE/COFF and Mach-O support</li>
</ul>
</li>
<li>Requirements for tagging the 1.0 release:<ul>
<li>
 Improve UI/UX</li>
<li>
 Python scripting engine</li>
<li>
 Windows and macOS port</li>
<li>
 Import C headers and debug information</li>
<li>
 Compatibility layer</li>
<li>
 Support for packers/self-modifying code</li>
<li>
 Support remote processing</li>
</ul>
</li>
</ul>
<h2>Conclusions</h2>
<p>We'd like to thank everyone who is participating in the nightly builds programme.
Your feedback will help us along the way towards the final release.</p>
<p>Releasing nightly builds, along with switching to a fully open air development of the open source components, is part of our effort to spread the word and collect feedback.
Our ultimate goal is to build a robust community to engage with and to grow a flourishing ecosystem of software based on rev.ng binary analysis framework.</p>
<p>Also, a shout-out to all those who put their hard work in order to make this first public release finally possible, in particular Pietro, <a href="https://twitter.com/carpikes">Alain</a>, <a href="https://twitter.com/fcremo">fcremo</a> and Andrea, but also all the others who contributed to spot bugs and share their opinions.</p>
<p>We hope you're excited as we are.
Enjoy!</p>
          
        </div></div>]]>
            </description>
            <link>https://rev.ng/blog/the-road-ahead/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048645</guid>
            <pubDate>Tue, 10 Nov 2020 17:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linus Torvalds' Home Office [YouTube]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048457">thread link</a>) | @bojanvidanovic
<br/>
November 10, 2020 | https://devandgear.com/posts/linus-torvalds-home-office/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/linus-torvalds-home-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When it comes to computer setups, there is one that always comes to my mind,
the setup of Linus Torvalds in the famous YouTube video <strong>“Linus Torvalds Guided
Tour of His Home Office”</strong>. The video is from 2014 with almost 300k views, and
his home office probably changed until now, but interestingly it gives
a glimpse of how one of the most influential figures in the open-source
community works.</p>
<p>One would have imagined multiple <a href="http://localhost:1314/products/categories/monitors/">monitors</a> connected together, with a bunch of
computers, and everything perfectly organized. But that’s not a case here,
Linus getting done his work on a medium-sized Dell monitor set on a walking
desk. I wasn’t expecting to see a walking desk, they are very rare to be seen,
but in theory, they are healthier than a standing desk that keeps you in
a static position. If you already own a standing desk, you can add a walking
pad to it like this <a href="https://amzn.to/38t9Ll8">one</a>, and make it a walking desk. Aside from that everything
else seems pretty normal, a clean productive space.</p>
<p>That is one side of the office, the other side of his office is a bit messy
with a bunch of hardware stacked one on top of each other, which he admits it’s
probably best to burn.</p>
<p>I’d like to see the evolution of Linus’s office, but if you don’t know he is
a very reserved person, so it will be hard. Anyway, if you haven’t seen the
video, here is the link and enjoy it.</p>



        </div></div>]]>
            </description>
            <link>https://devandgear.com/posts/linus-torvalds-home-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048457</guid>
            <pubDate>Tue, 10 Nov 2020 17:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout can exacerbate work stress, further promoting a vicious circle]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 181 (<a href="https://news.ycombinator.com/item?id=25048455">thread link</a>) | @rustoo
<br/>
November 10, 2020 | https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universität Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gemäß Einstellungen für option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Indexüberschrift:  -->
               <h3>
                  Work stress and burnout are mutually reinforcing / Surprisingly, the effect of work stress on burnout is much smaller than the effect of burnout on work stress
               </h3>
               <p>
                  10 November 2020
               </p>
               <p>
                  Stress and overload in the workplace are increasing worldwide and are often considered a cause of burnout. Indeed, a new study shows that work stress and burnout are mutually reinforcing. However, contrary to popular belief, burnout has a much greater impact on work stress than vice versa. "This means that the more severe a person's burnout becomes, the more stressed they will feel at work, such as being under time pressure, for example," said Professor Christian Dormann of Johannes Gutenberg University Mainz (JGU). Employees suffering from burnout should be timely provided with adequate support in order to break the vicious circle between work stress and burnout.
               </p>
               <p>
                  Symptoms of burnout include exhaustion, cynicism, and reduced performance. "The most important burnout symptom is the feeling of total exhaustion – to the extent that it cannot be remedied by normal recovery phases of an evening, a weekend, or even a vacation," said Dormann. "To protect themselves from further exhaustion, some try to build a psychological distance to their work, that is, they alienate themselves from their work as well as the people associated with it and become more cynical," added Dr. Christina Guthier. She conducted the study as part of her doctoral thesis in Dormann's research group and was awarded with the dissertation prize of the Alfred Teves Foundation in 2020. The study has recently been published in <em>Psychological Bulletin</em>.
               </p>
               <p>
                  For the joint publication with Professor Christian Dormann and Professor Manuel Völkle of Humboldt-Universität zu Berlin, Christina Guthier evaluated 48 longitudinal studies of burnout and work stress comprising 26,319 participants. The average age in the initial survey was about 42 years, 44 percent of the respondents were men. The longitudinal studies from 1986 to 2019 came from various countries, including predominantly European countries as well as Israel, the USA, Canada, Mexico, South Africa, Australia, China, and Taiwan.
               </p>
               <h4>
                  Stopping the downward spiral and reducing the effect of burnout on work stress
               </h4>
               <p>
                  The results challenge, or at least relativize, the common perception that work stress is the driving force behind burnout. "Burnout can be triggered by a work situation, but that is not always the case," Dormann pointed out. Once burnout begins, it develops only very gradually, building up slowly over time. Ultimately it leads to work being increasingly perceived as stressful: The amount of work is too much, time is too short, and work stress is too great. "When exhausted, the ability to cope with stress usually decreases. As a result, even smaller tasks can be perceived as significantly more strenuous," explained Guthier, the first author of the article. "We expected an effect of burnout on work stress; the strength of the effect was very surprising," she noted. The effect of burnout on perceived work stress can be somewhat mitigated if employees have more control over their own work and receive support from colleagues or superiors.
               </p>
               <p>
                  According to Dormann, a new research area is emerging on the basis of this unique data because the strong boomerang effect of burnout on work stress has not yet been investigated. Key questions that need to be addressed are: how can the effects of burnout on perceived work stress be reduced and how can the development of this vicious circle be prevented? Dormann and Guthier suggest that the place to start is with management behavior. Employees should have the opportunity to give feedback on their work stress at any time and be appreciated. Last but not least, proper recovery could also help to stop the downward spiral.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048455</guid>
            <pubDate>Tue, 10 Nov 2020 17:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avo's Ultimate Tracking Plan Template (With Downloadable Worksheet)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048395">thread link</a>) | @kelseyfecho
<br/>
November 10, 2020 | https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We talked in depth about <em>why</em> you need a tracking plan in our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>; now, we’ll break down the awesome tracking plan template we created for you, so you’re ready to implement better product analytics via your tool of choice (possibly Avo 😉).</p><p>But before we dive in, here’s a quick refresher on what a tracking plan is (you may recognize this from our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>):</p><p><em>A tracking plan is a document that defines the key stages of your customer life cycle and codifies a single source of truth for the data that supports it. It helps you standardize your data management and capture better and cleaner data.</em></p><p>As part of your tracking plan, you’ll need to outline the events and properties relevant to your goals, explain where in your codebase tracking code should be placed, and provide context for why you’re tracking what you are.</p><p>While each of the elements of your tracking plan will be as unique to your business as your product is to your market, you can save admin time up front by using a tracking plan template. There are dozens floating around the internet, so we went ahead and created our 🎉Ultimate Tracking Plan Template 🎉 that pulls together the 10 elements you absolutely must have. Use this template to spend less time researching how to make your tracking plan and more time using it.</p><h2><strong>What makes a good tracking plan?</strong></h2><p>Your tracking plan should include events and properties that help you understand your customers’ behavior and measure progress through your sales funnel and customer journeys so you can see how well your features are meeting customer needs. It shouldn’t aim to measure every drop of data under the sun—just those that are most important to you.</p><p><em>For the full breakdown of how to find the events and properties that mirror your customer journey, check out</em><a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"><em> our full guide on tracking plans</em></a><em>, and then meet us back here.</em></p><p>To get a full picture of your customers’ behaviors and experiences, you’ll need a mix of both <strong>qualitative metrics</strong> (the kind that reflect user sentiment) and <strong>quantitative metrics</strong> (the kind that reflect user actions).</p><p>Your tracking plan will focus on quantitative metrics. That's because it's possible to objectively measure whether an action happened. But it’s equally important that your sales and product teams reach out to customers and users via surveys, social media, and reviews to get qualitative data to complement your tracking plan.</p><h2><strong>The 10 key elements of your tracking plan</strong></h2><p>We have a lot of experience helping folks build killer tracking plans (and we’ve seen a lot of great examples of tracking plans from other companies, too). When we sat down and pulled from our experience—and the experiences of others—we noticed there were <strong>10 key elements</strong> that every great tracking plan included.</p><h3><strong>1. KPIs</strong></h3><figure id="w-node-530d128e532a-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8da57e1d363a3d9b0b_zFsYVY341ROFEJtzHTqKjGUl5B--qn1HOpQJveWLNR_qPh-UsdTVUqGCRatRYI8S9Y4z4ZM3U7bm__KHLqPCOEYSYsO-dvIwiyB57Y4sU1_D481F9IvaSCLtb9v687GfNMss5BvN.png" alt=""></p></figure><p>‍</p><p>Each event you track should tie directly to a business-end key performance indicator (KPIs) that affects your success, so you can easily reference the tie-in between metrics tracked and their real-world value.</p><p>These KPIs will change depending on your company maturity, product, and business strategy, but here are some examples:</p><ul role="list"><li>Signup funnel&nbsp;</li><li>Retention from signup to playing game&nbsp;</li><li>Monthly new signups&nbsp;</li></ul><p>This first section is what will give any business-end stakeholders the context they need to understand how the tracking plan ties into a wider strategy.</p><h3><strong>2. Event categories</strong></h3><figure id="w-node-4acb0f34daaa-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d25d6db8b075c10f4_DU2hKDTJVw5geaQSvCWdZyykuvO9nbgj3zRVCYZgG8Lv3eAKNBRShY9_R0XpxJ7hY0KcAPgHKukstUyxK-n7mC_UQxJ622J3GsS01LFzSXbnwPWfZHkuQzvcdYcsKibJImCc9_us.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should break down events tracked by macro category—typically reflecting the different kinds of KPIs you’ve set—so you can keep track of each segment of customer success.</p><p>Like all things on this list, the kinds of events you’ll track will depend on your goals and use case, but here are a few examples:</p><ul role="list"><li>Authentication&nbsp;</li><li>Gameplay</li><li>Tournaments&nbsp;</li><li>Navigation</li></ul><p>Once you’ve set the broad categories of events you care about, you can drill down and decide on the specific events and properties within each category.</p><h3><strong>3. Event names</strong></h3><figure id="w-node-187250f1dc30-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8fd082e416a91e7b79_TcJUo78HcU3SgDp2OEbWGP1kUdEwnKRCNvMBKYg3wctbFjMTcyr37VzBXFtiVQWmIzikz_XIAvHu1iL17HcPDyLiWG7H_R6DDMCDUPGrvJsQ1cShwvQ6qauCwydT-pFzwUMWaAKM.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include one row for each event name (each of which will have rows for child properties). Additionally, each of your events should be <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namenaming-conventionsa-naming-conventions-for-events-and-properties">named in a consistent way</a> that’s in line with your agreed-on naming schema. This structure makes it easy for anyone to quickly scan and understand what events you’re tracking.</p><p>Your event names will depend on the kinds of events you’re tracking and on your naming schema. Within the categories we outlined above, some possible event names could include the following:</p><ul role="list"><li>Signup Started&nbsp;</li><li>Signup Completed&nbsp;</li><li>Login Completed&nbsp;</li><li>Game Started&nbsp;</li><li>Game Completed&nbsp;</li></ul><p>Note how each of these event names shares the same tense (past tense) and capitalization. This isn’t just to make your template look pretty; it makes everything easier to understand.</p><h3><strong>4. Event description</strong></h3><figure id="w-node-1dc7d6600a1b-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8e862fad531128fb1f_tHQLNeHbz4xZgGQ3UDyoKeIlRgTnEAInfIqB5SPwyCVGMzW8Is3gsevwEqNtDkAoBbEBFjggi_w5pBtynvHVoB1a16Hr9qE1EGK1uGG-zs0g3pTwRCeDDNhmWt_ZEK0yFUaBGhAk.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include a clear description for each event, including the event source (where the action is taking place) and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namedescriptionsa-descriptions-for-events-and-properties">any additional context of when and why the event happens</a>. That makes it easy for anyone looking at your template to quickly understand what the event is tracking.</p><p>Your event descriptions should be no longer than one or two sentences and should clearly and concisely explain what it is you’re measuring (and when). Let’s assume that we’re measuring the event “Game Completed.” Our description for this event might be:</p><p><em>Event sent when a user has successfully completed a game.&nbsp;</em></p><p>Creating consistent descriptions for each of your events will make it easy for anyone using your tracking plan to gain the context they need to interpret your data.</p><h3><strong>5. Properties</strong></h3><figure id="w-node-333264b27c1d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee33289892753ad21_3EYStOV5VQlQYeGzMJPyMOp8QzHD8qKyZdFUxZp4ZAmQBmsKtm5gRQ-X1wUejDhl0AQRr2yjQ8F9uv4-0v-WDSn3lJJ5irFTq_c-S229dgHG8M9ts_0w0vdaSl4WAc4VMHbXMyIe.png" alt=""></p></figure><p>‍</p><p>For each event, you should include a full breakdown of its attached properties, with one row per property—again, all named consistently—so you can easily see which properties are being tracked for a given customer action.</p><p><em>Bonus: You should also define your property groups (these can be spaced across event groups) so you can easily see what kind of user behaviors you’re tracking.</em></p><p>It can be easy to let <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties">naming conventions for properties</a> slide, but ensuring that each property follows your schema will prevent data collection and compilation errors down the road. Let’s say we’re measuring gameplay events, particularly the “Game Completed” event we identified above. We might track the following properties:</p><ul role="list"><li>Game Mode&nbsp;</li><li>Game Count&nbsp;</li></ul><p>Each of these properties will tell us whether or not a specific user action was completed (e.g., “Game Mode” tells us the mode of the game the user played and “Game Count” tells us how many games the user has completed).&nbsp;&nbsp;</p><h3><strong>6. Property description</strong></h3><figure id="w-node-7f23661ce86e-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8dda8f2787d81a87d7_SRKyGBFh80amOWqLYm4bzJbJVTRc8dPooGC5elZjp7LEHi4ATelWDMowhRa3Jx0RdpBp68K52pDCGMe6smASuB6iYRY0gTZ1klOETv6ue1imXwlaJkmpuLJyd_AYaq2jfgNAcKEd.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include a clear description for each property so that any user can understand what the property is tracking and where the data is coming from.</p><p>Just like your event descriptions, your property descriptions should fill a column to the right of your property names and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties-1">clearly and concisely describe what each property measures</a>.</p><p>For example, if we’re tracking how many games players complete during their session, we may track a property called “Game Count”. Our description of this property might look something like this:</p><p><em>The number of games a player has completed when this event is sent. Including the game that was just completed on Game Completed.&nbsp;</em></p><p>This extra context will help anyone looking at your tracking plan make sense of all your properties.</p><h3><strong>7. Property value types</strong></h3><figure id="w-node-a7b247d39bb4-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d4c3a92f224aa4e6d_P3Be8oQWJnz8WdmT5_PSPQpWy7JYNkUaweT8IWfUYFgC1Q7-zXGDT9kMMAKYc8Uo4g3K1E9F_4rhTIBRdSM_-wcGvRH2H_Sm7F3YhG-stRmHQU4jtRpScWITAVLZzg00buHIrHz8.png" alt=""></p></figure><p>‍</p><p>Each property within your tracking plan will collect a different data type. These types should be explicitly laid out so developers implement across codepaths and platforms consistently. This also helps your data analysts know what to expect from the tracking analytics code output.&nbsp;</p><p>This is one of the few sections of your tracking plan that will not greatly vary. Instead, the data in this column should include these common data types:</p><ul role="list"><li>int</li><li>floating-point number</li><li>boolean</li><li>string</li><li>datetime</li><li>a list of any of the data types above&nbsp;</li></ul><p>When you formally identify these data types for each of your events and properties, you help your developers avoid coding errors that will impact data compilation down the line.</p><h3><strong>8. Platforms</strong></h3><figure id="w-node-27beb698434d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d3e80f7aef4929f6c_uE8HThZK-UHSz_XorkNrq5sj8lGQP5dYoD4Tr4jWi33Ky80JvVP_6wti3UGVtB1K4F2760jlQbO9zeYsK9CwjN94Yu-J93rG7TpLDpWKGWAy03pkK3tnB24ITLqB2vjPxz5-3u2W.png" alt=""></p></figure><p>‍</p><p>For each property, you should note what platform the data is coming from so you can keep track of which applications contribute what information to your dataset.</p><p>This will depend on the development platforms you use and how your codebase is structured. But here’s a general outline of some of the platforms you may need to think about:</p><ul role="list"><li><strong>For web: </strong>JavaScript, TypeScript or Reason</li><li><strong>For mobile (generally): </strong>React Native or Expo or Flutter for iOS and Android apps</li><li><strong>For mobile (Android): </strong>Java or Kotlin&nbsp;</li><li><strong>For mobile (iOS):</strong>Swift or Objective C&nbsp;</li><li><strong>For backend: </strong>one or more backend sources (depending on number of programming languages and micro services)&nbsp;</li><li><strong>For game engines: </strong>Unity</li></ul><p>Including this breakdown of platforms that contribute data to your app will ensure that developers know where to implement tracking analytics across the board, and you won’t forget about any key components of your product.</p><h3><strong>9. Status</strong></h3><figure id="w-node-1697c41ba975-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee332892c4253ad22_Kjv8rek4cO-Y02kJmcgee0I4Wm5Qy2WxefQzbBeqQCf3nuMUA8hYuAKJUYL7Oi2Dpx-5VBZP88VKAWdwnxGdvugItvH_SoBxIOHrdTTofdp35s9GE_gqsGI-6qXl77A2pJn1Ahnh.png" alt=""></p></figure><p>‍</p><p>This is a really important one: Your tracking plan must indicate the status of each step of tracking analytics implementation. This ensures that your team--and your tracking plan stakeholders--have a clear understanding of what work has been completed, what needs review, and what is in testing.&nbsp;</p><p>For example, let’s say you’re tracking events and properties related to your login authentication method. You’ll need to note when that analytics code is ready for review and testing so your developers know that it’s not ready to ship, and don’t prematurely launch what could be a buggy bit of code.&nbsp;</p><h3><strong>10. Code snippet</strong></h3><figure id="w-node-9cafc5601453-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee3ef37d419b6f69b_sBOY_kvaTx5H_ds77RHPB7lR0xEDQ1MZL4SAWDVD5ICI4O8FvrD30dNhnEfq8Xv7_1B3HOclQUWqkXmuE6RquaNN3YLNxcOSTa4jNGV4gNcLxwEZz-cg_eYd9FNk_amDfkjxjR9N.png" alt=""></p></figure><p>‍</p><p>Finally, your tracking plan should include your tracking code for each event and property that needs to be tracked so that your developers can easily place it into the correct spot without naming-convention or syntax errors.</p><p>If you’re doing this manually with a spreadsheet alone—instead of using a tool, like Avo, that can house your implementation code and send it directly to developers—this section can get a little lengthy.</p><p>By explicitly giving the code for each property, you reduce the likelihood of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</a></em></p>]]>
            </description>
            <link>https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048395</guid>
            <pubDate>Tue, 10 Nov 2020 17:21:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka a More Accurate Perspective on Pulsar Performance]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25048083">thread link</a>) | @addisonj
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048083</guid>
            <pubDate>Tue, 10 Nov 2020 16:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gods on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 157 (<a href="https://news.ycombinator.com/item?id=25047838">thread link</a>) | @ivm
<br/>
November 10, 2020 | https://www.riknieu.com/the-gods-on-hackernews/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-gods-on-hackernews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tank_ghisletti?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Francisco Ghisletti</a> on <a href="https://unsplash.com/s/photos/greek-gods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>(This post is mostly fun and tongue-in-cheek, please contain your indignation.)</p><p>Every so often I encounter a comment on HackerNews that involuntarily makes my jaw drop, head shake and eyes water. It's usually concerning what some on HackerNews consider a 'worthwhile' amount of money you can earn as an solopreneur or maker VS being an employee. </p><p>Obviously, it's probably a small minority of the silent masses who scroll through HN daily who have these views, but comments like the following, or a variant of it comes up so often I can't help but feel that a decent part of the community is <em>ridiculously</em> out of touch with the rest of humanity. </p><p>Behold.</p><!--kg-card-begin: html--><blockquote><p lang="und" dir="ltr">😂 <a href="https://t.co/mg1UFHxp08">https://t.co/mg1UFHxp08</a></p>— Pete from No CS Degree (@petecodes) <a href="https://twitter.com/petecodes/status/1326144308706209798?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote> <!--kg-card-end: html--><p>$1000 per month from a side project is considered meh. 😳 🙃</p><p>And here's another from the same day,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/soundslikealot.png"></figure><p>And from the same user a few scrolls later,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/FANG.png"></figure><p>My god. Look, the commenter had the self awareness to bring up regional cost of living and that not everyone can work at the FAMANGs of the world, but really? Getting $3.7 million dollars for just 7 years of work is, like, a bad deal?</p><p>To consider making $500K pa as a doable, realistic salary to be taken into account when deciding between starting a company or just seeking a job... Like us millennials say, "I can't. Even." </p><p>That annual salary far outstrips what I can reasonably expect to earn in a decade, and I'm a developer working for a fintech startup with a good couple of years under my belt. For most people in the world, $500K pa is a <em><strong>preposterous</strong></em> amount of money. </p><p>I'm too lazy to go dig up more examples, but I'm sure you'll find some more gems like these if you go digging around on past threads.</p><p>This kind of poo-pooing of what most - and I'm talking 90% of the US population, never mind the rest of the world! - would consider rather large amounts of money is incredibly mind-blowing and makes my head spin.</p><p>Now I'm sure that in commenters like the above's worlds, that kind of money is indeed average and peanuts, but I wanted to write this article for myself and the rest of us to just try and deal. </p><p>I'm trying to make sense of the fact that I'm on this forum, interacting with people everyday, talking about current events and issues, that make more money per year than I can even imagine. In a way we're peers, but more realistically they're like the gods of Olympus who occasionally slum it with the rest of us.</p><p>So if you're like me, and you consider even a $1000 as lot of money, let's look at this as average mortals should.</p><h2 id="1-1000pm-is-a-flippen-lot">1) $1000pm is a flippen lot</h2><p>Let's go with the $1000 pm example, because figures like $3.6 million is, to be frank, in the realms of La-La land for me and almost everyone I know personally. </p><p>And let's - for the sake of simplicity - assume that you can take home 60% of that revenue as net earnings. And that the project doesn't take up more free time with maintenance and support issues than you can handle on your own. That's $600 per month. Extra. From a thing on the side. </p><p>I realise that I live in one of those cheap, unappealing parts of the world, but that kinda money would easily cover me and my family's rent every month, and then some. Do you realise how much of a mental weight that can take off a persons shoulders? To know rent is covered over and above your day-job earnings?</p><p>Away with your $1000-is-not-worth-it malarky!</p><h2 id="2-making-money-with-your-own-products-is-hard-">2) Making money with your own products is HARD.</h2><p>Take a look at <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">this post</a> by <a href="https://twitter.com/mccrmx">Chris McCormick</a>, titled "<a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">Holy heck this is hard</a>". </p><p>When he last checked, 12 solo founders out of 17207 made more than $10K MRR. Only 54 products made more than $2000pm. I don't think I need to express that in ratios for you to see the probability of making a profitable project.</p><p>Starting a product and <em>actually earning money from it</em> is hard. Insanely hard. Hell, if you manage to make even $100pm from a side project you've got my respect. You've got me beat by a lot!</p><p>When I see makers on IndieHackers or Twitter celebrate $100 in sales I get genuinely excited for them. It's really an incredible feat. Bravo to them, I wish them luck and more success in the future.</p><h2 id="that-1000-per-month-can-grow">That $1000 per month can grow</h2><p>Another thing to consider is that earning a $1000 pm means your project is basically validated and ready to explode. With work, you could probably scale it to much higher multiples. </p><p>Sure, the money it makes is negligible to the higher beings in Silicon Valley, but for us regular plebs that's a <em>strong</em> signal that your project potentially has legs. It might even be a project you could sell for $3.7 million dollars in 7 years time, if you put the work in and get a little lucky.</p><h2 id="ya-but-rik-cost-of-living">Ya, but Rik, cost of living</h2><p>Sure, things cost more in the States. And more so in SanFran. But I can't just up and go live in the States. Nor pretty much anywhere else in the First World. A heck of a lot of the people frequenting HN, TW and IH on a daily basis could probably not either.</p><p>So for people like us, it's inspiring to read about some rando making a $1000 pm, on their own, independently. It gives us hope that some dude in Alabama could start a thing and sell it for more money than we could expect to earn in a lifetime as a salaried employee. Because maybe that means we could too.</p><p>Because they used the same tools we have access too(except for Stripe 😝). They had access to the same markets we could reach. </p><p>And they make the kinds of money with those tools that could buy people like us freedom. Freedom from being chained to a job, freedom from financial stress, and possibly even the freedom to move our families to better places in the world. Places that others just get born in.</p><p>So when you see smarmy comments on HackerNews new putting down the success of others, take a step back and realise, it's not meant for you. It's not personal. </p><p>These are merely the musings of a few lucky, privileged gods, reflecting on the toils of the mortals.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/the-gods-on-hackernews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047838</guid>
            <pubDate>Tue, 10 Nov 2020 16:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the youtube-dl project]]>
            </title>
            <description>
<![CDATA[
Score 492 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25047818">thread link</a>) | @rg3
<br/>
November 10, 2020 | https://rg3.name/202011071352.html | <a href="https://web.archive.org/web/*/https://rg3.name/202011071352.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<h3><a href="https://rg3.name/202011071352.html">Origins of the youtube-dl project</a></h3>
<p>Posted on <time>2020-11-07T13:52Z</time>. Updated on <time>2020-11-10T16:28Z</time>.</p>


<p>As you may know, as of the time this text is being written <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl’s repository at GitHub</a> is blocked due to a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA takedown letter</a> received by GitHub on behalf of the RIAA. While I cannot comment on the current maintainers' plans or ongoing discussions, in light of the claims made in that letter I thought it would be valuable to put in writing the first years of youtube-dl as the project creator and initial maintainer.</p>
<div>
<h4 id="_copper_thieves">Copper thieves</h4>
<p>All good stories need at least a villain so I have arbitrarily chosen copper thieves as the villains of the story that set in motion what youtube-dl is today. Back in 2006 I was living in a town 5 to 10 kilometers away from <a href="https://en.wikipedia.org/wiki/Avil%C3%A9s">Avilés</a>, which is itself a small city or town in northern Spain. While people in Avilés enjoyed some nice infrastructures and services, including cable and ADSL Internet access, the area I lived in lacked those advantages. I was too far away from the telephone exchange to enjoy ADSL and copper thieves had been stealing copper wires along the way to it for years, causing telephone service outages from time to time and making the telephone company replace those wires with weaker and thinner wires, knowing they would likely be stolen again. This had been going on for several years at that point.</p>
<p>This meant my only choice for home Internet access so far had been a dial-up connection and a <a href="https://en.wikipedia.org/wiki/Modem#Standardized_56k_(V.90/V.92)">56k V.90 modem</a>. In fact, connection quality was so poor I had to limit the modem to 33.6 kbps mode so the connection would be at least stable. Actual download speeds rarely surpassed 4 KB/sec. <a href="https://en.wikipedia.org/wiki/YouTube">YouTube</a> was gaining popularity then to the point it was purchased by Google at the end of that year.</p>
</div>
<div>
<h4 id="_up_all_night_to_get_some_bits">Up all night to get some bits</h4>
<p>Watching any YouTube video on the kind of connection I described above was certainly painful, as you can imagine. Any video that was moderately big would take ages to download. For example, a short 10 MB video would take, if you do the math, 40 minutes to download, making streaming impossible. A longer and higher-quality video would take several hours and render the connection unusable for other purposes while you waited for it to be available, not to mention the possibility of the connection being interrupted and having to start the download process again. Now imagine liking a specific video a lot after watching it and wanting to watch it a second or third time. Going through that process again was almost an act of masochism.</p>
<p>This situation made me interested in the possibility of downloading the videos I was trying to watch: if the video was interesting, having a copy meant I could watch it several times easily. Also, if the downloader was any good, maybe the download process could be resumed if the connection was interrupted, as it frequently was.</p>
<p>At the time, there were other solutions to download videos from YouTube, including a quite popular <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> script. By pure chance, none of the few I tested were working when I did, so I decided to explore the possibility of creating my own tool. And that is, more or less, how youtube-dl was born. I made it a command-line program so it would be easy to use for me and wrote it in Python because it was easy thanks to its extensive standard library, with the nice side effect that it would be platform independent.</p>
</div>
<div>
<h4 id="_an_ethereal_start">An Ethereal start</h4>
<p>The initial version of the program only worked for YouTube videos. It had almost no internal design whatsoever because it was not needed. It did what it had to do as a simple script that proceeded straight to the point. Line count was merely 223, with only 143 being actual lines of code, 44 for comments and 36 of them blank. The name was chosen out of pure convenience: youtube-dl was an obvious name, hard to forget, and it could be intuitively typed as “Y-O-U-TAB” in my terminal.</p>
<p>Having been using Linux for several years at that point, I decided to publish the program under a free software license (MIT for those first versions) just in case someone could find it useful. Back then, GitHub did not exist and we had to “make do” with <a href="https://en.wikipedia.org/wiki/SourceForge">SourceForge</a>, which had a bit of a tedious form that you needed to fill to create a new project. So, instead of going to SourceForge, I quickly published it under <a href="https://web.archive.org/web/20060812055952/http://www.arrakis.es/~rggi3/youtube-dl/">the web space that my Internet provider gave me</a>. While not usual today, it was common for ISPs to give you an email address and some web space you could upload stuff to using FTP. That way, you could have your own personal website on the net. The first ever version made public was 2006.08.08, although I probably had been using the program for a few weeks at that point.</p>
<p>To create the program, I studied what the web browser was doing when watching a YouTube video using Firefox. If I recall correctly, Firefox didn’t yet have the development tools it has today to analyze network activity. Connections were mostly HTTP and <a href="https://en.wikipedia.org/wiki/Wireshark">Wireshark</a>, known as “Ethereal” up to that year, proved invaluable to inspect the network traffic coming in and out of my box when loading a YouTube video. I wrote youtube-dl with the specific goal of doing the same things the web browser was doing to retrieve the video. It even sent out a User-Agent string that was verbatim copied from Firefox for Linux, as a way to make sure the site would send the program the same version of video web pages that were used to study what the web browser was doing.</p>
<p>In addition, YouTube used <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a> back then for the player. Videos were served as Flash Video files (FLV), and this all meant a proprietary plugin was required to watch them on the browser (many will remember the dreaded <code>libflashplayer.so</code> library), which would have made any browser development tools useless. This proprietary plugin was a constant source of security advisories and problems. I used a Firefox extension called <a href="https://en.wikipedia.org/wiki/Flashblock">Flashblock</a> that prevented the plugin from being loaded by default and replaced embedded content using the plugin, in web pages, with placeholder elements containing a clickable icon so content would be loaded only on demand and the plugin library was not used unless requested by the user.</p>
<p>Flashblock had two nice side effects apart from making the browsing experience more secure. On the one hand, it removed a lot of noisy and obnoxious ads from many web pages, which could also be a source of security problems when served by third parties. On the other hand, it eased analyzing how videos were being downloaded by the video player. I would wait until the video page had finished downloading completely and then start logging traffic with Wireshark just before clicking on the embedded video player placeholder icon, allowing it to load. This way, the only traffic to analyze was related to the plugin downloading the video player application and the application itself downloading the video.</p>
<p>It’s also worth noting the Flash Player plugin back then <a href="https://www.nirsoft.net/articles/copy_flash_flv_temp_file.html">was already downloading a copy of those videos to your hard drive</a> (they were stored in <code>/tmp</code> under Linux) and many users relied on that functionality to keep a copy of them without using additional tools. youtube-dl was simply more convenient because it could retrieve the video title and name the file more appropriately in an automated way, for example.</p>
</div>
<div>
<h4 id="_ahh_fresh_meat">Ahh, fresh meat!</h4>
<p>The Flash Player plugin was eventually <a href="https://www.omgubuntu.co.uk/2010/09/saving-flash-videos-in-linux-tmp-no-longer-works">modified so videos wouldn’t be so easily available to grab</a>. One of the first measures was to <a href="https://en.wikipedia.org/wiki/Unlink_(Unix)">unlink</a> the video file after creating it, so the i-node would still exist and be available to the process using it (until it was closed) while keeping the file invisible from the file system point of view. It was still possible to grab the file by using the <code>/proc</code> file system to examine file descriptors used by the browser process, but with every one of those small steps youtube-dl turned to be more and more convenient.</p>
<p>As many free and open source enthusiasts back then, I used <a href="https://en.wikipedia.org/wiki/Freecode">Freshmeat</a> to subscribe to new releases of projects I was interested in. When I created youtube-dl, I also created a project entry for it in that website so users could easily get notifications of new releases and a change log listing new features, fixes and improvements. Freshmeat could also be browsed to find new and interesting projects and its front page contained the latest updates, which usually amounted to only a few dozens a day. It’s only my guess that’s the way <a href="https://en.wikipedia.org/wiki/Joe_Barr">Joe Barr</a> (rest in peace), an editor for <a href="https://en.wikipedia.org/wiki/Linux.com">linux.com</a>, found out about the program and decided to write <a href="https://www.linux.com/news/cli-magic-enhance-your-youtube-viewing-pleasure/">an article about it</a> back in 2006. Linux.com was a bit different then and I think it was one of the frequently-visited sites for Linux enthusiasts together with other classics like <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a> or <a href="https://en.wikipedia.org/wiki/LWN.net">Linux Weekly News</a>. At least, it was for me.</p>
<p>From that point on, youtube-dl’s popularity started to grow and I started getting some emails from time to time to thank me for creating and maintaining the program.</p>
</div>
<div>
<h4 id="_measuring_buckets_of_bits">Measuring buckets of bits</h4>
<p>Fast forward to the year 2008. youtube-dl’s popularity had kept growing slowly and users frequently asked me to create similar programs to download from more sites, a request I had conceded a few times. It was at that point that I decided to rewrite the program from scratch and make it support multiple video sites natively. I had some simple ideas that would separate the program internals into several pieces. To simplify the most important parts: one would be the file downloader, common for every website, and another one would be the information extractors: objects (classes) that would contain code specific to a video site. When given a URL or pseudo-URL, the information extractors would be queried to know which one could handle that type of URL and then requested to extract information about that video or list of videos, with the primary goal of obtaining the video URL or a list of video URLs with available formats, together with some other metadata like the video titles, for example.</p>
<p>I also took the chance to switch version control systems and change where the project would be hosted. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rg3.name/202011071352.html">https://rg3.name/202011071352.html</a></em></p>]]>
            </description>
            <link>https://rg3.name/202011071352.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047818</guid>
            <pubDate>Tue, 10 Nov 2020 16:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma's Bund Finance Summit Speech]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25047544">thread link</a>) | @ceohockey60
<br/>
November 10, 2020 | https://interconnected.blog/jack-ma-bund-finance-summit-speech/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/jack-ma-bund-finance-summit-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!-- social share icon -->
                    

                    <p><em>I don’t normally do any translation, because Interconnected is focused on original work and thinking. But I felt compelled to provide an English version of Jack Ma’s speech on October 24 at the Bund Finance Summit in Shanghai, because mainstream media coverage of the speech and the subsequent cancellation of Ant Group’s IPO has been lacking and simplistic. The speech is worth reading in its entirety to have a deeper understanding the full picture. Below is my unofficial translation of the speech </em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>based on a Chinese transcript</em></a><em>, with minor edits for clarity and speechifying. To read my deep dive analysis on the speech and its broader context, please check out: "<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">Jack Ma, P2P Lending, Responsibility, Legacy</a>"</em></p><p><em>我通常不做任何翻译工作，因为《互联》专注于原创作品和思考。但我觉得有必要提供马云10月24日在上海外滩金融峰会上的演讲的一个英文版，尽管只是我个人非官方的翻译，因为主流媒体对演讲和随后蚂蚁集团取消上市的报道太欠缺，过于简单化。整套演讲值得一读来更深层的了解整个事情，可以在</em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>这里看全文</em></a><em>，在</em><a href="https://finance.sina.com.cn/chanjing/gsnews/2020-10-28/doc-iiznctkc8161643.shtml"><em>这里看视频</em></a><em>。想看我对这套演讲和有关大观景的深度分析，请读《<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">马云，P2P借贷，责任，留给社会的遗产</a>》</em></p><hr><p>Thank you for inviting me to this Summit. I am delighted to have this opportunity to learn, discuss, and exchange ideas together with you. In 2013, also in Shanghai, I came to the Lujiazui Finance Summit and shared some “pie in the sky” views about Internet-powered finance. Seven years later, today I'm back in Shanghai as an unofficial non-professional person here at the Bund Finance Summit, hoping to share more ideas for you to ponder.</p><p>Actually, I was quite torn about whether to speak here today. But I think there is one thing that is incumbent upon this group of people, and that is the responsibility to think about the future, because although the world has left us many opportunities for development, there are really only one or two critical opportunities. This is a most critical moment.</p><p>So I come here to share some of my own thoughts and views, which are the result of our own practical experience in the last 16 years, plus discussions and research I have had with scholars, experts, and practitioners from all over the world, during the period when I was honored to be the co-chair of the UN High-Level Panel on Digital Cooperation and an advocate for the UN Sustainable Development Goals (SDGs).</p><p>I’m basically retired at this point, so I thought I'd speak freely at this unofficial forum and share the non-professional views of a non-professional person. Fortunately, I've discovered that many professionals no longer speak about their professions anymore.</p><p>I have three points of view for you to consider. They may be immature, incorrect, or laughable. Just give them a listen, if they make no sense, just forget about them.</p><p>The first point of view is we have some inertia in our thinking, like we always feel that in order to keep pace with international standards, we must do what developed countries like Europe and the United States have done. If we don’t have something they have, the so-called “blank spot”, we must fill those blank spots domestically. Filling these spots has become the goal to pursue.</p><p>I have always felt that, given this year's situation, the phrase to “fill the blank spot” is problematic. Just because Europe and the United States have something does not mean that thing is always advanced and worth having ourselves. In fact, today, we should not be concerned about what things to align with, which country's standard to adapt to, what blank spots to fill. Today, we have to think about how to align with the future, how to adapt to the future’s standard, how to fill the future’s blank spots. We have to figure out what the future will be, and what we really want to do, and then look at how others do it. If we always repeat the language of others, discuss topics defined by others, we will not only be lost in the present, but also miss the future.</p><p>After World War II, the world needed to restore economic prosperity. The establishment of the Bretton Woods system was an enormous catalyst to the global economy. Later, after the Asian financial crisis occurred, the Basel Accords talked about risk control, which has been gaining more and more attention, to the point that it became an operational standard for risk control. Now the trend is, the world is talking more and more just about risk control, not development. Very few people talk about where the opportunities are for young people, for developing countries.</p><p>This, in fact, is the root cause of many of the world's problems today. We also see today that the Basel Accords have put great limitations on Europe’s ability to innovate as a whole, for example, in digital finance.</p><p>Basel, more like a seniors club, is about solving the problem of an aging financial system that has been operating for decades, and Europe’s aging system is extremely complex. But the problem in China is the opposite: it is not a problem of systemic financial risk, because China's financial sector basically doesn’t have a system. Its risk is actually a "lack of financial system."</p><p>China's financial sector, like other developing countries that have just grown up, is a young industry that does not have a mature ecosystem and is not fully moving. China has many big banks. They are more like big rivers or arteries in our body’s circulatory system, but today we need more lakes, ponds, streams and tributaries, all kinds of swamps. Without these parts of the ecosystem, we will die when we are flooded, and die when we are in a drought. So, today we are a country that bears the risk of lacking a healthy financial system, and we need to build a healthy financial system, not worry about financial systemic risks.</p><p>They are like two completely different diseases, like Alzheimer's disease and polio. Both look similar at first glance but are two totally different illnesses. If a child takes Alzheimer's medication, he or she will not only get the old person’s disease, but a lot of other strange diseases as well.</p><p>The Basel Accords is designed to treat the diseases of the elderly with an aging system and over-complexity, and what we have to think about is what can we learn from the elderly? You must remember, older people and younger people care about different issues. Younger people care about whether there are schools, older people care about whether there are hospitals.</p><p>So, the way the world is changing this year is fascinating and very fast. Last night in Shanghai, we decided on the pricing of Ant’s IPO. This is the largest listing ever priced in the history of the entire human race, and the pricing happened in a place other than New York City. This was unthinkable five years ago, even three years ago, but miracles happen.</p><p>Second, innovation must come at a price, and our generation must take on that responsibility.</p><p>President Xi once said, "success does not have to come from me." I understand this phrase to be about a sense of responsibility. It’s about taking responsibility for the future, for tomorrow, for the next generation. Many of the world's problems today, including China's, can only be solved by innovation. However, for real innovation to happen, no one will show you the way, and someone must shoulder that responsibility, because innovation is bound to make mistakes. But the question is not how not to make mistakes, but whether we can perfect and correct them after making mistakes and persistently innovate. To make risk-free innovation is to stifle innovation, and there is no risk-free innovation in this world. There is no such thing as risk-free innovation. Oftentimes, managing risk down to zero is the biggest risk.</p><p>When the battle of Red Cliff was fought, I believe Cao Cao’s act of connecting all the ships together was the first instance of an aircraft carrier, in China and the world, but after a fire burned it all down, for a thousand years, the Chinese people didn't dare to think about it again. Once they thought about that fire, who still wanted to make a bigger ship, who could still have this kind of system-level thinking?</p><p>Seven or eight years ago, also in Shanghai, I mentioned this concept of Internet-powered finance. We have always emphasized that Internet-powered finance must have three core elements: first, it must have rich data; second, it must have risk control technology based on rich big data; and third, it must have a credit-based system built on big data.</p><p>Using these three criteria to evaluate, we can see that P2P is not Internet-powered finance at all, but today we cannot negate the innovation that the Internet has brought to finance just because of P2P. In fact, let's think about it, how can there be thousands of Internet-powered finance companies in China within a few years? Shouldn't we examine what gave birth to thousands of “Internet-powered finance”, the so-called P2P companies?</p><p>Today, it's really difficult to regulate ourselves; it's hard to conduct regulation everywhere around the globe. Innovation mainly comes from the marketplace, innovation comes from the grassroots, innovation comes from young people. Regulatory challenges are getting bigger and bigger. In fact, <em>jian </em>[editor's note: English word is “supervision”, the first character in the word for “regulation” in Chinese] and <em>guan </em>[editor's note: English word is “management”, the second character in the word for “regulation” in Chinese] are two different things. "Supervision" means watching you as you develop and paying attention to your development. “Management” means intervening when there is a problem or when there is a foreseeable problem.</p><p>We are very good at “management”, but our “supervision” ability is sorely lacking.</p><p>Good innovation is not afraid of regulation, but is afraid of being subjected to yesterday's way to regulate. We cannot use the way to manage a railway station to manage an airport. We cannot use yesterday's way to manage the future.</p><p>"Supervision" and "management" are not the same, “policies” and “documents” are also not the same. This isn’t allowed, that isn’t allowed, those are all called “documents”. Policy …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/jack-ma-bund-finance-summit-speech/">https://interconnected.blog/jack-ma-bund-finance-summit-speech/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/jack-ma-bund-finance-summit-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047544</guid>
            <pubDate>Tue, 10 Nov 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C source-to-source compiler enhancement from within]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25047169">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://hal.inria.fr/hal-02998412 | <a href="https://web.archive.org/web/*/https://hal.inria.fr/hal-02998412">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p><strong>Abstract</strong> : We show how locally replaceable code snippets can be used to easily
  specify and prototype compiler and language enhancements for the
  C language that work by local source-to-source
  transformation.
  A toolbox implements the feature and provides many directives that
  can be used for compile time configuration and tuning, code
  unrolling, compile time expression evaluation and program
  modularization.
  The tool is also easily extensible by simple filters that can be
  programmed with any suitable text processing framework.                    </p>
                                </div><p><small>
                https://hal.inria.fr/hal-02998412<br>
                Contributeur : <a rel="nofollow" href="https://hal.inria.fr/search/index/q/*/contributorId_i/105206" target="_blank">Jens Gustedt</a>                        &lt;<a href="" id="link5fad98cd262da"></a>&gt;
                        <br>Soumis le : mardi 10 novembre 2020 - 15:02:12<br>DerniÃ¨re modification le : mercredi 11 novembre 2020 - 03:36:16</small>
        </p></div>]]>
            </description>
            <link>https://hal.inria.fr/hal-02998412</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047169</guid>
            <pubDate>Tue, 10 Nov 2020 15:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka – The Full Benchmark Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046908">thread link</a>) | @tuhaihe
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046908</guid>
            <pubDate>Tue, 10 Nov 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how not to write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046894">thread link</a>) | @zdw
<br/>
November 10, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it’s me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger’s endless unfixed bugs. I’m going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene’s main texture installation tool, built on top of aquadran’s MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‘core’ features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that’s not why I’m here today – I’m here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you’d be expect from a mid 2000’s console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It’s… a really meh port that has not aged very well. It’s passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it’s not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator – which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system’s install of PhysX, while Mass Effect uses the local game’s PhysX. Mass Effect 2 and Mass Effect 3 also use the ‘modern’ version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it’s ‘modern’ versions. </p>
<p>But that doesn’t seem to stop Legacy PhysX’s uninstaller from deleting modern PhysX’s files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn’t work, even after installing the ‘modern’ PhysX redistributable. It’s really annoying how BioWare couldn’t just ship a 8MB library with the game – they already shipped the installer for PhysX with the game, so it’s not like it saved space!</p>
<p>But anyways…</p>
<h2>The issue with Epic Games’ PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system’s installed version</h2>
<p>Err… wait, how is that an issue? Can’t you just load the local dll, and if that doesn’t exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won’t believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you’re looking for yourself.</p>
<p>Remember these registry values, they’re going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it’s compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash… </p>
<p>So it’s already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn’t be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn’t name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect’s behavior – the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it’s always done, just without administrative rights. There wasn’t really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer – even though our application didn’t actually change how Mass Effect was behaving writing these values, so there’s no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game’s PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system’s MAC address would break other games – or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory’s PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn’t install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you’re strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system’s MAC address to determine if it should load the local directory’s PhysX libraries or the system’s.</h4>
<p>Which MAC address? </p>
<h3>¯\_(ツ)_/¯</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system’s MAC address against it</li>
<li>If it matches, it uses the local folder’s PhysX, if not, it uses the system’s redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror’s Edge, have a PhysXLoader.dll that also reads these values (as they’re based on the same code), <em>but they don’t include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn’t start. This information is second hand from mirh – I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn’t exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed – it will use the system libraries instead. If system PhysX is not installed, the application will not boot – this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It’s hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you’re interfacing with a library that has exports you can call to initialize/load the PhysX SDK… couldn’t you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what’s up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions – and after disassembling the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046894</guid>
            <pubDate>Tue, 10 Nov 2020 15:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homegrown KDP doubling crystal for Nd:YAG laser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046806">thread link</a>) | @buescher
<br/>
November 10, 2020 | http://www.milankarakas.org/pub/KDP/HomegrownKDP.html | <a href="https://web.archive.org/web/*/http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><span>

<p>
Long time ago I had idea to add a doubling crystal to my
Nd:YAG laser to get green output. But the problem is
that I have no idea which one to buy. There is many
choices, but no simple guide which one will be
appropriate for such Q-switched Nd:YAG laser. I have
another Nd:YAG laser without Q-switch, and this
complicates things a bit more if I want to get doubled
frequency from that laser too.

</p><p>
I heard of KDP (chemical formula
KH<sub>2</sub>PO<sub>4</sub>), and I have that chemical
for hydroponic use, but did not believe that it is
possible to grow decent crystal for SHG (Second Harmonic
Generation). Since my school days, I know how to grow
crystals with jar, chemical and just fiber. This type of
growing crystals give only heap of crystals bond
together, for which I not believe that it is possible to
use as a SHG.

</p><p>
Just by accident, I watched video on YouTube about
growing another type of crystal, so called
‘alum’, and there is explanation how to get
single seeded crystal. Aside that, I saw another video
where they grow KDP crystal for NIF (National Ignition
Facility). Second video looks too complicated to me, so
I decided to follow procedure for growing alum crystal,
but with KH<sub>2</sub>PO<sub>4</sub> chemical. Result
was disappointing. I got many crystals aside from the
seeded one, and mostly bonded together. I tried re-seed
bigger one, but it lead to even worst situation.

</p><p>
After few attempts I gave up. What I get is hundreds of
small crystals, for what I believed that there is no
even smallest chance to get frequency doubling, or
making other harmonics (THG, FHG, etc.). I tried to find
information on the internet about whether someone got
homegrown KDP crystal and use it as SHG. There is no
results. Only result I got is about purchasing such
crystals, but price is... huh... &nbsp; :-p

</p><p> In private conversation with my friend
<a href="http://www.jarrodkinsey.com/">
Jarrod Kinsey</a>
he pushed me to try to put some small crystal at the
output beam from the Nd:YAG laser anyway. I argued that
this is not possible and that for such frequency
doubling it is required special cut of the crystal,
precision aligning, polarized laser, and so on.

</p><p>
Later on, I wanted to check what is necessary to get
proper angle, but all I got is many offers for buying
finished crystals with instructions how to use. At few
pages they mentioned some angles, but also many other
data, for what at this time I have no idea what they
means. Until today I am not sure about many of that, but
I am much more close to understanding it.

</p><p>
Laser is there, crystals are there, but also many
questions too. Finally, I got courage to try it. During
preparing for this test, I had all the time idea how to
tell him that it failed, and that he is wrong. Also, I
remember conversation with another friend,
<a href="http://www.jossresearch.org/">
Jon Singer,</a>
a long time ago about this subject, before my attempt to
grow crystals. He mentioned to me that this may be
difficult too, but not impossible. He also mentioned
that it is worth to try to grow crystals;
“What’s to lose?”

</p><p>
With all of that on my mind, and with serious doubt, I
wear safety goggles and fire my laser with focusing lens
onto small KDP crystal. I had no idea where to point
that focus. I tried few times with different angles, and
WOW! Green light popped right out of the crystal. At
first very weak, but at that moment, my excitement
increased my perception of such intensity to the
extreme. By slightly changing angle, I got even more
green light out.

</p><p>
It took me a while until cool down my mind and realized
what I got. Then I reported to my friends on the
<a href="https://mail.neurotica.com/mailman/listinfo/lasers">
Lasers -- Laser and high-energy physics hacking </a>
mailing list, who congratulated me for this achievement.

<br>

</p>
<p>
At third picture from the left, there is glued crystal
at approximately 42° to the incoming beam. Note that
I am not sure of the exact angle, because incoming beam
is focused, which produce cone of light. Such cone is
not so good, and part of the incoming energy is wasted.
I tried to use binocular as a beam shrinker. Instead of
3 mm beam, my attempt is to narrow it to about 0.3 mm
(if binocular has magnification 8x, then reversed should
narrow or shrink beam to very narrow beam. Such narrow
beam has high divergence, but at short distance it is
okay. After beam pass crystal, it will be good to use
beam expander to back to the original beam diameter, or
to expand beam even more to achieve lower divergence.
But I forgot that in binocular are glued two lenses
together to correct chromatic aberration. Here is how it
looks after a few laser pulses:

<br>

</p>

<div><p>
There is glue, or optical cement between that two lenses.
It seems that some glues/cements don’t like IR (infra
red) radiation. I noticed that at first, there is only
burning spot, but as room temperature changes, one of
two lenses made different expansion rate and produce
crack.

</p></div>
<p>
I am mentioned birefringence which is visible on the
green spot. By slightly adjusting (rotating) angle, that
two groups of spots becomes one. When collimating to the
infinite, such phenomena is less visible, because both
spots make one small spot, slightly elliptic.

</p><p>
My both Nd:YAG lasers are non-polarized. For that reason
I use so called ‘Type II’ phase matching. Since I
am ‘newbie’ in that field, on the Internet you may
find some nice article(s) about phase matching. One of
them is:
</p>

<a href="http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf">
http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf</a>

<p>
And another document:

</p>
<a href="http://www.quantumtech.com/apps/916.pdf">http://www.quantumtech.com/apps/916.pdf</a>

<p> Citation from page 5:

</p><p>*4.

</p><p>
“When the cell is mounted horizontally in an optical
mount, the screw (for filling the fluid) should face the
ceiling. The polarization for the input beam should make
and angle of 45° with respect to the horizontal or
vertical plane. Slight Rotation and/or angular
adjustment is required to obtain optimum efficiency.”

</p><p>
*5.

</p><p>
"Type II process is more efficient because the
acceptance angle is wider, making alignment and thermal
control less critical than Type I process, especially
for doubling 1060nm. For tripling two orthogonally
polarized beams, this process is attractive if the
crystal is cut at the proper angle for tripling. The
distance between the doubler and tripler should be as
small as possible for best efficiency. Two orthogonally
polarized beams should make an angle of 45° when the
cell is oriented as in instruction *4." [End of
citation]

</p><p>
I tried tripling Nd:YAG laser, but since my laser is not
polarized, and because there is huge amount of white
light from flashlamp, can’t be sure whether I got 355 nm
(THG) in UV range. For tripling frequency, there must be
actually two crystals. One after another, carefully
oriented, aligned and so on. Too much complicated for me
at this moment.

</p><p>
One of the beauty for such wide acceptance angle is for
beginners like me. Even when holding KDP crystal in
hand, one may be able to adjust close to the proper
angle, so that there is at least some green light.
Further adjusting is then easier, because it increase or
decrease intensity of doubled frequency very gently. Not
so sharp like Phase I matching. I tried that too, but it
works bad for non-polarized lasers.

</p><p>
Another good thing is that even completely fogged
crystal produce some green light. Not much, but crystal
glow green anyway. There is almost no output beam (no
visible spot), just diffuse green glowing. Even most
clear crystal produce some fluorescence which is
consequence of change in refraction indexes. I am not
completely sure how and why, because in relatively short
period read so much documents, and this matter is very
complex.

</p><p>
Such fluorescence can bee seen in clear crystals, so
that one may see the path of the laser beam.

</p><p>
In one document (can’t remember which one), they said
that fine powder can produce SHG too, but with helps of
PMT (Photo Multiplier Tube). This means that random
oriented small crystals, many of them will be
accidentally oriented close to the proper angle, so that
they can make frequency doubling. At that way, they get
very dim green light which can be seen only with aid of
PMT.

</p><div><p>
About conversion efficiency. I have no instruments for
measuring efficiency, and suppose that in my case,
efficiency of conversion is low. In one of my post to
the lasers mailing list, I mentioned that it is possible
to put KDP crystal intracavity for lasers which has not
Q-switch. On that way, one may get greater efficiency by
counting on standing waves inside laser resonator, But
this is very problematic if laser is not polarized.  My
friend Douglas Little tried it and got some green light
out too. But after few shots, one or both HR mirrors,
got optical damage. Standing wave become stronger and
stronger each time passes lasing media. Just one part is
‘extracted’ and converted into harmonic. It will be good
that conversion efficiency is high, so that both laser
mirrors are HR, but one of them with added high
reflectance for 532 nm. If both HR mirrors are for 1064
nm, then doubled frequency will exit at both end of the
Nd:YAG doubled laser.

</p></div><div><p>
About making seed crystals. You may use an old method of
growing crystals as a start for growing small KDP
crystals for seeds.

</p></div> 

<div><p>
An old method with string may give you bad result, so
consider alternative method, which is also simple.
</p></div> 
<p>
If you are lucky enough, and get big crystal, after
cutting to proper size and angle for SHG or THG use,
rest of the crystal may serve as seed crystal. Chose
part which is clear. Shape it and put it as a seed. Or,
if big crystal not met quality requirement, at least one
part of such crystal may serve as a seed crystal. Mostly
clear part is pyramidal part of the KDP crystal.
Prismatic part may be with inclusions, bubbles, water
pockets, and other defects.

</p><p>
I have no chance to get enough big crystal yet. For such
growing of near perfect crystals, it require more or
less sophisticated apparatus, ultra pure water, well
prepared solution etc. I use ’industrial grade’
KH<sub>2</sub>PO<sub>4</sub>, which bought in hydroponic
store. It is marked as MKP 0-52-34. The problem with
that chemical is that there is small amount of</p></span></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</a></em></p>]]>
            </description>
            <link>http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046806</guid>
            <pubDate>Tue, 10 Nov 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading, Wisely – How I'm Using Readwise to Improve My Learning]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046762">thread link</a>) | @ggnall
<br/>
November 10, 2020 | https://www.grahamgnall.com/blog/2020/11/9/reading-wisely | <a href="https://web.archive.org/web/*/https://www.grahamgnall.com/blog/2020/11/9/reading-wisely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-9da5bc9359b1bdaa3cf4"><div><p>Readwise is a utility that’s changed the way I read. I'm thoroughly enjoying it and I recommend it to anyone looking to improve their learning. You can sign up for a trial here:</p>
<p><a href="https://readwise.io/">Readwise - plain link</a></p>
<p><a href="https://t.co/3y8bAXryW7?amp=1">Readwise - my referral link</a></p>
<h2 id="about">About</h2>
<p>Readwise is an app (browser extension, web app, mobile app) that organizes information from the books you read. The app relies on learning techniques like <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> to train your memory on your reading highlights and annotations.</p>
<h2 id="benefits">Benefits</h2>
<p><strong>Retention</strong></p>
<p>Readwise makes it easy to retain information you’ve read and deemed important in the past. I try to read constantly, but when I look at my <a href="https://www.grahamgnall.com/books">Books</a> list, there are plenty of subjects that are blurry or shockingly, missing altogether from my memory. I’ve been a Kindle device/app enthusiast and previously built my own scripts to export and organize my highlights. It was fun, but I ended up spending more time writing the so-called automation than actually reviewing the highlights. Readwise handles all of the syncing automatically from all your ebooks and articles, and even supports input from physical books. Its Daily Readwise review feature is a daily, randomized feed of highlights that surfaces old and new content to train on.</p>
<p><strong>Making New Connections</strong></p>
<p>There is a thrilling feeling when your mind makes connections between two seemingly disparate topics. This is foundational in my belief in <a href="https://www.grahamgnall.com/blog/2014/7/9/learn-disciplines-not-skills-startups-for-liberal-arts-majors">liberal arts education</a> and it's applications. The simple act of viewing highlights from multiple, unrelated books in the Daily Readwise allows your brain to play with these concepts on the same plane. Readwise’s tagging feature allows you to group highlights about the same topic or theme, so you can build your knowledge base with more examples and perspectives. Both of these features aid in constructing, expanding, and applying mental models to the world, or what Charlie Munger called a <a href="https://fs.blog/great-talks/a-lesson-on-worldly-wisdom/">“latticework”</a> of models from different disciplines.</p>
<h2 id="how-i-use-it">How I Use It</h2>
<p><strong>Set Up</strong></p>
<p>I mostly use the core Readwise syncing sources:</p>
<ol>
<li>Kindle - automated</li>
<li>Pocket - automated</li>
<li>Non-kindle ebooks - semi-automated, requires one manual step when I finish a book</li>
<li>Physical books - manual, but with highly reliable OCR.</li>
</ol>
<p>There are also other a growing number of non-traditional sources like Twitter threads and podcast annotations. I haven’t tried them out yet, but they look promising.</p>
<p>The default settings are thoughtfully done to maximize your learning right out of the box (e.g. 5 daily items, mix of old and new highlights). You can get really granular configuring these settings, down to the book/article level. So far, I’ve only used this to filter out certain things, like definitions from a Javascript textbook I read in 2012. </p>
<p><strong>Developing a Review Habit</strong> </p>
<p>The best product experiences create new habits and rituals around them, for a positive result. Readwise has created a few distinct habits for me. I look forward to my Daily Readwise and it’s one of the few things I let myself do on my phone when waking up. This takes less than a minute and is easy to implement. I never have to schedule in time for this and I never miss it.</p>
<p>Readwise sits on my home screen and I’ve started to open it whenever I need a “feed fix”. It takes my boredom trigger and offers something more valuable than a dopamine hit. Sometimes I’ll do a few cycles of 5 items before calling it quits and going back to whatever I was supposed to be doing. </p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_44801"><div><p><strong>Developing Better Reading Habits</strong></p>
<p>Readwise has also changed the way I read. I now look for insights that I want to extract and return to later far more deliberately. I’ve found that even for books I abandon, if I was able to pull a single interesting idea out of it, I got some value out of it. This has reduced the guilt of putting down a book that can’t hold my attention. Or in the case of many business books, lets me extract the primary bits in the beginning without slogging through the filler.</p>
<p>The same applies to how I approach articles. I now view all types of text as holding information I can extract for my own purposes. I'm excited to uncover items to clip and have been delighted by the easy inputs into Readwise, including: highlighting directly in my browser, copy/pasting text from a mobile app, or taking an image of a physical book or magazine. This lets me jot things down, like book recommendations, without having to leave the text and pick them up later. </p>
<p><strong>Organizing Information</strong></p>
<p>I’ve always liked the idea of linking ideas together and this was lacking in my homegrown version of this tool. In addition to notes, you can also add freeform tags to your highlights. This makes it easy to view all your highlights that relate to theme like <code>writing</code> or <code>decision-making</code>. I use this feature to learn about a specific topic. I’m very interested in learning about the routines and processes of interesting creators, and I’ve started to aggregate tags for <code>routine</code> and <code>process</code> for instance. </p>
<p>I use the Daily Review to tag anything that fits into my ongoing areas of interest.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604956577898_10298"><p>The free-form search is also a great way to pull in notes on a specific topic. Feeling homesick recently, I typed in “new york” and saw some highlights that made me smile:</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_70588"><div><h2 id="last-word">Last Word</h2>
<p>I was happy to drop my hacky version for a simple, easy, and well-designed product. It's helping me to create better habits and reinvigorating my reading pracitce.</p>
<p>I'm training myself to spend on well-designed software products so that such things can exist. Unfortunately paid apps are still a boundary for many - and hopefully the COVID trend of increased subscription spending will change that. For me, the $8.99 / month is well worth the increased utility from books I’ve already purchased (usually for the low Amazon set price of $9.99). I’m sure this was intentional: get more out of your books for less than the already low price of a book a month. Better yet, it makes me <em>excited</em> to buy and read more books.</p>
<p>Of course, if you want to apply these lessons to a self-hosted system you can. You can scrape (pun intended) together your own version by parsing the Kindle Cloud Reader (and other reading apps) to a database (including no-code databases in Notion, Airtable, and even Google Sheets) and building out the necessary views. Or you can keep it lo-fi. I’ve heard of several non-fiction authors using a index card based version of Readwise, where they group passages from different sources by them. I wouldn’t be surprised if this tradition influenced Readwise's card ui and tag features. </p>
<p>And then you <em>could</em> always take it further. While many in the <em>organized thinking</em> movement (or <a href="https://twitter.com/cultroam?lang=en">roamcult</a>) are using Readwise’s Notion and Roam exports to develop fully mapped information on <em>everything</em>, I find the Readwise experience to be fully satisfactory on its own.</p>
</div></div></div>]]>
            </description>
            <link>https://www.grahamgnall.com/blog/2020/11/9/reading-wisely</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046762</guid>
            <pubDate>Tue, 10 Nov 2020 15:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046519">thread link</a>) | @airza
<br/>
November 10, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">⊕</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> – Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a …</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046519</guid>
            <pubDate>Tue, 10 Nov 2020 14:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of JavaScript at the end of 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046293">thread link</a>) | @milo_im
<br/>
November 10, 2020 | https://www.ideamotive.co/javascript-business-guide | <a href="https://web.archive.org/web/*/https://www.ideamotive.co/javascript-business-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
           <p><span id="hs_cos_wrapper_pillarPage_content" data-hs-cos-general-type="widget_container" data-hs-cos-type="widget_container"><p id="hs_cos_wrapper_widget_1603280203415" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>00</span>
        
        
          <span>State of JavaScript in 2020 [INFOGRAPHIC]</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1603200140243" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p><img src="https://www.ideamotive.co/hs-fs/hubfs/Pillar%20JS/JavaScript%20in%202020%20C%20(4).png?width=1439&amp;quality=low" alt="JavaScript in 2020 C (4)"></p>

    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603280336294" data-hs-cos-general-type="widget" data-hs-cos-type="module">









  <div>
    <p> Share the infographic in social media </p>
    
  </div>


</div>
<p id="hs_cos_wrapper_widget_1601646578122" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>01</span>
        
        
          <span>What is JavaScript?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601646616007" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>You might have heard that “JavaScript is everywhere.” Which is where exactly?&nbsp;&nbsp;</p>
<p>According to <a href="https://w3techs.com/technologies/details/cp-javascript" rel="noopener" target="_blank">Web3Techs</a> — on over 96% of all websites. Google, LinkedIn, Yahoo, YouTube, eBay, Amazon, you name it. There’s JavaScript all over the place.&nbsp;</p>
<p>Created in 1995 by Brendan Eich, JavaScript is a scripting language used to build and manage dynamic web content, such as multimedia, interactive forms, animations, photo slideshows, calendars, autocomplete suggestions, and much more.</p>
<p>JS is one of the three core technologies of frontend web development, along with HTML and CSS. While HTML is a markup language responsible for giving the structure to a website, and CSS is a language used to apply styles to HTML content, JavaScript is responsible for creating and managing dynamic, interactive website elements.</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069795205" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        Who is the JavaScript creator?
      </h3>
    
    
      <div>
        <p>Born in 1961, <a href="https://www.linkedin.com/in/brendaneich/" rel="noopener" target="_blank"><span>Brendan Eich</span></a> is an American technologist, software engineer, and keynote speaker. After joining Netscape Communications in 1995, Eich created a language to support the browser. It was designed based on Java’s syntax and standard library, and with object names that corresponded to Java classes.&nbsp;</p>
<p>In 1998, Eich co-founded the Mozilla project, ultimately leading to the creation of the Mozilla Foundation, which later became <a href="https://www.mozilla.org/en-US/foundation/moco/" rel="noopener" target="_blank"><span>Mozilla Corporation</span></a>. After leaving Mozilla, Eich set up another company, <a href="https://brave.com/" rel="noopener" target="_blank"><span>Brave Software</span></a>, developing a privacy-oriented browser combined with a blockchain-based digital advertising platform.</p>
      </div>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601646749682" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>Is JavaScript a programming language?</h3>
<p>Yes! As the name implies — JavaScript is a <em>scripting language</em>. Traditionally, scripting languages are executed one line at a time by an interpreter, so a computer program that directly executes the written instructions. This stands in opposition to <em>compiled languages</em>, such as C++, for instance, which must run through a compiler before they can be translated into binary code.&nbsp;</p>
<p>Currently, it is possible to run JS with a just-in-time compiler, too. It compiles the code on the fly and caches the result to speed up the subsequent runs. Still, JavaScript remains a scripting language.</p>
<p>&nbsp;As a programming language, JavaScript is:</p>
<ul>
<li><strong>High-level</strong> – high-level languages resemble natural languages or mathematical notation, which helps simplify programming, including code updates and extensions.</li>
<li><strong>Dynamic </strong>– as a dynamic language, JS uses dynamically-written code to quickly implement functionality to an application, in a way that enhances programming efficiency.</li>
<li><strong>Prototype-based </strong>– JavaScript’s structure is based on prototypical objects, which can be cloned and reused as templates to build new objects. Prototypes also enable building associations between objects in JS. Copying and modifying objects are more direct than in class-based languages such as Java, which simplifies coding and reduces the programmer’s cognitive load.</li>
<li><strong>Multi-paradigm </strong>– JS supports event-driven, functional, and imperative programming styles, which makes it a multi-paradigm language. This results in its flexibility and enables different approaches to development.&nbsp;</li>
</ul>
<h3>Is JavaScript open source?</h3>
<p>Open source applies to software, and JS is a programming language, so no, JS is not open source. However, it’s an open standard that conforms to <a href="https://www.ecma-international.org/ecma-262/" rel="noopener" target="_blank"><span>ECMAScript</span></a> specification. Anyone can use it to develop their own implementations.&nbsp;</p>
<p>For JS to produce any output, we need <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)" rel="noopener" target="_blank"><span>interpreter engines</span></a>, each of which is subject to its own license agreement. For example, <a href="https://v8.dev/" rel="noopener" target="_blank"><span>Google’s V8</span></a>, <a href="https://github.com/facebook/hermes" rel="noopener" target="_blank"><span>Facebook’s Hermes</span></a>, or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Rhino" rel="noopener" target="_blank"><span>Mozilla’s Rhino</span></a>, they are all open source. By contrast, <a href="https://jerryscript.net/" rel="noopener" target="_blank"><span>Jerryscript</span></a> is licensed under the Apache License.</p>
<h3>The difference between JavaScript library and framework</h3>
<p>While interpreters are essential to generate JS output, frameworks and libraries are optional but highly recommended. These are <strong>prewritten components that your JavaScript team can use to build robust, highly-performant code faster</strong>. They offer significant advantages to your business, too, from reducing code size and complexity to speeding up the deployment of your project.&nbsp;</p>
<p>Sometimes, e.g., in the case of React, it’s hard to categorically determine whether a given resource is a framework or a library. Nevertheless, in theory, the two notions are distinct.</p>
<p><strong><img src="https://www.ideamotive.co/hubfs/The%20difference%20between%20JavaScript%20library%20and%20framework%20(2).png" alt="The difference between JavaScript library and framework (2)"></strong></p>
<h4>Framework</h4>
<p>A <strong>framework </strong>is a software platform that lays the groundwork for programmers to develop applications. You can compare it to a house plan or blueprint that needs to be populated with input before the construction begins.&nbsp;</p>
<p>Same with a software framework; it is pre-equipped with code for predefined classes, workflows, and functions, but needs specific details to be supplied by the programmer before it can run a complete code.&nbsp;</p>
<p>Popular JS frameworks include Angular, Bootstrap, and Vue.js.</p>
<p><strong>Jump to </strong><a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener"><strong><span>this section</span></strong></a><strong> to learn more about JS frameworks.&nbsp;</strong></p>
<h4>Library</h4>
<p>A <strong>library</strong>, like a framework, refers to a reusable piece of code; however, libraries are usually focused on delivering a specific functionality/component, and give developers greater freedom over the code structure than frameworks. Coming back to the house metaphor: libraries can be compared to ready-made pieces of furniture or appliances that we choose to make our home complete.&nbsp;</p>
<p>The main difference between a library and a framework is that a library contains snippets of ready-made code that needs to be still arranged by the developer into a workflow. Frameworks, on the other hand, are in charge of running workflows. Additionally, one framework can utilize multiple libraries.</p>
<p>There are dozens of JS libraries available, with DOJO, jQuery, and React topping popularity charts.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069971226" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
    
      <p>While most JavaScript developers rely on specific frameworks and libraries, some of them also build applications using the so-called “Vanilla JavaScript,” i.e., pure JS code without any additional resources. However, this approach is infrequent.</p>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601647248048" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>How does JavaScript work?</h3>
<p>JavaScript is primarily used in the form of<strong> client-side JavaScript</strong>. This means it is typically running on client devices (laptops, smartphones, PCs, and others) communicated with the network.&nbsp;</p>
<p>In the client-side context, scripts execute directly in the browser, which results in faster processing and immediate response to the user’s requests. Because of the speed and more lightweight script processing on the client side, this model is preferred to implement dynamic, interactive web content and handle user interactions.</p>
<p>An extended version of JS allows it to be run on the server side, with backend access to files, databases, and servers. In this context, JS code is created similarly to C, Java, or any other server-side language.</p>
<p><strong>Server-side JavaScript</strong> can be applied to handle logging in, manage personal information and preferences, and fetch specific files or data as requested by the user. <a href="https://nodejs.org/" rel="noopener" target="_blank"><span>NodeJS</span></a> is commonly used as a runtime environment to execute JavaScript code outside a web browser</p>
<p><strong>See also section <a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener">The most popular JavaScript frameworks</a>.</strong></p>
<p>Currently, JS is the only commonly-recognized client-side language for browsers apart from WebAssembly, which is rather to be seen as a complementary technology. Alternative solutions like Java applets, Silverlight, or ActiveX, have all been discontinued by now.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603785890114" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        What is the difference between Java and JavaScript?
      </h3>
    
    
      <p>We’ve seen it happen too many times... A job posting for JavaScript talent with a “Java Developer” header. A few years ago, the confusion between the two languages was so common it became anecdotal. Today, it seems to be a thing of the past.The two languages could not be further from the same thing. Still, just in case you (or your HR department) need a little recap, here are the core differences between Java and JS:</p>
    
  </div>

</div>

<div id="hs_cos_wrapper_widget_1601896662232" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>What can you build with JavaScript?</h3>
<p>Originally, JavaScript was conceived to add interactivity into static browser pages. While today, it is still mostly used to enrich websites with animated, lively components, its capabilities also cover the creation of:</p>
<ul>
<li>Robust web and server applications</li>
<li>Stunning business presentations</li>
<li>Interactive gaming platforms</li>
<li>Multi-functional mobile apps</li>
<li>Smart device applications&nbsp;</li>
</ul>
<p><strong><br>For more details</strong><a href="https://www.ideamotive.co/javascript-business-guide#what-is-javascript-used-for" rel="noopener"><strong><span> jump to the next chapter</span></strong></a></p>
<h3><span>How is JavaScript different from TypeScript?</span></h3>
<p>If you already have some grasp of JavaScript, you might have stumbled upon <a href="https://www.typescriptlang.org/" rel="noopener" target="_blank"><span>TypeScript</span></a>. A superset of JS, TypeScript is a modern programming language developed and maintained by Microsoft. It was publicly released in 2012 as a tool for the development of large applications in JS (“JavaScript that scales” — states the official slogan). TypeScript simplifies JavaScript code, making it easier to read and debug, and at the same time, it expands on JS capabilities.</p>
<p><strong>See also: </strong><a href="https://www.ideamotive.co/javascript-business-guide#javascript-vs-typescript" rel="noopener"><strong><span>JavaScript vs. TypeScript</span></strong></a></p>
    </div>
  </section>

</div>
<p id="hs_cos_wrapper_widget_1601896842863" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="what-is-javascript-used-for">
    
      <h2>
        
          <span>02</span>
        
        
          <span>What is JavaScript used for?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601896857056" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>In the introduction, we have already covered some of the key JavaScript applications. Here, we will add some more details about each use of the language.</p>
<h3>Adding interactive website components</h3>
<p>JavaScript was made to create and control dynamic website content, and this task remains its primary application. A vast majority of developers use JS to enhance Internet web pages with interactive features such as:</p>
<ul>
<li>dynamic forms</li>
<li>animated graphics</li>
<li>autocomplete suggestions</li>
<li>photo slideshows</li>
</ul>
<p>If we said that everyone uses JS on their website, this wouldn’t be much of an overstatement. JS powers over 90% of all global sites, including those of …</p></div></section></div></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ideamotive.co/javascript-business-guide">https://www.ideamotive.co/javascript-business-guide</a></em></p>]]>
            </description>
            <link>https://www.ideamotive.co/javascript-business-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046293</guid>
            <pubDate>Tue, 10 Nov 2020 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue 3.0 Components Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046142">thread link</a>) | @quatro444
<br/>
November 10, 2020 | https://quatrochan.github.io/Equal/ | <a href="https://web.archive.org/web/*/https://quatrochan.github.io/Equal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quatrochan.github.io/Equal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046142</guid>
            <pubDate>Tue, 10 Nov 2020 14:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU has plans for a European Internet with a firewall [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046096">thread link</a>) | @MaKey
<br/>
November 10, 2020 | https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39 | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>UÉÆ}ªÈžÎ6ž·26ÌkþîçoÙÛ©9·-æ¶ãsíð\;zò–ÏÇ–ÁÊÛ2|î¸ú}òz›Vê´×°ÑÚ.}nÝþÚ‡|ÞÅ_—³H�
endstream
endobj
2614 0 obj
&lt;&gt;stream
H‰´WÛrÜÆ}ß¯˜GLÊXÎ¸\®ŠHI–-Ñ¤¸ªTŠN¥jEo¢%%RŠÊùzŸîž`—+^b™hôôõôéG‹ÙÞ‘úî»½ûÏ”Qßÿè`_ÍööOŒ:»VfîÃ&nbsp;ÔõÙÅloaÿi”U‹·3gç�j
Ä�›•ìÜ©&lt;\¬g�Ò‹Ï¿ -£f[4ÑféVÁw¢ÂûÛT¸QEkç©‡è›/ˆú
Ñ&gt;¦/‹†û‹ÆûÐÝ_kº¿h†ûkµfCÖÝ¦ÖÚÈn&amp;Ìßjƒ€ÞðÙøÙš47�ÉÞ-Ÿîðï1zëÉêüÓÕrü¦æåÃÌº4.ª€ë€«�È©÷Ð5$dL]-gSÜ{Šf&lt;¿žeßwQqç°œ1&amp;%ÊB`¸ófnÐ�§�­g{ÏÖF\ÎŽovTÍü1Ùã4aìzå]�ª&nbsp;&amp;Ï6<z"xaá‚qøßù(ýŒÇ€†3´ôÜ8§Ÿ•Ï�«�ÔØ�…~´÷is¨ Õ,?këæi5ê@üà¿ÚÍ-®ï="" us©="ð¥y/âëå…ö–ä?ê…ÍµÆ?¥ÿ±ø‘b}|O3«�!nÛ™" Ž‹}*v®´¡s.´¥8ª…oÍý„="ùí¹¶�ÞæŸuO&amp;¾Ö�<y‡àˆ:a+§Q²t8">‡£pN›å•¦859«3m=}¼¼.ÈÎ]GŽ…Þe—H¡aObÁT¾ð¨ú’Ërq³ì¤"¹ÿ—ˆÛ5P¦š�OokDóÍgµ5lBQ¹ =AŒàÑ¯ºµ9Á­åT^ñ�§ðÕtþ_m�îœ™÷åü¦ÍAøZº)¸E·úcº)»]©�´#ŽÔÕaŒä/�n;
˜“�¹8«}¢›_t~ÿ�&amp;|A	®9è¸[jGæ4ojá"ô½j&gt;ißÓ§ë¯›ßõZ
|ŠR
èîF|êï“ƒœ‚ˆ|ÕHÆã7;ZÀoÒÖn•›:Zq¨‹»š6:ä,IÙ)àŒûõB&lt;|¸&amp;&lt;|GÔsGJ~}.x5X@NÒOÇújFd€kCW�ð£nÁi è6ô&lt;ãƒT1ÎTýà%ü­ï&amp;	ð[¿©DR½gœ‰E3n®®qçdÌŒïžÎô �Næp§`8#}€èÖ[Ýtu]½&amp;Wõ”«â:ˆQv=ò¤l1ã@ƒnÓ x]L¸ÐüšbÞòtP°Q÷‚¢ŽÁ^7ð˜Y­ù¶—™hþp°0KZ*ÝQoÕ²"îÇ£x®bð¤2ZwTËió–¬qcæ¯èê³ubœÙbû¨M³ƒ*MŠ×ß&amp;í
è6rrÎ0h	.æv®Î),0s%á¨Ê‘£œÔè^q&nbsp;<g_rrÃze8t”¥¿ò“Žjhd4Ø¶q‡Çxõ`»õ1†>ïUBâbÇjiöAéÛ&lt;ÔWx°ù;“à­EQ#…5=Ê‘i}ÿ—›V˜¤ÈôÊ‘i�½°ÆÏí0L¼™@Yö&gt;ºóL¬,ßß‰i¾›`š-ë©ÿ£Õ
¾¨pIXË%aË¶éàd7§ˆ)†£Ì)/µ 
1¶ ì‹â7-ÀŽê�`’!ù÷Ú1ËãŠ¸Ò®bêùå:]èAä¹z«#À§¥ñCPKë¹ég‰r~‘,ªÊïµXÈ&gt;¦˜q˜~¸ú‚
«bCuQ±!‹&amp;ÂšNªX¬ÂÝ±ŽÜßŸt4™Þ²Š–çþå5Z˜Œi4¶9ºùœÈF(Ö	kW?ÜÈJÏÙvîz_\?¼¿�/Ó*êëÚ`«ÈaŠÑn²ƒ1Íf(&gt;�íØïM†º�{Þ	xk%û—Ä¤Ò(òš~SïoÃ uËd RÁºZ°Væ¡/~œ6Oµ•…		ât`U‡“&lt;$ÉP}¥\5™W‹œz¦CÎ°—b:¥¢¨Ë/¶RiåÄ²ÂTB4ø1ï(aü½ÜNƒé-éu-«#¯.§CR!Q¤ZC%(Ád;™ƒ—DÃ9»Uó¾KÓi¼qDJçº}ý4DK¦á”ô2Ø½ÿ0à2Í�q¢Ù†Ÿ`Îùš™)Çf&nbsp;ÝÙüú¾Þ|“Ï}ÎuÔñê¤¸[×ÕË’­á5”:„ôöÅÆnbã¯åsù€sÙF'(“»ï„¹¿žÐ¸ž\_–=,[¿OäH5âNYè^ GLÎF”Q÷®Ïå!‘«6ˆÑY]IØEv­¦²(ºøŸÞô˜ËmëŽ¸B7êX$?p†…›ÜYPyCñOšýþY‹wG™¸?Ñ6æ%‰¡Çª‡æG¸+&lt;Ðç¥´¯aòBEèt#ø(Ìâi`´eQn°’\‘TÙ¤—¯Øy.%g%ôÎL�*ˆYOeUi¢ªÊP&gt;ÆçWÌe|1"M
“�a|"À{Hº¦¡bkàóóçåîp»Íü&lt;ÞŽ¹ÁM0·ôŸ�B~Q	9ƒq�´í¥ƒ‚�ÊCk¬jRÔ]Pê7m)'¶d©åí­/´c&nbsp;ö|ÒoøÅçŒ3|Ð®õiƒÍf^Aw¾£ªfƒ¥z»ÅÀBÜb`ÑÀ“¨�ÌÒ=á.»XH#ãoA'‰$s„K{åmd©­l©îbh ÛQN˜€Ñ$Ð,^=&gt;ÌíøL»Vç3ÍµÄ"~…w;v±ÎŒcXÚÝj:×sk‡�YïÍ˜E7�„çM&gt;ìûÝ”•7Œ”dyh &amp;56ÔÜ©'h¢-‰å	@HùJðþ€VEÕü}Jÿï&lt;;röä !ÉÓ“j�Ž7£mPÐ�²G-¡Ë
'Ž;™`L˜x—½`"Æ.¼$—I€ðƒîh‚1ù&lt;ä;!1ïŸF6Tžsê_„�7SäEŽVÞ,ÁFÐöŽðJØÇ¾ˆ:Ž÷U€Q¤šÃT+dç®×+Ýy¯'ó•PìÆž‰vî‡
LúR1M6™€
í-íZÖ¡:‰|²8çæÃlï)ÐàüzÆ¯ÝÈ‡bfÀ¦"”PŠŒÇ¬Jp›†
¯³õlïÙÚªƒK$l·)q¬k‰§æà9žGë	âMkð²£ÃÓÀÆ°	&gt;ƒì†ÁY…ÅÝš:ð_±ÄM,9žý.ÀïkÎ(
endstream
endobj
2615 0 obj
&lt;&gt;stream
H‰b``œáèâäÊ$ÀÀ�›WRää¥À~ž���™“‹|@ì¼ü¼Tðí#ˆ¾¬2S/`M.(*Ò€Ø(%µ8HâÌò’&nbsp;8c�-’”
fƒÔ‰d‡9Ù@6_IjHŒÁ9¿&nbsp;²(3=£DÁÐÒÒRÁ1%?)U!¸²¸$5·XÁ3/9¿¨ ¿(±$5¨jð»%V*¸'ææ&amp;*é‘èr"(,!¬Ï!à0b;�C€äÒ¢2(“‘É˜� ÀIÆ8/
endstream
endobj
2616 0 obj
&lt;&gt;stream
H‰|U{TgŸa˜Iä1ÃHt&amp;Z�«õ…Š‚¨”‡J"BWM„(!èé¶†­§n·Ý]QD@°¢Ö"A¤�WD@VYuÕ={ê�øáé°í9ûÏþó�ûøîoîýîýÍÅ1{;Çq�€&nbsp;5aÑê¹tq•A?_­�OMŒ3Œ99~*Î»ÛóÓœ´å¾{÷n	Ù“¡vÊ­©Ób¥�ãä™ÒÀTƒ~­&gt;IˆO0*{zzÎ;½”«5ú�ZeÄÁ£v_Š2xÿ.½!Ioˆ3j5”«•ê±€¥Z›¢5˜ÆŒ‘"(UÂ…ýFe€×R¯yK}/˜ÈL©KQÆ)
Úx�€fÐj”FCœF»/Î°W©ßýÿ¾´p]ÄæƒIZ¥�R£Ý�a¸PFÙcN.‹aJæ¯À¶aX,†%à˜ÃÒ0ì†µbX;†=À°A?‚aÛ…§Â6b*ì&gt;¯Ãíh»@»=vGìòìnØu,±†È ^Ù/±Ï!qr&amp;YFÍ¤vRÇ©¢¹¢ÇâùâoÄ¯&amp;LJœ”=é•ƒ›Ã|‡í_;\pä“ï8¹;e9½rÞèœà|Æù�$H’'±JÐd§És'ŸrqtÙèrsŠË”ð)ýÒÒ(i‰tH
´ž¾NÛ\5®íŒ‚If¾eÞË¼e¸©Ý2ÜòÝž»‹ÜW¹«Ü{¸{|&amp;'å;å�)�G«ù—Õ¸pÎ¬&amp;ŽÚó6Õh¹¨�A~ð	#R¢ZÆ”Ñ?‹F©íã2ø!A§øfLBcš½“&nbsp;3¸ð
iÒzpø]?Ýs`s‚7’s©£F’¼„â˜rËù²rca¼Î�ŸP�t‰“€ápínœ¯-¨…ÄZiI;¬lq¬j£ËÍf›Ã,
Xƒd’e·÷)u¶Â4p	k_ÄÙÂüh	^¹4ycøæÄ¦þ®¿¸ùKëÍUï1†§mËÈjTú~I×˜ùõüìq ·q&nbsp;�&gt;ÅÀ�ê�"÷ÞÈæúK I™¹Eg²‘�Ò�&gt;Þ=t%�È¿’íº–p9þrõ�âGù?‹WPŸ-3…$þ~GUh—ºEœ+z[[Yß!Rï�ìUÞË?&gt;SËfˆèJ¿¸ÍÊgu/·®fË­–6êóœ&gt; ¦+Qfã«¾ÓÓñÃµrwéýåWbÅ	{c’Õ
º4Ÿ¿ÇÔY¶íTÇÆ¯×pûËS+ªä5Å7êX‰Í/
¿#6?Æ�üAjxý—îE7®fKÐ·ÈÙV�7uea6x!×,-FQ­Èõ®ÛF¼Þ®°NÁµ ³þ“ý5fY‰'È™i¼4l•Ct¸†ö³ë©ÎÙ·�+Z/GA›‘,`6+)<k‚ôfn7pš fÐ!d="" jo‚t05"iæšðs°ˆèe“˜¢ï¯aœ“în^“¤4©„4óà�Íx="" %j ž="" �£Í"‰¤x="" 8@˜™="" ËùòŠ”Â„còîøñ‰ai¶Õix¼&zv1pjÓ‘ë)tñ½Ž”¨Í­|i+^þòŸpr˜ä="">9¡ýÚ›ówä´föƒ’a×*�&nbsp;iÜë™áÊÈùî˜±hEÔX�õÿèá$ê³&amp;¾¹ÿhšÌƒt˜eƒ6ÖŸ¢ÛÐŒ�Nù#™CIÔG­üß¬8ðO~‡ÌŠ¾ËÕT‘ÂT¹?~	NòÕ¤ôÕk·³EÉs%7Kî(^^ÜÌeÍñ÷F¾hñº ÷H‘�t|Ýš)&lt;
¦G®–2¦‹MF«&lt;û†ÿ=Ò¸"�ËÑo_¹}OÞÞ�\ƒ
k	%ÏU[j}¥Û¢ü|÷„r1Á7)zd°_ã™ÍEf'¬E¤bSø¹&lt;Ãx=Ø�ƒøÉ!Ð
üL·yò³ç‰ÐµÑ%d8Ô¡@ÒA“#‚%�œ_’Wtæ²G.•©ËÒéähßDª—[Á»ÛÁÚX5Qq¨™Ì-(&gt;V¡Y}˜w6çé£Úr&amp;/‰M
"Ó.4¦u(`ú›ç@÷ÇÕo-æ
vEÿ5Z‘òifæ¸s°BØÔXç&nbsp;¡&lt;»ñK�Á"`{Ùf3Ÿ¤fIæ–§¯Ý¹Eºmr•£UÃ}`BC}�hm¤ng"›A�|k}¬åÜ1Kv~–Í-bÆô¾ÍäòŽÿò/ì÷7Kk}µlÝà?Ñâ.+Î;&gt;#n•¬�ŽL*í$‡)(ç‡È†±‚›ø«w¥OC åQÈm_xÆÐC+t1áËåóú}a*¸¼ì²7ú¶ïE6WD÷&lt;¼|þN�¼oC/’"Ê+p&amp;K[#.DtêØgèªéÝÐ’ËýTYÝý
ûÄP§])§­Á[£W²Ù¼àîé½¥Ú±+âç&amp;¦¬YpÖ_©²²uú}ð½7ïá•�áÄñ"�9›U”}ñOí_µ•Tß7ýTõ&gt;�ƒïrÀ�òXŒ04÷—À¤æšÂëål.uÈ/Q½C³;ácÓÖÃû2R3äˆÁKàì³Êeˆø4#ý‹Ï9�qÛ~•â£˜Û}Ïj[º8�ˆSàÀod„çcl,ã*²Œç	†¤Ýã¿ðlôóoöÂ1{ò„]à=+7‚ñàWî~8ÁýT•ø_¼v|!TÏá¿h’B˜ÞSñ+üq‚¯…§Lãèñ0m��$ÈGH‹Ïè”
ýwœó¶ÉŒý‚y™±§ôÝzØÌd�Ëø!ï»ë5Uõ—«[åÝQH´%â“”ÿp]¥QQdWXÄ*ÚÑ)#u›®XA&amp;ŠaÐí£¢B@qDTÐQY»7\XeqCAÑ@°»•Equ„†FdÀnQÜã-òð$�œääï«÷nÝ{ß÷Ýï{Áì7âlaÙ)Ó�Zì-Þ¸i
»ne¬ÇQ¯ôpýò
òýRË&amp;Îïå`r¨Úõ?Ã‰Û0©ÚðÚÝÁ&amp;ð¸	3ïÒ½ñüOp\ˆ%æ¯ñ^N«ßè’Ê¡Ö_u¹IÉY\é¨XµÙkŸ'ƒÌ‘Þ08€/F`ó´&amp;h‡�#�§‹w’¶O™Ó¡€å¢SáA'üÄY ý�Ã�oøÔß¯.º§d3I|À=ùJX3Ø«ƒïÀM„)ÈE Sä‚6£5À¡É0ÿÑ�“EuU�9/mu'c…üº“w©°
I	¬ìqXMH‹õñ©)‘×,l‚µýòtùÉò¬2A:™˜�ãÛ„¼DÔÎ„fÈn‚ÈG†ZˆÖ-&nbsp;?v¤“Šª“î30¾#ÿZ
§¸\PY/~·è¶ë�+¾õâµ»�âÛ²2éEVá¿:Ç–q÷H8ÄiW
3²2ÊÝýPÇk6ÌãÉåÚHúã«®&nbsp;yóC¬B#Ò2â8*+¾�¯Öl—ªèþb¿0Nº&amp;Þ‹AóçüÀ’�ïÁúNÍ¾]—9úÊ¹V‚n9å•gÏ&nbsp; ÜS´…ƒ)ú&lt;{æž)á¨×	jþZ‹^‡–ŸÔ¯�SO¬¼•üÓ†

\Ã/Š0^zÒ'ulÝJë"4•Yê–pÐ‹Óº
�(2«p{1Ù¤rhÅlSä¼--3š¥$‡5�ÔÁXŸ—ð"!Ê�`(ÖŒŽûlÇOÁ’I�CRóñMÔ·AÔ—}FZ¨‡ãmè8DA‘ý‹¤:µÁN5Ó„ŽUËOî£‡øgðIˆ"–Àt´‘Ü/&lt;ˆ1d5ó=ü’O`~sÕÞ]*Ž~:VùPö÷\	ƒdˆEfhc*g¢²ª_Íº5õ†`ú;²K9ªgÐÒJ9Îºtú#vÂÏvZh�.Ô¢±³AJÔJÌ®Þs²;ù—D¿î±Ã«&gt;ø2@®!Z}�8,¬¥’áG�Å²{Î—*a@&nbsp;«Ž_kk@íüo\nù°"P/ñ‰Îð"H†R�#1b�ÆEÇFÆ†'Ã[’²ÀŠúæ÷Sü$
*çßàUØ›	Íd|¯Ö°~d16baÔGúcü"}«{A_Ùnéç"H&amp;ãÔQí;±&amp;@—¥Ã|0¾%ó&nbsp;âèû#@¤÷§“g.Ù–Ì`U×CíD‰ÇH·bào}]XìRí�"âÈ\¥;¤¥Œø	“§£^õÐ&gt;`måt(LHyšØÇf¤)œ«Ö,2†ôŠÀ=\€”$�k’¾à¸›’º­%°u]—1
…AbÎg;\Æ¤øVþf«žê%ÿã€&gt;|q¢exVÿ	… ?˜ŠXX
‹`L�ÝàƒÍÊäÆ%-Â,5Þ"Fs%ˆÆ&lt;]B˜	æm`39*ßk®ŠÆ&nbsp;
	_»]@&amp;æ_H½Èô=.¬­æÊ¼ëÄ÷£k·”°ª·üï™%?%òç´nÂÌœ¢Œ«Ìë?kKWo“‘éGb¸ÿKsdV¸Ð3ËùÌ²\A¦L(íÆ2à$†
8?äŠV âP(ÚŽaú
Ø&amp;°§³³¹'aÏÃú#¨l„è�Ž8cÓ4f§¶a¹4cÀT�1ÈR‚%’å¨m¸†ª&amp;8öèj¨ê!»’UÒ|Ë³ö9ž'å‚äž‹»£w©C¯¯ÍÃF»õÂ�{ÏÅ·bªƒ‹Ù«þ¹–Œ‡[â_Në.ÌÌ.Î¬`R‚lÅWz[²Ö$µ0^Ã_oÁ¯lNwb“©j•72`ÓÙ?üvU"+9KÕæ¿7ˆ«•uªäûÎ³tÕL¯ÎÜíëÎ,eÐ4[‰ÉœfOÈõKU[ÝÄ.k}¬=&lt;ó/²”3öCØùaßég¤ã‡`sûh’ø“T'nç?åz�uÐ®ÓŒ)5:Ã
;³A¯X~ºÍ¨©²p]nfµì!ü™åM
¨}‡_,£�a&amp;ÿ3#HÀˆ·$‰ž�Þf§]ŒD�BÆvEôìè7�&gt;Ñ\Â0Ú)(:üÞAÆ7ÿ†‘›3ò�ö†b£×0LÐÒBmNÓ©Gx²ŸpÉ^~îû&gt;4,Â^g5ŽkMZ£—}Zf³h�»¿5¶;¦{¼ý…´B/£leñËŒSÈ}�±½ò^Í#á‡±ß¥}ez!Ÿ§Ï_3B[à-øÃSÂŒœ‡¬#üâBcŒ“ÉXUŒ"¢Ò¬E³IX�žaæïÈ§`®¼wVu¶Óò\àù-JÏgÈBDíød¸›�Œ&nbsp;Ìdü4Âœü¹‡{GùÆøâDd5òòð›sÀ]dNBð¨ˆ@¥Tž…½b&gt;^¿Øˆ�×Œ~›Aò¾‚¸=ºÁ^%Œ~3ZIPKÐTüîå“õMXÇ'ß0&nbsp;FœåzJ°ÐÇ¾b“ðdÛ¥ásõ«DaýÐ¸({eß"ƒÃ€j4TêÀ¿�®å­à†phë{dî¾*.&lt;€Í_EœWÔdW1oOþÀí7@i¦®h¢xÉ�¥oZn)®^ÂŒÞ}Ì�è&amp;.§”Wˆíj„tí�”ýÉØÍ{Ü˜MA—î‚^îëŽJ�WÉx‰¶É
5ZPéèZ
LÒ»ýRÖ§„°$]›ÙMd�®ª;ajÆ�Þ3pâÀ,ÍîšÌHVK×„r)p×–ÔŽ:	³3N¥gý›ô²
jêJã81Þ°;™™ëfrÛ{«TÀŠÚŠ¬® EÛ*(E!lPAÅ"J…AÖ"	�(²ˆò‘ßÄ‚@©+¢"`_ÚuÇ©ÏMûrBëv¿ï—{fÎÌùŸsžç&gt;ÿó{˜Ó•¦úIÇê÷ÿs¯å›ƒš{SXíqmA�Dˆ„øµâÕcðv§4#Sƒé%
ÂÜ=÷€áœF]Âž¼Ièãe†í4Z±ÃåbäüÔ	¿í4êO±Â¯4Ã»åœç&nbsp;õÀõ¡˜s²H)Ô¬4$×¬£Ñ&lt;'gä–Ã"§œÁîÎµ¦KŒ‡$oq‡Ì:—Ýn–p÷®3y”*[�¥fDí&gt;ŠÀÝ[i—�»?¾º4ö¨ÿ‚,ÀÀæjr”‰pƒf&lt;úÀ¡�W?ø\È©œ|]¡Iòpf&nbsp;h� GäøÐß¾h,¬b”}„*r�Æ—vý°ÞÐ²9}Tï±†{éŸÊVdã¶²
×°Û¬æÝÃ�ÜÚùœØ
 »Ó‚ïOôß*7e|e`ô7‰c)±Ç¢é°©Q‘lØnå–�’„�Þ7gÜp×ŠöÂÂ°jfƒP&gt;‰_ñxI‰î^Ó5èjORô<s=¡%å²l*üw–¡Õh2±þp««¶µ‚Õ’hèó—ü‚m'£¬Ís\Ã u7Ý{³°¥�mk.½="" |Éjx‹rjs2”l@²ô‹@Ÿ;oanÏðø="" ó® b6o�“ª”•ø.kfp6x#s ™â�ÌŸ‚vÒ˜c8ªg.·6^¥ïwú¬eqÕ~ÑÀÝ¡qsdô!e«llt´ÕÂewrˆb•ä¤�Ïþ:ðo‰¦Ám="">—ì:“Œ»ÑË***!&gt;zi|UMiÙ™l¶J^ÉÑŠ´�³«F~]�"¨¶Å

¬¹¥¨÷‰„Ûâ:³D€lïŽ�eä	û4áY¶¢°ÞÒMEbÅ˜’ƒçjJÊ+g£¡ãì) ßçe%þ«VþS:	›ÈÖÀJâ‰»Özðƒb‰"wUJŠ\�‚=Bˆ&amp;±“H­A°FÀ"Å—#–sÿ§hdöO@ô„èîÈü	�"]ÑQÓRØØr™¨ðd‘yºÅ¹ÅyzÆ\ÔP×AW,cQÅÔÀÃ¥y³,J�Ã$)“åÊXlšWåÁ�&gt;´{èNY,›…k4s”ð$sÃsÂ‚_gÄº­5!¢ÛÖŒ´X÷Ì+`Ú‹Z›ºqF6áŒœ�‚f¬qhôv•Å3ZRÔš1F¬}­#×ôsóúq©BÛ|¨âÒ($Yà‚þ„–¾X;xs6‚óÒˆeµ&gt;ÔË&amp;‡?#ž¯Ç*·OÇ~~Üúì%6ô‰ü9þ�æµ»&lt;ARjŠudHå•7h ž€õàäú²óðß·5‚ÅÇ¸›yŸð u2]ðÉ¤ŒÒçrÑó~ãs=Ýi5–À—ùnkîU°Ú­Þ ¦Ïn5ÄÍÒ¼ö…çœÞkŠ;�;ršuMÌj\YÖ²h‹®ó¢!;wäƒœ/bôRý…Ó¬ŽáÜÔ¬”L5ói’tŸ?ýžlüð.ß~Ôß&amp;œ5•»X&amp;ñû÷5Iµ^KÔ;‚1¢G¸P§gúõ-m×i}~¶6ŸîD½º´ôœCôÖma›ÙLRT™õÔš«Ð©?VZÿk�/Žƒä¿á•TÝ®ºHƒ&nbsp;¿÷Áw;›W�e}ËbL�’ÚÊ3]­5
õ	¦ôQ»³PJ;øn^ûYSÈd4ûm|yÂ.Iøþ¨Í;d&amp;c®Œ4ÍÀoz‚?Í
Q+¼¼o!£À?gy_rNÕDWW|}ÌÈfö™©*m&lt;-M©îa¡ì�=Ø
„Éš‘0k)ØM�rJÔÊä’)WÔA*²©ÌnEXØVÚýÀõÇ,”¸¢Zò|´ëo��
§¬N›|Ôƒ%³ê³[:$ÂG¦¼g¥\¨(Ö€uÀw&amp;™'ÁŸK&amp;–“KQ9†ÅU¸&amp;Sõ¡ÆÔFE‹”‹…°æÈ8\{‚ÙÂd	Õ™¬KñÒ1rRpfì*êÐwcÆÐû†¿G
ñ	ïcÕ•ä”©ðO
J“b"Ð´«:¿ìö‚ñ:Òe+¶)¶k¬ó‡;R;T—6C¶XøæÂ#Ip&lt;‰÷
çÇ/¶î´B^èñ·¬<s¥±¼ø fclqì‰Ãˆ'þ;‰<!·‡©„¹ñ]eœâ "«**”å_vlx):#{¹å�$^="">ÂÏ·Jnœñ'ò4ºôIFVzæa&amp;)tÿñÉq‰1ªÄôÒuâÒ<s‘¹¾§Ëü Ö€~ #— :õ¾c{Ç`�i«t×kÎ.€±-<2Ï†y&îm¾i="">÷öªÕ‘¥å'ËNV@4T‹s.3ÄÇP¤%ã’äqèªÇ«ÆQî/JÞÄÂr˜ú—rà¥@xÂJúíÛ¯qoöˆê°9ÚÀ^ªGWZ^K×ÖÉÚpÏ5X«n¤¯w7ÀÜÖ�ü&lt;;%&amp;‚Þ»×TÄŠ^œõŽ2ì¢79å±Â{.Òy×þm³AcÃï´xSÅ(�¸D!�¢h+üTCçkø9ý²Ô
?~ƒH;þûd¬l²IÄDô	$ô`ÌòåŸ�:Ê�óíX…&lt;­Büi‹'¥ù8ÖAþÙ•¯ÅçÍ`sê¾m÷!&lt;ç�ø¿sÂWgšî™¡Ú&lt;ÙÄ«í˜ìâætðaÚò…<qÃÃà¯à<a-Ž<ƒ»#o„gäÁf‡q¸sšƒæaqaÖqf‹wsÐ°…Åp�90 iésc‹¶ÓŽ|„hÇw°m>ÿÍ©V]O(öhÂéåÒ¾Ñ±ó=OÚêéöw¶¸¿á\µøàBs ú°�Ñ;ñÿÒÆwù�®}Úx¿ïýÃw¹„_
ûîòãœèŠù‹—­([˜Ÿ_R’_°&nbsp;x…üw?1¸X)Pl&gt;PLøåÇßo(u¤6ûR¡´}ªôé¶£¯X{ÙŽê°žgÓz¹Xh“ZÑÀÊ«¯�%V	È‹�…w
oûîG´w~g0%¾„«D.á‚.Üs|ïw¯‹BçY&gt;þñ£ø¥h]Ily˜´ð—ÐÈy›ÒäV–ok&gt;Êñ}ý6á¿·±Mêž0QjfÏ¬žrß·ìý½šmê�ù;V®àX¿vû¼ƒÒ;¶ÖÖ.‘Ÿ–uV~ìœiK¯Ü°ùä¤ÜÀzWÏÈcl]µ]5ÕmÝmmRAQ'Ù¦8/	Ü˜È¸÷rÎé³û,X%Ï×0í§ÙôßqÓ¾ëOÛ3íOÉ$¶^ûLü“?mÇÄÙå$¸6ÍüÏÃyŽë1÷ã~ÞïÉ"À&nbsp;0Eo©á
endstream
endobj
2617 0 obj
&lt;&gt;stream
H‰œ–yTSwÇoÉž�•°Ãc
[€°�5la‘QIBHØADED„ª•2ÖmtFOE�.®c­Ö}êÒõ0êè8´×Ž�8G�Ng¦Óïï÷9÷wïïÝß½÷�ó&nbsp;'¥ªµÕ0�Ö&nbsp;ÏJŒÅb¤	
 2y­.-;!à’ÆK°ZÜ	ü‹ž^�i½"LÊÀ0ðÿ‰-×é
@8(”µrœ;q®ª7èLöœy¥•&amp;†Qëñq¶4±jž½ç|æ9ÚÄ
�V�³)g�B£0ñiœW×•8#©8wÕ©•õ8_ÅÙ¥Ê¨QãüÜ«QÊj@é&amp;»A)/ÇÙgº&gt;'K‚óÈtÕ;\ú”
Ó¥$ÕºF½ZUnÀÜå˜(4TŒ%)ë«”ƒ0C&amp;¯”é˜¤Z£“i˜¿óœ8¦Úbx‘ƒE¡ÁÁBÑ;…ú¯›¿P¦ÞÎÓ“Ì¹žAüom?çW=
€x¯Íú·¶Ò-Œ¯Àòæ[›Ëû0ñ¾¾øÎ}ø¦y)7ta¾¾õõõ&gt;j¥ÜÇTÐ7úŸ¿@ï¼ÏÇtÜ›ò`qÊ2™±Ê€™ê&amp;¯®ª6ê±Z�L®Ä„?â_øóyxg)Ë”z¥�ÈÃ§L­UáíÖ*ÔuµSkÿSeØO4?×¸¸c¯¯Ø°.òò·åÒR´
ß�Þô-•’2ð5ßáÞüÜÏ	ú÷Sá&gt;Ó£V­š‹“då`r£¾n~ÏôY&nbsp;&amp;à+`œ�;ÂA4ˆÉ ä€°ÈA9Ð=¨-&nbsp;t�°lÃ`;»Á~pŒƒ�Á	ðGp|	®�[`Lƒ‡`&lt;¯ "AˆYA�+äùCb(Š‡R¡,¨*�T�2B-Ð
¨ê‡†¡Ðnè÷ÐQètº}MA&nbsp;ï&nbsp;—0Óal»Á¾°Ž�Sàx	¬‚kà&amp;¸^Á£ð&gt;ø0|&gt;_ƒ'á‡ð,ÂG!"F$H:Rˆ”!z¤éF‘Qd?r9‹\A&amp;‘GÈ”ˆrQ¢áhš‹ÊÑ´íE‡Ñ]èaô4z�BgÐ×Á–àE#H	‹*B=¡‹0HØIøˆp†p�0MxJ$ùD1„˜D, V›‰½Ä­ÄÄãÄKÄ»ÄY‰dEò"E�ÒI2’�ÔEÚBÚGúŒt™4MzN¦‘Èþär!YKî ’÷�?%_&amp;ß#¿¢°(®”0J:EAi¤ôQÆ(Ç()Ó”WT6U@�&nbsp;æP+¨íÔ!ê~êêmê�æD¥eÒÔ´å´!ÚïhŸÓ¦h/èº']B/¢éëèÒ�Ó¿¢?a0nŒhF!ÃÀXÇØÍ8ÅøšñÜŒkæc&amp;5S˜µ™�˜6»lö˜Iaº2c˜K™MÌAæ!æEæ#…åÆ’°d¬VÖë(ëk–Íe‹Øél
»—½‡}Ž}ŸCâ¸qâ9
N'çÎ)Î].ÂuæJ¸rî
î÷wšGä	xR^¯‡÷[ÞoÆœchžgÞ`&gt;bþ‰ù$á»ñ¥ü*~ÿ ÿ:ÿ¥…�EŒ…Òb�Å~‹ËÏ,m,£-•–Ý–,¯Y¾´Â¬â­*­6X�[Ý±F­=­3­ë­·YŸ±~dÃ³	…</qããà¯à<a-ž<ƒ»#o„gäáf‡q¸sšƒæaqaöqf‹wsð°…åp�90 iésc‹¶óž|„hçw°m></s‘¹¾§ëü ö€~></s¥±¼ø></s=¡%å²l*üw–¡õh2±þp««¶µ‚õ’hèó—ü‚m'£¬ís\ã></k‚ôfn7pš></g_rrãze8t”¥¿ò“žjhd4ø¶q‡çxõ`»õ1†></z"xaá‚qøßù(ýœç€†3´ôü8§ÿ•ï�«�ôø�…~´÷is¨></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</a></em></p>]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046096</guid>
            <pubDate>Tue, 10 Nov 2020 14:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitdefender: UPX Unpacking Featuring Ten Memory Corruptions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046084">thread link</a>) | @landave
<br/>
November 10, 2020 | https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/ | <a href="https://web.archive.org/web/*/https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>This post breaks the two-year silence of this blog, showcasing a selection of memory corruption vulnerabilities in Bitdefender’s anti-virus engine.</p>
<h2 id="introduction">Introduction</h2>
<p>The goal of binary packing is to compress or obfuscate a binary, usually to save space/bandwidth or to evade malware analysis.
A packed binary typically contains a compressed/obfuscated data payload. When the binary is executed, a loader decompresses this payload and then jumps to the actual entry point of the (inner) binary.
Most anti-virus engines support binary unpacking at least for packers (such as <a href="https://upx.github.io/">UPX</a>) that are very popular and that are also used by non-malware software.</p>
<p>This blog post is about UPX unpacking of PE binaries in the Bitdefender core engine. The main steps in UPX unpacking of PE binary files are the following:</p>
<ol>
<li>Detect the loader from the entry point</li>
<li>Find the compressed data payload and extract it</li>
<li>Unfilter the extracted code</li>
<li>Rebuild various structures (such as the import table, the relocation table, the export table, and the resources)</li>
</ol>
<p>The following vulnerabilities are presented in the control-flow order of the UPX unpacker.</p>
<p><strong>Disclaimer</strong>: In the following, decompiled code from Bitdefender’s core engine is presented.
The naming of variables, fields, and macros is heavily inspired by the <a href="https://github.com/upx/">original UPX</a>. For some snippets, a reference to the original function is added for comparison. It is likely that some types are incorrect.</p>

<p>After the UPX loader has been detected, the Bitdefender engine tries to detect whether the loader applies a specific kind of deobfuscation to the compressed data payload before extracting it. The (de)obfuscation is very simple, making only use of the three operations ADD, XOR, and ROTATE_LEFT.
If this deobfuscation is detected, then the engine iterates through the corresponding instructions of the loader and parses them with their operands in order to be able to deobfuscate the data as well. This looks as follows:</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> operation[<span>16</span>]; <span>// on the stack
</span><span></span><span>int32_t</span> operand[<span>16</span>]; <span>// on the stack
</span><span></span><span>int</span> i <span>=</span> <span>0</span>;
<span>int</span> pos <span>=</span> <span>0</span>;
<span>do</span> {
  <span>bool</span> op_XOR_or_ADD <span>=</span> <span>false</span>;
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0x81u</span>
    <span>&amp;&amp;</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>  <span>||</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x4</span>)) {
      operation[i] <span>=</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>) <span>?</span> <span>OP_XOR</span> : OP_ADD;
      operand[i] <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>loaderdata[pos <span>+</span> <span>3</span>];
<span>      <span>++</span>i;
</span>      pos <span>+=</span> <span>7</span>;
      op_XOR_or_ADD <span>=</span> <span>true</span>;
    }
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xC1u</span> <span>&amp;&amp;</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>4</span>) {
    operation[i] <span>=</span> OP_ROTATE_LEFT;
    operand[i] <span>=</span> loaderdata[pos <span>+</span> <span>3</span>];
<span>    <span>++</span>i;
</span>    pos <span>+=</span> <span>4</span>;
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (op_XOR_or_ADD) {
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) { <span>/* omitted: apply collected operations */</span> }
  pos <span>+=</span> <span>2</span>;
} <span>while</span> (pos <span>+</span> SOME_SLACK <span>&lt;</span> loaderdata_end);
</code></pre></div><p>Observe how the bound-check on the index variable <code>i</code> is performed. As the buffer <code>loaderdata</code> is fully attacker-controlled, it is easy to verify that we can increase the index variable <code>i</code> by two before running into one of the checks <code>i == 16</code>. In particular, we can increase <code>i</code> from 15 to 17, after which we can overwrite the stack with completely arbitrary data.</p>
<div><pre><code data-lang="python">(<span>10</span>ec<span>.</span><span>12</span>dc): Break instruction exception <span>-</span> code <span>80000003</span> (first chance)
<span>00000000</span><span>`</span><span>0601</span>fe42 cc              <span>int</span>     <span>3</span>
</code></pre></div><p>The debug break is due to the stack canary which we have overwritten. If we continue, we see that the return fails because the stack is corrupted.</p>
<div><pre><code data-lang="python"><span>0</span>:<span>000</span><span>&gt;</span> g
(<span>10</span>ec<span>.</span><span>12</span>dc): Access violation <span>-</span> code c0000005 (first chance)
First chance exceptions are reported before <span>any</span> exception handling<span>.</span>
This exception may be expected <span>and</span> handled<span>.</span>
<span>00000000</span><span>`</span><span>06006603</span> c3              ret

<span>0</span>:<span>000</span><span>&gt;</span> dd rsp
<span>00000000</span><span>`</span><span>0014</span>ed98  deadbeef deadbeef deadbeef deadbeef
<span>00000000</span><span>`</span><span>0014</span>eda8  deadbeef deadbeef deadbeef deadbeef
</code></pre></div>
<p>The collected operations (for the deobfuscation shown in //1//) are applied to the payload buffer at an attacker-controlled offset <code>write_offset</code>.
Obviously, this offsets needs to be checked before writing to it. There are two checks on <code>write_offset</code>. The first is</p>
<div><pre><code data-lang="cpp"><span>if</span> (write_offset <span>&lt;=</span> extractobj<span>-&gt;</span>dword10 <span>+</span> <span>3</span>) 
</code></pre></div><p>and the second one is</p>
<div><pre><code data-lang="cpp"><span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) {
  <span>if</span> (write_offset <span>&gt;=</span> extractobj<span>-&gt;</span>dword10 <span>-</span> <span>3</span>)
</code></pre></div><p>Both checks test against the field <code>dword10</code>. Interestingly, the field <code>dword10</code> is never initialized and sitting on the calling function’s stack frame. This makes the bound check useless and allows a fully attacker-controlled heap buffer overflow.</p>

<p>After the extraction, the engine attempts to deobfuscate the extracted data with a static XOR key.</p>
<div><pre><code data-lang="cpp"><span>for</span>(<span>int</span> i<span>=</span><span>0</span>; i<span>&lt;</span><span>0x300</span>; i<span>++</span>) {
  <span>if</span> (<span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[i] <span>==</span> <span>0x4243484B</span>) {
    <span>int32_t</span> j <span>=</span> i <span>+</span> <span>0x4A</span>;
    <span>uint8_t</span> xor_key <span>=</span> entrypoint_data[j]; <span>// attacker-controlled
</span><span></span>    <span>int32_t</span> xor_len <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[j <span>-</span> <span>7</span>]; <span>// attacker-controlled
</span><span></span>    <span>if</span> (xor_len <span>&gt;</span> packer<span>-&gt;</span>set_to_size_of_rawdata) <span>return</span> j; <span>// &lt;-- wrong bound check
</span><span></span>    <span>for</span>(<span>int32_t</span> k<span>=</span><span>0</span>; k<span>&lt;</span>xor_len; k<span>++</span>) {
<span>      packer<span>-&gt;</span>extracted_data[k] <span>^=</span> xor_key; <span>// &lt;-- oob write
</span></span><span></span>    }
    <span>*</span>info_string <span>=</span> <span>"encrypted"</span>;
  }
}
</code></pre></div><p>The bound check is completely wrong. It should check against the size of the extracted data buffer. Instead, it checks against a value that is previously set to the raw data size of the section we extracted the data from. Those two sizes have nothing to do with each other. In particular, one can be much smaller than the other, or vice-versa.</p>
<p>As the function does not return after the first deobfuscation run, the memory corruption can be triggered up to 0x300 times in a row.
This allows us to bypass the limitation that in a single deobfuscation run we always XOR with the same byte. We would simply XOR as follows:</p>
<div><pre><code data-lang="cpp">First run (i<span>=</span><span>0</span>)<span>:</span>  XOR with B0 B0 B0 B0 B0 B0 B0
Second run (i<span>=</span><span>1</span>)<span>:</span> XOR with B1 B1 B1 B1 B1
Third run (i<span>=</span><span>2</span>)<span>:</span>  XOR with B2 B2
</code></pre></div><p>Overall, we then have XORed with C0 C0 C1 C1 C1 C2 C2 for completely arbitrary C0, C1, and C2. We can essentially XOR with such a pattern of almost arbitrary length, and switch the byte at most 0x300 times.</p>
<p>Needless to say, this vulnerability is a useful exploitation primitive as it enables very powerful memory corruptions: XORing allows us to modify selectively only certain parts of data, leaving other parts (for example heap metadata or critical objects) untouched.</p>
<h2 id="4-heap-buffer-overflow-in-the-filters">//4//: Heap Buffer Overflow in the Filters</h2>
<p>A filter is a simple transformation on binary code (say, x86-64 code) that is applied before compression, with the goal to make the code more compressible. After we have decompressed the data, we need to revert this filtering.
Bitdefender supports about 15 different filters. Here is one of them (filter 0x11):</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> bytes_to_filter <span>=</span> <span>/* omitted. is guaranteed not to be oob. */</span>; 
<span>int</span> i <span>=</span> <span>0</span>;
<span>while</span> (<span>1</span>) {
  <span>do</span> {
    <span>if</span> (<span>--</span>bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  } <span>while</span> (extracted_data[i<span>++</span>] <span>!=</span> <span>0xE8u</span>);
  <span>if</span> (bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>extracted_data[i] <span>-=</span> i; <span>// &lt;-- oob write
</span><span></span>  i <span>+=</span> <span>4</span>;
}
</code></pre></div><p>The problem is that <code>bytes_to_filter</code> is only updated when <code>i</code> is incremented by one, but not when it is later incremented by four.</p>
<p>Of the 15 filters, about 8 seem to be affected by such a heap buffer overflow. I treated them all together as one bug (after all, it is not unlikely that they share code).</p>
<h2 id="5-heap-buffer-overflow-when-rebuilding-imports">//5//: Heap Buffer Overflow when Rebuilding Imports</h2>
<p>The following memory corruption occurs in a loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>). It looks like this:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>if</span> (ptr_diff(<span>this</span><span>-&gt;</span>importednames,<span>this</span><span>-&gt;</span>importednames_start) <span>&amp;</span> <span>1</span>) <span>--</span><span>this</span><span>-&gt;</span>importednames;
<span>      memcpy(<span>this</span><span>-&gt;</span>importednames <span>+</span> <span>2</span>, p, ilen); <span>// &lt;-- memory corruption
</span></span><span></span>      <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ptr_diff(<span>this</span><span>-&gt;</span>importednames,extract_obj<span>-&gt;</span>extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin);
      <span>this</span><span>-&gt;</span>importednames <span>+=</span> ilen <span>+</span> <span>2</span>;
      p <span>+=</span> ilen;
    }
    <span>else</span> {
      <span>//omitted, see below //5//
</span><span></span>    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The length <code>ilen</code> that is passed to memcpy is completely attacker-controlled and thus needs to be checked. Observe that the <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2847">original UPX</a> does a checked omemcpy at this place.</p>
<h2 id="6-another-heap-buffer-overflow-when-rebuilding-imports">//6//: Another Heap Buffer Overflow when Rebuilding Imports</h2>
<p>In the same loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>), there is another memory corruption:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>//omitted, see above //5//
</span><span></span>    }
    <span>else</span> {
      extracted_data <span>=</span> extract_obj<span>-&gt;</span>extracted_data;
      dst_ptr <span>=</span> (extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin) <span>+</span> (<span>*</span><span>this</span><span>-&gt;</span>newiat <span>+</span> <span>2</span>);
      <span>if</span> (dst_ptr <span>&lt;</span> extracted_data) <span>return</span> <span>0</span>;
      extracted_data_end <span>=</span> <span>&amp;</span>extracted_data[extract_obj<span>-&gt;</span>extractbuffer_bytes_written];
      <span>if</span> (dst_ptr <span>&gt;</span> extracted_data_end <span>||</span> <span>&amp;</span>dst_ptr[ilen <span>+</span> <span>1</span>] <span>&gt;</span> extracted_data_end) <span>return</span> <span>0</span>;
<span>      strcpy(dst_ptr,p); <span>// &lt;-- memory corruption
</span></span><span></span>      p <span>+=</span> ilen;
    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The problem is that the strings <code>dst_ptr</code> and <code>p</code> can overlap, so we overwrite the string that we called strlen() on earlier.
This can turn a terminating null-byte into a non-null byte and when strcpy() is called, the string is longer than expected, overflowing the buffer.</p>
<p>A possible fix is to replace the <code>strcpy(dst_ptr,p)</code> with <code>memmove(dst_ptr,p,ilen)</code>.</p>
<p>It looks like <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">original UPX</a> is affected as well. The two commits <a href="https://github.com/upx/upx/commit/14992260c60b8d6677a677a9cdfae98b11353df7">14992260</a> and <a href="https://github.com/upx/upx/commit/1faaba8f4ce56eb5df8ce24bb4f04d665b87b4fa">1faaba8f</a> are an attempt to fix the problem in the devel branch of UPX.</p>
<h2 id="7-heap-buffer-overflow-when-unoptimizing-the-relocation-table">//7//: Heap Buffer Overflow when Unoptimizing the Relocation Table</h2>
<p>Another memory corruption is in the function Packer::unoptimizeReloc (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/packer.cpp#L990">Packer::unoptimizeReloc</a>):</p>
<div><pre><code data-lang="cpp"><span>for</span> (<span>uint8_t</span> <span>*</span> p <span>=</span> <span>*</span>in; <span>*</span>p; p<span>++</span>, relocn<span>++</span>) {
  <span>if</span> (<span>*</span>p <span>&gt;=</span> <span>0xF0u</span>) {
    <span>if</span> (<span>*</span>p <span>==</span> <span>0xF0u</span> <span>&amp;&amp;</span> <span>!*</span>(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</a></em></p>]]>
            </description>
            <link>https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046084</guid>
            <pubDate>Tue, 10 Nov 2020 14:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hands on with: MeiliSearch – A next generation search engine for modern web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045927">thread link</a>) | @piterrro
<br/>
November 10, 2020 | https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web | <a href="https://web.archive.org/web/*/https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <div>
                            <p><strong>In this post, I’m gonna review the Meilisearch repository which describes itself as a “Lightning Fast, Ultra Relevant and Typo-Tolerant Search Engine”. There were couple of things that caught my eye with this project...</strong></p>

<h3>Quick intro: What is the “Hands on with X” series?</h3>
<p>This is a series of blog posts in which we focus on open source technologies encountered in the course of our research for new development projects or while browsing latest news from a development environment which is close to our minds in our day to day work. One day I realized that my Github account is full of starred repositories containing interesting tools, databases, libraries and other cutting-edge technologies that seem to be very interesting for me. I was alway staring at them on Github for later review but never got a chance to really use them. That’s when the idea for this blog post series was born. I was having a feeling that a lot of users are in the same situation, they starred a repository because they might have used it in the future and was curious how it works, but never got a chance to do that. So for the next couple of posts I’m gonna focus on reviewing and using interesting and popular repositories I’ve found on Github for the past couple of years.
</p>



<h3 id="h">Table of contents</h3>
<ul>
    <li><a href="#h2"> - Motivations for reviewing Meilisearch</a></li>
    <li><a href="#h3"> - Github repository and Readme</a></li>
    <li><a href="#h4"> - The data set for testing purposes</a></li>
    <li><a href="#h5"> - Kicking it off - Download binary and start the server</a></li>
    <li><a href="#h6"> - Prepare the data to be ingested</a></li>
    <li><a href="#h7"> - Indexing first collection</a></li>
    <li><a href="#h8"> - Indexing speed</a></li>
    <li><a href="#h9"> - Making search queries</a></li>
    <li><a href="#h10"> - Frontend integration</a></li>
    <li><a href="#h11"> - Would I recommend MeiliSearch?</a></li>
    <li><a href="#h12"> - Conclusions</a></li>
</ul>
<hr>

<h3 id="h2">Motivations for reviewing Meilisearch</h3>
<p><strong>Its search engine</strong>. I’m not a heavy user of search engines in my day-to-day projects. I know Elasticsearch and Spinx are among the most popular ones. I also have some experience with TSvector in Postgresql which allowed to create simple “search engine features” within Postgresql database. But that's it, so I’m curious how that new Meilisearch project accommodates itself in this long-inhabited environment.</p>

<p><strong>Its written in Rust</strong> which is interesting so that Rust is very close to bare metal. It’s also a new technology and most of the search engines we have are written in C++ or Java. I feel that a new perspective from a totally new language might be worth a try.</p>

<p>Since it’s Rust, it compiles to a single binary and it's portable, so that means no more long hours of building a project which would make deploying along with any other project a breeze.</p>

<p><strong>It claims to have “search as-you-type experience”</strong> which means that it is able to return results so fast that it returns results for EVERY keystroke. Interesting given the fact that the Readme file doesn’t contain information about reference dataset authors used to support that claim. Of course it is not possible for a dataset of any size and for smaller data sets it's trivial, so I wanted to learn how long Meilisearch is able to support that claim, given that I’ll be using a bigger than usual dataset.
</p>

<h3 id="h3">Github repository and Readme</h3>
<p>The url address of Github repository is <a href="https://github.com/meilisearch/MeiliSearch">https://github.com/meilisearch/MeiliSearch</a>. As of the beggining of the September 2020, the repository has over 9k stars and over 30 contributors. The commits are pushed more or less weekly. The tool seem to have small community around it so its definitely not a dead project. In addition Meili raised 1,5M euros in their first funding round (<a href="https://blog.meilisearch.com/meili-fundraise/">https://blog.meilisearch.com/meili-fundraise/</a>) which shows that they are determined to develop the product and compete with big players, which is what they also claim on their website, they want to be an alternative to search engine APIs like Algolia.</p>
<p>What is more important for us - developers is the documentation and its clarity. The readme page is short and compact, with only relevant information which is a plus, because they also have a full blown documentation hosted as a separate website at <a href="https://docs.meilisearch.com/">https://docs.meilisearch.com/</a>.</p>
<p>The readme contains all of the basic informations need to start using the engine which means it has recipes for building from source as well as downloading a compiled binary or using a docker image. In addition there are examples how to index a first collection and make queries. All that is compact enough so that following it step by step should take no more than 10-15 minutes to complete.</p>
<p>The documentation contains description of the main concepts that were used when building the engine as well as advanced guides starting from installation and configuration up to the most advanced features of the engine. It is well written but after reading it I was left with a feeling that it is still immature project with a long road ahead of it.</p>




<h3 id="h4">The data set for testing purposes</h3>
<p>Of course testing the search engine with a small data set doesn’t make much sense since today’s hardware capabilities allows to easily keep in memory datasets weighing a couple hundreds of megabytes. So I took a different approach, I decided to find a data set that consists mostly of text and would be useful in real world examples. My choice went to Kaggle dataset: Cornell University arXiv index (<a href="https://www.kaggle.com/Cornell-University/arxiv">https://www.kaggle.com/Cornell-University/</a>). As per Wikipedia, arXiv is an open-access repository of electronic preprints (known as e-prints) approved for posting after moderation, but not full peer review. It consists of scientific papers in the fields of mathematics, physics, astronomy, electrical engineering, computer science, quantitative biology, statistics, mathematical finance and economics, which can be accessed online. The dataset hosted on Kaggle is just a friction of the whole arXiv and it contains an index of publications with information like: author, title, category and short excerpt. The dataset format is JSON and weights about 2.7gb all you need to do to download it and unzip.</p>

<h3 id="h5">Kicking it off - Download binary and start the server</h3>
<p>Now that I have a data set we can start testing MeiliSearch. The installation is pretty straightforward, I used a ready to use bash script (of course I reviewed the script in the first place as I know these bash installations are basically an attack vector).</p>
<pre><code>$ curl -L https://install.meilisearch.com | sh
$ ./meilisearch
Server is listening on: http://127.0.0.1:7700</code></pre>
<p>That was very smooth, it went well without any problems, point for Meilisearch.</p>


<h3 id="h6">Prepare the data to be ingested</h3>
<p>In order to search the data we have to create an index first (think of it as a database table) and ingest the data to it in a Meilisearch instance. For index creation I used:</p>
<pre><code>curl -i -X POST 'http://127.0.0.1:7700/indexes' --data '{ "name": "arxiv", "uid": "arxiv" }'</code></pre>
<p>After the command completed I tried to feed the index with raw data, but there are couple of constraints to the format. First thing is that the file must be less than 10 megabytes and second is that the JSON should actually be a JSON array where each element is a separate document identified by unique id field. I tried to use good old split, awk, sed unix tools in the first place, but after some time I gave up and switched to Node.js. </p>
<p>You can check the whole script below. Its not very sophisticated but it does the job.
</p>




<h3 id="h7">Indexing first collection</h3>
<p>The script above does basically two things. It first reads the file contents line by line and builds a payload containing about 1000 documents. It then sends the payload to MeiliSearch, in return we get an “updateId” which is an identifier that we can later use to ask our MeiliSearch instance whether the indexation operation for that batch finished. If the indexation batch is finished, then we can resume the file consumption, assemble another data batch and send it to MeiliSearch. And here comes the first surprise, as the documentation doesn’t clearly lay that out and I had to figure it (how it works). It seems that MeiliSearch has an internal queue that is able to accept any number of data payloads for ingesting and it processes this queue at its own pace. Makes sense to me, but as it turned out later, it’s not so lovely.
</p>

<h3 id="h8">Indexing speed</h3>
<p>Buffering incoming data has a lot of advantages, having that buffer you are able to not overwhelm your processing units with work, while still maintaining the work pace. In addition you can scale your work capacity by adding more workers, that’s when the buffers shine, because you can quickly consume additional data by throwing more resources at it. Unfortunately MeiliSearch indexing queue is processed only by one worker even on a multi-core CPU. That means, you can throw a lot of data for indexing at it but it will basically take the same amount of time, if you would do it one payload at a time. </p>
<p>It actually gets worse as the indexation time increases as your data set size increases. That is not a bad thing as long as the growth is linear and it's not too significant. Unfortunately again with MeiliSearch it's exactly the opposite. The indexation time grows exponentially and even with small data sets it gets to a point where indexing 3gb of data would take unknown time (from my calculations). I was having high hopes downloading a 2.7gb data set and trying to index it with MeiliSearch, unfortunately I was only able to index 115mb (yes, megabytes) which is about 80 000 lines from the file. Just to give you the context, the first 20 000 items were indexed in less than 1 minute, another 20 000 items took about 4 minutes. Reaching 88 000 items took 10 minutes and arXiv data set has almost 1 800 000 items. </p>

<p>That being said, the indexation time is too long and I didn’t want to spend the next few days waiting for it to finish. I did spend some more time trying to find how to speed up the indexing process, I looked through the documentation and Issues on Github, unfortunately I was not the only one that had that problem. This issue: <a href="https://github.com/meilisearch/MeiliSearch/issues/876">https://github.com/meilisearch/MeiliSearch/issues/876</a> highlights it. Until the indexing process can be paralleled at least in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</a></em></p>]]>
            </description>
            <link>https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045927</guid>
            <pubDate>Tue, 10 Nov 2020 13:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kraftwerk song performed with 5 Arduinos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045818">thread link</a>) | @alanjay
<br/>
November 10, 2020 | https://marquisdegeek.com/music_kraftwerk01 | <a href="https://web.archive.org/web/*/https://marquisdegeek.com/music_kraftwerk01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marquisdegeek.com/music_kraftwerk01</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045818</guid>
            <pubDate>Tue, 10 Nov 2020 13:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aesthetics over Usability – Google's New App Icons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045441">thread link</a>) | @moeminm
<br/>
November 10, 2020 | https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605012940954/mO5AoN3Ie.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605011290156/BFSvCYtdr.png?auto=format&amp;q=60" alt="Google-Workspace-Icons-bad.png"></p>
<p>Google's new app icons are, well, a massive disappointment. They are so bad, there's a <a target="_blank" href="https://restoreoldicons.xyz/">Chrome extension</a> that you can download to restore the old icons. Design changes are always met with some sort of backlash, that's understandable, people don't like change. Facebook's desktop redesign, Instagram's icon redesign, Macbook's touchbar, etc. The problem here; however, revolves around usability, and that's when user feedback should be seriously taken into consideration.</p>
<p>Aside from the icon's shapes, there is nothing else distinguishable about them. They are all made from a palette of four colors; blue, green, yellow, and red. There's a reason why people hate them, and it's not colors, it's usability. </p>
<p>Browsing through the internet, here are some common complaints:</p>
<blockquote>
<p>I had to manually change every Google app icon on my Android phone. I had trouble finding the Maps icon even though it is in the same place. All the new icons look similar to Google drive icon.</p>
</blockquote>
<p>The complaints all revolve around not being to <em>find</em> the apps they want to launch.</p>
<blockquote>
<p>Bring back the old version. Like the new icons aren't even close. They're so unrecognizable that when I go search for them, I forget what I'm looking for before I get to them. It takes me 3 tries to create new events in my calendar or check my email lol</p>
</blockquote>
<p>I believe this comment summarizes why this change rolled out and is live</p>
<blockquote>
<p>To me, this is a symptom of a large company with lots of internal politics and friction, where it is not safe for a designer to push back and say "no, this is not a good idea" to their manager.</p>
<p>Or, even more likely, someone did, and were forced to execute anyway.</p>
</blockquote>
<p>Unfortunately, this is the current state of UX and Design in a lot of companies. Stakeholders are ultimately the one making decisions despite being met with proven statistics from designers. </p>
<p>I also feel like this is a great lesson to any aspiring designer that working for FANG companies isn't always rainbows and sunshine. I can't be sure why these icons rolled out, if it actually was internal politics or not, but it <strong>does</strong> happen. It isn't always about working for FANG companies, but working for a company that aligns with your values. </p>
<p>See you in another Google rebrand. </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045441</guid>
            <pubDate>Tue, 10 Nov 2020 12:59:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bidirectional Scrolling: Why Not Both?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045390">thread link</a>) | @bradley_taunt
<br/>
November 10, 2020 | https://uglyduck.ca/bidirectional-scrolling/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/bidirectional-scrolling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <section>
        
          <p><time datetime="2020-11-09T00:00:00+00:00">November 9, 2020</time></p>
        
        
        
          <p><em>Discussing the design decisions of bidirectional scrolling in regards to performance</em></p>
        
        <p>I recently came across Adam Silver’s post <a href="https://adamsilver.io/articles/bidirectional-scrolling-whats-not-to-like/">about the merits and pitfalls of bidirectional scrolling</a> and found myself conflicted with the design arguments put forth in the article. It’s a very good article overall, and I suggest giving it a read before digging deeper into my post here.</p>

<h2 id="the-premise">The Premise</h2>

<p>The original article argues that displaying page content via horizontal scrolling (and therefore slightly hiding interactive content) creates a few major issues:</p>

<ul>
  <li>it increases the chance users won’t see it</li>
  <li>there’s a greater reliance on digital literacy</li>
  <li>it’s generally more labour intensive for users</li>
</ul>

<p>Adam also makes a solid statement here:</p>

<blockquote>
  <p>Having to scroll down and across in a zig zag fashion can be tiresome, especially for people with motor impairments.</p>
</blockquote>

<p>But I don’t believe these issues create a need to completely remove the horizontal “scrolling” design altogether. You can still implement the <code>See All Items</code> category link, while allowing the horizontal content to load in <em>dynamically</em>. Balance is always key.</p>

<h2 id="not-all-at-once-please">Not All At Once, Please!</h2>

<p>So what exactly do I mean by <em>dynamically</em> loading in horizontal content?</p>

<ul>
  <li>The user is shown the top 4 items in a given category</li>
  <li>From there, the user can use the <code>See All Items</code> link to jump into a full category page</li>
  <li>If they so desire, they can begin scroll horizontally in a given category row
    <ul>
      <li>Once they reach the end of the row, 4 more items will load in automatically to expand the list</li>
      <li>To avoid a never-ending list, it might be best to limit total row items to ~20 items. At this point the UI could prompt the user to <code>View All Items</code> in that category.</li>
    </ul>
  </li>
</ul>

<p>By loading the row content in piece-by-piece, initial loads for users will be faster and subsequent list items will load quickly as well (since they would limit to a set default - in this case only 4).</p>

<h2 id="final-improvements">Final Improvements</h2>

<p>Below you can find a quick, static version of this concept. Here you can see the horizontal list items, along with their corresponding <code>See All Items</code> links. You’ll have to use your imagination for how new items would load once you each the end of a horizontal row. (I’m too lazy to spend extra time building out that functionality for a hypothetical blog post)</p>

<p data-height="844" data-theme-id="dark" data-default-tab="result" data-user="bradleytaunt" data-slug-hash="pobxpXz" data-pen-title="Bidirectional Scrolling CSS">
  <span>See the Pen <a href="https://codepen.io/bradleytaunt/pen/pobxpXz">
  Bidirectional Scrolling CSS</a> by Bradley Taunt (<a href="https://codepen.io/bradleytaunt">@bradleytaunt</a>)
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>



        
<br>

      </section>
    </div></div>]]>
            </description>
            <link>https://uglyduck.ca/bidirectional-scrolling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045390</guid>
            <pubDate>Tue, 10 Nov 2020 12:52:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micro 3.0 is a platform for cloud native development]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25044604">thread link</a>) | @asim
<br/>
November 10, 2020 | https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html | <a href="https://web.archive.org/web/*/https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
      
      

      <p>This is the official announcement for the release of Micro 3.0 better known as M3O - a platform for cloud native development. 
Our 3.0 release is a major refactor and consolidation of the existing tooling into something that addresses the entire workflow 
of build, run, manage and consume all from the developers perspective.</p>

<p>Read on to learn more or go straight to the <a href="https://github.com/micro/micro/releases/latest">latest release</a>. 
Head to <a href="https://m3o.com/">m3o.com</a> for the hosted offering.</p>

<h2 id="overview">Overview</h2>

<p>Micro focuses on developer productivity for the backend. It’s clear that the Cloud has become infinitely more complex 
over the past few years. Micro attempts to create order out of that chaos by distilling it all down to a handful of 
primitives for distributed systems development.</p>

<p>Why should you care? If you’re reading this you’ve no doubt encountered the tedious nature of infrastructure management, 
wrangling a kubernetes cluster on AWS or the thousands of things you need to do to cobble together a platform before 
starting to build a product. We think we’ve nailed the solution for that just as Android did for Mobile. Keep reading 
if you want to find out more.</p>

<h2 id="quick-flashback">Quick Flashback</h2>

<p>Micro started out as a <a href="https://micro.mu/blog/2016/03/20/micro.html">toolkit for microservices</a> development, 
incorporating an api gateway, web dashboard and cli to interact with services built using a Go RPC framework. 
Back then it felt like getting anyone to buy into PaaS again was going to be a losing battle. So we chose 
to write single purpose tools around an RPC framework thinking it might allow people to adopt it piece by piece 
until they saw the need for a platform. It was really straight forward right until it wasn’t.</p>

<p>There was a simple Go framework plus some surrounding 
components to query and interact with them, but like any long lived project, the complexity grew as we 
tried to solve for that platform experience that just couldn’t be done with a swiss army knife. The repo 
exploded with a number of independent libraries. To the creator its obvious what these are all for but to 
the user there is nothing but cognitive overload.</p>

<p>In 2019 we went through a <a href="https://micro.mu/blog/2019/06/10/the-great-consolidation.html">consolidation</a> of all those libraries 
which helped tremendously but there was still always one outstanding question. What’s the difference between 
<a href="https://github.com/micro/micro">micro</a> and <a href="https://github.com/micro/go-micro">go-micro</a>? It’s a good 
question and one we’ve covered before. We saw go-micro as a framework and micro as a toolkit but these 
words were basically empty and meaningless because multiple projects working in coordination really need a 
crisp story that makes sense and we didn’t have one.</p>

<p>In 2020 we’re looking to rectify that but let’s first let’s talk about platforms.</p>

<h2 id="paas-in-2020">PaaS in 2020</h2>

<p>5 years ago the world exploded with a proliferation of “cloud native” tooling as containers and 
container orchestration took centre stage. More specifically, Docker and Kubernetes redefined the 
technology landscape along with a more conscious move towards building software in the cloud.</p>

<p>Micro took a forward looking view even as far back as 2015. It was clear distributed systems and cloud native 
was going to become the dominant model for backend services development over the coming years but, what wasn’t clear 
is just how long we’d spend wrangling all sorts tools like docker, kubernetes, grpc, istio and everything else. 
It felt like we were rebuilding the stack and weren’t really ready to talk about development aspects of it all.</p>

<p>In fact at that time, people mostly wanted to kick the tyres on all these tools and piece something together. 
Running kubernetes yourself became all the rage and even using service mesh as the holy grail for solving 
all your distributed systems problems. Many of us have come to realise while all of this tech is fun 
it’s not actually solving development problems.</p>

<p>We’ve gotten to the point of managed kubernetes and even things like Google Cloud Run or DigitalOcean App 
Platform, but none of these things are helping with a development model for a cloud native era. Our 
frustrations with the existing developer experience have grown and Micro felt like something that 
could solve for all that, but only if we took a drastic step to overhaul it.</p>

<p>We think PaaS 3.0 is not just about running your container or even your source code but something that 
encapsulates the entire developer experience including a model for writing code for the cloud. Based on that 
Micro 3.0 aka M3O is a platform for cloud native development.</p>

<h2 id="what-even-is-cloud-native">What even is Cloud Native?</h2>

<p>What is cloud native? What does it mean to build for the cloud? What is a cloud service?</p>

<p>Cloud native is basically a descriptive term for something that was built to run in the cloud. That’s it. It’s not 
magic, it might sound like a buzzword, but the reality is it simply means, that piece of software was built 
to run in the cloud. How does that differ from the way we used to build before? Well the idea behind the cloud 
is that its ephemeral, scalable and everything can be accessed via an API.</p>

<p>Our expectation for services running in the cloud is that they’re mostly stateless, leveraging external services 
for the persistence, that they are identified by name rather than IP address and they themselves provide an 
API that can be consumed by multiple clients such as web, mobile and cli or other services.</p>

<p>Cloud native applications are horizontally scalable and operate within domain boundaries that divide them as 
separate apps which communicate over the network via their APIs rather than as one monolithic entity. 
We think cloud services require a fundamentally different approach to software creation and why Micro 3.0 
was designed with this in mind.</p>

<h2 id="micro-30-aka-m3o">Micro 3.0 aka M3O</h2>

<p>Micro 3.0 (M3O) reimagines Micro as a platform for cloud native development. What does that mean? Well we think of 
it as PaaS 3.0, a complete solution for source to running and beyond. Micro has moved from just being a Go 
framework to incorporating a standalone server and hosted platform. Our hosted offering is called 
<a href="https://m3o.com/">M3O</a>, a hat tip to Micro 3.0 or M[icr]o, whichever way you want to see it.</p>

<p>Another way to think about it. What Git is to GitHub, Micro is to the M3O platform. Let’s dig into it.</p>

<p>Micro 3.0 includes the following.</p>

<h3 id="server">Server</h3>

<p>The server is our abstraction for cloud infrastructure and underlying systems you might need for writing 
distributed systems. The server encapsulates all of these concerns as gRPC services which you can 
query via any language. The goal here is to say developers don’t really need to be thinking about infrastructure 
but what they do need is design patterns and primitives for building distributed systems.</p>

<p><img src="https://micro.mu/images/micro-3.0.png"></p>

<p>The server includes the following:</p>

<ul>
  <li>
    <p><strong>Authentication</strong>: Auth whether its authentication or authorization is part of the system. Create JWT tokens, define access rules, use one system to govern everything in a simple and straight forward manner. Whether it’s for a user or a service.</p>
  </li>
  <li>
    <p><strong>Configuration</strong>: Dynamic config management allows you to store relevant config that needs to be updated without having to restart services. Throw API keys and business logic related configuration into the secure config service and let your services pick up the changes.</p>
  </li>
  <li>
    <p><strong>Key-Value Storage</strong>: We’re focused on best practices for microservices development which means keeping services mostly stateless. To do this we’re providing persistent storage on the platform. Key-Value allows you to rapidly write code and store data in the format you care about.</p>
  </li>
  <li>
    <p><strong>Event Streaming</strong>: Distributed systems are fundamentally in need of an event driven architecture to breakdown the tight dependencies between them. Using event streaming and pubsub allows you to publish and subscribe to relevant events async.</p>
  </li>
  <li>
    <p><strong>Service Registry</strong>: Micro and M3O bake in service discovery so you can browse a directory of services to explore your service APIs and enable you to query services by name. Micro is all about microservices and multi-service development.</p>
  </li>
  <li>
    <p><strong>Service Network</strong>: Because you don’t want to have to resolve those service names to addresses and deal with the load balancing aspect, the server bakes in a “service mesh” which will handle your inter-service requests (as gRPC) and route to the 
appropriate instance.</p>
  </li>
  <li>
    <p><strong>Identity Proxy</strong>: We include a separate identity proxy for external requests using gRPC via the CLI and other means. This enables you to query from your local machine or anywhere else using valid auth credentials and have it seamlessly work as if 
you were in the platform itself.</p>
  </li>
  <li>
    <p><strong>API Gateway</strong>: Finally there’s an API gateway that automatically exposes your services to the outside world over HTTP. Internally writing service to service using gRPC makes sense, but at the end of the day we want to build APIs consumed from clients via HTTP.</p>
  </li>
</ul>

<h3 id="clients">Clients</h3>

<p>The server provides inter-service communication and two means of external communication with a HTTP API and gRPC proxy but that 
experience is made much better when there’s user experience on the client side that works. Right now we’ve got two ways of doing this.</p>

<ul>
  <li>
    <p><strong>Command Line</strong>: The CLI provides a convenient and simple way to talk to the server via gRPC requests through the proxy. 
The most convenient commands are builtin but every service you write also gets beautiful dynamic generated commands 
for each endpoint.</p>
  </li>
  <li>
    <p><strong>gRPC SDKs</strong>: Every service in the server is accessible via gRPC. We’re code generating clients for the server itself 
so you can access them from any language. What this enables is a wide array of experiences on the client side without 
having to handcraft libraries for each language.</p>
  </li>
  <li>
    <p><strong>Web Interface</strong>: Coming soon is a dynamically generated web interface that creates a simple query mechanism through a 
browser for any of your services. We’ve got a http api, gRPC proxy and command line interface but feel like the browser 
could use some love too.</p>
  </li>
</ul>

<h3 id="framework">Framework</h3>

<p>One thing we really understood from our time working on go-micro was that the developer experience …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</a></em></p>]]>
            </description>
            <link>https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044604</guid>
            <pubDate>Tue, 10 Nov 2020 11:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to revert HP printer’s ban on 3rd-party ink cartridges]]>
            </title>
            <description>
<![CDATA[
Score 407 | Comments 247 (<a href="https://news.ycombinator.com/item?id=25044597">thread link</a>) | @kdeldycke
<br/>
November 10, 2020 | https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/ | <a href="https://web.archive.org/web/*/https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
     <p>
      Hewlett
      <span>
       &amp;
      </span>
      Packard, the founders, had great lessons to teach us (managers in high-tech) about culture. I even
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management/commit/de3e64647c911f78a37b3e54c7e46197acb061e1">
       quoted them
      </a>
      in my
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management#readme">
       awesome list on engineering team management
      </a>
      .&nbsp;👨‍💼
     </p>
     <p>
      <span>
       HP
      </span>
      Inc., the company, sucks. At least their
      <a href="https://news.ycombinator.com/item?id=25045024">
       printer division’s business model
      </a>
      . They recently pushed a
      <strong>
       firmware update to ban third-party compatible toner cartridges
      </strong>
      .&nbsp;💔
     </p>
     <p>
      The timeline is&nbsp;straightforward:
     </p>
     <ul>
      <li>
       <p>
        2020, March: general lockdown. 🦠 I need a home office.
        <span>
         SO
        </span>
        is a scientist and spend her time printing papers for review. Got her an
        <a href="https://amzn.com/B073R2WVKB/?tag=kevideld-20">
         <span>
          HP
         </span>
         Color LaserJet M254dw
        </a>
        to keep her productive workflow (
        <a href="https://en.wikipedia.org/wiki/Publish_or_perish">
         publish or perish!
        </a>
        ).
       </p>
      </li>
      <li>
       <p>
        2020, October:
        <span>
         HP
        </span>
        release a new firmware (versioned
        <code>
         20201021
        </code>
        ).
       </p>
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20201021-firmware.jpg">
     </p>
     <ul>
      <li>
       2020, November: my printer auto-upgrade. I’m welcomed with this
       <em>
        Supply Problem
        <a href="https://en.wikipedia.org/wiki/Screen_of_death">
         Screen of Death
        </a>
       </em>
       :
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-supply-problem-screen-of-death.jpg">
     </p>
     <p>
      I can’t print anymore.&nbsp;🤯
     </p>
     <p>
      Eight months. My printer worked for only 8 months.&nbsp;😤
     </p>
     <p>
      <span>
       OK
      </span>
      . It’s my fault. I should have spent more money buying certified™ gear.&nbsp;😑
     </p>
     <p>
      <img alt="" src="https://comdoc.com/wp-content/uploads/2019/01/copier-printer-meme-03.jpg">
     </p>
     <p>
      The solution is to travel back in time when things were working just great, and downgrade to the previous&nbsp;firmware.
     </p>
     <h2 id="disable-auto-upgrade">
      Disable Auto-Upgrade
      <a href="#disable-auto-upgrade" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      We will start by stopping this madness for good, and prevent the printer from downloading a firmware behind our&nbsp;back.
     </p>
     <p>
      In the control panel, go to
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       LaserJet Update
      </code>
      &gt;
      <code>
       Manage Updates
      </code>
      :
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-manage-updates-menu.jpg">
     </p>
     <p>
      Then set these&nbsp;options:
     </p>
     <ul>
      <li>
       Allow Downgrade:
       <code>
        Yes
       </code>
      </li>
      <li>
       Check Automatically:
       <code>
        Off
       </code>
      </li>
      <li>
       Prompt Before Install:
       <code>
        Always Prompt
       </code>
      </li>
      <li>
       Allow Updates:
       <code>
        No
       </code>
      </li>
     </ul>
     <p>
      I’m quite surprised downgrades are allowed. 🤔 It seems out of character. Therefor, with my
      <em>
       Evil Product Manager
      </em>
      hat, I advise
      <span>
       HP
      </span>
      to monetize this feature under a monthly Enterprise Subscription of sort.&nbsp;😈
     </p>
     <h2 id="download-old-firmware">
      Download Old Firmware
      <a href="#download-old-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      I got lucky and found the previous
      <code>
       20200612
      </code>
      firmware referenced in
      <a href="https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf">
       <code>
        https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf
       </code>
      </a>
      .
     </p>
     <p>
      There you’ll get a direct link to the
      <code>
       .rfu
      </code>
      file (Remote Firmware Update):
      <a href="http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       <code>
        http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      And just in case it disappear from its original location, here is a
      <a href="https://kevin.deldycke.com/uploads/2020/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       copy of
       <code>
        HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      The checksum of that file&nbsp;is:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> sha256sum ./HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
<span data-linenos="2 "></span><span>91c7f51ceba2386f3b94dcb9da20c669ab10b1ee3a9b1e1f742c40091920188e</span>
</code></pre>
     </div>
     <h2 id="downgrade-firmware">
      Downgrade Firmware
      <a href="#downgrade-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      Once you get the
      <code>
       .rfu
      </code>
      file, list all your printers from a macOS&nbsp;terminal:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpstat -p -d
<span data-linenos="2 "></span><span>printer HP_Color_LaserJet_M254dw_0 is idle.  enabled since Fri Nov  6 17:47:06 2020</span>
<span data-linenos="3 "></span><span>system default destination: HP_Color_LaserJet_M254dw_0</span>
</code></pre>
     </div>
     <p>
      And run the firmware downgrade
      <span>
       CLI
      </span>
      :
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpr -P HP_Color_LaserJet_M254dw_0 /Users/kde/Downloads/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
</code></pre>
     </div>
     <p>
      Nothing gets printed to the&nbsp;console.
     </p>
     <p>
      I don’t know what happens here but it seems the
      <code>
       .rfu
      </code>
      file is pushed to the printer’s queue and then gets consumed as any other printable document. See,
      <a href="https://www.jsof-tech.com/unpacking-hp-firmware-updates-part-1/">
       the
       <span>
        RFU
       </span>
       file format is a matryoshka doll
      </a>
      embedding printing commands, encoded data and raw
      <span>
       NAND
      </span>
      code.
     </p>
     <p>
      After a minute  or two, the printers reboots and upgrades&nbsp;itself:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-firmware-updating.jpg">
     </p>
     <p>
      And we’re back in business!&nbsp;🥳
     </p>
     <p>
      A detour via
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       Firmware Datecode
      </code>
      menu confirm we’re running the the previous&nbsp;firmware:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20200612-firmware.jpg">
     </p>
     <h2 id="printer-security">
      Printer Security
      <a href="#printer-security" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      In my research for this article, I found out about
      <a href="https://github.com/RUB-NDS/PRET">
       <span>
        PRET
       </span>
       , a printer exploitation toolkit
      </a>
      . It’s a brilliant tool, in a malignant way. It allows for pen-testing and hacking, using the same vectors as the firmware update.&nbsp;🤫
     </p>
     <p>
      I’ll probably play with it in the future. For fun, but also to try enhance the security of the printer. In the mean time, I guess a password is the bare minimum. And if my printer get kidnapped by a cyber gang, I now have a way to restore my printer’s firmware!&nbsp;😬
     </p>
     <h3>
      Related content
     </h3>
     
     
    </div></div>]]>
            </description>
            <link>https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044597</guid>
            <pubDate>Tue, 10 Nov 2020 10:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The myriad meanings of pwd in Unix systems]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25044131">thread link</a>) | @quyleanh
<br/>
November 10, 2020 | https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Last week I ran a poll on Twitter to see what people considered with respect to the meaning of ‘pwd’ in Unix and Linux systems. The results were varied, for perhaps good reason.</em></p>

<p>At the end of Oct 2020 I ran a <a href="https://twitter.com/qmacro/status/1322567992551624705">brief poll on Twitter</a>, on which 82 people voted. Here’s that poll, and the results. They’re quite mixed, which at first might seem surprising. But there are reasons for that, as we’ll find out.</p>

<p><img src="https://qmacro.org/content/images/2020/11/twitter-poll-pwd.png" alt="Poll on Twitter: &quot;Fun Saturday afternoon shell poll. In Unix (and Linux), what do you think the P in $PWD (or pwd) stand for?&quot;"></p>

<p><strong>Print working directory</strong></p>

<p>The most popular option was “print working directory”. At first sight it seems logical: “print out the current working directory, i.e. where I am right now”. Moreover, the description in various versions of the manual for <code>pwd</code> help to drive home that notion. Typically we see sentences like “<a href="https://linux.die.net/man/1/pwd">print name of current/working directory</a>” or “<a href="https://www.mankier.com/1/pwd">print the current directory</a>”.</p>

<p>But there are lots of commands that print stuff, and are described in that way too. Take the <code>id</code> command. Here’s what one man page says: “<a href="https://man7.org/linux/man-pages/man1/id.1.html">print real and effective user and group IDs</a>”. There’s “print” again. But the command isn’t <code>pid</code>, it’s <code>id</code>. When you think about it, many, many commands in Unix send information to STDOUT, i.e. to the terminal. That’s sort of the point of many of them.</p>

<p>This time arguably only superficially definitive, it would seem, the Wikipedia entry states, on the <a href="https://en.wikipedia.org/wiki/Pwd">page for <code>pwd</code></a>: “the pwd command (print working directory) writes the full pathname of the current working directory to the standard output”. As if to underline the hopeful authority of this statement, there are five (!) footnotes that supposedly link to resources that back this up.</p>

<p>Unfortunately, the first footnote points to a Wayback Machine copy of the <a href="https://web.archive.org/web/20050520231659/http://cm.bell-labs.com/7thEdMan/v7vol1.pdf">UNIX PROGRAMMERS MANUAL - Seventh Edition, Volume 1 - January, 1979</a>, wherein there are actually zero references to <code>pwd</code> being short for “print working directory”:</p>

<p><img src="https://qmacro.org/content/images/2020/11/programmers-manual-pwd.png" alt="excerpt from UNIX PROGRAMMERS MANUAL on pwd"></p>

<p>I don’t know about you, but this historic document carries more weight for me than other sources I’ve come across, and it only serves here to undermine the credibility of the Wikipedia entry.</p>

<p>The rest of the footnote links seem dubious at best, except for the one pointing to the <a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#pwd-invocation">GNU Coreutils manual on pwd</a> which has it as “print working directory”. But everything else I’ve seen so far makes me think that this is a misunderstanding that has spread for obvious and innocent reasons. In addition, the one footnote in the Wikipedia page that is not used to back this claim up is a pointer to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html">The Open Group Base Specifications Issue 7, 2018 edition’s information on pwd</a>, which almost seems like it’s actually avoiding using the word “print” at all: “return working directory name” … “The pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot.”. Very specific, very not-print.</p>

<p>So I’m thinking that “print working directory” isn’t what <code>pwd</code> stands for. In fact, “print working directory” may be common to some man pages, but on this macOS machine, with its <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> heritage, we have, instead: “pwd – return working directory name”. Moreover, it goes on to say “The pwd utility writes the absolute pathname of the current working directory to the standard output”.</p>

<p><strong>Pathname of working directory</strong></p>

<p>So perhaps it really is “pathname of working directory”. That would, at least to me, make more sense. Not only does it eschew the redundancy of “print”, it also is more specific about the output - if I’m in <code>/home/dja/</code> for example, then invoking pwd will tell me that, i.e. where I am, including the whole path, and not just <code>dja</code>:</p>



<p><strong>Process working directory</strong></p>

<p>As for the other options, I do favour “process working directory”, mostly because it makes a lot of sense to me; every process in Unix has the concept of a current working directory, and that’s exactly what I’m asking for when I’m in my shell process and enter <code>pwd</code> - there’s a part in the video <a href="https://youtu.be/hgFBRZmwpSM?t=165">Unix terminals and shells</a> that explains this very well.</p>

<p>I’d love to be able to point to some old Unix sources that definitively explain the answer, but unfortunately that search has come up with very little - the <code>pwd</code> source in both the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s2/pwd.c">5th</a> and <a href="https://github.com/yisooan/unix-v6/blob/master/source/s2/pwd.c">6th</a> Editions of Unix shed no light on this whatsoever.</p>

<p><strong>Present working directory</strong></p>

<p>What about “present working directory”? Well, that option seems to have legs, in the form of the Korn shell. While <a href="https://northstar-www.dartmouth.edu/doc/solaris-forte/ipe-help/dbx/dbx88cc.html">one source</a> implies that the answer might well be “pathname of current working directory”, in that <code>pwd</code> just emits the value of the <code>$PWD</code> environment variable (and a variable called “print working directory” makes no sense at all) … it would seem that in ksh-land, at least, “present working directory” is what <code>pwd</code> represents. Take, for example, the <a href="https://osr507doc.xinuos.com/en/man/html.C/ksh.C.html">ksh man page</a> which states “PWD - The present working directory set by the cd command”.</p>

<p>There’s a ton of discussion, both direct and indirect, on this very question. Take for example these two entries in the Unix &amp; Linux Stack Exchange forum: <a href="https://unix.stackexchange.com/questions/399026/etymology-of-pwd">Etymology of $PWD</a> and <a href="https://unix.stackexchange.com/questions/174990/what-is-pwd-vs-current-working-directory">What is $PWD? (vs current working directory)</a>. Of course, perhaps the definitive answer will never be found, as computing history is nothing if not varied and prone to forking.</p>

<p><strong>Multics and print_wdir</strong></p>

<p>Talking of history, we could go further back to pre-Unix roots, in the form of Multics, which indirectly gave rise to Unix (originally “Unics”). In the <a href="https://multicians.org/multics-commands.html">list of Multics Commands</a>, we see, nestled amongst other similarly named commands, something that jumps out at us:</p>

<div><div><pre><code>print_mail (pm)	display mail in a mailbox
print_messages (pm)	display interactive messages in a mailbox
print_motd (pmotd)	display message of the day (source)
print_proc_auth (ppa)	display process's sensitivity level and compartments
print_request_types (prt)	display list of I/O daemon request types
print_search_paths (psp)	display search paths
print_search_rules (psr)	display ready messages
print_wdir (pwd)	display working directory
</code></pre></div></div>

<p>There’s <code>pwd</code>, and in fact, just like its sibling <code>pmotd</code>, for example, which is short for <code>print_motd</code>, it’s short for <code>print_wdir</code>. Now, given the context of the original poll being set to Unix and Linux, perhaps we must discount this information. But as someone who is fascinated with Unix history in general - how can I?</p>

<p>I guess there are few things to conclude. The history is rich and diverse, and maybe we’ll never know for sure. Perhaps, in fact, the answer will depend on whom we ask. In the grand scheme of things, it doesn’t really matter … but to those who delight in minutiae, it’s a fun topic worth exploring.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044131</guid>
            <pubDate>Tue, 10 Nov 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Automation Part 4: Who made it, why, and in what context?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25044097">thread link</a>) | @nonoesp
<br/>
November 10, 2020 | https://sketch.nono.ma/who-made-it-why-and-in-what-context | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/who-made-it-why-and-in-what-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191102-cordoba-las-ramblas-alfar-torres-ferreras-ceramic-artisan.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p>Andy Warhol's artworks have sold for millions of dollars. His most famous works—think of Campbell's Soup Cans (1962) and Marylin Diptych (1962)—are limited edition paintings. Campbell's Soup Cans' piece consists of 32 images produced over five months<sup id="fnref:wikipedia-warhol-andy"><a href="#fn:wikipedia-warhol-andy" role="doc-noteref">1</a></sup>, and Marilyn Monroe's artwork consists of 50 portraits.<sup id="fnref:wikipedia-warhol-marilyn"><a href="#fn:wikipedia-warhol-marilyn" role="doc-noteref">2</a></sup></p>
<p>After hand-painting thirty-two soup cans by hand, Warhol moved to photo-silkscreen, a printmaking technique originally invented for commercial use that allowed Warhol and other artists to create reproductions of the same artwork using a silkscreen.<sup id="fnref:warhol-moma-learning"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>Warhol painted the soup cans with acrylic paint. Each canvas corresponded to a soup variety sold by Campbell's back in the 1960s.</p>
<p>Screen printing speeds up the reproduction of an artwork. Once the silkscreen is ready, colors are applied, one by one, using a squeegee to push the ink through the mesh screen<sup id="fnref:dickblick-screen-printing"><a href="#fn:dickblick-screen-printing" role="doc-noteref">4</a></sup>, either by hand or automatically with a machine, a process being used at the time to mass-produce advertisements.<sup id="fnref:warhol-moma-learning__2"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>"I don't think art should be only for the select few," Warhol claimed, "I think it should be for the mass of the American people."</p>
<p>Nowadays, we could argue this vision is a reality. Large corporations and artisans deploy a wide range of mediums to automate what used to be done by hand, producing goods en masse, lessening their price and uniqueness while improving its quality and availability. You can buy a ready-to-hang print of Vang Goh's&nbsp;<em>The Starry Night</em>&nbsp;at IKEA for $49.99 while the Museum of Modern Art in Midtown Manhattan shields and exhibits the original painting.</p>
<p>Contrary to his statement, Warhol created artwork for the selected few that could pay for it. In 2007, a 1964&nbsp;<em>Large Campbell's Soup Can</em>&nbsp;sold for $7.4 million, and&nbsp;<em>Silver Car Crash</em>&nbsp;sold for $105.4 million in 2013.</p>
<p>Aesthetics and taste aside, it's all about the story behind each piece.</p>
<p>Who made it, why, and in what context?</p>
<!-- References -->



  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/who-made-it-why-and-in-what-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044097</guid>
            <pubDate>Tue, 10 Nov 2020 09:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Hanging Fruits in Front End Performance Optimization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044079">thread link</a>) | @pawurb
<br/>
November 10, 2020 | https://pawelurbanek.com/frontend-performance-optimization | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/frontend-performance-optimization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" alt="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" data-src="https://pawelurbanek.com/assets/frontend-optimization-fruits-6ff2f8bc957fe4e1142ab67c3a460ce9dc962eba5b1dc2f10c5125292c558b37.jpg" src="https://pawelurbanek.com/assets/frontend-optimization-fruits-thumb-90ff9c113ed86f833b4e2fa0bbe34e130f2ee5871d3b08aa033fe1e1cbc0e7ad.jpg">
    </p>
  

  

  

  <p>I conduct Rails performance audits for a living. Clients usually approach me with a request to speed up the backend, i.e., optimize the bottleneck API endpoint or tune the database queries. After the initial research, it often turns out that tweaking the frontend will make a better impact on the perceivable performance than fine-tuning the backend.</p>

<p>In this blog post, I describe the often-overlooked techniques that can significantly improve your web app’s overall performance.</p>

<p>These tips apply to all the web technologies like Ruby on Rails, NodeJS, Python Django, or Elixir Phoenix. It does not matter if you render an HTML or serve an API consumed by the JavaScript SPA framework. It all comes down to transferring bytes over the HTTP protocol. Frontend performance optimization is all about making this process as efficient as possible.</p>

<h2 id="why-is-frontend-performance-critical-for-your-websites-success">Why is frontend performance critical for your website’s success?</h2>

<p>I guess that developers often disregard the frontend performance because it doesn’t directly affect the infrastructure costs. Rendering the unoptimized website is offloaded to the visitor’s desktop or mobile device and cannot be measured using backend monitoring tools.</p>

<p>Developers usually work on top-notch desktop computers with a high-speed internet connection. They do not experience poor performance themselves. The UX of visiting your landing page on a 15 inch Mac Book Pro with a fiber connection cannot be compared to an old Android device on a shaky 3G network.</p>

<p>A typical web app issues dozens of requests on initial load. Only a few are backend-related, i.e., website HTML, API calls, etc. The majority of requests are static assets, JavaScript libraries, images. Fine-tuning the frontend-related requests will give a much greater return than shaving a couple of hundered milliseconds off a database query.</p>

<p>Google Bot measures the performance of your website, and it directly affects the SEO rating. Since <a href="https://developers.google.com/search/mobile-sites/mobile-first-indexing" target="_blank" rel="noopener noreferrer">July 2019</a>, Google Bot is using a <em>“Mobile first”</em> approach to assessing your website.</p>

<p>You might not care about frying the CPU and wasting the bandwidth of your mobile users. Maybe landing a sweet spot in Google search results should convince you to focus on your frontend performance?</p>

<h2 id="test-in-your-clients-shoes">Test in your client’s shoes</h2>

<p><em>“If you want to write fast websites, use slow internet.”</em>.</p>

<p>You should regularly throttle the internet speed during the development process to experience first-hand how your app will behave for most users.</p>

<p>On macOS, you can use the <a href="https://nshipster.com/network-link-conditioner/" target="_blank" rel="noopener noreferrer">Network Link Conditioner</a> to do it:</p>

<p><img alt="Simulate mobile network on a desktop computer" title="Simulate mobile network on a desktop computer" loading="lazy" src="https://pawelurbanek.com/assets/3g-network-performance-4273c3bd62edbdaddfdc36d7dad126747f3d69804a7ce8c1227cd8f96ff0a1ed.png"></p>

<p>Also, both Firefox and Chrome developer tools offer the option to throttle the internet speed in the <strong>Network</strong> tab:</p>

<p><img alt="Chrome network throttle setting" title="Chrome network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/chrome-network-throttle-ed2b0e3cb5163dbf3d6fe89601bd32c072af9a2b7146e82d8004f8e536ca208d.png"></p>

<p>Chrome network throttle</p>

<p><img alt="Firefox network throttle setting" title="Firefox network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/firefox-network-throttle-d11d6b54034fff903c4cc721f05a66747904fd72d3d9760ab7f1141491875434.png"></p>

<p>Firefox network throttle</p>


<p>Maybe the internal demos of the new features should also be done on the throttled network? Everyone in the company should have the chance to see how the app really works for most users.</p>

<h2 id="reconnaissance">Reconnaissance</h2>

<p>Discovering frontend issues is usually more straightforward than backend ones. You don’t even need admin access to the website. By definition, the frontend issues are in the <em>frontend</em>. You can scan and diagnose every website out there. I use the following tools to perform the initial scan:</p>

<p><a href="https://www.fastorslow.com/" target="_blank" rel="noopener noreferrer">FastOrSlow</a></p>

<p><a href="https://www.webpagetest.org/" target="_blank" rel="noopener noreferrer">WebPageTest</a></p>

<p><a href="https://developers.google.com/speed/pagespeed/insights/" target="_blank" rel="noopener noreferrer">Google PageSpeed Insights</a></p>

<p><a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noopener noreferrer">GoogleChrome lighthouse</a></p>

<p>There’s no reason why ANY website shouldn’t score top on each of those tools. Read on if your score is anywhere below 90%.</p>

<p><img alt="Abot for Slack FastOrSlow score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-fastorslow-28336ad9b7b74849a6a1d85a1ad269be81dd6288a960ee3b3ecbe69e6cf6b6a7.png"></p>

<p><img alt="Abot for Slack WebPageTest score" title="Abot for Slack WebPageTest score" loading="lazy" src="https://pawelurbanek.com/assets/abot-webpagetest-e33807bf28e738ced4aa16f48cdf17e44836a986b283aca9d673c8504ff045fa.png"></p>

<p><img alt="Abot for Slack Google speed score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-googlespeed-03d18ebbc637cce72357f44e3ed65e1cf60062e633df52bafc2eb178e0cca7ac.png"></p>

<p>The <a href="https://abot.app/" target="_blank">Abot landing page</a> is a dynamic Rails website getting top performance rating</p>





<h2 id="client-side-caching">Client-side caching</h2>

<p>Correctly configuring client-side caching is the most critical frontend optimization. I’ve seen it misconfigured in multiple production apps so far. <a href="https://github.com/webpack/webpack" target="_blank" rel="noopener noreferrer">Webpack</a> comes with a great mechanism to easily leverage client-side caching, i.e., <em>MD5 digest</em>. The production assets generation process must be configured to append the <em>MD5 digest</em> tag to the filename.</p>

<p>It means that in the production environment, the <code>application.js</code> file becomes <code>application-5bf4f97...95c2147.js</code>. The random suffix is generated based on the file contents, so it is guaranteed to change if the file changes. You must add the correct <code>cache-control</code> header to make sure that once downloaded, the file will persist in the browser cache:</p>

<figure><pre><code data-lang="bash">cache-control: public, max-age<span>=</span>31536000, immutable</code></pre></figure>

<p>The <code>immutable</code> parameter ensures that cache is not cleared when the user explicitly refreshes the website on the Chrome browser.</p>

<p>If you’re using NGINX as reverse proxy you can use the following directive:</p>

<figure><pre><code data-lang="nginx"><span>location</span> <span>~</span><span>*</span> <span>\</span><span>.(?:ico|css|js|gif|jpe?g|png|woff2)</span>$ <span>{</span>
  <span>add_header</span> <span>Cache-Control</span> <span>"public,</span> <span>max-age=31536000,</span> <span>immutable"</span><span>;</span>
  <span>try_files</span> <span>$uri</span> <span>=</span><span>404</span><span>;</span>
<span>}</span></code></pre></figure>

<p>I’ve seen many apps using <code>Etag</code> and <code>Last-Modified</code> headers instead of <code>Cache-Control</code>. <code>Etag</code> is also generated based on the file contents, but the client has to talk to the server to confirm that the cached version is still correct. It means that on every page visit, the browser has to issue a request to validate its cache contents and wait for <code>304 Not Modified</code> response. This  completely unnecessary network roundtrip can be avoided if you add a <code>Cache-Control</code> header.</p>

<h2 id="limit-bandwidth-usage">Limit bandwidth usage</h2>

<p>Nowadays, websites are just MASSIVE. It often takes multiple MBs to render a static landing page. Let me point out the most common mistakes that affect it and how they can be resolved.</p>

<h3 id="compress-and-resize-images">Compress and resize images</h3>

<p>There’s no excuse for serving uncompressed images on your website. You must make sure to process all your images with tools like <a href="https://compressor.io/" target="_blank" rel="noopener noreferrer">Compressor.io</a>. There’s often no perceivable difference for images processed with <strong>Lossy</strong> compression, and it usually means ~70% size reduction.</p>

<p>Resizing an image to the size that it actually needs is often overlooked. To check it, visit your website using Firefox on a large desktop screen, right-click the image, and select <strong>View image info</strong>. You’ll see what dimensions the image needs vs. how large it is now:</p>

<p><img alt="Checking real image" title="Checking real image" loading="lazy" src="https://pawelurbanek.com/assets/real-image-size-524abe8437774180a233461deb8ada35092fda22cee4b3dfe85c0d0ad2e757b8.png"></p>

<p>Make sure first to resize the image and only then compress it. Otherwise, you might lose quality.</p>

<h3 id="defer-images-loading">Defer images loading</h3>

<p>You should defer the loading of the images that are not visible in the initial viewport. During the initial load, dozens of requests are competing for network throughput. Delaying the transfer of unnecessary images will leave more resources for necessary assets like CSS stylesheets etc.</p>

<p>There’s <a href="https://github.com/aFarkas/lazysizes" target="_blank" rel="noopener noreferrer">plenty</a> of <a href="https://github.com/tuupola/lazyload" target="_blank" rel="noopener noreferrer">different</a> <a href="https://github.com/vvo/lazyload" target="_blank" rel="noopener noreferrer">JavaScript libraries</a> that offer this feature. Including them means additional bandwidth usage, so I prefer to keep things simple and use a native <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-loading" target="_blank" rel="noopener noreferrer"><code>loading='lazy'</code></a> HTML attribute.</p>

<p>It has decent <a href="https://caniuse.com/loading-lazy-attr" target="_blank" rel="noopener noreferrer">browser support</a>. Have a look at how it affected one of my blog posts:</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/before-lazy-images-a0e8cdb9099f3d5a348f853f4f222b67149aa058e59ecd29d2d5338be81cd8c0.png"></p>

<p>Without lazy loaded images</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/after-lazy-images-836f1781a9b7bf56cd8883a0ad0d252f52223f74b856e7e994ecef1d52efd029.png"></p>

<p>Lazy loading for images enabled</p>



<p>As you can see, adding <code>loading='lazy'</code> to all the images reduced ten requests and over <em>250kb</em> of transfer on the initial load. That’s a massive deal for slower internet connections!</p>

<h3 id="enough-with-the-gifs-already">Enough with the GIFs already…</h3>

<p>GIFs are HUGE! I understand you want to showcase a fancy UI on your landing page, but maybe you could use a lazy-loaded movie clip instead? <em>10MB</em> GIF can be converted to <em>250kb</em> mp4 file… Twitter automatically changes <em>GIF</em> images to <em>mp4</em> files, so I’d trust them on this one.</p>

<h3 id="cherry-pick-and-measure-dependencies-size">Cherry-pick and measure dependencies size</h3>

<p>Many frontend libraries offer a modular approach to including them in your application. For example, <a href="https://getbootstrap.com/docs/3.4/customize/" target="_blank" rel="noopener noreferrer">Bootstrap</a> allows you to customize the build to include only the components you need.</p>

<p>Some popular libraries have lightweight alternatives. Since recently, <a href="https://twitter.com/addyosmani/status/1304676118822174721" target="_blank" rel="noopener noreferrer">ChromeDevTools suggests them</a>, so make sure to use it for your application.</p>

<h3 id="reconsider-3rd-party-dependencies">Reconsider 3rd party dependencies</h3>

<p>Overusing externally hosted 3rd party JavaScript libraries is the simplest way to kill the performance of your website.</p>

<p>Dropping in yet another <code>&lt;script src="..."&gt;</code> tag might not seem like a big deal. It’s easy to forget that one script can result in a cascade of requests, each including more resources. Here’s the cost of embedding sample 3rd party JavaScript libraries:</p>

<table>
  <tbody><tr>
    <th></th>
    <th>Requests</th>
    <th>Bandwidth (total/gzipped)</th>
  </tr>
  <tr>
    <td><a href="https://www.google.com/analytics/" target="_blank" rel="noopener noreferrer">Google Analytics</a></td>
    <td>4</td>
    <td>104.09 KB / 40.37 KB</td>
  </tr>
  <tr>
    <td><a href="https://simpleanalytics.com/" target="_blank" rel="noopener noreferrer">Simple Analytics</a></td>
    <td>2</td>
    <td>5.29 KB / 3.12 KB</td>
  </tr>
  <tr>
    <td><a href="https://developer.twitter.com/en/docs/twitter-for-websites/follow-button/overview.html" target="_blank" rel="noopener noreferrer">Twitter button</a></td>
    <td>8</td>
    <td>173.68 KB / 59.30 KB</td>
  </tr>
  <tr>
    <td><a href="https://disqus.com/" target="_blank" rel="noopener noreferrer">Disqus</a></td>
    <td>26</td>
    <td>862.55 KB / 271.48 KB</td>
  </tr>
  <tr>
    <td><a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a></td>
    <td>5</td>
    <td>64.73 KB / 19.25 KB</td>
  </tr>
</tbody></table>



<p>The only 3rd party JavaScript dependency I use for this blog is <a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a> for comments. It’s over <strong>10x</strong> lighter than its alternative Disqus.</p>

<p>I’ve switched from using Google Analytics to SimpleAnalytics long ago. Recently I’ve decided I don’t need to track the visitors of this blog at all. Summary visit stats from Cloudflare are enough for me.</p>

<p><img alt="CloudFlare visits stats" title="CloudFlare visits stats" loading="lazy" src="https://pawelurbanek.com/assets/cloudflare-total-stats-2af208b0332a799e70e0aaa5495ef01c05c12ccc24514110accd3a4005817863.png"></p>

<p>All the tracking I need. No JavaScript dependencies required</p>


<p>Including 3rd party libraries from external sources often reduces your ability to set correct caching headers, thus hurting your performance score.</p>

<p>You should always look for the most straightforward tool that meets your requirements and only resort to using 3rd party if you cannot develop the lightweight solution yourself.</p>

<h2 id="http-2">HTTP 2</h2>

<p><em>HTTP 2</em> offers massive performance improvement over <em>HTTP 1.1</em> for loading static assets. Headers are compressed to reduce bandwidth. Even more important is that multiple assets can be loaded in parallel over a single HTTP connection.</p>

<p>It might not be critical for API calls, but for static assets, you should enable <em>HTTP 2</em> and expect serious performance gains.</p>

<p>How to do it depends on your infrastructure. If you’re using custom infrastructure with NGINX reverse proxy, you can check out <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-with-http-2-support-on-ubuntu-18-04" target="_blank" rel="noopener noreferrer">this tutorial</a>.</p>

<p>If you’re using Heroku, you’re out of luck because currently, it <a href="https://help.heroku.com/JAOCNZ25/does-heroku-have-plans-to-support-http-2" target="_blank" rel="noopener noreferrer">does not support HTTP 2</a>. The simplest way to add HTTP 2 support for Heroku is to proxy your traffic through <a href="https://pawelurbanek.com/cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare</a>.</p>

<p>If you don’t want to move your application to Cloudflare’s DNS, you can always use a custom domain just for serving assets from their CDN.</p>

<h2 id="physical-server-location-and-cdn">Physical server location and CDN</h2>

<p>The usage of CDN (<em>Content Delivery Network</em>) is critical if your user base is spread across the globe. Correctly configured CDN will cache static assets on the edge locations, significantly reducing the request’s duration. We’re talking like <em>50ms</em> vs. <em>800ms</em> (<strong>16x</strong> …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/frontend-performance-optimization">https://pawelurbanek.com/frontend-performance-optimization</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/frontend-performance-optimization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044079</guid>
            <pubDate>Tue, 10 Nov 2020 09:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software development: should we stop? Maybe we should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044031">thread link</a>) | @enz
<br/>
November 10, 2020 | http://blog.spencermounta.in/2020/should-we-stop/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2020/should-we-stop/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://blog.spencermounta.in/2020/should-we-stop/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044031</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Awful Edge Case in Bash's Set -e]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044030">thread link</a>) | @jbrot
<br/>
November 10, 2020 | http://jbrot.com/blog/dash_e_problems.html | <a href="https://web.archive.org/web/*/http://jbrot.com/blog/dash_e_problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <header>
                
                
            </header>

            <p>
            The last six months, I've been building out the automated testing infrastructure at a start up.
            Our infrastructure is mostly in Python, but writing Bash scripts is inevitable.
            At the end of the day, automated testing is all about running commands in a row—and Bash is the right tool for the job.
            </p>

            <p>
            There are a <a href="https://mywiki.wooledge.org/BashPitfalls">whole</a> <a href="https://github.com/anordal/shellharden/blob/master/how_to_do_things_safely_in_bash.md">bunch</a> <a href="https://sipb.mit.edu/doc/safe-shell/">of</a> <a href="https://wizardzines.com/comics/bash-errors/">articles</a> about how to write safe Bash scripts, and the standard advice is to add <code>set -euo pipefail</code> to make your scripts "safe."
            In this article, I'm going to describe one edge case where <code>set -e</code> completely fails to work.
            </p>

            <h2> Background </h2>

            <p>
            Suppose we have two projects in a git repo, say MyLibrary and MyApplication, where MyApplication depends on MyLibrary. And suppose each project provides a script <code>test.sh</code> that looks something like this:
            </p>

<pre><code>#!/bin/bash

set -e

./configure
make

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            This is a pretty reasonable script.
            We can now require that all changes pass both <code>my_library/test.sh</code> and <code>my_application/test.sh</code> before being merged.
            </p>

            <p>
            As time goes on, the amount of tests (and projects!) can spiral out of control.
            Eventually, someone (me) gets tasked with trying to optimize things.
            One obvious thing to do is to abort early.
            If MyLibrary fails testing, we don't need to bother with testing MyApplication.
            </p>

            <p>
            Of course, the developers who used to get errors from both projects aren't very happy about this change.
            Now passing the <code>test.sh</code> scripts is like peeling an onion: you resolve the first layer of errors only to find more errors lurking underneath—hidden by the early abort.
            However, there's a middle ground.
            We can test MyApplication only if MyLibrary fails while running test cases.
            If MyLibrary fails during compilation, continuing on is pointless since MyApplication depends on MyLibrary.
            </p>

            <p>
            So how do we distinguish when <code>test.sh</code> fails during compilation from when it fails during testing?
            Exit codes, naturally:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            And we're done!
            An exit code of 0 means we passed the tests, an exit code of 79 means compilation failure (no need to test further projects), and any other exit code means we failed in testing—so we can continue testing the other projects.
            </p>

            <h2> Finding the Problem </h2>

            <p>
            The above solution works fine when we only have two lines that need the special exit code.
            However, it quickly becomes unwieldly when it needs to be applied to more lines:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

pushd codegen_tool1 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool1 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

pushd codegen_tool2 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool2 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            Gross!
            Clearly, we should factor out the <code>|| exit $COMPILE_FAILURE_CODE</code> line and have it apply to all of our lines at once.
            We can easily do this by creating a separate <code>build.sh</code> script:
            </p>

<pre><code>#!/bin/bash

set -e

pushd codegen_tool1
./configure
make
./codegen_tool1
popd

# snip

./configure
make
</code></pre>

            <p>
            And then adjusting <code>test.sh</code> to just have:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./build.sh || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            And this, too, works great!
            But wait!
            Why even use a second script?
            Can't we do the exact same thing with a subshell?
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

(
    pushd codegen_tool1
    ./configure
    make
    ./codegen_tool1
    popd

    # snip

    ./configure
    make
) || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            <strong>No!</strong>
            This subshell implementation is dangerously broken.
            The rest of this article will explore how and why the subshell code does not function as expected.
            </p>

            <h2> There's a Problem? </h2>

            <p>
            Let's run some simple bash programs and see what happens.
            First, we'll confirm <code>set -e</code> works as expected.
            </p>

<pre><samp>$ cat script1.sh
#!/bin/bash
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ echo "$?"
0

#!/bin/bash
set -e
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ ./script2.sh
Statement 1

$ echo "$?"
3
</samp></pre>

            <p>
            Yep, that's what we expected.
            Without <code>set -e</code> Bash ran every statement, and with <code>set -e</code> Bash stopped after the first non-zero exit code.
            What if we put our statements in a subshell?
            </p>

<pre><samp>$ cat script3.sh
#!/bin/bash
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script3.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat ./script4.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script4.sh
Statement 1

$ echo "$?"
3
</samp></pre>

        <p>
        And again, that's what we expected.
        The subshell made no difference.
        Note that <code>set -e</code> does propagate into the subshell.
        Alright. What if we mask the subshell's exit code?
        </p>

<pre><samp>$ cat script5.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script5.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>And again everything works as...</p>

        <h2> Wait, what? </h2>

        <p>Okay. Maybe <code>set -e</code> doesn't propagate?</p>

<pre><samp>$ cat script6.sh
#!/bin/bash
set -e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script6.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat script7.sh
#!/bin/bash
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script7.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>
        Nope. Still doesn't work.
        Even if we just have <code>set -e</code> in the subshell and not in the outer script, it doesn't work.
        </p>

        <h2>So what's going on?</h2>

        <p>
        Well, if we dig into the Bash man page, we find this excerpt about <code>set -e</code>:
        </p>

        <blockquote>
              Exit  immediately  if a pipeline (which may consist of a single simple command), a list, or a compound command (see SHELL GRAMMAR above), exits with a non-zero status.
              The shell does not exit if the  command  that  fails  is part  of  the command list immediately following a while or until keyword, part of the test following the if or elif reserved  words, <em>part of any command executed in a &amp;&amp; or || list except the command following the final &amp;&amp; or ||,</em> any command in a pipeline but the last, or if the command's return value is being inverted with !.
        </blockquote>

        <p>
        So, the spec says that if you're using <code>&amp;&amp;</code> or <code>||</code>, only the last command's exit code can cause the shell to exit.
        This makes sense, because you expect  <code>command_1 || command_2</code> to execute <code>command_2</code> if <code>command_1</code> fails.
        Without this exception, it would be very hard to have any logical statements when <code>-e</code> is set.
        </p>

        <p>
        The behavior we just witnessed is, therefore, Working as Intended™.
        When we try to mask the subshell's exit code, we put the subshell at the start of an <code>||</code> list.
        So, the subshell's exit code will not cause an exit despite <code>-e</code> being set.
        But, every single command inside the subshell is <em>also</em> considered part of the <code>||</code> list, and thus no exit code anywhere in the subshell can cause the subshell to exit.
        It's as if <code>set +e</code> is being run implicitly in the subshell—only, as we've seen, we can't override it with an explicit <code>set -e</code> in the subshell.
        </p>

        <p>
        Is there anything we can do to fix this?
        Well, you're probably better off with one of the approaches I presented earlier.
        If you need to stay inside the same shell script, the solution with <code>trap</code> below is probably what you want.
        And if you truly need to use a subshell, I was able to come up with this mess:
        </p>

<pre><samp>$ cat script8.sh
#!/bin/bash
set -e
echo "Some stuff with -e set"

set +e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)
[[ $? -ne 0 ]] &amp;&amp; exit 9
set -e

echo "More code with -e set (unreachable)"

$ ./script8.sh
Some stuff with -e set
Statement 1

$ echo "$?"
9
</samp></pre>

        <h3>Bonus Solution</h3>

        <p>
        I ended up using <code>trap</code> for error masking:
        </p>

<pre><samp>$ cat script9.sh
#!/bin/bash

set -e

trap 'exit 9' ERR

echo "Statement 1"
(exit 3)
echo "Statement 2"

trap - ERR

$ ./script9.sh
Statement 1

$ echo "$?"
9
</samp></pre>

        <p>
        The nice part about this solution is it allows you to stick with just one script (useful if you need to use functions), and the logic is straightforward.
        This option can be harder to make work if you're already using <code>trap ERR</code> for cleanup, though.
        </p>

        </article></div>]]>
            </description>
            <link>http://jbrot.com/blog/dash_e_problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044030</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become Covid Savvy in 10 Steps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044022">thread link</a>) | @datashrimp
<br/>
November 10, 2020 | https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/ | <a href="https://web.archive.org/web/*/https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044022</guid>
            <pubDate>Tue, 10 Nov 2020 09:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Productivity Guide: All You Need to Know to Be Efficient]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043892">thread link</a>) | @iuliangulea
<br/>
November 10, 2020 | https://iuliangulea.com/productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/productivity.png" alt="Productivity"></p><h2 id="productivity-definition">Productivity Definition</h2><blockquote><p>Productivity is a measure of the efficiency of a person to perform a specific task.</p></blockquote><p>We often think it is a state of constant efficiency that allows us to do everything faster and better, but this is wrong. <em>Productivity is a measurement per individual task.</em></p><p>If you try to measure productivity as the number of tasks you accomplish daily, you still have to count in each individual assignment, which endorses the idea that productivity is a measurement per task.</p><h2 id="productivity-from-within-and-without">Productivity From Within And Without</h2><p>There are different strategies for productivity, and all those strategies can be classified into two main categories: <strong>external productivity</strong> and <strong>internal productivity.</strong></p><p><strong>External productivity</strong> is what usually people put their emphasis on. Also, it is what all those products, apps, and services promise to deliver. External productivity is all about automation, better tools, frameworks, software, and anything that allows you to perform your work better and faster. It has a significant potential to improve your performance by taking advantage of technology and advanced tools.</p><p><strong>Internal productivity,</strong> on the other hand, is often overlooked. Unlike the external one, internal productivity is all about your cognitive and physical performance, about your ability to focus, sustain your attention on the task at hand, manage your energy, and, generally speaking, understand how your body and mind works.</p><h2 id="gaining-productivity-expertise--the-pyramid-of-mastery">Gaining Productivity Expertise — The Pyramid Of Mastery</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-of-mastery-1.png" alt="Pyramid of Mastery"></p><p><a href="https://iuliangulea.com/pyramid-of-mastery/">The Pyramid of Mastery</a> is a model that defines any domain in terms of 4 categories:</p><p><strong>Elements</strong> are the fundamental building blocks that make up a domain. In productivity, elements are abstract: focus, attention, working memory, sensory channels, etc.</p><p><strong>Rules</strong> are the laws by which the elements interact with each other and general principles that govern a domain. Some rules are: goal-directed attention is easily distracted, senses have a different throughput, working memory cannot perform two tasks simultaneously (hence multitasking is a myth), etc.</p><p><strong>Tools</strong> are the instruments that help you operate with the Elements and Rules. The majority of productivity tools nowadays are software apps. One of the best productivity tools is pen and paper.</p><p><strong>Frameworks</strong> are a combination of the previous layers. A Framework is a layer of abstraction that hides the underlying fundamentals behind a friendly facade that is easy to use to achieve a specific goal. Some frameworks in productivity are office suites and various productivity methods (e.g., <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 Rule</a>, <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a>, and others).</p><p>All four layers together allow you to be an expert in your field. Leave one out, and there will always be something you do not fully understand. And when you don’t understand something, you cannot be fully efficient at it.</p><p>If you would like to find out more about how the Pyramid of Mastery applies to the field of productivity, I wrote a separate <a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">article</a> on that topic.</p><h2 id="productivity-approaches">Productivity Approaches</h2><p>Generally speaking, you can be more productive by taking one or several of the following approaches:</p><p><strong>1. Delegate/Outsource the task.</strong> This approach is the most efficient from the time standpoint as it frees all your time and allows you to focus on other tasks. Although it is limited in how much you can delegate/outsource, it is crucial to keep in mind that you can and need to delegate.</p><p><strong>2. Automate the task.</strong> If you cannot delegate/outsource, think about whether your work on a task can be either fully or partially automated. There are lots of services, products, and programs that can do the work for you in a broad range of areas. If their cost is smaller than the value of the time you can save using them, then do it.</p><p><strong>3. Use better tools and learn them well.</strong> If automation is also not an option, then it means <em>you</em> need to do it. Having good tools is crucial if you want to be productive. A thorough understanding of their functions can make a big difference. In the case of software, learn its features and the shortcuts of the most frequently used functionality by you.</p><p><strong>4. Understand cognitive processes and learn what works best for you.</strong> Whenever we need to perform mental work, understanding <em>how</em> our <a href="https://iuliangulea.com/human-senses/">senses</a>, <a href="https://iuliangulea.com/attention/">attention</a>, <a href="https://iuliangulea.com/working-memory/">working memory</a>, and other relevant processes work can make a huge difference. As a plant flourishes, when the conditions are right, our brains can be incredibly performant whenever we offer them the right environment in which they can function.</p><h2 id="my-top-productivity-strategies">My Top Productivity Strategies</h2><p><strong>The Rule Of Threes.</strong> This is a meta strategy I came up with some time ago that help me make the right decisions when it comes to taking on new opportunities. No matter how productive you are, if you have too much on your plate, your attention and energy will split into too many places, and that will affect your productivity. The rule is simple: at any one point in time, I should have no more than three ongoing projects, and by an ongoing project, I mean any work that spans for longer than one week. Having more than that will scatter your energy and attention to the detriment of effectiveness.</p><p><strong>Plan Your Day In Advance.</strong> It is much easier to follow a predefined list of steps rather than having only the destination in mind and think about your next course of action after each task. The 10–15 minutes spent in the evening to decide and prioritize what you will work on will save you plenty of energy and time the following day.</p><h2 id="more-productivity-tips-for-every-day">More Productivity Tips For Every Day</h2><p><strong>1. Reduce Distractions As Much As Possible.</strong> If there is something that can distract you, sooner or later, it will distract you. Therefore, if you want to keep focused for a longer time, remove as many distractions as you can. This includes visual distractions on your table and screen (yes, those Facebook and Twitter tabs are hooking your attention pretty easy, aren’t they?), audial distractions (buy yourself a good pair of noise-canceling headphones), and other types of disturbances that distract you regularly.</p><p><strong>2. Put Your Phone Away.</strong> Although it is also a distraction, this tip deserves a separate mention. Put your phone on silent mode and away from your sight (not in your pocket). All those sounds (including notifications, calls, etc.) and flashes are nothing else than stimuli that have their primary goal to grab your attention and distract you from the thing you are focused on. It is also essential to put the phone away, as having it in your area of sight will also urge you to grab it when you see it on the table.</p><p><strong>3. Split Your Tasks Into Manageable Chunks.</strong> If an assignment is too big for you to comprehend, consider splitting it into several smaller subtasks until you get them of a size that you can easily accomplish. A positive side-effect of this is that smaller tasks provide a sense of progress, positively affecting your overall state and mood.</p><p><strong>4. Use Good Tools And Learn Them Properly.</strong> If you use software tools, learn the shortcuts of the programs you work in as it will save you dozens of hours within a year. If you use physical tools, buy high-quality tools, as they will pay off multiple times.</p><p><strong>5. Your Energy Is More Important Than The Allocated Time.</strong> Time Management is overrated. It’s not that timing your tasks is not essential, but <em>time is absolute.</em> It is independent of anything. Consider your energy levels when planning your tasks. Your energy is what matters when working on a job. You can spend 2 hours banging your head against something in the evening when you are tired and then complete that task in 30 minutes the next morning. Know when you are more productive and work on the most important tasks then.</p><p><strong>6. Use Visual Aids.</strong> A pen and a piece of paper are sometimes the best, simple, and most efficient productivity tools you can use. If the task you are working on relies on manipulating multiple pieces of information at a time, write them on paper or draw a diagram. That will free up resources necessary to store them in your working memory so that you can focus on processing and manipulating them instead. This will also involve your visual sense, allowing you to make more potentially relevant connections between ideas.</p><h2 id="all-productivity-articles">All Productivity Articles</h2><p>These are all articles I have written on productivity. Enjoy!</p><ul><li><a href="https://iuliangulea.com/keyboard-shortcuts/">6 Shortcuts That Save Me 62 Hours Each Year</a></li><li><a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">The Ultimate Productivity Guide — Scientifically Proven Techniques To Get Things Done</a></li><li><a href="https://iuliangulea.com/attention/">The Dual Nature Of Attention — 5 Ways To Stay Less Distracted And Be More Productive</a></li><li><a href="https://iuliangulea.com/working-memory/">How People Learn — Working Memory And The 3 Basic Rules Of Productivity</a></li><li><a href="https://iuliangulea.com/the-most-substantial-word/">Your Name — The Most Substantial Word</a></li><li><a href="https://iuliangulea.com/how-i-automated-things/">How I Saved 14 Hours Of Working Time Each Month</a></li><li><a href="https://iuliangulea.com/one-percent-rule/">The One Percent Rule - How Tiny Changes Can Bring Big Results</a></li><li><a href="https://iuliangulea.com/team-processes-what/">Increase Your Team’s Productivity by Establishing Processes - Part III</a></li><li><a href="https://iuliangulea.com/team-processes-how/">Increase Your Team’s Productivity by Establishing Processes - Part II</a></li><li><a href="https://iuliangulea.com/team-processes-why/">Increase Your Team’s Productivity by Establishing Processes - Part I</a></li></ul><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043892</guid>
            <pubDate>Tue, 10 Nov 2020 08:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 133 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Event, 18th Nov: Building a Notion Website Live]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25043693">thread link</a>) | @saviorand
<br/>
November 9, 2020 | http://optemization.com/how-to-build-notion-website | <a href="https://web.archive.org/web/*/http://optemization.com/how-to-build-notion-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-how-to-build-notion-website"><div id="block-128d927961c546d8870b1a51a5579a93"><picture><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-d2269dc812f14b90932490290a797437"><span id="d2269dc812f14b90932490290a797437"></span><span><span>🖥️ You can do websites on Notion?</span></span></h2><blockquote id="block-2d6de681f9a04563af1656151a4a72ac"><span><span>If you spend anytime on #productivity Twitter or r/Notion you know that building websites on Notion, is the new normal :)  Thanks to projects like Super and Fruition, Notion pages can turn into real websites, with custom domains, analytics, and styling!

My new teammate Valentine, just shared a </span><span><a target="_blank" rel="noopener noreferrer" href="https://optemization.com/notion-landing-page-guide">comprehensive guide</a></span><span> on how to build your own Notion website. 

However, this stuff is really visual, so we thought it'd be super fun to host an </span><span><strong>event where we conceptualize, design and ship a Notion website LIVE</strong></span><span>! 

So two things: RSVP below and tell us what kind of website do you want to build!</span></span></blockquote><h2 id="block-1b34e201f6484d4680c97fe88b965d4c"><span id="1b34e201f6484d4680c97fe88b965d4c"></span><span><span>🖋️ Sign Up</span></span></h2><h2 id="block-b67496c5fc8b4bdcb04d5891dc6baf0b"><span id="b67496c5fc8b4bdcb04d5891dc6baf0b"></span><span><span>😃 Are you excited?</span></span></h2><div id="block-c91d2a953127494f86a21d77c34339ea"><div id="block-f2134537e8d04052915c6399871b09eb"><blockquote id="block-7d5a84aa13624e43ba7e69fbac453dea"><span><span>Share the event on the ze twitter 🙏</span></span></blockquote></div></div></article></div></div></div>]]>
            </description>
            <link>http://optemization.com/how-to-build-notion-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043693</guid>
            <pubDate>Tue, 10 Nov 2020 07:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Haskell Is Ready for Prime Time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043675">thread link</a>) | @_query
<br/>
November 9, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043675</guid>
            <pubDate>Tue, 10 Nov 2020 07:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Poignant Guide to Ruby]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043544">thread link</a>) | @creolabs
<br/>
November 9, 2020 | https://poignant.guide/book/chapter-2.html | <a href="https://web.archive.org/web/*/https://poignant.guide/book/chapter-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<h2>1. Opening This Book</h2>

<p>Pretend that you’ve opened this book (although you probably <em>have</em> opened this
book), just to find a huge onion right in the middle crease of the book. (The
manufacturer of the book has included the onion at my request.)</p>

<p>So you’re like, “Wow, this book comes with an onion!” (Even if you don’t
particularly like onions, I’m sure you can appreciate the logistics of shipping
any sort of produce discreetly inside of an alleged programming manual.)</p>

<p>Then you ask yourself, “Wait a minute. I thought this was a book on Ruby, the
incredible new programming language from Japan. And although I can appreciate
the logistics of shipping any sort of produce discreetly inside of an alleged
programming manual: Why an onion? What am I supposed to do with it?”</p>

<p>No. Please don’t puzzle over it. You don’t need to do anything with the onion.
Set the onion aside and let <em>it</em> do something with <em>you</em>.</p>

<p>I’ll be straight with you. I want you to cry. To weep. To whimper sweetly. This
book is a <strong>poignant</strong> guide to Ruby. That means code so beautiful that tears
are shed. That means gallant tales and somber truths that have you waking up the
next morning in the arms of this book. Hugging it tightly to you all the day
long. If necessary, fashion a makeshift hip holster for <em>Why’s (Poignant) Guide
to Ruby</em>, so you can always have this book’s tender companionship.</p>

<p>You really must sob once. Or at least sniffle. And if not, then the onion will
make it all happen for you.</p>





<h2>2. The Dog Story</h2>

<p>So try this first bit of poignancy on for size:</p>

<p>One day I was walking down one of those busy roads covered with car dealerships
(this was shortly after my wedding was called off) and I found an orphaned dog
on the road. A woolly, black dog with greenish red eyes. I was kind of feeling
like an orphan myself, so I took a couple balloons that were tied to a pole at
the dealership and I relocated them to the dog’s collar. Then, I decided he
would be my dog. I named him Bigelow.</p>

<p>We set off to get some Milkbones for Bigelow and, afterwards, head over to my
place, where we could sit in recliners and listen to Gorky’s Zygotic Mynci. Oh,
and we’d also need to stop by a thrift store and get Bigelow his own recliner.</p>

<p>But Bigelow hadn’t accepted me as his master. So five minutes later, the stupid
dog took a different crosswalk than I did and I never caught up. So whereas he
had previously only been lost once, he was now lost twice. I slowed my pace
towards the life of Milkbones and an extra recliner. I had a dog for five
minutes.</p>

<p>Stupid Benedict Arnold of a dog. I sat on a city bench and threw pine cones at a
statue of three sheep crossing a bridge. After that, I wept for hours. The tears
just came. Now there’s a little something poignant to get you started.</p>

<p>I wonder where he went with all those balloons. That crazy dog must have looked
like a party with legs.</p>

<p>It wasn’t much later that I pulled my own Bigelow. I printed out a bunch of
pages on Ruby. Articles found around the Web. I scanned through them on a train
ride home one day. I flipped through them for five minutes and then gave up. Not
impressed.</p>

<p>I sat, staring out the window at the world, a life-sized blender mixing graffiti
and iron smelts before my eyes. <em>This world’s too big for such a a little
language</em>, I thought. <em>Poor little thing doesn’t stand a chance. Doesn’t have
legs to stand on. Doesn’t have arms to swim.</em></p>

<p>And yet, there I was. One little man on a flimsy little train (and I even still
had a baby tooth to lose at the time) out of billions of people living on a
floating blue rock. How can I knock Ruby? Who’s to say that I’m not going to
happen to choke on my cell phone and die later that evening. Why’s dead, Ruby
lives on.</p>

<p>The gravestone:</p>

<blockquote>
  <p>What’s in his trachea? Oh, look, a Nokia!</p>
</blockquote>

<p>Just my luck. Finally get to have a good, long sleep underground, only to be
constantly disturbed by <em>Pachelbel’s Canon</em> going off in my stomach.</p>



<h2>3. The Red Sun Rises</h2>

<p>So, now you’re wondering why I changed my mind about Ruby. The quick answer is:
we clicked.</p>

<p>Like when you meet Somebody in college and they look like somebody who used to
hit you in the face with paintbrushes when you were a kid. And so, impulsively,
you conclude that this new Somebody is likely a non-friend. You wince at their
hair. You hang up phones loudly during crucial moments in their anecdotes. You
use your pogo stick right there where they are trying to walk!</p>

<p>Six months later, somehow, you and Somebody are sitting at a fountain having a
perfectly good chat. Their face doesn’t look so much like that childhood
nemesis. You’ve met the Good Twin. You clicked.</p>

<p>So whereas I should probably be pounding your teeth in with hype about Ruby and
the tightly-knit cadre of pertinent acronyms that accompany it everywhere
(whetting the collective whistles of your bosses and their bosses’ bosses),
instead I will just let you coast. I’ll let you free-fall through some code,
interjecting occasionally with my own heartfelt experiences. It’ll be quite
easy, quite natural.</p>

<p>I should offer you some sort of motivation, though. So, Smotchkkiss, I’m going
to give my three best reasons to learn Ruby and be done with it.</p>

<ol>
  <li>
    <p><strong>Brain health.</strong></p>

    <p>Vitamin R. Goes straight to the head. Ruby will teach you to <em>express</em> your
ideas through a computer. You will be writing stories for a machine.</p>

    <p>Creative skills, people. Deduction. Reason. Nodding intelligently. The
language will become a tool for you to better connect your mind to the world.
I’ve noticed that many experienced users of Ruby seem to be clear thinkers and
objective. (In contrast to: heavily biased and coarse.)</p>
  </li>
  <li>
    <p><strong>One man on one island.</strong></p>

    <p>Ruby was born in Japan. Which is freaky. Japan is not known for its
software. And since programming languages are largely written in English, who
would suspect a language to come from Japan?</p>

    <p>And yet, here we have Ruby. Against the odds, Yukihiro Matsumoto created
Ruby on February 24, 1993. For the past ten years, he has steadily brought Ruby
to a global audience. It’s triumphant and noble and all that. Support diversity.
Help us tilt the earth just a bit.</p>
  </li>
  <li>
    <p><strong>Free.</strong></p>

    <p>Using Ruby costs nothing. The code to Ruby itself is open for all of the
world to inhale/exhale. Heck, this book is free. It’s all part of a great, big
giveaway that should have some big hitch to it.</p>

    <p>You’d think we’d make you buy vacuums or timeshare or fake Monets. You’d
think there’d be a 90 minute presentation where the owner of the company comes
out at the end and knuckles you into sealing the deal.</p>

    <p>Nope, free.</p>
  </li>
</ol>

<p>With that, it’s time for the book to begin. You can now get out your highlighter
and start dragging it along each captivating word from this sentence on. I think
I have enough hairspray and funny money on my person to keep me sustained until
the final page.</p>



<h2>4. How Books Start</h2>

<p>Now, if you ever have read a book, you know that no book can properly start
without an exorbitant amount of synergy. Yes, synergy. Maybe you didn’t know
this. Synergy means that you and I are supposed to cooperate to make this a
great reading experience.</p>

<p>We start off the book by getting along well in the Introduction. This
togetherness, this <strong>synergy</strong>, propels us through the book, with me guiding you
on your way. You give me a reassuring nod or snicker to indicate your progress.</p>

<p>I’m Peter Pan holding your hand. Come on, Wendy! Second star to the right and on
till morning.</p>

<p>One problem here. I don’t get along well with people. I don’t hold hands very
well.</p>

<p>Any of my staff will tell you. At the Opening Ceremonies of This Book (a catered
event with stadium seating), I discovered that the cucumber sandwiches weren’t
served in tea towels. As a result, the butter hadn’t set with the cucumbers
right… Anyways, I made a big scene and set fire to some of the advertising
trucks outside. I smashed this spotlight to pieces and so on. I had this loud
maniacal laughing thing going on deep into that night. It was a real mess.</p>

<p>But, since I don’t get along well with people, I hadn’t invited anyone but
myself to the Opening Ceremonies of This Book. So it wasn’t really that
embarrassing. I kept it under wraps and no one found out about the whole ordeal.</p>

<p>So you’ve got to know that <strong>synergy</strong> doesn’t actually mean <strong>synergy</strong> in this
book. I can’t do normal <strong>synergy</strong>. No, in this book, <strong>synergy</strong> means
<strong>cartoon foxes</strong>. What I’m saying is: this book will be starting off with an
exorbitant amount of <strong>cartoon foxes</strong>.</p>

<p>And I will be counting on you to turn them into <strong>synergy</strong>.</p>


      <p>
      <a href="https://poignant.guide/book/chapter-3.html">Turn page.</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://poignant.guide/book/chapter-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043544</guid>
            <pubDate>Tue, 10 Nov 2020 07:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon – July 26, 2008<br>
Revised – September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming—a kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs—3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs—six
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master—though they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"—CHR$(07)—causes the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy—any value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes—which fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise …</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Kills Cname Cloaking on iOS/iPadOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25042374">thread link</a>) | @fenier
<br/>
November 9, 2020 | https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/ | <a href="https://web.archive.org/web/*/https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042374</guid>
            <pubDate>Tue, 10 Nov 2020 02:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking for Introverts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042288">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/how-to-network-as-an-introvert/ | <a href="https://web.archive.org/web/*/https://gradually.co/how-to-network-as-an-introvert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-876">

					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              			<p>																								Health								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Networking for Introverts</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 9, 2020						</span>

						<img width="640" height="312" src="https://gradually.co/wp-content/uploads/2020/11/GD23-Health.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://giphy.com/gifs/giphydiscovery-dogs-VzGQrj8sLH4GLcSiG1" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://medium.com/@byrnehobart/writing-is-networking-for-introverts-5cac14ad4c77" target="_blank">
										Writing is Networking for Introverts									</a>
									 &nbsp;by Byrne Hobart									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“Networking is painful, and I’m suspicious of anyone who claims to enjoy it. Unfortunately for me, networking is effective: most good opportunities come from personal connections” — Byrne Hobart</span></li>
<li><span>Networking works, but it doesn’t work very well for people who are bad at striking up and maintaining conversations with strangers.&nbsp;</span></li>
<li><span>“There is a solution: be famous. You lose the ability to filter out who you want to talk to, but at least everyone starts the conversation with some context; you’re outsourcing the extroversion to them.” — Byrne Hobart</span>
<ul>
<li><span>Fame doesn’t just grow on trees. Byrne says there’s a second alternative called being </span><i><span>microfamous</span></i><span>, though. “Microfame is the best kind of fame because it combines an easier task (be famous to fewer people) with a better outcome (be famous to the right people).”</span></li>
<li><span>“If you’re trying to calibrate how hard it is to achieve micro-fame, focus on the micro, not the fame. Micro-fame just means your friends-of-friends have a nonzero chance of knowing who you are, and striking up a conversation with you about something mutually interesting.” — Byrne Hobart</span></li>
</ul>
</li>
<li><span>To achieve microfame for introverts, Byrne believes one way is to write. Specifically, “writing-as-networking strategy is that writing about your other interests gets other people interested. You’re not just identifying neighbors in your intellectual ghetto; you’re recruiting more. If more of your friends do it, you get exposed to more ideas.”&nbsp;</span></li>
<li><span>“This is not for everyone. There are some people who really love the idea of walking into a room full of strangers with a fat stack of business cards and making a bunch of valuable connections. But for those of us who faintly dread the prospect, writing is an alternative. If you put in the effort, you can substitute the worst parts of socializing for time spent alone with your computer.” — Byrne Hobart</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>I certainly identify as an introvert and I used to think it was a weakness (and it somewhat is to a certain extent), but it’s also somewhat of a superpower too. You have the ability to listen more intently, pick up on things others probably wouldn’t, and weaponize your empathy for good. Writing can act as a bat signal for others interested in what you’re interested in. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->

			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/how-to-network-as-an-introvert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042288</guid>
            <pubDate>Tue, 10 Nov 2020 02:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1984 by George Orwell [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042280">thread link</a>) | @bra-ket
<br/>
November 9, 2020 | https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf | <a href="https://web.archive.org/web/*/https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042280</guid>
            <pubDate>Tue, 10 Nov 2020 02:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Writing Clean Interfaces in Go]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25042085">thread link</a>) | @lanecwagner
<br/>
November 9, 2020 | https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042085</guid>
            <pubDate>Tue, 10 Nov 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking an election fraud claim using open data and Dolt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25041998">thread link</a>) | @proverbialbunny
<br/>
November 9, 2020 | https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041998</guid>
            <pubDate>Tue, 10 Nov 2020 01:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try Design Thinking]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25041961">thread link</a>) | @gbasin
<br/>
November 9, 2020 | https://garybasin.com/try-design-thinking/ | <a href="https://web.archive.org/web/*/https://garybasin.com/try-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://garybasin.com/try-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041961</guid>
            <pubDate>Tue, 10 Nov 2020 01:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing my phone battery with a cheap AliExpress knock-off]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25041894">thread link</a>) | @flotwig
<br/>
November 9, 2020 | https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>This is a story of one manâ€™s quest for power.</p> <p>I purchased my current phone, a OnePlus 5T, in 2017. This summer, after about two and a half years of ownership, I noticed that it was no longer holding a charge all day. Frequently, the phone would reach 0% and shut off, right in the middle of tracking an evening bike ride or watching Netflix while cooking dinner. Although cell phone battery wear is a well-known issue, I got tired of it pretty quickly.</p> <p>I used the <a href="https://play.google.com/store/apps/details?id=com.digibites.accubattery&amp;hl=en_US&amp;gl=US">AccuBattery</a> app for about two months to try and get a handle on my battery health. It measured my phoneâ€™s amperage draw during the day and used that to estimate that of the 3300 milliamp-hour (mAh) capacity that my battery originally offered, only about 2400 mAh of capacity remained - only about 75% of the batteryâ€™s original health:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-capacity.png" alt="Screenshot of AccuBattery app for OEM battery capacity"></p> <p>This answered the question of â€œwhy does it feel like my phone is shutting off so quickly?â€� pretty clearly. Now, it was up to me to get a replacement battery.</p> <h3 id="attempting-to-get-a-genuine-battery">Attempting to get a genuine battery</h3> <p>My first thought was that I could simply order the OEM OnePlus 5T battery somewhere online. Why not? I found a page on the OnePlus website where prices are listed for replacement parts. The USA page was down at the time of this writing, but the <a href="https://www.oneplus.in/support/pricing/detail?code=7">India support page</a> lists a OnePlus 5T OEM battery replacement as being about $15.</p> <p>This seemed acceptable to me. My first thought was to email OnePlus support asking how to purchase the battery. Unfortunately, according to the service rep, they do not ship or sell OEM batteries without service:</p> <blockquote> <p>We would like to inform you that we do not ship or sell the accessories in any parts of the world, and all the repairs are carried out by our Authorized service centers only. So if you wish to get the device repaired, you can send it to the OnePlus authorized service center and get the same repaired.</p> </blockquote> <p>This is in line with what other OnePlus customers have reported - nobody, as far as I can tell, has ever been able to source OEM batteries from OnePlus, leaving DIY customers like myself to try and find knock-offs elsewhere.</p> <p>I wouldâ€™ve sent my phone in for repairs, but after I received the above email, I had such a long and terrible customer support experience trying to arrange the repair that by the end of it, I no longer trusted OnePlus to reliably service and return my phone. This lack of trust was reinforced by horror stories from other OnePlus customers - one customerâ€™s phone was <a href="https://www.reddit.com/r/oneplus/comments/eleckw/sent_my_oneplus_5_to_fort_worth_tx_for_repair_no/">lost by the Fort Worth, TX service center</a>, anotherâ€™s was <a href="https://www.reddit.com/r/oneplus/comments/depgkg/oneplus_lost_my_coworkers_phone_during_repair_at/">lost and took 4 weeks before being returned</a>, and yet another customer had <a href="https://www.reddit.com/r/oneplus/comments/jke2kd/sent_my_op3t_for_a_battery_replacement_oneplus/">their phone held hostage unless they agreed to repairing EVERYTHING instead of just getting the battery replaced</a>. These stories, combined with my awful customer support experience, convinced me that sending my phone in would be a truly bad idea.</p> <h3 id="buying-an-aftermarket-battery">Buying an aftermarket battery</h3> <p>Many people on the /r/oneplus5t subreddit have recommended purchasing a <a href="https://www.ifixit.com/Store/Android/OnePlus-5-5T-Replacement-Battery/IF330-018?o=2">replacement battery from iFixit</a>, but I felt like iFixit was simply selling cheap Chinese batteries with a nice label on them. I mean, if OnePlus can fix it for $15, why does the iFixit battery cost $30, if not for marketing?</p> <p>So, I hit up eBay and AliExpress, and eventually found the [sic] â€œSpecail Mobilephone Parts Storeâ€�, where they offer a <a href="https://web.archive.org/web/20201109223630/https://www.aliexpress.com/item/4000438352423.html">â€œ4650 mAhâ€� â€œPerfect business batteryâ€�</a> for the OnePlus 5T. With slogans like <a href="https://zach.bloomqu.ist/assets/battery/giant-energy-huge-capacity.webp">â€œGiant energy; huge capacityâ€�</a>, <a href="https://zach.bloomqu.ist/assets/battery/safety-does-not-explode.webp">â€œSafety does not explodeâ€�</a>, and <a href="https://zach.bloomqu.ist/assets/battery/ensure-qualified-and-safe-to-use.webp">â€œEnsure qualified and safe to useâ€�</a>, I felt confident that my $11.87 was going to a good place. I placed the order and, about 3 weeks later, I received the battery in my mailbox.</p> <h3 id="battery-physics-101">Battery Physics 101</h3> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-and-aftermarket.jpg" alt="Photo of the OEM battery and the aftermarket battery side-by-side"> <small>The OEM battery (left) and the aftermarket battery installed (right).</small></p> <p>The first thing I noticed about the replacement battery was that the capacity was even HIGHER than what I ordered. The OnePlus 5T OEM battery is rated at 3300 mAh capacity, the AliExpress product page advertised a battery with 4650 mAh capacity, and the label on the battery I received claimed an astounding <em>5350 mAh</em> capacity - 162% of the OEM capacity. Clearly, I had gotten a great deal!</p> <p>The second thing I noticed was that the aftermarket battery was significantly lighter than the OEM battery. So much lighter that I weighed the batteries out of curiosity. The OEM OnePlus 5T battery weighed 47.0g. The aftermarket OnePlus 5T battery weighed 38.7g, or about 17% less.</p> <p>Itâ€™s amazing that Da Da Xiong was able to achieve 162% capacity with 17% less weight. Too amazing to be true, in fact.</p> <p>Via Wikipedia, I learned that the <a href="https://en.wikipedia.org/wiki/Specific_energy">specific energy</a> of a lithium-ion polymer battery can be up to <a href="https://en.wikipedia.org/wiki/Lithium-ion_battery">265 watt-hours per kilogram (Wh/kg)</a>. The nominal voltage of the lithium-ion polymer batteries here is about 3.8V. We can use <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohmâ€™s law</a> to calculate the maximum possible capacity of each battery based on weight, assuming that each battery is always supplying the nominal 3.8V.</p> <p>Letâ€™s start by calculating the maximum possible Amp-hours (Ah) per kilogram (kg) for a Li-ion poly battery at 3.8V, using Ohmâ€™s law:</p> <div><div><pre><code>265 Wh/kg / 3.8 V = 69 Ah/kg
</code></pre></div></div> <p>Now, we can calculate the maximum physically possible capacity for each battery by multiplying this number by the weights of each battery:</p> <div><div><pre><code>OEM battery:          .047 kg * 69 Ah/kg = 3.2 Ah = 3200 mAh
Aftermarket battery: .0387 kg * 69 Ah/kg = 2.6 Ah = 2600 mAh
</code></pre></div></div> <p>The astute reader might be wondering why this estimate for the maximum capacity of the OEM battery (3200 mAh) is less than the capacity OnePlus advertises (3300 mAh). Why is this? Well, itâ€™s because the assumption we made - that each battery is always supplying the nominal 3.8V - is false. The voltage output of a Li-ion poly battery <a href="https://learn.adafruit.com/li-ion-and-lipoly-batteries/voltages">drops over time</a>, so the calculation shown is only a lower bound approximation of each batteryâ€™s maximum capacity.</p> <p>I donâ€™t have information about the exact chemical composition of these batteries, nor the voltage charts, nor do I know what the upper and lower voltage limits are on the OnePlus 5T charging circuit. However, if we estimate that the voltage drops from 3.8V to 3.0V in a linear fashion (<code>V = 3.8 - .8t, 0 &lt;= t &lt;= 1</code>), we can use integration to arrive at approximately 3600 mAh maximum capacity for the OEM battery and 2900 mAh maximum capacity for the aftermarket battery.</p> <p>Even without exact numbers, these calculations demonstrate that <em>something</em> is fishy about the Da Da Xiong batteryâ€™s mAh claims.</p> <h3 id="real-world-usage">Real-world usage</h3> <p>Anyways, I didnâ€™t buy this shady AliExpress battery just so that I could do a bunch of math. I purchased it to restore my phoneâ€™s ability to last all day, and it has definitely succeeded at that. From a qualitative perspective, I now have enough juice to keep my phoneâ€™s battery fueled all day until I can recharge it at night.</p> <p>From a quantitative perspective, AccuBattery reports that the aftermarket battery has an estimated 3360 mAh capacity, which about matches the capacity of the OEM battery:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/aftermarket-capacity.png" alt="Screenshot of AccuBattery app for aftermarket battery capacity"></p> <p>However, what AccuBattery fails to account for is the fact that once the aftermarket battery reaches 15%, the battery percentage begins to free-fall until it reaches 0% and shuts off. It seems like 15% on the aftermarket battery is equivalent to 1% on the OEM battery. I think this is because the Android OS cannot correctly estimate the batteryâ€™s remaining charge because it has different voltage characteristics than the OEM battery, but it doesnâ€™t really bother me, I just have to make sure that to charge the phone at 15% instead of 1%. This seems to be an extremely common experience with DIY battery replacements - even folks using the iFixit battery run in to this issue.</p> <p>If we take 15% off of AccuBatteryâ€™s estimated capacity, we get 2856 mAh, which is really really close to what a brand new OnePlus 5T reports - AccuBattery estimates the OEM battery as having ~3000 mAh capacity when it is brand new. That about matches my experience - with the Da Da Xiong battery, the phone is staying alive longer, almost like when it was new.</p> <h3 id="conclusions">Conclusions</h3> <ul> <li>Random Chinese batteries do not work as advertised - they will not magically double your phoneâ€™s battery capacity.</li> <li>However, random Chinese batteries work <em>almost as well</em> as brand new OEM batteries, but your battery percentage will forever be miscalibrated.</li> <li>Never trust OnePlus customer service.</li> </ul> </div></div>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041894</guid>
            <pubDate>Tue, 10 Nov 2020 01:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ladders of Wealth Creation]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25041361">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/roadmap-to-building-wealth/ | <a href="https://web.archive.org/web/*/https://gradually.co/roadmap-to-building-wealth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-878">
				<!--<a href="https://gradually.co/roadmap-to-building-wealth/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Roadmap to Building Wealth</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 9, 2020						</span>

						<img width="640" height="418" src="https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1024x668.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1024x668.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-300x196.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-768x501.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1536x1002.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-2048x1336.png 2048w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://nathanbarry.com/wealth-creation/" target="_blank">
									[Image source: Nathan Barry]								</a></p><h5>
									<a href="https://nathanbarry.com/wealth-creation/" target="_blank">
										The ladders of wealth creation: a step-by-step roadmap to building wealth									</a>
									 &nbsp;by Nathan Barry									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“…Making money is a skill—like playing the drums or piano—that you can get better at over time. I wouldn’t expect to be able to sit down at a piano for the first time and immediately play a concerto.” — Nathan Barry</span></li>
</ul>
<ul>
<li><b><i>Your time for money</i></b><span>: the only skills you need are showing up consistently, being reliable, and learning new skills on the job. Nathan goes on to say, “Then in order to take the next step up the ladder you will need to specialize in certain skills (design, copywriting, legal, becoming a nurse, etc) to gain a salaried position.”&nbsp;</span></li>
</ul>
<ul>
<li><b><i>Your own service business</i></b><span>: This next rung on the ladder requires skills such as setting up a company, finding clients, creating proposals, pricing services, hiring employees, establishing an online presence, accounting, finance, business ops, etc.&nbsp;</span></li>
</ul>
<ul>
<li>
<ul>
<li><span>However, these two are probably the most important: follow up with customers and doing what you said you were going to do.&nbsp;</span></li>
</ul>
</li>
</ul>
<ul>
<li><b><i>Productized services</i></b><span>: Nathan mentions, “…To truly reach new levels of income you need to learn a different lesson: how to sell without ever talking to the customer.” This rung of the ladder requires you to learn how to write quality sales copy, design a sales page, process online payments, and create systems to deliver repeatable quality with each service.&nbsp;</span></li>
</ul>
<ul>
<li><b><i>Selling products</i></b><span>: Nathan continues, “A product takes far more work to create upfront, but then each individual sale and the fulfillment of that sale happens without much (or any) additional effort from the business owner.”&nbsp;</span></li>
</ul>
<ul>
<li><span>“All across society extra money—whether from a raise or working extra—disappears into lifestyle inflation or temporary purchases, when it could be put to work so much more effectively.” — Nathan Barry</span></li>
<li><span>You should always trade your time for money if:</span>
<ul>
<li><span>You’re early in your career and just starting out</span></li>
<li><span>You’re getting paid to learn a new skill while growing your earning potential</span></li>
<li><span>It’s a step in getting to a higher rung or on to the next ladder</span></li>
<li><span>You’re building relationships or finding mentors</span></li>
<li><span>The work is rewarding and meaningful in its own right</span></li>
</ul>
</li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>There’s no secret formula for building wealth. It takes a ton of hard work and time. At the end of the day, it boils down to how much of your time you’re willing to give up to make more money. If you’re able to learn how to make more money while giving up less of your time, you’re learning how to build wealth. There are no shortcuts.&nbsp; </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/roadmap-to-building-wealth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041361</guid>
            <pubDate>Mon, 09 Nov 2020 23:47:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned Building an Open Source MLOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039872">thread link</a>) | @ChefboyOG
<br/>
November 9, 2020 | https://www.cortex.dev/post/building-an-open-source-mlops-platform | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/building-an-open-source-mlops-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>For the last two years, we’ve been working on Cortex, our open source machine learning deployment platform. Over that time, we’ve been really fortunate to see it grow into what it is today, used in production by teams around the world, and supported by a fantastic community of contributors.</p><p>We’ve also had to change our thinking several times along the way. The understanding of the ML ecosystem we had at the beginning has not always turned out to be accurate, and this is reflected in various changes we’ve made to Cortex.</p><p>As interest in MLOps continues to increase, I thought it would be useful (for our sakes as much as anyone else’s) to document a few of the key lessons we’ve learned that’ve come to shape Cortex.</p><p>If you’re working on a production machine learning system, building machine learning infrastructure, or designing your own MLOps tool, hopefully the following lessons (listed in no particular order) are useful for you.</p><h3>1. Production machine learning runs in the cloud</h3><p>When Cortex was still in its idea stage, one of our most frequent discussions was whether or not it should support on-premise deployments. At the time, the worry was that a large portion of the machine learning ecosystem was going to remain on-premise indefinitely due to privacy and cost.</p><p>These worries were enflamed when we initially released Cortex. While we had some excited users, we also had plenty of people writing in requesting on-prem support. We worried that by going all-in on the public clouds, we’d cut off most of the machine learning ecosystem.</p><p>Over the last two years, things have changed. Production machine learning is almost entirely moving to the cloud, and there are a couple reasons why.</p><p>The first is the standard reason for moving to the cloud: scalability. As production machine learning systems become more powerful and responsible for more features, their workloads increase. If you need to autoscale to dozens of GPUs during peak hours, the cloud has obvious advantages.</p><p>The second is the investment by the major clouds into ML-specific offerings. Major clouds now offer both dedicated software and hardware for machine learning. For example, Google and AWS both offer ASICs (TPUs and Inferentia, respectively) that substantially improve machine learning performance, and both are only available on their respective clouds.</p><p>More and more, the cloud is becoming the only realistic way to deploy production machine learning systems.</p><h3>2. It’s too early for end-to-end MLOps tools</h3><p>Another misguided belief we held in Cortex’s early days was that Cortex needed to be an all-inclusive, end-to-end MLOps platform that automated your pipeline from raw data to deployed model.</p><figure id="w-node-a47abffb7609-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5cb4b8083a07ddc765_0*6z89yrFEvqkVBqIg.jpeg" alt=""></p></figure><p>We’ve written a full <a href="https://towardsdatascience.com/we-tried-to-build-an-end-to-end-ml-platform-heres-why-it-failed-190c0f503536" target="_blank">breakdown of why that was the wrong decision,</a> but the short version is that it’s still way too early in the lifespan of MLOps to build that sort of platform.</p><p>Every page of the production machine learning playbook is constantly being rewritten. For example, in the last several years:</p><ul role="list"><li><strong>Our notion of “big” models has exploded.</strong> We thought models with hundreds of millions of parameters were flirting with boundaries of being “too large” to deploy. Then Transformer models like GPT-2 started weighing in the billions—and people still built applications out of them.</li><li><strong>The ways we train models have changed. </strong>Transfer learning, neural architecture search, knowledge distillation—we have more techniques and tools than ever to design, train, and optimize models efficiently.</li><li><strong>The machine learning toolbox has grown rapidly</strong>. PyTorch was only released in 2016, shortly after TF Serving’s initial public release. ONNX came out in 2017. The frameworks, languages, and features that an end-to-end MLOps platform would need to support changes endlessly.</li></ul><p>We ran into all of these problems with our first release of Cortex. We provided a seamless experience—<em>if</em> <em>you used the narrow stack we supported.</em> Because everything (including language, pipeline, frameworks, and even team structure) can vary so wildly across ML orgs, we were almost always “one feature away” from fitting any given team’s stack.</p><p>As a modular platform, focused on one discrete part of the machine learning lifecycle—deployment—without opinions about the rest of the stack, Cortex has been adopted by many more teams at a much faster pace. We’ve seen rapid growth in other MLOps tools with similar “best of breed” approaches at different parts of the stack, including <a href="https://dvc.org/" target="_blank">DVC (Data Version Control) </a>and <a href="https://www.comet.ml/site/" target="_blank">Comet</a>.</p><h3>3. Data science, ML engineering, and ML infrastructure are all different — in theory</h3><p>With Cortex, we use the following high-level model of an ML function and its constituent parts:</p><ul role="list"><li><strong>Data science</strong>. Concerned with the development of models, from exploring the data to conducting experiments to training and optimizing models.</li><li><strong>Machine learning engineering</strong>. Concerned with the deployment of models, from productionizing models to writing inference services to designing inference pipelines.</li><li><strong>Machine learning infrastructure</strong>. Concerned with the design and management of the ML platform, from resource allocation to cluster management to performance monitoring.</li></ul><p>And in theory, these are nicely delineated functions with clear handoff points. Data science creates models which are turned into inference pipelines by ML engineering and deployed to a platform maintained by ML infrastructure.</p><p>But, this is an overview of the theoretical functions in an ML org, not the <em>actual roles</em> people hold. Oftentimes, a data scientist will also do ML engineering work, or an ML engineer will be tasked with managing an inference cluster.</p><p>Building a tool for these different use-cases gets complex, as the optimal ergonomics of an interface for one role can vary drastically from another.</p><p>For example, <a href="https://towardsdatascience.com/why-we-do-machine-learning-engineering-with-yaml-not-notebooks-a2a97f5e04f8" target="_blank">for reasons we’ve explained before</a>, Cortex APIs are written as Python scripts with YAML manifests, not notebooks, and are deployed via a CLI. </p><p>For MLEs, this is comfortable. For data scientists, however, it is often uncomfortable, as YAML and CLIs aren’t common tools in their ecosystem. Because of this, we needed to build a Python client for defining deployments in pure Python in order for some teams to use Cortex successfully.</p><p>Now, people who are more comfortable with CLIs can deploy like this:</p><figure id="w-node-b878c71bee4b-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c272d5ce9d4c2dd28_0*yV51u9hxfGDvxtF3.png" alt=""></p></figure><p>And people more comfortable with pure Python can do this:</p><figure id="w-node-5864f8b2c1a4-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c09e66f37c2c56cdf_1*1CO_-hPGhV9qNuH4c3Jxuw.png" alt=""></p></figure><p>The takeaway here is that if you’re building MLOps tooling, remember everyone who will be using it in practice, not just in theory.</p><h3>4. ML native companies have different needs</h3><p>Several years ago, the most common examples of production machine learning were popular products optimized by trained models. Payment processors would sprinkle in fraud detection models, streaming platforms would boost their engagement with recommendation engines, etc.</p><p>Now, however, there is a new wave of companies whose products aren’t enhanced by models—they <em>are</em> models.</p><p>These companies, which we refer to as ML native, operate in different ways. Some sell access to an inference pipeline as an API, as in the case of <a href="https://www.glisten.ai/" target="_blank">Glisten</a>, whose API allows retailers to tag and categorize products instantly:</p><figure id="w-node-dc634e21281f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa47e5ab8c60a850d3f4032_0*mw_tAL1CeDD1Q8e3.png" alt=""></p></figure><p>Others build applications whose core functionality is provided by a trained model. For example, <a href="https://postera.ai/" target="_blank">PostEra’s</a> medicinal chemistry platform uses models to predict the most likely chemical reactions for creating a specific drug, and <a href="https://play.aidungeon.io/main/home" target="_blank">AI Dungeon</a> uses a trained language model to create an endless choose-your-own-adventure:</p><p>These ML native applications have different infrastructure needs. For one, they typically rely on realtime inference, meaning their models need to be deployed and available at all times.</p><p>Ensuring this availability can get very expensive. <a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9" target="_blank">AI Dungeon uses a 6 GB model</a> that can only handle a few concurrent requests and requires GPUs for inference. To scale to even a few thousand concurrent users, they need many large GPU instances running at once—something that is costly to sustain for long periods.</p><p>When we first built Cortex, we hadn’t worked with many ML native teams. After working with them, we wound up prioritizing a new set of features, many of which were at least in part aimed at helping control inference costs:</p><ul role="list"><li>Request-based autoscaling to optimally scale each model for spend</li><li>Spot instance support to allow for cheaper base instance prices</li><li>Multi-model caching, live reloading, and multi-model endpoints to increase efficiency</li><li>Inferentia support for more cost-effective and performant instance types</li></ul><p>As the number of ML native companies continues to rise quickly, MLOps tools and platforms are going to have to build for their needs.</p><h3>5. MLOps is production machine learning’s biggest bottleneck</h3><p>This is one of the few things we believed before building Cortex that we still find to be true today. It is the feasibility of building and deploying a production machine learning system prevents teams from using ML. </p><p>Training and retraining models is not cheap. Deploying models to production isn’t cheap either. Building a platform to support those deployments is a full-scale infrastructure project, one that has to be maintained moving forward.</p><p>These costs make machine learning unapproachable for most companies. and the frustrating part is that they aren’t intrinsic qualities of machine learning. We can solve them with better infrastructure—no ML research breakthroughs needed.</p><p>As the MLOps ecosystem matures, new tools will continue to abstract away these parts of infrastructure and nullify the costs that prohibit teams from using ML in production. If you want to accelerate the proliferation of machine learning, consider contributing to any of the many open source MLOps projects—<a href="https://github.com/cortexlabs/cortex" target="_blank">like this one</a>.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/building-an-open-source-mlops-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039872</guid>
            <pubDate>Mon, 09 Nov 2020 21:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039758">thread link</a>) | @anuragsoni
<br/>
November 9, 2020 | https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>See a typo? Have a suggestion?
<a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/posts/haskell-bad-parts-2.md">Edit this page on Github</a>
</i>
</p>

<p>If you didn’t see it, please check out <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">part 1 of this series</a> to understand the purpose of this. Now, for more bad parts!</p>
<h2>Partial functions (in general)</h2>
<p>Laziness very likely belongs in this list. My favorite part of criticizing laziness is how quickly people jump to defend it based on edge cases. So let’s be a bit more nuanced before I later get far <em>less</em> nuanced. Laziness is <strong>obviously</strong> a good thing. Strictness is <strong>obviously</strong> a good thing. They also both suck. It depends on context and purpose. Each of them introduce different kinds of issues. The real question is: what’s a more sensible default? We’ll get to that another time.</p>
<p>I called this section partial functions. Am I having a senior moment? Maybe, but I intentionally started with laziness. In a strict language, function calls can result in exceptions being thrown, segfaulting occurring, or panicking. (And if I write a “Rust: The Bad Parts”, believe me, I’ll be mentioning panicking.) The fact that a function <em>acts</em> like it can successfully perform something, but in fact fails in a predictable way (like failing a <code>HashMap</code> lookup), it should be reflected at the type level. If not, ya dun goofed.</p>
<p>Also, if you have a language that doesn’t let you reflect this information at the type level: ya dun goofed.</p>
<p>Partial functions are the antithesis of this concept. They allow you to say “yeah dude, I can <em>totally</em> give you the first value in an empty list.” Partial functions are like politicians: you can tell they’re lying because their lips are moving. (“But Michael,” you say. “Functions don’t have lips!” Whatever, I’m waxing poetical.)</p>
<p>Alright, so plenty of languages screw this up. Haskell tells those languages “hold my beer.”</p>
<p><img src="https://www.snoyman.com/static/images/holdmybeer.jpg"></p><p>Haskell screws up partial functions way, way worse than other languages:</p>
<ol>
<li>It promotes a whole bunch of them in the standard libraries and <code>Prelude</code>.</li>
<li>Some libraries, like <code>vector</code> (I’m getting to you, don’t worry) make it <em>really</em> confusing by providing an <code>index</code> and <code>unsafeIndex</code> function. Hint: <code>index</code> isn’t really safe, it’s just less unsafe.</li>
<li>There’s no obvious way to search for usages of these partial functions.</li>
<li>And, by far, the worst…</li>
</ol>
<h3>Values are partial too!</h3>
<p>Only in a lazy language does this exist. You call a function. You get a result. You continue working. In any other non-lazy language, that means you have a value. If I have a <code>u32</code> in Rust, I actually have a <code>u32</code> in Rust. Null pointers in languages like C and Java somewhat muddy this situation, but at least primitive types are really there if they say they’re there.</p>
<p>No, not Haskell. <code>x :: Int</code> may in fact not exist. It’s a lie. <code>let x = head [] :: [Int]</code> is a box waiting to explode. And you find out <em>much</em> later. And it’s even worse than that. <code>let alice = Person { name = "Alice", age = someAge }</code> may give you a valid <code>Person</code> value. You can evaluate it. But Cthulhu help you if you evaluate <code>age alice</code>. Maybe, just maybe, <code>someAge</code> is a bottom value. Boom! You’ve smuggled a dirty bomb out.</p>
<p>I’m not advocating for removing laziness in Haskell. In fact I’m not really advocating for much of anything in this series. I’m just complaining, because I like complaining.</p>
<p>But <em>if</em> I was to advocate some changes:</p>
<ul>
<li>Deprecate partial functions</li>
<li>Introduce a naming scheme for partial functions to be more obvious</li>
<li>Introduce a compiler warning to note partial function use (with a pragma to turn off specific usages)</li>
<li>Warn by default on partial pattern matches</li>
<li>Advocate strict data fields by default</li>
</ul>
<h3>But ackshualllly, infinite loops</h3>
<p>Someone’s gonna say it. So I’ll say it. Yes, without major language changes, you can’t prevent partial functions. You can’t even detect them, unless Turing was wrong (and I have my suspicions.) But Haskell community, please, please learn this lesson:</p>
<p><strong>DON’T LET THE PERFECT BE THE ENEMY OF THE GOOD</strong></p>
<p>We can get rid of many of the most common partial functions trivially. We can detect many common cases by looking for partial pattern matches and usage of <code>throw</code> (again, horribly named function). “But we can’t get everything” doesn’t mean “don’t try to get something.”</p>
<h2>Hubris</h2>
<p>Given what I just said, we Haskellers have a lot of hubris. Each time you say “if it compiles it works,” a thunk dies and collapses into a blackhole. We’ve got plenty of messes in Haskell that don’t sufficiently protect us from ourselves. The compiler can only do as good a job as our coding standards and our libraries allow.</p>
<p>“But Haskell’s at least better than languages like PHP.” I mean, obviously I agree with this, or I’d be writing PHP. But since I’m being ridiculously hyperbolic here, let me make a ridiculous claim:</p>
<blockquote>
<p><strong>PHP is better than Haskell, since at least you don’t get a false sense of security</strong></p>
<p><em>- Michael Snoyman, totally 100% what he actually believes, you should totally quote this out of context</em></p>
</blockquote>
<p>I’ve said this so many times. So I’ll say it again. Using a great language with safety features is one tiny piece of the puzzle.</p>
<ul>
<li>Did you get the software requirements right?</li>
<li>Did you leverage the type system to prevent the bugs you’re trying to prevent?</li>
<li>Do your underlying libraries have bugs?</li>
<li>Did you find a way to implement a function with correct types but incorrect semantics?</li>
<li>Did you host the thing on a dinky server sitting under your desk and forget that you have power outages on a daily basis?</li>
<li>Did you forget to write a single test case?</li>
<li>Do your test cases actually test anything meaningful?</li>
</ul>
<p>There are <em>so many ways</em> for software to fail outside the purview of the type system. We’ve got to stop thinking that somehow Haskell (or, for that matter, Rust, Scala, and other strongly typed languages) are some kind of panacea. Seriously: the PHP people at least know their languages won’t protect them from anything. We should bring some of that humility back to Haskell.</p>
<p>Haskell provides me tools to help prevent certain classes of bugs, so I can spend more of my time catching a bunch of other bugs that I’m absolutely going to write. Because I’m dumb. And we need to remember: we’re all dumb.</p>
<h2>More partial functions!</h2>
<p>You know what’s worse than partial functions? Insidiously partial functions. We’ve all been screaming about <code>head</code> and <code>tail</code> for years. My hackles rise every time I see a <code>read</code> instead of <code>readMaybe</code>. I can’t remember the last time I saw the <code>!!</code> operator in production code.</p>
<p>But there are plenty of other functions that are just as dangerous, if not more so. More dangerous because they aren’t well known to be partial. They are commonly used. People don’t understand why they’re dangerous. And they fail only in edge cases that people aren’t thinking about.</p>
<p>Exhibit A: I present <code>decodeUtf8</code>. (Thanks <a href="https://twitter.com/kerckhove_ts/status/1321390954172063745?s=20">Syd</a>.)</p>
<p>Go ahead, search your codebase. Be dismayed that you’ve found it present.</p>
<p>What’s wrong with <code>decodeUtf8</code>? As we established last time, character encoding crap breaks stuff in production. UTF-8 works about 99% of the time, especially for people in Western countries. You’ll probably forget to even test for it. And that function looks so benign: <code>decodeUtf8 :: ByteString -&gt; Text</code>.</p>
<p><strong>DO NOT BE FOOLED</strong></p>
<p>This function is a ticking time bomb. Use <code>decodeUtf8'</code> (yes, it’s named that badly, just like <code>foldl'</code>) and explicitly handle error cases. Or use I/O functions that explicitly handle UTF-8 decoding errors and throw a runtime exception.</p>
<p>“I can’t believe Michael still thinks runtime exceptions are a good idea.” I’ll get to that another time. I don’t really believe they’re a good idea. I believe they are omnipresent, better than bottom values, and our least-bad-option.</p>
<h2>Law-abiding type classes</h2>
<p>Now I’ve truly lost it. What in tarnation could be wrong with law-abiding type classes? They’re good, right? Yes, they are! The section heading is complete clickbait. Haha, fooled you!</p>
<p>There’s a concept in the Haskell community that all type classes should be law-abiding. I’ve gone to the really bad extreme opposing this in the past with early versions of <code>classy-prelude</code>. In my defense: it was an experiment. But it was a bad idea. I’ve mostly come around to the idea of type classes being lawful. (Also, the original namespacing issues that led to <code>classy-prelude</code> really point out a much bigger bad part of Haskell, which I’ll get to later. Stay tuned! Hint: Rust beat us again.)</p>
<p>Oh, right. Speaking of Rust: they do <em>not</em> believe in law-abiding type classes. There are plenty of type classes over there (though they call them <code>trait</code>s) that are completely ad-hoc. I’m looking at you, <code>FromIterator</code>. This is Very, Very Bad of course. Or so my Haskell instincts tell me. And yet, it makes code Really, Really Good. So now I’m just confused.</p>
<p>Basically: I think we need much more nuanced on this in the Haskell community. I’m leaning towards my <em>very</em> original instincts having been spot on. So:</p>
<ul>
<li>Law abiding type classes: great</li>
<li>Flippantly non-law-abiding type classes ala the original <code>classy-prelude</code>: bad</li>
<li>“You know what I meant” typeclasses like <code>ToContent</code> in Yesod: also great</li>
</ul>
<p>This isn’t exactly in line with a “bad part” of Haskell. Up until now I’ve been giving a nuanced reflection on my journeys in Haskell. Let me try something better then. Ahem.</p>
<p><strong>DON’T LECTURE ME ON LAW ABIDING TYPE CLASSES AND FLAGRANTLY VIOLATE LAWS</strong></p>
<p>I’m staring at you, <code>Eq Double</code>. No, you cannot do equality on a <code>Double</code>. (And thanks again to Syd for this idea.) Rust, again, Got It Right. See <code>PartialEq</code> vs <code>Eq</code>. Floating point values do not allow for total equality. This makes things like <code>Map Double x</code> dangerous. Like, super dangerous. Though maybe not as dangerous as <code>HashMap Double x</code>, which deserves its own rant later.</p>
<p>So come down from your high horses. We don’t have law abiding type classes. We have “if I close my eyes and pretend enough then maybe I have law abiding type classes.”</p>
<h2>Unused import warnings</h2>
<p>Haskell has a dumb set of default warnings enabled. (“I think you mean GHC, one implementation of Haskell, not Haskell the language itself.” Uh-huh.) How can we <em>not</em> generate a warning for a partial pattern match? Come on! ADTs and pattern matching is <em>the</em> killer feature to first expose people to. And it’s a total lie: the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039758</guid>
            <pubDate>Mon, 09 Nov 2020 20:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Statusly - Automate slack DND when you join a zoom meeting/gCal event]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25039692">thread link</a>) | @statusly
<br/>
November 9, 2020 | https://www.statusly.app/why-statusly?ref=hn | <a href="https://web.archive.org/web/*/https://www.statusly.app/why-statusly?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.statusly.app/why-statusly?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039692</guid>
            <pubDate>Mon, 09 Nov 2020 20:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark Godot with Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039494">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html | <a href="https://web.archive.org/web/*/https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently started looking into using Rust and the <a href="https://godotengine.org/">Godot</a> Game Engine for developing games. A very quick experiment recently was to compare performance of GDScript, Visual scripting and Rust for the same task.</p>



<p>It is simple: Let us just draw a ton of lines to have a lot of traffic between our code and the engine:</p>

<p><img src="http://extrawurst.github.io/assets/godot-rust-benchmark/result.png" alt="res"></p>

<p>In fact it is so many lines that we end up with a filled circle. Nothing beautiful, this is just a benchmark afterall 👌</p>



<p>Let us look at the contenders:</p>
<ul>
  <li>gdscript</li>
  <li>visual script</li>
  <li>gdnative (rust)</li>
</ul>

<p><strong>GDScript</strong> is the official scripting language shipping with Godot.</p>

<p><strong>Visual Script</strong> is the official node based way to visually script in Godot (think Unreal Blueprint or Unity Bolt)</p>

<p><strong>GDNative</strong> is the official C-Api to access Godot from escentially any language. We are using <a href="https://github.com/godot-rust/godot-rust">Godot-Rust</a> to be able to compile shared libraries from Rust code to interface with Godot.</p>

<hr>

<p>The entire test with all three options can be found on github: <a href="https://github.com/extrawurst/godot-rust-benchmark">extrawurst/godot-rust-benchmark</a></p>

<p>Rerun it for yourself :)</p>

<h2 id="gdscript">GDScript</h2>

<p>Let’s start with the official way of doing things in Godot - using GDScript:</p>

<div><div><pre><code><span>extends</span> <span>CanvasItem</span>

<span># how many lines to draw? (this can be adjusted from the editor UI)</span>
<span>export</span> <span>var</span> <span>cnt</span> <span>=</span> <span>6000</span>
<span># this is the center point</span>
<span>export</span> <span>var</span> <span>start</span> <span>=</span> <span>Vector2</span><span>(</span><span>250</span><span>,</span><span>250</span><span>)</span>
<span># radius (line length)</span>
<span>export</span> <span>var</span> <span>rad</span> <span>=</span> <span>200</span>

<span>func</span> <span>_draw</span><span>():</span>
	<span># lets measure the runtime</span>
	<span>var</span> <span>startTime</span> <span>=</span> <span>OS</span><span>.</span><span>get_ticks_usec</span><span>()</span>

	<span>var</span> <span>cntf</span> <span>=</span> <span>float</span><span>(</span><span>cnt</span><span>)</span>
	<span>for</span> <span>n</span> <span>in</span> <span>range</span><span>(</span><span>cnt</span><span>):</span>
		<span>var</span> <span>x</span> <span>=</span> <span>sin</span><span>(</span><span>n</span><span>/</span><span>cntf</span> <span>*</span> <span>360.0</span><span>)</span><span>*</span><span>rad</span>
		<span>var</span> <span>y</span> <span>=</span> <span>cos</span><span>(</span><span>n</span><span>/</span><span>cntf</span> <span>*</span> <span>360.0</span><span>)</span><span>*</span><span>rad</span>
		<span>draw_line</span><span>(</span>
			<span>start</span><span>,</span> 
			<span>start</span><span>+</span><span>Vector2</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>),</span> 
			<span>Color</span><span>(</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>),</span> 
			<span>1</span><span>,</span>
			<span>false</span><span>)</span>
	
	<span>print</span><span>(</span><span>"bench: "</span> <span>+</span> <span>String</span><span>(</span><span>OS</span><span>.</span><span>get_ticks_usec</span><span>()</span> <span>-</span> <span>startTime</span><span>))</span>

<span>func</span> <span>_process</span><span>(</span><span>_delta</span><span>):</span>
	<span>update</span><span>()</span>
</code></pre></div></div>

<h2 id="visual-script">Visual Script</h2>

<p>The following screenshot shows the same logic in a visual node based way:</p>

<p><img src="http://extrawurst.github.io/assets/godot-rust-benchmark/visualscript.png" alt="vs"></p>

<p>We immediately see how this is more verbose but at least it is possible and it even just crashed once on me 🙈</p>

<h2 id="gdnative-rust">GDNative (Rust)</h2>

<p>We are using <a href="https://github.com/godot-rust/godot-rust">Godot-Rust</a> for this.</p>

<div><div><pre><code><span>#[export]</span>
<span>fn</span> <span>_</span><span>draw</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>owner</span><span>:</span> <span>&amp;</span><span>CanvasItem</span><span>)</span> <span>{</span>
	<span>let</span> <span>start_time</span> <span>=</span> <span>OS</span><span>::</span><span>godot_singleton</span><span>()</span><span>.get_ticks_usec</span><span>();</span>

	<span>let</span> <span>cntf</span> <span>=</span> <span>self</span><span>.cnt</span> <span>as</span> <span>f32</span><span>;</span>

	<span>for</span> <span>n</span> <span>in</span> <span>0</span><span>..</span><span>self</span><span>.cnt</span> <span>{</span>
		<span>let</span> <span>x</span> <span>=</span> <span>f32</span><span>::</span><span>sin</span><span>(</span><span>n</span> <span>as</span> <span>f32</span> <span>/</span> <span>cntf</span> <span>*</span> <span>360.0</span><span>)</span> <span>*</span> <span>self</span><span>.rad</span><span>;</span>
		<span>let</span> <span>y</span> <span>=</span> <span>f32</span><span>::</span><span>cos</span><span>(</span><span>n</span> <span>as</span> <span>f32</span> <span>/</span> <span>cntf</span> <span>*</span> <span>360.0</span><span>)</span> <span>*</span> <span>self</span><span>.rad</span><span>;</span>
		<span>let</span> <span>target</span> <span>=</span> <span>Vector2</span><span>::</span><span>new</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>+</span> <span>self</span><span>.start</span><span>;</span>

		<span>owner</span><span>.draw_line</span><span>(</span>
			<span>self</span><span>.start</span><span>,</span> 
			<span>target</span><span>,</span> 
			<span>Color</span><span>::</span><span>rgb</span><span>(</span><span>0.0</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>),</span> 
			<span>1.0</span><span>,</span> 
			<span>false</span><span>)</span>
	<span>}</span>

	<span>godot_print!</span><span>(</span>
		<span>"bench: {}"</span><span>,</span>
		<span>OS</span><span>::</span><span>godot_singleton</span><span>()</span><span>.get_ticks_usec</span><span>()</span> <span>-</span> <span>start_time</span>
	<span>);</span>
<span>}</span>
</code></pre></div></div>



<p>I am not going to further comment on the ergonomics of either language. I really did this for two reasons: 1) can we do all we need in the visual script and 2) how does performance compare between the alternatives</p>

<p>Here are the timings:</p>

<table>
  <thead>
    <tr>
      <th>type</th>
      <th>usecs</th>
      <th>slowdown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gdnative (rust)</td>
      <td>~980 usec</td>
      <td>-</td>
    </tr>
    <tr>
      <td>gdscript</td>
      <td>~5112 usec</td>
      <td>5x</td>
    </tr>
    <tr>
      <td>visual script</td>
      <td>~7099 usec</td>
      <td>7x</td>
    </tr>
  </tbody>
</table>

<p><sub><sup>(executed on a macbook 2016 3,3 GHz i7, 16 GB Ram, Intel Iris 550 and Godot 3.2.3, avg. over 10 runs)</sup></sub></p>

<p>On twitter people noted that this might change with Godot 4.0 and the support of type checking in gdscript. This could be interesting to measure once 4.0 is released.</p>

<p>For now my conclusion is:</p>

<ul>
  <li>GDScript is easy and quick to learn</li>
  <li>Visual Scripting in Godot works although it feels a little instable</li>
  <li>Godot-Rust is a clear alternative to write entire Godot games in</li>
</ul>

<p>Of course point 3) is limited to people coming with a Rust background otherwise the Rust part in it is a clear challenge to learn first.</p>

      </div></div>]]>
            </description>
            <link>https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039494</guid>
            <pubDate>Mon, 09 Nov 2020 20:29:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The election of the doge]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25039470">thread link</a>) | @flannery
<br/>
November 9, 2020 | https://generalist.academy/2020/11/06/the-election-of-the-doge/ | <a href="https://web.archive.org/web/*/https://generalist.academy/2020/11/06/the-election-of-the-doge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4574">
	
		<p>
By  on <a href="https://generalist.academy/2020/11/06/the-election-of-the-doge/" title="7:00 am" rel="bookmark"><time datetime="2020-11-06T07:00:00+13:00">November 6, 2020</time></a>	• 
	</p>
	<section>

<p>The ruler of Medieval Venice was chosen by an exceptionally complex ten-step process of alternating random lots and elections.</p>



<div><figure><img loading="lazy" data-attachment-id="4580" data-permalink="https://generalist.academy/kms3898/" data-orig-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg" data-orig-size="2043,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Statens Museum for Kunst&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Canaletto (1697-1768), Dogen og det store raad forsamlede i Sala del consiglio maggior i Dogepaladset, About 1763&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;Public Domain (CC0)&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;kms3898&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kms3898" data-image-description="" data-medium-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300" data-large-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=656" src="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024" alt="Grand Council" width="768" height="451" srcset="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024 1024w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=768 768w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1536 1536w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=150 150w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300 300w" sizes="(max-width: 768px) 100vw, 768px"><figcaption><a href="https://commons.wikimedia.org/wiki/File:Canaletto_-_The_Doge_and_Grand_Council_in_Sala_del_Maggior_Consiglio_-_KMS3898_-_Statens_Museum_for_Kunst.jpg">Canaletto</a>, Public domain, via Wikimedia Commons</figcaption></figure></div>



<p>A few weeks ago I wrote about modern <a href="https://generalist.academy/2020/10/17/electoral-fairness/">democratic electoral systems</a>, and a couple of days ago I wrote about the complexities of the <a href="https://generalist.academy/2020/11/04/the-unpopular-president/">American Electoral College</a>. Today I wanted to go even further back, to the Medieval Venetian Republic. There, the selection of a new leader – the doge – was one of the more complex and baffling electoral processes in history. And even so, though this be madness, yet there is method in’t.</p>



<p>The Great Council of Venice was a large legislative body made up of a relatively small number of noble families. Obviously, everyone wanted to be the doge, but the council was very keen to avoid behind-the-scenes bribery, dirty deals, intrigue, and extended and contentious campaigns. To achieve this, the election of the doge went through multiple steps, all designed to reduce power consolidation.</p>



<p>First, thirty members of the Great Council were chosen at random. Then nine of those thirty were chosen, again randomly. Those nine members picked the next set: forty people from the Great Council. And those forty? Twelve, randomly picked from their number, moved on to the next step. Those twelve chose twenty-five; those twenty-five were randomly pared down to just nine. Having fun yet?</p>



<p>This set of nine members chose forty-five more; eleven were picked – again at random – from those forty-five. The eleven chose forty-one members. Those forty-one (finally!) voted for the doge. </p>



<p>There were some additional checks against skulduggery. Each noble family couldn’t have more than one member in each group, and members couldn’t vote for their own relatives. Every time a set of members voted for the next group, more than a simple majority was required: around three quarters of the voting group had to agree. (For the final election, just 25 of the 41 had to agree.)</p>



<p>To recap, this is the process:<br>Great Council &gt; 30 &gt; 9 &lt; 40 &gt; 12 &lt; 25 &gt; 9 &lt; 45 &gt; 11 &lt; 41 &gt; 1.</p>



<p>Because of this complexity, the chances of rigging or buying the election were greatly reduced, minority concerns were not buried by the majority, but neither was the majority tyrannized by the minority. Today we only use this kind of random process in jury selection and citizen’s assemblies.</p>



<p>[Thanks to Alistair S. for suggesting this topic.]</p>



<ul><li><a href="https://en.wikipedia.org/wiki/Doge_of_Venice">Doge of Venice</a></li><li><a href="https://en.wikipedia.org/wiki/Sortition">Sortition</a></li><li><a href="https://doi.org/10.1007/s10602-019-09290-6">How the Republic of Venice chose its doge: Lot-based elections and supermajority rule</a></li></ul>
		<p>Categories: <a href="https://generalist.academy/category/places/europe/" rel="category tag">Europe</a> <a href="https://generalist.academy/category/history/" rel="category tag">History</a> <a href="https://generalist.academy/category/history/medieval-history/" rel="category tag">Medieval history</a> <a href="https://generalist.academy/category/places/" rel="category tag">Places</a> <a href="https://generalist.academy/category/politics-law/" rel="category tag">Politics &amp; law</a>		</p>
	<div>
		<p><img alt="" src="https://0.gravatar.com/avatar/f7eb82f9df252be8cad1a3993809331d?s=100&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D100&amp;r=G" height="100" width="100"></p><h3>The Generalist</h3>
		<p>I live in Auckland, New Zealand, and am curious about most things.</p>
	</div>
	</section>
</article></div>]]>
            </description>
            <link>https://generalist.academy/2020/11/06/the-election-of-the-doge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039470</guid>
            <pubDate>Mon, 09 Nov 2020 20:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye USA]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25039397">thread link</a>) | @polote
<br/>
November 9, 2020 | https://larrysalibra.com/goodbye-usa/ | <a href="https://web.archive.org/web/*/https://larrysalibra.com/goodbye-usa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://larrysalibra.com/content/images/size/w300/2020/11/IMG_1166.jpeg 300w,
                            https://larrysalibra.com/content/images/size/w600/2020/11/IMG_1166.jpeg 600w,
                            https://larrysalibra.com/content/images/size/w1000/2020/11/IMG_1166.jpeg 1000w,
                            https://larrysalibra.com/content/images/size/w2000/2020/11/IMG_1166.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://larrysalibra.com/content/images/size/w2000/2020/11/IMG_1166.jpeg" alt="Goodbye USA">
</figure>
<section>
<div>
<p>A few weeks ago, when I was trying to open an account at a financial institution here in Hong Kong, someone noticed I was born in the USA and my account was denied.</p><p>They wrote “I regret to inform you at this time we are unable to accept bank wire deposits/withdrawals from US citizens. For more information, please refer to our article: Restricted nationalities and countries.” While this is a common experience for Americans living abroad, one I’ve experienced many times before, it was a mistake, a mistake that reminded me to write this blog post.</p><p>A few days ago, I received a rather passive-aggressive email from one of my banks asking me to “let us know about your tax connection to the United States” with the threat of closing my account if I don’t. Another common experience for Americans living abroad, another mistake and another reminder to write this post.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/Screen-Shot-2020-10-22-at-5.52.02-PM.png" alt=""></figure><p>Tomorrow, Americans will vote to choose one of two candidates no one really likes. I’m not allowed to vote this time around because two years ago, I finally rid myself of the burden that is American citizenship.</p><h2 id="a-hard-story-to-tell">A hard story to tell</h2><p>I’ve tried to write this blog post a number of times over the past two years. I’ve written entire drafts of this post from scratch more than once and never published them, unhappy with the tone or the content or the narrative or worried about the reaction of people I’ve never met on the internet. Perhaps it was the years of brainwashing…I mean, “<a href="https://en.wikipedia.org/wiki/Civic_education_in_the_United_States">civic education</a>”…in US public schools that has scared my psyche and made me afraid of what the tribe will do when it finds out I’ve deserted them. Having to say the "Pledge of Allegiance" every day during one's childhood before he knows what the words "pledge" or "allegiance" even mean really does a job on one's mind.</p><p>I want to tell my story because I hope that it will benefit others on their journey towards personal freedom just the stories of others benefited me.</p><p>Our story starts about a year ago, in October 2019.</p><p>It's 2am on a Saturday morning in Hong Kong and I can't sleep. My body thinks it's still in Paris after two weeks in Europe. One year ago today, I also couldn't sleep but for a different reason. I was tossing and turning from stress the night before what I thought was going to be the biggest decision of my life: to give up US citizenship.</p><p>After over 11 years living outside of the USA, I had made an appointment on October 12, 2018, at the US Consulate in Hong Kong to go through the process known as "expatriation" or "renouncing US citizenship."</p><p>This was the second appointment in the process. The first had been a few weeks prior, on August 31, 2018. You see, the United States wants you to believe that giving up US citizenship is a Big Deal, and in many ways it is! You lose a whole bunch of rights granted by citizenship such as no longer being able live or work in the country unless you get a visa. In this day and age of passports, visas and borders, (<a href="https://www.nationalgeographic.com/travel/features/a-history-of-the-passport/">it didn't used to be like this</a>! travel used to be free as in freedom!) if you didn't have another citizenship, you could become "stateless" with nowhere to go and no way to get past borders to get there. To someone like me who was born and raised in suburban Ohio, this felt like a Big Deal.</p><p>What they don’t tell you, is that you’re also freed from a number of coercive obligations you never agreed to that other countries don’t impose on their citizens by opting-out of US citizenship. They tell you it's all pain with no gain.</p><p>To drive home the Big Dealness of the decision, the State Department made me make two appointments at the consulate to make sure I got their point. And I had to make the appointments well in advance as they were fully booked for months. I wasn’t the only American in Hong Kong trying to exit.</p><p>At the first appointment, a nice vice consul named Rachel took me in to a tiny interview room complete with an American flag in the nondescript Garden Road compound. Our interview began with Rachel hitting her head on the phone on the wall quite hard as she was sitting down and me asking her with a bit of a shock, “OMG, are you okay?!?!" After a minute or so of rubbing her head and grimacing, she was fine and we started with our interview.</p><p>She roughly followed a script that is specified in the <a href="https://fam.state.gov/fam/07fam/07fam1260.html">US State Department's Foreign Affairs Manual</a>. She asked me questions about myself and my decision. Where was I from? (Ohio) How long have I lived abroad? (Since May, 2007) Where does my family live? (My parents live in the US and my brother lives in Bulgaria). Did I have another citizenship and passport? (Yes, Italian) Why did I want to give up US citizenship? (It's complicated, but I didn't feel American anymore and when visiting the US anymore I felt like a tourist).</p><p>After the questions she started reading me a list of what came off as warnings and disclaimers to make sure I knew what I was getting myself into:</p><ul><li>Any children I had wouldn't become US citizens</li><li>Might not be able to travel to the US again</li><li>Wouldn't be able to live or work in the US an appropriate visa</li><li>I would still have to file for and pay taxes that I owe</li><li>If I didn't have another citizenship I could be come stateless</li></ul><p>She then instructed me to take a couple of weeks for a "period of reflection" (this is required according to State Department regulations) and handed me a packet of papers to review listing the consequences giving up my blue passport and outlining the tax implications.</p><p>Where better to go to reflect and get some clarity on my decision to exit the US than to visit a country struggling with its own exit decision, the United Kingdom? So I headed off to the UK for a short vacation followed by a work trip in London.</p><p>By the time I made my first August appointment, I'd already made the decision - I'd been thinking about it for years and had done a ton of research and due diligence. I'd read a lot about other people's experiences and thinking. I was particularly inspired by bitcoin investor Roger Ver's story and Balajis Srinivasan's talk on <a href="https://www.youtube.com/watch?v=cOubCHLXT6A">Voice vs Exit</a>.</p><p>I was most concerned about losing the right to live and work in the US - it seems so many people want this right and that they're willing to go through great pain and inconvenience to get it. However, I hadn't ever used this right in the almost 20 years of my adult life. I’d always competed on the global market without the benefit of “work authorization” protecting me from competition of “aliens.” As life long entrepreneur and a strong advocate of remote work, I didn't ever see myself wanting to sign up for some office job in the States. But would I want to live there?</p><h2 id="a-tourist-in-my-own-country">A tourist in my own country</h2><p>In 2016, I flew to California and rented a car to do some due diligence on the country I was thinking of leaving. I spent a month driving across the US and back, taking in the sites and visiting places I thought I might like to live. The natural beauty of America and her parks is breathtaking. While it is amazing to visit and even vacation for a few weeks, it wasn’t someplace I'd want to live. New York and Chicago were my favorite cities, but cold climate and snow is a turn off as is the crumbling infrastructure and confiscatory tax rates.</p><p>A number of tech friends moved to Austin for the low tax and warm weather, so I stopped there for a few days. After over a decade in Asia, Austin hardly seems big enough to even be called a city. My impression was that it is a bunch of suburban sprawl with some bigger buildings in the middle. And I much prefer being on islands surrounded by water instead of landlocked.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/IMG_5406.jpeg" alt=""></figure><p>In June of 2018, I took a vacation to America’s only state that is “a bunch of islands surrounded by water,” Hawaii. I had found memories of visiting the Aloha state as a child and wanted to make sure that I wasn't missing out on some future destiny where Larry becomes a Hawaiian like George Clooney in <em>The Descendants</em>. The nature was nice, but the poverty, crime and remoteness from everywhere made it not very attractive as a future home.</p><p>I'd discussed the decision with family and friends. Friends ranged from very unhappy to mildly supportive to downright enthusiastic. My brother, also an entrepreneur who has lived outside of the States for more than a decade, was understanding of the challenges the USA imposes on its entrepreneurs abroad and very supportive. My parents were skeptical that it was the right decision. They'd lived their whole lives in the USA and grown up on stories of World War II valor and of their grandparents who had struggled to immigrate to the United States for a better life. They shared their views with me but never gave me any pressure and let me make my own decision.</p><h2 id="the-oath">The oath</h2><p>October 12, 2018, my second appointment in the renunciation process, quickly arrived. I couldn’t really sleep the night before. I was nervous about both the appointment and a <a href="https://blog.blockstack.org/a-path-to-decentralization/">big work announcement</a>. Lots of things were changing.</p><p>In the morning, I woke up and took a taxi to the US consulate for my appointment. Here’s a picture of me before the appointment. You can see the stress in my face.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/IMG_8562.jpeg" alt=""></figure><p>After entering the consulate and going through security, the first step of the appointment was paying the fee: US$2,350. You can’t free yourself from the Land of the Free without having the cash money to buy your freedom. Think of the renunciation fee as an emancipation fee, a lot of money, but a small price to pay for freedom.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/https---blogs-images.forbes.com-robertwood.jpg" alt=""></figure><p>The actual renunciation ceremony was sort of an out-of-body blur. I felt like I was watching myself in the little room with the American flag renouncing my allegiance (which of course the US education system forces children who don’t know what the word “allegiance” means to “pledge”) to the USA.</p><p>The consular official told me that they would take my US passport and hold on to it until the State Department approved my renunciation and return it to me canceled along with my Certificate of Loss of Nationality (CLN) at some later date. He advised that if I needed to travel to the US I might be able to borrow the passport for a trip if the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://larrysalibra.com/goodbye-usa/">https://larrysalibra.com/goodbye-usa/</a></em></p>]]>
            </description>
            <link>https://larrysalibra.com/goodbye-usa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039397</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Recalculate a Spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25039393">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://lord.io/blog/2020/spreadsheets/ | <a href="https://web.archive.org/web/*/https://lord.io/blog/2020/spreadsheets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Let’s say I’m ordering burritos for my two friends while they quar up in Jersey City, and want to calculate the total price of my order:</p>
<p><img alt="screenshot of spreadsheet; burrito price is listed as $7, burrito price w ship as burrito price plus $3, num burritos is 2, and total is num burritos times burrito price w ship, for a total of $20" src="https://lord.io/images/2020/anchors_0.png"></p>
<p>It’s a little confusing to follow the flow of data in a spreadsheet when it’s written like that, so I hope you don’t mind this equivalent diagram that represents it as a graph:</p>
<p><img alt="the previous spreadsheet represented as a graph, with arrows from one cell to another replacing the spreadsheet cell references" src="https://lord.io/images/2020/anchors_1.png"></p>
<p>We’re rounding the cost of an El Farolito super vegi burrito to $8, so assuming the per-burrito delivery toll remains at just $2 per burrito, it looks like the total for our two burritos will be $20.</p>
<p>Oh no, I completely forgot! One of my friends loves to wolf down multiple burritos at a time, so I actually want to place an order for three burritos. If I update <code>Num Burritos</code>, a naïve spreadsheet engine might recompute the entire document, recalculating first the cells with no inputs, and then recalculating any cell whose inputs are ready until we’ve finished every cell. In this case, we’d first calculate <code>Burrito Price</code> and <code>Num Burritos</code>, then <code>Burrito Price w Ship</code>, and then a new final <code>Total</code> of $30.</p>
<p><img alt="same as previous graph, but num burritos is updated to 3, and every cell is tagged as &quot;recalc&quot;" src="https://lord.io/images/2020/anchors_2.png"></p>
<p>This simple strategy of recalculating the whole document may sound wasteful, but it’s actually already <em>better</em> than VisiCalc, the first spreadsheet software ever made, and the first so-called “killer app”, responsible for popularizing the Apple II. VisiCalc would repeatedly recalculate cells from left-to-right and top-to-bottom, sweeping over them again and again until none of them changed. Despite this “interesting” algorithm, VisiCalc remained the dominant spreadsheet software for four years. Its reign ended in 1983, when Lotus 1-2-3 swept the market with “natural-order recalculation”, <a href="https://aresluna.org/attached/computerhistory/articles/spreadsheets/tenyearsofrowsandcolumns">as described by Tracy Robnett Licklider in Byte Magazine</a>:</p>
<blockquote>
<p>Lotus 1-2-3 exploited natural-order recalculation, although it also supported VisiCalc’s row- and column-order modes. Natural-order recalculation maintained a cell dependency list and recalculated a cell before recalculating cells that depended on it.</p>
</blockquote>
<p>Lotus 1-2-3 implemented the “recalculate everything” strategy we’ve shown above, and for the first decade of spreadsheets, that was as good as it got. Yes, we recalculate every cell in the document, but at least we only recalculate every cell once.</p>
<h2>but what about “burrito price w ship”</h2>
<p>Great point, header 2. In my three burrito example there’s no reason to recompute <code>Burrito Price w Ship</code>, because changing the number of burritos we order can’t possibly influence the per-burrito price. In 1989, one of Lotus’ competitors realized this, and created SuperCalc5, presumably naming it after the theory of super burritos at the core of this algorithm. SuperCalc5 recalculated “only cells dependent on changed cells”, which would make updating the burrito count look more like this:</p>
<p><img alt="same as prior graph, with burrito count updated from 2 to 3, but now only the two affected cells &quot;num burritos&quot; and &quot;total&quot; are tagged as recalc" src="https://lord.io/images/2020/anchors_3.png"></p>
<p>By only updating a cell when one of its inputs changes, we can avoid recalculating <code>Burrito Price w Ship</code>. In this case, it saves just a single addition, but on larger spreadsheets it can save quite a bit of time! Unfortunately, we now have another problem. Let’s say my friends now want meat burritos, which cost a dollar more, and simultaneously El Farolito adds a $2 fee paid per-order, regardless of how many burritos you order. Before any formula outputs are recalculated, our graph might look like this:</p>
<p><img alt="same as prior graph (after burrito count update finished calculation), but now burrito price is being updated from $8 to $9, and simultaneously total is updated from &quot;burrito price w ship * num burritos&quot; to &quot;burrito price w ship * num burritos + $2 fee&quot;" src="https://lord.io/images/2020/anchors_4.png"></p>
<p>Since there are two updated cells here, we have a problem. Should we recalculate <code>Burrito Price</code> first, or <code>Total</code>? Ideally, we first calculate <code>Burrito Price</code>, notice that its output has changed, then recalculate <code>Burrito Price w Ship</code>, and finally recalculate <code>Total</code>. However, if we instead recalculate <code>Total</code> first, we’ll have to recalculate it a second time once the new $9 burrito price propagates down. If we don’t calculate cells in the right order, this algorithm isn’t better than recalculating the whole document. In some cases, it’s as slow as VisiCalc!</p>
<p>Clearly, it’s important for us to figure out the right order to update our cells. Broadly, there are two solutions to this problem: dirty marking and topological sorting.</p>
<p>This first solution involves marking all cells downstream from an edit as dirty. For instance, when we update <code>Burrito Price</code>, we would mark the downstream cells <code>Burrito Price w Ship</code> and <code>Total</code> as dirty, even before doing any recalculations:</p>
<p><img alt="same as prior graph with the two updates, but now three nodes are tagged as dirty: &quot;burrito price&quot;, &quot;burrito price w ship&quot;, and &quot;total&quot;. would also like to apologize for the rather confusing image alt text so far; it's really hard to write these for graph diagrams!! if you are a screen reader user and have advice on better ways to do this, would love to hear from you." src="https://lord.io/images/2020/anchors_5.png"></p>
<p>Then, in a loop, we find a dirty cell that has no dirty inputs, and recalculate it. When there are no dirty cells left, we’re done! This solves our ordering problem. There’s one downside though — if a cell is recalculated and we find its new output to be the same as its previous output, we’ll still recalculate downstream cells! A little bit of extra logic can avoid actually running the formula trouble in this case, but we unfortunately still waste time marking and unmarking a lot of cells as dirty.</p>
<p>The second solution is topological sorting. If a cell has no inputs, we mark its height as 0. If a cell has inputs, we mark its height as the maximum of the heights of its inputs, plus one. This guarantees all cells have a greater height than any of their inputs, so we just keep track of all cells with a changed input, always choosing the cell with the lowest height to recalculate first:</p>
<p><img alt="same as prior graph with the two updates, but instead of dirty tags, now every node has a height tag. &quot;burrito price&quot; and &quot;num burritos&quot;, the two cells with no in-nodes, have height 0. &quot;burrito price w ship&quot; has height 1. &quot;total&quot; has height 2." src="https://lord.io/images/2020/anchors_6.png"></p>
<p>In our double-update example, <code>Burrito Price</code> and <code>Total</code> would be initially added to the recalculation heap. <code>Burrito Price</code> has lesser height, and would be recalculated first. Since its output changes, we then would add <code>Burrito Price w Ship</code> to the recalculation heap, and since it too has less height than <code>Total</code>, it would be recalculated before we finally recalculate <code>Total</code>.</p>
<p>This has a big advantage over the first solution: no cell is ever marked dirty unless one of its inputs actually change. However, it requires we keep all cells pending recalculation in sorted order. If we use a heap, this results in an <code>O(n log n)</code> slowdown, so in the worst case, asymptotically slower than Lotus 1-2-3’s strategy of recalculating everything.</p>
<p>Modern-day Excel uses <a href="https://docs.microsoft.com/en-us/office/client-developer/excel/excel-recalculation">a combination of dirty marking and topological sorting</a>, which you can read more about in their docs.</p>
<h2>demand-driven complications</h2>
<p>We’ve now more or less reached the algorithms used in modern-day spreadsheet recalculation. Unfortunately, I suspect there is basically no business case to be made for ever improving it further. The few people with the problem “my Excel spreadsheet is too slow” have already written enough Excel formulas that migration to any other platform is impossible. Fortunately, I have no understanding of business, and so we’re going to look at further improvements anyway.</p>
<p>Beyond caching, one of the cool aspects of a spreadsheet-style computation graph is we can only calculate the cells that we’re interested in. This is sometimes called lazy computation, or demand-driven computation. As a more concrete example, here’s a slightly expanded burrito spreadsheet graph. This example is the same as before, but we’ve added what is best described as “salsa calculations”. Each burrito contains 40 grams of salsa, and we perform a quick multiplication to know how much salsa is in our entire order. In this case, since our order has three burritos, there’s a total of 120 grams of salsa in our entire order.</p>
<p><img alt="a new graph. similar structure to the old graph, but there are two new nodes: &quot;salsa per burrito&quot;, which is set to the constant &quot;40 grams&quot;, and &quot;salsa in order&quot;, which is &quot;salsa per burrito&quot; times &quot;num burritos&quot;" src="https://lord.io/images/2020/anchors_7.png"></p>
<p>Of course, astute readers will have spotted the problem here already: knowing the total weight of salsa in an order is a pretty useless measurement. Who cares that it’s 120 grams? What am I supposed to do with this information?? Unfortunately, a regular spreadsheet would waste cycles calculating <code>Salsa In Order</code>, even if we don’t want it recalculated most of the time.</p>
<p>This is where demand-driven recalculation can help. If we could somehow specify that we’re only interested in the output of <code>Total</code>, we could only recompute that cell and its dependencies, and skip touching <code>Salsa In Order</code> and <code>Salsa Per Burrito</code>. Let’s call <code>Total</code> an <em>observed</em> cell, since we’re trying to look at its output. We can also call both <code>Total</code> and its three dependencies <em>necessary</em> cells, since they’re necessary to compute some observed cell. <code>Salsa In Order</code> and <code>Salsa Per Burrito</code> would be aptly described as <em>unnecessary</em>.</p>
<p>Some folks on the Rust team created the <a href="https://github.com/salsa-rs/salsa">Salsa</a> framework to solve this problem, clearly naming it after the unnecessary salsa calculations their computers were wasting cycles on. Salsa is really cool, and I’m sure <a href="https://www.youtube.com/watch?v=i_IhACacPRY">they can explain</a> how it works better than I can. Very roughly, they use revision numbers to track whether a cell needs recalculation. Any mutation to a formula or input increments the global revision number, and every cell tracks two revisions: <code>verified_at</code> to track the revision its output was last brought up-to-date, and <code>changed_at</code> to track the revision its output last actually changed.</p>
<p><img alt="our new graph, but now there's a title of &quot;current revision: R6&quot;. each cell is tagged with a change revision and verified at revision. all change revisions are R1, except &quot;salsa per burrito&quot;, which is R6. all verified at revisions are R6, except &quot;salsa in order&quot;, which is R1." src="https://lord.io/images/2020/anchors_8.png"></p>
<p>When the user indicates they’d like a fresh value for <code>Total</code>, we’d first recursively recalculate any cell necessary to <code>Total</code>, skipping cells if their <code>last_updated</code> revision is equal to the global revision. Once the dependencies of <code>Total</code> are up-to-date, we only rerun the actual formula in <code>Total</code> if either <code>Burrito Price w Ship</code> or <code>Num Burrito</code> have a <code>changed_at</code> revision greater than the <code>verified_at</code> revision of <code>Total</code>. This is great for Salsa’s purposes in the rust-analyzer, where simplicity is important and each cell takes a significant amount of time to compute. However, we can see the disadvantages in our burrito graph above — if <code>Salsa Per Burrito</code> constantly changes, our global revision number will frequently tick up. This will make each observation of <code>Total</code> walk the three cells necessary to it, even though none of those cells have actually changed. No formulas will be recalculated, but if the graph is large, repeatedly walking all of a cell’s dependencies could get expensive.</p>
<h2>faster demand-driven solutions</h2>
<p>Instead of inventing new algorithms for demand-driven spreadsheets, what if we instead draw from the two classical spreadsheet algorithms mentioned earlier: dirty marking and topological sorting? As you might imagine, a demand-driven model complicates both of these, but both are still viable.</p>
<p>Let’s first look at dirty marking. As before, when we change a cell’s formula, we mark all downstream cells as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lord.io/blog/2020/spreadsheets/">https://lord.io/blog/2020/spreadsheets/</a></em></p>]]>
            </description>
            <link>https://lord.io/blog/2020/spreadsheets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039393</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nginx conf snippet for blocking bad bots]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039051">thread link</a>) | @rogue_man_coder
<br/>
November 9, 2020 | https://www.michaellapan.com/blocking-bad-bots | <a href="https://web.archive.org/web/*/https://www.michaellapan.com/blocking-bad-bots">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-1a93d359="" data-v-0291b861=""> <p>A co-worker of mine recently brought up an issue to me where one of our clients were exceeding their monthly ShipperHQ api quota. The wordpress site in question was exceeding their 10k api limit from ShipperHQ for 2 months in a row. The combined traffic and sales from the site did not justify hitting 10k api calls monthly. This is where I came in to see if there was a deeper issue.</p> <p>My first steps were to identify when the api call was sent to ShipperHQ on the site. After some navigating though some pages and keeping an eye on the network tab. I determined the call was being sent out when visiting the checkout.</p> <p>With that known it was time to see where the hits were coming from.</p> <ol><li><p>My first though was to check if the shopping checkout was indexed somewhere on google. A quick google dork later <code>site:site-url inurl:checkout</code> I had found that there were a few entries for the shopping checkout url on google. We removed them and edited the robots.txt</p></li> <li><p>Ensured ShipperHQ was not on the cart page.</p></li> <li><p>lastly, after analyzing the logs I had found a large number of bots that did not respect the robots.txt. Becuase of this they were adding items to carts and navigating to the checkout as they crawled the site. This is where I believed the majortity of the ShipperHQ api hits were coming from. Now its time to block these bots entirly from the site.</p></li></ol> <h4>Nginx Config</h4> <p>To block these malicious bots from crawling the site you can do the following in your nginx conf. While this isnt perfect, as the person with the crawler can change the user_agent. It will atleast get the majortity of them</p> <p>If you need to find the user_agent just go to your nginx access.log and it will show it there. Copy and past it to this list (+restart nginx) and it will start blocking.</p> <p>Specifically for nginx we send back http code 444 for any matching user agents. Code 444 is</p> <blockquote><p>CONNECTION CLOSED WITHOUT RESPONSE</p></blockquote> <pre><code>  if ($http_user_agent ~* (360Spider|80legs.com|Abonti|AcoonBot|Acunetix|adbeat_bot|AddThis.com|adidxbot|ADmantX|AhrefsBot|AngloINFO|Antelope|BaiduSpider|BeetleBot|billigerbot|binlar|bitlybot|BlackWidow|BLP_bbot|BoardReader|Bolt\ 0|BOT\ for\ JCE|Bot\ mailto\:craftbot@yahoo\.com|casper|CazoodleBot|CCBot|checkprivacy|ChinaClaw|chromeframe|Clerkbot|Cliqzbot|clshttp|CommonCrawler|comodo|CPython|crawler4j|Crawlera|CRAZYWEBCRAWLER|Curious|Custo|CWS_proxy|Default\ Browser\ 0|diavol|DigExt|Digincore|DIIbot|discobot|DISCo|DoCoMo|DotBot|Download\ Demon|DTS.Agent|EasouSpider|eCatch|ecxi|EirGrabber|Elmer|EmailCollector|EmailSiphon|EmailWolf|Exabot|ExaleadCloudView|ExpertSearchSpider|ExpertSearch|Express\ WebPictures|ExtractorPro|extract|EyeNetIE|Ezooms|F2S|FastSeek|feedfinder|FeedlyBot|FHscan|finbot|Flamingo_SearchEngine|FlappyBot|FlashGet|flicky|Flipboard|g00g1e|Genieo|genieo|GetRight|GetWeb\!|GigablastOpenSource|GozaikBot|Go\!Zilla|Go\-Ahead\-Got\-It|GrabNet|grab|Grafula|GrapeshotCrawler|GTB5|GT\:\:WWW|harvest|heritrix|HMView|HomePageBot|HTTP\:\:Lite|HTTrack|HubSpot|ia_archiver|icarus6|IDBot|id\-search|IlseBot|Image\ Stripper|Image\ Sucker|Indigonet|Indy\ Library|integromedb|InterGET|InternetSeer\.com|Internet\ Ninja|IRLbot|ISC\ Systems\ iRc\ Search\ 2\.1|jakarta|Java|JetCar|JobdiggerSpider|JOC\ Web\ Spider|Jooblebot|kanagawa|KINGSpider|kmccrew|larbin|LeechFTP|libwww|Lingewoud|LinkChecker|linkdexbot|LinksCrawler|LinksManager\.com_bot|linkwalker|LinqiaRSSBot|LivelapBot|ltx71|LubbersBot|lwp\-trivial|Mail.RU_Bot|masscan|Mass\ Downloader|maverick|Maxthon$|Mediatoolkitbot|MegaIndex|MegaIndex|megaindex|MFC_Tear_Sample|Microsoft\ URL\ Control|microsoft\.url|MIDown\ tool|miner|Missigua\ Locator|Mister\ PiX|mj12bot|Mozilla.*Indy|Mozilla.*NEWT|MSFrontPage|msnbot|Navroad|NearSite|NetAnts|netEstate|NetSpider|NetZIP|Net\ Vampire|NextGenSearchBot|nutch|Octopus|Offline\ Explorer|Offline\ Navigator|OpenindexSpider|OpenWebSpider|OrangeBot|Owlin|PageGrabber|PagesInventory|panopta|panscient\.com|Papa\ Foto|pavuk|pcBrowser|PECL\:\:HTTP|PeoplePal|Photon|PHPCrawl|planetwork|PleaseCrawl|PNAMAIN.EXE|PodcastPartyBot|prijsbest|proximic|psbot|purebot|pycurl|QuerySeekerSpider|R6_CommentReader|R6_FeedFetcher|RealDownload|ReGet|Riddler|Rippers\ 0|rogerbot|RSSingBot|rv\:1.9.1|RyzeCrawler|SafeSearch|SBIder|Scrapy|Scrapy|SeaMonkey$|search.goo.ne.jp|SearchmetricsBot|search_robot|SemrushBot|Semrush|SentiBot|SEOkicks|SeznamBot|ShowyouBot|SightupBot|SISTRIX|sitecheck\.internetseer\.com|siteexplorer.info|SiteSnagger|skygrid|Slackbot|Slurp|SmartDownload|Snoopy|Sogou|Sosospider|spaumbot|Steeler|sucker|SuperBot|Superfeedr|SuperHTTP|SurdotlyBot|Surfbot|tAkeOut|Teleport\ Pro|TinEye-bot|TinEye|Toata\ dragostea\ mea\ pentru\ diavola|Toplistbot|trendictionbot|TurnitinBot|turnit|URI\:\:Fetch|urllib|Vagabondo|Vagabondo|vikspider|VoidEYE|VoilaBot|WBSearchBot|webalta|WebAuto|WebBandit|WebCollage|WebCopier|WebFetch|WebGo\ IS|WebLeacher|WebReaper|WebSauger|Website\ eXtractor|Website\ Quester|WebStripper|WebWhacker|WebZIP|Web\ Image\ Collector|Web\ Sucker|Wells\ Search\ II|WEP\ Search|WeSEE|Wget|Widow|WinInet|woobot|woopingbot|worldwebheritage.org|Wotbox|WPScan|WWWOFFLE|WWW\-Mechanize|Xaldon\ WebSpider|XoviBot|yacybot|YandexBot|Yandex|YisouSpider|zermelo|Zeus|zh-CN|ZmEu|ZumBot|ZyBorg) ) {
      return 444;
  }
</code></pre> <h4>Wordpress modification</h4> <p>If your are unable to modify your nginx conf. Another option would be to have shipping calculation on a different page.</p> <p>Or, using jQuery, to only load the ShipperHQ calculations after the shipping address is filled out.</p></div></div>]]>
            </description>
            <link>https://www.michaellapan.com/blocking-bad-bots</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039051</guid>
            <pubDate>Mon, 09 Nov 2020 19:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does consciousness even make sense?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25039045">thread link</a>) | @algoholix
<br/>
November 9, 2020 | http://niklasbuehler.com/blog/consciousness.html | <a href="https://web.archive.org/web/*/http://niklasbuehler.com/blog/consciousness.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<header>

<span><a href="http://niklasbuehler.com/">Home</a> / <a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</header>
<p><em>08.11.2020</em></p>
<!--
## How does consciousness even make sense?
<a id='1604845992' href='/log/#1604845992'>#1604845992 2020 Nov 08, 15:33</a>
-->
<p>I don’t think the current state of “artificial intelligence” really has proven that it earns the great title of <em>intelligence</em>, as I believe it’s all still just a sophisticated application of statistics on large amounts of data. I prefer the title “machine learning”, as in my opinion that describes the process of adjusting the parameters of statistical methods based on the given data adequately.</p>
<p>I’m not even sure if intelligence and consciousness can be simulated by a computer. Because if they could, then the speed of execution surely wouldn’t matter to that fact, right? And if speed didn’t matter, one could just as well represent the (deterministic!) calculations of a finite computer on a piece of paper or by arranging some stones on a large field. Granted, it’d be somewhat slower than a modern computer and the paper would have to be sufficiently large, but in the end flipping bits, drawing on paper, and moving rocks in a systematic way is just the same when it comes to representing computation. So that’d mean if we arranged a bunch of stones on a large field in a certain pattern and then used some fancy (but deterministic) rules to move them around, we’d create consciousness?! I can’t really believe that’s true.</p>
<p><em>But how is a human brain any different??</em> In the end it’s also just biological wires exchanging electricity (+ some chemistry added to the process)…<br>
I can’t really grasp that. Do my thoughts make sense? Where’s the flaw?</p>
<hr>
<h3 id="join-the-discussion-on-hacker-news">Join the discussion on Hacker News</h3>
<p>There’s an interesting discussion about this text on <a href="https://news.ycombinator.com/item?id=25039045">Hacker News</a>.</p>

<hr>

<h3>Want to leave a comment?</h3>
<p>
If you want to give me some feedback or share your opinion, please contact me via <a href="mailto:hi@niklasbuehler.com?subject=Comment%20on%20Blog:%20consciousness" target="_blank">email</a>.
</p>

<hr>

<p>
<span>© Niklas Bühler, 2020</span>
<span><a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</p>



</div>]]>
            </description>
            <link>http://niklasbuehler.com/blog/consciousness.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039045</guid>
            <pubDate>Mon, 09 Nov 2020 19:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote every day for 365 days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25038739">thread link</a>) | @patwalls
<br/>
November 9, 2020 | https://patwalls.com/365-blog-posts-in-365-days | <a href="https://web.archive.org/web/*/https://patwalls.com/365-blog-posts-in-365-days">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/365-blog-posts-in-365-days</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038739</guid>
            <pubDate>Mon, 09 Nov 2020 19:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Security Maturity Roadmap [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25038422">thread link</a>) | @sciurus
<br/>
November 9, 2020 | https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf | <a href="https://web.archive.org/web/*/https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038422</guid>
            <pubDate>Mon, 09 Nov 2020 19:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boost Visual Accessibility by Auto Flipping Text Color Based on Background Color]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25038248">thread link</a>) | @karenying7
<br/>
November 9, 2020 | https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color | <a href="https://web.archive.org/web/*/https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <a href="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ac56/boost-visual-accessibility-by-changing-your-text-color.webp 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d3be9/boost-visual-accessibility-by-changing-your-text-color.webp 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e46b2/boost-visual-accessibility-by-changing-your-text-color.webp 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/ccc09/boost-visual-accessibility-by-changing-your-text-color.webp 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ff5a/boost-visual-accessibility-by-changing-your-text-color.png 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e85cb/boost-visual-accessibility-by-changing-your-text-color.png 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png" alt="gradient.png" title="gradient.png" loading="lazy">
      </picture>
  </a>
    </span><em><a href="http://gradient-png.netlify.app/" target="_blank">gradient.png</a></em></p>
<p><strong>If you’re only looking for implementation, <a href="#implementation">skip ahead</a>.</strong></p>
<p>Often times, an app, website, or diagram will write text over a colored background. If the text is white, and the background is light colored, then it’s always hard to read. Visual accessibility is becoming an increasingly hot topic. In this post, we’ll quantify this contrast between two colors, define a standard for the minimum allowed contrast, and implement a way to dynamically change text color based on background color!</p>
<h2 id="wcag-and-contrast-ratio"><a href="#wcag-and-contrast-ratio" aria-label="wcag and contrast ratio permalink"></a>WCAG and Contrast Ratio</h2>
<p>The <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) aims to provide a set of standards for developers around the world — to make web content more accessible to people with disabilities.</p>
<p>Perhaps the most obvious applications of the WCAG are in visual accessibility. In this post we’ll dive into the world of color contrast, specifically looking at scenarios where you would want to dynamically change text color based on the background color to increase readability.</p>
<p>In order to understand the motivation behind this, we have to first understand how to quantify the contrast between two colors.</p>
<h3 id="mathematical-representation-of-colors"><a href="#mathematical-representation-of-colors" aria-label="mathematical representation of colors permalink"></a>Mathematical Representation of Colors</h3>
<p>A crash course:</p>
<ul>
<li>
<p>Each color can be represented as a triplet of red, green, and blue values, with values between 0 and 255 — this is the <a href="https://en.wikipedia.org/wiki/RGB_color_space" target="_blank">RGB color space</a></p>
<ul>
<li>Red is <code>(255, 0, 0)</code>, green is <code>(0, 255, 0)</code>, blue is <code>(0, 0, 255)</code></li>
<li>Eggplant purple is equal parts red and blue so it’s <code>(128, 0, 128)</code></li>
</ul>
</li>
<li>
<p>To digitize this RGB triplet, we have <a href="https://en.wikipedia.org/wiki/Web_colors#Hex_triplet" target="_blank">HTML (Hex) color codes</a> which HTML/CSS uses</p>
<ul>
<li>Hex codes are just the concatenation of RGB values in hexadecimal, often preceded by a <code>#</code></li>
<li>Red = <code>#ff0000</code>, green = <code>#00ff00</code>, blue = <code>#0000ff</code>, eggplant purple = <code>#800080</code></li>
</ul>
</li>
<li>Hex codes only represent the RGB color space. There are many other color spaces such as <a href="https://en.wikipedia.org/wiki/HSL_and_HSV" target="_blank">HSL/HSV/HSB</a>, <a href="https://en.wikipedia.org/wiki/CIELAB_color_space" target="_blank">CIELAB</a>, and <a href="https://en.wikipedia.org/wiki/CMYK_color_model" target="_blank">CMYK</a>. Each serve different purposes but we’ll be focusing on RGB for this post.</li>
</ul>
<h3 id="luminance"><a href="#luminance" aria-label="luminance permalink"></a>Luminance</h3>
<p>Now that we have a way to quantify colors, we can talk about <a href="https://en.wikipedia.org/wiki/Relative_luminance" target="_blank">luminance</a>, the preceived brightness of a color. This is the L value in the HSL color space. The mathematical model for <a href="https://planetcalc.com/7779/" target="_blank">calculating luminance</a> is rather convoluted so I’ll be glazing over it. All we need to know is that</p>
<ul>
<li>it can be derived from an RGB triplet — it’s roughly a weighted average of the three values</li>
<li>can be represented as a percentage, or as a value from 0 - 1 (what we’ll be using)</li>
<li>white is 1, black is 0</li>
</ul>
<h3 id="contrast-ratio"><a href="#contrast-ratio" aria-label="contrast ratio permalink"></a>Contrast Ratio</h3>
<p>The final piece is to calculate the <a href="https://webaim.org/articles/contrast/" target="_blank">contrast ratio</a> between two colors, namely between a text color and its background color here.</p>
<p>The formula is just the quotient between the brighter color’s luminance (the bigger number) and the dark color’s luminance (the smaller number):</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>ratio</mtext><mo>=</mo><mfrac><mrow><mi>l</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mrow><mtext mathvariant="bold">brighter</mtext><mtext>&nbsp;color)</mtext></mrow><mo>+</mo><mn>0.05</mn></mrow><mrow><mi>l</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mrow><mtext mathvariant="bold">darker</mtext><mtext>&nbsp;color</mtext></mrow><mo stretchy="false">)</mo><mo>+</mo><mn>0.05</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\textrm{ratio} = \frac{lum(\textrm{\textbf{brighter} color)} + 0.05}{lum(\textrm{\textbf{darker} color}) + 0.05}</annotation></semantics></math></span></span></span></p><p>The contrast ratio of any two colors ranges between 1 (two of the same colors) to 21 (black and white).</p>
<p><strong>The WCAG requires a contrast ratio of at least 4.5.</strong></p>
<p>There are three exceptions to the above rule:</p>
<ul>
<li><strong>Large text</strong>: larger text is easier to read. Thus the required ratio is at least 3.0 for bigger text.</li>
<li><strong>Incidental</strong>: text that is for decorative/design purposes, not really meant to be read</li>
<li><strong>Logos</strong></li>
</ul>
<h4 id="examples"><a href="#examples" aria-label="examples permalink"></a>Examples</h4>
<ul>
<li>Contrast ratio of <strong>12.98</strong> (good job Karen)</li>
<li><span>Contrast ratio of <b>4.77</b> (I could do better for links)</span></li>
<li><span>Contrast ratio of <b>4.54</b> (barely passable by WCAG standards)</span></li>
<li><span>Contrast ratio of <b>1.61</b> (terrible)</span></li>
<li><span>Contrast ratio of <b>1.15</b> (brb my eyes are crying)</span></li>
</ul>
<h2 id="use-cases"><a href="#use-cases" aria-label="use cases permalink"></a>Use Cases</h2>
<p>Before we get started coding, let’s run through a couple of examples of where you would want to dynamically changed the text color based on its background color.</p>
<h3 id="facebook-messenger"><a href="#facebook-messenger" aria-label="facebook messenger permalink"></a>Facebook Messenger</h3>
<p>Messenger is what spurred this post. Facebook lets you change the chat default color from the typical blue to a variety of different options. This theme color the background color of all the messages <em>you</em> send. The messages you receive are typically with a dark gray background.</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/8ac56/fb-blue.webp 240w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/d3be9/fb-blue.webp 480w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/7dbce/fb-blue.webp 686w" sizes="(max-width: 686px) 100vw, 686px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/8ff5a/fb-blue.png 240w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/e85cb/fb-blue.png 480w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png 686w" sizes="(max-width: 686px) 100vw, 686px" type="image/png">
        <img src="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png" alt="Facebook Messenger blue" title="Facebook Messenger blue" loading="lazy">
      </picture>
  </a>
    </span></span><br><em>Default Messenger blue</em></p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/8ac56/fb-palette.webp 240w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/d3be9/fb-palette.webp 480w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/f0cd5/fb-palette.webp 893w" sizes="(max-width: 893px) 100vw, 893px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/8ff5a/fb-palette.png 240w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/e85cb/fb-palette.png 480w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png 893w" sizes="(max-width: 893px) 100vw, 893px" type="image/png">
        <img src="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png" alt="Facebook Messenger palette" title="Facebook Messenger palette" loading="lazy">
      </picture>
  </a>
    </span></span><br> <em>Messenger solid palette. They change this up pretty often. Gradient options are also available 😍</em></p>
<p>However, regardless of what color you pick, the text color is infuriatingly white.</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/8ac56/fb-yellow.webp 240w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/d3be9/fb-yellow.webp 480w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/f686e/fb-yellow.webp 692w" sizes="(max-width: 692px) 100vw, 692px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/8ff5a/fb-yellow.png 240w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/e85cb/fb-yellow.png 480w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png 692w" sizes="(max-width: 692px) 100vw, 692px" type="image/png">
        <img src="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png" alt="Facebook Messenger yellow" title="Facebook Messenger yellow" loading="lazy">
      </picture>
  </a>
    </span></span><br> <em>Yellow theme in a group chat</em></p>
<p>Remember this example from before? <span>Contrast ratio of <b>1.61</b> (terrible)</span> 🙁</p>
<h3 id="gradientpng"><a href="#gradientpng" aria-label="gradientpng permalink"></a>gradient.png</h3>
<p>I made a gradient generating <a href="http://gradient-png.netlify.app/" target="_blank">app</a> a while back. The app lets you choose colors for a gradient, displaying the hex codes on the current colors.</p>
<p><span>
      <a href="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ac56/boost-visual-accessibility-by-changing-your-text-color.webp 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d3be9/boost-visual-accessibility-by-changing-your-text-color.webp 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e46b2/boost-visual-accessibility-by-changing-your-text-color.webp 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/ccc09/boost-visual-accessibility-by-changing-your-text-color.webp 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ff5a/boost-visual-accessibility-by-changing-your-text-color.png 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e85cb/boost-visual-accessibility-by-changing-your-text-color.png 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png" alt="gradient.png" title="gradient.png" loading="lazy">
      </picture>
  </a>
    </span><em>Imperfect implementation for <a href="http://gradient-png.netlify.app/" target="_blank">gradient.png</a></em></p>
<p>I calculated luminance for the colors and choose dark text if the luminance was below 50%. However, I didn’t apply the contrast ratio formula, so this is an imperfect implementation. Still better than nothing though?</p>
<h3 id="charts-and-diagrams"><a href="#charts-and-diagrams" aria-label="charts and diagrams permalink"></a>Charts and Diagrams</h3>
<p><img src="https://d2mvzyuse3lwjc.cloudfront.net/doc/en/UserGuide/images/Bar_Of_Pie_Chart/Bar_Of_Pie_Chart.png?v=83483" alt="Pie chart"><em>Rando pie chart I found <a href="https://www.originlab.com/doc/Origin-Help/Bar-Of-Pie" target="_blank">online</a></em></p>
<p>This concept might be most useful when you’re displaying data with different colors, and you want to write text over each section.</p>
<h2 id="implementation"><a href="#implementation" aria-label="implementation permalink"></a>Implementation</h2>
<h3 id="-1-prereqs"><a href="#-1-prereqs" aria-label=" 1 prereqs permalink"></a>-1. Prereqs</h3>
<p>This tutorial assumes you have some knowledge of JavaScript and React. All good? Let’s get started 👍🏼</p>
<h3 id="0-getting-started"><a href="#0-getting-started" aria-label="0 getting started permalink"></a>0. Getting Started</h3>
<p>We’ll use <a href="https://create-react-app.dev/docs/getting-started/" target="_blank">Create React App</a> to create, bundle, and run the project:</p>
<div data-language="bash"><pre><code>$ npx create-react-app dyn-change-text-color
$ <span>cd</span> dyn-change-text-color
$ <span>npm</span> start</code></pre></div>
<h3 id="1-colorbox-component"><a href="#1-colorbox-component" aria-label="1 colorbox component permalink"></a>1. ColorBox Component</h3>
<p>We’re going to create a <code>ColorBox</code> component which takes a hex code string as a prop. For consistency sake, we will always store hex codes variables without the pound sign, only adding it when necessary for CSS/HTML. The hex code prop will determine the background color of the component.</p>
<p>Create a new file called <code>ColorBox.js</code>:</p>

<div data-language="jsx"><pre><code><span>import</span> <span>'./ColorBox.css'</span><span>;</span>

<span>const</span> <span>ColorBox</span> <span>=</span> <span>(</span><span><span>{</span> backgroundHex <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span>
      <span>className</span><span><span>=</span><span>'</span>colorbox-container<span>'</span></span>
      <span>style</span><span><span>=</span><span>{</span><span>{</span> backgroundColor<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span> <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>export</span> <span>default</span> ColorBox<span>;</span></code></pre></div>
<p>Here we use inline styling to dynamically change the background color based on the component’s prop. We also render the hex code as text in the component.</p>
<p>Let’s import <code>ColorBox</code> to <code>App.js</code> and pass in black as the <code>backgroundHex</code> prop:</p>

<div data-language="jsx"><pre><code><span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>'</span>App<span>'</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span><span>ColorBox</span></span> <span>backgroundHex</span><span><span>=</span><span>'</span>2a2b2e<span>'</span></span> <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Add some styling:</p>

<div data-language="css"><pre><code><span>.colorbox-container</span> <span>{</span>
  <span>display</span><span>:</span> flex<span>;</span>
  <span>align-items</span><span>:</span> center<span>;</span>
  <span>justify-content</span><span>:</span> center<span>;</span>
  <span>height</span><span>:</span> 70px<span>;</span>
  <span>width</span><span>:</span> 200px<span>;</span>
  <span>border-radius</span><span>:</span> 5px<span>;</span>
  <span>padding</span><span>:</span> 20px<span>;</span>
  <span>text-align</span><span>:</span> center<span>;</span>
<span>}</span></code></pre></div>
<p>If we run the app, we should see:</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/8ac56/colorbox-1.webp 240w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/d3be9/colorbox-1.webp 480w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/20eb0/colorbox-1.webp 754w" sizes="(max-width: 754px) 100vw, 754px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/8ff5a/colorbox-1.png 240w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/e85cb/colorbox-1.png 480w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png 754w" sizes="(max-width: 754px) 100vw, 754px" type="image/png">
        <img src="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png" alt="ColorBox" title="ColorBox" loading="lazy">
      </picture>
  </a>
    </span></span><br><em><code>ColorBox</code> component with black as <code>backgroundHex</code> prop. Terrible contrast ratio with default black text</em></p>
<h3 id="2-so-oop-much-modularization"><a href="#2-so-oop-much-modularization" aria-label="2 so oop much modularization permalink"></a>2. So OOP, Much Modularization</h3>
<h4 id="21-templates"><a href="#21-templates" aria-label="21 templates permalink"></a>2.1 Templates</h4>
<p>To better organize our code, we’re gonna create a <code>Color</code> class as well as some helper methods. Let’s set these up:</p>

<div data-language="js"><pre><code><span>import</span> <span>{</span> textColors<span>,</span> contrastRatioPair<span>,</span> getLuminance <span>}</span> <span>from</span> <span>'./helper'</span><span>;</span>

<span>export</span> <span>default</span> <span>class</span> <span>Color</span> <span>{</span>
  
  <span>constructor</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>hex <span>=</span> hex<span>;</span>
  <span>}</span>

  
  <span>get</span> <span>luminance</span><span>(</span><span>)</span> <span>{</span><span>}</span>

  
  <span>contrastRatioWith</span><span>(</span><span>hex2</span><span>)</span> <span>{</span><span>}</span>

  
  <span>get</span> <span>textColor</span><span>(</span><span>)</span> <span>{</span><span>}</span>
<span>}</span></code></pre></div>

<div data-language="js"><pre><code><span>export</span> <span>const</span> textColors <span>=</span> <span>{</span>
  <span>BLACK</span><span>:</span> <span>'000000'</span><span>,</span>
  <span>WHITE</span><span>:</span> <span>'ffffff'</span><span>,</span>
<span>}</span><span>;</span>


<span>export</span> <span>function</span> <span>contrastRatioPair</span><span>(</span><span>hex1<span>,</span> hex2</span><span>)</span> <span>{</span><span>}</span>


<span>function</span> <span>hexToRGB</span><span>(</span><span>hex</span><span>)</span> <span>{</span><span>}</span>


<span>export</span> <span>function</span> <span>getLuminance</span><span>(</span><span>hex</span><span>)</span> <span>{</span><span>}</span></code></pre></div>
<p>Great, now we can start filling out these functions.</p>
<h4 id="22-luminance"><a href="#22-luminance" aria-label="22 luminance permalink"></a>2.2. Luminance</h4>
<p>As mentioned before, the luminance calculation is a bit messy. We need to first convert our 6 bit hex string to RGB values. To do so, we splice the string, and parse the substrings from hex to decimal:</p>

<div data-language="js"><pre><code>
<span>function</span> <span>hexToDecimal</span><span>(</span><span>hex_string</span><span>)</span> <span>{</span>
  <span>return</span> <span>parseInt</span><span>(</span>hex_string<span>,</span> <span>16</span><span>)</span><span>;</span>
<span>}</span>


<span>function</span> <span>hexToRGB</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
  <span>const</span> r <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>0</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>;</span>
  <span>const</span> g <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>2</span><span>,</span> <span>4</span><span>)</span><span>)</span><span>;</span>
  <span>const</span> b <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>4</span><span>,</span> <span>6</span><span>)</span><span>)</span><span>;</span>

  <span>return</span> <span>{</span> r<span>,</span> g<span>,</span> b <span>}</span><span>;</span>
<span>}</span></code></pre></div>
<p>We can then call <code>hexToRGB</code> in our luminance calculation. If you want to read more about exactly how to calculate, you can check out this <a href="https://planetcalc.com/7779/" target="_blank">calculator</a> or <a href="https://en.wikipedia.org/wiki/Relative_luminance" target="_blank">Wikipedia</a>. But if you just wanna trust me on this one, here’s the gross code:</p>

<div data-language="js"><pre><code>
<span>export</span> <span>function</span> <span>getLuminance</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
  <span>const</span> rgb <span>=</span> <span>hexToRGB</span><span>(</span>hex<span>)</span><span>;</span>

  <span>for</span> <span>(</span><span>const</span> key <span>in</span> rgb<span>)</span> <span>{</span>
    <span>let</span> c <span>=</span> rgb<span>[</span>key<span>]</span><span>;</span>
    c <span>/=</span> <span>255</span><span>;</span>

    c <span>=</span> c <span>&gt;</span> <span>0.03928</span> <span>?</span> Math<span>.</span><span>pow</span><span>(</span><span>(</span>c <span>+</span> <span>0.055</span><span>)</span> <span>/</span> <span>1.055</span><span>,</span> <span>2.4</span><span>)</span> <span>:</span> <span>(</span>c <span>/=</span> <span>12.92</span><span>)</span><span>;</span>

    rgb<span>[</span>key<span>]</span> <span>=</span> c<span>;</span>
  <span>}</span>

  <span>return</span> <span>0.2126</span> <span>*</span> rgb<span>.</span>r <span>+</span> <span>0.7152</span> <span>*</span> rgb<span>.</span>g <span>+</span> <span>0.0722</span> <span>*</span> rgb<span>.</span>b<span>;</span>
<span>}</span></code></pre></div>
<h4 id="23-contrast-ratio"><a href="#23-contrast-ratio" aria-label="23 contrast ratio permalink"></a>2.3. Contrast Ratio</h4>
<p>With our luminance function done, we can call it to calculate the contrast ratio between two colors with our division formula from before:</p>

<div data-language="js"><pre><code>
<span>export</span> <span>function</span> <span>contrastRatioPair</span><span>(</span><span>hex1<span>,</span> hex2</span><span>)</span> <span>{</span>
  <span>const</span> lum1 <span>=</span> <span>getLuminance</span><span>(</span>hex1<span>)</span><span>;</span>
  <span>const</span> lum2 <span>=</span> <span>getLuminance</span><span>(</span>hex2<span>)</span><span>;</span>

  <span>return</span> <span>(</span>Math<span>.</span><span>max</span><span>(</span>lum1<span>,</span> lum2<span>)</span> <span>+</span> <span>0.05</span><span>)</span> <span>/</span> <span>(</span>Math<span>.</span><span>min</span><span>(</span>lum1<span>,</span> lum2<span>)</span> <span>+</span> <span>0.05</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<h4 id="24-filling-out-colorjs"><a href="#24-filling-out-colorjs" aria-label="24 filling out colorjs permalink"></a>2.4. Filling out <code>Color.js</code></h4>
<p>We can now fill out the methods of the <code>Color</code> class with our helper methods:</p>

<div data-language="js"><pre><code>  
  <span>get</span> <span>luminance</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>getLuminance</span><span>(</span><span>this</span><span>.</span>hex<span>)</span><span>;</span>
  <span>}</span>

  
  <span>contrastRatioWith</span><span>(</span><span>hex2</span><span>)</span> <span>{</span>
    <span>return</span> <span>contrastRatioPair</span><span>(</span><span>this</span><span>.</span>hex<span>,</span> hex2<span>)</span><span>;</span>
  <span>}</span>

  
  <span>get</span> <span>textColor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>{</span> <span>BLACK</span><span>,</span> <span>WHITE</span> <span>}</span> <span>=</span> textColors<span>;</span>

    <span>return</span> <span>this</span><span>.</span><span>contrastRatioWith</span><span>(</span><span>BLACK</span><span>)</span> <span>&gt;</span> <span>this</span><span>.</span><span>contrastRatioWith</span><span>(</span><span>WHITE</span><span>)</span>
      <span>?</span> <span>BLACK</span>
      <span>:</span> <span>WHITE</span><span>;</span>
  <span>}</span></code></pre></div>
<p><code>textColor</code> computes the contrast ratio of the current color with black and white, and returns the color (black or white) that yields the highest contrast ratio.</p>
<h3 id="3-pulling-it-all-together"><a href="#3-pulling-it-all-together" aria-label="3 pulling it all together permalink"></a>3. Pulling it all Together</h3>
<p>Now we can turn back to our <code>ColorBox</code> component.</p>
<p>All we need to do is create a new <code>Color</code> object with the <code>backgroundHex</code> prop and call its appropriate properties/methods:</p>

<div data-language="jsx"><pre><code><span>const</span> backgroundColor <span>=</span> <span>new</span> <span>Color</span><span>(</span>backgroundHex<span>)</span><span>;</span>
<span>const</span> <span>{</span> textColor <span>}</span> <span>=</span> backgroundColor<span>;</span></code></pre></div>
<p>Then we can set the <code>color</code> CSS property of the div as <code>textColor</code>. I also added a couple of lines to display the current contrast ratio:</p>

<div data-language="jsx"><pre><code>  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span>
      <span>className</span><span><span>=</span><span>'</span>colorbox-container<span>'</span></span>
      <span>style</span><span><span>=</span><span>{</span><span>{</span> backgroundColor<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>,</span> color<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>textColor<span>}</span></span><span>`</span></span> <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>}</span><span>
      </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>Contrast ratio: </span><span><span>${</span>backgroundColor
        <span>.</span><span>contrastRatioWith</span><span>(</span>textColor<span>)</span>
        <span>.</span><span>toFixed</span><span>(</span><span>2</span><span>)</span><span>}</span></span><span>`</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<p>Now if you check out the app, it should look like this:</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ac56/colorbox-2.webp 240w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/d3be9/colorbox-2.webp 480w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/b5834/colorbox-2.webp 756w" sizes="(max-width: 756px) 100vw, 756px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ff5a/colorbox-2.png 240w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/e85cb/colorbox-2.png 480w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png 756w" sizes="(max-width: 756px) 100vw, 756px" type="image/png">
        <img src="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png" alt="ColorBox" title="ColorBox" loading="lazy">
      </picture>
  </a>
    </span></span><br><em>The …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color">https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color</a></em></p>]]>
            </description>
            <link>https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038248</guid>
            <pubDate>Mon, 09 Nov 2020 18:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API with NestJS #17. Offset and keyset pagination with PostgreSQL and TypeORM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25038192">thread link</a>) | @mwanago
<br/>
November 9, 2020 | https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/ | <a href="https://web.archive.org/web/*/https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article id="post-3395"><div><div> <p><time datetime="2020-11-09"> November 9, 2020 </time></p><ul><li>1. <a href="https://wanago.io/2020/05/11/nestjs-api-controllers-routing-module/" title="API with NestJS #1. Controllers, routing and the module structure">API with NestJS #1. Controllers, routing and the module structure</a></li><li>2. <a href="https://wanago.io/2020/05/18/api-nestjs-postgresql-typeorm/" title="API with NestJS #2. Setting up a PostgreSQL database with TypeORM">API with NestJS #2. Setting up a PostgreSQL database with TypeORM</a></li><li>3. <a href="https://wanago.io/2020/05/25/api-nestjs-authenticating-users-bcrypt-passport-jwt-cookies/" title="API with NestJS #3. Authenticating users with bcrypt, Passport, JWT, and cookies">API with NestJS #3. Authenticating users with bcrypt, Passport, JWT, and cookies</a></li><li>4. <a href="https://wanago.io/2020/06/01/api-nestjs-error-handling-validation/" title="API with NestJS #4. Error handling and data validation">API with NestJS #4. Error handling and data validation</a></li><li>5. <a href="https://wanago.io/2020/06/08/api-nestjs-serializing-response-interceptors/" title="API with NestJS #5. Serializing the response with interceptors">API with NestJS #5. Serializing the response with interceptors</a></li><li>6. <a href="https://wanago.io/2020/06/15/api-with-nestjs-6-looking-into-dependency-injection-and-modules/" title="API with NestJS #6. Looking into dependency injection and modules">API with NestJS #6. Looking into dependency injection and modules</a></li><li>7. <a href="https://wanago.io/2020/06/22/api-nestjs-relationships-postgres-typeorm/" title="API with NestJS #7. Creating relationships with Postgres and TypeORM">API with NestJS #7. Creating relationships with Postgres and TypeORM</a></li><li>8. <a href="https://wanago.io/2020/07/06/api-nestjs-unit-tests/" title="API with NestJS #8. Writing unit tests">API with NestJS #8. Writing unit tests</a></li><li>9. <a href="https://wanago.io/2020/07/13/api-nestjs-testing-services-controllers-integration-tests/" title="API with NestJS #9. Testing services and controllers with integration tests">API with NestJS #9. Testing services and controllers with integration tests</a></li><li>10. <a href="https://wanago.io/2020/08/03/api-nestjs-uploading-public-files-to-amazon-s3/" title="API with NestJS #10. Uploading public files to Amazon S3">API with NestJS #10. Uploading public files to Amazon S3</a></li><li>11. <a href="https://wanago.io/2020/08/10/api-nestjs-private-files-amazon-s3/" title="API with NestJS #11. Managing private files with Amazon S3">API with NestJS #11. Managing private files with Amazon S3</a></li><li>12. <a href="https://wanago.io/2020/09/07/api-nestjs-elasticsearch/" title="API with NestJS #12. Introduction to Elasticsearch">API with NestJS #12. Introduction to Elasticsearch</a></li><li>13. <a href="https://wanago.io/2020/09/21/api-nestjs-refresh-tokens-jwt/" title="API with NestJS #13. Implementing refresh tokens using JWT">API with NestJS #13. Implementing refresh tokens using JWT</a></li><li>14. <a href="https://wanago.io/2020/10/19/nestjs-performance-postgres-database-indexes/" title="API with NestJS #14. Improving performance of our Postgres database with indexes">API with NestJS #14. Improving performance of our Postgres database with indexes</a></li><li>15. <a href="https://wanago.io/2020/10/26/api-nestjs-transactions-postgresql-typeorm/" title="API with NestJS #15. Defining transactions with PostgreSQL and TypeORM">API with NestJS #15. Defining transactions with PostgreSQL and TypeORM</a></li><li>16. <a href="https://wanago.io/2020/11/02/api-nestjs-array-data-type-postgresql-typeorm/" title="API with NestJS #16. Using the array data type with PostgreSQL and TypeORM">API with NestJS #16. Using the array data type with PostgreSQL and TypeORM</a></li><li>17. API with NestJS #17. Offset and keyset pagination with PostgreSQL and TypeORM</li></ul><p>As our database grows, so do the results of our queries. Returning a lot of data in our API might not be the best approach performance-wise. Dividing our content into multiple pages and solutions like infinite scrolling have been around for quite some time. In this article, we explore ways of implementing pagination and point out their pros and cons.</p><p>You can find all of the code from this series in <a href="https://github.com/mwanago/nestjs-typescript">this repository</a>.</p><h2>Offset and Limit</h2><p>Let’s start with the following, straightforward query:</p><div id="crayon-5fad98ededb9c588710583" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p></div></td></tr></tbody></table></div></div><p>The above returns all of the records from the <span id="crayon-5fad98ededba5155044723"><span><span>post</span></span></span> table. To be sure about the order of the results, we sort them by id.</p><p>The first step in implementing pagination would be to limit the number of results. We can do that using the <span id="crayon-5fad98ededba7445947984"><span><span>LIMIT</span></span></span> statement.</p><div id="crayon-5fad98ededba9640577903" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p><p><span>LIMIT</span><span> </span>10</p></div></td></tr></tbody></table></div></div><p>Now, instead of getting all of the posts, we get just the first ten of them. This results in getting elements with ids from 1 to 10.</p><p>To have fully functional pagination, we need to specify the starting point of our query. To do that, we can use the <span id="crayon-5fad98ededbab296713094"><span><span>OFFSET</span></span></span> keyword. With it, we can say how many rows we want to skip.</p><div id="crayon-5fad98ededbae885605228" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p><p><span>OFFSET</span><span> </span>10</p><p><span>LIMIT</span><span> </span>10</p></div></td></tr></tbody></table></div></div><p>We omit the first ten posts with the above while still getting just ten posts as a result. This gives us elements with ids from 11 to 20.</p><p>If we would like to change the way we order elements while paginating, we need to modify our <span id="crayon-5fad98ededbb0001411195"><span><span>ORDER </span><span>BY</span></span></span> clause.</p><h3>Implementing offset and limit with TypeORM</h3><p>We want the users to provide the offset and the limit through query params. To implement this, let’s use the knowledge we’ve gained in previous parts of this series. This includes the usage of the <span id="crayon-5fad98ededbb2589835003"><span><span>class</span><span>-</span><span>validator</span></span></span> and the <span id="crayon-5fad98ededbb4516357630"><span><span>class</span><span>-</span><span>transformer</span></span></span>.</p><div id="crayon-5fad98ededbb6238595475" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>import</span><span> </span><span>{</span><span> </span><span>IsNumber</span><span>,</span><span> </span><span>Min</span><span>,</span><span> </span><span>IsOptional</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-validator'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>Type</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-transformer'</span><span>;</span></p><p><span>export</span><span> </span><span>class</span><span> </span><span>PaginationParams</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>0</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>We can now use the <span id="crayon-5fad98ededbb8488427338"><span><span>@</span><span>Query</span><span>(</span><span>)</span></span></span> decorator to inject the above parameters into our controller.</p><div id="crayon-5fad98ededbba547694134" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p></div></td><td><div><p><span>import</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>Controller</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>Get</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>UseInterceptors</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>ClassSerializerInterceptor</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>Query</span><span>,</span></p><p><span>}</span><span> </span><span>from</span><span> </span><span>'@nestjs/common'</span><span>;</span></p><p><span>import </span><span>PostsService </span><span>from</span><span> </span><span>'./posts.service'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>PaginationParams</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'../utils/types/paginationParams'</span><span>;</span></p><p><span>@</span><span>Controller</span><span>(</span><span>'posts'</span><span>)</span></p><p><span>@</span><span>UseInterceptors</span><span>(</span><span>ClassSerializerInterceptor</span><span>)</span></p><p><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>PostsController</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>constructor</span><span>(</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>postsService</span><span>:</span><span> </span><span>PostsService</span></p><p><span>&nbsp;&nbsp;</span><span>)</span><span> </span><span>{</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Get</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>async </span><span>getPosts</span><span>(</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>@</span><span>Query</span><span>(</span><span>'search'</span><span>)</span><span> </span><span>search</span><span>:</span><span> </span><span>string</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>@</span><span>Query</span><span>(</span><span>)</span><span> </span><span>{</span><span> </span><span>offset</span><span>,</span><span> </span><span>limit</span><span> </span><span>}</span><span>:</span><span> </span><span>PaginationParams</span></p><p><span>&nbsp;&nbsp;</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>search</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>this</span><span>.</span><span>postsService</span><span>.</span><span>searchForPosts</span><span>(</span><span>search</span><span>,</span><span> </span><span>offset</span><span>,</span><span> </span><span>limit</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>this</span><span>.</span><span>postsService</span><span>.</span><span>getAllPosts</span><span>(</span><span>offset</span><span>,</span><span> </span><span>limit</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>// ...</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Implementing offset-based pagination is very easy with TypeORM. Aside from returning an array of posts, we also want to return a number of them. Thanks to that, our frontend can estimate the number of pages available.</p><p>Although we could use the <span id="crayon-5fad98ededbbb716098801"><span><span>postsRepository</span><span>.</span><span>count</span><span>(</span><span>)</span></span></span> and <span id="crayon-5fad98ededbbd803558856"><span><span>postsRepository</span><span>.</span><span>find</span><span>(</span><span>)</span></span></span> methods separately, this would result in making two queries to the database. We can improve that by using <span id="crayon-5fad98ededbc0003377891"><span><span>postsRepository</span><span>.</span><span>findAndCount</span></span></span>.</p><div id="crayon-5fad98ededbc2127768990" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>async </span><span>getAllPosts</span><span>(</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> </span><span>count</span><span>]</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>findAndCount</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>relations</span><span>:</span><span> </span><span>[</span><span>'author'</span><span>]</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>'ASC'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>skip</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>take</span><span>:</span><span> </span><span>limit</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>items</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Implementing offset and limit with Elasticsearch</h3><p>In <a href="https://wanago.io/2020/09/07/api-nestjs-elasticsearch/">one of the previous parts of this series</a>, we’ve integrated our posts with Elasticsearch. Fortunately, it is effortless to add the offset-based pagination to it. We need to pass the additional <span id="crayon-5fad98ededbc5236264417"><span><span>offset</span></span></span> and <span id="crayon-5fad98ededbc6418693676"><span><span>size</span></span></span> parameters.</p><div id="crayon-5fad98ededbc8641199494" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div></td><td><div><p><span>async </span><span>search</span><span>(</span><span>text</span><span>:</span><span> </span><span>string</span><span>,</span><span> </span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>{</span><span> </span><span>body</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>elasticsearchService</span><span>.</span><span>search</span><span>&lt;</span><span>PostSearchResult</span><span>&gt;</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>index</span><span>:</span><span> </span><span>this</span><span>.</span><span>index</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>from</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>size</span><span>:</span><span> </span><span>limit</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>body</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>multi_match</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>text</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>fields</span><span>:</span><span> </span><span>[</span><span>'title'</span><span>,</span><span> </span><span>'paragraphs'</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sort</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>'asc'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>count</span><span> </span><span>=</span><span> </span><span>body</span><span>.</span><span>hits</span><span>.</span><span>total</span><span>.</span><span>value</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>hits</span><span> </span><span>=</span><span> </span><span>body</span><span>.</span><span>hits</span><span>.</span><span>hits</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>results</span><span> </span><span>=</span><span> </span><span>hits</span><span>.</span><span>map</span><span>(</span><span>(</span><span>item</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>item</span><span>.</span><span>_source</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>results</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Disadvantages</h3><p>The solution with offset and limit seems to be the most widely used. Unfortunately, its performance might fall short of our expectations.</p><p>An essential thing to keep in mind is that the database still needs to compute the rows skipped by the <span id="crayon-5fad98ededbca412869571"><span><span>OFFSET</span></span></span>. First, the database sorts all of the rows according to our <span id="crayon-5fad98ededbcc901998381"><span><span>ORDER </span><span>BY</span></span></span> clause. Then, Postgres drops the number of rows specified in the <span id="crayon-5fad98ededbce904309756"><span><span>OFFSET</span></span></span>. This might require quite a bit of work.</p><p>Aside from the performance, another important thing to consider is consistency. We want an element to appear in the results exactly once. Let’s imagine the following situation:</p><ol><li>one user fetches page number one with posts</li><li>meanwhile, the second user creates a new post – after sorting, it ends up on page number one</li><li>the first user fetches the second page</li></ol><p>The last element of the first page is now again seen on the second page because of the above. What’s even worse, the user missed the element that has been added to the first page.</p><h3>Advantages</h3><p>While the offset approach has its cons, it is still common. Due to its simplicity, it is straightforward to implement. Also, it is easy to change the column that we use for sorting, including the usage of multiple columns. Because of that, it is a viable solution in many cases. Especially if the offset is expected not to be big, and the result inconsistencies are acceptable.</p><h2>Keyset pagination</h2><p>While the offset-based pagination can be useful, its performance might not be the best. Sometimes we might want to avoid it.</p><p>One of the ways to do so is to implement keyset pagination. Instead of using the <span id="crayon-5fad98ededbd0032345837"><span><span>OFFSET</span></span></span> clause, we use the <span id="crayon-5fad98ededbd2799759442"><span><span>WHERE</span></span></span> command to select the data we haven’t fetched yet.</p><p>Let’s start with a simple query:</p><div id="crayon-5fad98ededbd4892288922" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM </span><span>post</span></p><p><span>ORDER </span><span>BY </span><span>id </span><span>ASC</span></p><p><span>LIMIT</span><span> </span><span>10</span></p></div></td></tr></tbody></table></div></div><p>The above query gets us the first ten posts. Let’s assume that the id of the last post was&nbsp;<strong>20</strong>. With this assumption, we can run this query:</p><div id="crayon-5fad98ededbd6325102465" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM </span><span>post</span></p><p><span>WHERE </span><span>id</span><span> </span><span>&gt;</span><span> </span><span>20</span></p><p><span>ORDER </span><span>BY </span><span>id </span><span>ASC</span></p><p><span>LIMIT</span><span> </span><span>10</span></p></div></td></tr></tbody></table></div></div><p>The above query gets us ten posts with id bigger than 20. Now, we can take the last post and rerun the query, changing the id. Doing that creates us simple and efficient pagination mechanism.</p><p>This exposes the biggest drawback of the keyset pagination, though. To get a page, we need to know the last element of the previous set of results. This makes traversing multiple pages at once impossible.</p><p>Fortunately, most of the time, the users got straight to the next page. To cover all of the cases, we can implement both the offset-based approach and the keyset pagination.</p><p>If we would like to change the column that we order our elements by, we need to change both the <span id="crayon-5fad98ededbd8908794803"><span><span>ORDER </span><span>BY</span></span></span> and <span id="crayon-5fad98ededbd9021506153"><span><span>WHERE</span></span></span> clauses.</p><h3>Implementing keyset pagination with TypeORM</h3><p>Adding keyset pagination is not difficult with TypeORM. First, let’s add another query parameter called <span id="crayon-5fad98ededbdb215706232"><span><span>startId</span></span></span>&nbsp;to our <span id="crayon-5fad98ededbdd535138319"><span><span>PaginationParams</span></span></span>.</p><div id="crayon-5fad98ededbdf973147743" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p></div></td><td><div><p><span>import</span><span> </span><span>{</span><span> </span><span>IsNumber</span><span>,</span><span> </span><span>Min</span><span>,</span><span> </span><span>IsOptional</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-validator'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>Type</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-transformer'</span><span>;</span></p><p><span>export</span><span> </span><span>class</span><span> </span><span>PaginationParams</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>startId</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>0</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Along the way, we will face a small issue with the count of our elements. The <span id="crayon-5fad98ededbe1075039420"><span><span>postsRepository</span><span>.</span><span>findAndCount</span></span></span> with a <span id="crayon-5fad98ededbe3948441487"><span><span>WHERE</span></span></span> clause will return only the number of matching posts. We need to count them separately.</p><div id="crayon-5fad98ededbe5118224508" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p></div></td><td><div><p><span>async </span><span>getAllPosts</span><span>(</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>startId</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> where:</span><span> </span><span>FindManyOptions</span><span>&lt;</span><span>Post</span><span>&gt;</span><span>[</span><span>'where'</span><span>]</span><span> </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>let </span><span>separateCount</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>startId</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where</span><span>.</span><span>id</span><span> </span><span>=</span><span> </span><span>MoreThan</span><span>(</span><span>startId</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>separateCount</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>count</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> </span><span>count</span><span>]</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>findAndCount</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>relations</span><span>:</span><span> </span><span>[</span><span>'author'</span><span>]</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>'ASC'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>skip</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>take</span><span>:</span><span> </span><span>limit</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>items</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span><span>:</span><span> </span><span>startId</span><span> </span><span>?</span><span> </span><span>separateCount</span><span> </span><span>:</span><span> </span><span>count</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Implementing keyset pagination with Elasticsearch</h3><p>We can also achieve the above result with Elasticsearch by adding the id of a post to our query.</p><p>In this very simple example, we separately count the matching posts. If you feel like using other pagination approaches due to performance reasons, Elasticsearch has <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html">other built-in methods of pagination</a>.</p><div id="crayon-5fad98ededbe7401449669" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>async </span><span>count</span><span>(</span><span>query</span><span>:</span><span> </span><span>string</span><span>,</span><span> </span><span>fields</span><span>:</span><span> </span><span>string</span><span>[</span><span>]</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>{</span><span> </span><span>body</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>elasticsearchService</span><span>.</span><span>count</span><span>&lt;</span><span>PostCountResult</span><span>&gt;</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>index</span><span>:</span><span> </span><span>this</span><span>.</span><span>index</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>body</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>multi_match</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>fields</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…</span></p></div></td></tr></tbody></table></div></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/">https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/</a></em></p>]]>
            </description>
            <link>https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038192</guid>
            <pubDate>Mon, 09 Nov 2020 18:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hidden gem in sound symmetry]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25037784">thread link</a>) | @gbh444g
<br/>
November 9, 2020 | https://soundshader.github.io/hn/acf/index.html | <a href="https://web.archive.org/web/*/https://soundshader.github.io/hn/acf/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<blockquote>
  <p><em><a href="https://pages.mtu.edu/~suits/autocorrelation.html">Autocorrelation</a> is used to compare a signal with a time-delayed version of itself. If a signal is periodic, then the signal will be perfectly correlated with a version of itself if the time-delay is an integer number of periods. That fact, along with related experiments, has implicated autocorrelation as a potentially important part of signal processing in human hearing.</em></p>
</blockquote>

<p>ACF is a simple method to visualize music that produces surprisingly good results. Perhaps the most unexpected property of ACF is that it accurately transfers the subjective “harmony level” from music to images. It’s almost an unreasonable property, if you think about it. Images below are ACF height maps in polar coordinates.</p>

<table>
  <thead>
    <tr>
      <th>Female vocal</th>
      <th>David Parsons</th>
      <th>Piano</th>
      <th>Bird</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/song-2.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bowl-3.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/piano-p.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bird-2.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>More examples: <a href="https://soundshader.github.io/gallery/">soundshader.github.io/gallery</a> (beware of large images).</p>

<p>Live demo: <a href="https://soundshader.github.io/">soundshader.github.io</a></p>



<p>Contrary to what you might think, our ears don’t seem to rely on an FFT-like process to extract isolated frequencies. Instead, our ears detect periodic parts in the signal, although in most cases those periodic parts closely match the FFT frequencies. There is a simple <a href="https://auditoryneuroscience.com/pitch/missing-fundamental-stimuli">experiment</a> that proves this point:</p>

<p><img src="https://auditoryneuroscience.com/sites/default/files/missingFundamental2.png" alt=""></p>

<p>As can be clearly seen on the FFT image, the A signal is a pure sinusoidal tone, while B is a mix of tones. Despite each tone in B is higher than A, our ears perceive B as a lower tone. If we plot both waveforms, we’ll see that A has about 9 peaks in a 20 ms window, while B has only 5. The definition of “peak” is moot, but it doesn’t stop our ears from counting them and using the “number of peaks per second” as a proxy to the tone height.</p>

<p>ACF detects those peaks. ACF sees that there are 5 equally spaced time shifts where <code>B[t] * B[t + shift]</code> reaches the maximum, so on the ACF output we’ll see those 5 peaks.</p>

<blockquote>
  <p>Given that I’ve shamelessly stolen the experiment’s illustration above, I feel obligated to recommend the book where the illustration came from: <a href="https://auditoryneuroscience.com/book-preview">Auditory Neuroscience</a>.</p>
</blockquote>

<p>One downside of ACF is that it drops the phase component of the input signal, and thus ACF is not reversible. This means that images that only render ACF, lose about 50% of the information from the sound and those 50% are important, e.g. dropping the phase from recorded speech makes that speech indiscernible. Real world sounds, such as voice, heavily use nuanced amplitude and phase modulation. ACF captures the former, but ignores the latter.</p>



<p>ACF of a sound sample <code>X[0..N-1]</code> can be computed with two FFTs:</p>

<div><div><pre><code>S = |FFT[X]|^2
ACF[X] = FFT[S]
</code></pre></div></div>

<p>And thus ACF contains exactly the same information as the spectral density <code>S</code> (the well known spectrogram).</p>

<blockquote>
  <p>If you’re familiar with the ACF definition, you’ll notice that I should’ve used the inverse FFT in the last step. There is no mistake. The inverse FFT can be computed as <code>FFT[X*]*</code>, where <code>X*</code> is complex conjugate, but since <code>S[i]</code> is real-valued (and positive, in fact), the conjugate has no effect on it, and since ACF is also real valued in this case, the second conjugate has no effect either.</p>
</blockquote>

<p>ACF is a periodic and even function and so it can be naturally rendered in polar coordinates. In most cases, ACF has a very elaborate structure. Below are some examples, where red = ACF &gt; 0 and blue = ACF &lt; 0.</p>

<table>
  <thead>
    <tr>
      <th>conventional music</th>
      <th>a bird song</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/acf-c-1.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/acf-c-3.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>Looking at the first example, we can tell that there are 5 prominent peaks in a 20 ms sound sample, which corresponds to 250 Hz. This means that our ears would necesserarily perceive this sound as a 250 Hz tone, regardless of what its spectrogram says. If it was a pure 250 Hz tone, we’d see perfectly round shapes of the <code>r = cos(250Hz * t)</code> line, but it’s not the case here: we see that the 5 peaks are modulated with small wavelets: there is one big wavelet in the middle (which consists of 3 smaller wavelets) and 4 smaller wavelets. Our ears would hear the big wavelet as the 2nd harmonic of the 250 Hz tone (i.e. it would be a 500 Hz tone with a smaller amplitude) and the 4 small wavelets as the 5th harmonic (1000 Hz) at barely discernible volume. In addition to that, the 500 Hz harmonic is also modulated by the 3 tiny wavelets, which means we’d hear a 1500 Hz tone, almost inaudible. We can say all this without even looking at the spectrogram or hearing the sound.</p>



<p>Music is a temporal ornament. There are many types of ornaments, e.g. the 17 types of wallpaper tesselations, but few of them look like music. However there is one particular type of ornament that resembles music a lot - I mean those “mandala” images. I don’t know how and why those are produced, but I noticed a connection between those images and music:</p>

<ul>
  <li>The 1st obvious observation is that a mandala is drawn in polar coordinates and is <code>2*PI</code> periodic. Sound is periodic too, so I thought the two facts are related.</li>
  <li>The 2nd observation is that patterns on those images evolve over the radial axis. Ans so is music is a sequence of evolving sound patterns.</li>
  <li>The 3rd observation is that a <code>2*PI</code> periodic function trivially corresponds to a set of frequencies. We usually use FFT to extract the frequencies and another FFT to restore the <code>2*PI</code> periodic function. Thus, a single radial slice of a mandala could encode a set of frequencies. If this is correct, a mandala is effectively an old school vinyl disk.</li>
</ul>

<p>Putting these observations together we naturally arrive with the ACF idea.</p>



<p>Open an issue on github or shoot me a email at ssgh@aikh.org</p>



<p>AGPLv3</p>


      
    </div></div>]]>
            </description>
            <link>https://soundshader.github.io/hn/acf/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037784</guid>
            <pubDate>Mon, 09 Nov 2020 18:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Illustrated Guide to Superlearning]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037740">thread link</a>) | @prostoalex
<br/>
November 9, 2020 | https://www.khstats.com/blog/sl/superlearning/ | <a href="https://web.archive.org/web/*/https://www.khstats.com/blog/sl/superlearning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      


<blockquote>
<p>Why use <em>one</em> machine learning algorithm when you could use all of them?! This post contains a step-by-step walkthrough of how to build a superlearner prediction algorithm in <code>R</code>.</p>
</blockquote>


<title>
HTML Image as link
</title>


<p><img alt="cheatsheet" src="https://www.khstats.com/img/Superlearning.jpg" width="100%&quot;"></p><figcaption>
<strong><em>A Visual Guide…</em></strong> Over the winter, I read <a href="https://www.springer.com/gp/book/9781441997814"><em>Targeted Learning</em></a> by Mark van der Laan and Sherri Rose. This “visual guide” I made for <em>Chapter 3: Superlearning</em> by Rose, van der Laan, and Eric Polley is a condensed version of the following tutorial. It is available as an <a href="https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/Superlearner.pdf">8.5x11" pdf on Github</a>, should you wish to print it out for reference (or desk decor).
</figcaption>



<div id="supercuts-of-superlearning">

<ul>
<li><p><strong>Superlearning</strong> is a technique for prediction that involves <strong>combining many individual statistical algorithms</strong> (commonly called “data-adaptive” or “machine learning” algorithms) to <strong>create a new, single prediction algorithm</strong> that is expected to <strong>perform at least as well as any of the individual algorithms</strong>.</p></li>
<li><p>The superlearner algorithm “decides” how to combine, or weight, the individual algorithms based upon how well each one <strong>minimizes a specified loss function</strong>, for example, the mean squared error (MSE). This is done using cross-validation to avoid overfitting.</p></li>
<li><p>The motivation for this type of “ensembling” is that <strong>a mix of multiple algorithms may be more optimal for a given data set than any single algorithm</strong>. For example, a tree based model averaged with a linear model (e.g.&nbsp;random forests and LASSO) could smooth some of the model’s edges to improve predictive performance.</p></li>
<li><p>Superlearning is also called stacking, stacked generalizations, and weighted ensembling by different specializations within the realms of statistics and data science.</p></li>
</ul>
<p><img src="https://www.khstats.com/img/spiderman_meme.jpg"></p>
</div>
<div id="superlearning-step-by-step">

<p>First I’ll go through the algorithm one step at a time using a simulated data set.</p>
<div id="initial-set-up-load-libraries-set-seed-simulate-data">
<h2>Initial set-up: Load libraries, set seed, simulate data</h2>
<p>For simplicity I’ll show the concept of superlearning using only four variables (AKA features or predictors) to predict a continuous outcome. Let’s first simulate a continuous outcome, <code>y</code>, and four potential predictors, <code>x1</code>, <code>x2</code>, <code>x3</code>, and <code>x4</code>.</p>
<pre><code>library(tidyverse)
library(knitr)
set.seed(7)</code></pre>
<pre><code>n &lt;- 5000
obs &lt;- tibble(
  id = 1:n,
  x1 = rnorm(n),
  x2 = rbinom(n, 1, plogis(10*x1)),
  x3 = rbinom(n, 1, plogis(x1*x2 + .5*x2)),
  x4 = rnorm(n, mean=x1*x2, sd=.5*x3),
  y = x1 + x2 + x2*x3 + sin(x4)
)
kable(head(obs), digits=3, caption = "Simulated data set")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Simulated data set</caption>
<thead>
<tr>
<th>id</th>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.287</td>
<td>1</td>
<td>1</td>
<td>1.385</td>
<td>5.270</td>
</tr>
<tr>
<td>2</td>
<td>-1.197</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-1.197</td>
</tr>
<tr>
<td>3</td>
<td>-0.694</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.694</td>
</tr>
<tr>
<td>4</td>
<td>-0.412</td>
<td>0</td>
<td>1</td>
<td>-0.541</td>
<td>-0.928</td>
</tr>
<tr>
<td>5</td>
<td>-0.971</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.971</td>
</tr>
<tr>
<td>6</td>
<td>-0.947</td>
<td>0</td>
<td>1</td>
<td>-0.160</td>
<td>-1.107</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 1: Split data into K folds
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step1.png">
The superlearner algorithm relies on K-fold cross-validation (CV) to avoid overfitting. We will start this process by splitting the data into 10 folds. The easiest way to do this is by creating indices for each CV fold.</p>
<pre><code>k &lt;- 10 # 10 fold cv
cv_index &lt;- sample(rep(1:k, each = n/k)) # create indices for each CV fold. We need each fold K to contain n (all the rows of our data set) divided by k rows. in our example this is 5000/10 = 500 rows in each fold</code></pre>


<h2>
<strong>Step 2: Fit base learners for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step2.png"></p>
<p>Recall that in K-fold CV, each fold serves as the validation set one time. In this first round of CV, we will train all of our base learners on all the CV folds (k = 1,2,…,9) <em>except</em> for the very last one: <code>cv_index == 10</code>.</p>
<p>The individual algorithms or <strong>base learners</strong> that we’ll use here are three linear regressions with differently specified parameters:</p>
<ol>
<li><p><strong>Learner A</strong>: <span>\(Y=\beta_0 + \beta_1 X_2 + \beta_2 X_4 + \epsilon\)</span></p></li>
<li><p><strong>Learner B</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_3 + \beta_4 sin(X_4) + \epsilon\)</span></p></li>
<li><p><strong>Learner C</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_1 X_2 + \beta_5 X_1 X_3 + \beta_6 X_2 X_3 + \beta_7 X_1 X_2 X_3 + \epsilon\)</span></p></li>
</ol>
<pre><code>cv_train_1 &lt;- obs[-which(cv_index == 10),] # make a data set that contains all observations except those in k=1
fit_1a &lt;- glm(y ~ x2 + x4, data=cv_train_1) # fit the first linear regression on that training data
fit_1b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train_1) # second LR fit on the training data
fit_1c &lt;- glm(y ~ x1*x2*x3, data=cv_train_1) # and the third LR</code></pre>
<p>I am <em>only</em> using the linear regressions so that code for running more complicated regressions does not take away from understanding the general superlearning algorithm.</p>
<p>Superlearning actually works best if you use a diverse set, or <strong>superlearner library</strong>, of base learners. For example, instead of three linear regressions, we could use a least absolute shrinkage estimator (LASSO), random forest, and multivariate adaptive splines (MARS). Any parametric or non-parametric supervised machine learning algorithm can be included as a base learner.</p>


<h2>
<strong>Step 3: Obtain predictions for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step3.png"></p>
<p>We can then get use our validation data, <code>cv_index == 10</code>, to obtain our first set of cross-validated predictions.</p>
<pre><code>cv_valid_1 &lt;- obs[which(cv_index == 10),] # make a data set that only contains observations except in k=10
pred_1a &lt;- predict(fit_1a, newdata = cv_valid_1) # use that data set as the validation for all the models in the SL library
pred_1b &lt;- predict(fit_1b, newdata = cv_valid_1) 
pred_1c &lt;- predict(fit_1c, newdata = cv_valid_1)</code></pre>
<p>Since we have 5000 <code>obs</code>ervations, that gives us three vectors of length 500: a set of predictions for each of our Learners A, B, and C.</p>
<pre><code>length(pred_1a) # double check we only have n/k predictions ...we do :-)</code></pre>
<pre><code>## [1] 500</code></pre>
<pre><code>knitr::kable(head(cbind(pred_1a, pred_1b, pred_1c)), digits= 2, caption = "First CV round of predictions") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 2: </span>First CV round of predictions</caption>
<thead>
<tr>
<th>pred_1a</th>
<th>pred_1b</th>
<th>pred_1c</th>
</tr>
</thead>
<tbody>
<tr>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>-1.27</td>
<td>-0.34</td>
<td>-0.11</td>
</tr>
<tr>
<td>2.16</td>
<td>1.32</td>
<td>1.10</td>
</tr>
<tr>
<td>4.27</td>
<td>4.26</td>
<td>3.98</td>
</tr>
<tr>
<td>3.31</td>
<td>3.98</td>
<td>3.78</td>
</tr>
<tr>
<td>2.29</td>
<td>2.42</td>
<td>2.83</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 4: Obtain CV predictions for entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step4.png"></p>
<p>We’ll want to get those predictions for <em>every</em> fold. So, using your favorite <code>for</code> loop, <code>apply</code> statement, or <code>map</code>ping function, fit the base learners and obtain predictions for each of them, so that there are 1000 predictions – one for every point in <code>obs</code>ervations.</p>
<p>The way I chose to code this was to make a generic function that combines Step 2 (base learners fit to the training data) and Step 3 (predictions on the validation data), then use <code>map_dfr()</code> from the <code>purrr</code> package to repeat over all 10 CV folds. I saved the results in a new data frame called <code>cv_preds</code>.</p>
<pre><code>cv_folds &lt;- as.list(1:k)
names(cv_folds) &lt;- paste0("fold",1:k)

get_preds &lt;- function(fold){   # function that does the same procedure as step 2 and 3 for any CV fold
  cv_train &lt;- obs[-which(cv_index == fold),]  # make a training data set that contains all data except fold k
  fit_a &lt;- glm(y ~ x2 + x4, data=cv_train)  # fit all the base learners to that data
  fit_b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train)
  fit_c &lt;- glm(y ~ x1*x2*x3, data=cv_train)
  cv_valid &lt;- obs[which(cv_index == fold),]  # make a validation data set that only contains data from fold k
  pred_a &lt;- predict(fit_a, newdata = cv_valid)  # obtain predictions from all the base learners for that validation data
  pred_b &lt;- predict(fit_b, newdata = cv_valid)
  pred_c &lt;- predict(fit_c, newdata = cv_valid)
  return(data.frame("obs_id" = cv_valid$id, "cv_fold" = fold, pred_a, pred_b, pred_c))  # save the predictions and the ids of the observations in a data frame
}

cv_preds &lt;- purrr::map_dfr(cv_folds, ~get_preds(fold = .x)) # map_dfr loops through every fold (1:k) and binds the rows of the listed results together

cv_preds %&gt;% arrange(obs_id) %&gt;% head() %&gt;% kable(digits=2, caption = "All CV predictions for all three base learners") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-7">Table 3: </span>All CV predictions for all three base learners</caption>
<thead>
<tr>
<th></th>
<th>obs_id</th>
<th>cv_fold</th>
<th>pred_a</th>
<th>pred_b</th>
<th>pred_c</th>
</tr>
</thead>
<tbody>
<tr>
<td>1…1</td>
<td>1</td>
<td>4</td>
<td>3.73</td>
<td>5.42</td>
<td>5.28</td>
</tr>
<tr>
<td>1…2</td>
<td>2</td>
<td>8</td>
<td>-0.77</td>
<td>-1.19</td>
<td>-1.20</td>
</tr>
<tr>
<td>1…3</td>
<td>3</td>
<td>2</td>
<td>-0.78</td>
<td>-0.81</td>
<td>-0.69</td>
</tr>
<tr>
<td>1…4</td>
<td>4</td>
<td>10</td>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>1…5</td>
<td>5</td>
<td>6</td>
<td>-0.78</td>
<td>-1.01</td>
<td>-0.97</td>
</tr>
<tr>
<td>1…6</td>
<td>6</td>
<td>7</td>
<td>-0.96</td>
<td>-1.04</td>
<td>-0.94</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 5: Choose and compute loss function of interest via metalearner
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step5.png"></p>
<blockquote>
<p>This is the key step of the superlearner algorithm: we will use a new learner, a <strong>metalearner</strong>, to take information from all of the base learners and create that new algorithm.</p>
</blockquote>
<p>Now that we have cross-validated predictions for every observation in the data set, we want to merge those CV predictions back into our main data set…</p>
<pre><code>obs_preds &lt;- 
  full_join(obs, cv_preds, by=c("id" = "obs_id"))</code></pre>
<p>…so that we can minimize a final loss function of interest between the true outcome and each CV prediction. This is how we’re going to optimize our overall prediction algorithm: we want to make sure we’re “losing the least” in the way we combine our base learners’ predictions to ultimately make final predictions. We can do this efficiently by choosing a new learner, a metalearner, which reflects the final loss function of interest.</p>
<p>For simplicity, we’ll use another linear regression as our metalearner. Using a linear regression as a metalearner will minimize the Cross-Validated Mean Squared Error (CV-MSE) when combining the base learner predictions. Note that we could use a variety of parametric or non-parametric regressions to minimize the CV-MSE.</p>
<p>No matter what metalearner we choose, the predictors will always be the cross-validated predictions from each base learner, and the outcome will always be the true outcome, <code>y</code>.</p>
<pre><code>sl_fit &lt;- glm(y ~ pred_a + pred_b + pred_c, data = obs_preds)
kable(broom::tidy(sl_fit), digits=3, caption = "Metalearner regression coefficients") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-9">Table 4: </span>Metalearner regression coefficients</caption>
<thead>
<tr>
<th>term</th>
<th>estimate</th>
<th>std.error</th>
<th>statistic</th>
<th>p.value</th>
</tr>
</thead>
<tbody>
<tr>
<td>(Intercept)</td>
<td>-0.003</td>
<td>0.002</td>
<td>-1.447</td>
<td>0.148</td>
</tr>
<tr>
<td>pred_a</td>
<td>-0.017</td>
<td>0.004</td>
<td>-4.739</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_b</td>
<td>0.854</td>
<td>0.007</td>
<td>128.241</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_c</td>
<td>0.165</td>
<td>0.005</td>
<td>30.103</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<p>This metalearner provides us with the coefficients, or weights, to apply to each of the base learners. In other words, if we have a set of predictions from Learner A, B, and C, we can obtain our best possible predictions by starting with an intercept of -0.003, then adding -0.017 <span>\(\times\)</span> predictions from Learner A, 0.854 <span>\(\times\)</span> predictions from Learner B, and 0.165 <span>\(\times\)</span> predictions from Learner C.</p>
<p><em>For more information on the metalearning step, check out the <a href="#appendix">Appendix</a>.</em></p>


<h2>
<strong>Step 6: Fit base learners on entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step6.png"></p>
<p>After we fit the metalearner, we officially have our superlearner algorithm, so it’s time to input data and …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.khstats.com/blog/sl/superlearning/">https://www.khstats.com/blog/sl/superlearning/</a></em></p>]]>
            </description>
            <link>https://www.khstats.com/blog/sl/superlearning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037740</guid>
            <pubDate>Mon, 09 Nov 2020 18:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Journalist vs. Facebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037615">thread link</a>) | @leoschwartz
<br/>
November 9, 2020 | https://restofworld.org/2020/the-journalist-vs-facebook/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-journalist-vs-facebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Maria Ressa has a cheerful way of making apocalyptic pronouncements. “The world as we knew it is rubble,” she says over a Zoom call from Manila. “Facts are debatable, we have alternate realities — the White House will say we have alternate realities.”</p>



<p>Ressa is the CEO of Rappler, a prominent digital news outlet in the Philippines. Over the past few years, she has watched from the front row as the internet helped demolish civil discourse and fracture society’s shared sense of reality. In 2016, Ressa witnessed a flood of digital disinformation help elect Rodrigo Duterte, the firebrand populist who as president launched a “war on drugs” that has killed thousands of Filipinos. That year, the same trends helped put in office U.S. President Donald Trump and push the United Kingdom to leave the European Union.</p>



<p>During Duterte’s 2016 campaign, Rappler analyzed fraudulent social media networks that promoted the president and attacked his opponents, drawing on Ressa’s experience mapping terrorist organizations as an investigative reporter in the 1990s and 2000s.</p>



<p>Over the following four years, Ressa became not only a chronicler of the government’s falsehoods but a target of them. Through intimidation and lawsuits, the Duterte administration has <a href="https://www.nytimes.com/2020/05/05/world/asia/philippines-abs-cbn-duterte.html">worked to muzzle</a> a number of independent media organizations in the Philippines. Ressa has been singled out: She and her company were charged with a series of spurious crimes, including tax evasion, all of which she has denied. In June, she and a former colleague <a href="https://www.nytimes.com/2020/06/14/business/maria-ressa-verdict-philippines-rappler.html">were convicted</a> of cyberlibel, a charge that stemmed from an article Rappler published in 2012. Ressa is now out on bail pending an appeal but could ultimately face years in prison.&nbsp;</p>



<p>Rather than silence her, these attacks have only given Ressa a bigger platform. Named a <em>Time </em>magazine <a href="https://time.com/5793800/maria-ressa-the-guardians-100-women-of-the-year/">person of the year</a> in 2019, she has become a global symbol of press freedom and an avatar of courage in the face of rising authoritarianism. As her profile has grown, so, too, has her mission. Today, Ressa’s focus has shifted away from Duterte, whom she sees as only the symptom of a larger problem: Facebook.</p>



<p>Ressa is one of the founding members of the <a href="https://www.theverge.com/interface/2020/9/29/21472092/real-facebook-oversight-board-stunt-activism-limitations">Real Facebook Oversight Board</a>, a group of academics, journalists, and activists formed as a tongue-in-cheek counterpoint to the company’s actual <a href="https://about.fb.com/news/2020/05/welcoming-the-oversight-board/">Oversight Board</a>, launched in May. That board was designed to function as a “Supreme Court” of sorts, with the power to decide if the company’s content-moderation decisions “were made in accordance with Facebook’s stated values and policies.” Ressa contends that those values and policies are<em> themselves</em> the problem, and says that Facebook’s persistent failure to effectively combat disinformation and hate speech poses an existential threat to democracy around the world.</p>



<p>“We’re fighting huge powers. Duterte, Zuckerberg,” she says. “Who would have thought you would have put the two of them in the same breath, but that’s what I’ve been living with for the last four years.”</p>



<p>Rappler began as a Facebook page in 2011 and launched as a stand-alone website the following year. Ressa says she was initially enthusiastic about the power of “social media for good.” Rappler even partnered with Facebook’s Internet.org initiative, which gives consumers in developing countries free access to certain websites. The program was instrumental in getting millions of Filipinos online, and <a href="https://nymag.com/intelligencer/2018/09/how-facebooks-free-internet-helped-elect-a-dictator.html">also on Facebook</a>: Today, nearly all internet users in the country have a Facebook account. It was the 2016 presidential election in the Philippines that eventually changed Ressa’s mind about the social network. “When the problems began, we were the first to feel it,” she says.&nbsp;</p>



<p>Rappler identified dozens of Facebook accounts that were creating and spreading disinformation in support of Duterte. Some posted fictionalized accounts of terrorist attacks and murders supposedly committed by drug addicts, which fed into the newly elected president’s law-and-order agenda. Ressa alerted Facebook, but she says it failed to take action. So <a href="https://www.rappler.com/nation/propaganda-war-weaponizing-internet">Rappler exposed the accounts</a> in a series of articles, instantly making the site a target of the same troll armies it was reporting on. (Facebook says it removes any content that violates its rules.)</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-400x601.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/h_3.01374802-600x902.jpg 600w, https://restofworld.org/wp-content/uploads/2020/11/h_3.01374802-1000x1503.jpg 1000w, " sizes="(max-width: 640px) 100vw, 300px" alt="“The platform itself is biased against facts. It’s really biased against journalism,” said Maria Ressa.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Tania/Contrasto/Redux</span>
			</figcaption>
		</figure>


<p>Since 2016, Ressa has become increasingly convinced that Facebook needs to profoundly change how it’s designed and governed. She believes the platform’s algorithms and content-moderation policies are inherently prejudiced against reasoned debate based on settled truths. “The platform itself is biased against facts. It’s really biased against journalism,” she says. “Social media platforms have atomized meaning to meaninglessness. They have completely deconstructed context.”</p>



<p>Her opinions are backed by a growing body of academic research, which shows that social media sites often <a href="https://jonahberger.com/wp-content/uploads/2013/02/ViralityB.pdf">reward emotional messages over rational analysis</a>, funnel users toward <a href="https://www.scientificamerican.com/article/biases-make-people-vulnerable-to-misinformation-spread-by-social-media/">content that reinforces their</a> preexisting beliefs, and<a href="https://science.sciencemag.org/content/359/6380/1146"> spread lies more rapidly and widely than they do the truth</a>.</p>



<p>Ressa says one of Facebook’s most alarming shortcomings is its reluctance to moderate <a href="https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/?utm_medium=Social&amp;utm_source=Twitter#Echobox=1603977263">disinformation posted by governments and politicians</a>. The company has justified its restraint by arguing that statements from public figures should remain online for public scrutiny. Although Facebook has removed state-backed propaganda in some instances, Ressa, along with other activists, say that these actions frequently amount to too little, too late. They say Facebook’s inaction has allowed propaganda and disinformation to spread unchecked, overwhelming and delegitimizing the news media.</p>



<p>“What we saw [in the Philippines] was that news organizations were being pushed to the periphery, and the center of the conversation was being taken over by the pro-government, state-sponsored disinformation,” Ressa says.</p>



<p>Without checks and balances on social media, Ressa says, authoritarian governments like Duterte’s can impose their own narratives — that drug addicts and communists run the country, and that journalists like Ressa are criminals and conspirators.</p>



<p>Ressa, who speaks in long, rapid-fire monologues, apologizes throughout her interview for her anger. “It’s very emotional for me,” she says. “I have real skin in the game. If they don’t fix this, this is how the government will normalize the possibility of jailing me. I could go to jail because [Facebook] refuses to address these problems that they created.”</p>



<p>The idea for the Real Facebook Oversight Board began taking shape last year, after Ressa met with Carole Cadwalladr, the journalist who, in 2018, first reported that political consulting firm <a href="https://www.theguardian.com/news/series/cambridge-analytica-files">Cambridge Analytica had harvested Facebook data</a> from millions of users. Since then, a number of high-profile academics and activists have joined the project, including Harvard professor Shoshana Zuboff, who wrote the best-selling book <em>The Age of Surveillance Capitalism</em>, as well as former Estonian President Thomas Hendrik Ilves and NAACP President Derrick Johnson.</p>



<p>The board was created to force Facebook into taking responsibility for the damage it has caused. The group <a href="https://www.axios.com/facebook-critics-take-on-its-oversight-board-06c496a2-355f-4a10-a8b4-d8f9b041a611.html">plans</a> to “use stunts, viral video, celebrity endorsement, and skillful media management” to put a spotlight on the threats social media companies pose to democracy. Ressa says she hasn’t fully discounted Facebook’s ability to do the right thing. “They just need to get off their butts and fix it before it is completely broken,” she says.</p>



<p>Ressa is still processing her evolution from journalism to activism, but she says she sees an obvious connection between the two, especially in an environment where facts are under constant attack. “Journalism is activism when it is a battle for truth,” she says. “This is a time when anyone living in a democracy, if you care about democracy, you have to sit there and answer the same question I was forced to answer four years ago, which is: What are you willing to sacrifice for the truth?”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-journalist-vs-facebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037615</guid>
            <pubDate>Mon, 09 Nov 2020 18:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Advice: Prepare to Be Scrutinized]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037454">thread link</a>) | @hackitup7
<br/>
November 9, 2020 | https://staysaasy.com/management/2020/09/18/management-scrutiny.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/18/management-scrutiny.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the weird things that people don’t tell you about management is the degree to which people will sometimes scrutinize your behavior.</p>

<p>This is completely opposite to how most human interactions work. Generally speaking people overestimate how much attention others are paying to them. It’s easy to be embarrassed if your voice cracks while meeting someone new, if you say something silly in front of your in-laws, or if you have spaghetti sauce on your shirt. In most cases nobody notices because their own life is being pumped into their brain in stereo.</p>

<p>But this isn’t always true. People actually <em>do</em> scrutinize the behavior of people who have some measure of control over their careers (such as the CEO) carefully, and in some cases will even document what they say for a rainy day. This pattern becomes more extreme as titles and organizations grow, to the point where the job of a Fortune 500 CEO almost overlaps with Broadway theater.</p>

<p>The reasons for this are obvious. People aren’t paying attention out of any sort of expectation of wisdom – but when someone has an impact on your job, it’s rational and reasonable to analyze them to help your career. However, I find that few new managers are aware of this phenomenon, which can have far-ranging consequences.</p>

<h2 id="the-awkward-lunch">The Awkward Lunch</h2>

<p>I remember the first time that I learned this lesson. I was eating lunch with my team as we lightly discussed our upcoming customer conference, and made a quick, dismissive offhand comment about how I felt that one of our marketing teams, led by Steve, was going in circles and wasting time on trivial details. This was 100% wrong – you should never “otherize” other teams – but I didn’t say anything particularly incendiary or critical. Nobody made any mention and I certainly forgot what I had said almost immediately.</p>

<p>Two weeks later, a member of my team offered out of the blue to handle an upcoming planning meeting with Steve’s group. I was confused – why was she making this offer? “Well, you mentioned that you thought that Steve had a tendency to waste time, and I know that you’re presenting at that conference in a week so you’re probably busy. I figured I could help cover a meeting with a team you don’t like.”</p>

<p>A team I don’t like? Where did that come from?! I dimly recalled the lunch in which I had made that comment, and realized that the offhand comment which I had immediately deleted from my mind had stuck with my lunchmates. With a growing sense of dread, I also realized that versions of this situation had probably been happening without my realizing it.</p>

<h2 id="managing-under-a-microscope">Managing Under a Microscope</h2>

<p>Advice that I had received earlier in my career, especially after becoming a new manager: assume that someone might remember everything you say or do. For extra fun, also expect that about 10% of the juiciest details that get remembered will be at least somewhat inaccurate.</p>

<p>Since it can be jarring to realize that your team is watching you a little bit more closely than you might like, I try to convey the general advice below to first time managers on my team:</p>

<ul>
  <li>Treat everything that you say like an email – assume that it may live on in someone’s memory for a long time after you say it.</li>
  <li>Be intentional in how you operate or communicate, as some people (particularly your team) may emulate some of your patterns. If you are really harsh when you communicate with other teams, they’ll tend to be harsher as well. If you’re extremely accommodating, they’ll also tend to be more accommodating.</li>
  <li>Build the mental muscle of being less reactive to stressful situations. Try not to visibly frown or look skeptical unless you really mean to express that emotion as people will likely pick up on it. This is true even if you’re stressed because you’re thinking about how your corgi Mr. Snuffles is sick, and your bad mood has nothing to do with work.</li>
  <li>Be extra vigilant not to say things that could be misconstrued as disrespectful or offensive.</li>
  <li>Don’t get wasted at your company’s holiday party, or at other types of events. While I find that most people will give you a pass, it’s really easy to start rumors after hours.</li>
</ul>

<p>There is no way to stop people from scrutinizing – it’s human nature mixed with rational behavior. But if you’re intentional in your actions, you should at least be able to avoid putting your foot in your mouth by saying something dumb at lunch.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/18/management-scrutiny.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037454</guid>
            <pubDate>Mon, 09 Nov 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Git]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037365">thread link</a>) | @jerodsanto
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037365</guid>
            <pubDate>Mon, 09 Nov 2020 17:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25037147">thread link</a>) | @adamnemecek
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev? | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037147</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peeking Inside the Black Box: Explaining Artificial Intelligence Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037136">thread link</a>) | @asafg6
<br/>
November 9, 2020 | https://www.turtle-techies.com/peeking-inside-the-black-box/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/peeking-inside-the-black-box/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Explaining Artificial Intelligence models</h4><p><h5>2020-11-08</h5></p></div><div><div itemprop="articleBody"><h2 id="a-brief-introduction">A Brief Introduction <a href="#a-brief-introduction"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>We live in the age of data and new technologies.
More and more, Artificial Intelligence is coming to our lives, from the image processing after a picture is shot in our phones to the recommendation algorithm in most content places.
And the number of companies that want to introduce some AI process to their workflow increases by the minute.</p><p>Soon, AI systems will be diagnosing illnesses, granting mortgages, etc.
But then doubts arise.
A lot of those AI systems will be black box systems, most likely Neural Networks or Ensembles.
Basically a lot of automatic learned equations and parameters that are going to tell everybody if they are fit to buy a house, or if they have this or that illness.<br>But can we really trust these systems? They have been proven wrong in the past, showing incredible and unexpected
<a href="https://metro.co.uk/2017/07/13/racist-soap-dispensers-dont-work-for-black-people-6775909/" target="_blank">biases</a>.</p><p>Here is why the trend is moving towards making AI fair and understandable.
There are great initiatives like
<a href="https://www.fast.ai/" target="_blank">fast.ai</a> that focus on unbiased AI, but here we are going to use some of the latest framework to <strong>explain existing models</strong>.<br>Whether you have an AI pipeline in your company or you are learning how to use the latest Neural Network models, this tutorial will explain you a bit more about what is going on inside that process.</p><h2 id="anchor">Anchor <a href="#anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>There are plenty of papers researching XAI (eXplainable Artificial Intelligence), but there are not so many frameworks that can currently take an existing model and explain its internal processes.
This kind of <em>post-hoc explanation</em> is very interesting because it does not have to reimplement and retrain the existing pipelines, but rather can work as a new addition to those pipelines.</p><p>In this article we will explain
<a href="https://github.com/marcotcr/anchor" target="_blank">Anchor</a>, a state-of-the-art library programmed in Python which has proven efficiency and is considered the rival to beat when developing new algorithms.
Anchor is an open-source library that learns a model-agnostic model (this is, it works with any kind of machine learning algorithm).
This model generates a set of rules (or anchors, hence the name) that classify and explain each particular example. Anchor can work with a variety of data, from text to images or tabular.
In this article, we will explain how to use it on a tabular database.</p><h2 id="installing-anchor">Installing Anchor <a href="#installing-anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>To install Anchor, we will need Python 3.7 or greater. To install the package from
<a href="https://pypi.org/" target="_blank">PyPI</a> just type:</p><p>Or clone their repository and install the package:</p><div><pre><code data-lang="Bash">
git clone https://github.com/marcotcr/anchor.git
python setup.py install

</code></pre></div><h2 id="installing-additional-elements">Installing Additional Elements <a href="#installing-additional-elements"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>First step will be to choose our database and to train our model. In this article we will use the very well known
<a href="https://archive.ics.uci.edu/ml/datasets/iris" target="_blank">iris database</a> that we can find packaged inside
<a href="https://scikit-learn.org/stable/" target="_blank">Scikit Learn</a>.</p><p>This is a flower database with 150 registers of different iris flowers. Each register measures both sepal and petal lengths in centimeters, and the target class is the type of iris (setosa, versicolor or virginica).</p><p>To install Scikit-Learn type in the terminal:</p><p>To train a model, we will use one of the best Python libraries out there:
<a href="https://xgboost.readthedocs.io/en/latest/" target="_blank">XGBoost</a>.</p><p>This will train a tree ensemble that grants a great accuracy.
Again, to install it type:</p><h2 id="training-our-model">Training our model <a href="#training-our-model"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>Now we are ready to train our model.
The first step will be to import everything we need:</p><div><pre><code data-lang="Python">
<span>import</span> xgboost <span>as</span> xgb

<span>from</span> sklearn <span>import</span> datasets
<span>from</span> sklearn.model_selection <span>import</span> train_test_split

<span>from</span> anchor <span>import</span> anchor_tabular

</code></pre></div><p>Here we have imported:</p><ul><li>The library to train our model (xgboost)</li><li>The datasets</li><li>A function to automatically generate the train and the test sets to properly validate the model</li><li>Anchor</li></ul><p>Next step will be to load the database:</p><div><pre><code data-lang="Python">
iris <span>=</span> datasets<span>.</span>load_iris()

X_train, X_test, y_train, y_test <span>=</span> train_test_split(iris<span>.</span>data, iris<span>.</span>target, test_size<span>=</span><span>0.3</span>, random_state<span>=</span><span>42</span>)

</code></pre></div><p>In this step, we load the iris dataset from the scikit package.<br>In this format, <code>iris.data</code> contains a series of <code>numpy</code> arrays with the features of the 150 registers, and <code>iris.target</code> contains an array of the prediction (as integers).
Then, we split the data in train and test sets.
This way, we have a random 70% of the database that will be used to train the model, and the 30% remaining that we will use to test the score.
We will also use it later to get some registers unknown to the model that we will be able to classify and explain.</p><p>Now it is time to train the model:</p><div><pre><code data-lang="Python">
xgb_model <span>=</span> xgb<span>.</span>XGBClassifier(random_state<span>=</span><span>42</span>)
xgb_model<span>.</span>fit(X_train, y_train)

</code></pre></div><p>The library <code>XGBoost</code> implements a
<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank">Gradient Boosting</a> algorithm.<br>What it does is to generate an ensemble of weak models that combine to generate a strong classifier.</p><p>This is typically done by training very shallow decision trees with random sets of data so that they are different from each other.
When they combine by
<a href="https://en.wikipedia.org/wiki/Boosting_%28machine_learning%29" target="_blank">boosting</a> they generate a very powerful model.</p><p>This is a classification problem, so we use a Classifier (not a Regressor).</p><blockquote><p>For this database we can leave the default parameters as is.<br>For other databases, you might need to fine-tune the model.
You can get all you need from the
<a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank">docs</a>.</p></blockquote><p>The model is trained just with the train data. Let’s see how it performs:</p><div><pre><code data-lang="Python">
<span>print</span>(xgb_model<span>.</span>score(X_test, y_test)) <span># 0.98</span>

</code></pre></div><p>If everything is correct, the score should be <code>0.98</code> or higher, given the randomness of some parts of the algorithm.</p><p>Impressive, but this will not tell us <strong>why a particular register is classified in some way</strong>.<br>For this, we will need to apply Anchor.</p><h2 id="applying-anchor-to-our-model">Applying Anchor to our model <a href="#applying-anchor-to-our-model"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>The first step will be to create the <code>explainer</code>.
This is the element that will take the model and explain the registers:</p><div><pre><code data-lang="Python">
explainer <span>=</span> anchor_tabular<span>.</span>AnchorTabularExplainer(class_names<span>=</span>iris<span>.</span>target_names,
                                                    feature_names<span>=</span>iris<span>.</span>feature_names,
                                                    train_data<span>=</span>X_train)

</code></pre></div><p>The <code>explainer</code> takes three parameters:</p><ul><li>The name of each feature</li><li>The name of each class value</li><li>The same data we have used to train the model.</li></ul><p>Note that we are not giving any data from our test set, the explainer does not use that to train.
This way, the explainer doesn’t know the test data, just like the model.</p><p>Let’s take the register with index 30 (at random) from out test data.<br>Pass it through our model:</p><div><pre><code data-lang="Python">
idx <span>=</span> <span>30</span>
np<span>.</span>random<span>.</span>seed(<span>1</span>)
<span>print</span>(<span>'Prediction: '</span>, explainer<span>.</span>class_names[xgb_model<span>.</span>predict(X_test[idx]<span>.</span>reshape(<span>1</span>, <span>-</span><span>1</span>))[<span>0</span>]])

</code></pre></div><pre><code>
Prediction:  setosa

</code></pre><p>Our <code>xgb_model</code> predicts that it will be a <code>setosa</code> output, but why?</p><p>Let’s generate the explanation:</p><div><pre><code data-lang="Python">
exp <span>=</span> explainer<span>.</span>explain_instance(X_test[idx], xgb_model<span>.</span>predict, threshold<span>=</span><span>0.95</span>)

</code></pre></div><p>Here is where the magic happens.<br>We pass the explainer the register we want to explain and the <code>predict</code> function from our model.
This is the good thing about Anchor: as long as the <code>predict</code> function can take a numpy array and return an integer as a prediction, it will work with absolutely any model out there! Even with custom ones you can program.
Note that there is a <code>threshold</code> parameter.
This means that the predictions for the explanation it has generated will hold at least 95% of the time.
But how to show that explanation?</p><p>With this code:</p><div><pre><code data-lang="Python">
<span>print</span>(<span>'Anchor: </span><span>%s</span><span>'</span> <span>%</span> (<span>' AND '</span><span>.</span>join(exp<span>.</span>names())))
<span>print</span>(<span>'Precision: </span><span>%.2f</span><span>'</span> <span>%</span> exp<span>.</span>precision())
<span>print</span>(<span>'Coverage: </span><span>%.2f</span><span>'</span> <span>%</span> exp<span>.</span>coverage())

</code></pre></div><pre><code>
Anchor: 1.70 &lt; petal length (cm) &lt;= 5.10 AND petal width (cm) &lt;= 1.30 AND sepal length (cm) &gt; 5.80
Precision: 1.00
Coverage: 0.06

</code></pre><p>Here we are.
Now we know that our register is a <code>setosa</code> because its petal length is smaller than 1.7 and so on.
We also know that 100% of the registers that match this rule are <code>setosa</code> and that 6% of the training registers match this rule.
With this, we have not only explained what is happening in the model, but also how confident we are in these rules.</p><h2 id="what-is-an-anchor">What is an Anchor <a href="#what-is-an-anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>All right, so now we have a rule or <em>anchor</em> that can explain the registry.<br>But how are they computed? Well, the deep mathematics of the anchor are a bit complicated, but the gist of it is as follows.<br>First, the system determines a probability for a certain <em>anchor</em> to get its precision.<br>Then, using a
<a href="https://en.wikipedia.org/wiki/Greedy_algorithm" target="_blank">greedy algorithm</a>, it starts adding features, values and splits (such as [<code>petal length (cm)</code>, <code>1.7</code>, <code>&lt;</code>]) and computing the best next addition.<br>The system keeps searching the best <em>anchor</em> according to the precision threshold, so that it returns the <strong>shortest</strong> anchor for the specified threshold.
It is not very explainable if the rule has 70 features, is it?<br>The nitty gritty part of the search is more complex, but if you want to have a look feel free to check the original
<a href="https://homes.cs.washington.edu/~marcotcr/aaai18.pdf" target="_blank">article</a>, where everything is explained.</p><h2 id="closing-words">Closing words <a href="#closing-words"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>In these days where AI is taking over more and more functions and processes, it is very easy to just let it decide for us without knowing why.
But there are aspects in life too important to just blindly trust a machine.
With Anchor, we have a library that is easy to add to any machine learning pipeline where the trust of each answer is as important as the answer itself.</p></div></div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/peeking-inside-the-black-box/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037136</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[18th Century England Had No Police]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25037076">thread link</a>) | @willbobaggins
<br/>
November 9, 2020 | https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/ | <a href="https://web.archive.org/web/*/https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1924">

                    
                    <div>
                        
<p>This week on the podcast, we have David Friedman. David holds a PhD in physics from the University of Chicago, he is chiefly known for his scholarly contributions to economics and law. He is the author of five books of non‐​fiction as well as three novels. We discuss the future, legal systems very different from our own, how technology drives progress, and what the future might look like.&nbsp;</p>



<figure></figure>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037076</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government pledges to connect 98% of Canadians via High-Speed Internet]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25037074">thread link</a>) | @aDfbrtVt
<br/>
November 9, 2020 | https://www.cbc.ca/news/politics/broadband-internet-1.5794901 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/broadband-internet-1.5794901">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Liberal government is promising to spend more than a billion dollars to connect most Canadian to high-speed internet by 2026.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4962390.1546282434!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/broadband-expansion.jpg"></p></div><figcaption>The Liberal government has been promising to do something to approve broadband internet service in rural areas.<!-- --> <!-- -->(Toby Talbot/Associated Press)</figcaption></figure><p><span><p>After some pandemic-related delays, the Liberal government says it's now&nbsp;on track to connect 98 per cent of Canadians to high-speed internet by 2026.</p>  <p>The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.</p>  <p>Prime Minister Justin Trudeau and a handful of cabinet ministers&nbsp;held a news conference in Ottawa to launch the $1.75 billion universal broadband fund — a program unveiled in the federal government's 2019 budget and highlighted on the campaign trail and in&nbsp;September's throne speech. Most of the money&nbsp;was&nbsp;announced in last year's budget.</p>  <p>"We were ready to go&nbsp;in March&nbsp;with the new Universal Broadband Fund and then the pandemic hit,"&nbsp;Rural Economic Development Minister Maryam Monsef told reporters.</p>  <p>The prime minister said the government is now on track to connect&nbsp;98 per cent of Canadians&nbsp;to high-speed&nbsp;by 2026 — an increase over&nbsp;the previously promised 95 per cent benchmark — and to link up&nbsp;the rest by 2030.</p>  <p>"These are ambitious targets&nbsp;and we're ready to meet them,"&nbsp;Trudeau said.</p>  <p><em><strong>WATCH |&nbsp;Trudeau announces a large investment in broadband services for rural Canadians</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Trudeau announces a large investment in broadband services for rural Canadians"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/573/747/ftr%20TRUDEAU%20broadband_frame_0.jpg" alt=""></p></div></div></div><span>Prime Minister Justin Trudeau spoke with reporters during a media briefing in Ottawa on Monday.<!-- --> <!-- -->2:47</span></span></span></p>  <p>About&nbsp;$150 million from the fund will be freed up to fund projects aimed at getting communities connected by next fall.</p>  <p>Senior officials with the department of&nbsp;Innovation, Science and Economic Development&nbsp;said applications will be reviewed on an ongoing basis until Jan. 15, 2021, with a goal of having projects completed by mid-November, 2021.</p>  <p>Deciding who gets upgraded connectivity first will depend on the service providers applying, they said.</p>  <p>Josh Tabish is&nbsp;corporate communications manager at the Canadian Internet Registration Authority, the not-for-profit agency that manages the .ca internet domain. He said he's hoping&nbsp;that a&nbsp;rapid build will bring relief to many Canadians over the next year.</p>    <p>"In terms of action, I think&nbsp;this is great news for Canadians who are stuck at home suffering from slow, crappy internet," he said.&nbsp;</p>  <p>But Tabish also said he hopes the government will look at need when deciding which projects should get approval first.&nbsp;His group has been working to identify the&nbsp;communities that&nbsp;have the slowest&nbsp;rates in Canada.</p>  <p>"What we really want to see happen is communities who are suffering with slow, sluggish connectivity get those upgrades first," he said.</p>  <p>The prime minister said the government also&nbsp;has reached a $600 million agreement with Telesat for satellite capacity to improve broadband service in remote areas and in the North.</p>    <p>"Good reliable internet isn't a luxury. It's a basic service," he said.</p>  <p>"Now more than ever, a video chat cutting out during a meeting or a connection that's too slow to upload a school assignment — that's not just a hassle, that's a barrier."</p>  <h2>Tories call out timelines</h2>  <p>The Opposition Conservatives criticized the government's timelines, arguing Canadians need better access now more than ever.</p>  <p>"This is absolutely unacceptable and a slap in the face to the nearly one million Canadians who don't have internet access at home, much less a reliable cell phone signal," said MP John Nater, Conservative critic&nbsp;for rural economic development.</p>  <p>"For months, Canada's Conservatives have been demanding concrete action to connect Canadians.&nbsp;We will continue to advocate for lower cell phone prices and for real improvements to broadband internet services, so that Canadians living in rural and remote areas have consistent access to these essential services."</p>  <p>The&nbsp;CRTC <a href="https://www.cbc.ca/news/politics/crtc-internet-essential-service-1.3906664">declared</a> broadband internet a basic telecommunications service in 2016.&nbsp;But its data suggest&nbsp;just&nbsp;<a href="https://crtc.gc.ca/eng/internet/internet.htm">40.8 per cent of rural Canadian households have access to </a>download speeds of&nbsp;at least 50 megabits per second (Mbps) and upload speeds of&nbsp;10 Mbps.</p>  <p>The government said those speeds will allow Canadians to work and learn online and access telehealth services.</p>  <p><em><strong>WATCH | Rural Canadians react to today's announcement</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Liberals promise to connect 98% of Canadians by 2030"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/732/431/politics_THURTON_broadband_money_7000kbps_1280x720_1817544259879.jpg" alt=""></p></div></div></div><span>After some pandemic-related delays, the Liberal government says it's now on track to connect 98 per cent of Canadians to high-speed internet by 2026. The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.<!-- --> <!-- -->1:47</span></span></span></p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/broadband-internet-1.5794901</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037074</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Converting Utzoo-Wiseman Usenet Tapes to PostgreSQL Back End Using Python]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25036780">thread link</a>) | @kxrm
<br/>
November 9, 2020 | https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/ | <a href="https://web.archive.org/web/*/https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="content" role="main" itemprop="mainEntityOfPage" itemscope="itemscope" itemtype="http://schema.org/Blog"> <article id="post-4678" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost"><div> <!-- .entry-header --><div itemprop="articleBody"><p>Recently, I came across a resource that allowed me to download the entire collection of UTZOO NetNews Archive of the earliest USENET posts. These were essentially the earliest available discussions posted to the Internet by people working at various Universities who were already connected to the Internet. There were approximately 2.1 million posts in these archives created between Feb 1981 and June of 1991. This article describes the journey of converting those tapes into fully searchable PostgreSQL database and later also into the <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer">usenetarchives.com</a> website.</p><p>Until 2001, these early Usenet discussions were considered being lost, but miraculously <a href="https://en.wikipedia.org/wiki/Henry_Spencer" target="_blank" rel="noopener noreferrer">Henry Spencer</a> from the University of Toronto, Department of Zoology was backing it up onto magnetic tapes and kept them stored for all these years (apparently at a great cost).</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png" alt="" width="325" height="259" srcset="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png 1282w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-300x239.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-768x613.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-1024x817.png 1024w" sizes="(max-width: 325px) 100vw, 325px"></a>H. Spencer had altogether 141 of these magnetic tapes, but there were of no use, so eventually, him and a couple of motivated people such as David Wiseman (who dragged 141 tapes back and forth in his a pickup truck), Lance Bailey, Bruce Jones, Bob Webber, Brewster Kahle, and Sue Thielen; embarked on a process of converting all of these tapes into the regular format, accessible to everyone.</p><p>And that’s the copy I downloaded. What a treasure, right?</p><p>Well, not so fast, once I unzipped the data, I realized that the TGZ format contains literally millions of small text files (each post in its own file). While it was certainly nice to have, it wasn’t something that I or anyone else could read. Certainly not in a forum like discussion format. It wasn’t obvious which post is the one that starts the discussion or which ones are the replies to the thread. And forget about searching through these files, that was utterly not possible. Just to put things into perspective, it took me over 5 hours to un-tar the archives.</p><p>That said, it didn’t take long for me to decide to develop a Python-based converter that would allow me to convert the entire collection from millions of flat files into a fully searchable PostgreSQL database. The following post talks about the process and also includes the Python code of the solution released as open source.</p><p>The UTZOO Usenet archive can be downloaded here:</p><ul><li>http://www.skrenta.com/rt/utzoo-usenet/</li><li>http://shiftleft.com/mirrors/utzoo-usenet/</li><li>https://ipfs.io/ipfs/QmTo7fRxpXwxv6Uw4TAAtyLWEmvugKaggrHSKNBTRHzWcA/</li><li>Or using this torrent: <a href="https://www.joe0.com/wp-content/uploads/2020/10/utzoo-wiseman-usenet-archive_archive.zip">utzoo-wiseman-usenet-archive_archive</a></li></ul><p>Once downloaded you’ll see that archive contains 161 x TAR Archive files. It looks like this:</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png" alt="" width="596" height="531" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png 832w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-300x268.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-768x685.png 768w" sizes="(max-width: 596px) 100vw, 596px"></a></p><p>So, I grabbed a copy of the 7-Zip archiver from <a href="https://www.7-zip.org/">https://www.7-zip.org</a> and started decompressing the files.</p><p>I ended up with over <strong>2,104,828</strong>&nbsp;flat text files in <strong>56,988</strong> folders, which was the entire copy of Henry Spencer’s Usenet archive.</p><p>For those who like numbers, here is each Utzoo tape along with its size, number of files and folders:</p><p id="MLqhONH"><img loading="lazy" width="602" height="2294" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png 602w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-79x300.png 79w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-269x1024.png 269w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-403x1536.png 403w" sizes="(max-width: 602px) 100vw, 602px"></p><h3>File Issues</h3><p>While examining the extract, I realized that Magnetic Tape 118 is uncompressed in \utzoo-wiseman-usenet-archive\news118f1 folder, named tape118, so I had rename it to tape118.tar and extracted it manually, only to realize it’s a copy of files which I already have. Someone creating the original archive forgotten to remove that file. There are 3 files in these folders that need to have.tar extension added and decompressed as well:</p><ul><li>\utzoo-wiseman-usenet-archive\news118f1\tape118</li><li>\utzoo-wiseman-usenet-archive\news120f1\tape120</li><li>\utzoo-wiseman-usenet-archive\news121f1\tape121</li></ul><p>If you opened one of the folders and navigated down to one of the many subfolders, you’d find a file that contained the message. For example, going into&nbsp;\utzoo-wiseman-usenet-archive\news006f1\b15\net\aviation folder, I was now apparently in the <strong>net.aviation</strong> Usenet group. But the only way to find out was to open one of the files and look at the content. Here I highlighted what it looked like.&nbsp;As you can see, each file seems to consist of a header, then a single empty line and the body of the message:</p><p id="RYYsysr"><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png" alt="" width="1110" height="759" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png 1110w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-300x205.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-768x525.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-1024x700.png 1024w" sizes="(max-width: 1110px) 100vw, 1110px"></a></p><p>So, I decided to build a Python parser, that went through all these files reading the header portion of each message and grouping all unique results together, giving me all the possible headers such as (From, Subject, Newsgroup, etc.). I found that there were about 79 x different types of headers. So it appeared that not all messages adhered to the same basic structure. Going through the headers, all had the standard set that was common across all posts.</p><p>Once I had the common field, I’ve created a Postgres database called ‘utzoo’</p><pre>create database utzoo;</pre><p>And a new schema called all_messages</p><pre>create schema all_messages;


</pre><p>The above database and schema were the pre-requisites. Everything else, like table creation, inserting the posts, etc. is part of the Python script and fully automated.</p><p>In terms of table creation, the script automatically creates 5 tables for each detected newsgroup:</p><ul><li>headers – parsed headers</li><li>references – references for each message</li><li>body – text of the message</li><li>from – who posted the message</li><li>subjects – list of unique subject lines</li></ul><p>This is what the script auto-creates for each unique Group name:</p><pre>create table all_messages.<strong>GroupName_headers</strong>
(
    id         bigserial not null
        constraint GroupName_headers_pk primary key,
    dateparsed timestamp,
    subj_id    bigint,
    ref        smallint,
    msg_id     text,
    msg_from   bigint,
    enc        text,
    contype    text,
    processed  timestamp default CURRENT_TIMESTAMP
);
alter table all_messages.GroupName_headers
    owner to postgres;


create table all_messages.<strong>GroupName_refs</strong>
(
    id      bigint,
    ref_msg text default null
);
alter table all_messages.GroupName_refs
    owner to postgres;

create table all_messages.<strong>GroupName_body</strong>
(
    id   bigint primary key,
    data text default null
);
alter table all_messages.GroupName_body
    owner to postgres;

create table all_messages.<strong>GroupName_from</strong>
(
    id   serial not null
        constraint GroupName_from_pk primary key,
    data text
);
alter table all_messages.GroupName_from
    owner to postgres;

create table all_messages.<strong>GroupName_subjects</strong>
(
    id      serial not null
        constraint GroupName_subjects_pk primary key,
    subject text
);
alter table all_messages.GroupName_subjects
    owner to postgres;</pre><p>Those will be the tables where the Python parser will dump all the data and make sure posts are properly lined up between tables.</p><p>The python script also creates indexes to make the inserting and later reading of the posts faster:</p><pre>create unique index GroupName_headers_uiidx on all_messages.GroupName_headers(id);
create unique index GroupName_headers_umidx on all_messages.GroupName_headers(msg_id);
create unique index GroupName_body_idx on all_messages.GroupName_body(id);; 
create unique index GroupName_from_idx on all_messages.GroupName_from(data);
create unique index GroupName_subjects_idx on all_messages.GroupName_subjects(subject);

</pre><p>Once created, the structure per group looks like this:</p><p id="kdsmyQE"><img loading="lazy" width="362" height="703" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png 362w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4-154x300.png 154w" sizes="(max-width: 362px) 100vw, 362px"></p><p>The following screenshot explains how it’s all wired up. I didn’t do any hardcoded relationships, but you can change the script if you want that.</p><p id="THgecCD"><img loading="lazy" width="601" height="496" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png 601w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef-300x248.png 300w" sizes="(max-width: 601px) 100vw, 601px"></p><p>The date is an integral part of each message and I had to do some data conversion massaging in Python to get the proper date, as dates were coming in a variety of formats. I’ve tried various libraries but dateutil.parser.parse standard date and time library for Python did the best job.</p><p>However, I still needed to account for various labelling of data fields in the headers, so if data wasn’t found in the ‘date’ header, I had to look into other header parts such as ‘NNTP-Posting-Date’, ‘X-Article-Creation-Date’,&nbsp;‘Posted’,&nbsp;or ‘Received’ fields.</p><p>Well and then it was all about creating a Python parser, start the PostgreSQL, point it to an archive directory, and wait :)</p><p>At the bottom of this article is the code of the Python solution. It’s about 1,000 lines, and it took altogether about 1 day to create and test it. The script is smart enough to keep the track of where it started, so if it needs to be interrupted, it’ll know where to continue from to get the job done.</p><p>The source code is available on GitHub as open-source under MIT license:</p><p><a href="https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py" target="_blank" rel="noopener noreferrer">https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py</a></p><p>The final solution artifact is called ‘<strong>utzoo2postgres.py</strong>‘ , and it was tested on Python 3.8.</p><p>Open the script and define the path to un-tared Utzoo archive directories.</p><p>Examples:</p><pre># for Windows
positionFilePath = "E:\\Usenet\\Utzoo\\"
# for linux:
# positionFilePath = "/Usenet/Utzoo/"</pre><p>Also, define the particulars of your PostgreSQL database:</p><pre>db_connection = psycopg2.connect(host="localhost", user="", password="", port="5432", database="utzoo")</pre><p>And then just execute the script!</p><pre>python 3 utzoo2postgres.py</pre><p><em>Note: In case you need to stop the program and run it later, the script is smart to resume from the last spot it was processing.</em></p><p>The script will process all Utzoo Archive messages in about 6 hours (depending on the speed of your machine).</p><p>Screenshot from processing:</p><p id="UwdOjId"><img loading="lazy" width="713" height="585" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png 713w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827-300x246.png 300w" sizes="(max-width: 713px) 100vw, 713px"></p><p>Here is a screenshot of the database after only a couple of minutes of conversion:</p><p id="JQYnVLo"><img loading="lazy" width="432" height="642" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png 432w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7-202x300.png 202w" sizes="(max-width: 432px) 100vw, 432px"></p><p>As you can see, the conversion utility produces a database with 5 tables per group where messages are linked to each other through auto-created indexes.</p><p id="kdsmyQE">Let’s say we want to look up all discussions in the<strong> net.physics</strong> discussions; and sort them out by the number of replies.</p><p>This is how you can do that:</p><p id="ymEaJie"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png" alt="" width="1198" height="625" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png 1198w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-300x157.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-1024x534.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-768x401.png 768w" sizes="(max-width: 1198px) 100vw, 1198px"></a></p><p>Now, we can look up a particular discussion by the ID. For example, we want the ID: 1648 from the screenshot above, the discussion with the subject: “<strong>Question on FTL and quantum mechanics</strong>“. That’s not so hard either:</p><p id="rcwUUqq"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png" alt="" width="1697" height="847" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png 1697w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-300x150.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1024x511.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-768x383.png 768w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1536x767.png 1536w" sizes="(max-width: 1697px) 100vw, 1697px"></a></p><p>It’s nice to have a database full of posts, but it’s hardly usable that way. I needed something that would allow me to easily access these posts.</p><p>So, once everything was done, I built a PHP script around this code and registered <a href="http://usenetarchives.com/" target="_blank" rel="noopener noreferrer">https://usenetarchives.com</a> to make all these archives available online, in an easy to read and search (forum-like) web site.</p><p>The PHP code is not part of this article, but you can head over to <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer"><strong>https://usenetarchives.…</strong></a></p></div></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</a></em></p>]]>
            </description>
            <link>https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036780</guid>
            <pubDate>Mon, 09 Nov 2020 16:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Lightweight Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25036750">thread link</a>) | @phacks
<br/>
November 9, 2020 | https://orbit.love/blog/towards-a-lightweight-jamstack | <a href="https://web.archive.org/web/*/https://orbit.love/blog/towards-a-lightweight-jamstack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Note: this article is an edited transcript of my talk of the same name at the Jamstack Berlin meetup. You can watch the video <a href="https://youtu.be/taOyVmLgym4">here</a>.</em><br></p><p>Jamstack is thriving. There is a plethora of languages, frameworks, libraries, and services that allow you to take full advantage of static websites while being able to leverage the JavaScript and Serverless ecosystems to build rich, dynamic, and whimsical experiences.</p><p>This often comes at a cost—as most Jamstack frameworks are based on JavaScript frameworks (NextJS and Gatsby on React, NuxtJS, and Gridsome on Vue), <a href="https://timkadlec.com/remembers/2020-04-21-the-cost-of-javascript-frameworks/">the JavaScript tax</a> takes a toll on performance, and, ultimately, on your users.</p><p>This article aims to give directions to curb that JS tax—whether by optimizing your existing JavaScript-framework-based website or by going for an alternative: Eleventy.</p><p>But first, let’s take a trip down memory lane to understand how we got where we are today.</p><h2>From Jekyll to Gatsby</h2><p>The Static/Jamstack ecosystem has evolved <em>a lot</em> over the past decade. This evolution has had a deep impact on the way we conceive websites and on the way our users experience them.</p><p>We’re going to cover three major steps through that journey from the (fictional) point of view of a casual discussion between a server and a user.</p><p>Our user will try and access a website, and our server will give her what she needs to <em>view</em> and <em>interact</em> with it. Those two important steps (the user can see the content, the user can interact with it) will be denoted with associated red badges, highlighting the moment in the conversation when they become possible.</p><p>Buckle up! We’re going all the way back to 2008.</p><h3><br>Pure Static (e.g. Jekyll)</h3><p><a href="https://jekyllrb.com/">Jekyll</a>, created in 2008, has long been the most popular Static Site Generator. Following the “<a href="http://www.aaronsw.com/weblog/000404">bake, don’t fry</a>” adage, it pre-computed all the pages of the website to have them readily available for its visitors.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/4da9af4b2075d28a8d8e43004d0da1dfa53663ad-1876x802.png" alt="A discussion goes like this. User: “hey could you pass me that index.html file you got there?”. Server: “sure thing here you go”. User: “thanks”"></p><p>It’s straightforward. Simple. No shenanigans. The desired page is served immediately to the user, and it is immediately available to view and interact with. Should she navigate to another page, her browser would fetch it in the same way it did the first.</p><p>As years went by, however, the user experience this solution provided somehow lagged behind what users got used to with mobile applications. Transitions, offline-mode, all the bells and whistles of the mobile revolution were nowhere to be found.</p><p>JavaScript frameworks, Angular, React and Vue among them, offered a new proposition that was to bring native-like experiences to the web, bringing us to our next stop: Client-Side Rendered websites.</p><h3><br>Client-Side Rendering (e.g. React, Vue)</h3><p>To make websites feel native-like, the solution offered by new JavaScript frameworks circa 2015 was to embed a JS-based engine that would create and update the HTML markup and associated styles dynamically. The upfront price to download, parse, and execute that engine would supposedly be offset by faster subsequent navigation and a richer user experience.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/b6ac711b81b742038bfa1d6503e6768a046c83dd-1872x1150.png" alt="Discussion goes like this. User: “oooh this new online publication looks cool can i see it?”. Server: “you know what why don’t you take all the raw materials and figure it out yourself”. User: “ wow rude but ok”. User computes the page for a moment. User: “ it works!”"></p><p>The major shift that happened with that evolution is that <strong>the cost of building web pages passed from the server to the user’s browser</strong>. This cost is indicated in the discussion with the gear icon, during which the screen is mostly blank or showing a loading indicator.<br></p><p>As a result, the performance of Client-Side Rendered websites depend widely on the specs of the device of the user, as JavaScript is CPU-intensive. The following video, by <a href="https://joshwcomeau.com/">Josh Comeau</a>, shows a 28 seconds difference (!) in load time for the Washington Post between an iPhone and a $100 Xiaomi Redmi 8.</p><h3>Server-Side Rendering (e.g. Next.js, Nuxt.js)</h3><p>A few years after this paradigm was introduced, these issues lead the pendulum to swing back towards the server, with the introduction of Server-Side Rendering.</p><p>Server-Side Rendering was introduced to fix one of the most annoying aspects of Client-Side Rendering: that the content the user came for would not be visible until after the (usually large) JavaScript code is downloaded, parsed, and executed. Those seconds can be <a href="https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks/">the difference between the visitor staying or leaving the website</a>.</p><p>Frameworks like Next.js and Nuxt.js appeared to try and bring the server back to its original role: building web pages. The approach would be different from Jekyll’s, though: in the Server-Side Rendering paradigm, the server acts as a web browser and renders the page using JavaScript—not Ruby.<br></p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/515d9fcb7a96cf4f41c6c090977e5fbbb0cec9cc-1716x1364.png" alt="Discussion goes like this. User: “i heard they worked on performance on this publication”. Server: “they did! here it is: i’m building the page very quicky…”. Server computes the page for a moment. Server: “and now send you the raw materials to build it yourself BUT now you have a nice picture of the finished page to look at meanwhile!”. Server: “and now send you the raw materials to build it yourself BUT now you have a nice picture of the finished page to look at meanwhile!”. User: “sweet! i can see the content first…”. User computes the page for a moment. User: “and now click around!”"></p><p><br>This approach leverages the power of the server to show the content to the visitor immediately. However, as interactivity still relies on client-side JavaScript, a delay is being introduced between the <em>availability</em> of the content and its <em>readiness</em>. From the point of view of the visitor, this can induce <em>rage clicks</em>: clicking on a button or a link has no effect for several seconds, as illustrated below.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/46db90282489daeae289e6307f4dab205b1b79d4-800x445.gif" alt="An animated gif showing two pages loading (one resembling AirBnB, the other Amazon). The pages look like they are ready, and a fictional user clicks on them for around 20 seconds until it has an effect. The fictional user gets annoyed, then angry, then despaired at the situation."></p><p><em>Source: Addy Osmany, <a href="https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4">The Cost Of JavaScript in 2018</a></em>​</p><p>There would be much more to say on the topic, as some of the frameworks have additional optimizations (prerendering, link-prefetching…), but we already covered enough ground to know that JavaScript has an impact on the user experience for Jamstack websites. This impact has been dubbed the <em>JavaScript tax</em>.</p><h2>Curbing the JavaScript tax</h2><p>Without entering into more details, we can follow the simple approximation that the less JavaScript is used, the lower the tax will be. Shipping less JavaScript then becomes a powerful approach to enhance the performance of our websites.</p><p>What if we could remove it altogether?</p><h3>Removing the JavaScript of JavaScript frameworks</h3><p><a href="http://nextjs.org/">Next.js</a> and <a href="https://www.gatsbyjs.com/">Gatsby</a> are two popular Server-Side Rendered JavaScript frameworks used on many Jamstack websites. They both use React as the underlying JS library to manage state and UI.</p><p>For this section, I’ll take <a href="https://phacks.dev/">my personal blog</a> as an example. I chose to build it with Gatsby, as I wanted to learn more about how it worked and could leverage my React experience to ship it quickly.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/1a51c0e83d712f7944362eea3142c9f42e60e64f-2756x1164.png" alt="A screenshot of my personal blog"></p><p>The Developer Experience was a delight and I’m overall pretty happy with it, but something felt <em>off</em>. My blog is pretty basic: an index of all the articles, a page for each, and a few other pages here and there. Yet it was powered by the same technology that powers Facebook, AirBnB and many other extremely complex websites: React. Any overengineering questions put aside, I still required any reader to download, parse, and execute React for <em>no benefits at all</em>. There are no smart widgets or complex UI to justify React. Only text and images.</p><p>My (outstanding) developer experience had an impact on my reader’s user experience. <a href="https://twitter.com/getify/status/1139625725504512003">There is no such thing as trickle-down UX</a>.</p><p>Well, it turns out that there <em>is</em> a way to get the best of both worlds. If, like my blog, your Gatsby website does not require React (or any other JavaScript) to run, you can <em>disable it</em>. The <a href="https://github.com/itmayziii/gatsby-plugin-no-javascript">Gatsby Plugin No Javascript</a> community plugin will let you enjoy the DX of Gatsby without taking a toll on user experience. A <a href="https://github.com/vercel/next.js/pull/11949">similar (experimental) plugin</a> also exists for Next.js.</p><p>Of course, not every website is as simple as my blog—that would be pretty boring. A lot of Gatsby and Next.js websites out there rely on React for their user experience: pretty animations, shopping carts, newsletter sign-ups, and the likes. Is there something we can do on those websites to make them lighter?</p><h3>(P)react</h3><p>When React is required for a website to run properly, we can’t just get rid of JavaScript. What we can do, however, is look for ways to reduce its footprint.</p><p><a href="https://preactjs.com/">Preact</a> is an alternative to React that has the same functionality, the same modern API, for a tenth of its size. The Preact team managed to drastically reduce the footprint by dropping support for some old browsers and legacy React APIs.</p><p>Although there are some slight differences (<a href="https://preactjs.com/guide/v10/differences-to-react#main-differences">see the list</a>), Preact can be used instead of React for many websites without any impact on the end-user, and barely any on the developers.</p><p>We switched from React to Preact on the Orbit app without issues and shaved off half of our JavaScript footprint in the process. If you’d like to try, there are plugins for <a href="https://www.gatsbyjs.org/packages/gatsby-plugin-preact/">Gatsby</a> and <a href="https://github.com/vercel/next.js/tree/canary/examples/using-preact">Next.js</a>, and <a href="https://preactjs.com/guide/v10/switching-to-preact">a guide for switching manually</a>.</p><p>Now, say you are in a situation where you have to create a brand new website. You want to use the Jamstack because you’re convinced of the benefits. You want to be mindful of the user experience, also because you’re convinced of the benefits. Say the website you want to create is similar to this very one, <a href="https://orbit.love/">orbit.love</a>.</p><p>What would you choose for a Lightweight Jamstack? What <em>did I</em> choose for a Lightweight Jamstack?</p><h3>Building orbit.love with Tailwind, Eleventy, and Alpine.js</h3><p>The Orbit website does not have a complex UI—interactivity is limited to a mobile nav menu, modals, and sign-ups for our newsletter and early access. I knew from the get-go that reaching out to (P)react would be heavy handed, so I looked for lightweight alternatives.</p><p>I went for the following: TailwindCSS, for styling, Eleventy, for the static site generation, and Alpine.js, for interactivity.</p><p><a href="http://11ty.dev/">Eleventy</a> is a JavaScript-based Static Site Generator that, despite being written in JavaScript, shares a lot more with Jekyll than with Gatsby. Indeed, Eleventy (also known as 11ty) <em>does not ship any JavaScript by default</em>. You are free to add any, of course, but it does not force you to use any library or framework.</p><p>Not having to use a JavaScript framework also meant that HTML, not JSX or Vue components, is now front and center in the code you write. This helped me avoid the usual traps when writing React: the infamous <a href="https://www.chillybin.com.sg/would-you-like-another-bowl-of-div-soup/#:~:text=What%20is%20Soup%3F,to%20make%20your%20eyes%20bleed.">div soup</a>, inaccessible components, or non-semantic tags.</p><p><a href="https://tailwindcss.com/">TailwindCSS</a> is a utility-first CSS framework, which means that instead of writing CSS for your components (class="navbar__mobile"), you combine utility classes that each do one specific thing (class="flex flex-row justify-center w-full").</p><p>I find this approach incredibly productive once you learn the grammar, and it makes for a resilient CSS architecture at the admitted cost of some duplication in your code. What makes it a great match with Eleventy is that you rarely, if ever, leave your HTML components when writing code. It helps me focus on the task at hand by …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orbit.love/blog/towards-a-lightweight-jamstack">https://orbit.love/blog/towards-a-lightweight-jamstack</a></em></p>]]>
            </description>
            <link>https://orbit.love/blog/towards-a-lightweight-jamstack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036750</guid>
            <pubDate>Mon, 09 Nov 2020 16:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe enforces IM-Services to store encryption master key for government access]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25036061">thread link</a>) | @lilatentakel
<br/>
November 9, 2020 | https://fm4.orf.at/stories/3008930/ | <a href="https://web.archive.org/web/*/https://fm4.orf.at/stories/3008930/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ss-storyText" role="article">
     
     <p><strong>Im EU-Ministerrat wurde binnen fünf Tagen eine Resolution beschlussfertig gemacht, die Plattformbetreiber wie WhatsApp, Signal und Co. künftig dazu verpflichtet, Generalschlüssel zur Überwachbarkeit von E2E-verschlüsselten Chats und Messages anzulegen.</strong></p>
     



     


     <p>Von <a href="http://fm4.orf.at/tags/erichmoechel">Erich Moechel</a></p><p>Der Terroranschlag in Wien wird im EU-Ministerrat dazu benützt, um ein Verbot sicherer Verschlüsselung für Services wie WhatsApp, Signal und viele andere im Schnellsiedeverfahren durchzusetzen. Das geht aus einem mit 6. November datierten internen Dokument der deutschen Ratspräsidentschaft an die Delegationen der Mitgliedsstaaten im Rat hervor, das ORF.at vorliegt.</p><p>Das sollte nun unter den „weiteren Schritten gegen den Terrorismus“ zu verstehen sein, die Frankreichs Präsident Emmanuel Macron mit Bundeskanzler Sebastian Kurz (ÖVP) im Rahmen einer Videokonferenz zu Wochenbeginn besprechen will. Der Beschluss ist bereits so weit akkordiert, dass er in der Videotagung der Innen- und Justizminister Anfang Dezember ohne weitere Diskussion verabschiedet werden kann.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/eu_ministerrat_cover.5944853.jpg" alt="Text" title="© EU Ministerrat" width="800" height="560"></p><p>EU Ministerrat</p><p>Rechts sind die Ratsarbeitsgruppen aufgelistet, an die dieser Text erging, dessen erste revidierte Fassung offenbar am Freitag fertig wurde. Wie im Ministerrat üblich, wurde das Dokument als „limite“ klassifiziert. Da es aus diesem Grund abseits des Rats nirgendwo für die Öffentlichkeit einsehbar ist, wird es hier zur Verfügung gestellt: <a href="https://files.orf.at/vietnam2/files/fm4/202045/783284_fh_st12143-re01en20_783284.pdf">[PDF]</a></p></div><h2>Analogien zur Vorratsdatenspeicherung</h2><p>Aus dem ursprünglich für Anfang kommender Woche geplanten Besuch Macrons wurde pandemiebedingt eine Videokonferenz „zur Bekämpfung des islamistischen Terrorismus“. Weiters steht ein Besuch des EU-Ratspräsidenten Charles Michel in Wien für Montag an, der ebenfalls mit Bundeskanzler Kurz Gespräche führen wird. Zudem empfängt Europaministerin Karoline Edtstadler (ÖVP) den französischen Europastaatssekretär Clement Beaune im Bundeskanzleramt. Alleine um Kondolenzbezeugungen geht es dabei natürlich nicht.</p><p>Mittlerweile wird zwar immer klarer, dass offenbar haarsträubende Ermittlungsfehler im BVT den Anschlag erst ermöglicht hatten und nicht fehlende digitale Überwachungsbefugnisse. Ob irgendein solcher Zusammenhang zur Tat besteht, ist allerdings unerheblich. In Brüssel wird so ein Anlass seit 25 Jahren mit schnöder Regelmäßigkeit dafür missbraucht, längst geplante Überwachungsvorhaben durchzusetzen. Auf diese Weise wurde die fünf Jahre lang in der EU umstrittene Vorratsdatenspeicherung nach den Zugsanschlägen in Madrid (2004) und London durch Islamisten (2005) durch den Ministerrat und das Parlament geschleust.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/ohne-titel-2.5944858.jpg" alt="Text" title="© EU Ministerrat" width="800" height="360"></p><p>EU Ministerrat</p><p>An den letzten Änderungen (fett und unterstrichen) sieht man, welche Formulierungen von einzelnen Mitgliedsstaaten in den Text reklamiert worden waren. Zuletzt eingefügt wurden „Terrorismus“ und eine unscheinbare Änderung im Wording. Statt der in allen Dokumenten seit 1995 üblichen Strafverfolger („law enforcement“) ist nun konsequent von „competent authorities“ die Rede. Wer damit gemeint ist, steht weiter unten.</p></div><h2>Verabschiedung ohne weitere Diskussionen</h2><p>Diese Resolution des Ministerrats ist laut Dokument - da wird um allfällige letzte Einwände gebeten -  nicht nur fast fertig ausformuliert. Sie ist im Rat offenbar auch bereits fertig abgestimmt. Am 19. November soll sie dann in der Ratsarbeitsgruppe zur Kooperation im nationalen Sicherheitsbereich (COSI) verabschiedet werden, am 25. ist die Vorlage im Rat der ständigen Vertreter der EU-Mitgliedsstaaten (COREPER) geplant. Dort hat der Ratsbeschluss bereits den Status eines I-Items, damit kann er ohne weitere Diskussion passieren.</p><p>In einer für Anfang Dezember geplanten virtuellen Sitzung des Rats der Innen- und Justizminister soll der Beschluss dann abgefeiert werden. Was folgen wird, ist klar, nämlich ein Auftrag des Ministerrats an die EU-Kommission, einen Entwurf für eine Verordnung zu erstellen, die dann das übliche Prozedere durch Parlament und Rat durchlaufen wird. Angesichts der offenbaren Einstimmigkeit wäre es im Ministerrat allerdings möglich, die geplante Regulation in ihrem Kern auch ohne Mitwirkung des Parlaments durchzuziehen. Auch das hat es in Zusammenhang mit Überwachung schon gegeben. So wurde der berühmte Beschluss im Fischereiausschuss des Rats von 1995 zur Überwachbarkeit der damals neuen GSM-Netze als A-Item (beschlossene Sache) durchgezogen, von dem das EU-Parlament erst nach seinem Inkrafttreten 1996 Kenntnis erhielt.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/ohne-titel-1.5944852.jpg" alt="Text" title="© Public | FiveEyes" width="1280" height="255"></p><p>Public | FiveEyes</p><p>Diese Passage sieht dem EU-Ministerratsbeschluss zwar zum Verwechseln ähnlich, stammt jedoch nicht aus Europa. <a href="https://www.justice.gov/opa/pr/international-statement-end-end-encryption-and-public-safety">Sie findet sich vielmehr in einer Resolution der Innen- und Justizminister</a> aus den „Five Eyes“-Staaten, datiert mit 11. Oktober. Die Spionageallianz ist neben Europol und diversen europäischen Diensten eine der treibenden Kräfte, auf die der aktuelle Ministerratsbeschluss zurückzuführen ist.</p></div><h2>Treibende Kräfte im Hintergrund</h2><p>Frankreich treibt das ursprünglich von Großbritannien angestoßene Vorgehen gegen sichere Verschlüsselung auf Plattformen wie WhatsApp bereits das ganze Jahr auf EU-Ebene voran. Der Boden dafür wurde seit 2015 in einer ganze Serie von Kampagnen vorbereitet, die abwechselnd von Europol und FBI bzw. den Diensten der „Five Eyes“-Spionageallianz samt den dafür zuständigen Ministern gefahren wurden. Erst Anfang Oktober hatten die Innenminister dieser fünf Staaten - Großbritannien, USA, Australien, Neuseeland und Kanada - die Internetkonzerne erneut aufgefordert, ihre IT-Netze mit Hintertüren für die Strafverfolger auszustatten.</p><p>Sekundiert wurden sie dabei von ihren Amtskollegen in Japan und in Indien. Warum sich die Geheimdienstallianz so auffällig um die bedauernswerten Strafverfolger jahrelang öffentlich gesorgt hat, ist eigentlich selbsterklärend. Sie sind die übrigen „competent authorities“ die ebenfalls Zugang erhalten werden.</p><h2>„Competent authorities“ lassen grüßen</h2><p>Laut weiteren Informationen, die ORF.at vorliegen, soll die Überwachungsmethode „Exceptional Access“ gewählt werden, das geht indirekt bereits aus diesem  nicht technischen Resolutionstext hervor. Unter acht möglichen Modellvorschlägen, die allesamt aus technischen Szenarien verschiedener Geheimdienste stammen, wurde jener aus dem britischen „National Cyber Security Center“ (NCSC) ausgewählt. Das NCSC ist eine Abteilung des britischen Militärgeheimdienstes GCHQ. Plattformbetreiber wie WhatsApp, Signal und Co, die alle E2E-Verschlüsselung benützen, sollen verpflichtet werden, zusätzlich Generalschlüssel anzulegen und diese zu hinterlegen.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20200939/eu_ministerrat_diskussionspapier_ea.5941753.jpg" alt="Skizzen aus Dokumenten" title="© EU-Ministerrat" width="800" height="409"></p><p>EU-Ministerrat</p><p>Hier wird ein Nachschlüssel für Dritte in den Verschlüsselungsprozess zweier Chatteilnehmer geschmuggelt, es ist die Methode „Exceptional Access“ des GCHQ. Mit sicherer Verschlüsselung hat diese wie alle anderen in diesem Dokument enthaltenen Varianten nichts zu tun, es sind einfach nur verschiedene Arten von „Man in the middle“ -Angriffen auf sichere Kommunikation. Die Studie wurde im Auftrag der deutschen Ratspräsidentschaft erstellt und im August <a href="https://www.politico.eu/wp-content/uploads/2020/09/SKM_C45820090717470-1_new.pdf">vom Fachmagazin Politico</a> veröffentlicht.</p></div><p>Das nämlich sind die „competent authorities“: GCHQ, DGSE, BND usw., deren Staubsaugermethoden an den Glasfasern wegen zunehmender Transportverschlüsselung immer weniger verarbeitbare Daten einbringen. Um diese drohende Datenarmut abzuwenden, wurden jetzt Generalschlüssel verlangt - und wie es aussieht, wird das im Rat auch bewilligt. Dann kann das BVT, das es nicht einmal schafft, einen Terroristen auszuschalten, der von zwei anderen Diensten zweimal auf dem Silbertablett serviert wird, künftig auch in Chatverläufen wochenlang nicht ermitteln.</p>
     
     



   </div></div>]]>
            </description>
            <link>https://fm4.orf.at/stories/3008930/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036061</guid>
            <pubDate>Mon, 09 Nov 2020 15:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separating User Database and Authorization from Apps with Istio and FusionAuth]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25035985">thread link</a>) | @mooreds
<br/>
November 9, 2020 | https://reachablegames.com/oidc-fusionauth-istio/ | <a href="https://web.archive.org/web/*/https://reachablegames.com/oidc-fusionauth-istio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://reachablegames.com/content/images/size/w300/2020/11/security.jpg 300w,
                            https://reachablegames.com/content/images/size/w600/2020/11/security.jpg 600w,
                            https://reachablegames.com/content/images/size/w1000/2020/11/security.jpg 1000w,
                            https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg" alt="Separating your User Database and Authorization from Applications with Istio and FusionAuth">
            </figure>

            <section>
                <div>
                    <p>Kubernetes is a tremendously powerful cluster management system. &nbsp;There are many pluggable technologies to choose from that exhibit the features you desire, which is great because you have options--but also comes with the down-side that the likelihood someone else has done exactly what you are trying to do is slim. &nbsp;Eventually, there will be some consolidation as developers gather around the best solutions, but for the moment, there are lots of interesting projects to choose from (and not a ton of great examples for certain configs). Today, I'm sharing a slightly challenging setup and hoping it helps the community.</p><p>I am using Istio as my L7 ingress and routing controller, which is based on Envoy. &nbsp;It is a highly scalable L7 proxy with excellent performance characteristics and relatively mature feature set. When it came time to implement a basic <code>/admin</code> route on a project, I came up with the list of features that I wanted to achieve. &nbsp;My desired config:</p><ul><li>Applications should not have access to user passwords or necessarily email</li><li>Applications should not re-implement role-based access control (RBAC) security, as every application will need it</li><li>Users should be able to login without creating yet another username/password to remember, but support it if they prefer</li><li>Users should be able to self-register, password reset if necessary, and manage what remote authentications are associated with their account without needing support (Google keyword CIAM)</li><li>Application Admins should be able to edit the role of users, either explicitly or by group permissions, with a visual interface for non-technical people to control access</li><li>K8s Ops should be able to change what RBAC rules protect individual routes to applications without a redeploy</li><li>Fully self-hosted, to limit external dependencies and have auditable security around user data</li></ul><p>The simplest way to get started is to follow the excellent walkthrough on <a href="https://www.blog.jetstack.io/blog/istio-oidc/">Jetstack.io</a> that explains in reasonably good detail how to cover your whole ingress with JWT handling. &nbsp;I won't go over all that detail here. &nbsp;Instead, I will present the exact YAML manifests necessary to directly deploy a working config, as well as show screenshots of relevant bits in FusionAuth of exactly how to configure the application so it communicates properly with these manifests.</p><h3 id="why-fusionauth">Why FusionAuth?</h3><p>I usually try out two or three alternative technologies before settling into one I like. Although I did start with KeyCloak, it felt a little unpolished and left a lot to be desired when it came to explaining how to configure it if the terminology wasn't familiar (eg. people who aren't security professionals). &nbsp;I studied several other options and it came down to Gluu or FusionAuth. &nbsp;The main deciding factor for me in favor of FusionAuth was the amount of documentation and tutorials (with much appreciated touches of humor). &nbsp;There is also a clear effort made by the developers to provide official docker images and Kubernetes examples that show real world use. &nbsp;I have been remarkably satisfied with this decision.</p><h3 id="quick-architecture-overview">Quick Architecture Overview</h3><p>Ok, so let's talk about the architecture of how this works together. &nbsp;Like any other traffic using Istio, a request will come into an application by following the routing rules of a <code>VirtualService</code> to a <code>Service</code>, then to a Deployment's <code>Pod</code>. &nbsp;To use the Istio security features, this pod needs to have the Sidecar Proxy running, otherwise the rules don't do anything. (This is unfortunate, as it has been my experience that the sidecar can cause connectivity issues with certain workloads, so just be aware it can cause side effects and you may need to explicitly create and configure the <code>Sidecar</code> for this namespace). The easiest way to get this working is to enable automatic sidecar proxy injection on a new <code>Namespace</code> and deploy the application there. &nbsp;By declaring a <code>RequestAuthentication</code> rule, we configure Istio to refuse any traffic that doesn't have a validly signed Json Web Token (JWT). &nbsp;And by declaring an <code>AuthorizationPolicy</code> rule, we configure Istio to accept or deny traffic by matching specific HTTP paths or user roles, etc. &nbsp;That's great! &nbsp;Right?</p><p>Well, Istio isn't quite mature enough to speak Open ID Connect. &nbsp;It's only smart enough to expect a validly decoded JWT and do some simple pattern matching against its contents. &nbsp;When those rules fail, you just get <code>RBAC: access denied</code> as a response to your request. &nbsp;There's no redirection logic to send the browser to the auth server login page. &nbsp;So, let's teach it to do that with a simple <code>EnvoyFilter</code> rule that is injected on <code>SIDECAR_INBOUND</code>. This lets us target specific applications to protect only the routes we care about without impacting anything else. </p><p>A few critical details: <code>RequestAuthentication</code> only accepts a &nbsp;JWT that is signed with an RSA key, because HMAC is a symmetrical key and anyone who can decode it can also sign it. &nbsp;This means it needs to know where to get the public RSA key, which is supplied in the <code>issuer</code> field. &nbsp;Assuming this checks out, Istio then looks at any <code>AuthorizationPolicy</code> rules and either <code>ALLOW</code> or <code>DENY</code> traffic based on matching or non-matching details. &nbsp;In this case, I have provided a basic rule that allows anyone who has been verified to have an account with this application, and further restrict the <code>/admin/</code> path to accounts that have the <code>admin</code> role. &nbsp;Should anything go wrong, Istio just says <code>RBAC: access denied</code> . &nbsp;To diagnose, just delete these rules and try hitting the endpoint to see what errors pop up. &nbsp;If these rules are removed and you are still getting Unauthorized messages, it's oauth2-proxy refusing the user--check the config and logging to see why.</p><p>Here's the YAML we've all been waiting for. &nbsp;This fully describes a working config where the <code>VirtualService</code> is in the default namespace but everything else is in <code>auth</code> just to keep it away from everything else. &nbsp;The application is hosted at <code>https://auth-example.reachablegames.com</code>. &nbsp;Certain difficult and undocumented details that cause problems if not configured properly have been commented below--please pay attention before changing or simplifying things.</p><pre><code># create namespace where applications can have sidecar injection
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app: auth
    istio-injection: enabled
  name: auth
---
# This rule makes sure the JWT is decoded and passed through to the web server as HTTP_PAYLOAD base64 encoded.
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  jwtRules:
  - issuer: "https://fusionauth.reachablegames.com"
    # this passes the full bearer token as the "authorization" header
    forwardOriginalToken: true        
    # this passes just the decoded JWT as "payload" header
    outputPayloadToHeader: "payload"  
---
# This rule verifies the user is an authenticated user (requestPrincipals) and also authorized (request.auth.claims)
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  action: ALLOW
  rules:
  - from:  # limit admin path to users with admin role
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        paths: ["/admin/*"]
    when:
    - key: request.auth.claims[roles]
      values: ["admin"]
  - from:  # allow anyone who is authorized to access the site to access anything other than /admin
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        notPaths: ["/admin/*"]
---
# This intercepts and sends the traffic directly to the oauth2-proxy if there isn't a JWT cookie in the header.
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: auth-example
  namespace: auth
spec:
  workloadSelector:
    labels:
      app: auth-example
  configPatches:
  - applyTo: HTTP_FILTER
    match:
      context: SIDECAR_INBOUND
      listener:
        portNumber: 80
        filterChain:
          filter:
            name: envoy.http_connection_manager
            subFilter:
              name: envoy.filters.http.jwt_authn
    patch:
      operation: INSERT_BEFORE
      value:
        name: envoy.filters.http.ext_authz
        typed_config:
          "@type": type.googleapis.com/envoy.config.filter.http.ext_authz.v2.ExtAuthz
          http_service:
            server_uri: # Note, this absolutely must be the FQDN for the service.  Does not work as a shortname.
              uri: http://auth-example-oauthproxy.auth.svc.cluster.local:8081
              cluster: outbound|8081||auth-example-oauthproxy.auth.svc.cluster.local
              timeout: 10s
            authorizationRequest:
              allowedHeaders:
                patterns:
                - exact: cookie
            authorizationResponse:
              allowedUpstreamHeaders:
                patterns:
                - exact: authorization
---
# Critical: spell out the FQDN because this VirtualService is in "default" but the Service is in "auth"
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: auth-example
  namespace: default
  labels:
    app: auth-example
spec:
  hosts:
  - "auth-example.reachablegames.com"
  gateways:
  - istio-gw
  http:
  - route:
    - destination:
        host: auth-example.auth.svc.cluster.local  # this refers to a Service with name="auth-example"
        port:
          number: 80
---
# Sends traffic to the auth-example deployment pods, which is our application we are trying to secure
apiVersion: v1
kind: Service
metadata:
  name: auth-example
  namespace: auth
  labels:
    app: auth-example
spec:
  ports:
  - port: 80
    name: http-web
    targetPort: http-web
    protocol: TCP
  selector:
    app: auth-example  # send traffic to the auth-example pods
  sessionAffinity: None
  type: ClusterIP
---
# Sends …</code></pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reachablegames.com/oidc-fusionauth-istio/">https://reachablegames.com/oidc-fusionauth-istio/</a></em></p>]]>
            </description>
            <link>https://reachablegames.com/oidc-fusionauth-istio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035985</guid>
            <pubDate>Mon, 09 Nov 2020 15:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oneapi.jl – Native Julia Support for Intel GPUs]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25035875">thread link</a>) | @KenoFischer
<br/>
November 9, 2020 | https://juliagpu.org/2020-11-05-oneapi_0.1/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-11-05-oneapi_0.1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main"><i data-feather="calendar"></i><time datetime="2020-11-05">Nov 5, 2020</time><br><i data-feather="edit-2"></i>Tim Besard<p>We’re proud to announce the first version of oneAPI.jl, a Julia package for programming
accelerators with the <a href="https://www.oneapi.com/">oneAPI programming model</a>. It is currently
available for select Intel GPUs, including common integrated ones, and offers a similar
experience to CUDA.jl.</p><p>The initial version of this package, v0.1, consists of three key components:</p><ul><li>wrappers for the oneAPI Level Zero interfaces;</li><li>a compiler for Julia source code to SPIR-V IR;</li><li>and an array interface for convenient data-parallel programming.</li></ul><p>In this post, I’ll briefly describe each of these. But first, some essentials.</p><h2 id="installation">Installation</h2><p>oneAPI.jl is currently only supported on 64-bit Linux, using a sufficiently recent kernel,
and requires Julia 1.5. Furthermore, it currently only supports a limited set of Intel GPUs:
Gen9 (Skylake, Kaby Lake, Coffee Lake), Gen11 (Ice Lake), and Gen12 (Tiger Lake).</p><p>If your Intel CPU has an integrated GPU supported by oneAPI, you can just go ahead and
install the oneAPI.jl package:</p><pre><code>pkg&gt; add oneAPI
</code></pre><p>That’s right, no additional drivers required! oneAPI.jl ships its own copy of the <a href="https://github.com/intel/compute-runtime">Intel
Compute Runtime</a>, which works out of the box on
any (sufficiently recent) Linux kernel. The initial download, powered by Julia’s artifact
subsystem, might take a while to complete. After that, you can import the package and start
using its functionality:</p><pre><code>julia&gt; using oneAPI

julia&gt; oneAPI.versioninfo()
Binary dependencies:
- NEO_jll: 20.42.18209+0
- libigc_jll: 1.0.5186+0
- gmmlib_jll: 20.3.2+0
- SPIRV_LLVM_Translator_jll: 9.0.0+1
- SPIRV_Tools_jll: 2020.2.0+1

Toolchain:
- Julia: 1.5.2
- LLVM: 9.0.1

1 driver:
- 00007fee-06cb-0a10-1642-ca9f01000000 (v1.0.0, API v1.0.0)

1 device:
- Intel(R) Graphics Gen9
</code></pre><h2 id="the-onearray-type">The <code>oneArray</code> type</h2><p>Similar to CUDA.jl’s <code>CuArray</code> type, oneAPI.jl provides an array abstraction that you can
use to easily perform data parallel operations on your GPU:</p><pre><code>julia&gt; a = oneArray(zeros(2,3))
2×3 oneArray{Float64,2}:
 0.0  0.0  0.0
 0.0  0.0  0.0

julia&gt; a .+ 1
2×3 oneArray{Float64,2}:
 1.0  1.0  1.0
 1.0  1.0  1.0

julia&gt; sum(ans; dims=2)
2×1 oneArray{Float64,2}:
 3.0
 3.0
</code></pre><p>This functionality builds on the <a href="https://github.com/JuliaGPU/GPUArrays.jl/">GPUArrays.jl</a>
package, which means that a lot of operations are supported out of the box. Some are still
missing, of course, and we haven’t carefully optimized for performance either.</p><h2 id="kernel-programming">Kernel programming</h2><p>The above array operations are made possible by a compiler that transforms Julia source code
into SPIR-V IR for use with oneAPI. Most of this work is part of
<a href="https://github.com/JuliaGPU/GPUCompiler.jl">GPUCompiler.jl</a>. In oneAPI.jl, we use this
compiler to provide a kernel programming model:</p><pre><code>julia&gt; function vadd(a, b, c)
           i = get_global_id()
           @inbounds c[i] = a[i] + b[i]
           return
       end

julia&gt; a = oneArray(rand(10));

julia&gt; b = oneArray(rand(10));

julia&gt; c = similar(a);

julia&gt; @oneapi items=10 vadd(a, b, c)

julia&gt; @test Array(a) .+ Array(b) == Array(c)
Test Passed
</code></pre><p>Again, the <code>@oneapi</code> macro resembles <code>@cuda</code> from CUDA.jl. One of the differences with the
CUDA stack is that we use OpenCL-style built-ins, like <code>get_global_id</code> instead of
<code>threadIdx</code> and <code>barrier</code> instead of <code>sync_threads</code>. Other familiar functionality, e.g. to
reflect on the compiler, is available as well:</p><pre><code>julia&gt; @device_code_spirv @oneapi vadd(a, b, c)
; CompilerJob of kernel vadd(oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1})
; for GPUCompiler.SPIRVCompilerTarget

; SPIR-V
; Version: 1.0
; Generator: Khronos LLVM/SPIR-V Translator; 14
; Bound: 46
; Schema: 0
               OpCapability Addresses
               OpCapability Linkage
               OpCapability Kernel
               OpCapability Float64
               OpCapability Int64
               OpCapability Int8
          %1 = OpExtInstImport "OpenCL.std"
               OpMemoryModel Physical64 OpenCL
               OpEntryPoint Kernel
               ...
               OpReturn
               OpFunctionEnd
</code></pre><h2 id="level-zero-wrappers">Level Zero wrappers</h2><p>To interface with the oneAPI driver, we use the <a href="https://github.com/oneapi-src/level-zero">Level Zero
API</a>. Wrappers for this API is available under the
<code>oneL0</code> submodule of oneAPI.jl:</p><pre><code>julia&gt; using oneAPI.oneL0

julia&gt; drv = first(drivers())
ZeDriver(00000000-0000-0000-1642-ca9f01000000, version 1.0.0)

julia&gt; dev = first(devices(drv))
ZeDevice(GPU, vendor 0x8086, device 0x1912): Intel(R) Graphics Gen9
</code></pre><p>This is a low-level interface, and importing this submodule should not be required for the
vast majority of users. It is only useful when you want to perform very specific operations,
like submitting an certain operations to the command queue, working with events, etc. In
that case, you should refer to the <a href="https://spec.oneapi.com/level-zero/latest/index.html">upstream
specification</a>; The wrappers in the
<code>oneL0</code> module closely mimic the C APIs.</p><h2 id="status">Status</h2><p>Version 0.1 of oneAPI.jl forms a solid base for future oneAPI developments in Julia. Thanks
to the continued effort of generalizing the Julia GPU support in packages like GPUArrays.jl
and GPUCompiler.jl, this initial version is already much more usable than early versions of
CUDA.jl or AMDGPU.jl ever were.</p><p>That said, there are crucial parts missing. For one, oneAPI.jl does not integrate with any
of the vendor libraries like oneMKL or oneDNN. That means several important operations, e.g.
matrix-matrix multiplication, will be slow. Hardware support is also limited, and the
package currently only works on Linux.</p><p>If you want to contribute to oneAPI.jl, or run into problems, check out the GitHub
repository at <a href="https://github.com/JuliaGPU/oneAPI.jl">JuliaGPU/oneAPI.jl</a>. For questions,
please use the <a href="https://discourse.julialang.org/c/domain/gpu">Julia Discourse forum</a> under
the GPU domain and/or in the #gpu channel of the <a href="https://julialang.org/community/">Julia
Slack</a>.</p></main></div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-11-05-oneapi_0.1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035875</guid>
            <pubDate>Mon, 09 Nov 2020 15:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture Playbook]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25035752">thread link</a>) | @yarapavan
<br/>
November 9, 2020 | https://nocomplexity.com/documents/arplaybook/index.html | <a href="https://web.archive.org/web/*/https://nocomplexity.com/documents/arplaybook/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        
          By Maikel Mardjan<br>
        
            © Copyright 2018,2019, 2020 BM-Support.org. Created by Maikel Mardjan. This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (cc-by-sa).<br>
      </p>
  </div></div>]]>
            </description>
            <link>https://nocomplexity.com/documents/arplaybook/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035752</guid>
            <pubDate>Mon, 09 Nov 2020 15:31:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't care what Elon Musk thinks anymore]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25035658">thread link</a>) | @avthar
<br/>
November 9, 2020 | https://avthar.com/blog/dont-outsource-thinking | <a href="https://web.archive.org/web/*/https://avthar.com/blog/dont-outsource-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f18334b57a4385ee2a76"><div><p><em>This blog originally appeared in my </em><a href="https://avthar.substack.com/"><em>weekly newsletter</em></a><em>, where I share ideas I’m reflecting upon, experiments I’m trying and lessons I’ve learned, all to help you level up your own life. To get posts like this straight to your inbox, </em><a href="https://avthar.substack.com/"><em>subscribe here</em></a><em>.</em></p><p>—</p><p>Youtube recommended to me&nbsp;<a href="https://www.youtube.com/watch?v=vVnDE8wSrVo">what Elon Musk would work on if he was 22 years old today</a>. The video has almost 3 million views. In the past, I would’ve immediately watched the whole video, gotten inspired by what Elon thought were industries important to the future of humanity and then spent a ton of time working on that and telling everyone about it. All because Elon Musk thought it was important.&nbsp;</p><p><strong>This is outsourcing your thinking</strong>. This trick served me well in highschool and throughout college, but it’s not sustainable for long term success and happiness.&nbsp;</p><p>There are two problems with outsourcing your thinking. Continuing with the example of past me, there are things I’m already interested in, have&nbsp;<a href="https://nav.al/specific-knowledge">specific knowledge</a>&nbsp;about or possess a competitive advantage in, that won’t be mentioned on Elon’s list. Consequently, the first problem is that I will look down on those things as less meaningful and important and not pursue them, despite my better suitability and chances of success in those areas.</p><p>The second problem with outsourcing your thinking is that once the novelty of the problem fades away, I’d be faced with navigating difficulty, naysayers and the friction of creating something new, without an internal compass to guide me toward the correct paths to take. Put simply, Elon Musk isn’t there to talk me through what he thinks the path forward to be. This all stems from the issue that I pursued something, not because I had interest in that thing, actually enjoyed it or thought it was important, but because Elon Musk (or whoever else) thought it was important to work on. And I followed his thinking, rather than thinking for myself.</p><p>The reason this is important is because most success in business is having&nbsp;<strong>product-market-founder fit</strong>, not just about working on what’s world changing or hot. It’s about building a product that solves a burning problem for the right market and&nbsp;<strong>being the right person, with the right intuition</strong>&nbsp;to bring that product to market, operate that company and delight those customers. Even if you’re working on an important problem, if you don’t have conviction that comes from your own mental models, you’ll get burned when chaos hits. Just ask all the crypto ‘experts’ of 2016/17.&nbsp;<strong>It’s better to build something that’s an expression of yourself, rather than something others think is smart.</strong></p><p>Outsourcing your thinking is a manifestation of the error of trusting others more than we trust ourselves.&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a>&nbsp;talks about how this phenomenon of outsourcing your thinking happens all the time in the investing world:</p><blockquote><p>“<em>If you take investors, there might be an investment, which one from the outside we think is objectively good. But it really isn't objectively good. It has to fit into one's portfolio of investments in a way that emerges from one's own mental models. Otherwise, it is not a form of self expression. Then, when you enter volatility, you're not gonna know what to do with it.</em>” -&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a></p></blockquote><p>Elon Musk is a placeholder for anyone telling you what you should do or think. That could be entrepreneurs or VCs you idolize or maybe your parents (especially true if you’re brown). The reality is that you should not care what Elon Musk or anyone else says is important, you should decide for yourself what you should work on, based on following your own curiosity and interest.&nbsp;<strong>Do the hard work of experimenting, exploring and thinking for yourself. Don’t outsource your thinking.</strong></p><p><a href="https://avthar.substack.com/"><em>Subscribe here</em></a><em> to get posts like this straight to your inbox, </em></p></div></div></div>]]>
            </description>
            <link>https://avthar.com/blog/dont-outsource-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035658</guid>
            <pubDate>Mon, 09 Nov 2020 15:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dying for movies: Suicide highlights labour issues in Canada's VFX sector]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035628">thread link</a>) | @alibarber
<br/>
November 9, 2020 | https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>MONTREAL -- 
	Last April, Malcolm Angell, a 46-year-old New Zealander who moved to Montreal to work in the city's famed visual effects industry, was taken to hospital after attempting suicide.</p>
<p>
	He was back at work two days later at Montreal-based visual effects studio Mill Film, according to his brother, Ivan. A month later -- shortly after learning his mother had a brain tumour and didn't have long to live -- Angell tried to kill himself again. This time he died.</p>
<p>
	Angell's former colleagues allege the work environment at Mill Film was toxic. They say 80-hour workweeks were common, and that Angell was regularly humiliated by his bosses. Ivan says he's certain his brother would have quit -- were it not for a clause in Angell's contract requiring he pay a $35,000 penalty.</p>
<p>
	The story told by Angell's colleagues is not uncommon in Canada's visual effects and animation sectors, according to industry insiders. Long overtime hours, often unpaid, are seen as normal, they say. And employees in these industries are vulnerable -- particularly foreign workers -- who toil on short-term contracts and are afraid to speak up out of fear of not getting hired again.</p>
<p>
	For Vanessa Kelly, a former animator and union organizer in Vancouver's animation industry, Angell's suicide is a sign that something is deeply wrong with the visual effects sector. She said similar issues exist in animation and within video game companies across Canada.</p>
<p>
	"These are movies. Why are people dying for movies?" said Kelly, general director of the Art Babbitt Appreciation Society, which is trying to organize animators in Vancouver.</p>
<p>
	Angell had nearly 20 years experience in film, and got his start working on set during the production of The Lord of The Rings. In August 2019, he moved to Montreal to work in the city's visual effects industry -- one of the largest in the world. Colleagues and friends say it was not long before the job started to get to him.</p>
<p>
	The Canadian Press spoke to three of Angell's former colleagues, who painted a picture of a workplace where Angell was under extreme pressure and where bosses yelled at him during meetings. Complaints to human resources and to senior mangers, they said, went nowhere.</p>
<p>
	The Canadian Press has agreed not to identify those workers because they fear repercussions. All three said people in the industry who speak out against work conditions are frequently blacklisted.</p>
<p>
	"Work kinda sucks," Angell wrote in an email to a friend in New York City in early September 2019. By November, in an email to the same friend, he said he was doing the work of two people. A planned trip to New Zealand for a wedding in February, 2020, was cancelled, his brother Ivan said in a recent interview, because Angell couldn't get the time off work.</p>
<p>
	Ivan Angell said friends noticed a change in his brother by December. The man who was described in an obituary as a "superfriend" who was always smiling, had become a "shadow of himself," he said.</p>
<p>
	Julia Neville, with the International Alliance of Theatrical Stage Employees, said fears of being blacklisted for speaking out in the visual effects industry are legitimate. Visual effects artists are precarious workers, Neville said, because their contracts are typically for one project at a time. "There's always that underlying insecurity," she said. Foreign workers, such as Angell, are "particularly vulnerable."</p>
<p>
	"They can't just cross the street and work for another visual effects house -- their whole ability to work in Canada is tied to a specific employer," Neville said. Much of the film industry is unionized, while the large majority of visual effects artists are not, she explained. Long hours and unpaid overtime "are very common," she said, adding that unfair labour practices are frequent in other entertainment sectors, such as animation, reality television and in commercials.</p>
<p>
	Neville said visual effects companies try to underbid each other for work on projects produced by major movie studios. "That pressure is exerted downward onto the worker," she said. "What ends up happening is there's never enough time allotted to accomplish what you need done."</p>
<p>
	Angell's former colleagues said he was under extreme pressure to complete his part in the movie "Bios," starring Tom Hanks. They said Angell and the team he oversaw had been told by his bosses at Mill Film to finish additional work but hadn't been given more time or money to get it done.</p>
<p>
	Another element that tied Angell to his employer was his contract, a copy of which The Canadian Press viewed. The contract included a clause stating he was liable to pay Mill Film a $35,000 indemnity should he leave in the middle of a project.</p>
<p>
	The indemnity clause identified Angell as a "key member" of the team and indicated that the company would be contractually committing Angell's services to its client. The contract said that for "certain very exceptional and serious" reasons the company could decide to waive the indemnification clause.</p>
<p>
	Adelle Blackett, a law professor at McGill University and labour law expert, said that clause "is deeply disturbing." Quebec's labour standards require employers to provide working conditions that "safeguard employees' dignity, health and well-being," she wrote in an email. "An employee working in conditions of freedom must be able to terminate an employment contract with only minimally necessary restrictions."</p>
<p>
	Technicolor, Mill Film's parent company, did not make anyone available to speak on the record. In an emailed statement, the company said Angell's death was a "traumatic and tragic event for his family, friends and for our team. We mourn his passing and continue to express our deepest condolences to his family."</p>
<p>
	The company said it has introduced a new program aimed at supporting employee mental health since Angell's death -- due to the "severity and isolating nature of the pandemic." Another program has been launched encouraging employees to "call out" inappropriate behaviour, the company said.</p>
<p>
	"Technicolor has had longstanding and robust anti-harassment policies in place in Canada. This specifically includes broad anti-bullying and related anti-retaliation policies, among others," it said. The company said it takes complaints seriously and that it didn't receive any formal complaints about Angell's treatment at Mill Film.</p>
<p>
	Kelly -- who quit animation work in 2017 to pursue a science degree -- said unpaid overtime is common. "In animation and (visual effects) we have major skilled labour shortages," she said, adding that companies often don't have the budget to hire more people. "We have to fill in those gaps with overtime and they don't want to pay us for it."</p>
<p>
	Kelly said she got involved with union organizing after working on a project as a storyboard artist. She said her workload suddenly doubled but her deadline remained the same. The work -- which required hours of unpaid overtime -- damaged her wrist and her eyesight, she said.</p>
<p>
	"My physical body was being harmed, my mental capacity was being harmed and my relationships were being harmed. And I looked around and I said, what is this for? A PBS show for children?"</p>
<p>
	For many workers in animation, the job is a part of their identity, Kelly said. "People don't do this because they just want a job, they do this because they have a skill and a passion.</p>
<p>
	"They eat, live and breathe this." But behind the scenes, she said, "there's blood on the screen."</p>

<p>
	<em>-- this report by The Canadian Press was first published Nov. 5, 2020.</em></p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035628</guid>
            <pubDate>Mon, 09 Nov 2020 15:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to price your SaaS product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035529">thread link</a>) | @moeamaya
<br/>
November 9, 2020 | https://www.lennyrachitsky.com/p/saas-pricing-strategy | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/saas-pricing-strategy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><em><a href="https://www.lennyrachitsky.com/p/moving-from-ic-product-manager-to">Moving from IC product manager to manager of product managers</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/top-5-most-interesting-things-about">Top 5 most interesting things about Booking.com's early growth strategy</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/the-most-important-bottom-up-saas">The most important bottom-up SaaS metrics to track (and how to best visualize them)</a></em></p></li></ol><blockquote><h2>Q: I'm building a SaaS product and don't know where to start when pricing it. How should I approach my pricing strategy?</h2></blockquote><p>When this question came in, I took to Twitter to find the smartest person in the world on SaaS pricing…</p><p>Many suggestions came though but one name came up again and again: <a href="https://twitter.com/Patticus">@Patticus</a>, aka Patrick Campbell.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:657394,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I cold DM’d Patrick and asked him if he’d be up for writing a guest post. He instantly agreed 🙌🙌🙌</p><p>For those that don’t know Patrick, he is CEO of <a href="https://www.profitwell.com/">ProfitWell</a>, and generally regarded guru on anything SaaS. Unrelated to this post, I started using ProfitWell a couple of months back to track my newsletter metrics, and the amount of insight you get into your subscription business is unreal. AND IT’S FREE.  If you’re running a SaaS business,  definitely <a href="https://www.profitwell.com/">check it out.</a> This is not a sponsored post — I just love the product.</p><p><em>🚨 <strong>Bonus</strong>: Patrick Campbell is doing a live AMA at 5pm PT today (10/27) in our subscriber-only Slack group. Ask Patrick any question you have about pricing your product live!</em></p><p>With that out of the way, let’s dive in!</p><p>—</p><p><em>by Patrick Campbell</em></p><p>Pricing is one of those topics that sits at the nexus of uncomfortable and long-term, which means companies often don’t think about it for far too long. Even when they eventually figure it out, they don’t touch it again for years.</p><p><strong>The most successful companies optimize monetization in some manner every quarter</strong>. You may be thinking, “they change their price every 3 months!?” No, and that's the first lesson of monetization: pricing goes so much further than the actual price. Let me explain.</p><p>If we go to a thirty thousand foot view, you have to think about what you're actually doing with pricing. No matter the business you're in — non-profit, retail, SaaS, DTC, B2B, whatever — you've created some sort of value. You attach a unit of measurement to the value you created: your price. Put simply, your price is the exchange rate on the value you're creating in the world.</p><p>But price doesn’t live in a vacuum. Everything in your business — from sales and marketing to product and finance — is used to drive someone to buy the product at the price you're offering. Dozens of aspects of your business influence your price, and how effectively it converts customers:</p><ol><li><p><strong>The segment and vertical you are targeting</strong>: You can go upmarket to customers who have higher willingness to pay, shift to a vertical that sees more value in your offering, or even change the ideal customer profile entirely.</p></li><li><p><strong>Your product, positioning, and packaging</strong>: You can come out with new features, move features to different tiers, pull features out and make them add-ons, change up your value propositions, etc.</p></li><li><p><strong>Your price</strong>: You can move your price up or down, which will impact conversion obviously, but will also impact the perception of your brand.</p></li></ol><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F637dba83-56b6-434f-906e-330f363cbde7_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F637dba83-56b6-434f-906e-330f363cbde7_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/637dba83-56b6-434f-906e-330f363cbde7_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>These are not the only axes when it comes to pricing, but the point is anything that influences the value of your product is involved in pricing and monetization. Cool – I've now given you a college lecture worthy of a tweed blazer, so let's dig into where you should start.</p><p><strong>In the beginning, the actual number you're charging isn't that important. </strong></p><p>There are some exceptions, but for the most part, you should first be figuring out the range you're in: a $10 product, $100 product, $1k product, etc. Don't waste time debating $500 vs. $505, because this doesn't matter as much until you have a stronger foundation beneath you.</p><p>What matters much more is two other questions:</p><ol><li><p>Your <strong>value metric</strong></p></li><li><p>Your ideal <strong>customer profiles and segments</strong></p></li></ol><p>These two elements are the foundation of your monetization and pricing strategy. Let’s explore them individually.</p><h3>Step 1: Determine your Value Metric</h3><p>A “value metric” is essentially what you charge for. For example: per seat, per 1,000 visits, per CPA, per GB used, per transaction, etc. <strong>If you get everything else wrong in pricing, but you get your value metric right, you'll do ok</strong>. It's that important. Partly because it bakes lower churn and higher expansion revenue into your monetization.</p><p>Pricing based on a value metric (vs. a tiered monthly fee) is important because it allows you to make sure you're not charging a large customer the same as you'd charge a small customer.</p><p>If you remember back to your high school or college economics class, the professor put a point on a demand curve for the perfect price and said “the revenue a firm gets is the area under that point.” The problem here is — what about all that other area under the curve? <strong>You’re missing out on that revenue by charging a flat monthly fee.&nbsp;</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F971baee8-62bc-4007-8a62-b2179faef927_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F971baee8-62bc-4007-8a62-b2179faef927_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/971baee8-62bc-4007-8a62-b2179faef927_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Good, better, best” pricing is a bit more advantageous, because you end up with three points on our trusty demand curve, and thus more revenue potential. You see this in a lot of retail products who are constrained by being physical goods — the car with the basic package vs. the car with the stereo and sunroof vs. the car with everything. In software, it’s thankfully dying out, but you’ll still see it with mass-market products:&nbsp; Netflix, Adobe Creative Cloud, etc.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>A value metric however allows you to have essentially infinite price points — maximizing your revenue potential. In practice, you’ll never show infinite price points on your pricing page, sales deck, or mobile conversion page, but you may have a customer come in at a certain level and then grow.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>Value metrics also bake growth directly into how you charge because as usage or the amount of value received goes up (and those are not the same thing), the customer pays more. If they end up using or consuming less, they pay less (and thus avoid churning). This is why companies using value metrics are typically growing at <a href="https://www.profitwell.com/recur/all/outcome-based-value-metrics-for-growth">double the rate with half the churn and 2x the expansion revenue</a> when compared to companies that charge a flat fee or where the only difference between their pricing tiers are features.&nbsp;</p><h4><strong>How to determine your value metric</strong></h4><p>To determine your value metric, think about the <em>ideal essence of value</em> for your product&nbsp;— what value are you directly providing your customer? </p><p>In B2B, it's likely going to be money saved, revenue gained, time saved, etc. In DTC, it may be the joy you bring them, fitness achieved, increased efficiency, etc. Obviously, we can't measure all of these, but if you can, <em>and</em> your customer trusts your measurement (meaning you say you saved them $100 and they agree you saved them $100), that’s your value metric.</p><p>As an example, the perfect value metric for ProfitWell Retain (our churn recovery product) is how much churn we recover for you. We can measure this, and our customers agree to the measurement, so we can charge on that axis. Other pure value metric products include <a href="https://mainstreet.us/">MainStreet</a>, which handles government paperwork to automatically get you back tax credits — you pay a percentage of the money saved.&nbsp;</p><p>Most of you won't have a pure value metric, so the next step is to find a proxy for that metric. Take for example <a href="https://www.hubspot.com/">HubSpot</a>’s marketing product. Their pure value metric is the amount of revenue their tool drives for your business. This is hard to measure and hard for the customer to agree to in terms of what percentage of credit HubSpot deserves for revenue from a blog post. Proxies for HubSpot are things like the number of contacts, number of visits, number of users, etc.&nbsp;</p><p>To find the right proxy metric, you want to come up with 5-10 proxies and then talk to your customers and prospects. You’ll typically find 1-2 of these pricing metrics will be most preferred amongst your target customers. You then want to make sure those 1-2 also make sense from a growth perspective. Your larger customers should be using/getting more of the metric, whereas your smaller customers should be using/getting less of the metric. You also want to make sure the metric encourages retention.</p><p>When we look at HubSpot, if they were to primarily price on “number of seats”, folks could share a login and HubSpot wouldn’t make much more money on large customers vs. small. Ironically they wouldn’t get as many people invested into HubSpot, because there’d be friction to adding additional seats. Instead, if they give unlimited seats and price based on “number of contacts” there’s minimal friction to getting as many people into HubSpot as possible to do activities (e.g. blog posts, email campaigns, landing pages, etc.)&nbsp;that then produce contacts.</p><p>The result: HubSpot’s marketing product’s value metric is “contacts”, which ensures growth is baked directly into how they make money. The usage drives the metric, which therein drives revenue. Most importantly customers small, medium, and large are all paying at the point they see value and then can grow.</p><p>Some other examples:</p><ol><li><p><a href="https://wistia.com/">Wistia</a> charges by the number of videos or channels you use/have</p></li><li><p><a href="https://zapier.com/">Zapier</a> invented the concept of zap (connection of software) and charge based on time to connect</p></li><li><p><a href="https://www.bbc.com/news/technology-29551380">Theater in Barcelona charged based on the number of laughs</a></p></li><li><p><a href="https://www.husqvarna.com/">Husqvarna</a> charges based on time for lawn care products vs. making you buy them</p></li><li><p><a href="https://www.rolls-roycemotorcars.com/en_US/home.html">Rolls Royce</a> charges per mile for airplane engines. They own the engines on the plane you own and do all the maintenance. Cool model.</p></li><li><p><a href="https://www.freshpatch.com/">Fresh Patch</a> charges based on the amount of grass you want per month for your dog — yes they deliver grass to you monthly</p></li></ol><p>As a side note, you should stop pricing based on seats for products where each seat doesn’t provide a unique experience. For instance, in a CRM if I log in to the AE sitting next to me’s account, I can’t really do my work because I’m only seeing their leads and accounts. Conversely, if I log in to our marketing manager’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/saas-pricing-strategy">https://www.lennyrachitsky.com/p/saas-pricing-strategy</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/saas-pricing-strategy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035529</guid>
            <pubDate>Mon, 09 Nov 2020 15:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aaron Swartz would have been 34 years old today]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035500">thread link</a>) | @paulcarroty
<br/>
November 9, 2020 | https://www.aaronswartzday.org/remembering-aaron-in-2020/ | <a href="https://web.archive.org/web/*/https://www.aaronswartzday.org/remembering-aaron-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em><strong>This year’s <a href="https://www.aaronswartzday.org/invitation/">Aaron Swartz Day and International Hackathon</a> will take place online from 10am-5pm PST on November 14, 2020. </strong></em></p>
<p><strong>It’s free and </strong><span data-key="1936"><em data-slate-leaf="true"><strong data-slate-leaf="true">livestreamed on our </strong></em></span><a href="https://www.youtube.com/channel/UCAX6qlJGN1g1EAXtRoZVN7w" data-key="1937"><span data-key="1938"><em data-slate-leaf="true"><strong data-slate-leaf="true">YouTube</strong></em></span></a><span data-key="1939"><em data-slate-leaf="true"><strong data-slate-leaf="true"> and </strong></em></span><a href="https://www.facebook.com/AaronSwartzDay/" data-key="1940"><span data-key="1941"><em data-slate-leaf="true"><strong data-slate-leaf="true">Facebook</strong></em></span></a><span data-key="1942"><em data-slate-leaf="true"><strong data-slate-leaf="true"> channels. </strong></em></span></p>
<p><em><strong><a href="https://www.eventbrite.com/e/aaron-swartz-day-and-international-hackathon-2020-tickets-128384147441">Register on Eventbrite</a> to have the streaming links emailed to you in the morning on Saturday, November 14. You can also just check our <a href="https://twitter.com/aaronswartzday">@AaronSwartzDay </a>Twitter or look on our home page here at <a href="http://aaronswartzday.org/">aaronswartzday.org</a> on that morning.<br>
</strong></em></p>
<p><a href="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png"><img loading="lazy" src="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png" alt="" width="566" height="443" srcset="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png 566w, https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron-300x234.png 300w" sizes="(max-width: 566px) 100vw, 566px"></a></p>
<p>Today would have been Aaron’s 34th birthday, but instead we mourn our friend and wonder what could have been, had he not taken his own life seven years ago after being terrorized by a career-driven prosecutor and U.S. Attorney who decided to just make shit up, make an example out of Aaron, impress their bosses and further their own careers.</p>
<p>As it turns out though, <strong><a href="https://www.aaronswartzday.org/aaron-swartz-was-authorized/">Aaron’s downloading wasn’t even illegal</a></strong>, as he was a Harvard Ethics Fellow at the time and Harvard and MIT had contractual agreements allowing Aaron to access those materials en masse.</p>
<p>But all this didn’t come to light until it was too late.</p>
<p>Aaron was careful not to tell his friends too much about his case for fear he would involve them in the quagmire. In truth, we wouldn’t have minded doing anything we could to help him, but we didn’t realize he needed help, and that his grand jury’s runaway train had gone so far off the rails.</p>
<p>We should have known though, as Grand Juries are <strong><a href="https://www.releasechelsea.com/faq/e/">a dangerous, outdated practice</a></strong> that <strong><a href="https://www.releasechelsea.com/faq/h/">give prosecutors unlimited power</a></strong>, making it easy to manipulate the way that witnesses and evidence are presented to the Grand Jury and convince jurors of almost anything. These kinds of proceedings also often violate <strong><a href="https://www.releasechelsea.com/faq/i/">the subject and witness’ constitutional rights</a></strong> in different ways. For these reasons, most civilized countries have transitioned away from them<strong> <a href="https://www.releasechelsea.com/faq/j/">in favor of preliminary hearings</a></strong>.</p>
<p>We learned many other lessons from his case, after the smoke had cleared. We learned that Aaron’s Grand Jury prosecutor, Assistant U.S. Attorney Stephen Heymann, and the U.S. Attorney in charge of his case, Carmen Ortiz, were so obsessed with trying to make names for themselves, they were&nbsp; willing to fabricate charges and evidence in order get indictments that would otherwise be unachievable.</p>
<p>As Dan Purcell explained:</p>
<blockquote><p>“Steve Heymann did what bureaucrats and functionaries often choose to do. He wanted make a big case to justify his existence and justify his budget. The casualties be damned…</p>
<p>Our bottom line was going to be that Aaron had done only what MIT permitted him to do. He hadn’t gained unauthorized access to anything. He had gained access to JSTOR with full authorization from MIT. Just like anyone in the jury pool, anyone reading Boing Boing, or anyone in the country could have done.</p>
<p>We hoped that the jury would understand that and would acquit Aaron, and it quickly became obvious to us that there really wasn’t going to be opportunity to resolve the case short of trial because Steve Heymann was unreasonable.”</p></blockquote>
<p>We also learned that MIT was more concerned with their own reputation than standing up for the truth or protecting Aaron. In fact, we learned that MIT decided to <em>assist the government with its case</em> <em>against Aaron</em>, rather than helping him by pressuring to Feds to drop the case, even after JSTOR had made it clear it did not wish to prosecute.</p>
<p>We know all this because <strong><a href="https://www.aaronswartzday.org/kevin-poulsen-2014/">Kevin Poulsen explained to us how he had to sue the Department of Homeland Security</a></strong> to get access to documents in <strong><a href="http://swartzfiles.com/">Aaron’s FBI file</a></strong>, and that <strong><a href="https://boingboing.net/2013/07/18/mit-blocking-release-of-aaron.html">MIT blocked their release</a></strong> – intervening as a third party – and demanding to get a chance to further redact them before they were released to Kevin – and the Judge granted their request! Only time will tell what MIT was so worried about, but its behavior suggests that there may have been some kind of cover-up&nbsp; regarding its involvement in Aaron’s case.</p>
<p>Most recently, thanks to Property of the People’s Ryan Shapiro, we learned that <strong><a href="https://www.aaronswartzday.org/jan11rawthought/#Aarondocs">Aaron had an erroneous code in his FBI record</a></strong>&nbsp; that meant “International Terrorism involving Al Qaeda” – deriving from his sending a single email to the University of Pittsburg, which might explain why the FBI was so suspicious of him during his case.</p>
<p>There are still many pieces of the puzzle missing, but we won’t stop trying to put it all together. We hope you will join us on November 14th to honor him and learn about his projects and ideas that are still bearing fruit to this day, such as <strong><a href="https://securedrop.org/">SecureDrop</a></strong>, <strong><a href="https://openlibrary.org/">Open Library</a></strong>, and the <strong><a href="https://www.aaronswartzday.org/psp/">Aaron Swartz Day Police Surveillance Project</a></strong>.</p>
<p>Until then, we will continue to come together to help each other and share information, knowledge and resources, and to try to make things better in our world.</p>
<p>Please email us at aaronswartzday at gmail.com or <strong><a href="https://twitter.com/aaronswartzday">DM us on Twitter</a></strong> if you would like to contribute a project to the hackathon – or want to be on the hackathon or speaker Jitsi calls<strong>. </strong></p>
<p>We hope to see you on November 14th!</p>
<h4><strong><em>&nbsp;<a href="https://www.aaronswartzday.org/howl-for-aaron-swartz/">Howl For Aaron Swartz</a> (by Brewster Kahle)</em></strong></h4>
<h5>Howl for Aaron Swartz</h5>
<p><em>Written by Brewster Kahle, shortly after Aaron’s Death, on January 11, 2013.<br>
</em></p>
<p>Howl for Aaron Swartz<br>
New ways to create culture<br>
Smashed by lawsuits and bullying<br>
Laws that paint most of us criminal</p>
<p>Inspiring young leaders<br>
Sharing everything<br>
Living open source lives<br>
Inspiring communities selflessly</p>
<p>Organizing, preserving<br>
Sharing, promoting<br>
Then crushed by government<br>
Crushed by politicians, for a modest fee<br>
Crushed by corporate spreadsheet outsourced business development</p>
<p>New ways<br>
New communities<br>
Then infiltrated, baited<br>
Set-up, arrested</p>
<p>Celebrating public spaces<br>
Learning, trying, exploring<br>
Targeted by corporate security snipers<br>
Ending up in databases<br>
Ending up in prison</p>
<p>Traps set by those that promised change<br>
Surveillance, wide-eyes, watching everyone now<br>
Government surveillance that cannot be discussed or questioned<br>
Corporate surveillance that is accepted with a click</p>
<p>Terrorists here, Terrorists there<br>
More guns in schools to promote more guns, business<br>
Rendition, torture<br>
Manning, solitary, power</p>
<p>Open minds<br>
Open source<br>
Open eyes<br>
Open society</p>
<p>Public access to the public domain<br>
Now closed out of our devices<br>
Closed out of owning books<br>
Hands off<br>
Do not open<br>
Criminal prosecution</p>
<p>Traps designed by the silicon wizards<br>
With remarkable abilities to self-justify<br>
Traps sprung by a generation<br>
That vowed not to repeat<br>
COINTELPRO and dirty tricks and Democratic National Conventions</p>
<p>Government-produced malware so sophisticated<br>
That career engineers go home each night thinking what?<br>
Saying what to their families and friends?</p>
<p>Debt for school<br>
Debt for houses<br>
Debt for life<br>
Credit scores, treadmills, with chains</p>
<p>Inspiring and optimistic explorers navigating a sea of traps set by us<br>
I see traps ensnare our inspiring generation<br>
Leaders and discoverers finding new ways and getting crushed for it</p>

	</div></div>]]>
            </description>
            <link>https://www.aaronswartzday.org/remembering-aaron-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035500</guid>
            <pubDate>Mon, 09 Nov 2020 15:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Flavoured Erlang: Erlang to Elixir Transpiler]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035483">thread link</a>) | @marianoguerra
<br/>
November 9, 2020 | http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/ | <a href="https://web.archive.org/web/*/http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Last year I was invited to <a href="https://en.elixirconf.la/">ElixirConf Latin America in Colombia</a> to give a talk,
I proposed to also give a tutorial about <a href="https://riak-core-lite.github.io/">Riak Core</a>
and they said that it should be in Elixir, so I started looking into Elixir to
translate my Riak Core material to it.</p><p>This year I was invited to give another talk about languages on the Erlang virtual machine at <a href="https://www.codebeambr.com/">Code BEAM Brasil 2020</a> and I thought it would be a good idea
to continue working on it and maybe announce it at the talk.</p><p>To measure progress I built some scripts that would transpile the Erlang
standard library to Elixir and then try compiling the resulting modules with
the Elixir compiler, I would pick one compiler error, fix it and try again.</p><p>With this short feedback loop and a counter that told me how many modules
compiled successful it was just a matter of finding errors and fixing them.
At the beginning each fix would remove lot of compiler errors and some times
surface new ones, after a while each error was a weird corner case and progress
slowed.</p><p>Some days before the talk I managed to transpile all of Erlang/OTP and 91% of
the Elixir translations compiled successfully.</p><p>The result is of course <a href="https://github.com/marianoguerra/efe">Elixir Flavoured Erlang</a>, but
as a side effect I have Erlang/OTP in Elixir, so I decided to publish it too.</p><p>The objective of this repository is to allow Elixir programmers to read Erlang
code for projects they use, most of the code compiles but I can't ensure that
it behaves identically to the original source.</p><p>While writing the readme of efe I needed some example that wasn't OTP so I
decided to also transpile a widely used project on Erlang and Elixir: the <a href="https://github.com/marianoguerra/otp.ex/tree/main/cowboy/src">Cowboy web server</a></p><div id="the-match-operator-in-elixir">
<h2>The ^ match operator in Elixir</h2>
<p>In Elixir variable bindings by default rebind to the new value, if they are
already bound and you want to pattern match on the current value you have to
add the <em>^</em> operator in front:</p>
<pre><a name="rest_code_fd61af65dfe74189aeb889ef8462540c-1"></a><span>iex</span><span>(</span><span>1</span><span>)</span><span>&gt;</span> <span>a</span> <span>=</span> <span>1</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-2"></a><span>1</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-3"></a><span>iex</span><span>(</span><span>2</span><span>)</span><span>&gt;</span> <span>a</span> <span>=</span> <span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-4"></a><span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-5"></a><span>iex</span><span>(</span><span>3</span><span>)</span><span>&gt;</span> <span>a</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-6"></a><span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-7"></a><span>iex</span><span>(</span><span>4</span><span>)</span><span>&gt;</span> <span>^</span><span>a</span> <span>=</span> <span>3</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-8"></a><span>**</span> <span>(</span><span>MatchError</span><span>)</span> <span>no</span> <span>match</span> <span>of</span> <span>right</span> <span>hand</span> <span>side</span> <span>value</span><span>:</span> <span>3</span>
</pre>
<p>In Erlang variables are bound once and then always pattern match, the easy
part of the translation is that I know that when a variable is bound and in
match position I have to add the <em>^</em>, the thing is that I can't add the <em>^</em>
on the first binding and I have to know where variables are in match position.</p>
<p>For this I do <a href="https://github.com/marianoguerra/efe/blob/main/src/efe_var_ann.erl">a pass on the Erlang Abstract Syntax Tree and I add annotations
on variables</a> to know if it's already bound and if it's in match possition, the
pretty printer in the second pass checks those annotations to know if it has
to add the <em>^</em> or not.</p>
</div><div id="why-some-modules-don-t-compile">
<h2>Why some modules don't compile?</h2>
<p>Here's a list of reasons why the remaining modules don't compile after being
transpiled.</p>
<div id="for-comprehensions-must-start-with-a-generator">
<h3>For comprehensions must start with a generator</h3>
<p>There's a weird trick in Erlang where you can generate an empty list if a
condition is false or a list with one item if a condition is true by having a
list comprehension that has no generator but has a filter.</p>
<p>I've been told that it's an artifact of how list comprehensions used to be
translated to other code in the past.</p>
<pre><a name="rest_code_2bdc186984394a22b651c88739f592c2-1"></a><span>1</span><span>&gt;</span> <span>[</span><span>ok</span> <span>||</span> <span>true</span><span>].</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-2"></a><span>[</span><span>ok</span><span>]</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-3"></a>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-4"></a><span>2</span><span>&gt;</span> <span>[</span><span>ok</span> <span>||</span> <span>false</span><span>].</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-5"></a><span>[]</span>
</pre>
<p>The fact is that it's valid Erlang and is used in some places in the standard library.</p>
<p>For simple cases in efe I insert a dummy generator:</p>
<pre><a name="rest_code_0369c5665dce49749f10a1cf9ea48854-1"></a><span>for</span> <span>_</span> <span>&lt;-</span> <span>[</span><span>:EFE_DUMMY_GEN</span><span>],</span> <span>true</span> <span>do</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-2"></a>    <span>:ok</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-3"></a><span>end</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-4"></a>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-5"></a><span>for</span> <span>_</span> <span>&lt;-</span> <span>[</span><span>:EFE_DUMMY_GEN</span><span>],</span> <span>false</span> <span>do</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-6"></a>    <span>:ok</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-7"></a><span>end</span>
</pre>
<p>For more advanced cases with many filters I have to analyze if inserting a
generator at the beginning doesn't change the result, that's why some cases are
left as is.</p>
</div>
<div id="erlang-records-dont-evaluate-default-expressions-elixir-defrecord-do">
<h3>Erlang records don’t evaluate default expressions, Elixir defrecord do</h3>
<p><a href="http://erlang.org/doc/reference_manual/records.html">Erlang records</a> are not
part of the language, they are expanded by the <a href="http://erlang.org/doc/man/epp.html">Erlang Preprocessor</a>.</p>
<p>What the preprocessor does is to insert the default values "as is" on the places
where a record is created, this means that if the default is a function call it
won't be evaluated during definition, there will be a function call for each
instantiation of the record.</p>
<p>Elixir has <a href="https://hexdocs.pm/elixir/master/Record.html">a module to deal with Erlang Records</a> using macros, the thing is that Elixir will evaluate the defaults when they are defined,
this means that if the call doesn't return a constant the behavior won't be the same.
If the call returns a value that can't be represented as a constant in the code it won't compile either.</p>
<p>Another issue is if the function being called is declared after the record is
defined, it will fail with an error saying that the function doesn't exit.</p>
<p>There could be a solution here by creating another module that tries to emulate
the way default values behave in Erlang (they behave as "quoted" expressions)
but I don't know so much about Elixir macros to know how to do it.</p>
</div>
<div id="named-lambda-functions">
<h3>Named lambda functions</h3>
<p>In Erlang <a href="https://erlang.org/doc/reference_manual/expressions.html#fun-expressions">lambda functions can have names to allow recursion</a>, in Elixir this is not supported, there's
no way to automatically change the code in a local/simple way, it's easy to
change the code by hand so I decided to transpile it as if Elixir supported
named lambda functions and get a compiler error.</p>
</div>
<div id="expressions-in-bitstrings">
<h3>Expressions in bitstrings</h3>
<p>In Elixir <a href="https://elixir-lang.org/getting-started/binaries-strings-and-char-lists.html#bitstrings">size in bitstring expects an integer or a variable as argument</a>, Erlang allows any expression there, it's easy to fix by hand by extracting the expression into a variable and putting the variable there, it could be doable but for now I just leave the expression in place and get a compiler error.</p>
</div>
<div id="variable-defined-inside-scope-and-used-outside">
<h3>Variable defined inside scope and used outside</h3>
<p>In Erlang variables introduced within the if, case or receive expressions are implicitly exported from the bodies, this means this works:</p>
<pre><a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-1"></a><span>case</span> <span>1</span> <span>of</span> <span>A</span> <span>-&gt;</span> <span>ok</span> <span>end</span><span>,</span> <span>A</span><span>.</span>
<a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-2"></a><span>% or this</span>
<a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-3"></a><span>case</span> <span>1</span> <span>of</span> <span>1</span> <span>-&gt;</span> <span>B</span> <span>=</span> <span>2</span> <span>end</span><span>,</span> <span>B</span><span>.</span>
</pre>
<p>Elixir has more strict scoping rules and that is not allowed, this is highly discouraged in Erlang but used in some places in the standard library.</p>
</div>
</div><div id="corner-cases-all-the-way-down">
<h2>Corner cases all the way down</h2>
<p>Here's a list of small differences that I had to fix.</p>
<div id="erlang-vs-elixir-imports">
<h3>Erlang vs Elixir imports</h3>
<p>In Erlang you can import functions from a module in multiple imports and they "add up".</p>
<p>In Elixir later imports for the same module "shadow" previous ones.</p>
<p>The solution is to group imports for the same module and emit only one import
per module.</p>
<p>In Erlang you can import a function more than once, in Elixir it's a compiler
error, the solution is to deduplicate function imports.</p>
</div>

<div id="lowercase-variables-that-become-keywords">
<h3>Lowercase variables that become keywords</h3>
<p>Erlang variables start with uppercase, Elixir variables with lowercase, this
means in Erlang variable names can't clash with language keywords but the lowercase
versions can, that's why I have to <a href="https://github.com/marianoguerra/efe/blob/main/src/efe_pp.erl#L1738">check if the variable is a keyword</a> and add a suffix to them.</p>
</div>
<div id="local-calls-and-kernel-autoimports">
<h3>Local calls and Kernel autoimports</h3>
<p>Elixir auto import functions from the <a href="https://hexdocs.pm/elixir/Kernel.html">Kernel</a> module
that may clash with local functions in the current Erlang module, for this case I have to <a href="https://github.com/marianoguerra/efe/blob/21ac93fb9eecfb8b164787d0e9935dae6ba7119e/src/efe_pp.erl#L1838">detect Kernel functions and macros</a> that are also local functions and add an expression to avoid auto importing them, like this:</p>
<pre><a name="rest_code_004b69f2fa9941fe83cdf5cee61ad893-1"></a><span>import</span> <span>Kernel</span><span>,</span> <span>except</span><span>:</span> <span>[</span><span>to_string</span><span>:</span> <span>1</span><span>,</span> <span>send</span><span>:</span> <span>2</span><span>]</span>
</pre>
</div>
<div id="private-on-load-function">
<h3>Private on_load function</h3>
<p>Erlang allows to define a private function to be run when the module loads,
Elixir only allowed public functions, this has been reported and fixed in
Elixir but not yet released.</p>
</div>
<div id="function-capture-calls-with-dynamic-values">
<h3>Function capture/calls with dynamic values</h3>
<p>In Erlang the syntax to pass a reference to a function is uniform for constants
and variables:</p>
<pre><a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-1"></a><span>fun</span> <span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-2"></a><span>fun</span> <span>cornercases</span><span>:</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-3"></a><span>fun</span> <span>M</span><span>:</span><span>F</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-4"></a><span>fun</span> <span>M</span><span>:</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-5"></a><span>fun</span> <span>M</span><span>:</span><span>F</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-6"></a><span>fun</span> <span>cornercases</span><span>:</span><span>F</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-7"></a><span>fun</span> <span>cornercases</span><span>:</span><span>calls</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-8"></a><span>fun</span> <span>M</span><span>:</span><span>calls</span><span>/</span><span>Arity</span><span>}</span>
</pre>
<p>In Elixir I had to special case when any part is a variable.</p>
<pre><a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-1"></a><span>&amp;</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-2"></a><span>&amp;</span><span>:cornercases</span><span>.</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-3"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-4"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>:calls</span><span>,</span> <span>3</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-5"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>3</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-6"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>:cornercases</span><span>,</span> <span>f</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-7"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>:cornercases</span><span>,</span> <span>:calls</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-8"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>:calls</span><span>,</span> <span>arity</span><span>)</span>
</pre>
<p>Something similar happens with function calls:</p>
<pre><a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-1"></a><span>M</span> <span>=</span> <span>erlang</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-2"></a><span>F</span> <span>=</span> <span>max</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-3"></a><span>M</span><span>:</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-4"></a><span>M</span><span>:</span><span>F</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-5"></a><span>erlang</span><span>:</span><span>F</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-6"></a><span>erlang</span><span>:</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-7"></a><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_40785744968a44b196ab0dffde38b6c8-1"></a><span>m</span> <span>=</span> <span>:erlang</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-2"></a><span>f</span> <span>=</span> <span>:max</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-3"></a><span>m</span><span>.</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-4"></a><span>apply</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>])</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-5"></a><span>apply</span><span>(</span><span>:erlang</span><span>,</span> <span>f</span><span>,</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>])</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-6"></a><span>:erlang</span><span>.</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-7"></a><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</pre>
</div>
<div id="binary-operators">
<h3>Binary operators</h3>
<p>In Erlang <a href="http://erlang.org/doc/reference_manual/expressions.html#arithmetic-expressions">binary operators</a> are builtin.</p>
<p>In Elixir they are macros from the <a href="https://hexdocs.pm/elixir/Bitwise.html">Bitwise</a> module.</p>
<p>The fix was easy, just use the module.</p>
</div>
<div id="call-expressions">
<h3>Call Expressions</h3>
<p>In Erlang there's no extra syntax to call a function that is the result of an
expression:</p>
<pre><a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-1"></a><span>fun</span> <span>()</span> <span>-&gt;</span> <span>ok</span> <span>end</span><span>().</span>
<a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-2"></a><span>% or</span>
<a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-3"></a><span>(</span><span>return_fn</span><span>())().</span>
</pre>
<p>In Elixir it has to be wrapped in parenthesis and a dot added before the call:</p>
<pre><a name="rest_code_a7611ce6437f4112b8095f769d3914e5-1"></a><span>(</span><span>fn</span> <span>()</span> <span>-&gt;</span> <span>:ok</span> <span>end</span><span>)</span><span>.</span><span>()</span>
<a name="rest_code_a7611ce6437f4112b8095f769d3914e5-2"></a><span># or</span>
<a name="rest_code_a7611ce6437f4112b8095f769d3914e5-3"></a><span>(</span><span>return_fn</span><span>())</span><span>.</span><span>()</span>
</pre>
</div>
<div id="weird-function-names">
<h3>Weird function names</h3>
<p>In Erlang to declare or call function names whose names are not valid identifiers
the name has to be in single quotes:</p>
<pre><a name="rest_code_e525dfbd2faa468dab783017a1e1faf2-1"></a><span>'substring-after'</span><span>()</span> <span>-&gt;</span>
<a name="rest_code_e525dfbd2faa468dab783017a1e1faf2-2"></a>    <span>wxMenu</span><span>:</span><span>'Destroy'</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>).</span>
</pre>
<p>In Elixir the declaration is different from the call.</p>
<pre><a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-1"></a><span>def</span> <span>unquote</span><span>(</span><span>:"substring-after"</span><span>)()</span> <span>do</span>
<a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-2"></a>    <span>:wxMenu</span><span>.</span><span>'Destroy'</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-3"></a><span>end</span>
</pre>
<p>When the function is a keyword in Elixir the declaration is the same but a
local call must be prefixed with the module to be valid syntax:</p>
<pre><a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-1"></a><span>keyword_methods</span><span>()</span> <span>-&gt;</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-2"></a>    <span>{</span><span>nil</span><span>(),</span> <span>in</span><span>()}.</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-3"></a>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-4"></a><span>nil</span><span>()</span> <span>-&gt;</span> <span>nil</span><span>.</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-5"></a><span>in</span><span>()</span> <span>-&gt;</span> <span>in</span><span>.</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-1"></a><span>def</span> <span>keyword_methods</span><span>()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-2"></a>    <span>{</span><span>__MODULE__</span><span>.</span><span>nil</span><span>(),</span> <span>__MODULE__</span><span>.</span><span>in</span><span>()}</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-3"></a><span>end</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-4"></a>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-5"></a><span>def</span> <span>unquote</span><span>(</span><span>:nil</span><span>)()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-6"></a>    <span>nil</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-7"></a><span>end</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-8"></a>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-9"></a><span>def</span> <span>unquote</span><span>(</span><span>:in</span><span>)()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-10"></a>    <span>:in</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-11"></a><span>end</span>
</pre>
</div>
<div id="erlang-non-short-circuit-boolean-operators">
<h3>Erlang non short circuit boolean operators</h3>
<p>For historical reasons Erlang's boolean operators <em>and</em> and <em>or</em> do not short
circuit, this means they evaluate both sides before evaluating itself, for short
circuit versions the newer and recommended <em>andalso</em> and <em>orelse</em> operators
exist. Still the old versions are used in some places.</p>
<p>Elixir only has short circuit versions, to solve this I replace calls to those
operators to the functions in the Erlang module that do the same, since I need
to force the evaluation of both sides and function calls evaluate the arguments
before calling it does what I need.</p>
<pre><a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-1"></a><span>o_and</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>A</span> <span>and</span> <span>B</span><span>.</span>
<a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-2"></a><span>o_or</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span>  <span>-&gt;</span> <span>A</span> <span>or</span> <span>B</span><span>.</span>
<a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-3"></a><span>o_xor</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>A</span> <span>xor</span> <span>B</span><span>.</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-1"></a><span>def</span> <span>o_and</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-2"></a>  <span>:erlang</span><span>.</span><span>and</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-3"></a><span>end</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-4"></a>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-5"></a><span>def</span> <span>o_or</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-6"></a>  <span>:erlang</span><span>.</span><span>or</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-7"></a><span>end</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-8"></a>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-9"></a><span>def</span> <span>o_xor</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-10"></a>  <span>:erlang</span><span>.</span><span>xor</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-11"></a><span>end</span>
</pre>
<p>The problem is in guards, where only a subset of functions can be used, in
Erlang since <em>and</em> and <em>or</em> are operators they are allowed, but in Elixir the
function calls are not, only in this case I replace the non short circuit
version for the short circuit ones since …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/">http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/</a></em></p>]]>
            </description>
            <link>http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035483</guid>
            <pubDate>Mon, 09 Nov 2020 15:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is there so much surprise around Trump's approach to losing the US Election]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035356">thread link</a>) | @twords
<br/>
November 9, 2020 | https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020- | <a href="https://web.archive.org/web/*/https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020-">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div><div><div><div><div><header><div><p><a tag="[object Object]" href="https://twords.com/"><img src="https://twords.com/static/media/inverse_cropped.0601fa81.svg"></a></p><div><div><div></div></div></div><div><p><a tag="[object Object]" href="https://twords.com/authentication/login">Login</a></p></div></div></header></div><div class="page"><div><div><p><a href="https://twords.com/#" data-rb-event-key="/" role="button"></a><a href="https://twords.com/">Home</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/trending" role="button"></a><a href="https://twords.com/trending">Trending</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/my-feed" role="button"></a><a href="https://twords.com/my-feed">My Feed</a></p></div></div><div><nav><a href="https://twords.com/"></a></nav></div><div><div><a href="https://twords.com/view-article/null"><div><p>Continue reading...</p></div></a></div><div></div></div><div><div><p><h3>Latest Articles</h3></p><div><div><p><span>Loading..</span></p></div><p><span>Loading...</span></p></div></div></div></div><div><nav><div><p><a tag="[object Object]" href="https://twords.com/about-us">About Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/contact-us">Contact Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/faq">FAQ</a></p></div><div><div><p><a href="https://twitter.com/official_twords">Twitter</a></p></div></div></nav></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020-</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035356</guid>
            <pubDate>Mon, 09 Nov 2020 14:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vulnerabilities Discovered in Tcl Android TVs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035350">thread link</a>) | @moviuro
<br/>
November 9, 2020 | https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/ | <a href="https://web.archive.org/web/*/https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                
<p>The following piece is the culmination of a three-month long investigation into Smart TVs running Android. Having lived through this research experience, I can wholeheartedly say that there were multiple moments that I, and another security researcher that I met along the way, couldn’t believe what was happening. On multiple occasions I found myself feeling as though, “you couldn’t even make this up…”</p>



<p>I’m a security researcher, a freelance developer, and a hacker.</p>



<p>Please follow me on Twitter <a href="https://twitter.com/sickcodes" target="_blank" rel="noreferrer noopener">@sickcodes</a> here: <a href="https://twitter.com/sickcodes" target="_blank" rel="noreferrer noopener">https://twitter.com/sickcodes</a></p>



<p>The second researcher in this story is John Jackson: <a href="https://twitter.com/johnjhacking" target="_blank" rel="noreferrer noopener">https://twitter.com/johnjhacking</a>, an Application Security Engineer with Shutterstock, and a hacker.</p>



<p>We met about half way through this, and I have included his experience too.</p>



<h2>Initial Research</h2>



<p>Near the end of September, while conducting research into low-end Android boxes, I came across a number of serious flaws in the way in which these devices were being designed.</p>



<p>Without delving into the nuances of each device, all of the Smart TV products are Android based.</p>



<p>There are four types of TV products in the TV market:</p>



<ol><li>TV Sticks</li><li>TV Boxes</li><li>Smart TVs</li><li>Android TVs</li></ol>



<p>All of them are ARM based single board computers (SBCs). Most of the dies are 32bit, some are 64bit, but all of them are like a little Raspberry Pi competitor, focusing on GPU performance through the small, but powerful, Mali GPUs.</p>



<p>Some of the products that I investigated were “factory-flawed” and deliberately insecure.</p>



<h2>First Blood</h2>



<p>On 2020-09-20, I discovered some ridiculous security shortfalls in the TV Sticks.</p>



<p><em>NOTE: TCL does not make TV sticks that are vulnerable. Only TCL Android TVs are affected. The following vulnerabilities refer to other products that I was testing at the time before finding the TCL vulnerability that is discussed in depth after the nmap scaps below.</em></p>



<p>Each stick that I tested had at least one of the following major security flaws.</p>



<ul><li>Port 22 open and allowing SSH access as root:root out of the box</li><li>Port 5555 open and allowing unauthenticated android (adb) as root:root out of the box</li><li>Rooted device, with world-executable su binaries in multiple locations</li><li>Open WiFi network with adb and ssh daemons running</li></ul>



<p>In effect, if you had a thousand of these devices, you could worm through all of them, taking advantage of the dual WiFi, plain-text WAN router credentials, and the ability to then hop from the TV stick, to the router, MITM the router, search for more vulnerable devices from the larger, more powerful router, and truly “surf the internet”.</p>



<p><strong>Proof of Concept</strong></p>



<pre># connect to the device's open WiFi network without any password
adb connect 192.168.1.1
adb shell
su
whoami
# root</pre>



<p>Having witnessed how dismal the security was on these devices, or lack thereof, my plan was to write a really big proof of concept, in the form of an actual shell based worm, that would hop between the 4 or 5 TV sticks that I had.</p>



<p>Speaking to an associate about my idea, we ended up chatting about real Android TVs.</p>



<p>Suddenly, I thought, “If these sticks are the same, just little Rockchip &amp; Amlogic CPUs, then what is so special about Smart TVs?”</p>



<p>Since I don’t actually have an Android Television to test, I asked my friend what type of Smart TV does he have and is it running Android?</p>



<p>His answer was, “TCL and not sure.”</p>



<p>I hadn’t really heard much about TCL, but it turns out TCL is a huge Chinese electronics manufacturing company.</p>



<p>TCL has been growing their global market share, at a remarkable rate.</p>



<p>According to a Forbes article, they only launched in the United States in 2013 and sales began on Amazon: <a href="https://www.forbes.com/sites/sethporges/2016/11/14/how-a-no-name-chinese-tv-brand-came-to-dominate-the-amazon-charts/?sh=15fd0d52f096" target="_blank" rel="noreferrer noopener">https://www.forbes.com/sites/sethporges/2016/11/14/how-a-no-name-chinese-tv-brand-came-to-dominate-the-amazon-charts/?sh=15fd0d52f096</a></p>



<div><figure><img loading="lazy" width="928" height="545" src="https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020.png" alt="TV market share 2008 2020" srcset="https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020.png 928w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-300x176.png 300w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-768x451.png 768w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-750x440.png 750w" sizes="(max-width: 928px) 100vw, 928px"><figcaption>TV market share 2008 to 2020</figcaption></figure></div>



<p>With their Amazon success, TCL began targeting other large markets.</p>



<p>The key point here is that they aren’t Samsung or LG, but they ARE selling millions of TV sets…</p>



<p>We did a remote desktop session and I ran a trivial nmap scan on the TV to see what it was running out of the box.</p>



<p>Here is the nmap scan:</p>



<pre>Starting Nmap 7.91 ( https://nmap.org ) at 2020-10-16 21:55 UTC
…
Scanning 10.0.0.117 [65535 ports]
Discovered open port 6550/tcp on 10.0.0.117
Discovered open port 8012/tcp on 10.0.0.117
Discovered open port 6466/tcp on 10.0.0.117
Discovered open port 8009/tcp on 10.0.0.117
Discovered open port 9000/tcp on 10.0.0.117
Discovered open port 8443/tcp on 10.0.0.117
Discovered open port 10101/tcp on 10.0.0.117
Discovered open port 46211/tcp on 10.0.0.117
Discovered open port 7989/tcp on 10.0.0.117
Discovered open port 6467/tcp on 10.0.0.117
Discovered open port 6559/tcp on 10.0.0.117
Discovered open port 6553/tcp on 10.0.0.117
Discovered open port 4332/tcp on 10.0.0.117
Discovered open port 8008/tcp on 10.0.0.117
Completed SYN Stealth Scan at 21:56, 20.40s elapsed (65535 total ports)
Initiating Service scan at 21:56
Scanning 14 services on 10.0.0.117
…
Completed Service scan at 21:58, 156.41s elapsed (14 services on 1 host)
Not shown: 65521 closed ports</pre>



<p>If you nmap your Android mobile phone, you will generally find 0 open TCP ports.</p>



<p><strong>Zero.</strong></p>



<p>So why does a TV need so many open ports?</p>



<p>While there are some reasons why TVs should have open ports, some of the above services warranted much deeper investigation.</p>



<p>Since I was in a remote desktop session, I just entered all the URLs manually into his web browser.</p>



<pre>http://10.0.0.117:6550
http://10.0.0.117:8012
http://10.0.0.117:6466
http://10.0.0.117:8009
http://10.0.0.117:9000
http://10.0.0.117:8443
http://10.0.0.117:10101
http://10.0.0.117:46211
http://10.0.0.117:7989
http://10.0.0.117:6467
http://10.0.0.117:6559
http://10.0.0.117:6553
http://10.0.0.117:4332
http://10.0.0.117:8008</pre>



<p>I also tested the https:// editions:</p>



<pre>https://10.0.0.117:6550
https://10.0.0.117:8012
https://10.0.0.117:6466
https://10.0.0.117:8009
https://10.0.0.117:9000
https://10.0.0.117:8443
https://10.0.0.117:10101
https://10.0.0.117:46211
https://10.0.0.117:7989
https://10.0.0.117:6467
https://10.0.0.117:6559
https://10.0.0.117:6553
https://10.0.0.117:4332
https://10.0.0.117:8008</pre>



<p>Some of the pages were blank white pages. This can indicate an API endpoint.</p>



<p>Some of the pages just hang the browser.</p>



<p>Then the rest of the nmap scan came through…</p>



<pre>PORT STATE SERVICE VERSION
4332/tcp open getty-focus?
6466/tcp open ssl/unknown
| ssl-cert: Subject: commonName=atvremote/BeyondTV2/BeyondTV/BeyondTV2/unknown
| Subject Alternative Name: email:<a href="https://sick.codes/cdn-cgi/l/email-protection" data-cfemail="32535c56405d5b561f46441f40575f5d46571f414742425d404672555d5d555e571c515d5f">[email&nbsp;protected]</a>
| Issuer: commonName=atvremote/BeyondTV2/BeyondTV/BeyondTV2/unknown
| Public Key type: rsa
| Public Key bits: 2048
| Signature Algorithm: sha256WithRSAEncryption
…
6467/tcp open tcpwrapped
6550/tcp open fg-sysupdate?
| fingerprint-strings:
| NULL:
|_ Version 4
6553/tcp open unknown
6559/tcp open unknown
| fingerprint-strings:
| GenericLines:
…
7989/tcp open unknown
| fingerprint-strings:
| FourOhFourRequest:
| HTTP/1.1 404 Not Found
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:57:17 GMT
| Accept-Ranges: bytes
| Connection: keep-alive
| Content-Length: 26
| Error 404, file not found.
| GenericLines:
| HTTP/1.1 400 Bad Request
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:56:27 GMT
| Connection: keep-alive
| Content-Length: 56
| REQUEST: Syntax error. Usage: GET /example/file.html
| SIPOptions:
| HTTP/1.1 404 Not Found
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:57:37 GMT
| Accept-Ranges: bytes
| Connection: keep-alive
| Content-Length: 26
|_ Error 404, file not found.
8008/tcp open http?
|_http-title: Site doesn\'t have a title (text/html).
8009/tcp open ssl/castv2 Ninja Sphere Chromecast driver
|_ajp-methods: Failed to get a valid response for the OPTION request
8012/tcp open unknown
8443/tcp open ssl/https-alt\?
|_http-title: Site doesn\'t have a title (text/html).
| ssl-cert: Subject: commonName=/organizationName=Google Inc/stateOrProvinceName=Washington/countryName=US
| Issuer: commonName=TCL TV BeyondTV Realtek RTD2851 Cast ICA/organizationName=Google Inc/stateOrProvinceName=Washington/countryName=US
9000/tcp open ssl/cslistener?
10101/tcp open ssl/ezmeeting-2?
46211/tcp open tcpwrapped</pre>



<p>Port 7989 was showing a 404 error, yet when I visit 10.0.0.117:7989 in the browser, an error is shown.</p>



<p>http://10.0.0.117:7989 did not return a page in the browser.</p>



<div><figure><img loading="lazy" width="1007" height="664" src="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure.png" alt="TCL directory file structure" srcset="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure.png 1007w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-300x198.png 300w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-768x506.png 768w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-750x495.png 750w" sizes="(max-width: 1007px) 100vw, 1007px"><figcaption>TCL directory file structure</figcaption></figure></div>



<p>What kind of special web server doesn’t show an index page, but shows deeper pages?</p>



<p>I had recently done research on an IoT device that was serving CGI scripts from the / directory, so the first page I thought to test was init.rc</p>



<p><em>http://10.0.0.117:7989/init.rc</em></p>



<p>403 Forbidden.</p>



<p>Yikes.</p>



<p>This means that the file is exists but we are not authorized to view it.</p>



<p>Naturally, I tested some other Android directories:</p>



<p><em>http://10.0.0.117:7989/sdcard</em></p>



<figure><img loading="lazy" width="916" height="691" src="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability.png" alt="TCL directory file structure vulnerability" srcset="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability.png 916w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-300x226.png 300w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-768x579.png 768w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-750x566.png 750w" sizes="(max-width: 916px) 100vw, 916px"><figcaption>TCL directory file structure vulnerability</figcaption></figure>



<p>If you work with computers, no matter whether it be mobile apps, web apps, websites, back-end, front-end, upend…</p>



<p>Ask yourself this question right now:</p>



<figure><blockquote><p><em>When in the history of your career…</em><br><em>Have you ever needed to serve the entire filesystem…</em><br><em>over http?</em></p></blockquote></figure>



<p>This becomes a really import question because this custom vendor firmware is currently installed in millions of TCL Android TVs around the world.</p>



<p>My friend who was actually on the phone to me while we were doing the remote desktop, was fairly surprised.</p>



<p>“Why can we see all the files in the TV?”</p>



<p>Port 7989 is not on the list of standard TCP/UDP ports by the Internet Assigned Numbers Authority (IANA), https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt</p>



<p>This means, without scanning all 65,535 ports, most scanners will skip that port.</p>



<p>Secondly, the actual root page is blank.</p>



<p>So in order to scan more than 1 page per port, port scan times will exponentially increase…</p>



<p>Curiously, I checked the IANA list for other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/">https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/</a></em></p>]]>
            </description>
            <link>https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035350</guid>
            <pubDate>Mon, 09 Nov 2020 14:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A US Visa in 937 Days]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 144 (<a href="https://news.ycombinator.com/item?id=25035307">thread link</a>) | @caution
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Here’s the complete timeline of events. From my first denial to travel to the US until I eventually received a tourist visa. And then I can’t go anyway.</p>



<h2>December 5-11, 2016</h2>



<p>I spent a week on Hawaii with Mozilla – my employer at the time. This was my 12th visit to the US over a period of 19 years. I went there on ESTA, the visa waiver program Swedish citizens can use. I’ve used it many times, there was nothing special this time. The typical procedure with ESTA is that we apply online: fill in a form, pay a 14 USD fee and get a confirmation within a few days that we’re good to go.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg" alt="" width="558" height="414"></a><figcaption>I took this photo at the hotel we stayed at during the Mozilla all-hands on Hawaii 2016.</figcaption></figure>



<h2>June 26, 2017</h2>



<p>In the early morning one day by the check-in counter at Arlanda airport in Sweden, I was refused to board my flight. Completely unexpected and out of the blue! I thought I was going to San Francisco via London with British Airways, but instead I had to turn around and go back home – slightly shocked. According to the lady behind the counter there was “something wrong with my ESTA”. I used the same ESTA and passport as I used just fine back in December 2016. They’re made to last two years and it had not expired.</p>



<figure><a href="https://twitter.com/bagder/status/879198063998513152"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-06-Twitter-Publish.png" alt="" width="553" height="199"></a><figcaption>Tweeted by me, minutes after being stopped at Arlanda.</figcaption></figure>



<p>People engaged by Mozilla to help us out could not figure out or get answers about what the problem was (questions and investigations were attempted both in the US and in Sweden), so we put our hopes on that it was a human mistake somewhere and decided to just try again next time.</p>



<h2>April 3, 2018</h2>



<p>I missed the following meeting (in December 2017) for other reasons but in the summer of 2018 another Mozilla all-hands meeting was coming up (in Texas, USA this time) so I went ahead and applied for a new ESTA in good time before the event – as I was a bit afraid there was going to be problems. I was right and I got denied ESTA very quickly. “Travel Not Authorized”.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/ESTA-travel-not-authorized.png" alt="" width="642" height="458"><figcaption>Rejected from the ESTA program.</figcaption></figure>



<h2>Day 0 – April 17, 2018</h2>



<p><strong>Gaaah</strong>. It meant it was no mistake last year, they actually mean this. I switched approach and instead applied for a tourist visa. I paid 160 USD, filled in a ridiculous amount of information about me and my past travels over the last 15 years and I visited the US embassy for an in-person interview and fingerprinting.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/Administrative-Processing.png" alt="" width="577" height="289"></figure>



<p>This is day 0 in the <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/" data-type="post" data-id="11076">visa process</a>, 296 days after I was first stopped at Arlanda.</p>



<h2>Day 90 – July 2018</h2>



<p>I missed the all-hands meeting in San Francisco when I didn’t get the visa in time.</p>



<h2>Day 240 – December 2018</h2>



<p>I <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/">quit Mozilla</a>, so I then had no more reasons to go to their company all-hands…</p>



<h2>Day 365 – April 2019</h2>



<p><a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/" data-type="post" data-id="12216">A year passed</a>. “someone is working on it” the embassy email person claimed when I asked about progress.</p>



<h2>Day 651- January 28, 2020</h2>



<p>I emailed the embassy to query about the process</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/651-days-email.png" alt="" width="611" height="166"><figcaption>Screenshotted email</figcaption></figure>



<p>The reply came back quickly:</p>



<blockquote><p>Dear Sir, </p><p>All applications are processed in the most expeditious manner possible. While we understand your frustration, we are required to follow immigration law regarding visa issuances. This process cannot be expedited or circumvented. Rest assured that we will contact you as soon as the administrative processing is concluded.</p></blockquote>



<h2>Day 730 – April 2020</h2>



<p><a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/" data-type="post" data-id="13456">Another year had passed</a> and I had given up all hope. Now it turned into a betting game and science project. How long can they actually drag out this process without saying either yes or no?</p>



<h2>Day 871 – September 3, 2020</h2>



<p>A friend of mine, a US citizen, contacted his Congressman – <a href="https://en.wikipedia.org/wiki/Gerry_Connolly">Gerry Connolly</a> – about my situation and asked for help. His office then subsequently sent a question to the US embassy in Stockholm asking about my case. While the response that arrived on September 17 was rather negative…</p>



<pre>your case is currently undergoing necessary administrative processing and regrettably it is not possible to predict when this processing will be completed.</pre>



<p>… I think the following turn of events indicates it had an effect. It unclogged something.</p>



<h2>Day 889 – September 22, 2020</h2>



<p>After 889 days since my interview on the embassy (only five days after the answer to the congressman), the embassy contacted me over email. <em> For the first time since that April day in 2018.</em></p>



<pre>Your visa application is still in administrative processing. However, we regret to inform you that because you have missed your travel plans, we will require updated travel plans from you.</pre>



<p>My travel plans – that had been out of date for the last 800 days or so – suddenly needed to be updated! As I was already so long into this process and since I feared that giving up now would force me back to square one if I would stop now and re-attempt this again at a later time, I decided to arrange myself some updated travel plans. After all, I work for an American company and I have a friend or two there.</p>



<h2>Day 900 – October 2, 2020</h2>



<p>I replied to the call for travel plan details with an official invitation letter attached, inviting me to go visit my colleagues at <a href="https://www.wolfssl.com/">wolfSSL</a> signed by our CEO, Larry. I really want to do this at some point, as I’ve never met most of them so it wasn’t a made up reason. I could possibly even get some other friends to invite me to get the process going but I figured this invite should be enough to keep the ball rolling.</p>



<h2>Day 910 – October 13, 2020</h2>



<p>I got another email. Now at 910 days since the interview. The embassy asked for my passport “for further processing”.</p>



<h2>Day 913 – October 16, 2020</h2>



<p>I posted my passport to the US embassy in Stockholm. I also ordered and paid for “return postage” as instructed so that they would ship it back to me in a safe way.</p>



<h2>Day 934 – November 6, 2020</h2>



<p>At 10:30 in the morning my phone lit up and showed me a text telling me that there’s an incoming parcel being delivered to me, shipped from “the Embassy of the United State” (bonus points for the typo).</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png" alt="" width="496" height="211"></a></figure>



<h2>Day 937 – November 9, 2020</h2>



<p>I received my passport. Inside, there’s a US visa that is valid for ten years, until November 2030.</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg" alt="" width="441" height="221"></a><figcaption>The upper left corner of the visa page in my passport…</figcaption></figure></div>



<p>As a bonus, the visa also comes with a NIE (National Interest<br>Exception) that allows me a single entry to the US during the PP (Presidential Proclamations) – which is restricting travels to the US from the European Schengen zone. In other words: I am actually allowed to travel right away!</p>



<p>The timing is fascinating. The last time I was in the US, Trump hadn’t taken office yet and I get the approved visa in my hands just days after Biden has been announced as the next president of the US.</p>



<h2>Will I travel?</h2>



<p>Covid-19 is still over us and there’s no end in sight of the pandemic. I will of course not travel to the US or any other country until it can be deemed safe and sensible.</p>



<p>When the pandemic is under control and traveling becomes viable, I am sure there will be opportunities. Hopefully the situation will improve before the visa expires.</p>



<h2>Thanks to</h2>



<p>All my family and friends, in the US and elsewhere who have supported me and cheered me up through this entire process. Thanks for keeping inviting me to fun things in the US even though I’ve not been able to participate. Thanks for pushing for events to get organized outside of the US! I’m sorry I’ve missed social gatherings, a friend’s marriage and several conference speaking opportunities. Thanks for all the moral support throughout this long journey of madness.</p>



<p>A special thanks go to David (you know who you are) for contacting Gerry Connolly’s office. I honestly think this was the key event that finally made things move in this process.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035307</guid>
            <pubDate>Mon, 09 Nov 2020 14:47:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Kafka – 8 things to check before going live]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25035239">thread link</a>) | @ariskk
<br/>
November 9, 2020 | https://ariskk.com/kafka-8-things | <a href="https://web.archive.org/web/*/https://ariskk.com/kafka-8-things">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="A Kafka System" title="A Kafka System" src="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg" srcset="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/46946/kafka-system.jpg 240w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/55489/kafka-system.jpg 480w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg 960w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/60e21/kafka-system.jpg 1440w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/198e7/kafka-system.jpg 1485w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>Apache Kafka is a beautiful system. It scales well, it is stable and it provides phenomenal system architecture flexibility.
After 5 years of running production Kafka clusters, I have collected a list of tips and pitfalls. Some of them were learnt the hard way.
If you work in a small team rolling out Kafka to production, those might prove useful.
The article assume familiarity with basic Kafka concepts, such as brokers, topics, producers and consumers.
What is more, the following points should be valid for up to Kafka 2.6.0.
Without further ado.</p><h3>1. Key all the messages!</h3><p>Kafka topics consist of a (configurable) number of partitions.
If the partition number is not provided by the user, <code>KafkaProducer</code>
chooses the partition for the message using the <code>key</code> in the <code>ProducerRecord</code> instance passed to it.</p><p>Check out the default <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java#L65">implementation</a>:
It checks if the key is <code>null</code>, and if it isn't it, computes a <code>murmur2</code> hash modulo the number of partitions.
This is consistent; it will yield the same result for messages sharing the same key.
If the key is <code>null</code> though, it uses a <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/StickyPartitionCache.java#L60">sticky partitioner</a>
that chooses a partition randomly at every batch.
In practical terms, if no key is passed, the producer will choose the partition randomly.</p><p>This has important implications because <strong>Kafka only provides delivery ordering guarantees within a partition</strong>.
Messages in the same partition will be delivered in the order they were committed.
Messages in different partitions will be delivered in non-deterministic order.
If the messages have any form of <strong>causal relationship</strong> between them, and they are <strong>not</strong> in the same partition,
then any downstream consumer will have to collect all messages for a key before processing them, else causal consistency might be violated; whatever <em>all</em> means in the context of
an infinite stream.</p><p>As a simple example to illustrate the above, think of a simple event like the following:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p><p><span>6</span><span></span></p><p><span>7</span><span>def storeToDB(sub: EmailSubscription) = ???</span></p><p><span>8</span><span>val events: Stream[EmailSubscription] = ???</span></p></pre></div><p>If emails arrive in causal order, then we can map the events statelessly:</p><p>If per-email causal order is not guaranteed though, we need to maintain enough state to know
if the event we see is indeed the latest. Else if the order is reversed, we might send an email to a user who
has unsubscribed.
For example:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>events</span></p><p><span>2</span><span>  .groupMapReduce(_.email)(identity)(</span></p><p><span>3</span><span>    (e1, e2) =&gt; if (e1.createdOn.isAtfer(e2.createdOn)) e1 else e2</span></p><p><span>4</span><span>  )</span></p><p><span>5</span><span>    .values</span></p><p><span>6</span><span>    .map(storeToDB)</span></p></pre></div><p>If we key messages using <code>email</code>, then Kafka will deliver all messages for a single email in the order they were inserted.
Our consumer can be completely stateless; it can fetch messages from Kafka and store them to a datastore.
If the key is <code>null</code> (none provided), our stateless consuer will happily store a message from the past.
To mitigate that, at the very minimum we need to maintain the latest <code>createdOn</code> date for every email.
Relying on wall clocks for causality <a href="https://github.com/aphyr/distsys-class#clocks">is a very bad idea</a>.</p><p>Assuming per key ordering can be guaranteed, downstream reducer bounds can be reduced from a <code>Semilattice</code> to a <code>Semigroup</code>.
In practical terms, by taking advantage of this property we can drop the commutativity requirement which unlocks easier implementations.
If designing reducers for Kafka consumers sounds interesting, let me know and I will write about it.</p><h3>2. Ensure all producers are using the same partitioner</h3><p>Providing a key is not enough. Partitioners (ie the function f: (key) =&gt; partition) are configurable.
Kafka provides a few and users can roll out their own. Do <strong>NOT</strong> assume all producers are using the same partitioner.</p><p>In a complex system where Go services, Python services, Spark and other wild animals all share the same Kafka cluster, all sorts of different implementations might exist.
If different services are pushing data to the same topics, an integration test would be very useful.
If things go wrong, delivery to consumers will be non-deterministic and debugging it can be pure hell.</p><h3>3. Topic versioning</h3><p>The beauty of Kafka is that data can be reprocessed as many times as needed.
This forgives a lot of errors. To illustrate this one, let's assume the same dummy model:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p></pre></div><p>Let's now assume messages are serialized to <code>json</code> before being pushed to Kafka.
Due to a json serialization bug, the following is pushed to the <code>emailsubscriptions</code> topic:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": {</span></p><p><span>3</span><span>    "value": "aris@aris.com"</span></p><p><span>4</span><span>  },</span></p><p><span>5</span><span>  "active": false,</span></p><p><span>6</span><span>  "createdOn": 1600000000</span></p><p><span>7</span><span>}</span></p></pre></div><p>Instead of the expected:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": "aris@aris.com",</span></p><p><span>3</span><span>  "active": false,</span></p><p><span>4</span><span>  "createdOn": 1600000000</span></p><p><span>5</span><span>}</span></p></pre></div><p>Downstream consumers try to deserialize the message and fail. What can be done?</p><p>One solution would be to create a custom deserializer for those buggy instances and to add it to all the consumers.
That's non trivial and error prone code; useful just for this instance.</p><p>Another solution would be to implement a consumer that would read from <code>emailsubscriptions-1</code>, fix the issue, and write to <code>emailsubscriptions-2</code>.
Once the offsets of the two topics are identical, producers and consumers can switch from <code>emailsubscriptions-1</code> to <code>emailsubscriptions-2</code> without having to update any code.
What's great about this is that those migrations can fail with no major consequences. If <code>emailsubscriptions-2</code> is no good, we can run again and produce <code>emailsubscriptions-3</code> and so on.
This trick also works for non-trivial schema changes, migrations and other data enrichments.
Avro and Profobuf can help in some cases, but bugs will occur and requirements will evolve in unpredictable ways.
In any case, "fixing" a topic's data by reading from it and publishing to it is rarely a good idea.
Topics should be immutable and versioning them can help in many situations where a topic's content have been corrupted.</p><h3>4. Treat ZooKeeper like royalty</h3><p>Up until at least 2.6.0, Kafka relies on ZooKeeper.
Losing connection to ZooKeeper means no ISRs (In-Sync-Replicas, more on that later), no partition leader election and eventually the brokers shut down.
Thankfully <a href="https://twitter.com/fpjunqueira?lang=en">@fpjunqueira</a> and his team who created ZooKeeper are real pros, and that won't happen without reason.
In fact, ZooKeeper is one of the most reliable distributed systems (that I have seen at least).</p><p>The two following mess ups have occurred though:</p><ol><li>Due to a bug in the provisioning Ansible script, 2/3rds of a cluster ended up in the same availability zone, with sequential IPs (that usually means in the same rack on AWS).
They all disappeared at the same time. No consensus, hell broke loose.</li><li>A QA environment ran for long enough for all nodes to run out of disk space (ZooKeeper creates backup snapshots of the transaction log over time and someone/something external has to deal with deleting them).
At the same time. Bringing this env back to life required editing znodes manually, and still data was lost.</li></ol><p>To clean up older transaction log snapshots in ZooKeeper 3.4.x, ZooKeeper provides the following tool:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>java -cp zookeeper-3.4.x.jar:lib/*:conf org.apache.zookeeper.server.PurgeTxnLog \</span></p><p><span>2</span><span>  /var/lib/zookeeper /var/lib/zookeeper -n 5</span></p></pre></div><p>Ideally on a cron.</p><p>Those are just two examples. A lot more can go wrong. Because of the consequences of failure, proper JMX metric monitoring and real time log aggregation,
all hooked up to a form of PagerDuty, are very highly recommended.</p><h3>5. Unclean elections and minimum ISRs</h3><p>This is essentially a trade off between availability and durability. Let's start with unclean elections.</p><p>Let's assume we have a topic with a single partition and a single replica. Data is happily flowing in.
If the replica is "in-sync" (aka identical to the leader and in the ISR set in ZooKeeper),
then if the leader partition becomes unavailable (eg the broker crashes) then the replica can pick up, accept writes and continue with no downtime.
If the replica lags behind though, the leader will remove it from the ISRs in ZooKeeper. If then the leader goes down, there are two options:</p><ol><li>The lagging replica picks up, accepts writes and whatever excess writes the old leader had are <em>lost</em>. Essentially, the replica gets elected as leader without being in-sync. This is the "unclean" part.</li><li>The partition becomes unavailable and new writes are rejected.</li></ol><p>It entirely depends on the kind of data the topic holds. If the topic holds system metrics,
then maybe the most recent data is more valuable and thus losing some older writes might be acceptable.
If the topic contains bank transactions, going down until a human intervenes might be a better option.
This is a broker level config that can be overridden per topic.</p><p>The second part of this equation is <code>min.insync.replicas</code>, which represents the minimum number of replicas that have to be in-sync for a write to go through.
This is configurable at the broker level, topic level and even at the producer level (ie <code>acks</code>). Same considerations as above,
if the topic holds payments, having just 1 replica with all the data might be risky.</p><p>Legendary distributed systems researcher Kyle Kingsbury, aka Aphyr, did an <a href="https://aphyr.com/posts/293-call-me-maybe-kafka">excellent analysis on Kafka's replication mechanism</a> some 7 years ago.
If you wish to dig deeper into this trade off, reading Aphyr's piece is very highly recommeneded. As far as I understand, the basic trade offs discussed still hold true today.</p><h3>6. Memory Maps</h3><p>Kafka uses a LOT of those. Running out of them leads to a fatal runtime exception that will kill the broker.
If the OS defaults are used, it is extremely likely that those will be reached as soon as the cluster has a few tens of thousand segments per broker.
What's worse is that in a well balanced cluster where brokers hold similar numbers of partitions, those failures will occur roughly at the same time.
Let's look a bit closer:</p><p><code>vm.max_map_count</code>: is the maximum number of memory map areas a process can have.</p><p>From the linux kernel <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysctl/vm.html?highlight=max_map_count#max-map-count">docs</a>:</p><blockquote><p>max_map_count:<br>
<!-- -->This file contains the maximum number of memory map areas a process
may have. Memory map areas are used as a side-effect of …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ariskk.com/kafka-8-things">https://ariskk.com/kafka-8-things</a></em></p>]]>
            </description>
            <link>https://ariskk.com/kafka-8-things</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035239</guid>
            <pubDate>Mon, 09 Nov 2020 14:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at S&P 500's real excess return over Treasuries over long time horizons]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035020">thread link</a>) | @fa
<br/>
November 9, 2020 | https://fasiha.github.io/post/excess-returns/ | <a href="https://web.archive.org/web/*/https://fasiha.github.io/post/excess-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><figure><img src="https://fasiha.github.io/post/excess-returns/The_Monitor_and_Merrimac.jpg"></figure>  <ul>
    <li><a href="https://fasiha.github.io/">Blog</a></li>
    <li><a href="https://fasiha.github.io/#contact">Contact</a></li>
    <li><a href="https://fasiha.github.io/atom.xml">Feed</a></li>
  </ul><p><em>Updated on Sun, 08 Nov 2020 03:01:01 GMT, tagged with ‘finance’.</em></p><p>Imagine. It's 1871. A promising young American has just entered the workforce and makes it a point to buy $100 of the S&amp;P 500 index every month, with dividends reinvested, over a forty year career. It's now 1911. Our American, about to retire, stops these monthly purchases and asks, "What is the real return I achieved in excess of risk-free Treasuries over my forty-year investing horizon?"</p>
<p><strong><em>Answer: 3.8%.</em></strong></p>
<blockquote>
<p>You want details, I got details. You can read the <a href="https://github.com/fasiha/shiller-heat/blob/8cac0574702320ffc41302c8392b4929855ed321/shiller.ts#L121-L125">code</a> or the <a href="https://drive.google.com/file/d/1jzBiJ4OAIDo35Nom0U6a655TJAnqeoMf/view?usp=sharing">spreadsheet</a> (start at cell W5), but I use Robert Shiller's <a href="http://www.econ.yale.edu/~shiller/data.htm">online dataset</a>. It contains monthly numbers for the S&amp;P 500 index's price (dollars per share), dividends (dollars per month), CPI (consumer price index, to discount inflation), and 10-year Treasury yields, all starting in 1871. I assume you invested $1 at the beginning of each month at the real CPI-adjusted price of the stock index, reinvesting the dividends that accrued over the previous month. After 480 such buying sessions, I calculate the internal rate of return (XIRR) by assuming the entire portfolio was liquidated, which is just an accounting choice to answer the question, "what real return did the S&amp;P 500 yield over this forty year horizon after monthly dollar cost averaging".</p>
<p>I then do a similar exercise with Treasuries: every month I assume you put that real $1 into a savings account-like vehicle that pays interest monthly at the same rate as the 10-year T-note's (CPI-adjusted). XIRR again computes the internal rate of return, over the same time horizon. <em>Excess</em> return is just the S&amp;P's real return minus the Treasuries' real return, and is expressed in a percentage just like any rate of return.</p>
</blockquote>
<p>Imagine now that every year after 1871, we can find one such promising young American to join the work force and to do the same thing: monthly-dollar-cost average into the S&amp;P 500 index for forty years.</p>
<p>Seven years later, the investor who began dollar-cost averaging in 1878 and asks in 1918 what their real excess rate of return was, gets a shocking number.</p>
<p><strong><em>0.3%.</em></strong></p>
<p>This investor retiring in 1918; the next one retiring in 1919, and 1920, and on, up to 1924: each of these see an excess real rate of return between <strong><em>-1.3%</em></strong> and <strong><em>0.3%</em></strong>. In 1925, the retiree who began in 1885, sees a <strong><em>0.8%</em></strong> excess real return, and only after them does each successive year's retiree see a nice positive excess real return.</p>
<p>The graph below plots this time series: the excess real return each year's retiree saw, from 1911 to 2020. Thanks to Plotly, it's interactive so you can click, tap, zoom, pan, pinch, etc. You can see it starts out at the 3.8% mentioned above, drops to -1.3% in the early 1920s, and wanders between -2.4% and 6.6%, as each year's retiree does a bit better or worse than the previous year's. The <em>median</em> excess real return for all our retirees: 1.6%.</p>

<p>From 1925 to 1981, each retiree saw a positive real excess return.</p>
<p>Then, from 1981 to 2013, thirty-one retirees during this thirty-three year interval saw negative excess real returns over forty years of monthly dollar-cost averaging. (There was a brief blip into positive territory during 1999 and 2000, i.e., the Tech Bubble.) That's a whole generation: a parent and their child could both have seen zero real excess return, over a career's worth of investing.</p>
<p>As I'm writing this, in late 2020, I see this year's retiree is looking back on 3.1% real excess return of the S&amp;P 500 over Treasuries, over forty years of monthly dollar-cost averaging. I'm about fifteen years into my career. You might be thirty-five years into yours, or just three years. We don't yet know what the graph will look like for us when we retire, in five, twenty-five, and thirty-seven years hence—but seeing this graph, with its plateaus and gyrations, and imagining at each point a retiree looking back on <em>a lifetime</em> of following solid retirement advice, gives me pause: so many of them were <em>unrewarded</em> for investing in stocks—they could have just bought Treasuries and relaxed.</p>
<p>I'm caricaturing retirement conventional wisdom a little bit—although its simplest tenet is to buy and hold a diversified basket of equities and reap its risk premium over the long-term, we haven't simulated a glide path to bonds, or explored any alternatives. Nevertheless, for me personally, answering this simple question about equities' excess real returns following this commonly-recommended strategy was very illuminating, because it makes me feel that retirement savings is less of a solved topic than I thought.</p>
<p><strong>Postscript</strong> A friend recently asked me, "What should I invest in for my newborn's college fund?" Although the universe of assets worth considering is much larger than just S&amp;P 500 ETF vs a money market fund, the above analysis can apply: what is the excess real return of the S&amp;P 500 over Treasuries over all <em>twenty</em> year horizons of monthly dollar-cost averaging, with dividends reinvested?</p>
<p>That's the graph below (along with several other horizons).</p>

<p>Answer: it ranges from between 10.4% to -10% annualized rate of return, with a <em>median</em> of 2.4%. If we imagine an annual series of parent–investors adopting this strategy, the first's child turning twenty in 1891, this median means that half of them saw excess returns greater than 2.4% and half of them less. Do these returns justify putting your child's college fund in the S&amp;P 500? I would feel sufficiently uneasy about this and seek to explore other options.</p>
<blockquote>
<p><strong>Footnote</strong> Earlier versions of this post were circulated in February 2019, and again in March 2020 which led to finding and fixing a bug in the calculation. The <a href="https://drive.google.com/file/d/1jzBiJ4OAIDo35Nom0U6a655TJAnqeoMf/view?usp=sharing">Google Sheets version</a> of Shiller's dataset includes calculations for a single data point. I also sought some feedback from the readers of <a href="https://money.stackexchange.com/q/121010">Personal Finance Stack Exchange</a>.</p>
</blockquote>
<p>(Banner: a crop from "The Monitor and Merrimac: The First Fight Between Ironclads", chromolithograph by Louis Prang &amp; Co., 1886. <a href="https://commons.wikimedia.org/wiki/File:The_Monitor_and_Merrimac.jpg">Wikimedia</a>)</p>


<p>
<small>Previous: <a href="https://fasiha.github.io/post/risk-for-kids-and-grownups/">Learning about risk, for kids and grownups</a><br></small>
</p>
</div>]]>
            </description>
            <link>https://fasiha.github.io/post/excess-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035020</guid>
            <pubDate>Mon, 09 Nov 2020 14:19:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tiny CI System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034823">thread link</a>) | @yule
<br/>
November 9, 2020 | https://www.0chris.com/tiny-ci-system.html | <a href="https://web.archive.org/web/*/https://www.0chris.com/tiny-ci-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>2020-11-08</p>
<p>This is a little demonstration of how little you need to host your own git
repositories and have a modest <a href="https://en.wikipedia.org/wiki/Continuous_integration">Continuous Integration</a>
system for them. All you need is a unixy
server you can ssh into, but arguably you can try this out locally as well.
We will use Redis at one point to queue tasks, but
strictly speaking this can be achieved without additional software. To keep things
simple this will only work with one repository, since this is only describing a
pattern.</p>
<p>The source code to all of that follows below can be found <a href="https://git.sr.ht/%7Estchris/tiny-ci">here</a>.</p>
<h2>Hosting bare git repositories</h2>
<p>Assuming you can ssh into a server and create a directory, this is all you need
to create a shareable git repository:</p>
<pre><code>$ git init --bare
</code></pre>
<p>Ideally you are using a distinct user for it (named <code>git</code>) and have it set to
use <code>git-shell</code> as its default shell. By convention bare repositories are stored
in directories which end in <code>.git</code>. You can now clone this repository from your
machine with:</p>
<pre><code>$ git clone ssh://git@host.example.com/~git/repo.git
</code></pre>
<h2>post-receive hooks</h2>
<p>A <a href="https://git-scm.com/docs/githooks#post-receive">post-receive hook</a> is an executable which can do some work as soon as something new was pushed to the repository. We will use an executable shell script which needs to go inside the <code>hooks</code> directory of the (bare) repository on the server side.</p>
<p>Now the most trivial thing to do would be to do the actual work in here, but this would block the <code>git push</code> on the client side, so we just want to enqueue a new job, return a handle and exit. If what you do takes only a short amount of time, you can stop here. Alternatively you can use this repository for deployments only, by defining it as a separate remote. But the goal here is to have tests run on every push, so we will split the job creation from the actual run.</p>
<p>This is where Redis comes into play for the job queueing. We will assume redis is installed and running and we will use redis-cli to access it from the script. We will use two data structures: a list of jobs waiting to be executed, referenced by a UUID we will generate and a hash where we can store the git revision and the state associated to a given job, as well as its output.</p>
<p>Note that git is passing three arguments to the script via stdin: the old revision before the push, the new revision and the current ref.</p>
<pre><code>#!/bin/bash
while read -r _ newrev ref
do
	id=$(uuid)
	echo "Starting CI job $id"
	redis-cli hset "$id" rev "$newrev" &gt;/dev/null
	redis-cli hset "$id" ref "$ref" &gt;/dev/null
	redis-cli lpush jobs "$id" &gt;/dev/null
done
</code></pre>
<h2>Defining build jobs</h2>
<p>By convention our system will run whatever is in an executable script named <code>ci.sh</code>. The drawback is that this only works with trusted systems and access to the repository needs to be guarded to prevent random code execution. The big advantage is that we don't need to come up with a job definition DSL or cumbersome file format.</p>
<p>Our convention will also be that the script will be passed one argument: the name of the git ref, so we can decide what to do based on the branch we are on.</p>
<p>Let's just put this into a file named <code>ci.sh</code>:</p>
<pre><code>#!/usr/bin/env bash

# the git ref gets passed in as the only argument
ref="$1"

# pretend we're running tests
echo "running tests"

# only deploy if we're on the main branch
[[ "$ref" == "refs/heads/main" ]] &amp;&amp; echo "Deploying"
</code></pre>
<h2>The build runner</h2>
<p>Now that jobs are queued the last piece missing is a job runner. We will make use of Redis' <a href="https://redis.io/commands/blpop">BLPOP command</a> to block until the jobs list has a new job for us. That job id will give us the revision we need to check out and will allow us to write back the output and status of the job.</p>
<p>Note that, as discussed, this assumes a repository called <code>test</code> is already checked out right next to the script.</p>
<p>tiny-ci.sh</p>
<pre><code>#!/usr/bin/env bash

# ./runner.sh is supposed to run on the server where your git repository lives

# the logic in here will run in an infinite loop:
# * (block and) wait for a job
# * run it
while :
do

# Announce that we're waiting
echo "Job runner waiting"

# We are using https://redis.io/commands/blpop to block until we have a new
# message on the "jobs" list. We use `tail` to get the last line because the
# output of BLPOP is of the form "list-that-got-an-element\nelement"
jobid=$(redis-cli blpop jobs 0 | tail -n 1)

# The message we received will have the job uuid
echo "Running job $jobid"

# Get the git revision we're supposed to check out
rev=$(redis-cli hget "${jobid}" "rev")
echo Checking out revision "$rev"

# Get the git ref
ref=$(redis-cli hget "${jobid}" "ref")

# Prepare the repository (hardcoded path) by getting that commit
cd test || exit; git fetch &amp;&amp; git reset --hard "$rev";

# Actually runs the job and saves the output
if ! output=$(./ci.sh "$ref" 2&gt;&amp;1);
then
    status="failed";
else
    status="success";
fi;

# Update the result status
redis-cli hset "${jobid}" "status" $status;

# Update the job output
redis-cli hset "${jobid}" "output" "$output";

echo "Job ${jobid} done"

done
</code></pre>
<h2>Running it</h2>
<p>Summing up:</p>
<ul>
<li>there's a bare git repository somewhere, called <code>test.git</code></li>
<li>we can clone the empty repo (or create a new one and add the respective remote)</li>
<li>on the server hosting the git repository we clone <code>test.git</code> into <code>test</code> and place <code>tiny-ci.sh</code> next to it</li>
<li>we run builds by starting <code>tiny-ci.sh</code> on the server hosting the repository</li>
</ul>
<p>Now if we <code>git push</code> a new commit to the <code>main</code> branch with the <code>ci.sh</code> file from above, the output will return the job id</p>
<pre><code>Enumerating objects: 5, done.
...
remote: Starting CI job dab82634-21cc-11eb-b3b3-9b8767dff47c
</code></pre>
<h2>Checking build status</h2>
<p>Knowing a job uuid, the easiest way to get the status
of a build is by using the <code>--csv</code> style output of the <a href="https://redis.io/commands/hgetall">HGETALL</a> command of redis.</p>
<pre><code>$ ssh example.com redis-cli --csv hgetall $JOB_UUID
"rev","f0706ea18a22031f84619b1161c8fbdb0dcd6850","ref","refs/heads/master","status","success","output","running tests\nDeploying"
</code></pre>
<h2>Possible further improvements</h2>
<ul>
<li>
<p><strong>multi-repo support</strong></p>
<p>This would mean changes to the <code>post-receive</code> hook to put jobs in a list named <code>job-${REPONAME}</code> and then have the worker also react based on that. Notice how <code>redis-cli blpop</code> takes several lists to watch and will also return the name of the list.</p>
</li>
<li>
<p><strong>job cleanup</strong></p>
<p>Creating a key for every job pollutes the redis database unnecesarily. Enqueuing the job could be done via <a href="https://redis.io/commands/setex">SETEX</a> so that the keys go away after one hour / one day / one week. The purpose of Redis here is short term storage and not long-term archival of job results</p>
</li>
<li>
<p><strong>more workers</strong></p>
<p>Scaling to multiple workers on the same machine would need different working folders (and some process isolation depending on the tasks run in there). Scaling to multiple machines would need access to a central redis instance for job distribution.</p>
</li>
<li>
<p><strong>worker isolation / sandboxing</strong></p>
<p>For more complex tasks some kind of process and file-system isolation is necessary. The worker could spin up VMs or Docker containers. The build system used on <a href="https://builds.sr.ht/">builds.sr.ht</a> for instance uses a <a href="https://man.sr.ht/builds.sr.ht/installation.md#security-model">Docker container run as an unprivileged user in a KVM qemu machine</a>.</p>
</li>
<li>
<p><strong>timestamps</strong></p>
<p>For convenience you would definitely want timestamps for every operation. This also allows to list queries like "the last five jobs" or to do maintenance on job results based on their time.</p>
</li>
<li>
<p><strong>notifications</strong></p>
<p>Any CI system will have some form of notifications and the simplest form would be to do something in the script, right at the end. But this covers only the success case, so a better approach would be to create a notification queue and have a notification worker react on that.</p>
</li>
</ul>
<p><a href="https://lobste.rs/s/fbc6wl/tiny_ci_system">Discuss on lobste.rs</a></p>


<ul>
  
</ul>

    </div></div>]]>
            </description>
            <link>https://www.0chris.com/tiny-ci-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034823</guid>
            <pubDate>Mon, 09 Nov 2020 13:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Free Features]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25034809">thread link</a>) | @alangibson
<br/>
November 9, 2020 | https://landshark.io/2020/11/09/no-free-features.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/09/no-free-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://news.ycombinator.com/item?id=25032105">This thread recently hit the top of Hacker news</a>.</p>

<blockquote>
  <p>No More Free Work from Marak: Pay Me or Fork This</p>

  <p>Respectfully, I am no longer going to support Fortune 500s
( and other smaller sized companies ) with my free work.</p>
</blockquote>

<p>The gist is that Marak, who’s on the brink of homelessness after his apartment building caught fire, is no longer interested in doing unpaid work for businesses using his <a href="https://github.com/Marak/faker.js">faker.js</a> project. He seems to be getting a lot of support from the open source developer community.</p>

<h2 id="unpaid-interns">Unpaid Interns</h2>

<p>The foundational principle of open source is “fix your problem, then give the world a copy of the solution.” So let’s get one thing straight: <em>open source developers are not volunteering to fix your problem.</em> They are fixing their own problems, then letting you use the solution too because it costs them nothing. That near-zero cost of replicating software is why open source works.</p>

<p>Because of this, I don’t think developers claiming to do open source should expect compensation for features that they need for themselves. But developing a new feature that they don’t need is something different entirely. In IT we call that a Change Request, and CRs come with a fee to cover them. ‘Near-zero cost’ doesn’t apply anymore because now they’re taking on a lot of work they otherwise wouldn’t have done.</p>

<p>Not recognizing this difference has led to a situation where for-profit entities are using open-source devs as unpaid interns. Well it’s worse really: at least interns get resume filler.</p>

<h2 id="no-more-free-features">No More Free Features</h2>

<p>I look forward to a day when asking anyone to do unpaid labor is considered unethical by our industry. That goes for feature requests on open source projects, on unpaid internships, and on unpaid ‘take home’ interview assignments.</p>

<p>Requesting work in an economic context without offering compensation in some form is morally indefensible. It’s wrong because unpaid labor is wrong. It’s wrong because presuming on anyone’s helpful nature is wrong. We shouldn’t be using bounties to move our change requests to the head of the line because we shouldn’t even be making requests without a bounty attached.</p>

<p>(<a href="https://news.ycombinator.com/item?id=25034809">Official Hacker News discussion thread</a>)</p>

</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/09/no-free-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034809</guid>
            <pubDate>Mon, 09 Nov 2020 13:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Writing Is About Logic, Not Words]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25034706">thread link</a>) | @anacleto
<br/>
November 9, 2020 | https://pulseasync.com/operators/share-written-ideas/ | <a href="https://web.archive.org/web/*/https://pulseasync.com/operators/share-written-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article"><p>Today it's almost obvious to state that good written communication creates a business advantage.</p>
<p>I've probably read more articles on written communication in the workplace in the last two months than over the last 10 years. </p>
<p>Most of these essays gave tips on how to become better writers.</p>
<p>I couldn't help but notice that many (if not all) of them questioned the same thing: the prose.</p>
<p>Everyone advised to keep sentences short and to the point, use active voice and not passive&nbsp;voice, use fewer commas and more periods, avoid acronyms, etc.</p>
<p>Let's be clear: none of these are mistaken or wrong by any means. But this made me realize how huge the misconceptions are on what good business writing actually means.</p>
<p>In fact, what separates most people from good writing has very little to do with style, grammar, local sentences structure, word selection, or even content per se.&nbsp;</p>
<p>Most people can't write well because they don't know how to control the logical sequence in which they present their ideas.</p>
<p>And that is the single most important act necessary to clear writing.</p>
<p>In this essay we're going to dig into how you can effectively share written ideas in a way that value time and effort for others.</p>
<hr>
<h2 id="understanding-how-we-think"><a href="#understanding-how-we-think" aria-label="understanding how we think permalink"></a>Understanding How We Think</h2>
<p>Writing an idea is always the result of two macro-steps. First, decide the point that we want want to make, and then put into words.</p>
<p>To understand how we can effectively share written ideas, we need to understand first how we formulate them in the first place.</p>
<p>Deciding the point you want to make is the result of a 5-step process.</p>
<ul>
<li><em>Unbundling</em> a concept</li>
<li><em>Noticing</em> something</li>
<li><em>Articulating</em>/<em>Developing</em> an idea</li>
<li><em>Re-Bundling</em>&nbsp;</li>
<li><em>Reframing</em></li>
</ul>
<p><img src="https://pulseasync.com/assets/generate-idea-thinking-process.png" alt="State diagram to share the 5-step process one use to generate an idea."></p>
<h3 id="unbundling-a-concept"><a href="#unbundling-a-concept" aria-label="unbundling a concept permalink"></a>Unbundling A Concept</h3>
<p>Every idea begins with an unbundling process. Unbundling is an act of exploration that leads to the decoupling of all the individual items of a certain subject.</p>
<p>Unbundling something doesn't imply a deep understanding of it. It's more a perception of full awareness.</p>
<p>In fact, you might not even know how every individual piece works, but you know they all exist in separate forms. No hidden parts.</p>
<h3 id="noticing-something"><a href="#noticing-something" aria-label="noticing something permalink"></a>Noticing Something</h3>
<p>Unbundling enhances our ability to observe, and this can lead us to noticing something. This can be a pattern, an insight, a novelty, or even a minor detail.</p>
<p>If <em>unbundling</em> is the flint, <em>noticing</em> is the spark that really makes the fire.</p>
<h3 id="articulatingdeveloping-an-idea"><a href="#articulatingdeveloping-an-idea" aria-label="articulatingdeveloping an idea permalink"></a>Articulating/Developing An Idea</h3>
<p>Only when we notice something can we start developing an idea. That's where the creative part begins. That's where you try to develop your initial cue into a fully formed idea.&nbsp;</p>
<p>For instance, if you noticed that something was unnecessary or too complicated, you might run a simplification process. If you noticed something was missing, you go through an addition or reinforcement process.</p>
<h3 id="re-bundling-and-reframing"><a href="#re-bundling-and-reframing" aria-label="re bundling and reframing permalink"></a>Re-bundling And Reframing</h3>
<p>Once you finish including your idea, you go through re-bundling. This is a reconstruction process. This is where you try to recompose a world that now contemplates your newly inserted idea.&nbsp;</p>
<p>Bundling is a fundamental part because it's where you can verify if the your new world still holds up. If not, that's a signal you need to put more work in the articulation phase or what you noticed didn't lead to anything meaningful at all.</p>
<p>If at the end of the re-bundling process your world does hold up, you go through a reframing process.</p>
<p>On paper, this seems to be a very logical and clear process, but in reality it's much more complicated as you constantly repeat these steps of of unbundling, editing your idea, and re-bundling until you find a viable path.</p>
<p><img src="https://pulseasync.com/assets/generate-idea-complexity.png" alt="The complex process of idea generation"></p>
<p>Now that you have an idea, you need to decide how to put it into words that you can share with others.</p>
<h2 id="understanding-how-we-write"><a href="#understanding-how-we-write" aria-label="understanding how we write permalink"></a>Understanding How We Write</h2>
<p>From a broader point, the single goal of writing is to get some information into someone's head.</p>
<p>Think about it. It's almost a simulation act.</p>
<p>You need to reproduce your reader's thinking process using your brain. And know how to build up your information in a way that feels logical and makes sense to them.</p>
<p>This process has very little to do with what you went through when you came up with the idea in the first place. In fact, forcing the reader through the exact same original path you took will have the opposite effect and create more confusion.</p>
<p>Here's how it often goes:</p>
<ol>
<li>You have an idea <em>x</em></li>
<li>You write down a set of words <em>m</em> that lead you to <em>x</em></li>
<li>Because of the pre-existing narrative that led you to the idea, you associate <em>m -&gt; x</em></li>
<li>When you proofread it, you mentally get it. Not because <em>m -&gt; x</em> but because of all the pre-existing associations.</li>
</ol>
<p>This is how most people write. And it's exactly why most people's writing sucks.</p>
<p>Not because they use too many passive forms or weak verbs (that doesn't help either), but because they aren't able to write from the reader's perspective. Most writings lacks the basic logical order and structure.</p>
<h2 id="what-is-good-business-writing"><a href="#what-is-good-business-writing" aria-label="what is good business writing permalink"></a>What is Good Business Writing</h2>
<p>Good business writing is a combination of two things:</p>
<ul>
<li>Information Context</li>
<li>Information Resolution</li>
</ul>
<h3 id="how-to-build-context-the-scqa-framework"><a href="#how-to-build-context-the-scqa-framework" aria-label="how to build context the scqa framework permalink"></a>How to build Context: The SCQA Framework</h3>
<p>Context is the "<em>you're here</em>" red arrow that you can see on almost any maps. Good information context helps the reader set the frame to understand what they're about to read next.</p>
<p>Shared context helps the participants make judgments calls using the same pair of lenses.</p>
<p>A lack of a shared understanding on the basic principles can easily result in a partial understanding or conflict on what follows.</p>
<p>What's the best way to build information context?</p>
<p>Barbara Minto, a McKinsey consultant in the 70s, solved this problem with what she called the <em>SCQA framework</em>.</p>
<p>She named this framework the <em>Situation — Complication — Question — Answer</em> framework. You can unpack more on this topic in her book “The Pyramid Principle”.</p>
<p>According to Minto, context is the result of these four sub-ingredients:</p>
<ol>
<li>Situation,</li>
<li>A Complication,</li>
<li>A Question,</li>
<li>... and an Answer.</li>
</ol>
<p>The <strong>Situation</strong> is a non-controversial statement on a subject that you know the reader will agree because it's something he already knows. By summarizing what he already knows, the situation establishes the relevance of the questions that your document is going to answer.&nbsp;</p>
<p>The <strong>Complication</strong> describes an alteration of a stable situation. Keep in mind, this alteration is purely fact-based. The Situation-Complication combination should lead the reader to an immediate question.</p>
<p>The <strong>Question</strong> represents an intuitive response to the complication. The best Situation-Complication scenario makes the question sound totally superfluous to state. The best questions aren't posed, they emerge.</p>
<p>The <strong>Answer</strong> is the summary of your main idea. Beware, it's the solution, not the explanation of it. Good answers are typically represented by 3/4 bullet points. No more.</p>
<p>If you squint at it, you realise that the SCQA framework turned out initial schema upside down.</p>
<p>Ideas comes up in a bottom-up fashion, but they need to be told top-down.</p>
<p>This is not how we think. But it's how we should write.</p>
<p><img src="https://pulseasync.com/assets/scqa-reversed-thinking-frmework.png" alt="SCQA reversed thinking framework"></p>
<p>Another interesting benefit of building information context using the SCQA framework is that once you've gotten the initial part out of the way, you can focus all your energy on making and supporting the case for why it's true.</p>
<h3 id="how-to-increase-resolution-whyhow-dialogues"><a href="#how-to-increase-resolution-whyhow-dialogues" aria-label="how to increase resolution whyhow dialogues permalink"></a>How to increase Resolution: Why/How Dialogues</h3>
<p>Ensuring you and your reader are in the same place before you lead him through your thinking is a necessary but non-sufficient condition. </p>
<p>Once he's aware of the gist of your main idea (Answer), you need to argue and support it. That's when you need to focus on information resolution.</p>
<p>Think of <em>information resolution</em> as the density level of details that you're able to provide to the reader. The bolder the answer, the higher resolution levels it requires.</p>
<p>If you gloss over key important passages, people will not follow your thinking and might have a partial understanding of the message.</p>
<p>How do you increase information resolution?</p>
<p>You support your initial <em>Answer</em> using the form of Why/How dialogues. Making an initial statement that the reader doesn't know will automatically raise a logical question in his mind. <em>How is that possible?</em> <em>Why do you say that?</em> In your following answers, you're likely to tell him other details he doesn't know and this will raise further questions that you're going to answer. And so on.</p>
<p>The author will continue to write, raising and answering questions, until he reaches a point at which he judges the reader will have no more logical questions.</p>
<p>The vertical relationship of a why/how dialogue helps capture the reader's attention. It permits you, as an author, to establish an inner dialog that will pull him with great interest through your reasoning. The reader will be forced to respond logically to your ideas.</p>
<p>As you can see we've not made a full circle. We're now in the (previously discussed) unbundling part.</p>
<h2 id="examples-of-good-business-writing"><a href="#examples-of-good-business-writing" aria-label="examples of good business writing permalink"></a>Examples of Good Business Writing</h2>
<p>Armed with our SCQA framework and the Why/How vertical development, let's look at the skeleton of some real examples.</p>

<p>It's one of the most common examples. common examples. A salesperson, after speaking with a customers, irrupts in the #product or #engineering Slack channels requesting the implementation of a given feature.</p>
<p>If you've been in this position, here's how you can Minto-ize an internal feature request for your product:</p>
<blockquote>
<p><em>Situation:</em>
We have never allowed customers to customize XYZ in order to keep complexity low.</p>
<p><em>Complication:</em>
However, competitor X has now shipped such a customization feature, and we’ve been losing deals because of that.</p>
<p><em>Questions:</em>
We now need to decide whether we want to allow some kind of customization as well.</p>
<p><em>Answer:</em>
[...]</p>
</blockquote>

<p>Directives are the most common internal memo. Executives write them to request something of someone.</p>
<blockquote>
<p><em>Situation:</em>&nbsp;
As you know we're repositioning product <em>x</em> for mid-sized enterprise. We need to teach you how to see <em>x</em> for organizations between 100 and 200 employees.</p>
<p><em>Complication:</em>
We've never sold to this type of customer before. Hence, we need to construct a new customer profile from scratch</p>
<p><em>Questions:</em> (How can we do the profile?)</p>
<p><em>Answer:</em>
We're going to host:</p>
<ol>
<li>A …</li></ol></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulseasync.com/operators/share-written-ideas/">https://pulseasync.com/operators/share-written-ideas/</a></em></p>]]>
            </description>
            <link>https://pulseasync.com/operators/share-written-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034706</guid>
            <pubDate>Mon, 09 Nov 2020 13:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using “Virtio-Fs” on a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034668">thread link</a>) | @ingve
<br/>
November 9, 2020 | https://www.qemu.org/2020/11/03/osv-virtio-fs/ | <a href="https://web.archive.org/web/*/https://www.qemu.org/2020/11/03/osv-virtio-fs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
		<div>
			<!-- Main -->
	<section>
		<header>
			
			<p>03 Nov 2020 — by Fotis Xenakis</p>
		</header>
		<p>This article provides an overview of <a href="https://virtio-fs.gitlab.io/">virtio-fs</a>,
a novel way for sharing the host file system with guests and
<a href="https://github.com/cloudius-systems/osv">OSv</a>, a specialized, lightweight
operating system (unikernel) for the cloud, as well as how these two fit
together.</p>

<h2 id="virtio-fs">virtio-fs</h2>

<p>Virtio-fs is a new host-guest shared filesystem, purpose-built for local file
system semantics and performance. To that end, it takes full advantage of the
host’s and the guest’s colocation on the same physical machine, unlike
network-based efforts, like virtio-9p.</p>

<p>As the name suggests, virtio-fs builds on virtio for providing an efficient
transport: it is included in the (currently draft, to become v1.2) virtio
<a href="https://github.com/oasis-tcs/virtio-spec">specification</a> as a new device. The
protocol used by the device is a slightly extended version of
<a href="https://github.com/libfuse/libfuse">FUSE</a>, providing a solid foundation for
all file system operations native on Linux. Implementation-wise, on the QEMU
side, it takes the approach of splitting between the guest interface (handled
by QEMU) and the host file system interface (the device “backend”). The latter
is handled by virtiofsd (“virtio-fs daemon”), running as a separate process,
utilizing the
<a href="https://www.qemu.org/docs/master/interop/vhost-user.html">vhost-user</a> protocol
to communicate with QEMU.</p>

<p>One prominent performance feature of virtio-fs is the DAX (Direct Access)
window. It’s a shared memory window between the host and the guest, exposed as
device memory (a PCI BAR) to the second. Upon request, the host (QEMU) maps file contents to the window for the guest to access directly. This bears performance
gains due to taking VMEXITs out of the read/write data path and bypassing the
guest page cache on Linux, while not counting against the VM’s memory (since
it’s just device memory, managed on the host).</p>

<p><img src="https://gitlab.com/virtio-fs/virtio-fs.gitlab.io/-/raw/master/architecture.svg" alt="virtio-fs DAX architecture"></p>

<p>Virtio-fs is under active development, with its community focussing on a pair of
device implementation in QEMU and device driver in Linux. Both components are
already available upstream in their initial iterations, while upstreaming
continues further e.g. with DAX window support.</p>

<h2 id="osv">OSv</h2>

<p>OSv is a <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a> (framework). The
two defining characteristics of a unikernel are:</p>

<ul>
  <li><strong>Application-specialized</strong>: a unikernel is an executable machine image,
consisting of an application and supporting code (drivers, memory management,
runtime etc.) linked together, running in a single address space (typically
in guest “kernel mode”).</li>
  <li><strong>Library OS</strong>: each unikernel only contains the functionality mandated by its
application in terms of non-application code, i.e. no unused drivers, or even
whole subsystems (e.g. networking, if the application doesn’t use the
network).</li>
</ul>

<p>OSv in particular strives for binary compatibility with Linux, using a <a href="https://github.com/cloudius-systems/osv/wiki/Dynamic-Linker">dynamic
linker</a>. This means
that applications built for Linux should run as OSv unikernels without requiring
modifications or even rebuilding, at least most of the time. Of course, not the
whole Linux ABI is supported, with system calls like <code>fork()</code> and relatives
missing by design in all unikernels, which lack the notion of a process. Despite
this limitation, OSv is quite full featured, with full SMP support, virtual
memory, a virtual file system (and many filesystem implementations, including
ZFS) as well as a mature networking stack, based on the FreeBSD sources.</p>

<p>At this point, one is sure to wonder “Why bother with unikernels?”. The problem
they were originally
<a href="http://unikernel.org/files/2013-asplos-mirage.pdf">introduced</a> to solve is the
bloated software stack in modern cloud computing. Running general-purpose
operating systems as guests, typically for a single application/service, on top
of a hypervisor which already takes care of isolation and provides a standard
device model means duplication, as well as loss of efficiency. This is were
unikernels come in, trying to be just enough to support a single application
and as light-weight as possible, based on the assumption that they are executing
inside a VM. Below is an illustration of the comparison between
general-purpose OS, unikernels and containers (as another approach to the same
problem, for completeness).</p>

<p><img src="https://www.qemu.org/screenshots/2020-11-04-unikernel-vs-gpos.svg" alt="Unikernels vs GPOS vs containers"></p>

<h2 id="osv-meet-virtio-fs">OSv, meet virtio-fs</h2>

<p>As is apparent e.g. from the container world, it is very common for applications
running in isolated environments (such as containers, or unikernels even more
so) to require host file system access. Whereas containers sharing the host
kernel thus have an obvious, controlled path to the host file system, with
unikernels this has been more complex: all solutions were somewhat heavyweight,
requiring a network link or indirection through network protocols. Virtio-fs
then provided a significantly more attractive route: straight-forward mapping of
fs operations (via FUSE), reusing the existing virtio transport and decent
performance without high memory overhead.</p>

<p>The OSv community quickly identified the opportunity and came up with a
read-only implementation on its side, when executing under QEMU. This emphasized
being lightweight complexity-wise, while catering to many of its applications’
requirements (they are stateless, think e.g. serverless). Notably, it includes
support for the DAX window (even before that’s merged in upstream QEMU),
providing <a href="https://github.com/foxeng/diploma">excellent performance</a>, directly
rivalling that of its local (non-shared) counterparts such as ZFS and ROFS (an
OSv-specific read-only file system).</p>

<p>One central point is OSv’s support for booting from virtio-fs: this enables
deploying a modified version or a whole new application <strong>without rebuilding</strong>
the image, just by adjusting its root file system contents on the host. Last,
owing to the DAX window practically providing low-overhead access to the host’s
page cache, scalability is also expected to excel, with it being a common
concern due to the potentially high density of unikernels per host.</p>

<p>For example, to build the <code>cli</code> OSv image, bootable from virtio-fs, using the
core OSv <a href="https://github.com/cloudius-systems/osv#building-osv-kernel-and-creating-images">build
system</a>:</p>
<div><div><pre><code>scripts/build fs=virtiofs export=all image=cli
</code></pre></div></div>
<p>This results in a minimal image (just the initramfs), while the root fs contents
are placed in a directory on the host (<code>build/export</code> here, by default).</p>

<p><a href="https://github.com/cloudius-systems/osv#running-osv">Running</a> the above image
is just a step away (may want to use the virtio-fs development version of
<a href="https://gitlab.com/virtio-fs/qemu/-/tree/virtio-fs-dev">QEMU</a>, e.g. for DAX
window support):</p>
<div><div><pre><code>scripts/run.py --virtio-fs-tag=myfs --virtio-fs-dir=$(pwd)/build/export
</code></pre></div></div>
<p>This orchestrates running both virtiofsd and QEMU, using the contents of
<code>build/export</code> as the root file system. Any changes to this directory, directly
from the host will be visible in the guest without re-running the previous build
step.</p>

<h2 id="conclusion">Conclusion</h2>

<p>OSv has gained a prominent new feature, powered by virtio-fs and its QEMU
implementation. This allows efficient, lightweight and performant access to the
host’s file system, thanks to the native virtio transport, usage of the FUSE
protocol and the DAX window architecture. In turn, it enables use cases like
rapid unikernel reconfiguration.</p>

		<ul>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/storage/index.html">storage</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/virtio-fs/index.html">virtio-fs</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/unikernel/index.html">unikernel</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/osv/index.html">OSv</a></li>
		
		</ul>
	</section>

		</div>
	</div></div>]]>
            </description>
            <link>https://www.qemu.org/2020/11/03/osv-virtio-fs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034668</guid>
            <pubDate>Mon, 09 Nov 2020 13:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cyrillic orthography for the Polish language]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25034182">thread link</a>) | @keiferski
<br/>
November 9, 2020 | http://steen.free.fr/cyrpol/index.html | <a href="https://web.archive.org/web/*/http://steen.free.fr/cyrpol/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!---------------- Header ------------------->





<!---------------- Body ------------------->



<p><small><i>See also: </i> <a href="http://steen.free.fr/interslavic/index.html">Interslavic</a>, <a href="http://steen.free.fr/wenedyk/index.html">Wenedyk</a>, <a href="http://steen.free.fr/poilschi/index.html">Poilschi</a></small></p>

<a name="introduction"></a>

<h2>Ortografia cyrylicka dla języka polskiego</h2>
<h2>A Cyrillic orthography for the Polish language</h2>

<p><big>E</big>ver wondered what Polish would look like if it were written in Cyrillic? Perhaps you have. Or not. In any case, I have. That's what happens when you spend half of your life working on language projects that one way or another are related to Polish or the Slavic languages in general. Toying around with Polish, Slavic, as well as with several Slavic orthographies, it is hard not to think about the possibilities of a Cyrillic orthography for Polish.</p>

<p>Many people have argued that Cyrillic would be unsuitable for Polish. I disagree with that opinion. Granted, Polish phonology differs from that of the other Slavic languages in several ways, but these two facts remain: Polish is a completely Slavic language by any standard, and Cyrillic, unlike the Latin alphabet, was made especially to fit Cyrillic phonology, and therefore is perfectly suited for it. Therefore, I am convinced that Polish and Cyrillic are a perfect match. Much more so, in fact, than Polish and the Latin alphabet. Latin orthographies of Slavic languages always have one of the following two disadvantages: either they are full of diacritical marks, or they look horribly like English or another Western language. Slovene manages best, but still has <b>š</b>, <b>ž</b> and <b>č</b>. Other languages have more of those babies. Polish orthography has managed to avoid hačeks, but has a whole bunch of other diacritics instead: <b>ą</b>, <b>ę</b>, <b>ł</b>, <b>ż</b>, <b>ć</b>, <b>ń</b>, <b>ó</b>, <b>ś</b>, <b>ź</b>. Besides, Polish in addition tends to favour digraphs like <b>sz</b> and <b>ie</b>, so Polish words tend to be appear longer than they actually are.</p>

<p>Now, I am quite fond of Polish orthography, and therefore my Cyrillic orthography of Polish should by no means be treated as a serious proposal to replace Polish orthography. If anyone would ever make such a proposal, I would be the first to stand up against it. This project, therefore, is primarily a thought experiment, my answer to the question if such an orthography would be possible at all.</p>

<p>The idea, by the way, is not new at all. If we have to believe Wikipedia, Russia's czar Nikolay I intended to cyrillify Polish in the mid-19th century as a means for russification, although at last nothing came of his plans. Here is a sample:</p>

<table><tbody><tr><td>
<div><p>Поврóтъ Таты, <i>пр̌езъ А. Мицкевича</i></p><p>
Пóйдзьце о дзятки, пóйдзьце вшистке разэм<br>
За място, подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкнийце образэмъ,<br>
Побожне змóвце пацёрэкъ.</p><p>
Тато не враца ранки и вечоры<br>
Вэ Лзах го чекамъ и трводзэ;<br>
Розлялы р̌еки, пэлнэ звер̌а боры,<br>
И пэлно збóйцóвъ на дродзэ;-</p></div>
</td><td>
<div><p>Слышąцъ то дзятки бегнą вшистке разэмъ<br>
За място подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкая̨ образемъ,<br>
И зачиная̨ пацёрэкъ.</p><p>
Цалуя̨ земę, потэмъ въ Имę Ойца,<br>
Сына и Духа свęтэго,<br>
Бąдзь похвалёна пр̌енайсьвęтша Трóйца<br>
Тэразъ и часу вшелькего.</p><p>
(...)</p></div></td></tr></tbody></table>

<p>A few pecularities in this text deserve our attention:
</p><ul>
<li>the use of the letter <b>р̌</b> for Polish <b>rz</b>;
</li><li>the hard sign <b>ъ</b> at the end of many words (a feature common in prerevolutionary Russian);
</li><li>the fact that Polish <b>ó</b> remains untouched;
</li><li>this orthography inherits the Polish ogonek and adds it to Cyrillic letters;
</li><li>the use of <b>ць</b> and <b>дзь</b> where Polish has <b>ć</b> and <b>dź</b>, a feature also present in contemporary Belarusian.
</li></ul>

<p>My own Cyrillic orthography for Polish is largely based on the same premises, but there are a few differences as well, which I will describe below. By the way, it should be noted that the transcription quoted above is not the only attempt at a Cyrillic alphabet for Polish. Several people have played with the idea, seriously or less seriously. An interesting example is <a href="http://varpho.livejournal.com/2006/11/17/">Jusowica (Юсовица)</a>, created by Szymon Pawlas.</p>

<hr>

<p><big>T</big>he biggest problem related with the Cyrillisation of Polish are sounds that do not exist in other languages, nor do they correspond closely with anything else that exist in them: the nasal vowels <b>ą</b> and <b>ę</b>. The 19th century Russian solution is in fact a pretty funny one: it simply teleports the ogonek to Cyrillic, thus producing four characters that have never seen before in Cyrillic: <b>а̨</b>, <b>э̨</b>, <b>я̨</b> and <b>е̨</b> (the latter two representing <b>ją</b> and <b>ję</b> respectively). A funny solution indeed! And an unnecessary one to that, because Old Church Slavonic has precisely four Cyrillic characters for exactly these four sounds: <b>ѫ</b>, <b>ѧ</b>, <b>ѭ</b> and <b>ѩ</b>. True, they are uncommon, because the only living Slavic language that preserved these sounds is Polish, a language that happens to be written in Latin alphabet. But since these letters are around, why shouldn't we simply use them? After all, they exist, and are indefinitely more Cyrillic than Cyrillic letters with ogoneks beneath them. Besides, the choice for <b>а̨</b> and <b>я̨</b> is equally unlogical as the Polish letter <b>ą</b> itself, since it is pronounced as nasalised <b>o</b>; it is not for nothing that the Latin transcription of Old Church Slavonic uses <b>ǫ</b>.</p>

<p>Another specifically Polish letter is the <b>ó</b>, pronounced as [u] (its Czech equivalent is <b>ů</b>). The transcription mentioned above conveniently keeps it. But why would we? It has no pronunciation of its own; the only thing that distinguishes it from <b>u</b> is that it alternates with <b>o</b>. Incidentally, mixing up those two is the most common spelling mistake in Polish. As far as I am concerned, there is no reason to keep it. Since <i>miasto</i> alternates with <i>mieście</i> (and not with <i>miæście</i> or something), why can't <i>grud</i> alternate with <i>grodzie</i>? So let's be bold and use <b>у</b> instead.</p>

<p>The characters <b>ć</b> and <b>dź</b> could of course be rendered like Belarusian (and in a way, Polish) does, by using <b>ць</b> and <b>дзь</b>, but I'd much prefer <b>ть</b> and <b>дь</b>. Etymologically speaking, this is more correct; after all <b>ć/dź</b> are the softened equivalents of <b>t/d</b>, not of <b>c/dz</b>. Sequences like <b>ti</b> and <b>di</b> are rare in Polish and occur only in foreign words. In these rare cases, we could write <i>радио</i> and <i>тиара</i> (a Pole will know that they are to be read as <i>radio</i> and <i>tiara</i> and not like <i>radzio</i> or <i>ciara</i>). Or, if we want to be really sure that the <b>t</b> will not be softened in these cases, we could use the hard sign and write <i>радъио</i> and <i>тъиара</i>.<br>
Using <b>ть</b>/<b>дь</b> instead of <b>ць</b>/<b>дзь</b> has one more advantage: now at least will not have to worry about the sequence <b>cja</b>, which is unambiguously rendered as <b>ця</b>.</p>

<p>Same goes for the digraphy <b>rz</b>, which in Polish is pronounced like <b>ż</b>. Another common source of spelling errors. Yet, I wouldn't propose transcribing it to <b>ж</b>, for the same etymological reasons: <b>rz</b> comes from softened <b>r</b>, while <b>ż</b> comes from softened <b>g</b>. The fact that it sounds very different does not change that fact. Therefore, we simply use <b>рь</b> (and not this weird creation from the 19th century, <b>р̌</b>). Just like <b>ti</b> and <b>di</b>, <b>ri</b> is a rare sequence in Polish that occurs only in foreign words, so I propose the same solution for it as well.</p>

<p>And then we have the letter <b>e</b>. Because in Polish palatalising <b>e</b> is way more numerous than its non-palatalising equivalent, we will use Cyrillic <b>e</b> for the former (usually rendered as <b>je</b> or <b>ie</b>) and <b>э</b> for the latter. This is also what the 19th century version does.</p>

<p>The choice for other Cyrillic letters is merely a matter of picking an option. For example, how do we represent <b>i</b> and <b>y</b>? Do we follow the Russian model and pick <b>и/ы</b> or do we prefer the Ukrainian model and pick <b>і/и</b>? Both are possible, but I've decided to follow the Russian model. Also, when preceded by <b>cz</b>, <b>sz</b> or <b>ż</b> we write <b>и</b> instead of <b>ы</b> – just like Russian does. Again, a matter of etymology.</p>

<p>So, let's see now what Cyrylica Polska looks like.</p>

<a name="alphabet"><hr></a><h2>Alphabet</h2>

<p><big>C</big>yrylica Polska has 37 letters. Exactly the same as the 33 letters of the Russian alphabet, with four additional characters for the nasals:</p>

<p><p><b><span size="+1">А Б В Г Д Е Ë Ж З И Й К Л М Н О П Р С Т У Ф Х Ц Ч Ш Щ Ъ Ы Ь Э Ю Я Ѧ Ѫ Ѩ Ѭ</span></b></p></p>

<a name="vowels"><hr></a><h2>Vowels</h2>

<p><big>E</big>very vowel has a hardening and a softening version. Both can occur in two possitions: either it follows a consonant, or it doesn't (in that case it is either word-initial or after another vowel). In Polish orthography, when a softening vowel follows a consonant, it is preceded by <b>i</b>, unless the consonant in question is inherently soft. In other positions this vowel is preceded by <b>j</b>. The only exceptions are <b>i</b>, which is softening by definition, and <b>y</b>, which is never softening. <br>
Just like <b>i</b> and <b>y</b> form a pair, in Cyrillic all vowels come in pairs, as you can see in the table below:</p>

<p><table><colgroup><col><col><col><col>
</colgroup><tbody><tr><th colspan="2">Latin</th><th colspan="2">Cyrylica</th></tr>
<tr><th> <i>hard</i> </th><th> <i>soft</i> </th><th> <i>hard</i> </th><th> <i>soft</i> </th></tr>
<tr><td>	a	</td><td>	ia/ja		</td><td>	а	</td><td>	я	</td></tr>
<tr><td>	e	</td><td>	ie/je		</td><td>	э	</td><td>	е	</td></tr>
<tr><td>	y	</td><td>	i		</td><td>	ы	</td><td>	и	</td></tr>
<tr><td>	o	</td><td>	io/jo		</td><td>	о	</td><td>	ë	</td></tr>
<tr><td>	ó<br>u	</td><td>	ió/jó<br>iu/ju	</td><td>	у	</td><td>	ю	</td></tr>
<tr><td>	ą	</td><td>	ią/ją		</td><td>	ѫ	</td><td>	ѭ	</td></tr>
<tr><td>	ę	</td><td>	ię/ję		</td><td>	ѧ	</td><td>	ѩ	</td></tr>
</tbody></table></p>

<a name="consonants"><hr></a><h2>Consonants</h2>

<p><big>N</big>ow that the question of palatalised vs. non-palalalised consonant has been resolved by the vowels that follow them, the consonants have suddenly become very simple to handle. Here goes:</p>

<p><table><tbody><tr><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	p		</td><td>	п	</td></tr>
<tr><td>	b		</td><td>	б	</td></tr>
<tr><td>	f		</td><td>	ф	</td></tr>
<tr><td>	w		</td><td>	в	</td></tr>
<tr><td>	t, ć		</td><td>	т	</td></tr>
<tr><td>	d, dź		</td><td>	д	</td></tr>
<tr><td>	s, ś		</td><td>	с	</td></tr>
<tr><td>	z, ź		</td><td>	з	</td></tr>
<tr><td>	k		</td><td>	к	</td></tr>
<tr><td>	g		</td><td>	г	</td></tr>
<tr><td>	ch<br>h		</td><td>	х	</td></tr>
</tbody></table>
</td><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	sz		</td><td>	ш	</td></tr>
<tr><td>	ż		</td><td>	ж	</td></tr>
<tr><td>	cz		</td><td>	ч	</td></tr>
<tr><td>	szcz		</td><td>	щ	</td></tr>
<tr><td>	c		</td><td>	ц	</td></tr>
<tr><td>	m		</td><td>	м	</td></tr>
<tr><td>	n		</td><td>	н	</td></tr>
<tr><td>	ł, l		</td><td>	л	</td></tr>
<tr><td>	r, rz		</td><td>	р	</td></tr>
<tr><td>	j		</td><td>	й	</td></tr>
<tr><td>	ь		</td><td>	soft sign	</td></tr>
<tr><td>	ъ		</td><td>	hard sign	</td></tr>
</tbody></table>
</td></tr></tbody></table></p>

<p>A few notes:
</p><ul>
<li>Most consonants can be soft (palatalised) or hard. Whether a Cyrillic <b>д</b> should be read as <b>d</b> or <b>dź</b> is decided by the consonant that follows it: <b>дэ</b> should be read as <b>de</b>, <b>де</b> should be read as <b>dzie</b>.
</li><li>If a soft consonant is not followed by a vowel, i.e. when it is word- or syllable-final, it is followed by the soft sign: <b>bat</b> becomes <b>бат</b>, <b>bać</b> becomes <b>бать</b>.
</li><li>In reality, the soft sign will occur only after <b>т</b>, <b>д</b>, <b>н</b>, <b>л</b>, and <b>р</b>. However, in a few cases it can be placed after another consonant as well, although that wouldn't affect pronunciation. For example, take these two Polish cities: Kraków and Wrocław. When declined, the former has a hard <b>w</b>, the latter a soft <b>w</b>, and so their genitives are <i>Krakowa</i> and <i>Wrocławia</i> respectively. In Cyrillic, we could easily write <b>Вроцлавь</b> for "Wrocław", to make this fact predictable.
</li><li>Most consonant clusers as palatalised as a whole, and only in a few cases consonants in such a cluster are palatalised individually. Therefore, <b>śmiałość</b> is written <b>смялость</b>, and not <b>сьмялосьть</b>.
</li><li>The consonant clusters <b>śr</b> and <b>źr</b> (historically from <i>ser-/zer- &gt; srze-/zrze-</i>, in some dialects <i>st…</i></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://steen.free.fr/cyrpol/index.html">http://steen.free.fr/cyrpol/index.html</a></em></p>]]>
            </description>
            <link>http://steen.free.fr/cyrpol/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034182</guid>
            <pubDate>Mon, 09 Nov 2020 12:49:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Urgency Illusion: How to stay present when big things happen in the world]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034043">thread link</a>) | @LeonW
<br/>
November 9, 2020 | https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/ | <a href="https://web.archive.org/web/*/https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>    
                
            </header>

            <section>
            <div>
                <div><p>Last week I felt way more on edge than usual. There were new lockdown restrictions here in Austria due to COVID, the US elections kept me checking the news every few minutes and a terrorist attack shook up the country. My belly was tight and the world felt gray. Quickly, I felt preoccupied with so many things at once.</p>
<p>My experience is that when events like these happen, I can feel an urge to drop everything and somehow get involved and do things related to these events. Or to fall into apathy. Some of that feels good, yet often the intention it’s coming from is one of my underlying fear, anger, hatred, or sadness. I witness this in others often too. The more I reflect on this, the more it becomes clear to me that this is usually a dead-end. The more helpful way forward seems to be to attend to my emotions and state of being first, before I’m doing anything with it.</p>
<p>Hard, yet simple. Especially when so much is coming at us all at once.</p>
<h2>Being touched, but not led astray</h2>
<p>My friend Matthias told me recently on a hike through the forest, how he spent some time meditating on the terrorist attacks. His intention was to see the causes and conditions that led to it, casting a net as wide as possible. To me, this was a great example of letting ourselves be touched by current events, but not led astray. I would illustrate it like this:</p>
<p><img loading="lazy" src="https://leowid.com/wp-content/uploads/2020/11/ideas-8.jpg" alt="" width="2157" height="1668" srcset="https://leowid.com/wp-content/uploads/2020/11/ideas-8.jpg 2157w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-300x232.jpg 300w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-1024x792.jpg 1024w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-768x594.jpg 768w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-1536x1188.jpg 1536w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-2048x1584.jpg 2048w" sizes="(max-width: 2157px) 100vw, 2157px"></p>
<p>The patterns I see the most and know well from myself, that I believe aren’t very helpful are two extreme reactions to current events:</p>
<ul>
<li><strong>apathy or “I don’t care…”</strong>: I simply carry on with my life, pretending that nothing happened or ignoring any major current events that have shaken up the world. This tends to keep me focused, but also makes my work and attention kind of lifeless, apathetic, and overall feel disconnected from my own intentions and dreams.</li>
<li><strong>flooded or “OMG, drop everything &amp; let’s do something!”</strong>: Here I have such a strong reaction that I want to take to the streets immediately, express my anger, hurt, sadness, and pain in the hopes that it will improve the situation. I feel reactive and righteous that I’m doing something about the situation.</li>
</ul>
<p>I believe that neither of these reactions helps us create the life and world that we ultimately want to see. And I think there’s a middle way, that uses the wisdom of both of these more extreme directions:</p>
<ul>
<li><strong>Care</strong>: When there is a major external event after we’ve gotten to safety, whether it’s from disease, attack, or something else, we first need care. By care, I mean our ability to tend to the emotional and inner states that have been evoked from the event. Tending to our anger, hurt, pain, feeling our sadness, tears, and frustration. This can take some time and the more support we have to feel through these elements of life, the more enjoyable this part can be for us.</li>
<li><strong>Integration with the life you want</strong>: Once the big emotions have settled, we can turn our attention to integration and meaning-making. What does it mean that we have experienced this? How does this connect with our bigger intention of living the life we want? An example from my own life is that through plenty of reflection on the coronavirus crisis and the amount of physical distancing and disconnection has birthed a new idea of a product to help us reconnect in a meaningful way, even when we’re not in the same room together. I’ve deeply enjoyed working on this the last weeks, it doesn’t feel reactive, yet it seems to be aligned with what is happening in the wider world and my dream of creating more presence and aliveness for myself and the people I meet.</li>
</ul>
<h2>Letting the urgency illusion pass and acting with power</h2>
<p>As the urgency illusion passes, there comes a window for all of us where we can be present to what happened and at the same time have enough space inside for ourselves and our dreams. This is the sweet spot, where we can make useful sense of ourselves and the world around us.</p>
<p>If you’re stuck along the journey towards integration right now, here’re some questions that you might find helpful to journal with:</p>
<ul>
<li><strong>Care-questions</strong>: What needs to be tended to on the inside? How are you doing? What level of care would support you the most right now?</li>
<li><strong>Integration-questions</strong>: What are the 3 most important values for you to live into in this life? Where is the overlap between those and what happened in the world? How can you move forward in integrity with what happened, without throwing everything overboard?</li>
</ul>
<p>From there, see which actions naturally arise for you as you give yourself space and time to let everything integrate.</p>
<p>Whatever you’re going through, keep going, sending love and care your way!</p>
</div>
            </div>
        </section><section>
                <div>
                    <p><img data-src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" data-srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w" data-sizes="(max-width: 100px) 100vw, 100px" alt="" src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w">
                        <span>Leo Widrich</span>
                        <span>Leo Widrich coaches extraordinary people. In his previous life, he co-founded Buffer, a $20m+ revenue software company. He also lived in Buddhist monasteries for close to two years, trained as a trauma therapist and now lives in Vienna near the forest. He tweets <a href="https://twitter.com/LeoWid">@leowid</a>. To learn about working with him, <a href="https://leowid.com/working-with-me/">go here</a>.</span>
                    </p>
                </div>
            </section><section>
        <div>
            <div><h3>Receive my most vulnerable and powerful lessons from meeting life.</h3><p>Add your details below for my weekly newsletter.</p></div>
        </div>
    </section>
        </div></div>]]>
            </description>
            <link>https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034043</guid>
            <pubDate>Mon, 09 Nov 2020 12:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When remote work doesn't cut it]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25034037">thread link</a>) | @FlyingSnake
<br/>
November 9, 2020 | https://samkhawase.com/blog/remote-work/ | <a href="https://web.archive.org/web/*/https://samkhawase.com/blog/remote-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>The COVID-19 crisis, while disrupting the global world unlike anything before, has opened up an unexpected window to remote work. Nearly all major<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>tech<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> giants<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> have<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> allowed their workers to do home office. Many people are considering this as a sign of the advent of <strong>Work 2.0</strong>, where physical offices spaces will be irrelevant, and people can work from their cozy dens. There are however significant challenges in adoption of generalized remote work and things will be back as usual once the COVID-19 ends.</p>
<p>The <strong>challenges surrounding remote work outweigh it’s promises</strong>. Not every company is a FAANG, and companies will struggle to transition given their limited resources.</p>
<h2 id="regulations">Regulations</h2>
<p>The most significant hurdle in hiring a global remote team is <strong>regulation</strong>. Labor regulations are wildly different amongst countries, and could be cumbersome for some companies. Some major hurdles include:</p>
<ul>
<li>
<p><strong>Payroll taxes</strong>, retirement bonuses: Germany has rentenversicherung, sozialversicherung whereas USA has 401k contributions. Can a German company afford to <strong>setup payroll</strong> taxes for a remote workers hired from India, Chile or US? Or will it lead to worker abuse through <strong>laissez-faire abuse</strong> through freelance contracts?</p>
</li>
<li>
<p><strong>Notice periods</strong>: Europeans (on average) have 3 months notice period while US Americans have 2 weeks. How would a US company deal with it? On top of that, several countries have <strong>protection against unlawful termination</strong>, and how can a Slovakian employee avail that benefit against a German company?</p>
</li>
<li>
<p><strong>IP protection</strong>: It’s hard to <strong>protect IP</strong> if employees are not in the same jurisdiction. A company operation from Czechia would find it hard to settle trade disputes with a remote worker from South Africa. Another example is of <strong>TISAX compliance</strong> that is required for specialized hardware projects for Automotive industries. Remote work fails to make a dent in this situation.</p>
</li>
</ul>
<h2 id="hardware-cant-remote">Hardware can’t remote</h2>
<p>Patio11’s law<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> states that the <strong>economy is much bigger than you think</strong>. There are companies which have widely different business models and they often have a hardware related product. My <a href="https://www.salonlab-server.de/en-GB/">current project</a> is an IoT device that talks to an iPad app. The <strong>hardware team</strong> needs <strong>specialized tools</strong> to work on the IoT device, and these tools can’t be moved to home office. Remote work is a strict no-no for such products.</p>
<h2 id="swim-against-the-tide">Swim against the tide</h2>
<p>The biggest hurdle employees face in remote/home offices is <strong>lack of focus and direction</strong>. Humans have evolved over thousands of years to collaborate based on interpersonal cues, and a video call simply does not have the same effect. Humans need <strong>feedback</strong> and <strong>constructive communication</strong> whereas isolation kills the spirit. People who are new to remote work often feel <strong>rudderless</strong> because <strong>self discipline is hard</strong> when there’s no structure. I’m doing remote work on-and-off since 2018, and it took me a lot of discipline to get productive. The simple fact is that remote work is not natural, and not suited for all work streams in a typical company. Add to it the fact that many <strong>families</strong> simply don’t have space to work from home, and on top of that there might be kids around.</p>
<p>Remote work might be one of the few positive outcomes of the COVID-19 crisis but unless we tend to it carefully, we’ll end up creating a unhappy and unproductive workspace.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300">https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html">https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201">https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever">https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://secondbreakfast.co/patio11-s-law">https://secondbreakfast.co/patio11-s-law</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://samkhawase.com/blog/remote-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034037</guid>
            <pubDate>Mon, 09 Nov 2020 12:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free Typography Logo Maker]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25034017">thread link</a>) | @hosshams
<br/>
November 9, 2020 | https://formito.com/tools/logo | <a href="https://web.archive.org/web/*/https://formito.com/tools/logo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://formito.com/tools/logo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034017</guid>
            <pubDate>Mon, 09 Nov 2020 12:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD Router Guide]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25033925">thread link</a>) | @upofadown
<br/>
November 9, 2020 | https://www.unixsheikh.com/tutorials/openbsd-router-guide/ | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/tutorials/openbsd-router-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<table>
    <tbody><tr>
        <td><img src="https://www.unixsheikh.com/includes/img/openbsd-icon.png" alt="OpenBSD icon"></td>
        <td>
            
            <h4>Network segmenting firewall, DHCP, DNS with Unbound, domain blocking and much more<br>
                <span>OpenBSD: 6.8 · Published: 2020-11-05 · Updated: 2020-11-12 · Version: 1.4.1</span>
            </h4>
        </td>
    </tr>
</tbody></table>

<h2>Introduction</h2>

<div><p>In this guide we're going to take a look at how we can use cheap and "low end" hardware to build an amazing OpenBSD router with firewalling capabilities, segmented local area networks, DNS with domain blocking, DHCP and more.</p><p>We will use a setup in which the router segments the local area network (LAN) into three separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. We will also look at how we can use DNS to block out ads, porn, and other websites on the Internet. The OpenBSD router can also be used on small to mid-size offices.</p></div>

<p>Table of contents</p>
<ul>
    <li><a href="#why-a-firewall">Why a firewall?</a></li>
    <li><a href="#the-hardware">The hardware</a></li>
    <li><a href="#why-openbsd">Why OpenBSD?</a></li>
    <li><a href="#the-network">The network</a>
    <ul>
        <li><a href="#setting-up-the-network">Setting up the network</a></li>
    </ul>
    </li>
    <li><a href="#dhcp">DHCP</a></li>
    <li><a href="#a-packet-filtering-firewall">PF - A packet filtering firewall</a>
    <ul>
        <li><a href="#pf-setup">PF setup</a></li>
        <li><a href="#clarifications">Clarifications</a></li>
        <li><a href="#pf-domain-name-resolution">Domain name or hostname resolution</a></li>
        <li><a href="#the-ruleset">The ruleset</a>
            <ul>
                <li><a href="#whitelist">The children's whitelist</a>
                    <ul>
                        <li><a href="#persistent-table">Using a persistent table</a></li>
                    </ul>
                </li>
            </ul>
        </li>
        <li><a href="#loading-ruleset">Loading the rules</a></li>
        <li><a href="#logging">Logging and monitoring</a></li>
    </ul>
    </li>
    <li><a href="#domain-name-service">DNS</a>
    <ul>
        <li><a href="#unbound">I present to you, Unbound</a></li>
        <li><a href="#blocking-with-dns">Blocking with DNS</a>
            <ul>
                <li><a href="#nxdomain">NXDOMAIN vs redirecting</a></li>
            </ul>
        </li>
        <li><a href="#doh">The problem with DNS over HTTPS (DoH)</a></li>
        <li><a href="#unbound-setup">Setting up Unbound</a>
            <ul>
                <li><a href="#basic-settings">Basic settings</a></li>
                <li><a href="#lets-block-some-domains">Let's block some domains!</a></li>
            </ul>
        </li>
        <li><a href="#dns-security">DNS security</a>
            <ul>
                <li><a href="#dns-hijacking">DNS hijacking</a>
                    <ul>
                        <li><a href="#dns-hijacking-prevention">DNS hijacking prevention</a></li>
                    </ul>
                </li>
                <li><a href="#dns-spoofing">DNS spoofing</a>
                    <ul>
                        <li><a href="#dns-spoofing-prevention">DNS spoofing prevention</a></li>
                    </ul>
                </li>
            </ul>
        </li>
    </ul>
    </li>
    <li><a href="#appendix">Appendix</a>
        <ul>
            <li><a href="#inspecting-doh">Inspecting DNS over HTTPS (DoH)</a></li>
            <li><a href="#blocking-doh">Blocking DNS over HTTPS (DoH)</a></li>
            <li><a href="#dhcp-domain">Adding the domain-name option to DHCP and using a FQDM</a></li>
            <li><a href="#recommended-reading">Recommended reading</a></li>
            <li><a href="#how-to-contribute">How to contribute to the guide?</a></li>
            <li><a href="#todo">TODO</a></li>
        </ul>
    </li>
</ul>

<h2 id="why-a-firewall">Why a firewall?</h2>
<p>Almost no matter how you connect to the Internet from your home or office, you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>Very rarely do consumer-grade modems or routers get firmware updates and they are often vulnerable to <a href="https://en.wikipedia.org/wiki/Home_router#Security">network attacks</a> that turns these devices into <a href="https://en.wikipedia.org/wiki/Botnet">botnets</a>, such like the <a href="https://en.wikipedia.org/wiki/Mirai_(malware)">Mirai malware</a>. Many consumer-grade modems and routers is to blame for some of the largest <a href="https://en.wikipedia.org/wiki/Distributed_denial_of_service_attack">distributed denial of service (DDoS) attacks</a>.</p>
<p>A firewall between you and your ISP modem or router cannot protect your modem or router device against attacks, but it can protect your computers and devices on the inside of the network, and it can help you monitor and control the traffic that comes and goes to and from your local network.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>It is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an very solid solution.</p>

<p><b>NOTE:</b><br>Currently this guide only deals with IPv4 as most people still don't use IPv6 and many ISPs also still only use IPv4, but IPv6 is planned for a future update of the guide.</p>

<h2 id="the-hardware">The hardware</h2>
<p>You don't have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and "low end" hardware you can get a very solid solution.</p>
<p>I have build multiple solutions with the <a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a> motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://www.unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I'll admit, it's a pretty "crappy" motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working "overtime" and the CPU hardly breaks a sweat.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunately the ASRock Q1900DC-ITX motherboard is no longer made, but I'm just using it as an example, I have used several other cheap boards as well.</p>
<p><b>NOTE:</b><br>Most of the current ASRock J-series can be used. Search for any J-series board on Amazon and a list will show up on recent hardware. Such as <a href="https://www.amazon.com/ASRock-Motherboard-Mini-DDR3-Q1900B-ITX/">ASRock Q1900B-ITX</a>, <a href="https://www.amazon.com/ASRock-J5005-ITX-Quad-Core-Processor-Motherboards/">ASRock J5005-ITX</a> and <a href="https://www.amazon.com/ASRock-Motherboard-CPU-Combo-J3355M/">ASRock J3335M</a> (These are not affiliate links!). Many other low power brands from other motherboard producers can be uses as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn't come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://www.unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performs very well and they save quite a bit of power contrary to running with a normal power supply.</p>
<p>Last, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://www.unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years - at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware <a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a>, such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don't take up much space. I don't recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can't handle the amount of traffic, but your mileage may vary.</p>
<p>You might also need a couple of cheap gigabit switches for the segmented local network, at least if you have more than one computer you want to connect to the same LAN :)</p>

<h2 id="why-openbsd">Why OpenBSD?</h2>
<p>In truth, you can get a similar setup with one of the other <a href="https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems">BSD flavors</a> or one of the many different <a href="https://en.wikipedia.org/wiki/Linux_distribution">Linux distribution</a>, but <a href="https://www.openbsd.org/">OpenBSD</a> is specifically very well suited and designed for this kind of task. Not only does it come with all the needed software in the base install, but it also has significantly better security and tons of improved mitigations already build-in into the operating system. I <a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html">highly recommend</a> OpenBSD over any other operating system for this kind of task.</p>
<p>This guide is not going to show you how to install OpenBSD. If you haven't done that before I recommend you spin up some kind of virtual machine or see if you have some unused and supported hardware laying around you can play with. OpenBSD is one of the easiest and quickest operating systems to install. Don't be afraid of the non-gui approach, once you have tried it you will really appreciate the simplicity. Use the default settings when in doubt.</p>
<p>Before you endeavor on this journey make sure to reference the OpenBSD documentation! Not only is everything very well documented, but you will most likely find all the answers you need right there. Read the <a href="https://www.openbsd.org/faq/index.html">OpenBSD FAQ</a> and take a look at the different <a href="https://man.openbsd.org/">manual pages</a> for the software we're going to use.</p>
<p>Another really useful place to find general information about OpenBSD is the <a href="https://marc.info/?l=openbsd-misc">OpenBSD mailing list archives</a>. Also make sure to stay up to date with relevant information by subscribing to the <a href="https://www.openbsd.org/mail.html">Announcements and security advisories</a> mailing list.</p>
<p>Last, but not least, please consider <a href="https://www.openbsd.org/donations.html">supporting OpenBSD</a>! Even if you don't use OpenBSD on a daily basis, but perhaps make use of <a href="https://www.openssh.com/">OpenSSH</a> on Linux, then you're really using software from the OpenBSD project. Consider making a small, but steady donation to support the further development of all the great software the OpenBSD developers make!</p>

<h2 id="the-network">The network</h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn't run out into the wild on the Internet, and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>NOTE:</b><br>A router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems, while a router joins similar networks. An example of a gateway would be a device that joins a PC network with a telecommunications network.</p>
<p>In this tutorial we're building a router and we have 4 networks of the same type to work with. One is the Internet and the other three are the internally segmented local area networks (LANs). Some people prefer to work with virtual LANs, but in this tutorial we're going to use the quad port NIC from the illustration above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don't have to segment the network into several parts if you don't need that, and it will be very easy to change the settings from this guide, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children requires only very limited access, but it is doable with some work, and the guide is going to show you one way you can do that.</p>
<p>This is an illustration of the network we're going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
  …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unixsheikh.com/tutorials/openbsd-router-guide/">https://www.unixsheikh.com/tutorials/openbsd-router-guide/</a></em></p>]]>
            </description>
            <link>https://www.unixsheikh.com/tutorials/openbsd-router-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033925</guid>
            <pubDate>Mon, 09 Nov 2020 12:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer and BioNTech Announce Vaccine Candidate Against Covid-19 Achieved Success]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033852">thread link</a>) | @doener
<br/>
November 9, 2020 | https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1 | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">

  <div>
                <ul type="disc"><li><em>Vaccine candidate was found to be more than 90% effective in preventing COVID-19 in participants without evidence of prior SARS-CoV-2 infection in the first interim efficacy analysis</em></li><li><em>Analysis evaluated</em><em> 94 confirmed cases of COVID-19 in trial participants </em></li><li><em>Study enrolled 43,538 participants, with 42% having diverse backgrounds, and no serious safety concerns have been observed; safety and additional efficacy data continue to be collected </em></li><li><em>Submission for Emergency Use Authorization (EUA) to the U.S. Food and Drug Administration (FDA) planned soon after the required safety milestone is achieved, which is currently expected to occur in the third week of November </em></li><li><em>Clinical trial to continue through to final analysis at 164 confirmed cases in order to collect further data and characterize the vaccine candidate’s performance against other study endpoints</em></li></ul><p><strong>NEW YORK and MAINZ, GERMANY, November 9, 2020</strong> — <a href="https://www.globenewswire.com/Tracker?data=PJ8PG63hVRh2bkt5smgOlFAGa-RXpa2iRwzAO6IqH_YcfyX-R7Tdk96PAniX7YGQoMAdF-jDHoeL-YX46MLSDw==" rel="nofollow" target="_blank"><u>Pfizer Inc.</u></a> (NYSE: PFE) and <a href="https://www.globenewswire.com/Tracker?data=XfaLG8yfG5HYcb1T5NR2xBQd-D3R4PCcCCpFaLX9rM23piCwE-K7u65TmqKeemgOsm9Iwv7SBS6CLe_lhfQmFA==" rel="nofollow" target="_blank"><u>BioNTech SE</u></a> (Nasdaq: BNTX) today announced their mRNA-based vaccine candidate, BNT162b2, against SARS-CoV-2 has demonstrated evidence of efficacy against COVID-19 in participants without prior evidence of SARS-CoV-2 infection, based on the first interim efficacy analysis conducted on November 8, 2020 by an external, independent Data Monitoring Committee (DMC) from the Phase 3 clinical study. After discussion with the FDA, the companies recently elected to drop the 32-case interim analysis and conduct the first interim analysis at a minimum of 62 cases. Upon the conclusion of those discussions, the evaluable case count reached 94 and the DMC performed its first analysis on all cases. </p>  <p>The case split between vaccinated individuals and those who received the placebo indicates a vaccine efficacy rate above 90%, at seven days after the second dose. This means that protection is achieved 28 days after the initiation of the vaccination, which consists of a 2-dose schedule. As the study continues, the final vaccine efficacy percentage may vary. The DMC has not reported any serious safety concerns and recommends that the study continues to collect additional safety and efficacy data as planned. The data will be discussed with regulatory authorities worldwide. </p>  <p>“Today is a great day for science and humanity. The first set of results from our Phase 3 COVID-19 vaccine trial provides the initial&nbsp;evidence of our vaccine’s ability to prevent COVID-19,” said <strong>Dr. Albert Bourla, Pfizer Chairman and CEO.</strong> “We are reaching this critical milestone in our vaccine development program at a time when the world needs it most with infection rates setting new records, hospitals nearing over-capacity and economies struggling to reopen. With today’s news, we are a significant step closer to providing people around the world with a much-needed breakthrough to help bring an end to this global health crisis. We look forward to sharing additional efficacy and safety data generated from thousands of participants in the coming weeks.”</p>  <p>“I want to thank the thousands of people who volunteered to participate in the clinical trial, our academic collaborators and investigators at the study sites, and our colleagues and collaborators around the world who are dedicating their time to this crucial endeavor,” added <strong>Bourla.</strong> “We could not have come this far without the tremendous commitment of everyone involved.”</p>  <p>“The first interim analysis of our global Phase 3 study provides evidence that a vaccine may effectively prevent COVID-19. This is a victory for innovation, science and a global collaborative effort,” said <strong>Prof. Ugur Sahin, BioNTech Co-founder and CEO.</strong> “When we embarked on this journey 10 months ago this is what we aspired to achieve. Especially today, while we are all in the midst of a second wave and many of us in lockdown, we appreciate even more how important this milestone is on our path towards ending this pandemic and for all of us to regain a sense of normality. We will continue to collect further data as the trial continues to enroll for a final analysis planned when a total of 164 confirmed COVID-19 cases have accrued. I would like to thank everyone who has contributed to make this important achievement possible.”</p>  <p>The Phase 3 clinical trial of BNT162b2 began on July 27 and has enrolled 43,538 participants to date, 38,955 of whom have received a second dose of the vaccine candidate as of November 8, 2020. Approximately 42% of global participants and 30% of U.S. participants have racially and ethnically diverse backgrounds. The trial is continuing to enroll and is expected to continue through the final analysis when a total of 164 confirmed COVID-19 cases have accrued. The study also will evaluate the potential for the vaccine candidate to provide protection against COVID-19 in those who have had prior exposure to SARS-CoV-2, as well as vaccine prevention against severe COVID-19 disease. In addition to the primary efficacy endpoints evaluating confirmed COVID-19 cases accruing from seven days after the second dose, the final analysis now will include, with the approval of the FDA, new secondary endpoints evaluating efficacy based on cases accruing 14 days after the second dose as well. The companies believe that the addition of these secondary endpoints will help align data across all COVID-19 vaccine studies and allow for cross-trial learnings and comparisons between these novel vaccine platforms. The companies have posted an updated version of the study protocol at <a href="https://www.globenewswire.com/Tracker?data=bE4RvEXc3amHdJ0LinFQkPyUCRxShL94rKlQWnVIuOebbWs0t_t1F1qSmc0deSfk8TsQTmqiZHqgYUA4_HoIG8cgZ-MTBQVX5ZbQ89L9eImlSxNuQzgmZ36Fp4CVqIu8sjS4aT-HPEktSLWmEhtRsQ==" rel="nofollow" target="_blank"><u>https://www.pfizer.com/science/coronavirus</u></a>. </p>  <p>Pfizer and BioNTech are continuing to accumulate safety data and currently estimate that a median of two months of safety data following the second (and final) dose of the vaccine candidate – the amount of safety data specified by the FDA in its guidance for potential Emergency Use Authorization – will be available by the third week of November. Additionally, participants will continue to be monitored for long-term protection and safety for an additional two years after their second dose.</p>  <p>Along with the efficacy data generated from the clinical trial, Pfizer and BioNTech are working to prepare the necessary safety and manufacturing data to submit to the FDA to demonstrate the safety and quality of the vaccine product produced. Based on supply projections, we expect to supply globally up to 50 million vaccine doses in 2020 and manufacture up to 1.3 billion doses in 2021. Pfizer and BioNTech plan to submit data from the full Phase 3 trial for scientific peer-review publication.</p>  <p><strong>About Pfizer: Breakthroughs That Change Patients’ Lives</strong></p>  <p>At Pfizer, we apply science and our global resources to bring therapies to people that extend and significantly improve their lives. We strive to set the standard for quality, safety and value in the discovery, development and manufacture of health care products, including innovative medicines and vaccines. Every day, Pfizer colleagues work across developed and emerging markets to advance wellness, prevention, treatments and cures that challenge the most feared diseases of our time. Consistent with our responsibility as one of the world's premier innovative biopharmaceutical companies, we collaborate with health care providers, governments and local communities to support and expand access to reliable, affordable health care around the world. For more than 150 years, we have worked to make a difference for all who rely on us. We routinely post information that may be important to investors on our website at <u><a href="https://www.globenewswire.com/Tracker?data=4FbrwG1rPf9jwYvPniD1rUMbj6s_Wqek0iGxXtCmV7zUg7CMpYiSUA1zc-r5E0Nf_ZNaQlSWnZ5e8_mFWG8XYA==" rel="nofollow" target="_blank">www.Pfizer.com</a></u>. In addition, to learn more, please visit us on <u><a href="https://www.globenewswire.com/Tracker?data=4FbrwG1rPf9jwYvPniD1rf9AtACzzG5su0IsLCtDLy0Q4vyLC1u2a07goDfiO7HGejXmxyveSXGtjTX9Jbf1aw==" rel="nofollow" target="_blank">www.Pfizer.com</a></u> and follow us on Twitter at <a href="https://www.globenewswire.com/Tracker?data=nZQmHBaz29Df7F7-i_Dx5Ci9JAIKZm1fs38JsJ0UDRndZf2WfVJLut17r7ky8GafcpFUih6abC7JiIHrL1K6Bw==" rel="nofollow" target="_blank"><u>@Pfizer</u></a> and <a href="https://www.globenewswire.com/Tracker?data=nZQmHBaz29Df7F7-i_Dx5EIUSI0zr1bjnR6DBf-Egt2of100u8SheiSFC3c0Qbr_yoniSSHE2UwRTyWYI9JOS5L8WV3tP6hHSIv-ym0XDP0=" rel="nofollow" target="_blank"><u>@Pfizer News</u></a>, <a href="https://www.globenewswire.com/Tracker?data=UH05W4ZxYdmUeMyOlJKhJmRsqWd0fvhHaFnVv0fo-CIWUdkF6HDUEv2p868nekUmyUYROhkLqSYY41Pcuq02MsL4ZoYkXD237abwsIit60U=" rel="nofollow" target="_blank"><u>LinkedIn</u></a>, <a href="https://www.globenewswire.com/Tracker?data=ir8lky4stO2XkFLpjU_Ut0YeVDly5-CLV1tWNdWEYeM0oZHykh1Sm3s7CRgIHdfPWelsTpFq7j2P9dXmnvMVig==" rel="nofollow" target="_blank"><u>YouTube</u></a> and like us on Facebook at <a href="https://www.globenewswire.com/Tracker?data=LTOch18I9XnaHE4qzjVzrNxzuXYwnNH0v4XrrVbCqgnXUaKX5nOdqwvgTZru4193lMFjeY16tudZKniE9EdlpQSPhDWRORO-8flQBehdsh8=" rel="nofollow" target="_blank"><u>Facebook.com/Pfizer</u></a>.</p>  <p><strong>Pfizer Disclosure Notice</strong></p>  <p>The information contained in this release is as of November 9, 2020. Pfizer assumes no obligation to update forward-looking statements contained in this release as the result of new information or future events or developments.</p>  <p>This release contains forward-looking information about Pfizer’s efforts to combat COVID-19, the collaboration between BioNTech and Pfizer to develop a potential COVID-19 vaccine, the BNT162 mRNA vaccine program, and modRNA candidate BNT162b2 (including qualitative assessments of available data, potential benefits, expectations for clinical trials, anticipated timing of clinical trial readouts and regulatory submissions and anticipated manufacturing, distribution and supply), that involves substantial risks and uncertainties that could cause actual results to differ materially from those expressed or implied by such statements. Risks and uncertainties include, among other things, the uncertainties inherent in research and development, including the ability to meet anticipated clinical endpoints, commencement and/or completion dates for clinical trials, regulatory submission dates, regulatory approval dates and/or launch dates, as well as risks associated with preliminary and interim data, (including the Phase 3 interim data that is the subject of this release), including the possibility of unfavorable new preclinical or clinical trial data and further analyses of existing preclinical or clinical trial data; the risk that clinical trial data are subject to differing interpretations and assessments, including during the peer review/publication process, in the scientific community generally, and by regulatory authorities; whether and when data from the BNT162 mRNA vaccine program will be published in scientific journal publications and, if so, when and with what modifications; whether regulatory authorities will be satisfied with the design of and results from these and future preclinical and clinical studies; whether and when any biologics license and/or emergency use authorization applications may be filed in any jurisdictions for BNT162b2 or any other potential vaccine candidates; whether and when any such applications may be approved by regulatory authorities, which will depend on myriad factors, including making …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1">https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1</a></em></p>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033852</guid>
            <pubDate>Mon, 09 Nov 2020 11:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Knowledge Is The Real Wealth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033771">thread link</a>) | @ozres1
<br/>
November 9, 2020 | https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/ | <a href="https://web.archive.org/web/*/https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr><p>The real source of wealth is not money. Money is abundant and plentiful. Fiat can be printed at will. It’s a means to an end.</p><p>Knowledge that advances civilization on the other hand is <em>scarce</em>. Great thinkers like Newton enable progress.</p><p>Consider for a moment what $1 million would have bought you 500 years ago… 100 years ago… today…</p><p>and 100 years into the future.</p><p>Being a John Rockefeller 100 years ago wouldn’t have gotten you an iPhone no matter how much money you spent.</p><p>The problem isn’t one of having enough money to organize labour and resources.</p><p><strong>The bigger problem is in <em>knowing</em> what to do. </strong></p><p>This has been the real bottleneck in unleashing human potential. Until now.</p><p><a href="https://giphy.com/gifs/5VKbvrjxpVJCM" target="_blank" rel="noopener">via GIPHY</a></p><p>AI and the advancement of thinking tools to assist in research, development and general decision making will greatly alleviate this strain and enable greater productivity.</p><div><div><div><figure><img data-attachment-id="1647" data-permalink="https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/naval-ravikant/" data-orig-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-orig-size="250,250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="naval-ravikant" data-image-description="" data-medium-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-large-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" width="250" height="250" src="https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-spai-eager="1" alt="" srcset="https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg 250w, https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant-150x150.jpg 150w, https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant-80x80.jpg 80w" loading="lazy" sizes="(max-width: 250px) 100vw, 250px" data-old-src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjUwIDI1MCIgd2lkdGg9IjI1MCIgaGVpZ2h0PSIyNTAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZydWl6aGlkb25nLmNvbSUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjExJTJGbmF2YWwtcmF2aWthbnQuanBnIiBkYXRhLXc9IjI1MCIgZGF0YS1oPSIyNTAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-lazy-src="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg?is-pending-load=1"><figcaption>Naval Ravikant</figcaption></figure></div><blockquote><p>Society, business, &amp; money are downstream of technology, which is itself downstream of science. Science applied is the engine of humanity. <br></p><p>Corollary: Applied Scientists are the most powerful people in the world. This will be more obvious in the coming years.</p><cite>— Naval Ravikant</cite></blockquote><hr></div></div><hr><h3>An example using an isolated island</h3><figure><p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/9EdnEOWA9w4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p></figure>
</div></div>]]>
            </description>
            <link>https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033771</guid>
            <pubDate>Mon, 09 Nov 2020 11:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract full news article content from any RSS feed using Extract API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033704">thread link</a>) | @imshashank
<br/>
November 9, 2020 | https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/ | <a href="https://web.archive.org/web/*/https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div itemprop="articleBody"><p>Learn how to extract all fields from any RSS feed or given a list of URLs. For this example, we will be using Medium’s RSS feed. The code will be in python but can easily be adapted for other languages.</p><p>Lets start by importing the packages. We will be using “feedparser” to extract Medium Rss feed.</p><pre><code lang="bash">pip install feedparser
pip install requests</code></pre><p>Let’s begin by first extracting links from the RSS feed. For this example, we will be extracting the articles from “Towards Data Science”. “Towards Data Science” is one of the leading blogs when it comes to Data Science, Machine Learning &amp; Artificial Intelligence.</p><pre><code lang="python">import feedparser

NewsFeed = feedparser.parse("https://towardsdatascience.com/feed")
print("Total entries found in feed: "+ str(len(NewsFeed.entries)) +"\n")
i =0
for entry in NewsFeed.entries:
print(str(i) + ": Got url: " + entry.link)
i = i +1</code></pre><p>We are able to extract the links, now we want to extract the entire content, summary, metadata and other details for each news article in the feed.</p><p>To extract we will be using Pipfeed’s extract API: <a href="https://promptapi.com/marketplace/description/pipfeed-api" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">https://promptapi.com/marketplace/description/pipfeed-api</a> You can get a free API key from prompt API.</p><pre><code lang="python">import requests

url = "https://api.promptapi.com/pipfeed"

payload = "https://towardsdatascience.com/topic-model-evaluation-3c43e2308526"
headers= {
  "apikey": "YOUR_API_KEY"
}

response = requests.request("POST", url, headers=headers, data = payload)

status_code = response.status_code
result = response.text
print(result)</code></pre><p>The above code will extract the given URL and return all the fields. Below is the response we get for the above code. DO NOT forget to replace the API key with your own API keys generated from prompt API.</p><p>“Summary” &amp; “predictedCategories” are generated using Pipfeed’s AI models. Rest of the fields are extracted from the article HTML itself.</p><pre><code lang="json">{
"publishedAt": "2020-11-09T05:15:23.001Z",
"title": "Topic Model Evaluation",
"authors": [
"Giri Rabindranath"
],
"description": "Evaluation is the key to understanding topic models - This article explains what topic model evaluation is, why it's important and how to do it",
"language": "en",
"url": "https://towardsdatascience.com/topic-model-evaluation-3c43e2308526",
"mainImage": "https://miro.medium.com/max/1200/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"category": "machine-learning",
"categories": null,
"predictedCategories": [
"machine-learning",
"data-science",
"programming"
],
"tags": [],
"keywords": [
"coherence",
"evaluation",
"human",
"model",
"models",
"topic",
"topics",
"way",
"word",
"words"
],
"summary": "In this article, we\u2019ll look at topic model evaluation, what it is and how to do it.\nWhat is topic model evaluation?\nTopic model evaluation is the process of assessing how well a topic model does what it is designed for.\nThis is why topic model evaluation matters.\nHow to evaluate topic models \u2014 RecapThis article has hopefully made one thing clear \u2014 topic model evaluation isn\u2019t easy!",
"images": [
"https://miro.medium.com/fit/c/140/140/1*74Yrxu8s4sOtTECtixv9Fg.jpeg",
"https://miro.medium.com/max/60/1*<a href="https://pipfeed.com/cdn-cgi/l/email-protection" data-cfemail="6b233d3b223125583e01251c212e5c31280e110f333f2a2b591345011b0e0c">[email&nbsp;protected]</a>?q=20",
"https://miro.medium.com/fit/c/140/140/0*l_zfjU9IKMa47tfy",
"https://miro.medium.com/fit/c/56/56/2*b2y5uCYazQ9FgiUQEUHT6Q.jpeg",
"https://miro.medium.com/max/60/1*mpyrgqwMjfclV2oN1U2VIA.jpeg?q=20",
"https://miro.medium.com/max/698/1*E4oPMmq5jTKuStZJuyDGpw.jpeg",
"https://miro.medium.com/max/12032/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"https://miro.medium.com/max/60/1*_MXaw5BKgIsm8J3dOUNHMg.jpeg?q=20",
"https://miro.medium.com/max/224/1*AGyTPCaRzVqL77kFwUwHKg.png",
"https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png",
"https://miro.medium.com/max/60/1*E4oPMmq5jTKuStZJuyDGpw.jpeg?q=20",
"https://miro.medium.com/max/1200/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"https://miro.medium.com/max/60/0*aP8H1qpRN_OR1x5r?q=20",
"https://miro.medium.com/max/60/0*NIpOoYo9iHt4lMbg?q=20",
"https://miro.medium.com/max/60/0*l_zfjU9IKMa47tfy?q=20",
"https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png",
"https://miro.medium.com/max/784/1*_MXaw5BKgIsm8J3dOUNHMg.jpeg",
"https://miro.medium.com/fit/c/140/140/1*FTG-junI6KJzojC_xRVNXg.png",
"https://miro.medium.com/max/60/0*fG5RLd48iOZezB_y.jpeg?q=20",
"https://miro.medium.com/fit/c/140/140/0*NIpOoYo9iHt4lMbg",
"https://miro.medium.com/fit/c/140/140/1*<a href="https://pipfeed.com/cdn-cgi/l/email-protection" data-cfemail="c1899791889b8ff294ab8fb68b84f69b82a4bba599958081f3b9efabb1a4a6">[email&nbsp;protected]</a>",
"https://miro.medium.com/max/60/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg?q=20",
"https://miro.medium.com/fit/c/140/140/1*mpyrgqwMjfclV2oN1U2VIA.jpeg",
"https://miro.medium.com/fit/c/140/140/0*fG5RLd48iOZezB_y.jpeg",
"https://miro.medium.com/fit/c/140/140/0*aP8H1qpRN_OR1x5r",
"https://miro.medium.com/max/60/1*74Yrxu8s4sOtTECtixv9Fg.jpeg?q=20",
"https://miro.medium.com/max/60/1*FTG-junI6KJzojC_xRVNXg.png?q=20"
],
"blogName": null,
"blogLogoUrl": null,
"html": "&lt;div class=\"page\" id=\"readability-page-1\"&gt;&lt;section&gt;&lt;div&gt;&lt;div&gt;&lt;h2 id=\"ef6b\"&gt;DATA SCIENCE EXPLAINED&lt;/h2&gt;&lt;h2 id=\"e375\"&gt;Here\u2019s what you need to know about evaluating topic models&lt;/h2&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;a rel=\"noopener\" href=\"https://medium.com/@g_rabi?source=post_page-----3c43e2308526--------------------------------\"&gt;&lt;div&gt;&lt;p&gt;&lt;img height=\"28\" width=\"28\" src=\"https://miro.medium.com/fit/c/56/56/2*b2y5uCYazQ9FgiUQEUHT6Q.jpeg\" alt=\"Giri Rabindranath\"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;p id=\"8bff\"&gt;&lt;em&gt;Topic models are widely used for analyzing unstructured text data, but they provide no guidance on the quality of topics produced. Evaluation is the key to understanding topic models. In this article, we\u2019ll look at what topic model evaluation is, why it\u2019s important and how to do it.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section&gt;&lt;div&gt;&lt;div&gt;&lt;h2 id=\"324c\"&gt;Contents&lt;/h2&gt;&lt;ul&gt;&lt;li id=\"dd12\"&gt;&lt;a rel=\"noopener\" href=\"#f0ce\"&gt;&lt;em&gt;What is topic model evaluation&lt;/em&gt;&lt;/a&gt;?&lt;/li&gt;&lt;li id=\"ceba\"&gt;&lt;a rel=\"noopener\" href=\"#d1ae\"&gt;&lt;em&gt;How to evaluate topic models&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"ea5d\"&gt;&lt;a rel=\"noopener\" href=\"#2932\"&gt;&lt;em&gt;Evaluating topic models \u2014 Human judgment&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"6275\"&gt;&lt;a rel=\"noopener\" href=\"#9b50\"&gt;&lt;em&gt;Evaluating topic models \u2014 Quantitative metrics&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"ea38\"&gt;&lt;a rel=\"noopener\" href=\"#19ff\"&gt;&lt;em&gt;Calculating coherence using Gensim in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"95a3\"&gt;&lt;a rel=\"noopener\" href=\"#1756\"&gt;&lt;em&gt;Limitations of coherence&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"251a\"&gt;&lt;a rel=\"noopener\" href=\"#63c4\"&gt;&lt;em&gt;How to evaluate topic models \u2014 Recap&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"e448\"&gt;&lt;a rel=\"noopener\" href=\"#31aa\"&gt;&lt;em&gt;Conclusion&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p id=\"6f84\"&gt;Topic modeling is a branch of &lt;a rel=\"noopener nofollow\" href=\"https://highdemandskills.com/natural-language-processing-explained-simply/\"&gt;natural language processing&lt;/a&gt; that\u2019s used for exploring text data. It works by identifying key themes \u2014 or topics \u2014 based on the words or phrases in the data that have a similar meaning. Its versatility and ease-of-use have led to a variety of applications.&lt;/p&gt;&lt;p id=\"3772\"&gt;Be&lt;span id=\"rmm\"&gt;i&lt;/span&gt;ng a form of unsupervised learning, topic modeling is useful when annotated or labeled data isn\u2019t available. This is helpful, as the majority of emerging text data isn\u2019t labeled, and labeling is time-consuming and expensive to do.&lt;/p&gt;&lt;p id=\"030c\"&gt;For an easy-to-follow, intuitive explanation of topic modeling and its applications, see &lt;a rel=\"noopener nofollow\" href=\"https://highdemandskills.com/topic-modeling-intuitive/\"&gt;this article&lt;/a&gt;.&lt;/p&gt;&lt;p id=\"fb4a\"&gt;One of the shortcomings of topic modeling is that there\u2019s no guidance about the quality of topics produced. If you want to learn about how meaningful the topics are, you\u2019ll need to evaluate the topic model.&lt;/p&gt;&lt;p id=\"b937\"&gt;In this article, we\u2019ll look at topic model evaluation, what it is and how to do it. It\u2019s an important part of the topic modeling process that sometimes gets overlooked. For a topic model to be truly useful, some sort of evaluation is needed to understand how relevant the topics are for the purpose of the model.&lt;/p&gt;&lt;p id=\"b85d\"&gt;Topic model evaluation is the process of assessing how well a topic model does what it is designed for.&lt;/p&gt;&lt;p id=\"44ee\"&gt;When you run a topic model, you usually do it with a specific purpose in mind. It may be for document classification, to explore a set of unstructured texts, or some other analysis. As with any model, if you wish to know how effective it is at doing what it\u2019s designed for, you\u2019ll need to evaluate it. This is why topic model evaluation matters.&lt;/p&gt;&lt;p id=\"e9c9\"&gt;Evaluating a topic model can help you decide if the model has captured the internal structure of a corpus (a collection of text documents). This can be particularly useful in tasks like e-discovery, where the effectiveness of a topic model can have implications for legal proceedings or other important matters.&lt;/p&gt;&lt;p id=\"a51a\"&gt;More generally, topic model evaluation can help you answer questions like:&lt;/p&gt;&lt;ul&gt;&lt;li id=\"b7ef\"&gt;Are the identified topics understandable?&lt;/li&gt;&lt;li id=\"1d2d\"&gt;Are the topics coherent?&lt;/li&gt;&lt;li id=\"325e\"&gt;Does the topic model serve the purpose it is being used for?&lt;/li&gt;&lt;/ul&gt;&lt;p id=\"da03\"&gt;Without some form of evaluation, you won\u2019t know how well your topic model is performing or if it\u2019s being used properly.&lt;/p&gt;&lt;p id=\"c559\"&gt;Evaluating a topic model isn\u2019t always easy, however.&lt;/p&gt;&lt;p id=\"3adc\"&gt;If a topic model is used for a measurable task, such as classification, then its effectiveness is relatively straightforward to calculate (eg. measure the proportion of successful classifications). But if the model is used for a more qualitative task, such as exploring the semantic themes in an unstructured corpus, then evaluation is more difficult.&lt;/p&gt;&lt;p id=\"ff58\"&gt;In this article, we\u2019ll focus on evaluating topic models that do not have clearly measurable outcomes. These include topic models used for document exploration, content recommendation and e-discovery, amongst other use cases.&lt;/p&gt;&lt;p id=\"dc38\"&gt;E…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/">https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/</a></em></p>]]>
            </description>
            <link>https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033704</guid>
            <pubDate>Mon, 09 Nov 2020 11:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Values / Guiding Principles from Ethics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033563">thread link</a>) | @hunglee2
<br/>
November 9, 2020 | https://lowercaseopinions.com/useful-values | <a href="https://web.archive.org/web/*/https://lowercaseopinions.com/useful-values">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>What we value is foundational to how we approach our lives, how we prioritise our time, and how we interact with one another. In society, in companies, in communities like families and friendship groups.</p>

<p>Our values already exist: in every group, there’s a set of shared or overlapping values. Perhaps you value being demonstratively affectionate to one another: your group chat is likely kind words, animal gifs, wishing each other luck and good vibes on stressful days, or arranging karaoke dates so you can sweetly serenade one another. Maybe you value learning, and that manifests through book recommendations, DMing each other links to thought-provoking articles, attending salons and watching documentaries together.</p>

<p>Often these values shift as the group changes, and as you change the group that you’re in. I find myself leaning harder into some of my values with a particular group of friends, and a different set with my family or my coworkers.</p>

<p>In companies, it’s fundamental that we’re able to talk coherently about what we value, especially if we want to preserve some of this sense of belonging as we scale. Culture is the manifestation of values, it’s the glue that binds us; to reinforce and steer this, we need to have a clear, shared understanding of what’s important to us all in how we work together.</p>

<p>A company’s mission, or a team’s mission, establishes what problem space is addressed; values and culture become the <em>how</em> underlying the business strategy to achieve the company’s mission.</p>

<p>I think it’s really interesting to observe the language that we use when talking about company values. People refer to “the right behaviours” or being a “good” employee. We’ve borrowed the language of ethics - and I don’t think this is a coincidence at all.</p>

<p>In fact, there are three frameworks in ethics that have striking parallels to how we set out what’s good or right in a company or business. One of these lends itself exceptionally well to framing company values.</p>



<p>Before we dive into my weird Good-Place-esque rundown of metaethics as applied to companies, I want to explore a little bit what makes a good set of values.</p>

<p>There’s a trope that every startup should have five pithy values that can be neatly painted onto the wall (and then a couple of pages explaining what each of them actually means!). And that is often the endpoint - something polished by a copywriter that gets thrown onto t-shirts or notebooks or painted on a wall back when a physical office felt important.</p>

<p>But often we miss a step. We get the polished pithy phrases, but don’t draw them from the right place. This process of understanding and surfacing what your team values has to be <em>descriptive</em>. It’s a weird, difficult, fun, generative, iterative journey of discovery. You’ll find the intrinsic qualities that you deem valuable in the people you all want to work with (smart, considerate), and the extrinsic qualities that you value in how you interact with one another (straightforward, open to early feedback).</p>

<p>This discovery process is so important to building a healthy and meaningful company culture. Values are so, so important - they’re what the culture is built on, they’re what bring us joy and meaning every day. But we dismiss them because so often they do end up just being a set of catchy but empty phrases painted on a wall.</p>

<p>I have two examples of pithy phrases masquerading as values which just aren’t useful:</p>

<p><em>Get shit done.</em>
This one baffles me because it provides no direction. What shit should I be getting done? What’s the best way to get it done? At what point is my shit done enough? Especially in the context of a company, where I get paid to do a job - my side of the employment contract is about getting shit done! You can tell me to value doing shit as much as you like, but this adds zero value when you consider that, contractually, as soon as I stop getting shit done, you’ll stop paying me!</p>

<p><em>Don’t be evil.</em>
I have a bunch of issues with this as a thing to value. Firstly, how are we defining evil? Secondly, can I do evil without being evil? What if it’s unintentional? Thirdly, is not being evil enough, or should I strive to be good? And if so, what is good? I used to say “be good, have fun” when I dropped my kid off at school in the mornings, but I’ve switched to “have fun, learn something” because it feels more directionally useful. I think “be good” sometimes reads as “don’t get told off”, and I’ve definitely been told off for doing what was right.</p>

<p>Honestly compared to these, if you’re going to paint something on your wall, I’d actually favour “live, laugh, love”. It’s more like a useful value statement than either of these - it’s clear that love and laughter are states to optimise for, which can at least guide the behaviours we choose. Tell me to “live, laugh, love” and my constraints are tighter than “don’t be evil”. Plus there’s already a bunch of wall decals on etsy!</p>



<p>Our values affect how we go about achieving things and interacting with others. They capture the quirks, traits and essences of the things that make your company and your community who they are.  For me, useful values have two properties: they are opinionated, and they guide behaviour.</p>

<p>The things that <em>you in particular</em> value have to take a perspective and a point of view. And it needs to be a meaningful point of view - where you can envisage a world where many very reasonable people take a conflicting point of view.</p>

<p>You know you have pinpointed genuinely useful values if you can use them to make decisions about what you do and how you do it. Particularly in high stress or difficult situations: for instance, how you approach interpersonal conflict or even conflicting priorities.</p>

<p>Both “don’t be evil” and “get shit done” fail on both counts - I can’t imagine anyone pasting the opposite on an office wall, and I can’t imagine solving a problem by using either. They are about as generic as you can be. Likewise “integrity” is not especially meaningful as a value; what would it mean to be a reasonable person who holds a value that’s contradictory to that?</p>

<p>“Move fast”, on the other hand, is absolutely meaningful. Depending on the context, you could choose to move fast; to be cautious; to take thoughtful and deliberate action; to prioritise perfection over speed. “Build to last” would take an opposing point of view, but be meaningful - as would “excellence always”. None of these three stances are objectively better than the others, which is great! Pick one and you now have a value that not only takes a perspective, but also influences how you work.</p>



<p>Our values delineate what we encourage and praise, and what is frowned upon or even punished. They set out what is right and what is wrong within the company. Values layer over the top of the ethical and moral norms of the society where you operate - like, the laws and regulatory principles and business governance.</p>

<p>When we internalise values as a sort of ethical system, it makes a lot of sense to adopt an ethics framework in order to establish how we want to think about values. Ethical <em>systems</em> concern themselves less with what specific acts are moral or immoral, and more with how we systematically determine this. So I want to focus less on what specific things we value, and more on how we frame values.</p>

<p>I’ll briefly outline three approaches to ethics from the western philosophical canon, and how the combination of the three gives us a strong framework for thinking about right and wrong in a company.</p>

<h2 id="categorical-imperatives-and-the-law">Categorical imperatives and the law</h2>

<p>One approach to ethics is through the <a href="https://plato.stanford.edu/entries/kant-moral/#CatHypImp">categorical imperative</a>: ethics should be a system of commands which are always, unconditionally, universally the correct and right way to act.</p>

<p><em>“Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.”</em> Judaism and Christianity’s Ten Commandments take the form of categorical imperatives.</p>

<p>There are no exceptions to the imperative. If, as a collective, we set out that lying is wrong, then it is not ever permissible for anyone to lie. This is super clear cut, which appeals to those who like simplicity! But humans are messy. The workplace is ambiguous, the decisions we make in our jobs are nuanced. There are a lot of behaviours that are context-dependent, or require a trade-off. So the universal commandment approach can’t capture the delightful quirks of one company over another - they are adopted by everyone.</p>

<p>But there is something useful in considering this approach. Let’s assume that there is a subset of actions which are either good or bad, based on whether everyone should do it, or everyone should not do it. In a company context, this approach is really useful in two places: the first is laws, regulation and governance. For example, it is never acceptable to commit fraud. The second is process and policies. For example, in our company, it is never acceptable to bully or harass others.</p>

<p>I referenced “don’t be evil” earlier, and for me that falls into the categorical imperative category, as does “only hire the best”. But there’s a whole layer of nuance beneath these that we need to unpick to determine what they mean within a particular company - “the best” is subjective, we characterise it through traits that we deem valuable, and those just won’t apply to everyone.</p>

<h2 id="utilitarianism-and-stakeholder-benefit">Utilitarianism and stakeholder benefit</h2>

<p><em>“It is the greatest happiness of the greatest number that is the measure of right and wrong.”</em></p>

<p>A second approach to ethics is <a href="https://plato.stanford.edu/entries/bentham/#PaiPle">utilitarianism</a> - where an act is good based entirely on its <em>consequences</em> and which way they swing happiness. In the context of a company, the clearest parallel is where a lot of what you do - the goals you set - optimise for stakeholder benefit (which includes profit and user happiness).</p>

<p>One of the difficulties with utilitarianism is that it is entirely based on consequences, intention has no role to play at all. This theory of ethics would judge someone’s actions good if …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lowercaseopinions.com/useful-values">https://lowercaseopinions.com/useful-values</a></em></p>]]>
            </description>
            <link>https://lowercaseopinions.com/useful-values</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033563</guid>
            <pubDate>Mon, 09 Nov 2020 11:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-drawn animated tram ride (web experiment)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033545">thread link</a>) | @parisianka
<br/>
November 9, 2020 | https://alexanderperrin.com.au/paper/shorttrip/ | <a href="https://web.archive.org/web/*/https://alexanderperrin.com.au/paper/shorttrip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="credits">
<div>
<p>
<strong>Short Trip - Alexander Perrin, 2017</strong>
</p>
<p>Hold left or right to move.</p>
<p>Read more about the project
<a href="http://alexanderperrin.com.au/portfolio/short-trip/" target="_blank">here.</a>
</p>
<p>Thank you to
<a href="https://twitter.com/domwillmott" target="_blank">Dom Willmott</a> for
<br>audio support.</p>
<p>If you would like to support Short Trip, you're welcome (but not obliged) to make a contribution
<a href="https://paypal.me/alexanderperrin">here.</a>
</p>
<p>Quality Mode:
<span id="default-button">Default</span>
<span id="eco-button">Eco</span>
</p>
<p>Sound:
<span id="mute-off">On</span>
<span id="mute-on">Off</span>
</p>
</div>
</div></div>]]>
            </description>
            <link>https://alexanderperrin.com.au/paper/shorttrip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033545</guid>
            <pubDate>Mon, 09 Nov 2020 11:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The power of HTTP headers and examples]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25033398">thread link</a>) | @loweisz
<br/>
November 9, 2020 | https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Almost everything in the web is sent with <strong>http</strong> and even non-developers have seen it when using the internet as keyword
inside urls or links.</p>
<p>Http stands for <strong>Hypertext Transfer Protocol</strong> and gives us the ability to transfer hypertext between a browser and a server.
This is a great technology that has been around almost since the invention of the web and is constantly evolving and
<a href="https://en.wikipedia.org/wiki/HTTP/2">offering more and more great features</a></p>

<p>As a developer you probably heard of http headers, at least in the moment you heard about the CORS policy.
This is a problem you must have heard about when developing websites.
But what exactly are http headers and what other ways are there to use them?</p>
<p>Let us first find out what they do and how you could use them. </p>
<p>When a browser requests a resource, for example a page of this blog, it asks the server with a request.
This request looks something like this: </p>
<div data-language="js"><pre><code><span>fetch</span><span>(</span><span>"https://www.lorenzweiss.de/race_conditions_explained/"</span><span>,</span> <span>{</span>
  credentials<span>:</span> <span>"include"</span><span>,</span>
  headers<span>:</span> <span>{</span>
    accept<span>:</span>
      <span>"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3"</span><span>,</span>
    <span>"accept-language"</span><span>:</span> <span>"en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7"</span><span>,</span>
    <span>"cache-control"</span><span>:</span> <span>"max-age=0"</span><span>,</span>
    <span>"sec-fetch-mode"</span><span>:</span> <span>"navigate"</span><span>,</span>
    <span>"sec-fetch-site"</span><span>:</span> <span>"same-origin"</span><span>,</span>
    <span>"sec-fetch-user"</span><span>:</span> <span>"?1"</span><span>,</span>
    <span>"upgrade-insecure-requests"</span><span>:</span> <span>"1"</span><span>,</span>
  <span>}</span><span>,</span>
  referrerPolicy<span>:</span> <span>"no-referrer-when-downgrade"</span><span>,</span>
  body<span>:</span> <span>null</span><span>,</span>
  method<span>:</span> <span>"GET"</span><span>,</span>
  mode<span>:</span> <span>"cors"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>So you can see the URL or location of the resource, some information about the request and also a lot of headers with some information about the request.
This is how your browser tells the server some more information about the request. For example what kind of data type it accepts or
how the client is handling the cache.</p>
<p>After sending the request, the server replies, and it also sets some headers in the reply, which could look like this: </p>
<div data-language="text"><pre><code>:authority: www.lorenzweiss.de
:method: GET
:path: /race_conditions_explained/
:scheme: https
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
accept-encoding: gzip, deflate, br
accept-language: en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7
cache-control: max-age=0
cookie: _ga=GA1.2.1173972759.1584812492; _gid=GA1.2.2076192721.1594044231
sec-fetch-mode: navigate
sec-fetch-site: same-origin
sec-fetch-user: ?1
upgrade-insecure-requests: 1
user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36</code></pre></div>
<p>There is also some information that the server wants to tell the browser what to do with the resource, for example
if there are cookies, it must be determined which encoding was used, etc</p>
<p>Basically, in the http-context the headers for the communication of the browser and the server are used to extend the simple
Requests for resources. You could see it as the sheet of paper that is added on top of a package that you oder from an online store,
giving you more information about the context and the resource that you ordered.
Most of the headers have quite good defaults which you don't need to think of, but there are some headers that
can get quite important, like CORS headers. But there are so much more headers that you might never heard of which are very useful
and good to know how to use. </p>

<p>Do not worry, this article will not deal with CORS headers. The following http headers are those that are rarely used, but
can be really powerful and helpful to significantly improve the communication between a server and the browser. </p>
<p>So let's dig into it. Here are some headers that you can set and that are very useful and practical.</p>
<h2 id="if-range"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/If-Range">If-Range</a><a href="#if-range" aria-label="if range permalink"></a></h2>
<h3>What and why?</h3>
<p>Imagine you start downloading a large resource, such as a video, an image, etc., and stop in between because of connection problems.
With <code>If-Range</code> you can tell the server if the representation is unchanged, to send the part(s) that are requested in Range.
Which means only the parts that were missing and not again the whole thing.</p>
<p>This can be very helpful when dealing with large resources and often bad connections as with mobile devices.
Because the resource can be downloaded in parts even if the connection is interrupted in between. </p>
<h4>How to use</h4>
<p>It can either be used with a date when the resources were last modified, or with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a>, which is a key to help if the resources was invalidated</p>
<div data-language="text"><pre><code>If-Range: &lt;day-name&gt;, &lt;day&gt; &lt;month&gt; &lt;year&gt; &lt;hour&gt;:&lt;minute&gt;:&lt;second&gt; GMT
If-Range: &lt;etag&gt;</code></pre></div>
<h4>Example</h4>
<div data-language="text"><pre><code>If-Range: Wed, 21 Oct 2015 07:28:00 GMT </code></pre></div>
<h2 id="vary"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Vary">Vary</a><a href="#vary" aria-label="vary permalink"></a></h2>
<p><code>Vary</code> Comes from a time when the web or http was used for a variety of things and not just for web pages.<br>
It is based on the idea of using http to exchange information in many different formats.
How does it do that? Well, it tells the server in which header to find the information, how to present the information. </p>
<p>Nowadays it can be really helpful if you have different resources for different customers, for example
mobile, tablet or desktop.
Imagine three different images for the same resource are stored on the server, depending on the device.
Then you can simply use the <code>Vary</code> header to tell the server to check the device and then decide which image size to send. </p>
<h4>Example</h4>
<p>For the example with the device dependent images, you can simply pass the 'user agent' to tell the server
that it should check the user-agent for device information. </p>

<h4>How to use</h4>

<p>Just enter the header, the server must check before deciding which resource to send.</p>
<h2 id="content-disposition"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Content-Disposition">Content-Disposition</a><a href="#content-disposition" aria-label="content disposition permalink"></a></h2>
<p>If we go back to the example of a request to a server, for example to load this website, it is clear to the browser,
that it must <strong>display</strong> the resource of the answer.
But it can also be the case that the server sends a resource that the browser should automatically download to the user's computer,
like a picture or pdf etc.
A server can tell the browser what the browser should do with the attached resource via the <code>Content Disposition</code> header.</p>
<h4>Example</h4>
<p>With defining the <code>Content-disposition</code> to <code>attachment</code> the browser knows that this is a resource to download instead of just
show. </p>
<div data-language="text"><pre><code>Content-Disposition: attachment; filename="data.pdf"</code></pre></div>
<h4>How to use</h4>
<p>You can define the header as <code>inline</code> or <code>attachment</code>, where `inline is always the default.  </p>
<div data-language="text"><pre><code>Content-Disposition: &lt;inline | attachment&gt;</code></pre></div>
<h2 id="feature-policy"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy">Feature-Policy</a><a href="#feature-policy" aria-label="feature policy permalink"></a></h2>
<p>This is a fairly new header and therefore only supported by modern browsers (sorry to all IE users). However
I want to mention this anyway because I think it can be really helpful for some use cases.<br>
Basically, the <code>feature-policy tells the browser which features or apis the browser should provide to the document and its</code>iframes` to be used. </p>
<p>For example, it can ban all scripts or iframes etc. within this website to allow sensitive apis like the camera or microphone.</p>
<h4>How to use</h4>
<div data-language="text"><pre><code>Feature-Policy: &lt;directive&gt; &lt;allowlist&gt;</code></pre></div>
<p>The <code>directive</code> is the name of the feature. You can see the full <a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy#Directives">list of features here</a>
The <code>allowlist</code> defines the origins which are allowed to use the directive.</p>
<h3>Example</h3>
<p>Suppose we want our website to use neither the microphone nor the camera. With this header the
document or a contained iframe cannot access these functions.</p>
<div data-language="text"><pre><code>Feature-Policy: microphone 'none'; camera 'none'</code></pre></div>
<h3>More Headers:</h3>
<p>Here are some more headers that are worth mentioning: </p>
<ul>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests">Upgrade-Insecure-Requests</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Age">Age</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Trailer">Trailer</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Location">Location</a></li>
</ul>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="conclusion permalink"></a></h2>
<p>Https headers are great and also very useful! But sometimes they can be quite complex, and it's really hard to get an overview of what headers are available and what benefits they bring.
Also when developing a website, especially in the frontend, you don't come in contact with them too often, except maybe with the CORS headers.
But I think that this missed some possibilities. http headers represent the communication between the server and the
customers much better, and we all know that communication is the key to a good relationship.</p>
<p>I hope I could shed some light on the darkness of http headers for you. In case I missed a good and helpful header,
please do not hesitate to send me a mail or contact me in any way.</p></div></div>]]>
            </description>
            <link>https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033398</guid>
            <pubDate>Mon, 09 Nov 2020 10:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Days in Desktop Web Browsers]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25033290">thread link</a>) | @svenfaw
<br/>
November 9, 2020 | https://www.radsix.com/dashboard1/ | <a href="https://web.archive.org/web/*/https://www.radsix.com/dashboard1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.radsix.com/dashboard1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033290</guid>
            <pubDate>Mon, 09 Nov 2020 10:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25033247">thread link</a>) | @TheFuntastic
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033247</guid>
            <pubDate>Mon, 09 Nov 2020 10:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Think Piece on Privacy and Big Data]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033030">thread link</a>) | @Rohitha_Perera
<br/>
November 9, 2020 | https://talk.hyvor.com/blog/privacy-and-big-data/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/privacy-and-big-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span></span>
<span>117</span>
</p>
<p>The majority of us in the present and in the immediate future <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">will face the issue of Privacy</a>. Consider this basic thought, which may sound like science fiction, but is actually quite present today: Thanks to the devices we wear now, <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">the harvesting of our biometric data</a> is a possibility. It is this thought process that led to this think piece on privacy and big data.</p>
<p>Corporations can get to know us far better than we know ourselves. They can then not just predict our feelings but also manipulate our feelings. Monitoring of our biometrics can make episodes like that of Cambridge Analytica’s data hacks prehistoric in comparison. </p>
<p>Remember that <a href="https://www.cheatsheet.com/money-career/heres-much-google-facebook-really-think-youre-worth.html/">you are worth quite a bit of money to the social channels </a>you use. The podcast detailing the <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9IY09mTE41Mg&amp;ep=14&amp;episode=MjM0YjM1OTgtZTQ1Mi00NGZhLTkzYjUtMTQxMGJjZTY1NGE4">Congressional Antitrust Investigation on Tech Monopolies: Google, Facebook, Amazon, and Apple</a> gives a serious look at how powerful these big data companies are. The scale is astronomical. Amazon captures 70% of all retails in the United States. They literally have seven times the revenue of their next largest competitor. </p>
<p>Now imagine their cloud computing capabilities. Take stock of the number of iPhones that are there. We know that what you share on social media, and the information that you surrender is a Big Data Issue; and, consider the number of search results Google controls. There’s information about you being harvested. You should know how your information is being used. </p>
<h2>Some Background</h2>
<p>We hear of how <a href="https://www.theguardian.com/us-news/2018/mar/22/steve-bannon-on-cambridge-analytica-facebook-data-is-for-sale-all-over-the-world">Steve Bannon used Facebook</a> to change politics and change culture. Facebook data, algorithms and narratives were his key weapons. These tools were used by the <a href="https://www.reuters.com/article/us-facebook-cambridge-analytica-kogan-idUSKBN1GX2F6">Cambridge Analytica team to identify the dark triad</a> — Narcissism, Machiavellianism and Psychopathy — in people. We now know about the Russian interference in American politics. We know how data had been manipulated to channel the latent proclivities of racism and anti-Semitism within America to divide it. </p>
<p>The same podcast makes mention of a great knowledge-infused book, which is Shoshana Zuboff’s <a href="https://youtu.be/QL4bz3QXWEo">The Age of Surveillance Capitalism</a>. In this book, Zuboff details the rise of a new form of power which will forever change our lives. By collecting behavioral data from their users, corporations have amassed an incomprehensibly large and detailed picture of our personal lives. They use this data to expand their corporate power and profitability. This, of course, has tremendous consequences for our privacy, but also for our political system.</p>
<figure><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" alt="" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Surveillance Capitalism talks of <a href="https://www.simplypsychology.org/big-five-personality.html">The Five Factor Personality Test</a>, which helps companies like Facebook infer our political proclivities and sexuality. This is based on the predictive signals based on the punctuation we use on a Facebook status. </figcaption></figure>
<p>Surveillance Capitalism is where it universally claims our private human experience as their free source of raw material. They take the rich predictive signals in our behavior and convert it into data. We hear of <a href="https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/#:~:text=Leaked%202017%20document%20reveals%20FB,exploit%20teens'%20words%2C%20images.&amp;text=Facebook's%20secretive%20advertising%20practices%20became,of%20the%20company's%20Australian%20office.">Facebook executives who promote&nbsp;advertising campaigns that exploit Facebook users’ emotional states</a>. Facebook’s algorithms can determine, and&nbsp;allow&nbsp;advertisers to pinpoint, “moments when young people need a confidence boost.”&nbsp;97% of Facebook’s revenue comes from its online targeted advertising markets. These are wholly-owned and operated in this surveillance capitalist economic logic. </p>
<p>Readers of Cathy O’Neil’s Weapons of Math Destruction will be compelled to believe the potential dangers of big data. O’Neil, a mathematician, analyses how the use of big data and algorithms in a variety of fields. These include insurance, advertising, education, and policing. They can lead to decisions that harm the poor, reinforce racism, and amplify inequality. Mathematicians and statisticians were for a very long time studying our desires, movements, and spending power. This is the Big Data economy we are living in. </p>
<h2>Trust is Important </h2>
<p>Consumers are more conscious of their data privacy than ever. A recent <a href="https://tealium.com/resource/whitepaper/how-brands-can-prioritize-privacy-in-the-age-of-data/">Tealium study</a> on consumer data privacy found that 97% of consumers surveyed said they are somewhat or very concerned about protecting their data. <a href="https://www.accenture.com/t20171220T024439Z__w__/us-en/_acnmedia/PDF-68/Accenture-Global-Anthem-POV.pdf#zoom=50">Research by Accenture</a>&nbsp;shows that&nbsp;88% of<strong> </strong>consumers say companies that provide personalized experiences without compromising their trust are more appealing and can relate to their needs better than others.</p>
<p>We are focusing on Facebook on this particular blog post to quite a degree since it is the one singular social medium that is growing exponentially. One of the ways in which Facebook garners your data is with you revealing your data and your intentions via the act of publishing status updates and even commenting. You see, the act of commenting fulfills just one touchpoint in the process of these tech giants harvesting of data. Facebook built&nbsp;<a rel="noreferrer noopener" href="https://developers.facebook.com/docs/plugins/comments/" target="_blank">comments plugin</a>&nbsp;to allow users to leave comments on websites, blogs and forums through their Facebook accounts. It was expected to provide high-quality conversations over the internet but instead ended up spamming popular sites.</p>
<p>If you do use the Facebook Comments plugin, remember that your comments are a valuable content asset that shouldn’t be subject to <a href="https://ducttapemarketing.com/how-and-why-i-use-the-facebook-comments-plugin/">Facebook’s Terms of Service</a>, which basically says they can do whatever they want with them. An increasing amount of spam raises questions about how well the policy of malicious content online is going on. There are many misleading and offensive comments, usually attracting and persuading users towards a specific link to click it. These comments are often repetitive and can easily be identified as spam.</p>
<p>According to an estimation by&nbsp;<a href="https://www.similartech.com/technologies/facebook-comments">Similartech</a>&nbsp;more than 360,000 unique domains have installed Facebook Comments plugin. It is still not clear why and how the spam filters of Facebook failed to filter spam comments. <a href="https://www.similartech.com/technologies/facebook-comments">In 2015</a>, one of the security firms, Symantec reported scammers had been trying to affect the comments sections of Facebook to spread malware. </p>
<p>For more than two years now, Facebook has been working on its content-moderation efforts and the spamming in Facebook Comment boxes shows that problematic content still finds its way to escape the loopholes. Moreover, <a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">Facebook can track what </a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?usqp=mq331AQFKAGwASA%3D&amp;amp_js_v=0.1#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">you</a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html"> type</a>, even if you never post it.&nbsp;Data scientists can determine that a status or comment has been typed by tracking code in the HTML form element of each page.</p>
<h2>Read The Terms and Conditions</h2>
<p>We live in a world where the concept of privacy already seems outdated. But that is largely because we’ve decided not to inquire about what happens when we trade it for convenience. The more connected you, and billions of others, are to Facebook, the more money Facebook makes by selling your personal information, and the more powerful it becomes.</p>
<p>The terms of service state,&nbsp;<em>We use the data we have — for example, about the connections you make, the choices and settings you select, and what you share and do on and off our Products — to personalize your experience.</em></p>
<figure><img loading="lazy" width="746" height="634" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" alt="" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" sizes="(max-width: 746px) 100vw, 746px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://qz.com/1266835/facebooks-terms-of-service-translated-so-you-understand-your-data-and-privacy-settings/">Be wary of nebulous terms and promises</a></figcaption></figure>
<p>Basically, this means that Facebook uses every bit of personal information it can, collected&nbsp;<a href="https://www.consumerreports.org/privacy/how-facebook-tracks-you-even-when-youre-not-on-facebook/">both on and off Facebook</a>, to entice advertisers. The better the company knows you through the personal information you share with your friends and family, the more likely they are to be able to sell you stuff you want.</p>
<h2>Choose The Right to Privacy</h2>
<p>Big data is big business and value is created from customer insight. But, where is the moral line? What happens when companies cross that line? What if consumers could flip the equation to offer their data directly to the companies they trust? The future could be customer-monetized data.</p>
<p>We are the authors of our own destruction here since we don’t choose to be aware. If you participate in Facebook, should you not have some semblance of an expectation of privacy. The former Federal Trade Commission Chairperson Jon Leibowitz publicly stated, “We all agree that consumers don’t read privacy policies.”</p>
<p><a href="https://talk.hyvor.com/docs/gdpr">Ensure you choose privacy</a> and are aware of how technology plans on using your data. The only solution is being non-participatory. The solution is choosing not to be part of a pernicious agenda that can be defined as Surveillance Capitalism. </p>
<div><div><div><h4>
Need a privacy-focused commenting platform for your website?
</h4>

</div></div></div> </div></div>]]>
            </description>
            <link>https://talk.hyvor.com/blog/privacy-and-big-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033030</guid>
            <pubDate>Mon, 09 Nov 2020 09:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Towards 1.0]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25032956">thread link</a>) | @lelf
<br/>
November 9, 2020 | https://pijul.org/posts/2020-11-07-towards-1.0/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-11-07-towards-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
                We are looking for <strong>VC funding</strong>. If you are interested in helping us build the future of collaboration (for code and other documents), shoot us an email at <a href="mailto:contact@pijul.org">contact@pijul.org</a>.
                
            </p>


<p>Saturday, November 7, 2020</p>
<p>After fixing the performance and scalability problems, we’re on our way to getting a stable Pijul. In this post, I explain what I’ve been up to in the recent months.</p>
<h2 id="context">Context</h2>
<p>Pijul has always been advertised as a research project, trying to implement a theory of patches that would be sound and fast. This is an ambitious goal, and became even more ambitious than initially envisioned.</p>
<p>One of the hardest challenges is that source code is by essence stateful, which makes it much harder to iterate over algorithm designs, like normal research projecst need to. For example, in order to get from our last published version to our current design, we have gone through many different variants, and there wasn’t much to publish.</p>
<p>Moreover, the UX aspect is what matters most in the end, and testing it on a real world project is the only way to get it there. However, unlike in a compiler, where bootstrapping is done one step at a time, and previous versions are always available to compile your current one, a version control system has the additional problem that the previous versions might not always be easily accessible if there is a bug.</p>
<p>One of the criticisms I’ve heard since I realised that better datastructures were possible is that I was “working secretely”. I certainly understand this feeling, but this is based on a misunderstanding of how research works. When I first had the idea that I’m explaining in this post, I realised that a complete rewrite would be needed. But for a very long time, almost nothing other than unusable, unreadable prototypes happened.</p>
<p>Back then, there wasn’t much to show, since it wasn’t even clear that the basic datastructure would work. And even when they started working at a large enough scale, it took me quite a bit of testing on large repositories before they started actually working.</p>
<p>This also implies that there wasn’t much to show for quite a while, since the new algorithm wasn’t usable until very recently, and any repository started before now would have become obsolete in a matter of days.</p>
<p>There were also <a href="#a-personal-note">persoprofessional reasons</a> for this silence, described at the end of this post.</p>

<p>Pijul depends on two other projects I’ve started.</p>
<h3 id="sanakirja">Sanakirja</h3>
<p>One of these projects is Sanakirja, which is “just” a key-value store, but has the extra feature that databases can be cloned efficiently. I would have loved to just use an existing library, but there just isn’t any that has this cloning feature. However, the scope of Sanakirja is still quite modest, it does one thing and does it well. Obviously, it took some time to find the memory-management bugs, but I have good confidence that this is now done.</p>
<p>In previous releases of Pijul, databases were implemented with a single mmapped file containing the binary representation of B Trees. Despite their lower writing performance (compared to alternatives such as <em>Log-structured merge-trees</em>), and the complexity of the code for deletions, B Trees are very well suited to this use case: indeed, since they are trees, reference-counting the nodes is enough to implement efficient clones.</p>
<p>One of the remaining issues was that in order to grow the database, we needed to un-mmapped the file, grow it, and mmap it again. Since applying a single change in Pijul must be an atomic operation, we needed to cancel the transaction when that happened, and restart it with a bigger file.</p>
<p>Another issue is that I wanted the next libpijul to compile on platforms that don’t have mmap, such as WASM. However, if reallocating an mmapped file has a very low complexity (even though it does have a non-zero cost in terms of system calls), reallocating a chunk of memory often requires copying everything. This completely defeats the point of the algorithms in Pijul, which rely on a particular representation of the datastructures on the disk.</p>
<p>The main innovation in Sanakirja 0.13 is to use a vector of memory blocks (either in memory or mmapped from a file), of exponentially-increasing size. The overhead is just one extra indirection, the complexity of adding items is the same (since the operation of creating an extra block is $O(1)$). The exponentially-increasing sizes mean that the allocated memory is always at least half-full.</p>
<h3 id="thrussh">Thrussh</h3>
<p>The other one is Thrussh. That library implements the SSH protocol, and tries to handle a number of key formats. The former is a surprisingly easy goal, and keeping up with Tokio versions has historically been the hardest bit, while the latter is the most horrendous hydra-like task, with new heads and legacy formats showing up every time you think you’re done.</p>
<h2 id="how-repositories-used-to-work-and-still-do-to-some-extent">How repositories used to work (and still do, to some extent)</h2>
<p>Old-style repositories represented a single file by a directed graph $G = (V, E)$ of lines, where each vertex $v\in V$ represented a line, and an edge from $u \in V$ to $v\in V$, labelled by some change (also called patch) number $c$, could be read as “according to change $c$, line $u$ comes before $v$”.</p>
<p>This means that changes could introduce vertices and lines, as in the following example, where a line $D$ is introduced between $A$ and $B$:</p>
<p><img src="https://pijul.org/img/repos-line-add.svg">
</p>
<p>Here, the thick line represents the change from the file containing the lines $A$, $B$, $C$ to the file with the new line $D$.
An important feature to note is that <strong>vertices are uniquely identified</strong>, by the hash of the change that introduced them, along with a position in that change. This means that two lines with the same content, introduced by different changes, will be different. It also means that a lines keeps its identity, even if the change is applied in a totally different context.</p>
<p>Moreover, this system is append-only, in the sense that <em>deletions</em> are handled by a more sophisticated labelling of the edges. In the example above, if we want to delete line $D$, we just need to make a change mapping the edge introduced by $c_0$ to a deleted edge, which we label by the name $c_1$ of the change that introduces it:</p>
<p><img src="https://pijul.org/img/repos-line-del.svg">
</p>
<p>From now on, we call the full edges <strong>alive</strong>, and the dashed ones <strong>dead</strong>.</p>
<p>We have just described the two basic kinds of actions in Pijul. There are no other. One kind adds vertices to the graph, along with “alive” edges around them, and the other kind maps an existing edge label onto a different one.
In order to fully described the system, I also need to mention that the edge labels are given by two parameters: their status (alive, deleted, and a few others related to multiple files and technical details explained below) and the change that introduced them.</p>
<h3 id="dependencies">Dependencies</h3>
<p>This scheme allows to defines dependencies between changes:</p>
<ul>
<li>
<p>If a change $c$ adds a vertex, we must have its <em>“context”</em>, i.e. the lines before and after it, hence the changes that introduced these lines are in the dependencies of $c$.</p>
</li>
<li>
<p>If a change $c$ deletes a vertex, or in other words maps an existing edge introduced by a change $d$, then $c$ must depend on $d$.</p>
</li>
</ul>
<p>Of course, this is just the minimal set of dependencies needed to make sense of the text edits. Hooks and scripts may add extra language-dependent dependencies based on semantics.</p>
<h3 id="are-edge-labels-minimal">Are edge labels minimal?</h3>
<p>Our goals is to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance. Therefore, one immediate question comes to mind: why even keep the change number on the edges?</p>
<p>In order to answer that question, suppose we don’t keep the labels, meaning that the maps happen between statuses only. Then, consider the following two situations:</p>
<ul>
<li>
<p><strong>Change inverses</strong></p>
<p>The first issue happens when two authors delete a line in parallel, and one of the authors reverts their change. Applying these changes yields the following diagram, where the two deletions get merged into one, and the inverse applies to both:</p>
 <p><img src="https://pijul.org/img/inverse2.svg">
 </p>
<p>However, this is not what we expect, since one of the authors explicitly reverted the deletion, while the other performed the same deletion in parallel.
By keeping the labels, this is what we get instead:</p>
 <p><img src="https://pijul.org/img/inverse3.svg">
 </p>
</li>
<li>
<p><strong>Missing contexts</strong></p>
<p>For the sake of clarity, in the rest of this post, we name two users Alice (with pronouns “she/her”) and Bob (with pronouns “he/his”).</p>
<p>This situation, where Alice writes something in the middle of a paragraph $p$, while Bob deletes $p$ in parallel.
One issue here, is that the situation is not symmetric: when Bob applies Alice’s change, he can tell immediately that something is wrong, because the context of Alice’s edits is labelled as deleted in his repository.</p>
 <p><img src="https://pijul.org/img/known-vertices1.svg">
 </p>
<p>However, Alice’s situation is different: indeed, consider the case where instead of deleting $p$ <em>in parallel</em> of her changes, Bob deleted $p$ after applying Alice’s change. The edges deleted are exactly the same, but this is not a conflict, as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices2.svg">
 </p>
<p>The situation is further complicated by the fact that this system doesn’t behave symmetrically with the contexts above and below the new line. Indeed, if Bob deleted the <em>down context</em> of the line (i.e. if he deleted line $C$) instead of the <em>up context</em> (line $B$), Alice could detect the conflict, since in that case, $C$ would have both an alive and a dead edge pointing to it ($C$ is called a “zombie vertex” internally), as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices0.svg">
 </p>
<p>Keeping the change identifiers on each edge allows us to solve this. In Pijul 0.12, Bob would add the labels of all the edges around the deleted lines to the dependencies of his change. Then, Alice can tell whether Bob knows of her change before applying it. The changes are conflict if and only if Bob doesn’t know of the new lines.</p>
<p>However, this behaviour was counter-intuitive, <a href="https://discourse.pijul.org/t/why-these-patches-dont-commute/449">as noted by @tae</a>.</p>
<p>A finer analysis of what dependencies are led to a different behaviour in the new Pijul. Changes now have two different sets of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pijul.org/posts/2020-11-07-towards-1.0/">https://pijul.org/posts/2020-11-07-towards-1.0/</a></em></p>]]>
            </description>
            <link>https://pijul.org/posts/2020-11-07-towards-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032956</guid>
            <pubDate>Mon, 09 Nov 2020 09:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I Git]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25032951">thread link</a>) | @stargrave
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032951</guid>
            <pubDate>Mon, 09 Nov 2020 09:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Beauty of Python's ExitStack (2015)]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25032924">thread link</a>) | @polm23
<br/>
November 9, 2020 | https://www.rath.org/on-the-beauty-of-pythons-exitstack.html | <a href="https://web.archive.org/web/*/https://www.rath.org/on-the-beauty-of-pythons-exitstack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I believe Python's <a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> feature does not get the recognition
it deserves. I think part of the reason for this is that its
documentation is somewhere deep down in the (already obscure)
<a href="http://docs.python.org/3/library/contextlib.html">contextlib</a> module because formally ExitStack is just one of many
available context managers for Python's <a href="http://docs.python.org/3/reference/compound_stmts.html#the-with-statement">with statement</a>. But
ExitStack deserves far more prominent notice than that. This post will
hopefully help with that.</p>
<p>So what makes ExitStack so important? In short, it's the best way to
handle allocation and release of external resources in Python.</p>
<div id="the-problem">
<h2>The Problem</h2>
<p>The main challenge with external resources is that you have to release
them when you don't need them anymore -- and in particular you must
not forget to do so in all the alternate execution paths that may be
entered in case of error conditions.</p>
<p>Most languages implement error conditions as "exceptions" that can be
"caught" and handled (Python, Java, C++), or as special return values
that you need to check to determine if an error occured (C, Rust,
Go). Typically, code that needs to acquire and release external
resources then looks like this:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>try</span><span>:</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>try</span><span>:</span>
        <span># do stuff with res1 and res2</span>
    <span>finally</span><span>:</span>
        <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>finally</span><span>:</span>
   <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
</pre></div>
<p>or, if the language doesn't have exceptions:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
   <span>goto</span> <span>error_out1</span><span>;</span>
<span>}</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>2</span><span>;</span>
   <span>goto</span> <span>error_out2</span><span>;</span>
<span>}</span>
<span>// do stuff with res1 and res2</span>
<span>retval</span> <span>=</span> <span>0</span><span>;</span> <span>// ok</span>

<span>error_out2</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res2</span><span>);</span>
<span>error_out1</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res1</span><span>);</span>
<span>return</span> <span>retval</span><span>;</span>
</pre></div>
<p>This approach has three big problems:</p>
<ol>
<li>The cleanup code is far away from the allocation code.</li>
<li>When the number of resources increases, indentation levels (or jump
labels) accumulate, making things hard to read.</li>
<li>Managing a dynamic number of resources this way is impossible.</li>
</ol>
<p>In Python, some of these issues can be alleviated by using the
<tt>with</tt> statement:</p>
<div><pre><span></span> <span>@contextlib.contextmanager</span>
 <span>def</span> <span>my_resource</span><span>(</span><span>id_</span><span>):</span>
     <span>res</span> <span>=</span> <span>acquire_resource</span><span>(</span><span>id_</span><span>)</span>
     <span>try</span><span>:</span>
         <span>yield</span> <span>res</span>
     <span>finally</span><span>:</span>
         <span>release_source</span><span>(</span><span>res</span><span>)</span>

<span>with</span> <span>my_resource</span><span>(</span><span>RES_ONE</span><span>)</span> <span>as</span> <span>res1</span><span>,</span> \
   <span>my_resource</span><span>(</span><span>RES_TWO</span><span>)</span> <span>as</span> <span>res2</span><span>:</span>
    <span># do stuff with res1</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>However, this solution is far from optimal: you need to implement
resource-specific context managers (note that in the above example we
silently assumed that both resources can be acquired by the same
function), you can get rid of extra indentation only if you allocate
all the resources at the same time and live with an ugly continuation
line (no parenthesis allowed in this context), and you still need to
know the number of required resources ahead of time.</p>
<p>Over in the world of exception-less programming languages (no pun
intended), <a href="http://www.golang.org/">Go</a> has developed a different remedy: the <a href="http://golang.org/ref/spec#Defer_statement">defer statement</a>
defers execution of an expression until the enclosing
function returns. Using <tt>defer</tt>, the above example can be written
as:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>1</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>2</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>// do stuff with res1 and res2</span>
<span>return</span> <span>0</span>
</pre></div>
<p>This is pretty nice: allocation and cleanup are kept close together,
no extra indentation or jump labels are required, and converting this
to a loop that dynamically acquires multiple resources would be
straightforward. But there are still some drawbacks:</p>
<ul>
<li>To control when exactly a group of resources is getting released you
have to factor out into separate functions all parts of code that
access the respective resources.</li>
<li>You cannot "cancel" a deferred expression, so there is no way to
e.g. return a resource to the caller if no error occured.</li>
<li>There is no way to handle errors from the cleanup functions.</li>
<li><tt>defer</tt> is available in Go, but not in Python.</li>
</ul>
</div>
<div id="exitstack-to-the-rescue">
<h2>ExitStack to the rescue</h2>
<p><a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> fixes all of the above issues, and adds some benefits on
top of it. An ExitStack is (as the name suggests) a stack of clean-up
functions. Adding a callback to the stack is the equivalent of calling
Go's <tt>defer</tt> statement. However, clean-up functions are not executed
when the function returns, but when execution leaves the <tt>with</tt>
block - and until then, the stack can also be emptied again.</p>
<p>Finally, clean-up functions itself may raise exceptions without
affecting execution of other clean-up functions. Even if multiple
clean-ups raise exceptions, you are will get a usable stacktrace.</p>
<p>Here's how to acquire multiple resources:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res1</span><span>)</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res2</span><span>)</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>Note that</p>
<ul>
<li>acquisition and release are close to each other</li>
<li>there's no extra indentation,</li>
<li>the pattern and it easily scales up to many resources (including a
dynamic number that's acquired in a loop)</li>
</ul>
<p>If there already is a context manager for your resource, there's also
a shortcut function:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'first_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'second_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>To open a bunch of files and return them to the caller (without
leaking already opened files if a subsequent open fails):</p>
<div><pre><span></span><span>def</span> <span>open_files</span><span>(</span><span>filelist</span><span>):</span>
    <span>fhs</span> <span>=</span> <span>[]</span>
    <span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
        <span>for</span> <span>name</span> <span>in</span> <span>filelist</span><span>:</span>
            <span>fhs</span><span>.</span><span>append</span><span>(</span><span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>name</span><span>,</span> <span>'r'</span><span>)))</span>
        <span>cm</span><span>.</span><span>pop_all</span><span>()</span>
        <span>return</span> <span>fhs</span>
</pre></div>
<p>Disclaimer: the <a href="https://bugs.python.org/issue13585">original idea for ExitStack</a> came from me.</p>
</div>
</div></div>]]>
            </description>
            <link>https://www.rath.org/on-the-beauty-of-pythons-exitstack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032924</guid>
            <pubDate>Mon, 09 Nov 2020 09:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Loop Software (2013)]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25032563">thread link</a>) | @netgusto
<br/>
November 9, 2020 | https://marak.com/blog/2013-05-13-time-loop-software | <a href="https://web.archive.org/web/*/https://marak.com/blog/2013-05-13-time-loop-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>What if it were possible to write software capable of time travel? What if we could write software that was able to retrieve results from a computation solved sometime in the near future? What would this software look like? What problems could be solved?</p>
<p><a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#Time_loop_logic">Time loop logic</a> is a hypothetical system of computation that exploits the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle">Novikov self-consistency principle</a>. In this system the computer is able to send the result of a computation backwards through time and rely upon the self-consistency principle to force the sent result to be correct. This futuristic concept might seem impossible now but I'd imagine trying to explain nuclear fission to a 3rd century blacksmith would seem equally impossible.</p>
<h2 id="writing-time-loop-software">Writing time loop software</h2>
<p>Building on the concept of time loop logic we are able to implement theoretical programming constructs to help better understand the concept of time travel in software. In the following examples we demonstrate what a time loop logic program might look like.</p>
<h3 id="an-event-loop">An event loop</h3>
<p>In the follow examples we'll be using the JavaScript programing language. JavaScript provides a single thread of execution for code to run in. The JavaScript virtual machine is constantly running an event loop. Each tick of this event loop represents a single cycle of code execution. Once this cycle is completed the next tick in the event loop will occur. In the popular <a href="https://nodejs.org/">Node.js</a> framework <a href="https://nodejs.org/api/process.html#process_process_nexttick_callback">an API is provided</a> to defer the execution of a block of code until the nextTick of the event loop occurs.</p>
<h4 id="node-js-process-nexttick-example">node.js process.nextTick() example</h4>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

process.nextTick(foo);
<span>console</span>.log(<span>'bar'</span>);
</code></pre><p>This will output:</p>
<pre><code><span>bar
</span><span>foo</span>
</code></pre><p>The same effect of <code>process.nextTick</code> can also be achieved using JavaScript's setTimeout command</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>0</span>)</span>
</code></pre><h4 id="node-js-process-prevtick-example">node.js process.prevTick() example</h4>
<p>Now let's imagine that instead of deferring a line of code until the next tick of the event loop we could instead push that code <em>backwards</em> to the <em>previous</em> tick of the event loop.</p>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

<span>console</span>.log(<span>'bar'</span>);
process.prevTick(foo);
</code></pre><p>Outputs:</p>
<pre><code><span>foo</span>
bar
</code></pre><p>The same effect of <code>process.prevTick</code> can also be achieved using setTimeout with a negative value</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>-1</span>)</span>
</code></pre><p>Since all we are doing is logging a simple string to the console, this is a contrived example. However; building on the concept of <code>process.prevTick</code> we can begin to implement more complex time loop programs.</p>
<h2 id="brute-force-cracking-with-time-loops">Brute force cracking with time loops</h2>
<p>Let's assume a simple <a href="https://en.wikipedia.org/wiki/Brute-force_search">brute-force search</a> password cracking scenario. Imagine there is a login function which expects a password. We have access to a very large word dictionary in which our cracking software will sequentially attempt logins using every word in the dictionary as a password until a match is found.</p>
<p>Here is the code for our brute-force program</p>
<p><em>Note: It's important to remember that Novikov's self-consistency principle guarantees that the sequence of events generating the paradox in the following code has zero probability.</em></p>


<h2 id="prime-factors-with-time-loops">Prime Factors with time loops</h2>
<p>Using time-loop logic  prime factors can be calculated in polynomial time.</p>


<h2 id="zero-lag-instant-communication">Zero-lag / Instant Communication</h2>
<p>The theoretical application of time-loop logic is endless. Imagine a time-loop based communication protocol. This would mean zero millisecond latency. Imagine gaming, video broadcasting, and file sharing with instantaneous transfer and zero lag. Through exploiting self-consistency we know that data will be sent in the immediate future ( since the data has begun transferring from the source ) and that eventually the transmission will arrive at it's destination. As long as the data will eventually be received, we are able to send the result back from the future into the immediate present, removing the notion of latency or lag.</p>
<h2 id="time-loop-logic-and-novikov-s-self-consistency-principle">Time Loop Logic and Novikov's Self-Consistency Principle</h2>
<p>How is it actually possible to program a time loop? Based on the self-consistency principle and continuing advancements in quantum entanglement these types of mind-bending constructs are not very far away. It's very possible we'll see this type of software actively being developed within the next hundred years.</p>
<p>Time loop logic was first written about by <a href="https://en.wikipedia.org/wiki/Hans_Moravec">Hans Moravec</a> who is best known for his work in robotics and artificial intelligence at Carnegie Mellon University. You can find Hans' original paper from 1991, "Time Travel and Computing", here: <a href="https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html">https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html</a>. I recommend reading the entire paper.</p>
<p>What we know from <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve#General_relativity">general relativity</a> is that at a quantum level backwards time-travel is mathematically possible in certain solutions containing <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve">closed timelike curves</a>. A closed timelike curve is a <a href="https://en.wikipedia.org/wiki/World_line">world-line</a> in a <a href="https://en.wikipedia.org/wiki/Lorentzian_manifold#Lorentzian_manifold">Lorentzian manifold</a>. </p>
<p>Closed timelike curves ( CTCs ) pose a problem for physicists. The existence of CTCs introduces the notion of time travel being possible. If time travel is possible, we have now introduced the notion of <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">time travel paradoxes</a> which can violate <a href="https://en.wikipedia.org/wiki/Causality_(physics)">causality</a>. Since it's generally accepted that we cannot violate causality in our universe we must be able to explain how closed time-like curves can exist.</p>
<p>In his self-consistency principle Novikov asserts that if an event exists that would give rise to a paradox, or to any "change" to the past whatsoever, then the probability of that event is zero. In short, it says that it is impossible to create time travel paradoxes. You can find the original paper here: <a href="http://authors.library.caltech.edu/3737">http://authors.library.caltech.edu/3737</a>. I recommend starting with reading the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#History_of_the_principle">history of the principle</a>.</p>

<p>In order for time loop logic to return an answer instantaneously, we <em>must</em> ensure that the problem will run long enough into the future to <em>actually</em> calculate the result. If a problem takes sixty seconds to solve, the program must run for at least sixty seconds. Time-loop logic does <em>not</em> violate causality. We are able to retrieve the answer instantly because we have committed to spending sixty seconds in the future calculating the answer and sending it back.</p>
<p>This turns debugging time-loop logic into somewhat of an impossibility. Any bugs in a time loop indicate that sometime in the future a problem has occurred. <strong>This event may or may not be related to software.</strong> </p>
<p>Imagine a computer that utilized a time loop to brute force crack passwords ( as our code posted above did). I turn the machine on and request it cracks the password. The program doesn't work. Frustrated, I turn off the machine and complain to my co-worker Josh.</p>
<p>Josh turns on the machine and requests the password. The software works instantly cracking the password in under 1ms.</p>
<p>Bewildered, I ask Josh why the machine worked for him but not for me.</p>
<p>Josh replies, "It's actually quite simple. Using that computer it's going to take approximately 400 hours to brute force the password. After that 400 hours the CPU must recursively return the cracked password back in time until it reaches right now. I was able to get the answer instantly because I have decided to not turn this computer off for another 399 hours and 59 minutes. Simply put, you turned off the computer too quickly"</p>
<p><em>The consequences of unplugging the computer</em></p>
</div></div></div>]]>
            </description>
            <link>https://marak.com/blog/2013-05-13-time-loop-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032563</guid>
            <pubDate>Mon, 09 Nov 2020 08:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25032481">thread link</a>) | @jessems
<br/>
November 9, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer — the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we’ll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from — that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032481</guid>
            <pubDate>Mon, 09 Nov 2020 08:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25032133">thread link</a>) | @ingve
<br/>
November 8, 2020 | https://ericniebler.com/2020/11/08/structured-concurrency/ | <a href="https://web.archive.org/web/*/https://ericniebler.com/2020/11/08/structured-concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>TL;DR: <strong>“Structured concurrency” refers to a way to structure async computations so that child operations are guaranteed to complete before their parents, just the way a function is guaranteed to complete before its caller.</strong> This sounds simple and boring, but in C++ it’s anything but. Structured concurrency — most notably, C++20 coroutines — has profound implications for the correctness and the simplicity of async architecture. It brings the <a href="https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=msvc-160">Modern C++ style</a> to our async programs by making async lifetimes correspond to ordinary C++ lexical scopes, eliminating the need for reference counting to manage object lifetime.</p>
<h2>Structured Programming and C++</h2>
<p>Back in the 1950’s, the nascent computing industry discovered structured programming: that high-level programming languages with lexical scopes, control structures, and subroutines resulted in programs that were far easier to read, write, and maintain than programming at the assembly level with test-and-jump instructions and <code>goto</code>. The advance was such a quantum leap that nobody talks about structured programming anymore; it’s just “programming”.</p>
<p>C++, more so than any other language, leverages structured programming to the hilt. The semantics of object lifetime mirror — and are tied to — the strict nesting of scopes; i.e., the <em>structure</em> of your code. Function activations nest, scopes nest, and object lifetimes nest. Objects’ lifetimes end with a scope’s closing curly brace, and objects are destroyed in the reverse order of their construction to preserve the strict nesting.</p>
<p>The Modern C++ programming style is built on this structured foundation. Objects have <em>value semantics</em> — they behave like the ints — and resources are cleaned up in destructors deterministically, which guarantees structurally that resources aren’t used after their lifetimes have ended. This is <em>very</em> important.</p>
<p>When we abandon this strict nesting of scopes and lifetimes — say, when we reference count an object on the heap, or when we use the singleton pattern — we are fighting against the strengths of the language rather than working with them.</p>
<h2>The Trouble With Threads</h2>
<p>Writing correct programs in the presence of concurrency is far more difficult than in single-threaded code. There are lots of reasons for this. One reason is that threads, like singletons and dynamically allocated objects, scoff at your puny nested scopes. Although you can use the Modern C++ style <em>within</em> a thread, when logic and lifetimes are scattered across threads, the hierarchical structure of your program is lost. The tools we use to manage complexity in single-threaded code — in particular, nested lifetimes tied to nested scopes — simply don’t translate to async code.</p>
<p>To see what I mean, let’s look at what happens when we take a simple synchronous function and make it asynchronous.</p>
<pre>void computeResult(State &amp; s);

int doThing() {
  State s;
  computeResult(s);
  return s.result;
}
</pre>
<p><code>doThing()</code> is simple enough. It declares some local state, calls a helper, then returns some result. Now imagine that we want to make both functions async, maybe because they take too long. No problem, let’s use Boost futures, which support continuation chaining:</p>
<pre>boost::future&lt;void&gt; computeResult(State &amp; s);

boost::future&lt;int&gt; doThing() {
  State s;
  auto fut = computeResult(s);
  return fut.then(
    [&amp;](auto&amp;&amp;) { return s.result; }); // OOPS
}
</pre>
<p>If you’ve programmed with futures before, you’re probably screaming, <em>“Nooooo!”</em> The <code>.then()</code> on the last line queues up some work to run after <code>computeResult()</code> completes. <code>doThing()</code> then returns the resulting future. The trouble is, when <code>doThing()</code> returns, the lifetime of the <code>State</code> object ends, <em>and the continuation is still referencing it</em>. That is now a dangling reference, and will likely cause a crash.</p>
<p>What has gone wrong? Futures let us compute with results that aren’t available yet, and the Boost flavor lets us chain continuations. But the continuation is a separate function with a separate scope. We often need to share data across those separate scopes. No more tidy nested scopes, no more nested lifetimes. We have to manage the lifetime of the state manually, something like this:</p>
<pre>boost::future&lt;void&gt;
computeResult(shared_ptr&lt;State&gt; s); // addref
                                    // the state

boost::future&lt;int&gt; doThing() {
  auto s = std::make_shared&lt;State&gt;();
  auto fut = computeResult(s);
  return fut.then(
    [s](auto&amp;&amp;) { return s.result; }); // addref
                                       // the state
}
</pre>
<p>Since both async operations refer to the state, they both need to share responsibility to keep it alive.</p>
<p>Another way to think about this is: <em>what is the lifetime of this asynchronous computation?</em> It starts when <code>doThing()</code> is called, but it doesn’t end until the continuation — the lambda passed to <code>future.then()</code> — returns. <em>There is no lexical scope that corresponds to that lifetime.</em> And that is the source of our woes.</p>
<h2>Unstructured Concurrency</h2>
<p>The story gets more complicated yet when we consider executors. Executors are handles to executions contexts that let you schedule work onto, say, a thread or thread pool. Many codebases have some notion of an executor, and some let you schedule things with a delay or with some other policy. This lets us do cool things, like move a computation from an IO thread pool to a CPU thread pool, or retry an async operation with a delay. Handy, but like <code>goto</code> it is a very low-level control structure that tends to obfuscate rather than clarify.</p>
<p>For instance, I recently came across an algorithm that uses executors and callbacks (called Listeners here) that retries the async allocation of some resource. Below is a greatly abridged version. It is described after the break.</p>
<pre>// This is a continuation that gets invoked when
// the async operation completes:
struct Manager::Listener : ListenerInterface {
  shared_ptr&lt;Manager&gt; manager_;
  executor executor_;
  size_t retriesCount_;

  void onSucceeded() override {
    /* ...yay, allocation succeeded... */
  }
  void onFailed() override {
    // When the allocation fails, post a retry
    // to the executor with a delay
    auto alloc = [manager = manager_]() {
      manager-&gt;allocate();
    };
    // Run "alloc" at some point in the future:
    executor_.execute_after(
      alloc, 10ms * (1 &lt;&lt; retriesCount_));
  }
};

// Try asynchronously allocating some resource
// with the above class as a continuation
void Manager::allocate() {
  // Have we already tried too many times?
  if (retriesCount_ &gt; kMaxRetries) {
    /* ...notify any observers that we failed */
    return;
  }

  // Try once more:
  ++retriesCount_;
  allocator_.doAllocate(
    make_shared&lt;Listener&gt;(
      shared_from_this(),
      executor_,
      retriesCount_));
}
</pre>
<p>The <code>allocate()</code> member function first checks to see if the operation has already been retried too many times. If not it calls a helper <code>doAllocate()</code> function, passing in a callback to be notified on either success or failure. On failure, the handler posts deferred work to the executor, which will call <code>allocate()</code> back, thus retrying the allocation with a delay.</p>
<p>This is a heavily stateful and rather circuitous async algorithm. The logic spans many functions and several objects, and the control and data flow is not obvious. Note the intricate ref-counting dance necessary to keep the objects alive. Posting the work to an executor makes it even harder. Executors in this code have no notion of continuations, so errors that happen during task execution have nowhere to go. The <code>allocate()</code> function can’t signal an error by throwing an exception if it wants any part of the program to be able to recover from the error. Error handling must be done manually and out-of-band. Ditto if we wanted to support cancellation.</p>
<p>This is <strong>unstructured concurrency</strong>: we queue up async operations in an <em>ad hoc</em> fashion; we chain dependent work, use continuations or “strand” executors to enforce sequential consistency; and we use strong and weak reference counts to keep data alive until we are certain it’s no longer needed. There is no formal notion of task A being a child of task B, no way to enforce that child tasks complete before their parents, and no one place in the code that we can point to and say, “Here is the algorithm.”</p>
<blockquote>
<p><strong>If you don’t mind the analogy, the hops through the executor are a bit like <code>goto</code> statements that are non-local in both time and space: “Jump to this point in the program, <em>X</em> milliseconds from now, on this particular thread.”</strong></p>
</blockquote>
<p>That non-local discontinuity makes it hard to reason about correctness and efficiency. Scale unstructured concurrency up to whole programs handling lots of concurrent real-time events, and the incidental complexity of manually handling out-of-band asynchronous control and data flow, controlling concurrent access to shared state, and managing object lifetime becomes overwhelming.</p>
<h2>Structured Concurrency</h2>
<p>Recall that in the early days of computing, unstructured programming styles rapidly gave way to structured styles. With the addition of coroutines to C++, we are seeing a similar phase shift happening today to our asynchronous code. If we were to rewrite the above retry algorithm in terms of coroutines (using Lewis Baker’s popular <a href="https://github.com/lewissbaker/cppcoro">cppcoro</a> library), it might look something like this:</p>
<pre>// Try asynchronously allocating some resource
// with retry:
cppcoro::task&lt;&gt; Manager::allocate() {
  // Retry the allocation up to kMaxRetries
  // times:
  for (int retriesCount = 1;
       retriesCount &lt;= kMaxRetries;
       ++retriesCount) {
    try {
      co_await allocator_.doAllocate();
      co_return; // success!
    } catch (...) {}

    // Oops, it failed. Yield the thread for a
    // bit and then retry:
    co_await scheduler_.schedule_after(
      10ms * (1 &lt;&lt; retriesCount));
  }

  // Error, too many retries
  throw std::runtime_error(
    "Resource allocation retry count exceeded.");
}
</pre>
<blockquote>
<p>Aside: This replaces the <code>executor_</code> with a <code>scheduler_</code> that implements cppcoro’s <a href="https://github.com/lewissbaker/cppcoro#delayedscheduler-concept">DelayedScheduler</a> concept.</p>
</blockquote>
<p>Let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericniebler.com/2020/11/08/structured-concurrency/">https://ericniebler.com/2020/11/08/structured-concurrency/</a></em></p>]]>
            </description>
            <link>https://ericniebler.com/2020/11/08/structured-concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032133</guid>
            <pubDate>Mon, 09 Nov 2020 07:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm going to experiment by being Blind and Alone for 24 Hours]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25031774">thread link</a>) | @Osiris30
<br/>
November 8, 2020 | https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-896">

	
	<!-- .entry-header -->


			<div>

			
<figure><img data-attachment-id="901" data-permalink="https://dormin.org/bird-box/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg" data-orig-size="2000,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bird-box" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=760" src="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024 1024w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300 300w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=768 768w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For 24 hours I will be blind and alone in my apartment. I eventually want to try being blind for a week, but I’ll need seven days with no other obligations, and I won’t have that for a while. For now, I’ll suffice with a smaller-scale experiments with a few extra provisions for added difficulty.</p>







<ol type="1"><li>I must leave my blindfold on for 24 hours.<ul><li>If I remove the blindfold, I have failed the experiment</li><li>If the blindfold falls off or I can get partial sight, I have failed the experiment.</li><li>I am only allowed to readjust my blindfold if I can see light.</li></ul></li><li>I must not be in contact with any other people for 24 hours.<ul><li>I cannot answer my phone or any other messaging system.</li><li>I cannot receive in-person visitors.</li><li>If someone knocks at the door, I cannot answer verbally or physically.</li></ul></li><li>I will set an alarm for 24 hours. I cannot set any other alarms or use any other means to ascertain the time.<ul><li>It is up to me to keep my phone charged so the alarm goes off.</li></ul></li><li>I cannot leave my apartment.</li></ol>











<p>I have no good reason. I just want to see if I am capable of doing it and what will happen. Some things I’m curious about:</p>



<ul><li>Do I have the willpower to get through the experiment?</li><li>Will I become disoriented from losing all sense of time?</li><li>Will I be able to stave off boredom with podcasts, audiobooks, and music on my phone?</li><li>Will I enter some sort of meditative state due to a lack of sensory input?</li><li><a href="https://www.discovermagazine.com/the-sciences/scientists-made-people-wear-blindfolds-for-4-days-the-resulting-hallucinations-were-incredible">Will I hallucinate</a>?</li><li>Will my non-sight senses heighten?</li><li>Will I hurt myself by falling or banging into something?</li><li>Will I sleep?</li><li>Will I eat? Is consuming caffeine a good idea (for entertainment) or a bad idea (energy with no direction)?</li><li>Will this experience make me more interested in being blind for a week? Or less?</li></ul>



<figure><img src="https://digitalimpact.io/wp-content/uploads/2014/08/Blind.png" alt="Modern CEOs Are Blindfolded - Digital Impact"></figure>







<p>Attempt One started at 10:30 AM and failed at 1:13 PM. I purposefully took off my blindfold because I was worried that my multiple failures to input my Iphone’s password had resulted in a permanent lock or data wipe. But the password screen was just locked for a minute and all was well.</p>



<p>Given that I failed in the early afternoon, I considered restarting the experiment on another day in the morning. But I had already carved out a 24 hour period when I wouldn’t do any work or be disturbed, and it might have been a week or two longer before I got that opportunity again.</p>



<p>So I checked my messages, briefly went on Reddit, and then restarted.</p>



<div><figure><img data-attachment-id="903" data-permalink="https://dormin.org/t86752/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg" data-orig-size="521,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;CSA Images \/ CSA Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Blindfolded Woman&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 CSA Images \/ CSA Images&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;T86752&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="T86752" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" src="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg 521w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=128 128w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256 256w" sizes="(max-width: 521px) 100vw, 521px"></figure></div>







<p>Attempt Two was successful. I put on my blindfold at 1:23 PM on Thursday, November 5, 2020. I removed it at 1:28 PM on Friday, November 6.</p>



<p>It was an… interesting experience. I don’t recommend it, but I’m glad I did it. I’m not sure where to begin in describing it, especially since I couldn’t take notes, and part of the challenge was being confused. But I’ll do my best to break down the experience.</p>



<div><figure><img src="https://cdn.shopify.com/s/files/1/0818/3417/products/Les_Sublimes_Cashmere_Scarf_Dark_Blue_packshot_2048x.jpg?v=1539973736" alt="Large Cashmere Scarf in Dark Blue | Les Sublimes" width="427" height="427"></figure></div>



<h2><strong><span>Blindfold</span></strong></h2>



<p>To simulate blindness, I used a dark blue scarf as a blindfold. One layer wasn’t quite dark enough, so I folded it in half for extra light defense.</p>



<p>With the blindfold securely on, my vision was the same whether my eyes were open or closed. I kept my eyes closed 99.9% of the time since it was usually more comfortable and helped limit light. I occasionally opened my eyes to check the brightness level and to… I guess you could call it <em>stretch my eyelids.</em> They don’t feel good if you leave them closed for too long.</p>



<p>I couldn’t get a perfect scarf seal around my eyes, so sometimes when I tilted my head back while sitting I noticed a little light come into the bottom of my vision. To limit this, I often pinched the scarf around my nose in that position. But many/most blind people can see some light anyway, so I don’t think this was a significant violation of the experiment.</p>



<p>My eyes got quite dry under the scarf, so I applied moisturizer to this lids and sockets four or five times. I wanted to use eyedrops too, but there was no way to do so without failing the experiment.</p>



<figure><img loading="lazy" data-attachment-id="906" data-permalink="https://dormin.org/image/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" data-large-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" src="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" alt="BLACK N BLACK - #blackouttuesday ✊🏻✊🏼✊🏽✊🏾✊🏿 | Facebook" width="786" height="786" srcset="https://dorminorg.files.wordpress.com/2020/11/image.jpeg 225w, https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=150 150w" sizes="(max-width: 786px) 100vw, 786px"></figure>



<h2><strong><span>Blindness</span></strong></h2>



<p>Initially, everything was black, but as the day went on and the sun went down, I could tell it was nighttime even through two layers of scarf and my eyelids. I’m not sure if I could tell because my eyes had adjusted to become extremely sensitive to light, or if there were other subtle signals (ie. noises, air temperature, circadian rhythms, etc.) which my body picked up on. As evidence of the latter, I could not see any difference between the tv being on or off, nor the refrigerator being opened or closed, even when I was sitting right in front of either.</p>



<p>What I saw depended on how I applied my focus. If I did focus on my vision, I’d see the typical blackness you get from closing your eyes, but it was never perfectly black nor uniform; there was always some odd movement and occasional coloring (whiteness, pale blue, or sometimes red). The most common distortions were a swirling or flowing whiteness, sort of like cream in coffee. I hoped that being blindfolded for so long would make the distortions more extreme, but for the most part it looked no different than what you’d see if you closed your eyes right now for ten minutes.</p>



<p>There was one exception. It must have been about 20+ hours into the experiment, and my eyes were itching, so I rubbed both of them at the same time over the scarf. If you rub your closed eyes and focus on your sight any time you can see some weird stuff, but this was far more extreme than usual. I remember my entire vision filling up with white bubbles which then broke and briefly returned to black. Then white lightning bolt shapes stretched across my sight, expanded to make my vision purely white, and then slowly faded back to black. The strangest thing about it was the <em>brightness</em>. I literally felt like I was staring into lights despite being blindfolded in a dark room. Unfortunately, it only lasted about 30 seconds, but my heart was racing.</p>



<p>More notable than what I saw was what I didn’t see. By default, I was lost in thought and I focused on nothing. In such a state, I didn’t even register my vision or notice the darkness. I <em>think</em> this made my imagination and mental visualization more acute. On occasion, I’d be deep in thought and I’d get the <em>brightness</em> sensation again because I’d be mentally picturing something so vividly that the inevitable return to darkness felt like shutting off the lights in my brain. I’ll explain more about this in the <strong>Three Phases</strong> section.</p>



<p>Sadly, I did not hallucinate, or at least not as far as I could tell.</p>



<figure><img src="https://i1.wp.com/www.intelligentliving.co/wp-content/uploads/2014/07/sloth-sleeping.jpg?fit=1024%2C698&amp;ssl=1" alt="Fighting Bacteria With Sloth Fur"></figure>



<h2><strong><span>Energy</span></strong></h2>



<p>This was the most surprising aspect of the experiment.</p>



<p>I read that <a href="https://abcnews.go.com/Health/story?id=117902&amp;page=1#:~:text=Without%20light%20cues%20that%20the,as%20a%20result%2C%20researchers%20say.">blind people have trouble getting to sleep</a> because they don’t access any/enough light for their circadian rhythms. I seem to have the exact opposite problem. Without light, my body always thinks it’s time to sleep and has trouble doing anything else. Throughout most of the experiment, I felt extremely lethargic, lazy, and had to fight to stay awake.</p>



<p>I started my first failed experiment attempt at 10:30 AM. I had gotten 7.5 solid hours of sleep, I hadn’t done anything tiring the previous day, and I generally felt fine. Then I put on my blindfold, and within thirty minutes I was nodding off. I semi-slept for two hours before deciding to get an energy drink to get myself out of the funk. That worked, but as soon as it wore off, I was back in semi-sleep mode.</p>



<p>Even when I was firmly awake, I generally felt weak and lethargic. Movement around the apartment was annoying of course, but made so much more difficult by my energy levels. I ended up lying perfectly still in my comfy computer chair with my feet on a table 95% of the time. That is, when I wasn’t lying in bed.</p>



<p>On the other hand, when I removed my blindfold after 24 hours, I experienced a <em>burst</em> of energy. Seriously, it was like I had downed a double shot of espresso. It was like a switch had been flicked. The haziness and cobwebs were gone in an instant, and I felt the energy coursing through my body. I guess light has a big impact on me.</p>



<div><figure><img data-attachment-id="908" data-permalink="https://dormin.org/blind-man-2/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg" data-orig-size="615,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1604789422&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="blind-man-2" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" src="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg 615w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300 300w" sizes="(max-width: 615px) 100vw, 615px"></figure></div>



<h2><strong><span>Movement</span></strong></h2>



<p>I moved exactly how you’d expect… clumsily.</p>



<p>For the most part, I slowly walked around my apartment with a hand out to feel for walls and edges. Sometimes I’d get lazy and crawl just so it was easier. I know my apartment well enough that it wasn’t hard to get around, but every once in awhile I’d lose track of where I was and would be left slowly swinging my arm around searching for anything. It’s not a pleasant sensation.</p>



<p>Before the experiment, I had planned to pace around for fun, or maybe even do some exercise with the free time. But the confusion and especially the lethargy stopped all that. I just sat in my chair and didn’t move unless I needed to get a drink, go to the bathroom, or sleep.</p>



<p>I kind of wish I had done the experiment in an unfamiliar environment to add to the movement challenge, but oh well.</p>



<div><figure><img src="https://secure.img1-fg.wfcdn.com/im/99629273/compr-r85/1167/116715839/dual-flush-elongated-one-piece-toilet-seat-included.jpg" alt="DeerValley Dual-Flush Elongated One-Piece Toilet (Seat Included) &amp; Reviews  | Wayfair" width="729" height="729"></figure></div>



<h2><strong><span>Necessities</span></strong></h2>



<p>For food, I ate a big lunch at 10 AM before the experiment and then munched on dark chocolate throughout the night. I felt the heavy lethargy well before the lack of calories was an issue. I probably should have put some prepackaged meals in my fridge to eat, but I was worried about making a mess and not being able to clean up. Do I want ants? Because that’s how I get ants.</p>



<p>For drinks, I could manage to get to the kitchen and fill a cup with water when I needed to. I never took a full cup back to my chair just in case I knocked it over (clean up would be a nightmare). I also had some diet coke to serve as entertainment and put a little caffeine in me.</p>



<p>For the bathroom, I (a man) peed sitting down. I’m not ashamed to admit it.</p>



<div><figure><img src="https://imgaz2.staticbg.com/thumb/large/oaupload/banggood/images/F2/09/b934b522-e3e3-491d-b758-d0b92c259f0c.jpg" alt="Novel surreal melting distorted wall clock surrealist salvador dali style  wall clock amazing home decoration gift Sale - Banggood.com" width="802" height="801"></figure></div>



<h2><strong><span>Time</span></strong></h2>



<p>As part of the experiment, I never knew what time it was. This was intended to confuse me throughout the 24 hours, and it did, but it may have helped too. With no sense of time, it was easy to sit back and not think about it. Time drifted by and I existed. That was that.</p>



<p>I actually did ask Siri for the time once… it was late in the experiment, and it felt like I had put on the blindfold forever ago. As you’d expect, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031774</guid>
            <pubDate>Mon, 09 Nov 2020 05:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Constraints]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25031762">thread link</a>) | @mkfeuhrer
<br/>
November 8, 2020 | https://www.mohitkhare.com/blog/postgres-constraints | <a href="https://web.archive.org/web/*/https://www.mohitkhare.com/blog/postgres-constraints">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><p data-v-70187a8e="">Postgres Constraints</p> <div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><a href="https://www.mohitkhare.com/categories/postgres" data-v-70187a8e=""><p>Postgres</p></a></div><div data-v-70187a8e=""><a href="https://www.mohitkhare.com/categories/programming" data-v-70187a8e=""><p>Programming</p></a></div></div> <p><span data-v-70187a8e="">7 Nov 2020</span></p></div></div></div> <div data-v-70187a8e=""><p><img data-src="/_nuxt/63ad73275483584243aebc1fd69ef658-784.webp" data-loading="data:image/webp;base64,UklGRgoBAABXRUJQVlA4IP4AAAAwBgCdASooABQAPrVUpE2nJKOiJWmY4BaJYwDJYQAKoFAB7kBcIIWHmJt9ZaBV40LzWjUry2QaaEQAAP74lTicra5rKSznYhK/eFaS4dVB+7QvzV2yPYbWUlxMrpz05N73X3b6B6rHrST5Ka3bHoSksnKFvvArong89ZLtdBEtzVjIcV2PqpFTYYGj9zusV8MytzLt/d9q7IjLLhrcMbost2qo1PBIeZoDGl3dsVjSoUlQSgG9dwBUUWxA0LtwTDYea8YtLezljE0O4N5NIQNKZ0fYH9TLqtNX6K92xjciU4hWo570XkAqdyf7mR+6BTuqoojNjOCbhcwgIuAAAA==" alt="Postgres Constraints" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/63ad73275483584243aebc1fd69ef658-784.webp"></p></div></div></div> <div data-v-1bfa12aa="" data-v-70187a8e=""><p data-v-1bfa12aa="">Get latest articles directly in your inbox</p> <div data-v-1bfa12aa=""><form action="https://usetaski.us18.list-manage.com/subscribe/post?u=2974614c11e6abca644007be7&amp;id=3b5ecce493" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate="" data-v-1bfa12aa=""><div data-v-1bfa12aa=""> </div></form></div></div>  <div data-v-5c76b055="" data-v-70187a8e=""><p data-v-5c76b055="">Liked the content? Do support :)</p> <div data-v-5c76b055=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/5021b7226315080e2ba0e37576a90ee6-320.png" alt="Paypal - Mohit Khare" width="125px" data-v-5c76b055=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/img/7c718ef.svg" width="175px" alt="Buy me a coffee" data-v-5c76b055=""></a></p></div></div>  <div data-v-70187a8e=""></div></div> <div data-v-70187a8e=""><div data-v-3d6db495="" data-v-70187a8e=""><p data-v-3d6db495="">Explore more</p> <div data-v-3d6db495=""><div data-v-3d6db495=""><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-423c8b1c=""><p><img data-src="/_nuxt/58c006b0de508ad0918f13aae4a9fd4d-613.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAbCAIAAACBclo5AAAACXBIWXMAAAsTAAALEwEAmpwYAAAHzUlEQVRIx4WWfVAU5x3HrzRBE3Q6IbGpqbFjpslMp21MooUkjCYabRtTElNGIsMfKUlDtFZjMmpMTKJ0agK+kIrgCeEugBoReROpHETgXrg7wJT3t+MOOA5u72X3dvf2du+du/6eXTg4ipb5zd6zz+09n9/39/s+zyJye3ws56EZlqScDoo2T093KmWN0hOKog8Ga7/C1VJCLbG3FdtVRfa2b+zKQhjgaHARhUIMMzblRZviolUutrYWQFhaC7CWApO+zeMNNbdWHz6+9nDW6oy/r3p158qnn4vdlbFyz5GHn0mIFXm8fs7tdbFuYDtI2mAYGxsbH+jplF0+rSg+1FX+xVSL2KEtsauLbapZME8t5AMNbAoxCvkFBFaILc3nzP0qzK7rGZJeqyjZ8fpjBz9/dH3ifYmbl7+d+ciLW5f9duP925PjEFhgs8CmmeqqqrxzuWq1empqsvXm5duSTzovHTXc+hpXS5BQVRHSpxTPKkaiBfZFBAbRt/9l7qyy4Q4n458wde8/8mJcnOidfQ8n716xYqXod88/uOPNFY//IiYhadksWGAzLg7HSYN+5FxuTmVlhdVm61A2tZSf1Vw6NnwjG1MUEuriea2gkgfPypUX2OQFmFJixaYoJ0vTdCgUVqoa3twdt/fQI2mZP1n7RMzadT9+6Q8PrP55THz8j+bB0GwoOHQaBhqNZnNSYn19HUXTfT0/qG6WaK+d7LmeZWw6h9io2ogNSAQGpEJslV+wtORbxvtJJ8c4XS4XByUcGm5/b++vk7bcvz4hdtWjooRNy5O2Llv105gNLywXRahCuFiOohmSdtbU1KTsTG6U3QLrGQz69ubaO3X5Xdf/OVKXjbcVQ9mR0FlniZG5mvOw/mYHzTqByroB7GRcOE5/eHDful+Jnn3+wbR34/eBrTbGPr4uJmFzrCiCFAI1G0zudEE2Q0PD3zc1dXd3gelwnOi5o1LXS7tqcweqT0435wMegeVivsEFls5KO+GAH0K/XJwHudXJcJy/qeXKwc8fe+Kp2D0frd7+2orfPPPA/o9/+VrKusVggQ0BiXNuHyzR29uv1WrMZgtFu/QjA5qmys66goHar4wNuWiDqZB0i6rYOm2koMguFioMqYNiALNcUNXxneY/n2W+vz317Z/t/kt8YtKynWlxGzfdtwQ4guezZlnOaxgb7+7uttnsJM1gmLlL23xHVtpfd2b05imrohC6i43+gFoLWM7D8nIBzKCzgR6fbDdbVARBXK46+OX5tady0w588NfPTr4yb65FEcFD3sh0pBOzWM0YBvV0OEj9cK+uq3X4dvFQ1QlLjwwnnU4k1h0N5hwUSRC41aanqMCQ/lp9yxsEqfd4QpSTnAd7fYGF4Mit4DjAw4r9A4NQdhfroZwuC2Ye7dNOD7YRdhvt5Fw8VbDInLlYioZDiSIchIP0GE2KcVO5HXfYcbuDZEQC426xULqw2QiCRCtCzhRDgHqapdHmQWm5eXMg6hwYvkInMUk6SJfFOopZ+kkK1R9+K7oH9X8zQJXkzziwLs2vy/CNELTOy53rMTwAluTZNOgmHDhJwS0Dk/9H8ULwQvURAOorj5xNa2kwAwFsAQkB81E9vjd1oe9m9fFXgSpkEwVGO8q1kC1QlwZHbOXm3EGff2YmHPAHIfy+AKweeSaCEUJoLcPDhO4yfDjnRc/yIrGEYhj7fIFgOIwx3KRp2k45daZpk9UenAl5vOgBH+QRCMAtBPoIh/2BoN8fhK/8gRlhKfTKAfacaAghich4iR77fH42MKOorJClvlq/5dlvk7ee3vPu2f17e3r6AAIxotN/W1I6YTRhFjtmsY2NT1ht+LQZM2OW8QmjxWq32fCe3j44cT0eX4S0KBa7Gh4FrS1XyhoTn9T849PWinLpp4dPp/35yz9tq6i4DtUOh8NyhfLCBXHZpctnzpy9erW8tvZGSUlpZWWVRCKFQVVVdUlJWXZ2DiTq9frhlSOYPwrsigaDemiq0UY0vv6SKufEgNFU+sVR8ZWrkqKi01sSmm7cAGowGBo1jOGEY3hE19qqGBnRGY2TDTKZXK5okDUZxia02o7qmtqGBpnRaIKCC3IZvvF3VSwIGuntk72yoaNdKz/0N+XLTx9L33W9uqZq5zZNYf5MOOzmPNBXWNEH/Qyh7sKiMAMDaLaXb5yP7zfHeQSLueYcd1cwKEZg3Wjj1uc6vpd1fFeqeuGp8sz0Tp1enrxJKS0CMJRkaFiXkfHOmbO5pWWXjh8/IZWWpKenf1Ms6R8YGh4ZhewFWwkOjwQ/w/KBxvNgSNPH7xzKH7q1L0Px1h+7dKOKzjvdk9Pa7OO3tm3UGcZ5VWFo8JEjH+8/cCAlJWXNmjUVFZXxDz109OgnqampcIUHhONsFjm3rRewebDAi4SXF63TG+re2tG8bUP7h+/Jd/3+3y+vV9fVBqDObi+QwcaZme+fzy8ov1aRk3MqLy8fXFYskWRlZeXlnYf6MwIvGizw5orhXgwW2gOrT9kJVZm08dhHzV/nDA4OAdXHVwW2cgCaGwrN8JsYsvT7A8IVihwMzkSdX5GIKjgMlgLzq/uD8AfLhcOwKmC80ScMN3dYChhmDsDwb092EXJxtdHM0mCh5l6Pz8cHbG6hEvd4bXCRE5R/cyyscLRiKDX6b/C/A4aUTsbNY1cAAAAASUVORK5CYII=" alt="Personal OKRs for Success" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/58c006b0de508ad0918f13aae4a9fd4d-613.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-423c8b1c=""><p data-v-423c8b1c="">Personal OKRs for Success</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-423c8b1c=""><p><img data-src="/_nuxt/e988377883f08d1ca218d809e931f11e-1000.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFEElEQVRYw+2W+1NUZRjH959ouLUTlwCBENIihL1x2cvZPec9e/bsBSIGAUVNblNc1AVxOexZlkYmIsxLTeOAEBREXJRRB9AxDaSZRCWgZtRJCsvCJiYVdpees8usdGfj0i+888yZ95x93/fzPN/3eZ93eTqi6n8x3gZ4A7wB3gCvO5jRIVZHmLnOeoK1yKJVGHW4SUda/hvbY7CeYGiCTVHty39BnBYcS6sqnKEzaw3mFKYx40mBcjBc1suPN0bgatKsX+uIDQRDEFZWmnZHhI8FookQ6pyfcHt8Dq2u0ePMmoANhNmAM1rSqkvM78fwiS2oJ0zZH6Ya4UvZEAVOMCkwgGD0y0635YERS8lKEVGVLd5bFyYYV+DnY6iBazc/Otl21lvU4htXEoVrcZNaeUiDHVjmli8DjMx6Zblpk6RsC94XhrWGCr9SUQPRRHfPuUbrkfPe4hY/UTdfdCJGW/K8av9zGIVY/cojhhxWk9bcpN1fhErb+cJBb6I5RDRBUNdDibN+4kF+wueBqia/uI+9pAP+WH9kQl+AlE4uWs4Z+3cwSVpLknbc3IQ1+gran5I0BsWPEdS1CDQaQo5uQkOBykafbS1eog4f8UCUbMBfbkjI05LVOnzFYA2qzpQWDDwrqAhVpCYV74nRjsgVY1HUUJBqJBQf8lfU8wWp4r1Zgl2NkUnN/mIKCgu3zauRXFq8Mjs2XS/bryer6sOlg2Lp5It0c7DwTHDyxWfkx7235r2UQdC16Qm5GfE7aGRZzeME6mmQNUtR+GmEtH2zZFyoaQoTtgdIOvkJnb7basMRCfJAHQWRV/M4waJ4JVTKdKzocrSy118yHCf/IEzc8rSgxSfusn8SG0kjkoWDvvwywvOkRFvSsJLhaKw7QFa/FWsLjT/qFVMblHgjQMps1iLS4lHx8gCsQZYMZWlnhHCnMM+AFxfFi7JiZaRiX0M4zobjiLKuCdh5FbIvY2WZ4hwS1aThr2WpaU2ymrudFMZMYY7Ww/vRs0tCS1TRpMVAmvGk8uajXeUF7xDSg3rSQpOWdfgjwBhIViExDn022fBmtzKhDPxYh/t40Wgl8+3Uj6e7hjGJ0aBeLBcpatZlTlc8AUMoME2PzK75i2mFzK6n62MqxZKyiuKCEwsLC3du3QMGWIraAgOQtAKUx5PLKcz0z2w9WgKGoWrFIZhJqyqRrALMuSILVRcWpVUM/ASmUZpgg/t6RxacrbqyNVlQCq7AgLrDnRf7R7s6ruTufJtSmNyuL0XowRBnPHdY4O+BovcvXbgxOX53ZGiixvyh0/2DGYY3tDiT/Upt66kLfT1XSwrfLc4/Mfd43gW+fWv6k44rR+q6e7uG4dVut8Nz5qdf8nIalInlIKEbCXlAyitI+SEw8JIHUcNXYNRWt9tt3DSHw7Hg4BbtaLsE7sMqX09OTX834yLNzj68/8PPi8N+34Bqs9nn5mzQvz56e9f2OlpZmUpxpwD0A3zhnqOv5x7bnfnW8JUJHqQG8DNTD39/7wFMmJ+3AR7mu3x3N6DYnN9dPDcVOrbF8U/8cAVwb3omXWeVifbD1jBlp0DIh78+evTw8YOZWZjFSS0XHTAZG50uO5aSOLhzRY5nf0Jy2P8Y65+bzck+03PVZGw63nDatbJbI3jlQV68ml0/8eXdv1RvJc3OqeNw++FSi3Pb6QTvvWN9U9/cX3Wqm23/G3l4kDtuZdaz8WzztqXqr1v7DeOTH/N/KPjZAAAAAElFTkSuQmCC" alt="Making Decisions: The right way" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/e988377883f08d1ca218d809e931f11e-1000.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-423c8b1c=""><p data-v-423c8b1c="">Making Decisions: The right way</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-423c8b1c=""><p><img data-src="/_nuxt/755f7f3a578954e44f3b07ab0c6debea-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEEUlEQVRYw+1WW0hbSRgOFNanug+CVXxYlWi9BrO1+BBpC6XQy1OfFJaCpcIKuwuLUGhrK4oYtcULWu9RXBcvVbNGI6s16x2lrZfE1tbGKxVtjTG9JEZNTs45/TzT1ZgYm9K+FM73MJlz8s985/vnn29GcNwNhISECIXCqKiotbU1lmUZhmG/GgKemCfmiXni7484ODhY+DkEBQUFBASIRKJvSRwZGRkdHX3iUCBALBbHxMTodLpdYpPJ9MFtINiRWCqV0jSt1+vfugb+tVqtNTU18/PzZNjW1lZERISHh4enp+fRQ4EAhIWHh2OIfbYEBQUF+KEo6pC02Gw2tE1NTXNzc+TN9va2RCLx9fX19/f/yQ4BTggMDPTz84uNjcWQfcT5+fl7xNxbBhnY2qStFub/Nw7EZDBaBDIcyCMAWZsHgcjdl+o9Ym78pnr0nfT2+h8Jhuu/GR/8bds0H6gYme/q6hoZGRkeHh4cHBwYGOjv7+/u7iaRbhXXJ2KLBa3h0cDrsxKdRPz+4inDhZMrkgh9+i2aYWknYijIyMiQyWS1tbXV1dUlJSWFhYV9fX1fUNWEmKZs26ztZtu18Wjh/K+/P6jvHZHnmTv8TP/8QOnbaS7UQXFbm0Iul3d2dv7LAepHR0ehG/QKhWJ8fBz9hxw0Go1LYpZhV94vn+68eC/tTHFl3+n7T+IrplZexLHPBdSbVJsTMbZHXV1dRUVFcXFxeXl5aWkpOtDd0NCA5OODWltb6+vrlUrl1NQUvmBHG00fTKwzrZ2rvXBZcelGsyLqT+WlrIf6Z+dZjYB6LXUmRqqxtCqVCuLa29uheGlpqbe3t6enp6OjA4uNztDQEOSiFBYWFpxtZ19VX1feEBWJr7Yl/FKXK1MlsE+PmB8fpTbUNONIjPiioqL09HTCmpmZqdVqoRJpSE1NzcvLq6qqyuWQmJiIT3Sp2EpZ0b4yLMX/dSUs9+czMtFzlYfpvx+NCyVcVVPOxJhOrVajhT5S2KQzMTEBrRCKxZ6ennZlEnuKGXZH1zuzQfa4UT50x/Iixax/xMUwztsJa5yTk1NWVoaXEJeVlZWcnIw6T0tLq6ysRIXjMSUlpaWlZXc3OhIjG8SJ8PcOPXEDZIYzDxsHC7fZGhsb7Q0EqaM47DoJwlDtmIrYhZWDy+2EpXLTMpubm4lXE5MyGAxw/42NDXTW19ctHEBpNBqJ+ZOzYYUDzMuROC4uDpnJzs6+6xrIKlYkKSlpeXl51yw1avXY2NhLrXZ2dha7FuuNzurqKjb04uIi+jMzM4ifnJzEquOkcShsAZzd29v72KHw8fHx8vLCjQA69o23m8jZwO1t/IBUh4aGhn0OONRwCcGRbH8eO0z6pbcD/rLHE/PEPDFP7DY+Aj8diF6OEZ/ZAAAAAElFTkSuQmCC" alt="Boost Productivity with Chrome Extensions" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/755f7f3a578954e44f3b07ab0c6debea-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-423c8b1c=""><p data-v-423c8b1c="">Boost Productivity with Chrome Extensions</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-423c8b1c=""><p><img data-src="/_nuxt/8aca56b2b6f66cbaa13ebd461ec75744-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEnklEQVRYw2NQJwJoaGioqKgYGBi8evXq//////79+08xYBi1eNTiUYtHLR61mBSL1UBAHYRgNqmpo7BpYrGGhromEGioa6iraaipaoDt0gSywfaBgDpISklJSU9Pn5oW5yaFH10z+ci62Tsa3TdPzlnVm7mmLuT0jOqTS8tWNiXNyLE4syh/SYH1smKLgiC9h0+pZ3FHXfH36zt/Pjz9ZGHYw93997Z1PVxT9v/m7v+3Z96dl763wfz/pe6bU4KfLwmfnmN15+ELuMVfv379TDT4+uXLf1TnMtTlxz/cPuH5rik3eiwvrap5cmz13b1z359Z/f9s591pQQfr9b9syzzUYLO/xaY1wfD+45cQbT9+/DA0NOTl5RURERHGC4AKgMqA6eP79+/IocXgZSydZ8na4CV6fGLUoaU9hxe2XVjZfmp+2erm6EBdbk9NzjAj3iwrjjADTjdj+Wcv38AtNjMzAxoqIyMjJSUlKSkJJyEAwpaWlgYqEBUVNTc3R7c4z9/4Up/nwQUNq2f2zmvK3D2t6OzcnFkFbuUR1jEu+iFutllh7ulWvBuq7Upjne4/fo6s+e/fv7/B4C8YAMUhIj9//vwHBt++ffsKBkAGehz3tDf8un902YS60sTA1qzA3oKgzmyfJQ2xVzb171vY3lWWOrkutzlQ/vai2O6CgLsPnkK0/fr1a+eOnQcPHLh06dKVK1d27dp16tSpLVu2nDhx4vLly3fv3j1y+PDBgweAAYMzcXXWFtzfPWtpX8W66U3HVk04smrSrgWdG6ZUnlw77eGFo6e3LS2NdKryEDnW6dSc5nrv0TOINqAPaqpr2traent7p06dWlVVNW/evKysrEkTJ65bt+7AgQP9/f09PT1fgGkKRy5gKMlOfHz99I1jW/ZtWLRgWs/8KV2bl82+fHjzrWMbH53c8P/9vYV1sdE6DO7qnHYGSi9evUYLaiD48+cPMHgh4j9//QJygWxgaEMYOH3s7Wyxc/PKFZv3lNS0FFXUFpZVlpZXNtTXzZkxae+m5TfP7r+yoX+SN2uoIY+dvhrcYiB48+bNx48fgX56BwZAm4ABC0xBnz59ArJfv34NjFqg+LOnT58/f44Z5gwtFbmfr2y7c/Xc60e3vz+5+uPp1Z9Pr/x8cvHr/TNf7526tGf5zAj1+V4Msea8trqqL2EWAz164fz5M6dP37xx4/atW+fOnj1//vzt27dfvHhx/Pjx+/fvQ2IayLhw4QKQDXQiWpgzNNeU/X937+nlI/du3Xj/8NLHm4ffXj/66vbxN7f2v7+99+r2abOi1FttGNItWd2NlJ6/fI2qH2EQRBDkpj9/IGxIOscZ1K21pf/f3vl45/SHO2dfXT/x+e6pz/fOfLp3+uv9ky+v7F/Snr26yrPJnfdsiUF5tOWDJy+Q7UB2BKnlKIOPp1tNaX5pflZZfmZxTjqIUQBiA1FJboa3o5Wvg0mkg0ahn5m3k+mz5y+pVlYrKipJSklLScsAkbSMLIQB48ooKqsoKqsqqGhIyClp6+hTt1rU0MQNINUikFJXUwWWty9fjjZ9Ri0etXjU4lGL6W8xAIU/JG106R/JAAAAAElFTkSuQmCC" alt="Improving Reading 101" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/8aca56b2b6f66cbaa13ebd461ec75744-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-423c8b1c=""><p data-v-423c8b1c="">Improving Reading 101</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-423c8b1c=""><p><img data-src="/_nuxt/7d79089f0176c12135db8901018a0f3b-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE8klEQVRYw+1W6U/bZRxv4F8giEAMJBhgkAnJwjLfmMzEbS9MFuWFJm4sgEOQTWRcy4CBAoVSekEvrq4ctqWFFhgttJylXHITbgQ55CwDFghYQPBDf66rBZnHErOknzTf3/P7Pk/7+d5PSe5/Ax4eHm5ubj4+Pmtra8fHx0dHR8f/GSQrsZXYSmwlfvOI8aMXXgUvLy8c8/X1XV1dfW3Erq6ubxvh4OAA+ZYRhMbJycnZ2RkLR0dHKD09PfV6vYkY8rd/AkvigIAAkUgkFBaJxeLS0pIyiUQslpQUF+PD5/F5XE5p6Q/FJSeIiIiYm5t7bR6zWCw8nunXdLrWZm1rW1t7b3dXQ1OzVqttam4pq1Q2NzWu609SW1xcPDk5icXh4SFkZ2dnUFBQWFhY6LnAgeDg4JSUFAunSTQafd+wl5RO/ySOc/lLSjRTnMCWXAmh3ojMThaobqWWXotgJaRlra2uiMTiiYkJfGd/fx8yPz+fRCLZ2tqSzoWNjQ0kSsRgMJhHi8ThcAd6u28/5nsGsfxCc77hPPUOZngH0n3uMr0DaZHsqg8eFNyMYTc2aBQKxdjYGL5D2L6+vt5pRFtbW0dHBxaQWLe3t2PR1dVlUgKDg4OWHnO5XJ1O5/+Q6x3E+Cg6L0feFpervBFbcDGYdjWSz6rQRfGVHz9g6bTNcrncnHhjY2NkZGRpaWlvb29lZWVxcRHNtru7iwKEcnx8HK9Qwj5UhnlV/kHM5nCG+nsDk/Pc79Cux+QnPVFHcqsfFdS+81laNO9pSpHmHrvmi1jq0vxMmVRGhNrkcXZ2NplMzsjISE1NjYuLY7PZFAoFKZAZwePxaDRaenp6+L1woVBoScxksXaeb4Qm0i/ezb4WnfcVvdwnmB7Dr3n3FuXz70vDmfKo3NqEdDqOikRiorgI4s3NzYaGBrVa3d3drao9QX19vVKlQkbqNRqEuq6urrKqSqNWz8zMIDyWVc1gMPDIYPKu3Od9GMn7lltzPU4A+gt3qJdCmJSy1gKZUiB4gjNFRUXmVY2wM5lMKpUqlUorKysLCwtz+XxoYA3W+Nn4+HiqEfPzC6ebkEShZOJRIZN++pDnG8ZP5pVJlC0hDMV7QTT32xkx+Wp5jYZKow8MDJSXlyNzJo9nZ2fhYktLi0qlgtPT09OQRHFNTU3By76+PlRPY2Mjts4gzsw8If555qfYFFoYWUDOzMrIkzBlWr9QllcgLYGvSM0RJqZSJicnkDaCmPAYNFFRUfAMsUWaq6urcQBTAU6j45FppP9xUhIkjDOZ+5IYoSDMGRwckMukFYpKgbDoUSb/cjjX72tOxHeM4f4f9cYBguFFhNpkOywgxiGhMbzAnhEHBwfYwuvpefmSGIdMqt3t52RuyaUwzvsReYmZ7M1nekJvQbyzs4PC3tra2t7eXl5exit6CTToHEhUE7Yg0VpotjNmNRFqHAU3JJzYN/wqFEmv3mfejGaVycoPjXqiuJA883bq6ekZGhpCmw4PD2OBKQFlf3//6OgocozUQkKPVyI7Z8xqk8eEN78szNeqNRg78OMkpMbd06E+H0dG/OUl4e/vjzbHBCC/QFpaWlZWFlJAp9MxENKMwCuuhIWFBfNr0QLmpr/SOJKLiwvuWoc/g7iV7e3tiS1cyXZ2dhj0pyffv78Wcb3/P/9ArP8yrcRWYivxG0f8O49FUp+RTJP8AAAAAElFTkSuQmCC" alt="Transactions on Postgres with Golang" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/7d79089f0176c12135db8901018a0f3b-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-423c8b1c=""><p data-v-423c8b1c="">Transactions on Postgres with Golang</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-423c8b1c=""><p><img data-src="/_nuxt/f2694ea112a372daa3fcf90c076889fc-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEiUlEQVRYw+1WSUwbZxSeQntp1KoHxBJUBCpKIeQAUqscorRVlaKqt1YcKvWAWhSpBzZFIKoACkLBZjNpIRKrTezYgCEoFAqBIlybTQaMHfadmMVgA8YYXC94mX7MUMcMiNI2l6r+NHrzzz8z//e+997/Zoj3L4CIiIjw8PDo6OitrS2SJF0uF/mvQXiJvcReYi/xf48Yi179K0RFReGxmJgYnU7nJoZ1XBhOp5NJHBYWFhQUdPksYD6QuhUcHOzv7x8ZGbm9vf3KFMfHxzc0NHC53NqT4PJ4IgFfLOQ/qq2t4fJEdXWpqakrKyt4BwpgFQpFcnJyenp62rnAAykpKRwOhyGaKCsrw8lut3vO0orW9x1jBqebSSgUzs/PY3B4eAhbXV1NEISvry9xLnx8fGBRKDabzTNaRFFREU5Wq81uP87HIeWEQr17q/DXm5UzqTJL56IJMwKBYH5hAQPad61W29PTI5VKe3t7ZTKZlIJEIsEYFuPfKEgoDA0NMRUXFxe7FcMbh/PII+nc1o0CybXsXz7lzsX+bIltMhhIUlwnnKMU015bLJbNzU3U+eLiIlKgo2A0GtVqNSzmURCwGK+uruJhZo5p4nK5tmJ420Gt2PJcE53b9V5mxwe5HXHi1din5s+fGHROsrH+mJiO/OjoaE5OTmJiIlYoLCxksVjl5eWIP9I5Ozvb2dnJ4/GQR8xnZGSoVCp3qI6JSzgcnD6qnL50T5n2TFMhWwy/2xqY3nqzSDLyYueB0vah0Hir8QQx/f7S0lJbW1tXV9fIyEh/f39fX9/k5CQI6GjPzMzAs46OjpaWFqVSabVamYqLKMUv9OYvRcv+7IkQliLkh/bvBUOavaPgsIYtMULjJ2KD1kk2nVQMPkgsKCioqqrKy8srLS1FuUDlwMCAWCyuqakRiUTNzc1yuRx+MOS+DDXpdNxpVL2T2ReYP3mZ/fzhoI6+nSu3XBMYb9QbNj2I6SWQS0hB+bS3t8NOTEwgwt3d3dC9vLyMW1AMJ2DHxsZO736CQ4X6m+pB4rv66/c7vxIuvJmjejtX9W2z2mp35its4bXG6yLDhoOpeHh4OCkpqaSkBMGEbiQV9Gw2u6mpCdXO5/MrKipQBFlZWRifoZjO8Rc/ST97IFvV/+5wkbefqt/IHvXNVn5cOf11q/7Ko/2Yx7uexO6WaTab7X8C61ooWCkcHByYTCYzBUaTOBHqA7PNbHPQOwpH2rP11zKVr9+Vv/vj0tXHppBK/doh+eQk8Wn8rVb6ch+7aCAm1Ov3pVoiffCt/IUrfFNyzz5m6kTHnevV9Gq6c6Gfub8k9qPjKB8PBzS32zZUW7i20Z1rwaNzoTOggej1+r29vbW1tX0KCOz6+jqCvLOzo6egpnDGdsI2ON2rGWD0app4d3cXpYtiRmOanp4eHx9H9YIJg6mpKY1Gg3a2sbGBMeocDjGJ4+LiUJnYiOxTYLHcBwsZSUhIgLKLh/r8x4jQ0NCAgIDAc4EPs5+fH/4FGN9j1ym4Jz3pz/SAwOf9n/2BeH/2vMReYi/x/474D5XblxQw5EkNAAAAAElFTkSuQmCC" alt="Improve your productivity with VS Code" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/f2694ea112a372daa3fcf90c076889fc-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-423c8b1c=""><p data-v-423c8b1c="">Improve your productivity with VS Code</p></a></div></div></div></div></div></div> <div data-v-70187a8e=""><div data-v-39a855d9="" data-v-70187a8e=""><p data-v-39a855d9="">
    Liked the content? <br data-v-39a855d9="">
    Support me
  </p> <div data-v-39a855d9=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-39a855d9=""><img src="https://www.mohitkhare.com/_nuxt/5021b7226315080e2ba0e37576a90ee6-320.png" alt="Paypal - Mohit Khare" width="100px" data-v-39a855d9=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-39a855d9=""><img src="https://www.mohitkhare.com/_nuxt/img/7c718ef.svg" width="150px" alt="Buy me a coffee" data-v-39a855d9=""></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.mohitkhare.com/blog/postgres-constraints</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031762</guid>
            <pubDate>Mon, 09 Nov 2020 05:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 Billion USD ICO From 2017: Clues Emerging, Finally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031582">thread link</a>) | @npguy
<br/>
November 8, 2020 | https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Travelers aboard a luxury TransAtlantic cruise have shared pictures that many in the crypto community believe could provide clues on the missing 4 billion dollars raised during the EOS ICO. </p>



<p>DoubleSpend’s own analysis based on the size of the box show that it could very well contain the amount in USDs that was raised in the year-long ICO.</p>
<div><p><a href="https://twitter.com/share?url=https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/&amp;text=Object%20Floating%20In%20Atlantic%20Ocean%20Could%20Contain%20EOS%E2%80%99%20ICO%20Funds%3A%20Sources" title="Share on Twitter" target="_blank" rel="nofollow noopener noreferrer" data-postid="409" data-social-network="Twitter" data-social-action="Tweet" data-social-target="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/"><span><span><svg version="1.1" xmlns="http://www.w3.org/2000/svg" width="29.71875" height="32" viewBox="0 0 951 1024"><path d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"></path></svg></span><span>Tweet</span></span><span>0</span></a></p></div>		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031582</guid>
            <pubDate>Mon, 09 Nov 2020 04:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to working remotely and smashing goals]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031490">thread link</a>) | @veebuv
<br/>
November 8, 2020 | https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals | <a href="https://web.archive.org/web/*/https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="45d72c63-4641-3f9f-f271-8df897413c12"><p>Alright the future of work is here to stay and we all need to prepare for the best remote work practices. Regardless of what happens, work has changed forever, people will go back to the office surely, but the dynamic will now be a hybrid mode.<br>‍</p><p>So learning how to work remotely will be a skill in your arsenal that might just propel you to your next career promotion. If you've asked yourself the question "how to work from home" - you've reached the right place.<br>‍</p><h4>1) Create a routine</h4><p>If you want to succeed working from home or working remotely this is a must, which is why it's the top position. You need to build a system that builds a body clock. I used to get into the zone when I got onto the train and grabbed by morning coffee at my office, when I couldn't do this anymore I spiraled. This was until I started building an atomic habit again, micro habits that signal the mind for whats about to happen next. Nowadays my trigger is early morning juice, similarly so, build a routine. Get out of bed, go to the gym, have a process.<br>‍</p><h4>2) Have your creative work space</h4><p>Separate your living, from your office space. Even if it means working from a coffee shop. You need to keep your area of comfort for leisure and work for work. This is an important work tip as separation of concerns as well as "environments" make a significant difference to motivation. Pretty much the same reason people go to libraries when they can read at home</p><p>‍</p><h4>3) Set time boundaries</h4><p>Its very easy to be sucked into 24 hour work when working from home. One of the keys to working remotely is creating time boundaries. Employers may feel like you're available to message after work hours. In addition you might get FOMO from all the slack notifications. Fight the urge, set your boundaries. 80% of 130 people I spoke to said they were constantly fatigued from working from home. This is a very important tip amongst other work from home tips and tricks. Stay disciplined to time<br>‍</p><h4>4) Leave home</h4><p>How to be productive working from home ? Leave your home. Ironic - I know but cabin fever can creep into you. As humans we need social interaction and movement. Step away from your home, go for a walk, meet a friend or better yet exercise. This will stimulate both your body muscles as well as your brain. Feeling fresh air graze your face makes a big difference, especially when you're glued to your screen<br>‍</p><h4>5) Plan meetings with work colleagues</h4><p>We've been remote for nearly 1.5 years now and I always advice social meetings for working remotely. Catch up with any team-mate in the same city as you and make it a monthly if not weekly thing. Building bonds with people in real life not only helps you create long lasting relationships, but also helps you connect deeper with another person. 70% of communication is non - verbal, which you miss out over zoom calls.<br>‍</p><h4>6) Reduce distractions</h4><p>"Minimise the number of distractions you have in your office" - simple yet sage advice for working remotely. We've got a concentration span of 12 seconds, with slack messages going off every moment combined with our innate nature of not wanting to miss out on important conversations leads us to doing absolutely no work at all. I encourage you to embrace an async first work culture, tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> help with async video meetings or even loom for screen recording.<br>‍</p><h4>7) Have no meeting Wednesdays</h4><p>Meets really hurt productivity. 72% of managers say meetings are a complete waste and 60% of employees think they will work better without meetings. This is the same reason Zoom fatigue is becoming a big issue, because you need to have your camera on and focus the entire time. Try encourage a culture where you have certain days with no meetings. Any conversation that needs to happen can occur in an asynchronous way, weather thats via tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> or vidyard. If you're reporting bugs, use feedback tools like bugheard or <a href="http://remoteworkly.co/show">remoteworkly.co/show</a></p><h4><br>8)Avoid unwanted meetings with conversation bloat</h4><p>Focus on getting work done, try set a decorum where you can leave meetings you're not needed in anymore. Teams that embrace the concept of async communication will win. This will reduce anxiety within teams, improve culture and make sure the meetings that do happen are purely focused on value and outcome. This can be done using tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> for async meetings and startups or even voice notes like recordify</p><h4><br>9)Start with the toughest task</h4><p>There's a science behind this but it works. We often think starting with easy tasks gives us the feeling of accomplishment and builds up momentum. There is some truth to this, however by the time you reach the tough/long task to complete you're left drained of energy and delay it to tomorrow, which never comes. Start with the toughest tasks, its the best way to be productive working from home<br>‍</p><h4>10)Over communicate</h4><p>There will be obvious disconnect between you and your team mates when you're remote. That is the nature of VoIP communication. So make sure you overcommunicate. This does not mean to spam people with 100 messages, but rather use video and tools that capture as much data as possible for you to make it easier for the other person to understand what you're doing without having to reach back to you."</p><h4><br>11)Leverage asynchronous communication</h4><p>My favorite tip in my list of remote work best practices. I strongly believe async communication is the way of the future. Leverage using async communication whenever and wherever possible without organizing impromptu/time blocking calls. There's several tools out there that let you take full advantage of async communication, <a href="http://remoteworkly.co/">remoteworkly</a>, <a href="http://loom.com/">loom</a>, <a href="http://vidyard.com/">vidyard</a>, <a href="http://marker.io/">marker</a> (for website feedback), <a href="http://remoteworkly.co/show">remoteworkly</a> (for QA feedback), <a href="http://trello.com/">trello</a>, <a href="http://asana.com/">asana<br>‍</a></p><h4>12)Use productivity hacks like pomodoro</h4><p>The pomodoro technique is one of the best productivity tips I came across. Its an old technique that lets you cut down your work into an investment reward balance. This builds another atomic habit loop where you learn to enjoy difficult tasks in anticipation of the reward. Your day is broken down into 25 minute work chunks of pure focus with 5 minute breaks, do this 4 times and then take a 20 minute break, rinse and repeat. Checkout timechi.com</p><h4><br>13)Share your project progress</h4><p>The easiest way to start working when you're feeling down or demotivated is by sharing your progress. Social accountability plays a big role in human motivation, something about putting our reputation at risk that kicks us in the behind. In addition, sharing your progress becomes a incredible feedback cycle, where you encourage others with your progress or cause them to reach out to you and motivate you to push faster. Lastly, having progress updates is a great way to look back and see how far you come, consequentially motivating you to work better</p><h4><br>14)Avoid jumping on impromptu phonecalls</h4><p>This rolls back to my earlier point about async conversations, Paul Graham mentioned that one of the downfalls of remote work is impromptu meetings where a large number of incredible ideas are usually generated is being robbed from todays workforce. Yes this is true, but on the flip side, most of the inefficiencies in working from an office came from these "tap on the shoulder" interruptions. I no longer pick up calls unless the message following up says "this is urgent", your concentration is sacred in 2020. Protect it at all costs.</p><h4><br>15)Set clear expectations for each day</h4><p>Employing a daily manifest of long term goals, short term goals, micro tasks as well as schedule has been a game changer in working remote. You almost get to "grade" each day in terms of the success you wanted to achieve and what you did achieve. This lets you work out what is the most effective work from home schedule for you. Each week, analyze the good days and bad days, pick up patterns that lead to bad days and those that lead to good days and optimize to focus on the good patterns.</p><h4><br>16Share with video whenever you can</h4><p>To prevent the feeling of isolation, use video software whenever you can. <a href="http://loom.com/">Loom</a> is a great place to begin, or even zoom for work meetings. I know it can be daunting at times, but it provides a great path to building deeper and more meaningful relationships with teams. PS - when you're chatting, look into the camera and not your screen. Makes double the impact</p><h4><br>17) Ask for one on one checkins</h4><p>Do NOT cancel your one on ones with your team mates, they're more important than every given there is no face to face relationship with your direct supervisor or subordinate. Use a template with a clear structure to find out how your team is doing, how things can be done better. This builds trust and encourages them to keep motivated even when people feel disconnected.<br>‍</p><h4>18) Bond with your team beyond work, get to learn about their family</h4><p>Use tools like <a href="http://donut.com/">donut</a> to encourage your team members to learn about each other. This is vital for new employees who don't have a chance to meet new people given you're restricted to a computer, donut runs introduction meetings between people. Encouraging that communication between new colleagues is a great way to improve team bond, morale and company culture</p><h4><br>19) Exercise</h4><p>Yes, do it. As human's we're not made to be seat potatoes. Despite how tasty potatoes are, you can't aspire to be one. Get out, hit the gym and exercise. The endorphins release as well as adrenaline rush you get post exercise is fundamental for peak performance. You won't find one successful person who doesn't preach for a daily exercise schedule</p><h4><br>20) Use noise filtering software</h4><p>Working at home with kids or even a dog can be very disturbing and sometimes embarrassing. Even though everyone is working remote, the noise of a grinder in the background whilst you're delivering your Q4 results can be quite distractive. Use tools like <a href="http://krisp.ai/">krisp</a> that magically cut out background noise and give you the confidence that regardless of who's speaking at the back, your colleagues won't be able to hear it.<br>‍</p><h4>21) Check in with 5 of your friends</h4><p>I assure you many of your friends will be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</a></em></p>]]>
            </description>
            <link>https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031490</guid>
            <pubDate>Mon, 09 Nov 2020 04:34:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with pen and paper]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25031483">thread link</a>) | @sethetter
<br/>
November 8, 2020 | https://sethetter.com/posts/start-with-pen-and-paper/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/start-with-pen-and-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            


<article>
    
    <section>
        <p>tl;dr — If you feel unfocused, grab a pen and paper and start writing your thoughts down.</p>
<p>Is there a question you are stuck on? A ambiguous goal you're trying to accomplish? Maybe a task you know you need to do but from which you keep getting distracted?</p>
<p><strong>Nothing will provide focus like pen and paper.</strong></p>
<p>It's all too easy these days to have a clear intention only to be sidetracked by the whirlpool of apps and services clawing for our attention on our devices.</p>
<p>It helps to take the time to groom our notification settings for importance and timeliness, but a digital device that we can use to complete nearly any task will never stand up to pen and paper in terms of it's ability to provide focus.</p>
<p>My thoughts are a constant whirlwind, I'm certainly more distractible than most, and interacting with nearly any online service only fuels that fire. So how can I get anything done if I'm unable to control my focus?</p>
<p><strong>Pen and paper.</strong> Whenever I catch myself stuck in the whirlpool, feeling not-great because I <em>know</em> I'm not doing what I want to be doing, or what I should be doing, I step away, grab pen and paper, and start writing.</p>
<p>The simple act of writing can focus my thoughts and attention in a way that nothing else can. Free from distractions, just a canvas to pour my thoughts into, and turn them into something with a sense of direction and purpose.</p>
<p>Writing is like a superpower to me. If there's any task I want to accomplish, the first step is always to write it down. Anytime I need to recenter myself on that task, I simply return to paper.</p>
<p>Throughout my life I've found that the simplest solutions are often the most powerful. So far I've found no simpler solution to start tackling any problem than to simply write it down, and then keep on writing.</p>

    </section>
</article>


        </div></div>]]>
            </description>
            <link>https://sethetter.com/posts/start-with-pen-and-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031483</guid>
            <pubDate>Mon, 09 Nov 2020 04:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool Machine Learning Books]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25031455">thread link</a>) | @ridddle
<br/>
November 8, 2020 | http://matpalm.com/blog/cool_machine_learning_books/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/cool_machine_learning_books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p>awhile ago i posted
   <a href="http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/">my list of cool machine learning books</a>,
   but it's been awhile so it's probably time to update it...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mml.jpg"></p>
<p><b><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a>
   by Marc Peter Deisenroth, A. Aldo Faisal &amp; Cheng Soon Ong.</b>
</p>
<p>this is my personal favorite book on the general math required for machine learning,
   the way things are described really resonate with me.
   available as a free pdf but i got a paper copy to support the authors after reading the
   first half.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/laalfd.jpg"></p>
<p><b><a href="http://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data</a>
   by Gilbert Strang.</b>
</p>
<p>this is gilbert's most recent work. it's really great, he's such a good teacher, and
   <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/">his freely available lectures</a>
   are even better. it's a shorter text than his other classic intro below with
   more of a focus on how things are connected to modern machine learning techniques.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itla.jpg"></p>
<p><b><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a>
   by Gilbert Strang.</b>
</p>
<p>this was my favorite linear algebra book for a long time before his 'learning from
   data' came out. this is a larger book with a more comprehensive view of linear algebra.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ts.jpg"></p>
<p><b><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats: Probability and Statistics for Programmers</a> by Allen Downey.</b>
</p>
<p>this book focuses on practical computation methods for probability and statistics.
   i got a lot out of working through this one.
   it's all in python and available for free.
   ( exciting update! as part of writing this post i've discovered there's a new edition
   to read!)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dbda.jpg"></p>
<p><b><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>
   by John Kruscgke</b>
</p>
<p>on the bayesian side of things this is the book i've most enjoyed working through.
   i've only got the first edition which was R and
   <a href="https://en.wikipedia.org/wiki/OpenBUGS">BUGS</a> but i see
   the second edition is R,
   <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> and
   <a href="https://mc-stan.org/">Stan</a>.
   it'd be fun i'm sure to work through it doing
   everything in <a href="https://github.com/pyro-ppl/numpyro">numpyro</a>. i might do that in all
   my free time. haha. "free time" hahaha. sob.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/eosl.jpg"></p>
<p><b><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>
   by Hastie, Tibshirani and Friedman</b>
</p>
<p>this is still one of the most amazing fundamental machine learning books i've ever had.
   in fact i've purchased this book <em>twice</em> and given it away both times :/ i might buy another
   copy some time soon, even though it's been freely available to download for ages. an
   amazing piece of work.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pgm.jpg"></p>
<p><b>
   <a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a>
   by Daphne Koller &amp; Nir Friedman</b>
</p>
<p>this is an epic textbook that i'd love to understand better. i've read a couple of sections in
   detail but not the entire tome yet.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/praml.jpg"></p>
<p><b>
   <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">Pattern Recognition and Machine Learning</a>
   by Christopher Bishop</b>
</p>
<p>this is probably the best overall machine learning text book i've ever read. such a beautiful book
   and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">the pdf is FREE FOR DOWNLOAD!!!</a>
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mlapp.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/machine-learning-1">Machine Learning: A Probabilistic Perspective</a> by Kevin Murphy</b>
</p>
<p>this is my second favorite general theory text on machine learning.
   i got kevin to sign my copy when he was passing my desk once but
   someone borrowed it and never gave it back :(
   so if you see a copy with my name on the spine let me know!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/homl.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</b>
</p>
<p>this is the book i point most people to when they are interested in getting up
   to speed with modern applied machine learning without too much concern for the
   theory. it's very up to date (as much as a book can be) with the latest libraries
   and, most importantly, provides a good overview of not just neural stuff but fundamental
   <a href="https://scikit-learn.org/stable/">scikit-learn</a> as well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mle.jpg"></p>
<p><b><a href="http://www.mlebook.com/wiki/doku.php">Machine Learning Engineering</a> by Andriy Burkov</b>
</p>
<p>a great book focussing on the operations side of running a machine learning system. i'm a bit
   under half way through the free online version and very likely to buy a physical copy to finish
   it and support the author. great stuff and, in many ways, a more impactful book than any of
   the theory books here.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itdm.jpg"></p>
<p><b><a href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Introduction to Data Mining</a>
   by Pang-Ning Tan, Michael Steinbach &amp; Vipin Kumar</b>
</p>
<p>this is another one that was also on my list from ten years ago and though it's section
   on neural networks is a bit of chuckle these days there is still a bunch of really
   great fundamental stuff in this book. very practical and easy to digest. i also see there's
   a second edition now. i reckon this would compliment the "hands on" book above very well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/salp.jpg"></p>
<p><b><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>
   by Dan Jurafsky &amp; James Martin</b>
</p>
<p>still the best overview of NLP there is (IMHO). can't wait to read the 3rd edition which
   apparently will cover more modern stuff (e.g. transformers) but until then, for the
   love of god though, please don't be one of those "this entire book is
   irrelevant now! just fine tune BERT" people :/
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/no.jpg"></p>
<p><b><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5">Numerical Optimization</a>
   by Jorge NocedalStephen J. Wright</b>
</p>
<p>this book is super hard core and maybe more an operations
   research book than machine learning. though i've not read it cover to cover the
   couple of bits i've worked through really taught me a lot. i'd love to understand
   the stuff in this text better; it's so so fundamental to machine learning (and more)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dl.jpg"></p>
<p><b><a href="https://www.deeplearningbook.org/">Deep Learning</a>
   by Ian Goodfellow</b>
</p>
<p>writing a book specifically on deep learning is very dangerous since things move so fast but
   if anyone can do it, ian can... i think ian's approach to explaining neural networks
   from the ground up is one of my favorites. i got the first edition hardback but it's free to
   download from the website.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pr.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/probabilistic-robotics">Probabilistic Robotics</a>
   by Sebastian Thrun, Wolfram Burgard and Dieter Fox</b>
</p>
<p>when i first joined a robotics group i bought a stack of ML/robotics books and this
   was by far the best. it's good intro stuff, and maybe already dated in places given
   it's age (the 2006 edition i have) but i still got a bunch from it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/tml.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/tinyml/9781492052036/">TinyML</a>
   by Pete Warden &amp; Daniel Situnayake</b>
</p>
<p>this was a super super fun book to tech review! neural networks on microcontrollers?!?
   yes please!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ec.jpg"></p>
<p><b><a href="https://www.wiley.com/en-us/Evolutionary+Computation%3A+Toward+a+New+Philosophy+of+Machine+Intelligence%2C+3rd+Edition-p-9780471669517">Evolutionary Computation</a> by David Fogel</b>
</p>
<p>this is still by favorite book on evolutionary algorithms; i've had this for a loooong
   time now. i still feel like evolutionary approaches are due for a big big comeback
   any time soon....
</p>
<hr>


<h2>in the mail...</h2>
<p>the good thing about writing a list is you get people telling you cool ones you've missed :)
</p>
<p>the top three i've chosen (that are in the mail) are...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ciis.jpg"></p>
<p><b><a href="http://bayes.cs.ucla.edu/PRIMER/">Causal Inference in Statistics</a> by
   Judea Pearl, Madelyn Glymour &amp; Nicholas P. Jewell</b>
</p>
<p>recommended by <a href="https://twitter.com/animesh_garg">animesh</a> who quite rightly points out
   the lack of causality in machine learning books in the books above.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itiala.jpg"></p>
<p><b><a href="https://www.cambridge.org/au/academic/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information Theory, Inference and Learning Algorithms</a> by David MacKay</b>
</p>
<p>i've seen this book mentioned a number of times and was most recently recommended by
   my colleague <a href="https://twitter.com/danesherbs">dane</a> so it's time to get it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/bmlpa.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications</a> by Emmanuel Ameisen</b>
</p>
<p>a number of people i worked with have enjoyed this. first recommended by another
   colleague <a href="https://twitter.com/davidcolls">dave</a>.
   looks to be on the practical side rather than the theory but that's ok some times :)
</p>

  </div></div>]]>
            </description>
            <link>http://matpalm.com/blog/cool_machine_learning_books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031455</guid>
            <pubDate>Mon, 09 Nov 2020 04:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does the event loop work in JavaScript? [video]]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25031384">thread link</a>) | @krayonatan
<br/>
November 8, 2020 | https://yonatankra.com/how-does-the-event-loop-work/ | <a href="https://web.archive.org/web/*/https://yonatankra.com/how-does-the-event-loop-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary"><main id="main" role="main"><article id="post-599"><div><!-- .entry-meta --><div> <p><span><span>Estimated Reading Time: </span> <span>&lt; 1</span> <span>minute</span></span></p><figure><p><span><iframe width="640" height="360" data-src="https://www.youtube.com/embed/Nqx3rtv_dko?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><figcaption>The event loop and your code talk from WarsawJS</figcaption></figure><p>On august 2020 I spoke at <a rel="noreferrer noopener" href="https://warsawjs.com/" data-type="URL" data-id="https://warsawjs.com/" target="_blank">WarsawJS</a>, explaining about the event loop and how it works.  I hope you will enjoy this talk.</p><p>If you prefer to read – <a href="https://yonatankra.com/the-event-loop-and-your-code/" data-type="post" data-id="299">here’s the blog post this talk is based on</a>.</p><p id="jp-relatedposts"><h3><em>Related</em></h3></p></div><!-- .entry-content --><!-- .entry-footer --></div></article><!-- #post-## --><p><h3>Enjoyed the article?</h3><h4>Sign up to my newsletter to enjoy more content:</h4></p>  <nav role="navigation" aria-label="Posts"><h2>Post navigation</h2></nav><!-- #comments --></main><!-- #main --></div></div>]]>
            </description>
            <link>https://yonatankra.com/how-does-the-event-loop-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031384</guid>
            <pubDate>Mon, 09 Nov 2020 04:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 The Biden-Harris plan to beat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031354">thread link</a>) | @hkhn
<br/>
November 8, 2020 | https://buildbackbetter.com/priorities/covid-19/ | <a href="https://web.archive.org/web/*/https://buildbackbetter.com/priorities/covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	

		<section id="content">

	  
<div data-module="">
  <div>
	<div>
	  <p><span>The American people deserve an urgent, robust, and professional response to the growing public health and economic crisis caused by the coronavirus (COVID-19) outbreak. President-elect Biden believes that the federal government must act swiftly and aggressively to help protect and support our families, small businesses, first responders, and caregivers essential to help us face this challenge, those who are most vulnerable to health and economic impacts, and our broader communities – not to blame others or bail out corporations. </span></p>
	</div>
  </div>
</div>

<div data-module="" id="covid-19-2" data-new-section="false" data-id="covid-19-2">
  <div>
	<div>
	  <div>
	   <p>The Biden-Harris administration will always:</p>
<ul>
<li><strong>Listen to science</strong></li>
<li><strong>Ensure public health decisions are informed by public health professionals</strong></li>
<li><strong>Promote trust, transparency, common purpose, and accountability in our government</strong></li>
</ul>
<p>President-elect Biden and Vice President-elect Harris have a seven-point plan to beat COVID-19.</p>
<p><strong>Ensure all Americans have access to regular, reliable, and free testing.</strong></p>
<ul>
<li>Double the number of drive-through testing sites.</li>
<li>Invest in next-generation testing, including at home tests and instant tests, so we can scale up our testing capacity by orders of magnitude.</li>
<li>Stand up a Pandemic Testing Board like Roosevelt’s War Production Board. It’s how we produced tanks, planes, uniforms, and supplies in record time, and it’s how we will produce and distribute tens of millions of tests.</li>
<li>Establish a U.S. Public Health Jobs Corps to mobilize at least 100,000 Americans across the country with support from trusted local organizations in communities most at risk to perform culturally competent approaches to contact tracing and protecting at-risk populations.</li>
</ul>
<p><strong>Fix personal protective equipment (PPE) problems for good.</strong></p>
<p>President-elect Joe Biden is taking responsibility and giving states, cities, tribes, and territories the critical supplies they need.</p>
<ul>
<li>Fully use the Defense Production Act to ramp up production of masks, face shields, and other PPE so that the national supply of personal protective equipment exceeds demand and our stores and stockpiles — especially in hard-hit areas that serve disproportionately vulnerable populations — are fully replenished.</li>
<li>Build immediately toward a future, flexible American-sourced and manufactured capability to ensure we are not dependent on other countries in a crisis.</li>
</ul>
<p><strong>Provide clear, consistent, evidence-based guidance for how communities should navigate the pandemic – and the resources for schools, small businesses, and families to make it through.</strong></p>
<ul>
<li>Social distancing is not a light switch. It is a dial. President-elect Biden will direct the CDC to provide specific evidence-based guidance for how to turn the dial up or down relative to the level of risk and degree of viral spread in a community, including when to open or close certain businesses, bars, restaurants, and other spaces; when to open or close schools, and what steps they need to take to make classrooms and facilities safe; appropriate restrictions on size of gatherings; when to issue stay-at-home restrictions.</li>
<li>Establish a renewable fund for state and local governments to help prevent budget shortfalls, which may cause states to face steep cuts to teachers and first responders.</li>
<li>Call on Congress to pass an emergency package to ensure schools have the additional resources they need to adapt effectively to COVID-19.</li>
<li>Provide a “restart package” that helps small businesses cover the costs of operating safely, including things like plexiglass and PPE.</li>
</ul>
	  </div>
	</div>
  </div>
</div>

<!-- .module.block-quote -->

<div data-module="" id="covid-19-4" data-new-section="false" data-id="covid-19-4">
  <div>
	<div>
	  <div>
	   <p><strong>Plan for the effective, equitable distribution of treatments and vaccines — because development isn’t enough if they aren’t effectively distributed.</strong></p>
<ul>
<li>Invest $25 billion in a vaccine manufacturing and distribution plan that will guarantee it gets to every American, cost-free.</li>
<li>Ensure that politics plays no role in determining the safety and efficacy of any vaccine. The following 3 principles will guide the Biden-Harris administration: Put scientists in charge of all decisions on safety and efficacy; publicly release clinical data for any vaccine the FDA approves; and authorize career staff to write a written report for public review and permit them to appear before Congress and speak publicly uncensored.</li>
<li>Ensure everyone — not just the wealthy and well-connected — in America receives the protection and care they deserve, and consumers are not price gouged as new drugs and therapies come to market.</li>
</ul>
<p><strong>Protect older Americans and others at high risk.</strong></p>
<p>President-elect Biden understands that older Americans and others at high-risk are most vulnerable to COVID-19.</p>
<ul>
<li>Establish a COVID-19 Racial and Ethnic Disparities Task Force, as proposed by Vice President-elect Harris, to provide recommendations and oversight on disparities in the public health and economic response. At the end of this health crisis, it will transition to a permanent Infectious Disease Racial Disparities Task Force.</li>
<li>Create the Nationwide Pandemic Dashboard that Americans can check in real-time to help them gauge whether local transmission is actively occurring in their zip codes. This information is critical to helping all individuals, but especially older Americans and others at high risk, understand what level of precaution to take.</li>
</ul>
<p><strong>Rebuild and expand defenses to predict, prevent, and mitigate pandemic threats, including those coming from China.</strong></p>
<ul>
<li>Immediately restore the White House National Security Council Directorate for Global Health Security and Biodefense, originally established by the Obama-Biden administration.</li>
<li>Immediately restore our relationship with the World Health Organization, which — while not perfect — is essential to coordinating a global response during a pandemic.</li>
<li>Re-launch and strengthen U.S. Agency for International Development’s pathogen-tracking program called PREDICT.</li>
<li>Expand the number of CDC’s deployed disease detectives so we have eyes and ears on the ground, including rebuilding the office in Beijing.</li>
</ul>
<p><strong>Implement mask mandates nationwide by working with governors and mayors and by asking the American people to do what they do best: step up in a time of crisis.</strong></p>
<p>Experts agree that tens of thousands of lives can be saved if Americans wear masks. President-elect Biden will continue to call on:</p>
<ul>
<li>Every American to wear a mask when they are around people outside their household.</li>
<li>Every Governor to make that mandatory in their state.</li>
<li>Local authorities to also make it mandatory to buttress their state orders.</li>
</ul>
<p>Once we succeed in getting beyond this pandemic, we must ensure that the millions of Americans who suffer long-term side effects from COVID don’t face higher premiums or denial of health insurance because of this new pre-existing condition. The Biden-Harris Administration will work to ensure that the protections for those with pre-existing conditions that were won with Obamacare are protected. And, they will work to lower health care costs and expand access to quality, affordable health care through a Medicare-like public option.</p>
	  </div>
	</div>
  </div>
</div>



	</section>

  </article></div>]]>
            </description>
            <link>https://buildbackbetter.com/priorities/covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031354</guid>
            <pubDate>Mon, 09 Nov 2020 04:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fun website that simulates fluid]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25031304">thread link</a>) | @svikashk
<br/>
November 8, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/ | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031304</guid>
            <pubDate>Mon, 09 Nov 2020 03:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Tunneling Basics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031064">thread link</a>) | @bswamina
<br/>
November 8, 2020 | https://www.polarsparc.com/xhtml/SSH-Tunnel.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/SSH-Tunnel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    <br>
    
    
    <hr> 
    <p>Overview</p>
    <p>In networking, a <span>Tunnel</span> is used to encapsulate a communication protocol that is not supported
        by the network inside a protocol that is supported by the network.</p>
    <p>The following are some of terms used in this article:</p>
    <table id="col2-table">
      <thead>
        <tr>
          <th>Term</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><span>SSH</span></td>
          <td>short for <span>S</span>ecure <span>SH</span>ell is a protocol that sets
            up an encrypted connection between two nodes over an unsecured network using a Client-Server architecture</td>
        </tr>
        <tr>
          <td><span>SSH Server</span></td>
          <td>a server that listens on the TCP port <span>22</span> for incoming SSH client
            requests, then authenticates those client requests, and provides a command prompt</td>
        </tr>
        <tr>
          <td><span>SSH Client</span></td>
          <td>a client used to connect to the remote SSH Server on a specific network node</td>
        </tr>
        <tr>
          <td><span>SSH Tunnel</span></td>
          <td>a method of encapsulating and transmitting arbitrary networking data over an encrypted SSH
            connection between a client node and a server node</td>
        </tr>
        <tr>
          <td><span>SSH Port Forwarding</span></td>
          <td>another name for <span>SSH Tunnel</span></td>
        </tr>
      </tbody>
    </table>
    <div id="para-div">
      <p>So, why do we need <span>tunneling</span> ??? The following are some of the reasons:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p>To allow access to legacy applications or unsecure services such as IMAP, POP3, VNC, etc</p>
        </li>
        <li>
          <p>To implement a virtual private network (<span>VPN</span>)</p>
        </li>
        <li>
          <p>To allow access to services behind a firewall</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>There are <span>3</span> types of <span>SSH Tunnel</span> options as listed below:</p>
      <ol id="blue-ol">
        <li>
          <p><span>Local</span> Port Forwarding</p>
        </li>
        <li>
          <p><span>Remote</span> Port Forwarding</p>
        </li>
        <li>
          <p><span>Dynamic</span> Port Forwarding</p>
        </li>
      </ol>
    </div>
    <p>We will discuss and demonstrate each of the above options in the following sections.</p>
    <p>Setup</p>
    <p>The setup will be on a Ubuntu 20.04 LTS based Linux desktop. For the demonstrations, we will create an environment with
        3 virtual machines running on the hypervisor <span>VirtualBox</span>.</p>
    <p>The following diagram illustrates the environment setup:</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/ssh-tunnel-2.png" alt="Environment"></p><p>Environment</p>
    </div>
    <br>
    <div id="para-div">
      <p>The following are some of the highlights of the 3 virtual machines:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p><span>vm-1</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a single virtual network
            interface with <span>NAT</span> networking (<span>10.0.2.15</span>)</p>
        </li>
        <li>
          <p><span>vm-2</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a single virtual network
            interface with <span>Host-only</span> networking (<span>192.168.56.104</span>)</p>
        </li>
        <li>
          <p><span>vm-3</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a two separate virtual
            network interfaces - one with <span>NAT</span> networking (<span>10.0.2.4</span>) and the
            other with <span>Host-only</span> networking (<span>192.168.56.103</span>)</p>
        </li>
      </ul>
    </div>
    <p>Open a Terminal window in each of the 3 virtual machines <span>vm-1</span> thru <span>vm-3</span>
        and install <span>Python Flask</span>, <span>Net Tools</span>, and <span>SSH Server
        </span> by executing the following command:</p>
    <p>$ sudo apt install python3-flask net-tools openssh-server -y</p>
    <p>The following would be a typical output:</p>
    <div id="out-div">
      <h4>Output.1</h4>
      <pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following additional packages will be installed:
  javascript-common libjs-jquery ncurses-term openssh-sftp-server python3-itsdangerous python3-jinja2 python3-markupsafe
  python3-openssl python3-pyinotify python3-werkzeug ssh-import-id
Suggested packages:
  apache2 | lighttpd | httpd molly-guard monkeysphere ssh-askpass python-flask-doc python-jinja2-doc python-openssl-doc
  python3-openssl-dbg python-pyinotify-doc ipython3 python-werkzeug-doc python3-lxml python3-termcolor python3-watchdog
The following NEW packages will be installed:
  javascript-common libjs-jquery ncurses-term net-tools openssh-server openssh-sftp-server python3-flask python3-itsdangerous
  python3-jinja2 python3-markupsafe python3-openssl python3-pyinotify python3-werkzeug ssh-import-id
0 upgraded, 14 newly installed, 0 to remove and 0 not upgraded.
Need to get 1,478 kB of archives.
After this operation, 9,096 kB of additional disk space will be used.
Get:1 http://us.archive.ubuntu.com/ubuntu focal/main amd64 javascript-common all 11 [6,066 B]
Get:2 http://us.archive.ubuntu.com/ubuntu focal/main amd64 libjs-jquery all 3.3.1~dfsg-3 [329 kB]
Get:3 http://us.archive.ubuntu.com/ubuntu focal/main amd64 ncurses-term all 6.2-0ubuntu2 [249 kB]
Get:4 http://us.archive.ubuntu.com/ubuntu focal/main amd64 net-tools amd64 1.60+git20180626.aebd88e-1ubuntu1 [196 kB]
Get:5 http://us.archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-sftp-server amd64 1:8.2p1-4ubuntu0.1 [51.5 kB]
Get:6 http://us.archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-server amd64 1:8.2p1-4ubuntu0.1 [377 kB]
Get:7 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-itsdangerous all 1.1.0-1 [14.6 kB]
Get:9 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-markupsafe amd64 1.1.0-1build2 [13.9 kB]
Get:9 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-jinja2 all 2.10.1-2 [95.5 kB]
Get:10 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-werkzeug all 0.16.1+dfsg1-2 [183 kB]
Get:11 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-flask all 1.1.1-2 [80.3 kB]
Get:12 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-openssl all 19.0.0-1build1 [43.3 kB]
Get:13 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-pyinotify all 0.9.6-1.2ubuntu1 [24.8 kB]
Get:14 http://us.archive.ubuntu.com/ubuntu focal/main amd64 ssh-import-id all 5.10-0ubuntu1 [10.0 kB]
Fetched 1,478 kB in 0s (5,095 kB/s)  
Preconfiguring packages ...
Selecting previously unselected package javascript-common.
(Reading database ... 192970 files and directories currently installed.)
Preparing to unpack .../00-javascript-common_11_all.deb ...
Unpacking javascript-common (11) ...
Selecting previously unselected package libjs-jquery.
Preparing to unpack .../01-libjs-jquery_3.3.1~dfsg-3_all.deb ...
Unpacking libjs-jquery (3.3.1~dfsg-3) ...
Selecting previously unselected package ncurses-term.
Preparing to unpack .../02-ncurses-term_6.2-0ubuntu2_all.deb ...
Unpacking ncurses-term (6.2-0ubuntu2) ...
Preparing to unpack .../net-tools_1.60+git20180626.aebd88e-1ubuntu1_amd64.deb ...
Unpacking net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...
Selecting previously unselected package openssh-sftp-server.
Preparing to unpack .../03-openssh-sftp-server_1%3a8.2p1-4ubuntu0.1_amd64.deb ...
Unpacking openssh-sftp-server (1:8.2p1-4ubuntu0.1) ...
Selecting previously unselected package openssh-server.
Preparing to unpack .../04-openssh-server_1%3a8.2p1-4ubuntu0.1_amd64.deb ...
Unpacking openssh-server (1:8.2p1-4ubuntu0.1) ...
Selecting previously unselected package python3-itsdangerous.
Preparing to unpack .../05-python3-itsdangerous_1.1.0-1_all.deb ...
Unpacking python3-itsdangerous (1.1.0-1) ...
Selecting previously unselected package python3-markupsafe.
Preparing to unpack .../06-python3-markupsafe_1.1.0-1build2_amd64.deb ...
Unpacking python3-markupsafe (1.1.0-1build2) ...
Selecting previously unselected package python3-jinja2.
Preparing to unpack .../07-python3-jinja2_2.10.1-2_all.deb ...
Unpacking python3-jinja2 (2.10.1-2) ...
Selecting previously unselected package python3-werkzeug.
Preparing to unpack .../08-python3-werkzeug_0.16.1+dfsg1-2_all.deb ...
Unpacking python3-werkzeug (0.16.1+dfsg1-2) ...
Selecting previously unselected package python3-flask.
Preparing to unpack .../09-python3-flask_1.1.1-2_all.deb ...
Unpacking python3-flask (1.1.1-2) ...
Selecting previously unselected package python3-openssl.
Preparing to unpack .../10-python3-openssl_19.0.0-1build1_all.deb ...
Unpacking python3-openssl (19.0.0-1build1) ...
Selecting previously unselected package python3-pyinotify.
Preparing to unpack .../11-python3-pyinotify_0.9.6-1.2ubuntu1_all.deb ...
Unpacking python3-pyinotify (0.9.6-1.2ubuntu1) ...
Selecting previously unselected package ssh-import-id.
Preparing to unpack .../12-ssh-import-id_5.10-0ubuntu1_all.deb ...
Unpacking ssh-import-id (5.10-0ubuntu1) ...
Setting up javascript-common (11) ...
Setting up net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...
Setting up openssh-sftp-server (1:8.2p1-4ubuntu0.1) ...
Setting up openssh-server (1:8.2p1-4ubuntu0.1) ...
Creating config file /etc/ssh/sshd_config with new version
Creating SSH2 RSA key; this may take some time ...
3072 SHA256:OVmIaDeM2PCBtB6O5tddPIC3q4nuZVdqfcs/7A3QM5A root@vm-3 (RSA)
Creating SSH2 ECDSA key; this may take some time ...
256 SHA256:qDrGgauXE9LwZ6S1j4fjbY0LIPyrL+YSU8iq+PbR7jM root@vm-3 (ECDSA)
Creating SSH2 ED25519 key; this may take some time ...
256 SHA256:WBk+gqOXD47VoAJrw+JeZLxQlzBWdaKFRxi5xfPAkYg root@vm-3 (ED25519)
Created symlink /etc/systemd/system/sshd.service â†’ /lib/systemd/system/ssh.service.
Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service â†’ /lib/systemd/system/ssh.service.
rescue-ssh.target is a disabled or a static unit, not starting it.
Setting up python3-openssl (19.0.0-1build1) ...
Setting up ssh-import-id (5.10-0ubuntu1) ...
Attempting to convert /etc/ssh/ssh_import_id
Setting up python3-pyinotify (0.9.6-1.2ubuntu1) ...
Setting up python3-itsdangerous (1.1.0-1) ...
Setting up python3-markupsafe (1.1.0-1build2) ...
Setting up python3-jinja2 (2.10.1-2) ...
Setting up libjs-jquery (3.3.1~dfsg-3) ...
Setting up ncurses-term (6.2-0ubuntu2) ...
Setting up python3-werkzeug (0.16.1+dfsg1-2) ...
Setting up python3-flask (1.1.1-2) ...
Processing triggers for systemd (245.4-4ubuntu3.3) ...
Processing triggers for man-db (2.9.1-1) ...
Processing triggers for ufw (0.36-6) ...</pre>
    </div>
    <p>Local Port Forwarding</p>
    <p>Assuming <span>vm-3</span> is hosting a useful web application on <span>10.0.2.4</span>, it is
        *ONLY* accessible within the <span>10.0.2.x</span> network. What if a client on the <span>
        vm-2</span> wants to access the web application ???</p>
    <p>In this situation, one could use Local Port Forwarding SSH Tunnel option to allow the client <span>vm-2</span>
        running on <span>192.168.56.104</span> to access the web application server running on the
        <span>10.0.2.x</span> network.</p>
    <p>The following is the code for the simple <span>Python</span> based web application:</p>
    <fieldset id="sc-fieldset"> <legend>Web.py</legend>
      <pre>import sys
from datetime import datetime
from flask …</pre></fieldset></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/SSH-Tunnel.html">https://www.polarsparc.com/xhtml/SSH-Tunnel.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/SSH-Tunnel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031064</guid>
            <pubDate>Mon, 09 Nov 2020 03:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Program Development in Limbo for Inferno OS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030961">thread link</a>) | @marttt
<br/>
November 8, 2020 | https://seh.dev/limbo-intro/ | <a href="https://web.archive.org/web/*/https://seh.dev/limbo-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <div>
<h2 id="motivation">Motivation</h2>
<p>Resources covering software development under Inferno are fairly scarce.</p>
<p>As such, this post aims to provide a start-to-finish demonstration of program development in Limbo inside Inferno.</p>
<h2 id="introduction">Introduction</h2>
<p>This post assumes you’re using Inferno, specifically <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a>, hosted under <code>linux/amd64</code> or similar.</p>
<p>It’s also possible to use Inferno under Docker as per the <code>INSTALL</code> file.</p>
<p>Other platforms are supported, but steps may differ here or there.</p>
<p>The rune <code>$</code> indicates a unix shell command under <code>bash</code>, probably.</p>
<p>The rune <code>;</code> or <code>%</code> indicates a command to be run from inside Inferno.</p>
<p>The final source from this post: <a href="https://github.com/henesy/socketh-limbo">https://github.com/henesy/socketh-limbo</a></p>
<p>This post will be an implementation of <a href="https://github.com/henesy/SocketH">SocketH</a> which was originally written in Go and has a few other implementations:</p>
<ul>
<li><a href="https://github.com/henesy/socketh-myr">https://github.com/henesy/socketh-myr</a></li>
<li><a href="https://github.com/henesy/SocketS">https://github.com/henesy/SocketS</a></li>
</ul>
<p>The original code isn’t great, but it gives a target for what we want to create.</p>
<h2 id="getting-started">Getting started</h2>
<p>Many, if not all, of these development steps prior to <em>running</em> the final Dis bytecode can be done from outside of Inferno.</p>
<p>The limbo compiler can be called as <code>limbo</code> and with the right workflow development may be more pleasant.</p>
<p>This post assumes:</p>
<ul>
<li>Development occurs inside of Inferno for the purpose of consistency</li>
<li>Some knowledge about imperative, C-like, language programming</li>
<li>Some knowledge about how unix-like systems work</li>
<li>Some knowledge about how C-like compiler and linker flows work</li>
<li>Knowledge about how to interact with a unix-like shell</li>
<li>Vague knowledge about Inferno, such as the fact Inferno exists ☺</li>
</ul>
<h3 id="build-inferno">Build Inferno</h3>
<p>Steps provided are targeted for <code>linux/amd64</code> as a host for Inferno.</p>
<p>The official <a href="https://bitbucket.org/inferno-os/inferno-os/">Inferno</a> tree is hosted over <a href="https://git-scm.com/">Git</a>.</p>
<p>The <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a> fork is hosted by the 9front project over <a href="https://www.mercurial-scm.org/">Mercurial</a>.</p>
<p>Cloning:</p>
<div><pre><code data-lang="text">$ hg clone https://code.9front.org/hg/purgatorio
destination directory: purgatorio
requesting all changes
adding changesets
adding manifests
adding file changes
added 86 changesets with 10904 changes to 10545 files
new changesets 78950db8e089:749c484c1b9c
updating to branch default
9584 files updated, 0 files merged, 0 files removed, 0 files unresolved
$ cd purgatorio/
$ ls
acme                     FreeBSD  libdynld     libprefab      mkfile       scripts
AIX                      icons    libfreetype  libsec         mkfiles      services
appl                     include  libinterp    libtk          module       Solaris
bitbucket-pipelines.yml  Inferno  libkern      limbo          NetBSD       tools
CHANGES                  INSTALL  libkeyring   Linux          NOTICE       usr
dis                      Irix     liblogfs     locale         Nt           utils
doc                      keydb    libmath      MacOSX         OpenBSD
Dockerfile               lib      libmemdraw   makemk-AIX.sh  os
DragonFly                lib9     libmemlayer  makemk.sh      Plan9
emu                      libbio   libmp        man            POSTINSTALL
fonts                    libdraw  libnandfs    mkconfig       README.md
$
</code></pre></div><p><strong>Read the</strong> <code>INSTALL</code> <strong>file!</strong></p>
<p>Update our <code>$HOME/.profile</code> to reflect the Inferno install, adapt this to your directories:</p>
<div><pre><code data-lang="text">export EMU='-g1280x960 -c1'
export INFERNO=$HOME/repos/purgatorio
export PATH=$PATH:$INFERNO/Linux/386/bin
</code></pre></div><p>Reload our shell currently in the purgatorio root tree:</p>
<div><pre><code data-lang="text">$ source $HOME/.profile
$
</code></pre></div><p>Update the <code>mkconfig</code> file to reflect our environment, adapt this as needed:</p>
<div><pre><code data-lang="text">ROOT=$HOME/repos/purgatorio

TKSTYLE=std

CONF=emu

SYSHOST=Linux		# build system OS type (Hp, Inferno, Irix, Linux, MacOSX, Nt, Plan9, Solaris)
SYSTARG=$SYSHOST	# target system OS type (Hp, Inferno, Irix, Linux, Nt, Plan9, Solaris)

OBJTYPE=386

OBJDIR=$SYSTARG/$OBJTYPE

&lt;$ROOT/mkfiles/mkhost-$SYSHOST			# variables appropriate for host system
&lt;$ROOT/mkfiles/mkfile-$SYSTARG-$OBJTYPE	# variables used to build target object type
</code></pre></div><p>Enable multi-arch support on debian-based distributions if on amd64 (64-bit) as Inferno is 32-bit only:</p>
<div><pre><code data-lang="text">$ dpkg --add-architecture i386
$ apt-get update
</code></pre></div><p>Install dependencies required to compile Inferno, this example shows dependencies for debian-based (Ubuntu) distributions:</p>
<div><pre><code data-lang="text">$ apt install libc6-dev-i386 libxext6:i386 libx11-dev:i386 libxext-dev:i386 libfontconfig1-dev:i386
…
$
</code></pre></div><p>Build <code>mk</code> which will be used to bootstrap the rest of the process:</p>
<p>Build and install Inferno!</p>
<div><pre><code data-lang="text">$ mk mkdirs
…
$ mk clean
…
$ mk install
…
$
</code></pre></div><h3 id="start-inferno">Start Inferno</h3>
<p>A graphical environment should appear.</p>
<p>You can make the gui window for Inferno larger by passing in a different size to <code>emu</code> as per <a href="http://man.postnix.pw/purgatorio/1/emu">the manual</a>:</p>
<div><pre><code data-lang="text">-gXsizexYsize
	Define screen width and height in pixels.  The default
	values are 640x480 and the minimum values are 64x48.
	Values smaller than the minimum or greater than the
	available display size are ignored.
</code></pre></div><p>thus:</p>
<p>and so forth.</p>
<p>Some programs can be found under the start menu in the bottom left corner decorated with the <a href="https://seh.dev/limbo-intro/vitanuova.com/">Vita Nuova</a> logo:</p>
<p><img src="http://www.vitanuova.com/images/vitanuova.jpg" alt="Vita Nuova’s logo"></p>
<p>The <code>Shell</code> entry in the start menu will provide a shell-interpreter window from which further commands can be run inside Inferno.</p>
<h3 id="preparation">Preparation</h3>
<div><pre><code data-lang="text">% cd $home/appl
% os git clone https://github.com/henesy/socketh-limbo
% cd socketh-limbo
% lc
.git/     LICENSE   README.md
% touch .gitignore socketh.b
% acme socketh.b
</code></pre></div><p><code>.gitignore</code>:</p>
<p>Limbo ‘libraries’, known as ‘modules’, and ‘programs’ are one and the same in terms of semantics, bar ‘libraries’ having module <code>.m</code> files which are similar to header <code>.h</code> files in C.</p>
<p>As such, the boilerplate for most Limbo programs is very similar. We can initialize our main file as follows.</p>
<p><code>socketh.b</code>:</p>
<div><pre><code data-lang="c">implement SocketH;

include <span>"sys.m"</span>;
	<span>sys</span>: Sys;

include <span>"draw.m"</span>;
include <span>"arg.m"</span>;

<span>SocketH</span>: module {
	<span>init</span>: fn(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string);
};


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;



	exit;
}
</code></pre></div><p>We can break this down a bit.</p>
<p><code>implement</code> declares a module by name.</p>
<p>A module definition must be provided indicating exported functions from the module:</p>
<div><pre><code data-lang="text">SocketH: module {
	init: fn(nil: ref Draw-&gt;Context, argv: list of string);
};
</code></pre></div><p>Note how a variable name of <code>nil</code> is used to drop assignment of a value.</p>
<p>The <code>init</code> function is special in shell-loaded Limbo programs and its signature <em>must</em> match what the shell expects the init function interface to be.</p>
<p>Functionally, <code>init</code> is equivalent to <code>main</code> in most other languages.</p>
<p><code>include</code> imports an external module’s definitions into our scope.</p>
<p><code>load</code> performs the dynamic loading of a module at runtime.</p>
<p><code>exit</code> performs the dynamic un-loading of a module at runtime.</p>
<p><code>raise</code> will throw an exception with a given string as its content.</p>
<p>We refer to names inside a module using the <code>-&gt;</code> operator.</p>
<p>We can jointly assign and declare in one step using the <code>:=</code> operator.</p>
<p>Curly braces are optional.</p>
<p>Semicolons are not.</p>
<p>Note the absence of a reserved <code>main</code> module. This is due to each <code>.dis</code> file, potentially an independent module, being theoretically loadable in its own right. A reserved name would cause significant issues with namespaces ☺.</p>
<h3 id="setting-up-a-workflow">Setting up a workflow</h3>
<p>Compiling our program should be as straightforward as running the Limbo compiler against our source file:</p>
<div><pre><code data-lang="text">% limbo socketh.b
% lc
.git/		LICENSE		socketh.b
.gitignore	README.md	socketh.dis
% socketh.dis
%
</code></pre></div><p>This program does nothing right now, but that’s fine.</p>
<p>Note how we can omit the <code>./</code> when running <code>.dis</code> programs.</p>
<p>Calling the limbo compiler each time is a bit of a pain, and if we start using commandline flags this will become tedious to type.</p>
<p>In acme, we could type the text we want to run in a tag or window and middle-click said text to run the compilation (or more!) on-demand. In Inferno, acme comes with a <code>Limbo</code> command in the default window tag, but that only works for one file.</p>
<p>We can simplify this process by writing a <s>makefile</s> <a href="http://doc.cat-v.org/bell_labs/mk/">mkfile</a>!</p>
<p><code>mkfile</code>:</p>
<div><pre><code data-lang="text">&lt;/mkconfig

DISBIN = /dis

TARG = socketh.dis

&lt;/mkfiles/mkdis
</code></pre></div><p>Mk semantics are similar to make with some changes.</p>
<p>How mk will behave inside Inferno using the <code>mkdis</code> mkfile as the trailing import:</p>
<ul>
<li>Mk can import outside mkfiles using the <code>&lt;</code> operator</li>
<li><code>mk</code> will call <code>mk all</code> which resolves to the <code>all</code> (default) target</li>
<li><code>mk install</code> calls the <code>all</code> target and copies the <code>TARG</code> file(s) to the <code>DISBIN</code> destination directory</li>
<li><code>mk clean</code> removes files such as <code>.dis</code> and <code>.sbl</code> from the working directory</li>
<li><code>mk nuke</code> calls the <code>clean</code> target as well as delete the ‘target’ files such as the <code>/dis/socketh</code> binary if the <code>install</code> target has been called</li>
</ul>
<p>A demonstration:</p>
<div><pre><code data-lang="text">% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
% mk
limbo -I/module -gw socketh.b
socketh.b:15: warning: argument argv not referenced
% lc
.git/		LICENSE		mkfile		socketh.dis
.gitignore	README.md	socketh.b	socketh.sbl
% mk install
rm -f /dis/socketh.dis &amp;&amp; cp socketh.dis /dis/socketh.dis
% mk clean
rm -f *.dis *.sbl
% whatis socketh
/dis/socketh.dis
% mk nuke
rm -f *.dis *.sbl
cd /dis; rm -f socketh.dis
% whatis socketh.dis
socketh.dis: not found
% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
%
</code></pre></div><p>Note the Limbo compiler flags being passed by default now for the <code>all</code> target.</p>
<p>At this point, I usually add <code>mk clean &amp;&amp; mk</code> to my acme tag and run that for multi-file or more complex Limbo programs. This flow is very similar to how I do development under Plan 9.</p>
<h3 id="common-patterns">Common patterns</h3>
<h4 id="commandline-flags">Commandline flags</h4>
<p>We can use <a href="https://seh.dev/limbo-intro/man.postnix.pw/purgatorio/2/arg">arg(2)</a> to process commandline flags:</p>
<div><pre><code data-lang="c"><span>…</span>

<span>chatty</span>: <span>int</span>	<span>=</span> <span>0</span>;	<span>#</span> Verbose debug output


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;

	<span>addr</span>: string <span>=</span> <span>"tcp!*!9090"</span>;

	arg<span>-&gt;</span>init(argv);
	arg<span>-&gt;</span>setusage(<span>"socketh [-D] [-a addr]"</span>);

	<span>while</span>((<span>c</span> :<span>=</span> arg<span>-&gt;</span>opt()) <span>!=</span> <span>0</span>)
		<span>case</span> c {
		<span>'D'</span> <span>=&gt;</span>
			chatty<span>++</span>;

		<span>'a'</span> <span>=&gt;</span>
			addr <span>=</span> arg<span>-&gt;</span>earg();

		<span>*</span> <span>=&gt;</span>
			arg<span>-&gt;</span>usage();
		}

	argv <span>=</span> arg<span>-&gt;</span>argv();



	exit;
}
</code></pre></div><p>We can see how these flags are parsed and how these functions act:</p>
<div><pre><code data-lang="text">% mk
mk: 'all' is up to date
% socketh -h
usage: socketh [-D] [-a addr]
% socketh -D
% socketh -a
usage: socketh [-D] [-a addr]
% socketh -a -D
% socketh -D -a
usage: socketh [-D] [-a …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seh.dev/limbo-intro/">https://seh.dev/limbo-intro/</a></em></p>]]>
            </description>
            <link>https://seh.dev/limbo-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030961</guid>
            <pubDate>Mon, 09 Nov 2020 02:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention Is My Most Valuable Asset for Productivity as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 630 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25030938">thread link</a>) | @zwbetz
<br/>
November 8, 2020 | https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/ | <a href="https://web.archive.org/web/*/https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
      <div>
        <div>
          <div>
            
  
  
  <p>
    
    
    
    <strong>Published: </strong>2020-11-08

    
    
      
      
        • <strong>Lastmod: </strong>2020-11-12

      
    
    
    
    
      <br>
      <span>
        <strong>Tags: </strong>
        
          
          
          
        
          
          
          
        
          
          
          
        
        <a href="https://zwbetz.com/tags/life/">life</a> • <a href="https://zwbetz.com/tags/attention/">attention</a> • <a href="https://zwbetz.com/tags/productivity/">productivity</a>
      
    </span>
  </p>
  
  
  
  

<p><em><strong>Note:</strong> This article has made the rounds on <a href="https://news.ycombinator.com/item?id=25030938">Hacker News</a> and <a href="https://www.reddit.com/r/programming/comments/jrlxbh/attention_is_my_most_valuable_asset_for/">Reddit</a>. The comments have been fun to read, and while I won’t address them all, I will say this… What I hope readers take away, is to realize just how interrupted and distraction-ridden their day may be, and that it doesn’t have to be that way, that you can improve it. Given that, these methods to guard your attention have worked for me, with “me” being the key word. So, take what’s useful for you, and discard the rest. Enjoy.</em></p>
<p>Like a tightly written function, I prefer to exit early if no work should be done. So, if you disagree with these definitions and assumptions, now’s a good time to stop reading.</p>
<ul>
<li><strong>Sustainable productivity:</strong> The maximum rate of quality work output, without loss to the wellbeing of the developer</li>
<li><strong>Quality work:</strong> Software that meets requirements, is valuable to users, is maintainable, and is as bug free as possible</li>
<li><strong>Attention:</strong> The limited mental capacity to focus on a task</li>
<li>Sustainable productivity is desired</li>
<li>Attention is essential to sustainable productivity</li>
</ul>
<p>My high-level workflow looks something like this: identify the problem to solve; think on the problem and let ideas percolate; research, discuss, and experiment with these ideas; implement and test the solution; deliver and maintain the solution.</p>
<p>This cycle could repeat many times in a day. Or I could spend days stuck on a single cycle step. Every step in this cycle requires attention. The more attention I can devote, the more cycles I can complete, and the more productive I am.</p>
<p>How long you can focus on a task varies by person. Some people are very good at it out of the box, some people, not so much. Regardless of the hand you were dealt, I believe that focus (the act of devoting your attention) is a skill, and like any skill, can be improved with practice.</p>
<p>So, how can you increase your attention reserves? The most bang for your buck is to organize your outside world in such a way that it’s distraction free as possible. Once you do that, you’ll have more time to practice, and therefore more time to get better.</p>
<p><strong>Build physical strength.</strong> The damage done by sitting 8+ hours a day is underrated. You need a way to offset this damage, especially if you plan to work in this field for decades. Opinions abound on this topic, but I personally prefer deadlifts. There are few movements more primal than picking a heavy object off the ground and standing up with it. You can <a href="https://www.youtube.com/watch?v=wYREQkVtvEc">learn correct technique in little time</a>. I most like deadlifts because you can do them safely, at high weights, into old age. I also like the hand, back, and hip strength they give, to make it that much harder for sitting damage to have its way with you.</p>
<p><strong>Make my place of work boring and tidy.</strong> My office is a spare bedroom. The walls are blank. There’s no tv. There’s a desk, chair, laptop, laptop stand, keyboard, mouse, and mouse pad. There’s a window, which lets enough light in so that I don’t feel like I’m missing a beautiful day, but not too much light to cause screen glare. If I need to work with paper, it’s immediately filed somewhere when done.</p>
<p><strong>Make my smart phone dumb.</strong> My phone has all notifications disabled, except for calls and text messages. Well, and National Hurricane Center alerts, since I live in Louisiana. Unless you’re my wife, you know that I don’t respond to text messages immediately, that’s just how it is. I disabled my social media accounts some time ago. But if you have them, turning off notifications should help curve the urge to compulsively check them.</p>
<p><strong>Be an OS minimalist.</strong> Apps I use less commonly are a keypress combo away. Given this, my dock has only the apps I use on a daily basis:</p>
<ul>
<li>File system explorer</li>
<li>Internet browser</li>
<li>Terminal</li>
<li>Text editor for front-end code and notes</li>
<li>IDE for back-end code</li>
<li>IDE for database</li>
<li>Visual file differ for version control</li>
<li>Email client</li>
<li>Instant message client</li>
</ul>
<p>My desktop alternates between clean and dirty states. Files I’m currently working with live on the desktop. Then they’re filed away into sensible folders when done.</p>
<p><strong>Organize my browser bookmarks.</strong> When I read something useful that I may need to reference later, I file it under a general archive folder. Then more specific items get their own folders. Frequently accessed links are visible on my bookmarks bar under their own folder.</p>
<p><strong>Minimize meetings.</strong> Look, I know some things make sense to discuss face to face, or voice to voice. But if they don’t, then you don’t need a meeting. An email or instant message will suffice.</p>
<p><strong>Finally, use the <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a> to categorize my tasks.</strong> Imagine a grid of 4 quadrants:</p>
<ul>
<li>Important and Urgent</li>
<li>Important and Not Urgent</li>
<li>Not Important and Urgent</li>
<li>Not Important and Not Urgent</li>
</ul>
<p>Important and Urgent tasks have to be dealt with. For me, these are usually major production issues.</p>
<p>Important and Not Urgent tasks should absorb the bulk of your time. For me, this is the plain old development work of implementing features, fixing bugs, and making existing code more maintainable and performant. Also included are building relationships with others and planning ahead.</p>
<p>Not Important and Urgent tasks are nasty attention thieves. They shout out to you in immediacy, but offer little value in return. You know what these are for you. For me, these are most often lazily asked questions, where the asker did not do their due diligence, and expects a top-notch answer immediately. Also included are last-minute meetings, and over-talkative coworkers.</p>
<p>Not Important and Not Urgent tasks are usually not known to your users. Take internal documentation updates as an example. Thing is, they’re an investment in yourself, which means a more productive future “you”. So don’t forget to show them some love in your spare moments.</p>
<p><strong>Further reading.</strong> If you don’t know who Cal Newport is, you’re missing out. He has a whole blog dedicated to this type of thing, and has written books such as <em>Deep Work</em> and <em>Digital Minimalism</em>. Here are some of my favorite articles by him:</p>
<ul>
<li><a href="https://www.calnewport.com/blog/2009/02/04/have-we-lost-our-tolerance-for-a-little-boredom/">Have We Lost Our Tolerance For a Little Boredom?</a></li>
<li><a href="https://www.calnewport.com/blog/2010/06/10/is-allowing-your-child-to-study-while-on-facebook-morally-equivalent-to-drinking-while-pregnant/">Is Allowing Your Child to Study While on Facebook Morally Irresponsible?</a></li>
<li><a href="https://www.calnewport.com/blog/2008/04/07/monday-master-class-how-to-reduce-stress-and-get-more-done-by-building-an-autopilot-schedule/">Monday Master Class: How to Reduce Stress and Get More Done By Building an Autopilot Schedule</a></li>
<li><a href="https://www.calnewport.com/blog/2009/11/24/are-passions-serendipitously-discovered-or-painstakingly-constructed/">Are Passions Serendipitously Discovered or Painstakingly Constructed?</a></li>
<li><a href="https://www.calnewport.com/blog/2018/06/08/jerry-seinfelds-closed-door/">Jerry Seinfeld’s Closed Door</a></li>
</ul>



  
  
  

  
  




          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030938</guid>
            <pubDate>Mon, 09 Nov 2020 02:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Windows 10 Installer Dystopia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25030752">thread link</a>) | @brenns10
<br/>
November 8, 2020 | https://brennan.io/2020/11/08/windows-10-nightmare-edition/ | <a href="https://web.archive.org/web/*/https://brennan.io/2020/11/08/windows-10-nightmare-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 08 November 2020</em></p><p>A few days ago I had the displeasure of helping a friend reinstall Windows on
their laptop, which had previously contained Ubuntu. The reason for their switch
isn’t that important – although I helpfully suggested keeping Linux, it was
their machine and their decision. I didn’t expect the process to be particularly
difficult. After all, I work on operating systems for a living now, so I didn’t
expect any trouble. But to my surprise, I encountered a nearly dystopian
situation before I even got to the desktop.</p>

<p>I started the process by creating a bootable USB from the ISO downloaded from
Microsoft’s <a href="https://www.microsoft.com/en-us/software-download/windows10ISO">download page</a>. It feels weird writing that, but yes, the ISO
seems to be freely, easily downloaded. No product key was required to download,
or even install. The USB creation process was not easy (Microsoft suggests using
Windows to create the bootable USB, a chicken-and-egg problem if ever there was
one). It seems that the standard <code>dd</code> process used by every Linux vendor does
not work here – instead you need to get the correct magic incantations of
partition types and filesystems, and then copy files from the ISO file into the
USB. I ended up falling back to a tool called <a href="https://github.com/slacka/WoeUSB">WoeUSB</a> to do this process,
after three failed manual attempts.</p>

<p>The real fun started after I (finally) successfully booted from the USB and
started through the installation wizard. Cortana loudly greeted me, telling me
she’d walk me through the installation process using my voice. I must say that,
while I don’t really care to have a voice assistant guide me through OS
installation, I can see it helping a lot of folks out there, if it works
properly (I did not test it). I’m glad that Microsoft is at least trying this
out!</p>

<p>I went through the (impressively quick) installation process, and the laptop
automatically rebooted. It prompted me to connect to the Internet, which I
foolishly did. Directly after connecting to WiFi, the wizard asked me to login
with a Microsoft account!</p>

<p>I chuckled internally. “Classic Microsoft, asking for a silly cloud login just
to use Windows,” I thought. I don’t know my friend’s MS account login, and even
if I did I wouldn’t link their OS account to some cloud account!</p>

<p>I searched for the cancel button, but couldn’t find one. I tried to submit the
form with empty username and password, but that didn’t work. Realizing that I
might be trapped, I got my phone and fired up Google.  Surely, Microsoft
wouldn’t make it <em>impossible</em> to setup a new PC without linking it to their
cloud, right?</p>

<p>I found an <a href="https://helpdeskgeek.com/windows-10/how-to-setup-windows-10-without-a-microsoft-account/">article</a> which said that, by disabling the Internet connection I
had just configured, I could skip the login process. So, I hit the back button
on the installer. The wizard animated for a moment as if it was working, and
then showed me the same login screen. No matter how many times I hit the back
button, the wizard did not let me go back to the Internet configuration page!</p>

<p>“They haven’t got me yet,” I thought. I held down the power button and rebooted
the computer. Certainly on reboot I would restart the process, and could skip
the Internet configuration, right?</p>

<p>The laptop rebooted to a Microsoft Account login page.</p>

<p>So, I did what any self-respecting, conscientious friend would do for a friend:
<strong>I reinstalled Windows all over again.</strong>  This time, during the setup wizard
after the reboot, I skipped configuring an Internet connection. I was greeted
with this page:</p>

<p><img src="https://brennan.io/images/win10-nointernet.png" alt="win10-nointernet"></p>

<p>This, to me, felt kind of chilling. After all, it’s not like I asked not to use
a MS account. All I did was decide not to configure Internet on my first boot,
which has nothing to do with linking a MS account. After all, maybe I just don’t
have Internet access at the moment, or maybe I forgot the WiFi password.  Why
should the installer lecture me about the benefits of a MS account when simply I
did not configure WiFi? It felt obvious that this was a bald-faced statement:
“we know you’re avoiding our login process, and in a few years we’ll get rid of
this loophole too. Welcome to the future!”</p>

<p>I clicked the text (which wasn’t highlighted as a link or as a button) which
said “Continue with limited setup”. This was an odd phrasing, given that none of
the operating system features I’m familiar with (scheduling processes, providing
a unified interface to hardware devices, etc) requires a cloud account.</p>

<p>At this point, I was allowed to create a “local account” for my friend, and
finish the setup. I was presented with a list of preferences, all helpfully
enabled by default:</p>

<p><img src="https://brennan.io/images/win10-privacy.png" alt="win10-privacy"></p>

<p>The irony here is beautiful. Ads “may be less relevant to you”. The only entity
this harms is Microsoft, being able to avertise at you less (within your very
<em>operating system</em>, no less). Why should they bill this as a negative?</p>

<p>After disabling all of the toggles, the desktop loaded for the first time, I
noticed the following at the bottom right:</p>

<p><img src="https://brennan.io/images/win10-edge.png" alt="win10-edge"></p>

<p>I used MS Edge to install Firefox, and closed it out. On reboot, the login
screen contained two advertisements (!!!) for MS Edge. I returned the laptop to
my friend, grateful I didn’t have to use this horror show of an operating
system.</p>

<h2 id="why-does-this-even-matter">Why does this even matter?</h2>

<p>I spend my workday working on operating systems. Don’t get me wrong, I’m new to
the field, and I have a lot to learn. But as far as I know, <strong>there is no
feature in a modern operating system which requires a cloud account login.</strong> (I
would love to be educated if this claim is false, please get in touch!)</p>

<p>I used to spend my career working on machine learning and data analysis. One
thing I remember from my “past life” is that <strong>there’s nothing better than
linking different types of identifiers together.</strong> If Microsoft can track you by
your “Windows installation ID” and also by your “Microsoft Account”, then <em>of
course</em> they want to link those two identifiers together.</p>

<p>More links means more data about you. What applications you run, what sites you
visit, etc. An operating system as at the root of what you trust when you use a
computer. Do you use online banking? Your operating system can read the password
to your bank account, the balances, and more, directly out of memory! I’m not
suggesting that Windows does that – I just want to illustrate the sort of trust
you implicitly use every time you login to your bank account on Windows (or Mac
OS for that matter). But maybe Microsoft just looks at how frequently you login
to your computer, or what sites you’re interested in. What DNS queries does your
OS resolve? What IP addresses have you used in the last 90 days?</p>

<p>All of the data which is obvious to your operating system, can be linked to your
personal identity when you connect it to a cloud account. Don’t get me wrong,
even if you don’t connect it to a cloud account, you still are getting
incredible amounts of telemetry and tracking recording your every move. But why
would you voluntarily give more links and data to Microsoft?</p>

<p>I don’t think most people understand the sort of data they’re giving over to
Microsoft when they login and use Windows. These dark patterns that Microsoft
employs are sickeningly obvious, and really difficult to avoid. Why would I
trust a company that tries to manipulate its customers into such total data
collection, to be responsible with the data it receives?</p>

<p>I can’t imagine how frustrating it must be to be an operating system developer
at Microsoft. I have a lot of respect for the operating system kernel they make.
It seems to be one of the few major non-Unix like kernels out there. It seems
fascinating and I’d love to learn more about it. But it must be frustrating to
see the product of your hard work go out packaged with software capable of
collecting and tracking your users’ every move, and thrown together with an
installer intent on forcing them to submit to this data collection.</p>



<hr>



  
  

  </div></div>]]>
            </description>
            <link>https://brennan.io/2020/11/08/windows-10-nightmare-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030752</guid>
            <pubDate>Mon, 09 Nov 2020 02:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Observations from listening and producing 350 startup podcasts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030613">thread link</a>) | @JollyMerchant
<br/>
November 8, 2020 | https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/ | <a href="https://web.archive.org/web/*/https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://viralwegrow.com/blog/content/images/size/w300/2020/11/istockphoto-165518488-170667a-1.jpg 300w,
                            https://viralwegrow.com/blog/content/images/size/w600/2020/11/istockphoto-165518488-170667a-1.jpg 600w,
                            https://viralwegrow.com/blog/content/images/size/w1000/2020/11/istockphoto-165518488-170667a-1.jpg 1000w,
                            https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg" alt="Observations from listening and producing 350+ startup podcasts">
            </figure>

            <section>
                <div>
                    <div><p>After listening to over 100 Nathan Latka Podcasts, observing 200 Indiehacker podcasts and watching 50 Microconf talks AND recording 80 episodes myself.</p><p>Here's what I've observed:</p><p><strong>SEO</strong><br>Over 70% of founders credited SEO for being their best source of growth. Invest into ASAP and build up that MOAT.</p><p><strong>FB / Social Media</strong><br>Its a hit or miss. Don't waste time curating the perfect Ad or post. Tim Doyle of Eucalyptus shared that his most profitable Ad was not some high quality video but rather a Doge meme.</p><p><strong>Velocity is everything</strong><br>When building companies you NEED to move fast, there is no alternative to it.</p><p><strong>Product</strong><br>Product led growth is the BEST type, its natural and doesn't feel forced.</p><p><strong>Distribution</strong><br>This is probably just as much if not more important than the content or product itself. Build with distribution in mind, articles / SEO or products.</p><p><strong>SLC</strong><br>NO ONE wants to use an MVP - stop using that mindset. Literally no one other than your Mum/Dad will use a "minimum" "viable" thing you build. Its 2020, the whole patchy product cycle doesn't exist. Aim for Simple, Loveable and Complete (or what I call Minimal Product for Impact) Introduce simple features that meet your north star and make sure they're complete.</p><p><strong>Cold Email</strong><br>Learn to master this, its a great skillset to have in building a company and distributing content.</p><p><strong>Feature Validation</strong><br>Before you build a feature, literally build a simple landing page, run some GAds to it for lifetime deals (this doesn't work always, but for some apps).</p><p><strong>Communicate</strong><br>Build every channel possible to communicate with your user as often as possible for as long as possible.</p><p><strong>No CC No Bueno</strong><br>UNTIL someone gives you their CC, you don't have validation. Do not take anything else as validation other than their CC.</p><p><strong>Timeframe</strong><br>Before you start, set a goal to hit, if you don't hit that goal, be quick to reflect. Build more or move on Last but the MOST important.</p><p><strong>Audience</strong><br>Almost 90% of all the "Super successful" founders attributed having a previous built audience as their reason for success. They built this audience through, podcasts, blogs, Youtube, Tiktok or even Newsletters. BUILD. AN. AUDIENCE. You have a higher chance of succeeding with a shit product and a large audience than vice versa For those that are keen.</p><p>All the best peeps!</p></div><p>-Vaibhav<br></p><blockquote><em><strong>Vaibhav</strong></em> has built several startups into Million Dollar businesses serving Millions of customers across the globe via five2one. He's commonly found on stage talking about AI/ML or Product engineering whilst building his 2nd startup cenario.</blockquote>
                </div>
            </section>

                <section>
    <h3>Subscribe to ViralWeGrow</h3>
    <p>Gain a personal advantage with our weekly insights and analysis into the startup hacks world.</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</main>






        

    </div><p><span></span>
        Could not sign up! Invalid sign up link.
    </p></div>]]>
            </description>
            <link>https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030613</guid>
            <pubDate>Mon, 09 Nov 2020 01:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big-O]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030390">thread link</a>) | @dleskosky
<br/>
November 8, 2020 | https://www.danielleskosky.com/big-o/ | <a href="https://web.archive.org/web/*/https://www.danielleskosky.com/big-o/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Big-O"><div>
<div><figure><img loading="lazy" width="2240" height="1260" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/bigo-banner.png" alt="Big O Banner"></figure></div>


<p>Big-O is pretty important.&nbsp; It is the metric that is used to describe the efficiency of algorithms.&nbsp; Having a thorough understanding of Big-O is crucial for ensuring that algorithms are as efficient as possible.&nbsp; Let’s learn more about this fundamental computer science topic.</p>


<h2>What is Big-O?</h2>


<p>Imagine that there is a ship builder.&nbsp; Her name is Andrea.&nbsp; She makes big ships and small ships for a port city.&nbsp; She can make the small ships pretty quickly, but the bigger ships take longer.&nbsp; The amount of&nbsp;<strong>time</strong> that it takes her to build a ship is proportional to the&nbsp;<strong>size</strong> of the ship.&nbsp;&nbsp;</p>
<p>Andrea is also a pirate.&nbsp; She is known to steal other peoples’ ships.&nbsp; She usually does her pirating in a port town that is 10 days worth of travel by land and 5 days of travel back with the stolen ship, so 15 days round trip.&nbsp; The port town that she pirates from always has the ship size that she is looking for.&nbsp;</p>
<p>If a customer asks Andrea to build a ship, she has two options.&nbsp; She can either build the ship or she could put on her pirate hat and go steal a ship.&nbsp;&nbsp;</p>
<p>So if someone wants Andrea to build a ship for them, which option should Andrea choose?&nbsp; That’s right!&nbsp; It depends.</p>
<ul>
<li><strong>Build the Ship: O(s):</strong>&nbsp; where s is the size of the ship.&nbsp; This is <strong>linear</strong> time.&nbsp; The time that it takes to build the ship increases linearly depending on the size of the ship.&nbsp;</li>
<li><strong>Steal the Ship: O(1):&nbsp;&nbsp;</strong>this is <strong>constant</strong> time.&nbsp; It doesn’t matter how big or small the ship is.&nbsp; It will always take Andrea 15 days to get the ship back to the customer.&nbsp;&nbsp;</li>
</ul>
<p>So Andrea should build the ship if she can get it done in less than 15 days.&nbsp; If the ship is big enough that it would take longer than 15 days to build, then Andrea should go steal the ship.&nbsp;</p>
<p>On a side note, this blog does not condone stealing and Andrea should really rethink her life of crime.</p>
<p>Here is a graph that represents the relationship between linear O(s) and constant O(1) time:</p>


<div><figure><img loading="lazy" width="532" height="484" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/constant-linear.png" alt="Constant v linear"></figure></div>


<p>There are many more possible runtimes that can occur besides linear and constant.&nbsp; Here is a graph that shows some of the more commonly-used runtimes:</p>


<figure><img loading="lazy" width="1618" height="1130" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/complexity-chart.png" alt="Complexity Chart"></figure>


<p>The above complexity chart comes from the <a href="https://www.bigocheatsheet.com/" target="_blank" rel="noopener noreferrer">Big-O Cheatsheet</a> website.&nbsp; Definitely a useful resource!</p>


<h2>The Three Cases</h2>


<p>Let’s use quick sort as an example.&nbsp; Quick sort picks a random element as a pivot and then swaps the values so that the elements less than the pivot appear before the elements that are greater than the pivot.&nbsp; Then it uses recursion to further sort the left and right sides.&nbsp; Learn more about quick sort <a href="https://www.geeksforgeeks.org/quick-sort/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<ul>
<li><strong>Best Case:</strong>&nbsp; The best case means that the algorithm is given the most ideal data.&nbsp; If all elements are equal in the array then quick sort will just have to traverse the array once.&nbsp; Traversing an array of <strong>N</strong> elements will give a runtime of&nbsp;<strong>O(N)</strong>.</li>
<li><strong>Worst Case:</strong>&nbsp; The worst case means that the algorithm is given the least ideal data.&nbsp; With quick sort, it could happen that the pivot is repeatedly the biggest element in the array.&nbsp; If this were to happen then instead of the subarray being recursively divided in half each time, the subbarray would only be reduced by one element.&nbsp; This would give a runtime of&nbsp;<strong>O(<b><i>N</i><sup>&nbsp;2</sup></b>)</strong>.</li>
<li><strong>Expected Case:</strong>&nbsp; Typically instead of having a worst case or a best case you are more likely to have an expected case.&nbsp; Sometimes the pivot will be high and sometimes the pivot will be low, but over time they will average each other out.&nbsp; This will give a runtime more close to&nbsp;<strong>O(N log N)</strong>.</li>
</ul>
<p>The best case runtime usually isn’t of too much interest when analyzing an algorithm.&nbsp; The&nbsp;<strong>worst</strong> and&nbsp;<strong>expected&nbsp;</strong>cases are the ones that need to be considered.</p>


<h2>Space Complexity</h2>


<p>Space complexity is used to describe the total amount of memory that an algorithm uses in respect to the input size of the algorithm.&nbsp;&nbsp;</p>
<p>If an algorithm requires an array of size <em>n</em>, this will require O(n) space.&nbsp; If there is a two dimensional array of size&nbsp;<em>n </em>by <em>n, </em>then O(n<sup>2</sup>) space is required.</p>


<h2>Some Useful Big-O Tips</h2>


<p>There are a couple of tips that you should keep in the back of your mind when you are working on finding the Big-O.&nbsp; Here they are:</p>
<ul>
<li><strong>No constants</strong></li>
<li><strong>No non-dominant terms</strong></li>
<li><strong>Consider multiple runtimes</strong></li>
</ul>


<h2>No Constants</h2>


<p>With Big-O time the constants are not taken into consideration.&nbsp;</p>
<blockquote>
<p>Big-O notation doesn’t care about constants because Big-O notation only describes the long-term growth rate of functions, rather than their absolute magnitudes.”&nbsp;&nbsp;</p>
</blockquote>
<p>An algorithm that might seem to be <em>O(2N)</em> is actually only <em>O(N).&nbsp; </em>Here is a <a href="https://stackoverflow.com/questions/22188851/why-is-the-constant-always-dropped-from-big-o-analysis#:~:text=Big%2DO%20notation%20doesn't,rather%20than%20their%20absolute%20magnitudes.&amp;text=A%20function%20whose%20runtime%20is%20n2%20%2F%202%20will%20be,runtime%20is%20just%20n2." target="_blank" rel="noopener noreferrer">Stack Overflow post</a> that does a pretty good job of describing it.&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>The runtime is O(array.length) or O(N).&nbsp;</p>
<p>Let’s take look at some more code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
}
for (int x : array) {
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>Your first intuition might to be assume that because there are two for loops that iterate the length of the array that the runtime must be O(2N).&nbsp; Don’t fall into this trap!&nbsp; The runtime is O(N).&nbsp; Remember to drop the constant!</p>


<h2>No Non-Dominant Terms</h2>


<p>What if you get a runtime like O(<i>N</i><sup>&nbsp;2</sup> + N)?&nbsp; What should we do then?&nbsp; Well, if you were able to deduce that we should drop the non-dominant term, then congratulations!&nbsp;&nbsp;</p>
<p>Consider the runtime O(<i>N</i><sup>&nbsp;2</sup> + <i>N</i><sup>&nbsp;2</sup>).&nbsp; This is the same as O(2<i>N</i><sup>&nbsp;2</sup>).&nbsp; We know that we should not include constants in our runtimes.&nbsp; So if one of the <i>N</i><sup>&nbsp;2</sup> terms is ignored then we can ignore the N in O(<i>N</i><sup>&nbsp;2</sup> + N) as well.&nbsp;&nbsp;</p>
<ul>
<li>O(<i>N</i><sup>&nbsp;2</sup> + N) becomes O(<i>N</i><sup> 2</sup>).</li>
<li>O(N + logN) becomes O(N).</li>
<li>O(5*2<sup>N</sup> + 1000N<sup>100</sup>) becomes O(2<sup>N</sup>).</li>
</ul>


<h2>Consider Multiple Runtimes</h2>


<p>If we had to iterate through two arrays of the same length N then we could say that the runtime was O(N) (remember to drop constants!).&nbsp; However what happens if the arrays are of different lengths?&nbsp;&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">for (int a : arrA) {
    print(a);
}

for (int b : arrB) {
    print(b);
}
</pre>

<p>We are iterating through two arrays of different lengths.&nbsp; The runtime is O(A + B).&nbsp; Both runtime lengths must be considered!</p>
<p>Let’s take a look at some more code:</p>

<pre title="">for (int a : arrA) {
    for (int b : arrB) {
        print(a + "," + b);
    }
}
</pre>

<p>If the arrays were of equal length we could say that the runtime was O(<i>N</i><sup>&nbsp;2</sup>).&nbsp; However, the arrays are different lengths.&nbsp; This means that for every element of A, arrB will be iterated through.&nbsp; This results in a runtime of <br>O(A * B).</p>


<h2>Thanks!</h2>


<p>Thanks for reading my post.&nbsp; I hope that you found it useful.&nbsp; Once you understand the material presented here, be sure to continue your learning about Big-O.</p>
<p>Here are some topics that you should explore next:</p>
<ul>
<li><a href="https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf" target="_blank" rel="noopener noreferrer">Log N Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/time-complexity-recursive-functions/" target="_blank" rel="noopener noreferrer">Recursive Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/amortized-time-complexity-analysis/" target="_blank" rel="noopener noreferrer">Amortized Time</a></li>
</ul>
<p>Thanks again!</p><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.danielleskosky.com/big-o/"
    dc:identifier="https://www.danielleskosky.com/big-o/"
    dc:title="Big-O"
    trackback:ping="https://www.danielleskosky.com/big-o/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.danielleskosky.com/big-o/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030390</guid>
            <pubDate>Mon, 09 Nov 2020 00:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the Underground: Supervised Discovery of Cybercrime Supply Chains [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030329">thread link</a>) | @stjo
<br/>
November 8, 2020 | https://damonmccoy.com/papers/ecrime2019.pdf | <a href="https://web.archive.org/web/*/https://damonmccoy.com/papers/ecrime2019.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Å”•PíTÃjÜ¿Ì9‚tœ†äWŸë_ûuVÓ#?‹ÒUY'ü{Ä^5t3},5Ý©Å�Â�YÜQŒµ‹;ðR(‘îh¡‡Y]çãS„i‹Ãq5èç´®ÞáîÀæŸ‰ÌpÞàüó_°ZNöÁ
¸xy5~­uH­�ÔÜêU[-x»ºÙú–e©–0ø‘
[¤3N=V´\ûuíjŽGw±t ð[ÏR!ÀKöžÁç÷÷N°�„Ä:Ám9-·¢‘ß´Z¤¾™Õ·Þiê5
«4w¦-&nbsp;.ÞR*Abd…âH@‘òWx­¶¥‹¿ÙB	KDÐ!|GD«e÷)
î2BæÆi
&gt;R 4&nbsp;†Þ·E»Øµ‡½PŠmÀ&nbsp;#eHÓàë-íHÊðjR_dW�]�Ï³²˜ä§](©‚EJ÷<wtÓ€ )!v‘¢_«¨—�œd“�Íi="">Œ‹Ëºø”wÊGH�n	Ñ" S­¡=ÄQUW×Ù(£ì)+³áõ¤èÂö$ü”¤ÊÆ!iÊ—Û#¼Ì&amp;õÐ€0.Àò¤ÅŠò¼—.ÕÀ©‚T'˜“jò‘0ÚQžM®ÆÝàI	nã¨aáe©`AlY§mcÍºq)áÛƒ?‹R	±š¯»v…“v‰ñÀ†ÐÙuqIfPÖq*;Í1�¯
ÂØÓE5¬É±äŸ‘T–m
&gt;/È:…-âS1©5ºl8¬NÉ¯¸ú"/bÌ±Í¶A{h§ù _Ó&gt;8-àòòÓ¢î¸°%)oTÈ¾iGBHe&lt;Ø]\—&lt;¢C¡¢@*\Naª�øZ˜˜„K°µ R›‡)eòT× *kGß‡a•žk$`T¤Ò;E6KDE#~¨u“ðY%°(sb]J§TC£j�I¯3&lt;+Zeâ·mm\Œò““.µdh´])–ìÉ(Ú®”ÃHÚàûýýO[¿õ_½Ýÿ£Ÿ:IŽÈ®f�Í‚¦G[‚{}VU°~ ”]
+pônÀXƒM‰O`¤w3Æy.ÛÕ›¥À�ð=ðýM½©eÜ„G²bSý»S3ðÆ £ƒýx`CV‘{-Û }“ :|œVÆ;`Ó§dþÛÀRÅFè$Ó&gt;eíòg��s&gt;È.;çîV;®‰ü¤H˜
’-z_.à×Î”¾ì	C‰ÊÐ[MN/
¶Ñ$E�u°„n÷j&lt;Îkb%~ÿ4/ëâì!ëp¿“?Aø÷v	¢„3^äú5I¯¢Ø*µe	�î"½Í�Ýy˜Ÿ`]Škl�Ò»U*KµÇ¯7Õäl�k§×p^®Ö˜ò‘»v·ÛJ�6z«ýõÆˆü‚Äf5áË�´
’ÄÒàŽøðaÊÓèmrƒ?º¨FÙ„¼—ßzµÿnKƒhgyú«#î{£ƒ¸@…šŸ‘Î€Qê/&lt;œZìYq~5^ú´.K�*GÚ‹©Ëµ‚{O›BR&nbsp;ÿþ<mƒa8:,#è-�‘<�sˆ «¾¾Ùç!Ù%�°±k="" r‚ú="" ìû“ÅÏ‹y»jÌ6v.ÆÕ¨¸áÙauú­nØì§w¬h£ÿ±ÈÒ†9ób="">ûËÖ{[�GÙ�õÖyÇó�m&lt;ï½Ù�zoþ–þ¾§'o˜ÄM›Õã«¼Us_÷l’'§Ø;-œ¼Íÿ|s/ûGÐ^&gt;äåiVÖÔd’^~LÝ"þª û+Ï¡§êëÍ×
5�à¨ú­,Ð0g3<ulš²-Ûbhag·=©óÑ~yv%«þy.Í»1Ÿ÷™êy–}Í6¶o«“t_»º¼æ#´À¼dòé¨úu÷ »\bÆß“ªhþÝy}Ög\ÚÅrÐ›Úzuc½÷i}@ì€Ñtî‰6¬9ÆÆ¶e="" �w‰`àÈÌ‚žhkg�à?4¾="">fŽŽþ ƒVb…˜Aow›�46Øg�é9ýª›3/î–ˆŽš#¨Rë`iO/¡#!Ò	:Õl½£b(ž¥šüƒ¨iÉÞk�¿¨€³Ë×yq~QCM
´?BŸ³}Q§„_‹€§·7ÌÎ'ÌMg{ù²úŒ©6-±fK]6áÉAMÓ‘+A§æîƒž•¨Ï^1ä9'Âƒ·Ù(¿SÖûu6,Ûåù0'™ô!õß™×„c¶˜&nbsp;±ì†¬žË
¥xì%Þj¬0ÖK¹n¨¹ÕíqCÍ½¡âñ"•\©ÿb÷¿Î‡ŸòºÀ—wÅ/ÛÆ)*FyÕƒz0º5ý`ZÓiCk¾ íƒap­1¸ocøÆ~ð­ç^�³}cîÐzîÈZcî'Šþ&gt;®ý�¦”4¦B.uo�Eß/©Ù1(×T�RDäL5šxýEl8`Z64dXP-Ñd~‹+ñ£[Øh-D¢+SBö¬)YBÉ&nbsp;
¥ÓzÁ-šYÜ£W&nbsp;,ÎGCŒÇÌšÊt&nbsp;AÇÐì°Ùžýÿ—bÏ‰µÒ'2 GB_ê±™õ<o¨n€ÇøÐ0¨ç¾xÝi±.üo-Öt[lœ¹‹;—ùôáq~µmxt7œØl¹Í¸5];¼&h^Ã%s?ÕðËóà%ntþ2ì}5¼=a®_z ófÌøª$}s’af`ª´b="" Žáæ�|yÐð^Ðr«›é="">í†‘@ÏËt_Eƒ0~žî#!º‘ïG+¸£¬žmš ècèÿüè�Q U"‰S’Û0EÑÌúo6*½3Û§ÿT²Ö`“=ïz†zôzÆÓ/QþøKT?þõ�¿Dó�–øäþTÙÇõ§O¿@÷ü/)cpendstream
endobj
180 0 obj
&lt;&lt; /Filter /FlateDecode /S 186 /Length 183 &gt;&gt;
stream
xœc```b`ëd`e`šÁ Æ`620°Xèp09°1p8±L`°~°§œ!¶Œ�çsÜÓsF\azÉæ
,-s\.oìÇtp'GEekxˆ‰‹ëškS¢®wº®Nït]džÑ@|}J8P°ÂõzKxKø0$Å|&nbsp;Ë||Í%�4'ó��}Ž�Ÿ�ÁeÂëƒçüs¾”�,Q˜¤p5îäåÏèäÞHw
endstream
endobj
181 0 obj
&lt;&lt; /Annots [ 191 0 R 192 0 R 193 0 R 194 0 R 195 0 R 196 0 R 197 0 R 198 0 R 199 0 R 200 0 R ] /Contents 182 0 R /MediaBox [ 0 0 612 792 ] /Parent 387 0 R /Resources 203 0 R /Type /Page &gt;&gt;
endobj
182 0 obj
&lt;&lt; /Filter /FlateDecode /Length 4519 &gt;&gt;
stream
xÚ¥Z[“ãÆ­~÷¯˜‡ã*Í©Í»È&lt;ÙY¯ÏÙT¼veÇq¥Ö~è![3©ðâñì¯&gt;MRÎ&amp;©¼Hhô�&gt;&nbsp;éßnü›ÿûÂ¿úÿãý_}DþMyyàG7÷û›8óò4¾Ù…¾—Ñÿ}yóqó½9Ÿ«æp»�âx3-ˆhóSSÚî6È6‡®›òRýa&lt;Ûî·ª·¥´ú¶ê‹ö6H6¿áÇvÏÒ¬Ýßþzÿ§› L¼ Jo¶áÎËòT¦{óü`»¢«N˜(ñ1ä¹~úÍÑTM�¾²òÀ÷ò$Ë±òmšyqº»ÙF�e¡ŒõÓW�FúþñhjÛ™V{ûþÍÎËw~€Î»ÈÃÝ
É!É¥ç/¾­Î{»(¤Yæ¦w2þ÷æ÷'[×Rø¦®Ì¹ëªí×æ£’—ñ7á;šCEtO¦ªUÐkû½(YÎöüÊTaº:ÕSº¹¾Ùwí§µ9Rß‹‚l9É§ÿl’oÍ©mT–ÅÚŒ?-ór3‰¯ŠŽÍC/�I	‚Ðs:°lx““~‡)†ÉèÈ±Œ4PÅ{o!¿'YÁßnópÓv�Rú©©~ƒ¶û›¾²[Œy­Êw;ZYwBä3Mø¼¶¬�·‹ó‹u]MÎ¢$Âœºª&lt;&nbsp;Ö®­š–¥ÿÙº&gt;ý{ëz×¶kÌPµ�QµÓžÎ#qUkŠÊ6…^ãwM?TU®­r¦©!\f2AÇ·÷áøuƒƒy=[Žª+'3_°•j\
ïâV|]Ô^aNž)¼ñQ[õÐê¯«¢¯&lt;29�,Ãš•àù6M6ËéŠBôñr.ÚÉ«Š­Å70£°Ÿ´52m¬ïdêrÝØ7ýÐ™bp¢Hí#º)Aâì2KliûÁ4%[á$JÅ
'ÑnÓÛŒ�q/|¨Øg¶Ì-ñ{WÕX[’Uæk“NÐ‘oq‘L4´Ô,6d¾÷·aBª†‘¿Vƒªe¯êµ®‹
*€‚ö–‚Ýïm1TÝo¢¢Òš33¨PïñÚ|Y•ÞÝÿg©?Yõ Ô¶Ã½¤S	éï`2èKe’Jo…ìÕi„y´)Äi0¿;ÞÍ)ÕáFÊÿ+!´á@»Ü.W¤r*h¥ã‰§Œ#èa3bç&nbsp;i³²÷ÁÆÏÐ"+´žÈ¹í™ÁråìplK¡‡£„ª—;6Û¯¬ädŠcÕðíÊ©ƒéÐ¥G�úR©:tæ|Ü&gt;ñÉÄ0t]Ÿ{J8x´·{2”!nì Þ6ßØß'-½:'Þ8ßMâ½—]ž´æJg¸…ˆh&lt;õRžm~;©y1¦�åê1P+x‹$¦­Ö‡¶«†ãIŠ…Q~UBµöÏRŠ¢/A"pâðK!ääB7Í&nbsp;cM€ãjO4_ÅÞ*&nbsp;“ø{Ë&amp;/Ü¼muÕ…¯Glþ2ö}e´õ,�;é£zw¾¼)$Š$×lú£\œîËÓ¨Nª]sïíg]p!i²l=P¥¨I‡\Ë½üÁ—BðÐ#ùòN8¯®uço¼1ñé¦»x¡t(a&amp;üóJÒ]2&gt;˜N¡@—–0Œå`•3ÂÖÏW’˜og#š�-‘àìðd-T‰­R*ÇbÐjÙ ¬ö¨bS
Ž^FêfdÓÂ&gt;·”ÊÔõóÊIŒ½Ý�5,H.�Íväë�œêÈŠL5,ÔTu]Õ&nbsp;í�”Ùï£šý¾´ïíŠ.®W˜F›ïœ9Ó˜.´9�ë[²ËwÂhÇNšéU‡‰@q2Ÿé|àÓê`üè4¤\Òõ—«hGˆ.ŽU¾q²¡S´ÏÂ«
ï^L("
[›ŠÜXÕg8b¥U'%Rr²¬†ñwkWä/Ñ	éÓ~lX
DÀÄ`Áíç#¸ÍBVêˆ—Ž[öƒÑwï”öw¥hs/D'Ø¯ypŠ¡âðÂƒ°äwp†r£1Â›Û¨Ì÷f;v'4üŸMsÉöKÕ�¢»b·IF1Î¥‡¯×Kñ›¦^š Ê
(èt3dßpe·	àÒÜk£$^J”nã=Ý¾�ö½MÉœÑá‡›˜ó-s~búÍ¢Í;¦¥ÍûUÈGP=ÌcB|ˆw×±ßÖô[³ý€`'žÑ†�Ø]*)‹ñB2c]WÁ¸1·•º¥ˆ6AîIÿYlz¤A@±C"3’
ôÇ¤ƒ;]©yÝÿáYëÛÓ©-«¡ú$ÚK¬²b5ÚÛÎÂg€u6Ý&nbsp;Ù¢Ò¿&amp;'¶œ|0Å#ã�`ó1Œõ„ü«à+%C�¯-QøÀùðCóyQÅï„kä¯?›ÓÉvk“b™YÈ2‹³¡RÈ·�xFþžØ&gt;K½´#te]+»Ä†'C½)£¬T¡BÄDrŠC·¶Œ¢³lN"òÌýÐv–âKHå'û@!�eGc§�©$!LÍ„8¶=Ð&nbsp;6ïXvšùJ¿”í	–�–ÉñesÀgvRAr©køTmlŠÂžiÜ65Ã0ðÏæ™=ïêNÙ°‘öcxF„OÀ ¸3ÒÎO¬ÁTÝ‹Ò{RúùH[å–/mpV&amp;t‡Ïx“QQ…0Î=ÙýBqèµG\&amp;Z=Ð•&nbsp;U’VOtº<a”o�È_vŸØ¹`3�t´,5bpfŸr1˜þÑ“ª7w·‘ûíÉ¯mÜyöy@2�ü�—i*a^Ür+cîÙh=6ŠkÎûaÐ³5º�Ù™Ò¾²>—þX�!¶0v8‚$&amp;'@¬=ß©ÒeÕG¥`2ª”ON·9(‡�5™&nbsp;˜‡¶-û5­VÐé;5ê¥TifE³8ý"©¦`¤¬ŒVß6‚æÓùØ{^išÏ€�hØS�(ø7Z³”6º²�6_B
”‡ixþkV[‚^Zs¦�(Ëp«\¼6-'&gt;
ýM[Kö±œj¸ƒ€b8ý’ƒ®×“Võ÷„ÿcWµ«†”M$§Šâ$ÚM/°˜®¥þO
«á
Ö+îâ$šÌQ+ÓFlg·kgÞ�5â•(Þ`Í�’ýhÒ &amp;3iAEb+À•u�[´c]
Ó6¤ùVØV¯»‹rMÕKu£&lt;ñÉ³&lt;[â‡Pxp�'£ƒ1ç�q:šõvžˆáªk�á¾ã`hè½f÷†±d³•Ä©Þ§sÝ
âLJ.í
š�œXöRÍI”8uÖlv5…rmò®LJì0Œ˜Iš—%)‰"ùõNj?†Ñ¯BI8Jµª/Âí['%ì&nbsp;0lhÂÊüVpÆ©eï»K×O­VãÂÜ†)‚ªw¼gÜ@6öLnžî™x`çvmî–ú&nbsp;K,LJ†×BHQ#¡yŽ,I!Ä€ª�Ã4ÿ©!#&lt;Œ°5çßî„/¸ª÷ŒôX£Íc#¬my°Â",qêÅ	ÅÑdôAWú�‘¦@P4k;¾TÅ$Ÿ²@Iê;çö7óòEã´K)¹WkºâÈ@]FV34ÑÇ¶X›W2”¼µ9¥¬R“;	…E2ô$Nëa{j
¡„‘·À¤Vº|F4k˜•…þ"¼•²¤$OÌ}&gt;[Í&gt;´ãá¨ì©WßÖå‹ZÕq2;­4uC¨³¦2L3H¶¿,8÷‚w¨¼VZÏù"mYu«)Þ
}=?ˆoâ&lt;öòXŸÉÔÐØn¨ØžïB
e‰Xä%&lt;á|ï²w( {×hHª!B,"¨±¿²;éâ0È&gt;™‘ðãt&nbsp;j;ÀŸ².³aKV&lt;Ñ¿ÓF�XÕ�×û`ÆºýÔ¹:â‹	 –;|f²Tü�&gt;ª?†)[bª\ºœô*¢ûÉ‹2.‚7%Ø
Y^½=NîV	qL.a›8ÚEÞ(šw·²&gt;,@§¦„�S5»«˜ìÙ3®
y¤t—»ôü¤Çç©š³Û&lt;×<yù§õhnvbªgb³âó ­ü÷d,iful«í<÷¤gÍ''Ð!Êâi…‚;af¢8á4="" Ûxæ^éx{—ŒbÙÀµÀhzzlØ£¨mß³{–ÈÃum¦…ÛaßàµˆóÁ‘•€2Òqï8w¥Ððîu]vÓenc¢$&9œëÊq«¦$!Š·a¥(9jŒ0ÔÖå”•­òd×Ýð+ëÐ½q$�ˆdê8i¬j‰Õc="">oðmÍ‚ƒÁy~!å†e¼¦^YËFkf½[²®0œ-SëQ¶KIì—W\Šƒ{!§ûƒ^|½}gÓ®¡ÞªX•0Vó	¢ä¡kÐ²­ë©N–³�Dsº™»N*…ÒR†(�Þ®™Ó3C|þpaõ(±÷À\NÁ,íô
�¢Ú0�¦Ôœ/Öº›¨ûÌþgÍ/ŒŽ›øs@§zùjð6�Õ«&amp;æçÛŒßàÂ&lt;—BT¢Ià¨¿ÜíÖ6Z1?¢Ån°çã–‰çêÌo	/mÌ8¸ç§OŠx‘³Î#…Ûƒ*&lt;`‰&gt;ÂUµ†#IþÒy%ùldPxÅÈLëÛFút‰7ìhµf6…TâG#nÈ§@?�X±’4Œ»üÊ)ÿí¸š~šŸŠÈˆÖS²vR&amp;#b~8zÑfrØ¨êÜ“Ìêã	{M÷â`rãþÙ‡&nbsp;Ü Çž…J
žbßnƒ
´…Å£Z1¨&nbsp;~4’ÁJ!ðh´š#ym­Û0‹f%ºŸB"”.
¢´^ˆºÅP¥vtš›-ž3
¤AþE,{2EÇ
¤I¢&gt;¹IóÀ¹W&amp;é�´ôB'Ùt3À$òéX1"Åh½üëKÑÊÔ{6AùnŠPÊæ&nbsp;U¢ Äå
Eü®z™SopqŠ_ä-%"‘ê½žŸV\Íé þpëÇZô4Ò±š��¾‹E�-"›HP¥rùÃ(ùòKþGWÓrôu·vMŠ¶ÄóHD
UšÁ(©ð)â--çŸQprÎÆJ`Í6%ÜYY®7&gt;÷]²cí(F÷=A¶Û’]Ü­+ËNH"û	}úmF°s�Òüà�J§¤ÌwXóš¡AôÏÁ©hÛ«vö2�˜úêË€SSŸóúàx�ª¢0§¼ðÎˆV2'×�Ï¤…X—t¼qG?å»’ÜŽífæ4•ˆ,`Nªùº�ÚÍº*6˜?%}
1\¾…Yê²w»ÉŽ¾š¥XnaGý…åLóÏY#Tßësá"Ý‰!¦…ÿTì­ÈÀ%Ñ"�(þ5ÔôÉgR~vI£
?ªr�Ø_âQ‡wT9~æ/ÞR×®ïâe5Œv›q¨\&gt;ÚiŽ|·Ìkãº’¡‡µGª–Q±'“L­MÝ·B­ø*§5|£"Jœ›‘–”¤ ¸€ÐÊ5Žw
©&lt;‡šá”½_;Ä4ô£û(Á
Z¾–ÈxÍr.g´|Bá*±Ö/~âWžõîÔ&lt;ËŸFD-6±²’&gt;¼—nÈÊŒÃýHKZyÐ’ÚeB_5‰?ïi9þ²*ŠväÄ.:»%gÑ¬%8ÆàÐN‚“�Ä�ÑŽPðÓQO¤†-9ýëIœ8qô™O†1Ì^\’Š³ÉºŽý:ëâgù¯[²[ú¡ûœ‚Ño;¡àJ«	íªéÛCÍ¶Sßä3ÆùÞ�èÓ„›ùY±’#Ò¼õòKñTDH8.PÛ­zÂäû¶Ö÷i’Ç.ÒF7»
"ÏwŸ¬þïe‹�dJýéžÅAH°fa‘Ú³0�üõ‹�¬c`Ó9~¦Zö¹&lt;ÄÕ•\	Uˆ�Ïææ×Ùä)‚_|Jz²{DCç?L¹Üw…¶xRËN„ûÀ
4‡£kOÑî»|o2Ã\”ôUG®?Ùe®—J	‰ÐØäË@öµ»�Hê2=Â¼•Øv-æ’�Fæ#Ü®Iò³ÇÌÆ¶Ûó§–üªÜÈ‹òŒÀ…ò¿„iÙºá]|@‡6‹ïÖ.ÖµÈÆq~ù
gâ/Å±~ç3GAR�&nbsp;ÜÉó¿ó&gt;'ù2gHÑž¼6H
g4ð¯/©msQ«_à­�®:íÄŸRü&nbsp;/–}'
»&lt;£ë¯`(ZÈ¼4ÎÜw0ù.ÛÛ]˜Û4Ê¢môU�õ?Qàù¾Î&amp;Aè¹~ˆüöíÛ‹ñßÞñOjl”¹
endstream
endobj
183 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 1421 /Length2 6662 /Length3 0 /Length 7636 &gt;&gt;
stream
xÚ�uT”m×.-Ž 
ÒCwwJJKwè03À303tw
ˆ4ˆÒ"RJŠ - ¢´€t‡ÿ¨ïû½ÿû�³Ö9ëYkžç¾vÜ{ßûºîá`10P† ì¡÷p´€ˆ&nbsp;°,PUÏØR(,,&amp;(,,
àà0�¡]¡Á3(CÀeÿ—ƒ*
Bc05ã§‡€µ=]�"b@IY)Yaa&nbsp;¨°°ÌßŽ¤,P
äƒõ�Ú8àPE¸û"aŽNhÌ6¹Á&lt;@)þßá@e7(Á�z ´Ô
³#ä
4F€aP´ï¿RpË;¡Ñî²BBÞÞÞ‚ 7” é¨ÈÃô†¡�€FPé…5¼rƒþéLÀ4q‚¡þàÆ´7	bW
Ga"&lt;á(ˆÙh¬¥Ôw‡Âÿ8ëþqàþu6@A‘ÿ¤û+úW"üw0F¸¹ƒà¾0¸#Ðæ
êßÓDû&nbsp;ù� 8ä—#È…ÀÄƒ¼@0W�=Æáwå à=eC Óà_í¡ÀH˜;%ˆ‚¹þjQèWÌ)«Ã!ª77(�üªO
†„‚1Çî+ôg².p„7Üÿ¯…qøÕÄÓ]Èóð„j©ýå‚�ÿ`ŽP4PBXFRR\õB}ÀNB¿Ò›øºCE~Á˜ýÝî@LÐ@˜óø£@^P é	
ôÿß†¯""@ŒÚCapÀ?Ù10ÔáÏ3|$Ìh-ŒážPø×óŸ/[½ ¸«ï?î¿ç+d¦fn&nbsp;lÂ÷§ãÿØTT&gt;@1a&nbsp;€Œ„PDDZ(%%üwì¯2„ÿ‰Õ‚; €2ªÅÓß{ýEî¿ÄÁüw®ûk¡@îHn#,!ÆüˆüSýwÈÿ�á¿²ü¿HþßÝótuýmæþmÿ?Ì 7˜«ï_Òz¢1ÐC`dÿoWsèÑêA!0O·ÿ¶j¡A!(Ã1dÿƒÃP÷`&gt;Pˆ
vúC™?¸é/©¹ÂàP
öënÁD	ÿ—
£/°æþ@axùÛÅÈçßûªÃÁÈ/�‰JHAH$È Œ¡“(fÞþ"AB&nbsp;&gt;¿™„#Ð˜ ¦Ç@&nbsp;	ø5V1&nbsp;…é†rÁLÁé—ñ7."*‚€1Çñ&amp;ú7±wý
ÿ«°'‰ÑäoÊ`
ý{ýû€B}&nbsp;`À§)X.Â¹&gt;¢í´V™Þ[`åÁ—¯±É–½1hÎéçþNº7²5Æ=TBªîfÌ”E�MÐóþ8ö±y›º�®ù�¥Þ»¤²+�?pvðÖÊAÐ9ŽHeÄ.‘í&lt;6d$yh�gÍõÄ|ê2RªKl­zµèªµf%³	t“²¤Ó£)çulâÄ[²°E¿·´!M$GZgzšh™Ž\áÄÃOTÚhÏ|—¬³ÞÏÏ¿ËíëÍÛ/Ðé®‘¬Š¢&nbsp;¥ôÓfÉLé§¥zœ«ÝŒÂâT‘8V-KKf¥}áÅ¹€êíþd-Óòf
¢Í½ñhçñá½æ{,xJôÖ3ãÚ�@ûÝÞúyý›.¡ä"mÛ1ùà”óùí
î&amp;‚%@‡dbÀ€¸^QbÛÁ¢¸ƒÃcÅ~UBâ|:¹Ù¡ŸÖ·ÎFíÊŽ�%¶àrÙŠ�ªÏ‰9±~ÊÝ'^&gt;uG$µQñw�,&nbsp;&amp;Q5dœô­AÓ•Ÿ:�ë†h	nûÊY	Þ?ôiª K7‹Ö•w÷pc8{'¬wC
ñ|Y¿ÅvŸˆmÎ1c­&amp;âéJÀÙŒClºD¨wË\ÕœéDÂ�K*ß¦ô­·s&gt;_ùÐWb£�Ðâ5ïœó"±yâ2=øcðVºBŸÐ×	V«Fž‚4‰ëj¦Ù6ÜÀn»‹iÁw¿û�vÏÜŠx²�ô«ÙÜñÀ~ $ž“'n™&gt;å[x‘@òá�èZÉ2~qV”ÃôU~w�o°c—2yIG4·
Aî}´ß#œúÇ%ÇE}Âc@¿oš]N8$˜9ìõ…VÇá‡9%‹ö*ÊKÿÂ©=ÿZóù�ê`Ý—�Ì
'ô
Q+%?ß›ðá
ÃK&amp;"ÙrÐd‰ŸÎ–¨’pÔ7ÉË¬=wá/òáûf£NÚ82â¹Ä�WQ8Y¸î)œ)Ü[nq«R¹Ÿð­ÃÜXìR7Á�qÖ0Ö[³ÝûBªgÖ4™.¯î"ïí‚’ãÓX×Ð¶w’e…«ùå¼õä´o›2Û6†ÁÉÌø¹(Í@ùÂá{N)E½b¶r­N
ÞG×IÌ�õöGgnÙ±~%1.Ã¤tEâ²_SiÈŽ¥F¢$�	ÃvT$Û©'ch‡/?á…Ê_x|exKÇ•xBñÕ-¸&gt;ÄUÊWØ‘½á{¨œ¦é;Á3×2^Žtañq¾k.oKiG1"[»‡“DÃd!ïéÝ5ï²û†7„ôˆ1;^B�y[ÉL²’Ùz?³;oÈD~Tí1cVýbœ(,è„¼ã¬%A�pU	y–þŽ
ßHrö¤Çm2{9&nbsp;€¦2Fjã�Èß�µs:Ñ“8�k&nbsp;À�l&amp;%/ŸÐXÓ¦Ì„¯µši,õa“‡hÏ’ÕÉ{¯…îÁery�õBPxÖò·ïÜé±µEo&nbsp;
qó
=ÏüŸj–?!Ê'¯üô”¥tÍ½b-B¯œ@Âôƒ'?–b,¬ÛÚ1ÔTÉiH*hÓ²x¬s†eXb$‰¼eõ9Ží²pÓ¯ïÜ¤û�E&gt;š×—ÚVe&amp;ÿ¥ÏÅ&nbsp;p©S®»UÇ‡Sæ&lt;ð!á\IicQÒ×2¯›š!Ù"¼I8o“‘+WÑ\a_qíÚ%§FÌ‡;ÓÈ·‰m,Ýö,�î¾ðmÍfÑJ@8òSÈ¶tæŽì§~–5Õ[ãjâÈkÐ5m/{pB:ƒ±ªti³o–ƒóîO4%¬[…ù�‰XŸÈ‰/‡ºÛ­7Ýßq¿(÷PQ’“pÍÄžÎQq=Š^ø�Lf‘rÖóÈ¥1&nbsp;hUÏ0­Ï&nbsp;1dcöª¶G�^&lt;¦Ó.‰¤}½e,3~QágÇ¼ÕÏÃ8EpwlQ@¦öz;ÏWïhvkæ•�|³Ç&amp;d5§’Œ1€W½
ŸŸ=Å»Ä]ZâMú¶Bs¯ÒUGzŒî†-{¤z¡ÛGw¥ÞBß&gt;É69`o�&amp;¯<k^n¢»r,jÔ³]áðgt¤è(Í´|fû1ª$ö 7‡Â<÷Õ`ÿ—}µçeÓüœõn,}ŸÂËbffé¶="~ÚëðôM:ÄÊK/ðƒ¤Ì''{ÓUÒ|NÃÆðôÔD%Ç.–‹è|kY¯dó&quot;‡Y¢ÈXÕ–€rnlûÙ]\X­Yæª�_'ã¨ËP&nbsp;Uy°²ÆÁR<M‹óç³Ðå­åÅ¨" £ãpæšêÝwn»œiõõ}¶›ÑÅpóð°;ýàÂåœm·%y¯~n?Þ8v›®="">¾.&gt;™«³Ü{FÎÞ730W�·¯F­èýÉè2´?Ä*ô:�rEºgé­ªtN–ç4�õ¹ºäI¶WÞ]¥ŽmA§yì�s’—Z(úRb·^i“7:=ì&lt;)‹ã]áÜ×·,wñ½•¾uwˆ9Y÷˜¦öµ´ßd‹ê&lt;Œ8&amp;J¶g5x:X[éÖ?Ž™G6?üG&amp;ÈP^è
cÇõ.¹{çGm,µ2&nbsp;�ý¼¬2‘¬J¿‹&nbsp;Ii
¬8ž¬.z{nJ+Çö¥Ñr'ß»änÝLÙ›"¨›ôú0s&nbsp;îüî¥ƒ¼Iêyö½T<h®f-×±!ég›.o�égÏæÉž� {@½s"vay;="" *‚ŸÈ™–x‰xŒºÙeÞä-‰�}vù¢:c¶ËÂój|¹¢võÍ+¿¦{¬="" s­¬Ô="" ¸ÆÌÄ¾»ÃŒo:ø³f¯ù÷l#ÂèÓc="">p/á)Šx0qŠº1Äí»S‹jQ3ê\å«pÍyk„÷ÑE?lF¦j¥­R&amp;�Z_ü(?ÐuþÈ½þÃ‡Àž
Z�nÐ5æÖÇ½Sßš!m{j‹–Î]e1e�ÞˆyB¨R\„#ñ£î:K´;¹‰ŽHë{Ž6A*Ü¼êdì•Ò,ˆô½l©gÕSÚOßªCñ×Ÿ€¥R£|gè(fN’³@‹†éúÏ¸™â¯Iò}Žã]Þz@è
¥ÎÀ^{€ÒÇ4‡„¶mþ¯RªäWGˆ×i7u,F™¥î‘ÛÓq…µÁ“`¿œOþäÝæDÖ²/ÂŒJXÒ´…ûpÜÁ"à§*=f:¸f,9„&amp;U]«®á=‘–/‹IµpÈ.âc\_~÷å�½9ñrL;ô34
Ò¶)©:ºÀ�RmurþUWfâ�­¥‡âó`ZŸ<f¡¼´õ‚ ýÏÒ¹5ål¬ŠÙßÎc*Ë�êõc¸(îpêÑxæ]¾‡˜_v7±Ðçm�*ý="" g‰Á="" êób+µèèðÔxÚòhýåÙl�ÿ-ŒaÑ(³ÇrdÙˆfò“'îÏoï‰†¦="" k6};eç¼[ÜŠoé|h¹¦="" Àk:–«yø3·ª2jœÄr‘azùå±¤Ùæ§ãtzlÕùÒtya#æo‘��o(n="©=UÕ!Ý#Õ?L¸GÕ3Ï%—7�n$R/ˆÍWê&quot;Ø¬¹Z(—ÞÚ?JRXÇ6V,wŸ" s_*Šc"o™�l{ÀÆk-÷ôÛÚ®æÉùkÇªËb“ó"¦Àå±íhß¡×edü‹”dùoñÍíxz‹…s="" y†ˆááè²�h©úy×wÂoj¥­ãÃÁ@¥çÂøi!å&á7ˆÒªj¥“¯pd�g‰£Ëmsõjórgãpê="">épÝfù&gt;õp?¤óL/#Úf­¹P±ñˆNèíu›ƒÆ‘ÓôRGLr]žaH~"1yÕõg¿"ÅËÁ—Ãš�)ÙEÇÖð0‚'­¸æ
ýxsU…A(UÁñ,¥ZÓó¶:=Š¡�|Ï¾D;7¬:b©b5¹Ã­æ¢m¾”úÕÚ!pFš%ÆäM;¾ÑŒU�É3Ù˜bþð®aUÄ:gM©ïý3bX7¬GÕ�rRíœpø·/µ&nbsp;…	œä,pöÐ«3E[ïÝŽv¬UKœÝj~q3®åSWì‘0{´ïKpHh%HÃ×RYÁ#¦Ì‚0OJÇ$æîW»Oú'ÜËâ¢ÌÓp÷=õz}Ø¢P“¯ŸôZ®¤Ž¹]Œ¤Wù®2êÛ*ÝÔhºPEwË»’ÌFz#Ÿ�H¥j²Auð%ót#&nbsp;Ÿb'“H‰óUüØucÊ&lt;5Lã2—àï._›/Ö�¾¨›lËïz](¨&lt;ƒÏ"KY8Q«ò„¯²¾žäzÞ�˜8à1&nbsp;:¶\/¶ÏyUÝÿ³BÃø"qü›þ…</f¡¼´õ‚></h®f-×±!ég›.o�égïæéž�></k^n¢»r,jô³]áðgt¤è(í´|fû1ª$ö></yù§õhnvbªgb³âó></a”o�è_vÿø¹`3�t´,5bpfÿr1˜þñ“ª7w·‘ûíé¯müyöy@2�ü�—i*a^ür+cîùh=6škîûað³5º�ù™ò¾²></o¨n€çøð0¨ç¾xýi±.üo-öt[lœ¹‹;—ùôáq~µmxt7œøl¹í¸5];¼&h^ã%s?õðëóà%ntþ2ì}5¼=a®_z></ulš²-ûbhag·=©óñ~yv%«þy.í»1ÿ÷™êy–}í6¶o«“t_»º¼æ#´à¼dòé¨úu÷></mƒa8:,#è-�‘<�sˆ></wtó€></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://damonmccoy.com/papers/ecrime2019.pdf">https://damonmccoy.com/papers/ecrime2019.pdf</a></em></p>]]>
            </description>
            <link>https://damonmccoy.com/papers/ecrime2019.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030329</guid>
            <pubDate>Mon, 09 Nov 2020 00:23:34 GMT</pubDate>
        </item>
    </channel>
</rss>
