<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 01 Jul 2020 20:17:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 01 Jul 2020 20:17:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Portals API]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23688699">thread link</a>) | @ginkoid
<br/>
June 30, 2020 | https://wicg.github.io/portals/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/portals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <details>
    <summary>This spec is behind the explainer</summary>
    <p>This specification document has not yet been updated to reflect the 2020-04 updates to <a href="https://github.com/WICG/portals#readme">the explainer</a>. We’ll fix that as soon as we
  can, but please be aware that there are probably contradictions, and the explainer should be taken
  as more authoritative for the time being.</p>
   </details>
   <section>
    <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
    <p><em>This section is non-normative.</em></p>
    <p>This specification extends <a data-link-type="biblio" href="#biblio-html">[HTML]</a> to define a new kind of <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#top-level-browsing-context" id="ref-for-top-level-browsing-context">top-level browsing context</a>,
  which can be embedded in another document, and a mechanism for replacing the contents of another
  top-level browsing context with the previously embedded context.</p>
    <p>It is structured as a series of patches to HTML and other specifications, with each major section
  indicating where each it would be placed in the event of eventual graduation from incubation.</p>
   </section>
   <section>
    <h2 data-level="2" id="concepts"><span>2. </span><span>Portal browsing contexts</span><a href="#concepts"></a></h2>
    <p><em>The following section would be added as a new sub-section of <a data-link-type="biblio" href="#biblio-html">[HTML]</a>'s <a href="https://html.spec.whatwg.org/#windows">Browsing contexts</a> section.</em></p>
    <p>Every <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#browsing-context" id="ref-for-browsing-context">browsing context</a> has a <dfn data-dfn-type="dfn" data-noexport="" id="portal-state">portal state</dfn>, which may be "<code>none</code>" (the default), "<code>portal</code>" or "<code>orphaned</code>".
  A <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#nested-browsing-context" id="ref-for-nested-browsing-context">nested browsing context</a> always has the <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state">portal state</a> "<code>none</code>".</p>
    <div role="note"><p>
      Briefly, these correspond to: 
     </p><ul>
      <li data-md="">
       <p>"<code>portal</code>": top-level browsing contexts embedded in a <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal">portal</a></code> element</p>
      </li><li data-md="">
       <p>"<code>orphaned</code>": top-level browsing contexts which have run <code><a data-link-type="idl" href="#dom-htmlportalelement-activate" id="ref-for-dom-htmlportalelement-activate">activate</a></code> but have not (yet) been <a data-link-type="dfn" href="#adopt-the-predecessor-browsing-context" id="ref-for-adopt-the-predecessor-browsing-context">adopted</a></p>
      </li><li data-md="">
       <p>"<code>none</code>": all other browsing contexts</p>
     </li></ul>
     <p><img alt="Diagram of portal state transitions" src="https://wicg.github.io/portals/portals-state-transitions.svg" width="100%"></p>
     <p>A top-level "<code>none</code>" context can become "<code>orphaned</code>" by <a data-link-type="dfn" href="#activate-a-portal-browsing-context" id="ref-for-activate-a-portal-browsing-context">activating</a> another context. An "<code>orphaned</code>" context can be <a data-link-type="dfn" href="#adopt-the-predecessor-browsing-context" id="ref-for-adopt-the-predecessor-browsing-context①">adopted</a> to
    become a "<code>portal</code>" context. A "<code>portal</code>" context can become a "<code>none</code>" context by being <a data-link-type="dfn" href="#activate-a-portal-browsing-context" id="ref-for-activate-a-portal-browsing-context①">activated</a> by its <a data-link-type="dfn" href="#host-browsing-context" id="ref-for-host-browsing-context">host browsing context</a>.</p>
     <p>A browsing context can be <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#close-a-browsing-context" id="ref-for-close-a-browsing-context">closed</a> while in any of these states.</p>
    </div>
    <p>A <dfn data-dfn-type="dfn" data-noexport="" id="portal-browsing-context">portal browsing context</dfn> is a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#browsing-context" id="ref-for-browsing-context①">browsing context</a> whose <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state①">portal state</a> is "<code>portal</code>".</p>
    <p>The <dfn data-dfn-type="dfn" data-noexport="" id="host-element">host element</dfn> of a <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context">portal browsing context</a> is a <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal①">portal</a></code> element which embeds its rendered output and receives messages sent from the
  portal browsing context.</p>
    
    <p>The <dfn data-dfn-type="dfn" data-noexport="" id="host-browsing-context">host browsing context</dfn> of a <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context①">portal browsing context</a> is its <a data-link-type="dfn" href="#host-element" id="ref-for-host-element①">host element</a>'s <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-node-document" id="ref-for-concept-node-document">node document</a>'s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#browsing-context" id="ref-for-browsing-context②">browsing context</a>.</p>
    <p>The <dfn data-dfn-type="dfn" data-noexport="" id="portal-task-source">portal task source</dfn> is a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#task-source" id="ref-for-task-source">task source</a> used for tasks related to the
  portal lifecycle and communication between a <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context②">portal browsing context</a> and its <a data-link-type="dfn" href="#host-browsing-context" id="ref-for-host-browsing-context①">host browsing context</a>.</p>
    <section data-algorithm="portal-browsing-context-activate">
      To <dfn data-dfn-type="dfn" data-noexport="" id="activate-a-portal-browsing-context">activate a portal browsing context</dfn> <var>successorBrowsingContext</var> in
    place of <var>predecessorBrowsingContext</var> with <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#concept-origin" id="ref-for-concept-origin">origin</a> <var>sourceOrigin</var>, data <var>serializeWithTransferResult</var>, and promise <var>promise</var>, run the following steps <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/infrastructure.html#in-parallel" id="ref-for-in-parallel">in parallel</a>: 
     <ol>
      <li data-md="">
       <p><a data-link-type="dfn" href="https://infra.spec.whatwg.org/#assert" id="ref-for-assert">Assert</a>: The <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state②">portal state</a> of <var>predecessorBrowsingContext</var> is "<code>none</code>".</p>
      </li><li data-md="">
       <p>Set the <a data-link-type="dfn" href="#host-element" id="ref-for-host-element②">host element</a> of <var>successorBrowsingContext</var> to null.</p>
       <p>User agents <em>should</em>, however, attempt to preserve the rendering of the
guest browsing context until <var>predecessorBrowsingContext</var> has been replaced
with <var>successorBrowsingContext</var> in the rendering.</p>
       <p role="note"><span>Note:</span> This is intended to avoid a visual glitch, such as a "white flash", where
the guest browsing context briefly disappears.</p>
      </li><li data-md="">
       <p>Set the <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state③">portal state</a> of <var>predecessorBrowsingContext</var> to "<code>orphaned</code>".</p>
      </li><li data-md="">
       <p>Update the user interface to replace <var>predecessorBrowsingContext</var> with <var>successorBrowsingContext</var> (e.g., by updating the tab/window contents and browser chrome).</p>
      </li><li data-md="">
       <p>Let <var>successorWindow</var> be <var>successorBrowsingContext</var>’s associated <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/window-object.html#windowproxy" id="ref-for-windowproxy">WindowProxy</a></code>'s [[Window]] internal slot value.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-global-task" id="ref-for-queue-a-global-task">Queue a global task</a> on the <a data-link-type="dfn" href="#portal-task-source" id="ref-for-portal-task-source">portal task source</a> given <var>successorWindow</var> to run the
following steps:</p>
       <ol>
        <li data-md="">
         <p><a data-link-type="dfn" href="https://infra.spec.whatwg.org/#assert" id="ref-for-assert①">Assert</a>: The <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state④">portal state</a> of <var>successorBrowsingContext</var> is "<code>portal</code>".</p>
        </li><li data-md="">
         <p>Set the <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state⑤">portal state</a> of <var>successorBrowsingContext</var> to "<code>none</code>".</p>
        </li><li data-md="">
         <p>Let <var>targetRealm</var> be <var>successorWindow</var>’s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#concept-global-object-realm" id="ref-for-concept-global-object-realm">realm</a>.</p>
        </li><li data-md="">
         <p>Let <var>dataClone</var> be null.</p>
        </li><li data-md="">
         <p>If <var>successorBrowsingContext</var>’s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#active-document" id="ref-for-active-document">active document</a>'s <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-document-origin" id="ref-for-concept-document-origin">origin</a> is <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-origin" id="ref-for-same-origin">same origin</a> with <var>sourceOrigin</var>, then:</p>
         <ol>
          <li data-md="">
           <p>Let <var>deserializeRecord</var> be <a data-link-type="abstract-op" href="https://html.spec.whatwg.org/multipage/structured-data.html#structureddeserializewithtransfer" id="ref-for-structureddeserializewithtransfer">StructuredDeserializeWithTransfer</a>(<var>serializeWithTransferResult</var>, <var>targetRealm</var>),
and set <var>dataClone</var> to <var>deserializeRecord</var>.[[Deserialized]].</p>
           <p>If this throws an exception, catch it and do nothing.</p>
         </li></ol>
        </li><li data-md="">
         <p>Let <var>event</var> be the result of <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event-create" id="ref-for-concept-event-create">creating an event</a> using <code><a data-link-type="idl" href="#portalactivateevent" id="ref-for-portalactivateevent">PortalActivateEvent</a></code> and <var>targetRealm</var>.</p>
        </li><li data-md="">
         <p>Initialize <var>event</var>’s <code><a data-link-type="idl" href="https://dom.spec.whatwg.org/#dom-event-type" id="ref-for-dom-event-type">type</a></code> attribute to <code><a data-link-type="event" href="#eventdef-window-portalactivate" id="ref-for-eventdef-window-portalactivate①">portalactivate</a></code>.</p>
        </li><li data-md="">
         <p>Initialize <var>event</var>’s <code><a data-link-type="idl" href="#dom-portalactivateevent-data" id="ref-for-dom-portalactivateevent-data">data</a></code> attribute to <var>dataClone</var>.</p>
        </li><li data-md="">
         <p>Set <var>event</var>’s <a data-link-type="dfn" href="#portalactivateevent-predecessor-browsing-context" id="ref-for-portalactivateevent-predecessor-browsing-context">predecessor browsing context</a> to <var>predecessorBrowsingContext</var>.</p>
        </li><li data-md="">
         <p>Set <var>event</var>’s <a data-link-type="dfn" href="#portalactivateevent-successor-window" id="ref-for-portalactivateevent-successor-window">successor window</a> to <var>successorWindow</var>.</p>
        </li><li data-md="">
         <p>Set <var>event</var>’s <a data-link-type="dfn" href="#portalactivateevent-activation-promise" id="ref-for-portalactivateevent-activation-promise">activation promise</a> to <var>promise</var>.</p>
        </li><li data-md="">
         <p><a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event-dispatch" id="ref-for-concept-event-dispatch">Dispatch</a> <var>event</var> to <var>successorWindow</var>.</p>
        </li><li data-md="">
         <p>Let <var>adoptedPredecessorElement</var> be <var>event</var>’s <a data-link-type="dfn" href="#portalactivateevent-adopted-predecessor-element" id="ref-for-portalactivateevent-adopted-predecessor-element">adopted predecessor element</a>.</p>
        </li><li data-md="">
         <p>If <var>adoptedPredecessorElement</var> is not null, then:</p>
         <ol>
          <li data-md="">
           <p>Set <var>adoptedPredecessorElement</var>’s <a data-link-type="dfn" href="#htmlportalelement-just-adopted-flag" id="ref-for-htmlportalelement-just-adopted-flag">just-adopted flag</a> to false.</p>
          </li><li data-md="">
           <p>If <var>adoptedPredecessorElement</var> <a data-link-type="dfn" href="#htmlportalelement-may-have-a-guest-browsing-context" id="ref-for-htmlportalelement-may-have-a-guest-browsing-context">may not have a guest browsing context</a> and
its <a data-link-type="dfn" href="#htmlportalelement-guest-browsing-context" id="ref-for-htmlportalelement-guest-browsing-context">guest browsing context</a> is not null, then <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#a-browsing-context-is-discarded" id="ref-for-a-browsing-context-is-discarded">discard</a> it.</p>
           <div role="note"><p>
             This unceremoniously <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#a-browsing-context-is-discarded" id="ref-for-a-browsing-context-is-discarded①">discards</a> the browsing context, as if the element had been removed from
  the document after previously being attached. This is
  distinct from the case where the predecessor was never
  adopted, below, which <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#close-a-browsing-context" id="ref-for-close-a-browsing-context①">closes</a> the
  browsing context, which dispatches the <code><a data-link-type="event" href="https://html.spec.whatwg.org/multipage/indices.html#event-unload" id="ref-for-event-unload">unload</a></code> event, somewhat similarly to if it
  had performed an ordinary navigation. 
            </p><p>Typically authors would not call <code><a data-link-type="idl" href="#dom-portalactivateevent-adoptpredecessor" id="ref-for-dom-portalactivateevent-adoptpredecessor①">adoptPredecessor()</a></code> unless they intend
  to insert it into the document before the <a data-link-type="dfn" href="#htmlportalelement-just-adopted-flag" id="ref-for-htmlportalelement-just-adopted-flag①">just-adopted flag</a> becomes false.</p>
           </div>
         </li></ol>
        </li><li data-md="">
         <p>Otherwise:</p>
         <ol>
          <li data-md="">
           <p><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-global-task" id="ref-for-queue-a-global-task①">Queue a global task</a> on the <a data-link-type="dfn" href="#portal-task-source" id="ref-for-portal-task-source①">portal task source</a> given <var>predecessorBrowsingContext</var>’s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#active-window" id="ref-for-active-window">active window</a> to resolve <var>promise</var> with undefined.</p>
          </li><li data-md="">
           <p><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#close-a-browsing-context" id="ref-for-close-a-browsing-context②">Close</a> <var>predecessorBrowsingContext</var>.</p>
           <p>The user agent <em>should not</em> ask the user for confirmation during the <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsing-the-web.html#prompt-to-unload-a-document" id="ref-for-prompt-to-unload-a-document">prompt to unload</a> step (and so the browsing context should be <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#a-browsing-context-is-discarded" id="ref-for-a-browsing-context-is-discarded②">discarded</a>).</p>
         </li></ol>
       </li></ol>
     </li></ol>
    </section>
    <ul>
     <li><a href="https://wpt.fyi/results/portals/portal-activate-event.html">portal-activate-event.html</a> <a href="http://web-platform-tests.live/portals/portal-activate-event.html" title="portals/portal-activate-event.html"><small>(live test)</small></a> <a href="https://github.com/web-platform-tests/wpt/blob/master/portals/portal-activate-event.html"><small>(source)</small></a>
     </li><li><a href="https://wpt.fyi/results/portals/portals-host-hidden-after-activation.html">portals-host-hidden-after-activation.html</a> <a href="http://web-platform-tests.live/portals/portals-host-hidden-after-activation.html" title="portals/portals-host-hidden-after-activation.html"><small>(live test)</small></a> <a href="https://github.com/web-platform-tests/wpt/blob/master/portals/portals-host-hidden-after-activation.html"><small>(source)</small></a>
    </li></ul>
    <p><a href="#issue-b49e4903"></a> In the case that structured deserialization throws, it may be useful to do something else to indicate it,
    rather than simply providing null data. </p>
    <p><a href="#issue-0d72b101"></a> We need to specify how the <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/history.html#session-history" id="ref-for-session-history">session history</a> of each browsing context is
    affected by activation, and supply non-normative text that explains how
    these histories are expected to be presented to the user. </p>
    <section data-algorithm="portal-browsing-context-adopt-predecessor">
      To <dfn data-dfn-type="dfn" data-noexport="" id="adopt-the-predecessor-browsing-context">adopt the predecessor browsing context</dfn> <var>predecessorBrowsingContext</var> in <var>successorWindow</var>, run the following steps: 
     <ol>
      <li data-md="">
       <p>Let <var>document</var> be the <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/window-object.html#concept-document-window" id="ref-for-concept-document-window">document</a> of <var>successorWindow</var>.</p>
      </li><li data-md="">
       <p>Let <var>portalElement</var> be the result of <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-create-element" id="ref-for-concept-create-element">creating an element</a> given <var>document</var>, <code>portal</code>, and the <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#html-namespace" id="ref-for-html-namespace">HTML namespace</a>.</p>
      </li><li data-md="">
       <p>Set <var>portalElement</var>’s <a data-link-type="dfn" href="#htmlportalelement-just-adopted-flag" id="ref-for-htmlportalelement-just-adopted-flag②">just-adopted flag</a> to true.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="https://infra.spec.whatwg.org/#assert" id="ref-for-assert②">Assert</a>: <var>portalElement</var> is an <code><a data-link-type="idl" href="#htmlportalelement" id="ref-for-htmlportalelement">HTMLPortalElement</a></code>.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-global-task" id="ref-for-queue-a-global-task②">Queue a global task</a> on the <a data-link-type="dfn" href="#portal-task-source" id="ref-for-portal-task-source②">portal task source</a> given <var>predecessorBrowsingContext</var>’s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#active-window" id="ref-for-active-window①">active window</a> to run the following steps:</p>
       <ol>
        <li data-md="">
         <p><a data-link-type="dfn" href="https://infra.spec.whatwg.org/#assert" id="ref-for-assert③">Assert</a>: The <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state⑥">portal state</a> of <var>predecessorBrowsingContext</var> is "<code>orphaned</code>".</p>
        </li><li data-md="">
         <p>Set the <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state⑦">portal state</a> of <var>predecessorBrowsingContext</var> to "<code>portal</code>", and
set the <a data-link-type="dfn" href="#host-element" id="ref-for-host-element③">host element</a> of <var>predecessorBrowsingContext</var> to <var>portalElement</var>.</p>
       </li></ol>
      </li><li data-md="">
       <p>Return <var>portalElement</var>.</p>
     </li></ol>
    </section>
    <div role="note"><p>
      Since the task to set the <a data-link-type="dfn" href="#portal-state" id="ref-for-portal-state⑧">portal state</a>, and thus expose the <code><a data-link-type="idl" href="#portalhost" id="ref-for-portalhost">PortalHost</a></code> object, is queued first, and from the same <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#task-source" id="ref-for-task-source①">task source</a>,
    it is exposed at the time the <a data-link-type="dfn" href="#portalactivateevent-activation-promise" id="ref-for-portalactivateevent-activation-promise①">activation promise</a> returned from <code><a data-link-type="idl" href="#dom-htmlportalelement-activate" id="ref-for-dom-htmlportalelement-activate①">activate(options)</a></code> is resolved. 
</p><pre><c- c1="">// In the successor document.</c->
onportalactivate <c- o="">=</c-> event <c- p="">=&gt;</c-> <c- p="">{</c->
  <c- c1="">// The predecessor document is adopted into a &lt;portal&gt; element...</c->
  document<c- p="">.</c->body<c- p="">.</c->appendChild<c- p="">(</c->event<c- p="">.</c->adoptPredecessor<c- p="">());</c->
<c- p="">});</c->

<c- c1="">// In the predecessor document.</c->
portalElement<c- p="">.</c->activate<c- p="">().</c->then<c- p="">(()</c-> <c- p="">=&gt;</c-> <c- p="">{</c->
  <c- c1="">// ...and it is guaranteed to observe that change by the time the</c->
  <c- c1="">// activation promise resolves.</c->
  console<c- p="">.</c->assert<c- p="">(</c->window<c- p="">.</c->portalHost <c- k="">instanceof</c-> PortalHost<c- p="">);</c->
<c- p="">});</c->
</pre>
    </div>
   </section>
   <section>
    <h2 data-level="3" id="the-portal-element"><span>3. </span><span>The <code>portal</code> element</span><a href="#the-portal-element"></a></h2>
    <p><em>The following section would be added as a new subsection of <a data-link-type="biblio" href="#biblio-html">[HTML]</a>'s <a href="https://html.spec.whatwg.org/#embedded-content">Embedded content</a> section.</em></p>
    <p>A <dfn data-dfn-type="element" data-export="" id="elementdef-portal"><code>portal</code></dfn> element allows for a <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context③">portal browsing context</a> to be embedded in an HTML document.</p>
    <ul>
     <li><a href="https://wpt.fyi/results/portals/portals-rendering.html">portals-rendering.html</a> <a href="http://web-platform-tests.live/portals/portals-rendering.html" title="portals/portals-rendering.html"><small>(live test)</small></a> <a href="https://github.com/web-platform-tests/wpt/blob/master/portals/portals-rendering.html"><small>(source)</small></a>
    </li></ul>
    <p>A <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal③">portal</a></code> element <var>portalElement</var> has a <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="dfn" data-lt="guest browsing context" data-noexport="" id="htmlportalelement-guest-browsing-context">guest
  browsing context</dfn>, which is the <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context④">portal browsing context</a> whose <a data-link-type="dfn" href="#host-element" id="ref-for-host-element④">host
  element</a> is <var>portalElement</var>, or null if no such browsing context exists.</p>
    <p>A <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal④">portal</a></code> element has a <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="dfn" data-lt="just-adopted flag" data-noexport="" id="htmlportalelement-just-adopted-flag">just-adopted
  flag</dfn>, which is a <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#boolean" id="ref-for-boolean">boolean</a> and is initially false. It is set during
  dispatch of the <code><a data-link-type="event" href="#eventdef-window-portalactivate" id="ref-for-eventdef-window-portalactivate②">portalactivate</a></code> event.</p>
    <p>The <dfn data-dfn-for="portal" data-dfn-type="element-attr" data-export="" id="element-attrdef-portal-src"><code>src</code></dfn> attribute gives the <a data-link-type="dfn" href="https://url.spec.whatwg.org/#concept-url" id="ref-for-concept-url">URL</a> of a
  page that the <a data-link-type="dfn" href="#htmlportalelement-guest-browsing-context" id="ref-for-htmlportalelement-guest-browsing-context①">guest browsing context</a> is to contain. The attribute, if
  present, must be a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/urls-and-fetching.html#valid-non-empty-url-potentially-surrounded-by-spaces" id="ref-for-valid-non-empty-url-potentially-surrounded-by-spaces">valid non-empty URL potentially surrounded by spaces</a>.</p>
    <p>The <dfn data-dfn-for="portal" data-dfn-type="element-attr" data-export="" id="element-attrdef-portal-referrerpolicy"><code>referrerpolicy</code></dfn> attribute is a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/urls-and-fetching.html#referrer-policy-attribute" id="ref-for-referrer-policy-attribute">referrer policy attribute</a>.
  Its purpose is to set the <a data-link-type="dfn" href="https://w3c.github.io/webappsec-referrer-policy/#referrer-policy" id="ref-for-referrer-policy">referrer policy</a> used when <a data-link-type="dfn" href="#htmlportalelement-set-the-source-url-of-a-portal-element" id="ref-for-htmlportalelement-set-the-source-url-of-a-portal-element">setting the source URL of a portal element</a>. <a data-link-type="biblio" href="#biblio-referrer-policy">[REFERRER-POLICY]</a></p>
    <p role="note"> A <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal⑤">portal</a></code> is similar to an <code><a data-link-type="element" href="https://html.spec.whatwg.org/multipage/iframe-embed-object.html#the-iframe-element" id="ref-for-the-iframe-element">iframe</a></code>, in that it allows another
    browsing context to be embedded.  However, the <a data-link-type="dfn" href="#portal-browsing-context" id="ref-for-portal-browsing-context⑤">portal browsing context</a> hosted by a <code><a data-link-type="element" href="#elementdef-portal" id="ref-for-elementdef-portal⑥">portal</a></code> is part of a separate <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#browsing-context-group" id="ref-for-browsing-context-group">browsing context group</a>,
    and thus a separate <a data-link-type="dfn" href="http://tc39.github.io/ecma262/#sec-agents" id="ref-for-sec-agents">agent</a>.  The user agent is therefore free to use a
    separate <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#concept-agent-event-loop" id="ref-for-concept-agent-event-loop">event loop</a> for the browsing contexts, even if they are <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-origin-domain" id="ref-for-same-origin-domain">same
    origin-domain</a>. </p>
<pre>[<a data-link-type="extended-attribute" href="https://heycam.github.io/webidl/#Exposed" id="ref-for-Exposed"><c- g="">Exposed</c-></a>=<c- n="">Window</c->, <a data-link-type="extended-attribute" href="https://html.spec.whatwg.org/multipage/dom.html#htmlconstructor" id="ref-for-htmlconstructor"><c- g="">HTMLConstructor</c-></a>]
<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="htmlportalelement"><code><c- g="">HTMLPortalElement</c-></code></dfn> : <a data-link-type="idl-name" href="https://html.spec.whatwg.org/multipage/dom.html#htmlelement" id="ref-for-htmlelement"><c- n="">HTMLElement</c-></a> {
    [<a data-link-type="extended-attribute" href="https://html.spec.whatwg.org/multipage/custom-elements.html#cereactions" id="ref-for-cereactions"><c- g="">CEReactions</c-></a>] <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-USVString" id="ref-for-idl-USVString"><c- b="">USVString</c-></a> <a data-link-type="attribute" data-type="USVString" href="#dom-htmlportalelement-src" id="ref-for-dom-htmlportalelement-src"><c- g="">src</c-></a>;
    [<a data-link-type="extended-attribute" href="https://html.spec.whatwg.org/multipage/custom-elements.html#cereactions" id="ref-for-cereactions①"><c- g="">CEReactions</c-></a>] <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <a data-link-type="attribute" data-type="DOMString" href="#dom-htmlportalelement-referrerpolicy" id="ref-for-dom-htmlportalelement-referrerpolicy"><c- g="">referrerPolicy</c-></a>;

    [<a data-link-type="extended-attribute" href="https://heycam.github.io/webidl/#NewObject" id="ref-for-NewObject"><c- g="">NewObject</c-></a>] <c- b="">Promise</c->&lt;<c- b="">void</c->&gt; <a data-link-type="method" href="#dom-htmlportalelement-activate" id="ref-for-dom-htmlportalelement-activate②"><c- g="">activate</c-></a>(<c- b="">optional</c-> <a data-link-type="idl-name" href="#dictdef-portalactivateoptions" id="ref-for-dictdef-portalactivateoptions"><c- n="">PortalActivateOptions</c-></a> <dfn data-dfn-for="HTMLPortalElement/activate(options), HTMLPortalElement/activate()" data-dfn-type="argument" data-export="" id="dom-htmlportalelement-activate-options-options"><code><c- g="">options</c-></code><a href="#dom-htmlportalelement-activate-options-options"></a></dfn>);
    <c- b="">void</c-> <a data-link-type="method" href="#dom-htmlportalelement-postmessage" id="ref-for-dom-htmlportalelement-postmessage"><c- g="">postMessage</c-></a>(<c- b="">any</c-> <dfn data-dfn-for="HTMLPortalElement/postMessage(message, options), HTMLPortalElement/postMessage(message)" data-dfn-type="argument" data-export="" id="dom-htmlportalelement-postmessage-message-options-message"><code><c- g="">message</c-></code><a href="#dom-htmlportalelement-postmessage-message-options-message"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="https://html.spec.whatwg.org/multipage/web-messaging.html#postmessageoptions" id="ref-for-postmessageoptions"><c- n="">PostMessageOptions</c-></a> <dfn data-dfn-for="HTMLPortalElement/postMessage(message, options), HTMLPortalElement/postMessage(message)" data-dfn-type="argument" data-export="" id="dom-htmlportalelement-postmessage-message-options-options"><code><c- g="">options</c-></code><a href="#dom-htmlportalelement-postmessage-message-options-options"></a></dfn> = {});

    <c- b="">attribute</c-> <a data-link-type="idl-name" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler"><c- n="">EventHandler</c-></a> <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="attribute" data-export="" data-type="EventHandler" id="dom-htmlportalelement-onmessage"><code><c- g="">onmessage</c-></code></dfn>;
    <c- b="">attribute</c-> <a data-link-type="idl-name" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler①"><c- n="">EventHandler</c-></a> <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="attribute" data-export="" data-type="EventHandler" id="dom-htmlportalelement-onmessageerror"><code><c- g="">onmessageerror</c-></code></dfn>;
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-portalactivateoptions"><code><c- g="">PortalActivateOptions</c-></code></dfn> : <a data-link-type="idl-name" href="https://html.spec.whatwg.org/multipage/web-messaging.html#postmessageoptions" id="ref-for-postmessageoptions①"><c- n="">PostMessageOptions</c-></a> {
    <c- b="">any</c-> <dfn data-dfn-for="PortalActivateOptions" data-dfn-type="dict-member" data-export="" data-type="any " id="dom-portalactivateoptions-data"><code><c- g="">data</c-></code></dfn>;
};
</pre>
    <p>The <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="attribute" data-export="" id="dom-htmlportalelement-src"><code>src</code></dfn> IDL attribute must <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-reflect" id="ref-for-concept-reflect">reflect</a> the <code><a data-link-type="element-sub" href="#element-attrdef-portal-src" id="ref-for-element-attrdef-portal-src">src</a></code> content attribute.</p>
    <p>The <dfn data-dfn-for="HTMLPortalElement" data-dfn-type="attribute" data-export="" id="dom-htmlportalelement-referrerpolicy"><code>referrerPolicy</code></dfn>…</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wicg.github.io/portals/">https://wicg.github.io/portals/</a></em></p>]]>
            </description>
            <link>https://wicg.github.io/portals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23688699</guid>
            <pubDate>Tue, 30 Jun 2020 10:37:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immunity to Covid-19 is probably higher than tests have shown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23687962">thread link</a>) | @azram
<br/>
June 30, 2020 | https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown?_ga=2.255133322.346876423.1593473416-933987514.1593473416 | <a href="https://web.archive.org/web/*/https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown?_ga=2.255133322.346876423.1593473416-933987514.1593473416">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/Ljunggren_HansGustaf_13_SIR-custom20200629160009.jpg" alt="Portrait of Hans-Gustaf Ljunggren"></p><p>Hans-Gustaf Ljunggren. Photo: Ulf Sirborn</p>
                  </div><div>
        
            <p>“Our results indicate that public immunity to COVID-19 is probably significantly higher than antibody tests have suggested,” says Professor <a href="https://staff.ki.se/people/hanlju">Hans-Gustaf Ljunggren</a> at the Center for Infectious Medicine, Karolinska Institutet, and co-senior author. “If this is the case, it is of course very good news from a public health perspective.”</p>

<p>T-cell analyses are more complicated to perform than antibody tests and at present are therefore only done in specialised laboratories, such as that at the Center for Infectious Medicine at Karolinska Institutet.</p>

<p>“Larger and more longitudinal studies must now be done on both T cells and antibodies to understand how long-lasting the immunity is and how these different components of COVID-19 immunity are related,” says Marcus Buggert.</p>

<p>The results are so new that they have not yet undergone peer review ahead of publication in a scientific journal. Pending such review, the article has been published on a preprint server, bioRxiv (see box).</p>

<p>The study was financed by the Knut and Alice Wallenberg Foundation, Nordstjernan AB, the Swedish Research Council, Karolinska Institutet, the Swedish Society for Medical Research, the Jeansson Foundations, the Åke Wiberg Foundation, the Swedish Society of Medicine, the Swedish Cancer Society, the Swedish Childhood Cancer Foundation, the Magnus Bergvall Foundation, the Hedlund Foundation, the Lars Hierta Foundation, the Swedish Physicians against AIDS foundation, the Jonas Söderquist Foundation, the Clas Groschinsky Memorial Foundation, and the Wellcome Trust.&nbsp;The authors report no conflicts of interest or patents associated with the results of the study.</p>

<h2>Publication</h2>

<p><a href="https://doi.org/10.1101/2020.06.29.174888">“Robust T cell immunity in convalescent individuals with asymptomatic or mild COVID-19”</a><br>
Takuya Sekine, André Perez-Potti, Olga Rivera-Ballesteros, Jean-Baptiste Gorin, Annika Olsson, Habiba Kamal, Sian Llewellyn-Lacey, David Wulliman, Tobias Kamann, Gordana Bogdanovic, Sandra Muschiol, Elin Folkesson, Olav Rooyackers, Lars I. Eriksson, Anders Sönnerborg, Tobias Allander, Jan Albert, Morten Nielsen, Kristoffer Strålin, Sara Gredmark-Russ, Niklas K. Björkström, Johan K. Sandberg, David A. Price, Hans-Gustaf Ljunggren, Soo Aleman, Marcus Buggert, Karolinska COVID-19 Study Group.<br>
bioRxiv, online 29 June 2020, doi:&nbsp;10.1101/2020.06.29.174888</p>
      
      </div></div>]]>
            </description>
            <link>https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown?_ga=2.255133322.346876423.1593473416-933987514.1593473416</link>
            <guid isPermaLink="false">hacker-news-small-sites-23687962</guid>
            <pubDate>Tue, 30 Jun 2020 08:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Async vs Sync Communication]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23687807">thread link</a>) | @Gustek
<br/>
June 30, 2020 | https://www.gustekdev.com/post/async-vs-sync-communication/ | <a href="https://web.archive.org/web/*/https://www.gustekdev.com/post/async-vs-sync-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>We can divide communication into two channels:<br>
<strong>Synchronous</strong> (Sync) - all parties are actively taking part in the conversation right now. For example, physical meetings or a video call<br>
<strong>Asynchronous</strong> (Async) - one party writes or records a message and has to wait for responses for an indefinite amount of time. For example, sending an email or posting on a discussion board.<br>
Conversations on sync channels are usually recorded only in the heads of the participants where async channels are a more permanent medium.<br>
Chat applications are a bit of a grey area; they allow for synchronous communication, but often you have to wait for a response. Because of the inherently fleeting nature of real-time chats, I consider them to be synchronous.</p>
<p>In the workplace, often conversations will revolve around making a decision - for instance, choosing between various options. These conversations, ideally, can be divided into three stages.<br>
Each stage will involve the usage of both synchronous and asynchronous channels. They are:</p>
<ol>
<li>Initialisation</li>
<li>Discussion</li>
<li>Decision</li>
</ol>

<p>This stage starts with someone writing down a proposal, an introduction to the subject, and it may also include some initial research done by the person writing it. It can be a detailed post, or it can be simply an email invitation with a short description of the subject. Follow up with brainstorming to gather opinions; it’s not a time for decisions yet - we are just stimulating the conversation and collecting ideas. After a brainstorming session, one person writes a follow-up post summarising what you have discussed and all the ideas mentioned, including rejected ideas as well for completeness. Someone good at taking notes will be very helpful here.<br>
We have here both synchronous and asynchronous communication.</p>

<p>Now people have been familiarised with the subject. It is time to digest it. I’m sure everyone has experienced clarity after a night of sleep - that is why this stage may take a few days or even weeks, assuming there is no particular time pressure. At this stage, people should mostly use async channels to communicate with the whole group. Sync channels should be seen as supplementary to be used when you want to avoid spamming the async channel with the back and forth of short questions and answers. I recommend adding a summary of such conversations in the async channel later.<br>
Again, we employed both synchronous and asynchronous channels.</p>

<p>When enough time has passed - maybe because there is a deadline, or the discussion is slowing down, or agreement seems to have been reached - we head back to a meeting room to make the decision. Ideally, there should be no more new ideas introduced at this point. In terms of how you pick the winning idea that is another subject. It could be a democratic vote, a manager/leader decision, or dice roll. After the meeting, you write a summary.<br>
Once more, both synchronous and asynchronous communication is involved here.</p>

<p>Writing and speaking with clarity can both be difficult, but they are vital skills and need to be worked on, no excuses here. But if you are bad at either and finding it hard to improve by yourself, then try to find someone good at it and work together.</p>
<h2 id="writing">Writing</h2>
<p>If you are bad at writing, find someone who does it well. Write a draft with what you want to say, and ask them to review it, improve it based on their feedback. Rinse, repeat until it is ready to be shown to a broader audience.</p>
<h2 id="speaking">Speaking</h2>
<p>If you are bad at speaking, then try to write down all the points you want to say first - remember it is ok to read notes in the meetings. You can practice speaking by finding someone who likes to have small debates and discuss opinions with them in a one-on-one setting, so you don’t stress because of group pressure.</p>
<h2 id="my-experience">My Experience</h2>
<p>For me, the writing was always my weaker point of the two. In school and university, I always struggled with reaching the required word count. Today I know that they taught me writing the wrong way. It is not about the word count. If you know what you want to say the words will come by themselves. Write a draft first as if you were talking, then review and improve it. There are a lot of books, blogs, and courses that share tips on how to improve your writing. One point they all agree on is this: write something, anything, and improve later.<br>
My speaking skills improved thanks to a volunteering organisation I was involved with in high school. During my university years, I had a job in customer service that helped a lot as well. When I started working as a software engineer, my problem was lack of confidence and impostor syndrome. I was questioning myself in my mind all the time, which made it hard to take part in conversations. That one is hard to solve, and I don’t have any suggestions here. I overcame it at least partially thanks to my team members at <a href="https://twitter.com/fr_devs">Football Radar</a> showing recognition for my skills.</p>

<p>It is not a case of async versus sync communication. As with many things, it is not one or the other. Each approach has its use cases, and they complement each other. Use them together at the right time to derive the most benefit.</p>
<p><a href="https://news.ycombinator.com/item?id=23687807">Leave comment on HackerNews</a></p>


        
          
        

        
            <hr>
            
        

        
      </article>

      
        
      


      

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.gustekdev.com/post/async-vs-sync-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23687807</guid>
            <pubDate>Tue, 30 Jun 2020 08:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons we learned building PipFeed mobile app]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23687761">thread link</a>) | @imshashank
<br/>
June 30, 2020 | https://pipfeed.com/2020/05/07/8-things-i-learned-from-building-pipfeed/ | <a href="https://web.archive.org/web/*/https://pipfeed.com/2020/05/07/8-things-i-learned-from-building-pipfeed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div itemprop="articleBody"><p>So I have spent my last 3 months building&nbsp;<a rel="noreferrer noopener" href="https://pipfeed.com/" target="_blank" data-wpel-link="internal">PipFeed.com</a>. PipFeed is an A.I. powered curated reading app. Think of it as when Pocket met Medium. I am an ex-AWS engineer and my main language of choice is JAVA but I can code in PHP, python, js etc.</p><p>The backend for PipFeed is in JAVA with a few services in python, node.js &amp; PHP. In January 2020 I learned Flutter and built the mobile app for PipFeed using it. This is my first experience building a mobile app and here are some of the learnings that I would like to share with you all.</p><h2>1) Have a CI/CD</h2><p>For mobile apps, it is extremely important to have a CI/CD. We use <a href="http://codemagic.io/" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">codemagic</a>, it ties up nicely with our Flutter ecosystem. Mobile apps need a lot more work to release like signing, bundle, etc etc.</p><p>P.S. I still don’t have a CI/CD for my backends and I deploy my AWS backend from my laptop using Cloudformation templates.</p><h2>2) Mobile apps crash a lot</h2><p>As compared to websites, backend code, and stand-alone software, mobile apps fail and throw exceptions a lot more. There are all sorts of errors like network errors, some image fails to load etc.</p><p>To make the app stable, we had to add a lot of exception handling, null checks, and mostly retries in almost all network calls.</p><h2>3) Distributed logs</h2><p>We use <a href="https://sentry.io/" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">Sentry</a> &amp; Crashlytics to manage and catch all our exceptions &amp; logs. We really love the service and it has a nice pricing model. We have now integrated our backend in JAVA with Sentry.</p><h2>4) Analytics is everything</h2><p>We use a mix of <a href="https://firebase.google.com/" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">firebase</a>, <a href="https://mixpanel.com/" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">mixpanel</a> &amp; AWS cloudwatch for our analytics. Analytics on mobile is a bit harder as everything you want to track requires a code change. Also, that would mean a lot of network calls for each event.</p><p>We found a way and moved the analytics to our backend system. So on an action like read, like, comment, etc when there is a database update, we trigger lambdas using AWS DDB stream and send metrics from there to other services. This helps us reduce the overall number of network requests and makes it easier to have the logic out of the mobile app.</p><h2>5) It’s so hard to A/B test</h2><p>As compared to any other software A/B testing is really hard on mobile. With websites you can have a version that people will see when they visit your URL with mobile your users will have a whole mix of versions, devices, screen-sizes and a lot more variables. So we are still figuring out how to do this.</p><p>Implementing A/B testing is harder in mobile as we need to create two separate code blocks and use firebase remote config or something similar to run once code block for some users and another for some other.</p><h2>6) Login/SignUp is the most important screen in your app</h2><p>The most important piece of code in your mobile app is your login/signup page. We learned this the hard way. We never paid much attention to our sigun/login page but when we analyzed the analytics we saw that from all the people who “installed” the app only 60% were actually signing up.</p><p>Hence we now do rigorous testing of our signup page. After so much work we still keep finding a lot of bugs/error in our login &amp; signup flow.</p><h2>7) Updates are harder because of backward compatibility</h2><p>With AWS, I am used to pushing to Production almost every other day. But with mobile, you need to take care of backward compatibility a lot more.</p><p>Like we have a bug in our app where a blog will show as being “unfollowed” even when the user is following it. This was caused by two bugs with one being in the mobile app and another in our backend. Now if I fix the backend bug the current mobile app will break. So what we do? We fixed the bug in the mobile app and after around 15 days or when 90% of users have updated to the latest app, we will push fix to the backend.</p><h2>8) Have a clear 2-way communication channel with users</h2><p>It is very important to have some way in which users can reach out to you. At first, we thought just asking our users to email us would be enough but I think around 5% of all users ever emailed us. That’s when we found <a href="https://instabug.com/" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">Instabug</a>. This is a really amazing tool and they provide a 2-minute installation. I think in all the tools mentioned here, this was the easiest to setup. We run all sorts of surveys including Net promoter Score surveys, survey to nudge users to upgrade etc. Also, Instabug lets users submit bugs reports and even vote on feature requests.</p><p>If you have a mobile app, it is very important to have a NPS survey. This is probably the one metrics VCs really care about.</p><hr><p>That’s all for now. These were the learning I have had from working on mobile apps for the last 3 months. I hope these were helpful.</p><p>Do checkout PipFeed. The app is both in the play store and app store and let me know what you guys think.</p></div></div></div>]]>
            </description>
            <link>https://pipfeed.com/2020/05/07/8-things-i-learned-from-building-pipfeed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23687761</guid>
            <pubDate>Tue, 30 Jun 2020 07:55:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Disclosure: RCE in Telia ISP intranet and root access on customers routers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23687014">thread link</a>) | @operatorius
<br/>
June 29, 2020 | https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html | <a href="https://web.archive.org/web/*/https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Multiple vulnerabilities could allow running arbitrary code on an intranet server and gain root access on all the customers' routers</p>

<p>Telia is a Swedish multinational telecommunications company. It also operates in Lithuania and provides mobile service, FTTH internet, DSL internet and IPTV. Telia rents and sells custom routers and set-top tv boxes to customers which have limited or almost no administration access left to them.</p>

<p>Every Telia router or tv box has a backdoor or "management interface". It is an <code>SSH</code> server running on VLAN 5 and/or WAN. Usually, it is running on port <code>8022</code>. Older models, like <code>ADB</code>, have password login enabled. The recent newer models, like <code>Technicolor</code>, have password login disabled and only use ssh with public key authentication (spoiler: it is still vulnerable).</p>

<p>Savitarna (in Lithuanian "Self service") - is a web service <a href="https://www.telia.lt/mano/sso">https://www.telia.lt/mano/sso</a> that allows Telia customers to order and manage services, get invoices, pay bills etc. It uses password authentication or external authority logins such as Facebook, Google, banking, digital signature etc. One of the new features: changing your router's wifi password. Sounds interesting, right? An internet web service that is able to change your local router's wifi password.</p>
<p>Login page:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-login.jpg" alt="Telia Savitarna web login page"></p>
<p>Change wifi settings:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-wifi-settings.jpg" alt="Telia Savitarna WiFi setting change feature"></p>

<p>How that works. When a user wants to change the password, the web service calls the backend to initiate an SSH connection to the user's associated router. Depending on the router it will be either password authentication or RSA public key. After a successful login a PHP script on the backend will issue some commands in the router's shell, parse the result and output some of the data to the user in the web UI, like wireless network name. <strong>Telia knows your WIFI password in plain text</strong>, keep it in mind and do not reuse this password anywhere. Overall scheme:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-scheme.jpg" alt="Overall scheme of Telia backdoor"></p>

<p>Let's take a look at how the SSH connection is established. Network capture shows an SSH client banner and the remote IP that initiated the connection:</p>
<p><code>SSH-2.0-libssh2_1.4.2 PHP 10.0.98.251</code></p>
<p>What is important here:</p>
<ul>
<li>Vulnerable <code>libssh2</code> version <code>1.4.2</code> <a href="https://www.libssh2.org/security.html">https://www.libssh2.org/security.html</a></li>
<li>Weak and deprecated key exchange <code>diffie-hellman-group1-sha1</code></li>
<li>The client does not verify <code>remote SSH server public key</code> (see below)</li>
<li><code>PHP</code></li>
</ul>
<p>And, yes, it turns out that Telia's client does not attempt to verify the remote server's public key. We were able to start a custom SSH server on the same port 8022 and Savitarna successfully established a connection without even trying to verify for a man-in-the-middle. This means that we can see the password used and could try to create a malicious SSH server that exploits public vulnerabilities on Telia's side.</p>

<p>That was an easy task. As soon as Telia's client connected to our malicious SSH server we got the universal router credentials:</p>
<pre>User: tadmin
Password: hqMV8Wps
</pre>

<p>Do you still own an ADB router? Just go ahead and login over the web interface with this user. You are now an admin. You can do some restricted stuff now, great! But what about the root shell? We were able to connect with those credentials locally and got a limited shell. That's nice too. This gave us a lot of additional information that was hidden inside the router, many more vulnerabilities. Using one of them we were able to escalate to root and got full access over the device. The newer models like Technicolor require some additional exploits chained to gain full root access, but all are publicly available and so - easily doable.</p>

<p>In order to exploit RCE we needed to build a virtual test environment that fully copies Telia's PHP client. Step by step we have gone through the sequence of Telia's commands sent over the SSH. And finally we got a malicious SSH server and a test libssh2 client running in our test lab. With this server we could fully control the protocol and start fuzzing.</p>
<p>In the first few days of the fuzzing we got some crashes and partially confirmed that RCE may be exploited. Here is a sample GIF video that demonstrates two kinds of the issues the fuzzer found for us. Same php file was executed twice, but the malicious SSH server sent different payloads which caused:</p>
<ul>
<li>Segfault (stack corruption)</li>
<li>Infinite loop with high CPU</li>
</ul>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-poc.gif" alt="GIF PoC video"></p>
<p>However, at the time of the report we couldn't find an easy way to exploit the stack corruption. It may require more time, longer and more sophisticated fuzzing and more knowledge about the server. As Lithuanian law prohibits exploit testing on the real server, we could only fingerprint the Windows OS, but nothing more.</p>

<p>The backend seems to run only 5 php processes, so it is fairly easy to perform DoS by keeping stalled ssh connections. When SSH connections stay active for too long filling all the 5 php processes (there seems to be no timeout reading the remote shell), the Savitarna will show a strange "Maintenance" message:</p>
<p>Translation:</p>
<pre>An update is in progress
Too many of you are trying to access the new Telia webpage.
We are expanding the resources and will accept you all soon.
Apologies for any inconvenience
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-DoS.jpg" alt="Service unavailbale"></p>

<p>If we now get all together, an attacker could exploit RCE on the intranet server and use that server to move laterally (because <code>10.0.98.251</code> is whitelisted everywhere) across all the customer routers with the same credentials creating the most powerful, persistent and undetectable botnet of Lithuania. Who knows, maybe someone already exploited that? (spoiler: see bonus section)</p>

<p>The report was responsibly disclosed to Telia and a copy sent to <code>CERT LT</code> (<a href="https://www.nksc.lt/">NKSC</a>). What happened next was a little bit of a surprise to the team. There were rumours previously about Telia's poor tech level, but we have experienced this in a real case.</p>
<p>First, Telia did not have a PGP key and did not know how to use it, so instead they asked us to ZIP the report with password and send the password over a separate email (private GMail). I hope Telia's engineers will be reading this article, so I would like to explain why the report should be encrypted. This is to protect you as the affected vendor. If there is a man in the middle who can intercept all the researcher's traffic, it will be very easy to get the ZIP file in the first email and then the password in the second email. Instead, PKI like PGP only allows to decrypt the report by the private key owner, ensuring that nobody else can intercept the report and exploit the vulnerabilities before you fix them all. </p>
<p>Second, Telia tried to threaten the reporter for the vulnerability discovery:</p>
<p>Translation:</p>
<pre>Thank you for the information
Are you sure you did not violate the electronic data protection law?
</pre>

<p>Original:</p>
<pre>Dėkojame už informaciją.
Ar tikrai tyrimą atlikote ir neviešus elektroninius duomenis rinkote
nepažeidžiant galiojančių įstatymų?
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-1.jpg" alt="Telia CSIRT email response"></p>
<p>And then they once again mentioned that they will check if this report wasn't a hacking attempt and that they will persecute any reporter that discloses any information about Telia vulnerabilities:</p>
<p>Translation:</p>
<pre>Thank you for the information. We will continue to check whether you made your report
legally without violating any law. And we will ensure that no fake information will be
published that could do any harm to the company's reputation and to the critical part
of Lithuanian network infrastructure.
</pre>

<p>Original:</p>
<pre>Dėkojame Jums už pasidalintą informaciją, kurios surinkimo teisėtumo vertinimą toliau
atliekame ir tikimės, kad į viešumą nebus paskleista tikrovės neatitinkanti ar neteisėtai
gauta informacija, kuri darytų žalą bendrovės reputacijai ir tuo pačiu sėtų nepasitikėjimą
kritine Lietuvos ryšių infrastruktūros dalimi.
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-2.jpg" alt="Telia CSIRT email confirmation"></p>
<p>We will not comment on this and let the IT community to judge. At the same time we will no longer provide any reports in any form to Telia company.</p>
<table>
<thead>
<tr>
<th>Vulnerability</th>
<th>Fixed?</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vulnerable libssh2</td>
<td>NO!</td>
<td><a href="https://www.libssh2.org/security.html">SSH-2.0-libssh2_1.8.0 PHP</a></td>
</tr>
<tr>
<td>Weak KEX</td>
<td>partially*</td>
<td>diffie-hellman-group-exchange-sha256</td>
</tr>
<tr>
<td>MITM</td>
<td>NO!</td>
<td>still no pub key check</td>
</tr>
<tr>
<td>Password leaked</td>
<td>NO!</td>
<td>password has not been rotated</td>
</tr>
</tbody>
</table>
<p>* Note: partial fix for KEX means the new KEX is not considered to be weak, however it is now possible to exploit libssh2 vulnerabilities after 1.8.0 with this particular KEX and a publicly known exploit for <a href="https://github.com/Semmle/SecurityExploits/blob/446048470633bf0f8da9570d008d056dbaa28ea9/libssh2/out_of_bounds_read_kex_CVE-2019-13115/server/home/diff.txt">KexAlgorithms diffie-hellman-group-exchange-sha256</a></p>

<p>After getting the root access and analyzing the Telia's routers' firmwares, we found several more users, like <code>ladmin</code> and <code>technician</code>. We will not disclose those passwords (yet), as it is not clear yet how both are used. But we were surprised that Telia's passwords appeared to be leaked many years ago. You can try to search for the tadmin password's hash on the web and you will be surprised - there was an attempt to crack the hash back in 2014!</p>
<pre>echo -n hqMV8Wps | md5sum
ff19d662d7127446d83c935e74430921  -
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-leaked-password-2014.jpg" alt="Screenshot of a leaked Telia admin password MD5"></p>
<p><a href="https://webcache.googleusercontent.com/search?q=cache:J9ef6qUfrCcJ:www.md5this.com/list.php%3Fpage%3D108462%26key%3D1%26author%3DToXiC%26country%3DCyprus%26city%3DNicosia+">Webcache</a></p>
<p>And finally, we found that the hash was cracked and was available in the old "weakpass" database. You can search for the "old" weakpass database (sometimes named "First version of weakpass") and grep it - password is there. This means that most probably we are not the first who were able to penetrate Telia.</p>

<pre>2019-10-22 - tried to get in touch with Telia and asked for PGP key
2019-10-23 - password protected ZIP sent to Telia as they asked
2019-10-24 - Telia confirmed that report had been received
2019-11-21 - disclosure reminder sent to Telia
2019-11-23 - Telia tried to threaten the reporter
2019-11-27 - Telia confirmed that everything was safe, vulnerabilities were "always fixed"
2020-06-29 - full disclosure
</pre>

    </article></div>]]>
            </description>
            <link>https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23687014</guid>
            <pubDate>Tue, 30 Jun 2020 05:54:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Indian Covid-19 vaccine made by Bharat Biotech is set to enter human trials]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23686964">thread link</a>) | @seekerrest
<br/>
June 29, 2020 | https://www.businessinsider.in/india/news/an-indian-covid-19-vaccine-made-by-bharat-biotech-is-set-to-enter-human-trials/articleshow/76702286.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/india/news/an-indian-covid-19-vaccine-made-by-bharat-biotech-is-set-to-enter-human-trials/articleshow/76702286.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt76702286read"><div data-den="denmark"><div><ul>
 <li><strong>Bharat Biotech’s coronavirus vaccine <keyword keytype="Location" smid="0" usetype="2" keywordseo="Covaxin" keynameseo="covaxin" actualkeyword="covaxin">Covaxin</keyword> is the first <keyword keytype="UnKnown" smid="0" usetype="2" keywordseo="COVID-19" keynameseo="covid-19" actualkeyword="covid-19">COVID-19</keyword> vaccine to get DGCI’s (Drug Controller General of India) nod.<br></strong></li>
 <li><strong>The drug regulatory body allowed the pharma company to conduct phase I and phase-II clinical trials. <br></strong></li>
 <li><strong>The vaccine was developed in collaboration with the National Institute of Virology, <keyword keytype="Company" smid="0" usetype="2" keywordseo="IndianCouncil-of-Medical-Research" keynameseo="indiancouncil-of-medical-research" actualkeyword="indiancouncil of medical research">IndianCouncil of Medical Research</keyword> (<keyword keytype="UnKnown" smid="0" usetype="2" keywordseo="ICMR" actualkeyword="ICMR">ICMR</keyword>).<br></strong></li>
 <li><strong>The human trials of Covaxin are likely to begin in July. <br></strong></li>
 <li><strong>According to the World Health Organisation (WHO), there are 13 vaccines undergoing clinical trials as of now. While 129 are in the pre-clinical evaluation phase. </strong></li>
</ul><p>India, on Monday (June 29) got the approval for conducting human trials of a potential coronavirus vaccine. 
</p><p>
Covaxin — developed by the Indian vaccine and bio-therapeutics manufacturer </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="Bharat-Biotech" actualkeyword="Bharat Biotech">Bharat Biotech</keyword><p> — is the first COVID-19 vaccine to get DGCI’s (Drug Controller General of India) nod. The drug regulatory body allowed the pharma company to conduct phase I and phase II clinical trials. 
</p><div data-type="twitter" data-handle="BharatBiotech" data-handlename="BharatBiotech" data-image="http://pbs.twimg.com/profile_images/1100655759069720576/FTMGdOoj_normal.png" data-favoritecount="1314" data-retweetcount="677" data-status="COVAXIN™, India's 1st indigenous Covid-19 vaccine, developed by Bharat Biotech successfully enters human trials.… https://t.co/Q6X8uJVrHK" data-createdat="1593453110000" data-id="1277661065002676224"><div><blockquote lang="en"><p data-pos="3">COVAXIN™, India's 1st indigenous Covid-19 vaccine, developed by Bharat Biotech successfully enters human trials.… https://t.co/Q6X8uJVrHK</p>&amp;mdash; BharatBiotech (@BharatBiotech) <a target="_blank" href="https://twitter.com/BharatBiotech/status/1277661065002676224" rel="nofollow">1593453110000</a></blockquote></div></div>
<p>The human trials of the vaccine — which was developed in collaboration with the National Institute of Virology, IndianCouncil of Medical Research (ICMR) — are likely to begin in July. 
<br data-name="20" data-nm1="div"><span>Advertisement</span></p><hr>
<p>The development comes after Bharat Biotech showed the results of pre-clinical studies of the potential vaccine, ensuring safety and immunity response. The company says that they completed pre-clinical studies in two months — after the regulatory approval. 
</p><p>    
“The collaboration with and NIV was instrumental in the development of this vaccine. The proactive support and guidance from CDSCO have enabled approvals to this project,” Krishna Ella, Chairman and MD of Bharat Biotech 
<a target="_blank" href="https://indianexpress.com/article/india/bharat-biotechs-covid-vaccine-1st-in-india-to-get-approval-for-human-trials-6482403/" rel="nofollow">told</a> the Indian Express. 
</p><p>
The drug manufacturer said that the vaccine has been developed in a high containment facility in Hyderabad.
</p><p><span>Advertisement</span></p><hr>
<p>“Our ongoing research and expertise in forecasting epidemics has enabled us to successfully manufacture a vaccine for the H1N1 pandemic. Continuing our focus on creating the only BSL-3 containment facilities for manufacturing and testing in India, Bharat Biotech is committed to advancing vaccine development as a matter of national importance to demonstrate India’s strength in handling the future pandemics,” Ella 
<a target="_blank" href="https://www.timesnownews.com/health/article/india-s-first-covid-19-vaccine-covaxin-gets-dcgi-approval-for-clinical-trials/613790" rel="nofollow">added</a>.
</p><p>
Scientists across the globe are now working towards a vaccine faster than ever. As many as 86 teams are presently working to come up with a Covid-19 vaccine including those undergoing clinical trials. 
<a target="_blank" href="https://www.hindustantimes.com/india-news/vaccine-by-bharat-biotech-first-to-get-human-trials-nod/story-Ha2bWTuHXIgh7xPDr6AyfN.html" rel="nofollow">According to</a> the World Health Organisation (WHO), there are 13 vaccines undergoing clinical trials as of now. While 129 are in the pre-clinical evaluation phase. 
</p><p>    
Coronavirus infection has already cost over 16,475 lives in India and the world is now waiting with bated breath for a vaccine. Zydus Cadila, Serum Institute of India and other Indian pharma giants are also working to develop COVID-19 vaccines. 
<br data-name="50" data-nm1="br"><span>Advertisement</span></p><hr>
<p>According to the Ministry of Health and Family Welfare, the total COVID infections spiked to 548,318, as on June 30. 
</p><p>    

<strong>See also:</strong>
<br>
<a href="https://www.businessinsider.in/international/news/who-says-the-coronavirus-pandemic-is-far-from-over/articleshow/76702071.cms">WHO says the coronavirus pandemic is far from over</a></p><p>
<span>Advertisement</span></p><hr>
<p><a href="https://www.businessinsider.in/india/news/unlock-2-no-bar-pass-for-inter-state-travel-home-secretary-to-states/articleshow/76701922.cms">Unlock 2: No bar, pass for inter-state travel, Home Secretary to states</a>
<br>
</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/india/news/an-indian-covid-19-vaccine-made-by-bharat-biotech-is-set-to-enter-human-trials/articleshow/76702286.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-23686964</guid>
            <pubDate>Tue, 30 Jun 2020 05:45:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US restricts Windows exports to Chinese/Russian/Venezuelan military and police]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23686798">thread link</a>) | @fuoqi
<br/>
June 29, 2020 | https://www.globaltradeandsanctionslaw.com/new-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela/ | <a href="https://web.archive.org/web/*/https://www.globaltradeandsanctionslaw.com/new-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>

			<!-- HEADER -->
			

			            

            <!-- MAIN -->
            <div id="main">
	                            <div>
                	
                	
	                <section>
	                		                	<div>
		                	

<article id="post-1180" itemprop="blogPost" itemtype="http://schema.org/BlogPosting" itemscope="">
	
	<div>
		<header>

			
			
						
			<p><span>Published on:</span> <time datetime="2020-04-29T21:39:21-04:00" itemprop="datePublished" pubdate="">April 29, 2020</time></p>
			
			
            
                <meta itemprop="headline" content="New Export Control Rules Confront Integration of Civilian and Military Technology Development in China, Rus...">
			
			
			
			
			<p><a href="http://api.addthis.com/oexchange/0.8/offer?url=https%3A%2F%2Fwww.globaltradeandsanctionslaw.com%2Fnew-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela%2F&amp;title=New+Export+Control+Rules+Confront+Integration+of+Civilian+and+Military+Technology+Development+in+China%2C+Russia%2C+and+Venezuela" target="_blank" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;"><img src="https://www.globaltradeandsanctionslaw.com/wp-content/themes/Willow-Responsive/images/share/share.gif" alt="Share this Post"></a>
	<a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwp.me%2Fp7CI3n-j2&amp;text=New+Export+Control+Rules+Confront+Integration+of+Civilian+and+Military+Technology+Development+in+China%2C+Russia%2C+and+Venezuela" target="_blank" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;"><img src="https://www.globaltradeandsanctionslaw.com/wp-content/themes/Willow-Responsive/images/share/twitter.gif" alt="Tweet this Post"></a>
	<a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.globaltradeandsanctionslaw.com%2Fnew-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela%2F" target="_blank" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;"><img src="https://www.globaltradeandsanctionslaw.com/wp-content/themes/Willow-Responsive/images/share/fb.gif" alt="Share on Facebook"></a>
	<a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.globaltradeandsanctionslaw.com%2Fnew-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela%2F&amp;title=New+Export+Control+Rules+Confront+Integration+of+Civilian+and+Military+Technology+Development+in+China%2C+Russia%2C+and+Venezuela&amp;source=Global+Trade+%26amp%3B+Sanctions+Law" target="_blank" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;"><img src="https://www.globaltradeandsanctionslaw.com/wp-content/themes/Willow-Responsive/images/share/linkedin.gif" alt="Share on LinkedIn"></a>
</p>					</header>
		<div itemprop="articleBody">
									<div>
								<p>On April 28, 2020, the U.S. Commerce Department’s Bureau of Industry and Security (BIS) published two final rules that will eliminate the license exception for civil end users (CIV) in the People’s Republic of China, Russia, and Venezuela and expand military end use and end user restrictions on these countries. These rules confront the national security risks presented by the increasing integration of civilian and military technology development, particularly in China, by requiring U.S. Government review of a broader range of exports including electronics and telecommunications items only controlled for antiterrorism (AT) reasons (with licenses subject to a presumption of denial) when shipped for military end uses or to military end users. These final rules will go into effect on June 29, 2020.</p>
<p>BIS also published a proposed rule that would modify License Exception Additional Permissive Reexports (APR) by restricting the destinations that will be eligible for the license exception. Comments on the proposed rule are also due June 29, 2020.<span id="more-1180"></span></p>
<p><strong>Expansion of Controls Related to Military End Use or Military End Users in China, Russia, or Venezuela</strong></p>
<p>The <a href="https://www.govinfo.gov/content/pkg/FR-2020-04-28/pdf/2020-07241.pdf">first final rule</a> expands license requirements for exports, reexports, and transfers (in-country) of items intended for military end uses and military end users in China, Russia, and Venezuela, pursuant to § 744.21 of the EAR. Effective June 29, 2020, the final rule:</p>
<ul>
<li><strong>Imposes a restriction on exports to <u>military end users</u> in China, similar to current requirements for Venezuela and Russia.</strong> Currently, for specified items, EAR Section 744.21 requires a license where the exporter has knowledge that (i) an item destined for China, Russia, or Venezuela will be used for a <u>military end use</u>, or (ii) an item destined for Russia or Venezuela (but not China) will be for a <u>military end user</u>.</li>
<li>
<ul>
<li>The term “military end user,” includes not only “the national armed services (army, navy, marine, air force, or coast guard), as well as the national guard and national police, government intelligence or reconnaissance organizations,” but also “<u>any person or entity whose actions or functions are intended to support ‘military end uses</u>.’”</li>
<li>Many large commercial manufacturers and other companies, particularly in China (as well as Russia and to a lesser extent Venezuela) may conduct some activities in support of a military end use. Under the new rule, it appears that a license may be required to export the covered categories of items (e.g., 3A991 integrated circuits) to such companies, even if the item itself will be used exclusively in connection with commercial applications. If interpreted in this way, the rule could have a broad impact; it will be important to monitor further guidance from BIS. Under any interpretation, exporters will need to focus their due diligence on whether any aspect of their counterparties’ business supports military end uses particularly in China, given what BIS refers to in the rule as “China’s widespread civil-military integration.”</li>
</ul>
</li>
<li><strong>Significantly expands the list of items subject to the military end use and end user license requirements in Supplement No. 2 to Part 744 of the EAR</strong> for exports to China, Russia, and Venezuela. The list will now also include certain materials processing, electronics, telecommunications, mass market encryption items, sensors and lasers, propulsion, electronics, maritime equipment, and aircraft items on the Commerce Control List (CCL). For example, sending a 3A991 chip, a 5A992 iPhone, or a copy of 5D992 Microsoft Windows to a military end user in China would be subject to this restriction.</li>
<li><strong>Broadens the “military end use” definition. </strong> “Military end use” currently is defined as:</li>
<li>
<ul>
<li>Incorporation into a military item described on the U.S. Munitions List (USML);</li>
<li>Incorporation into a military item described on the Wassenaar Arrangement Munitions List (as set out on the Wassenaar Arrangement Web site at <a href="http://www.wassenaar.org/">http://www.wassenaar.org</a>);</li>
<li>Incorporation into items classified under ECCNs ending in “A018” or under “600 series” ECCNs; or</li>
<li>For the “use,” “development,” or “production” of military items described above.</li>
</ul>
</li>
</ul>
<p>“Use” normally has a conjunctive definition with six elements – meaning all the elements need to be satisfied to constitute “use.” In this case, the final rule expands the “military end use” definition to also include<u> any item that supports or contributes to any one of the elements of “use,” i.e., the operation, installation, maintenance, repair, overhaul, refurbishing, “development,” <strong>or</strong> “production,” of military items.</u></p>
<ul>
<li><strong>Adopts a policy of presumption of denial of licenses </strong>for exports to China, Russia, and Venezuela for military end uses and end users, rather than the existing case-by-case license review standard. Accordingly, license applications pursuant to EAR § 744.21 will be denied in most cases.</li>
<li><strong>Expands Electronic Export Information (EEI) requirements for all items listed on the CCL that are destined for China, Russia, and Venezuela – independent of end use or value. </strong>Per the Foreign Trade Regulations, many less sensitive AT-controlled items generally do not require EEI reporting at all if their value is less than $2,500, and even if reported, the EEI would generally not need to specify an ECCN. The final rule requires EEI reporting to identify specific ECCNs for tangible exports of all items listed on the CCL to China, Russia, and Venezuela, with very few exceptions. As a result, even if a company does business with these countries entirely in the commercial realm, its export reporting obligations may change.</li>
</ul>
<p><strong>Elimination of License Exception Civil End Users (CIV) </strong></p>
<p>The <a href="https://www.govinfo.gov/content/pkg/FR-2020-04-28/pdf/2020-07240.pdf">second final rule</a> eliminates License Exception CIV. License Exception CIV currently authorizes the export of certain items that are controlled for national security (NS) reasons provided that the items are destined to civil end users for civil uses in Country Group D:1, which includes, among others, China, Russia, Venezuela, Ukraine, and Iraq. A number of items currently may be exported under License Exception CIV, including certain telecommunication equipment and computers. Accordingly, as of June 29, 2020 companies will no longer be able to utilize License Exception CIV.</p>
<p><strong>Modification of License Exception Additional Permissive Reexports (APR)</strong></p>
<p>The <a href="https://www.federalregister.gov/documents/2020/04/28/2020-07239/modification-of-license-exception-additional-permissive-reexports-apr">third rule</a> is a proposed rule that would modify License Exception APR, which currently authorizes the reexport of certain items from Country Group A:1 or Hong Kong to destinations in Country Group B (so long as the destination is not also in Country Groups D:2, D:3, or D:4) and Country Group D:1. The rule proposes removing destinations in Country Group D:1, including China, as eligible recipients of national security-controlled items reexported under License Exception APR.</p>
<p><a href="https://www.pillsburylaw.com/images/content/1/3/132544/New-Export-Control-Rules-Confront-Integration-of-Civilian-and-Mi.pdf">(English-Chinese version) New Export Control Rules Confront Integration of Civilian and Military Technology Development in China, Russia, and Venezuela</a></p>
							</div>
					</div>
		

	</div>
</article>
	
								</div>

																

							
						</section>

						

					</div>
				</div>


							<!-- FOOTER -->
				
						</div> <!-- /.cwrap -->
		</div></div>]]>
            </description>
            <link>https://www.globaltradeandsanctionslaw.com/new-export-control-rules-confront-integration-of-civilian-and-military-technology-development-in-china-russia-and-venezuela/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23686798</guid>
            <pubDate>Tue, 30 Jun 2020 05:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rise in opioid deaths serves as reminder Covid-19 isn't Canada's only health]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23685817">thread link</a>) | @mrfusion
<br/>
June 29, 2020 | https://www.cbc.ca/news/politics/minority-report-newsletter-opioid-deaths-covid-19-1.5610740 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/minority-report-newsletter-opioid-deaths-covid-19-1.5610740">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/politics/minority-report-newsletter-opioid-deaths-covid-19-1.5610740</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685817</guid>
            <pubDate>Tue, 30 Jun 2020 02:17:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Private Equity 401k]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23685626">thread link</a>) | @mikeberv
<br/>
June 29, 2020 | https://www.billiondollarstartupideas.com/ideas/private-equity-401k | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/private-equity-401k">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-86cc504f0c3a34e020e4"><div><p><strong>Problem: </strong>Right now, investing in private equity funds is only open to accredited investors and qualified clients. However, on June 3rd “The U.S. Department of Labor, which oversees retirement plan rules, on June 3&nbsp;<a href="https://www.bloomberg.com/news/articles/2020-06-03/private-equity-firms-get-trump-administration-s-nod-to-tap-401ks" title="Private Equity Gets a Big Win With U.S. Nod to Tap 401(k) Plans" target="_blank">issued guidance</a>&nbsp;that’s been taken as a green light to include PE funds in some plans. It doesn’t say that workers should suddenly get an option to pick one by themselves. Rather a PE fund might be included as part of the portfolio of another diversified fund.”</p><p><strong>Solution: </strong>A private equity fund that is funded primarily through 401ks. As described by Bloomberg in their article <a href="https://www.bloomberg.com/news/articles/2020-06-26/private-equity-is-coming-for-the-6-trillion-401-k-market">"Private Equity is Coming for The $6 Trillion 401k Market":</a></p><blockquote><p><a href="https://www.bloomberg.com/news/articles/2020-06-26/private-equity-is-coming-for-the-6-trillion-401-k-market">There’s roughly $5.6 trillion in such accounts (401ks),</a> and the prospect of capturing even a sliver of it has the industry abuzz. A more complicated question is whether ordinary investors will really want their money going into&nbsp;<a href="https://www.bloomberg.com/news/features/2019-10-03/how-private-equity-works-and-took-over-everything" title="Everything Is Private Equity Now" target="_blank">buyout funds</a>.</p><p><a href="https://www.bloomberg.com/quicktake/private-equity" title="QuickTake: Private Equity" target="_blank">Private equity is a different beast</a>&nbsp;from the mutual funds retirement savers are familiar with. PE managers often buy companies whole, financing the purchase with debt that ends up on the books of the companies themselves. That adds to potential profits but also to risk and complexity. Funds tend to have long lockup periods, during which investors can’t get their money out, and charge high management fees as well as take a share of profits off the top.</p></blockquote><p>Since this new guidance was issued less than 30 days ago, the industry is ripe for disruption. Because it is so new, the business would be primarily focused on marketing the opportunity to prospective investors and educating them about the potential risks and rewards. Of course, since PE funds would be layered inside other funds, the business’ goal would be to become part of as many blended funds as possible: thus, another avenue of marketing would be to fund-makers to be included in their funds and receive 401k dollars.</p><p><strong>Monetization: </strong>Ultimately, the goal of the business would be to acquire as much capital as possible: <a href="https://pitchbook.com/news/articles/how-private-equity-firms-make-money">PE funds have a monetization</a> model of fees (about 2%) and carried interest (20%). This business would adopt that model.</p></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/private-equity-401k</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685626</guid>
            <pubDate>Tue, 30 Jun 2020 01:44:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a System Call for OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23685279">thread link</a>) | @soheilpro
<br/>
June 29, 2020 | https://poolp.org/drafts/2020-05-28-015100-copy/ | <a href="https://web.archive.org/web/*/https://poolp.org/drafts/2020-05-28-015100-copy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://poolp.org/drafts/2020-05-28-015100-copy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685279</guid>
            <pubDate>Tue, 30 Jun 2020 00:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on 6 months of a solo SaaS startup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23685204">thread link</a>) | @c0nrad
<br/>
June 29, 2020 | https://blog.c0nrad.io/posts/reflections-6months/ | <a href="https://web.archive.org/web/*/https://blog.c0nrad.io/posts/reflections-6months/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#nobody-cares">Nobody cares</a></li>
    <li><a href="#careful-with-free-trials">Careful with free trials</a></li>
    <li><a href="#seo--pipeline--ads">SEO / Pipeline / Ads</a></li>
    <li><a href="#people-like-open-source-a-lot">People like “open source”… a lot</a></li>
    <li><a href="#on-the-plus-working-for-yourself-is-amazing">On the plus, working for yourself is… amazing</a></li>
    <li><a href="#delayed-reward">Delayed reward</a></li>
    <li><a href="#its-a-bit-of-a-rollercoaster">It’s a bit of a rollercoaster</a></li>
    <li><a href="#lonely">Lonely</a></li>
    <li><a href="#bug-fixes-are-meh">Bug Fixes are… meh</a></li>
    <li><a href="#others">Others</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>

        <p>It’s crazy to think my startup is already over 6 months old. This post is some informal reflections on that period.</p>
<p>To set the context for people who are not me, this was my first foray into startups. The startup is pretty lean (it’s a saas security startup), only on the verge of profitability. Single digit customers.</p>
<p>A lot of this may sound complain-y, they’re definitely first world problems. But they are things I wish I had fully internalized.</p>
<h2 id="nobody-cares">Nobody cares</h2>
<p>It sounds very negative, and I don’t mean it in a bad way. But I think it applies to many aspects of building the startup.</p>
<p>People want a tool that solves the problem. No one cares about the effort involved in creating little features. No one cares about the story, no one cares how it works. They just want to be re-assured it will work, so they can focus on their 1000 other problems.</p>
<p>There’s nothing wrong with that, it’s just important to remember.</p>
<p>The fact that no one cares also has positive aspects! I was worried about my two hours of planned downtime when I was doing a large migration. Literally no one cared. I think my startup could have been down for a few days, and no one would of cared that much. Unfortunately or fortunately I focused a lot on reliability (which was kind of wasted effort now that I realize it).</p>
<h2 id="careful-with-free-trials">Careful with free trials</h2>
<p>I thought it would be cool if I had a free sandbox plan. Let people kick the tires. When they see the amazing value they’ll upgrade!</p>
<p>Not so much.</p>
<p>The free sandbox offering attracted over 1000 businesses. Super neat! The only problem was… no one upgraded to paying plans. So I’m supporting 1000 customers on my platform. Goodbye life savings (kidding, but it does cost non-trivial money).</p>
<p>I don’t want to dive into the specifics of content-security-policy report-uri, but having a sandbox account created weird dynamics/incentives. My startup focuses on making this specific security tool easier. And I charge based on “usage” of the feature. But by making this security tool easier, there was less need for usage. So every feature I included made the Sandbox account a better solution, no need to upgrade for more usage.</p>
<p>So I had 1000+ people using the platform, and they had no incentive to upgrade. And every feature I released solidified that SANDBOX was all your need. I could of limited key features, but I hate it when other companies do that, and it wasn’t obvious to me what features to limit. It also feels dis-honest. Instead I’d rather focus on making the best product. So instead I went with a free trial period and made the choice to discontinue SANDBOX accounts. (If you were a sandbox user of Csper, against I apologize, but it had to be done).</p>
<p>There’s way less usage, but now people pay for the service. And I’m not fronting the bill for &gt;1000 customers (which I can not do for long since i’m self bootstrapped).</p>
<h2 id="seo--pipeline--ads">SEO / Pipeline / Ads</h2>
<p>It sounds so obvious now, but wasn’t fully fully internalized when I started.</p>
<p>People aren’t just going to “stumble” onto your product.</p>
<p>When Csper was released, I made sure it could handle a lot of load. I was worried that it would spread like wildfire. So I made sure everything could scale. Autoscaling k8s, autoscaling database. I setup observability on everything to debug issues, tracing, logging, monitoring dashboards, etc.</p>
<p>Long story short, almost no one showed up.</p>
<p>SEO / Marketing are the name of the game. (not an endorsement), but getting setup with SEM rush to track my SEO (specifically content marketing).</p>
<h2 id="people-like-open-source-a-lot">People like “open source”… a lot</h2>
<p>I built a similar open source product about 5-6 years ago. It’s crazy how fast people will refer an open source product compared to a paid product.</p>
<p>It’s a huge marketing advantage I never really considered. The product today is SIGNIFICANTLY better than the 5-6 year old product, yet people still share links to my old defunct product.</p>
<p>“open source” seems to trump reliability. I’m probably the same way, so I can’t complain too much. Just interesting to watch it happen.</p>
<p>I was very tempted to shift to “open source” and then have a paid plan. But, never did.</p>
<h2 id="on-the-plus-working-for-yourself-is-amazing">On the plus, working for yourself is… amazing</h2>
<p>I loved all my previous jobs. For better or worse, work is usually the center of my life.</p>
<p>But, there’s something about waking up in the morning, making yourself some coffee, and pouring your heart into something you own. For awhile I would shoot out of bed at 6am (without an alarm) because I was so excited to get to work. I’d work for 12 hours, and then do it all again, and I was excited about it.</p>
<p>And it’s so nice knowing where everything is. At some point I had to do a decent sized migration across 125 files. Knowing how everything works and where it is makes every project nice and fun. No hidden side effects.</p>
<h2 id="delayed-reward">Delayed reward</h2>
<p>More of a psychological thing. But it’s hard to remove the feeling of working hard and getting a reward.</p>
<p>I did two large migrations on Csper. One was a re-write of “projects” and “organizations” to consolidate billing and other stuff. It was like 4500 lines of code over 125 files. Then doing all the data base migrations and testing… It was a lot of work to make sure it all worked correctly. And it was a bit stressful.</p>
<p>After the release went smoothly, it was a hurah! But, it’s not like I would instantly get any new customers.</p>
<p>After the migration is done, I’m still just staring at my computer, nothing has changed.</p>
<p>Being generous, let’s say the different of consolidated billings increased conversions by 5%, I’d have to wait awhile to see that impact. I don’t think I even got a new customer that week.</p>
<p>It can be dis-heartening when you work super hard, but then nothing happens. It was a mental barrier to separate that.</p>
<h2 id="its-a-bit-of-a-rollercoaster">It’s a bit of a rollercoaster</h2>
<p>It seems like when things go bad, a lot of things go bad at once. A customer will leave, the firefox extension store will remove my addon, some feature will be acting up, and your competitors just signed a big deal.</p>
<p>That emotional buffer is important. I should have remembered to leave some room in my emotional tank to take hits. Wearing thin and then taking a couple of hits is not fun.</p>
<p>In the movies/books/interwebs every startup is successful. When you see people working hard, it’s like “no duh, the payoff and reward will be huge!” But in real life you have to face that most likely it will fail. When do you cut your losses? When you take a number of hits at once, those questions go to the front of your mind.</p>
<h2 id="lonely">Lonely</h2>
<p>Probably the biggest downside to this adventure so far is not working on a team. I miss is celebrating wins. Giving yourself a high five when a customer signs up is cool, but experiences are better shared with someone.</p>
<p>My girlfriend and I recently worked out a system where I get a twinkie when I get a new customer. Which is very nice. We celebrate the wins, but there’s something about a group working towards a goal and achieving that goal.</p>
<h2 id="bug-fixes-are-meh">Bug Fixes are… meh</h2>
<p>Previously as an engineer I would hate publishing bugs in my code. Where’s the attention to craft!</p>
<p>But now being honest about my todo list, most bugs don’t matter <em>that</em> much. The chance of defering a customer from paying because of a bug here and there is pretty small. (I mean, it depends on the bug, and you should try super hard not to have bugs. It’s no excuse for being sloppy).</p>
<p>But, I have a bug tracker pretty full of little bugs here and there. But when I assign dollar values to them, SEO/marketing is almost always more important than fixing a bug.</p>
<p>If an article attracts two new customers, and a weird edge case defers one customer, by the numbers it’s better to focus on the article. When you’re a non-bootstrapped solo startup, you have to run towards the money. You also can’t make everyone happy.</p>
<h2 id="others">Others</h2>
<p>Some things that I already knew, and thankful that I did:</p>
<ul>
<li>Staging/prod. Staging saved my butt a number of times. And made things way less stressful when doing big changes. Worth every penny.</li>
<li>k8s on gke was pretty nice. it took a day or two to get my infra setup, and then I never really thought about it. it just scales here and there.</li>
<li>Single command deploys, and lots of makefiles. Any command that could be useful later I store in a makefile. i never want to think about things.</li>
</ul>
<p>Things that were surprisingly frustrating:</p>
<ul>
<li>Browser extension review processes!
<ul>
<li>Chrome takes weeks and weeks to review extensions</li>
<li>Firefox is super picky about making sure that they can compile your code and it exactly matches what’s in the app store</li>
</ul>
</li>
<li>SaaS trails/charges. You rely on a number of services for your startup, and they start to add up. Some companies are also very sneaky about not emailing you before they charge your credit card. There was one company that charged me for 6 months without sending a single email.
<ul>
<li>I should of been reviewing my credit card statements, but when you’re already working long days, it’s near the bottom of the chopping block. At the end of the day, writing another article for SEO is more important than checking a hypothetical</li>
</ul>
</li>
<li>Kind of weird point, but I tried advertising on linkedin/google/facebook/twitter. I left with a very negative view of all the platforms and try very hard not to read from them anymore. Everyone knows that those platforms are about advertising, but it wasn’t until I was trying to shove my agenda down other peoples throats did I realize how disgusting it was. Now I see all the other businesses doing what I was doing, pushing their own agenda. I want no part of anyone else’s agenda. I was probably doing ads wrong, but I saw no drop in signups after I stopped them. I’m going to fully focus on SEO instead. I feel good about that, when people have a problem, they’ll google for it, and my company will be there.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Overall, building Csper has been a interesting experience. Maybe …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.c0nrad.io/posts/reflections-6months/">https://blog.c0nrad.io/posts/reflections-6months/</a></em></p>]]>
            </description>
            <link>https://blog.c0nrad.io/posts/reflections-6months/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685204</guid>
            <pubDate>Tue, 30 Jun 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's in a GIF – Bit by Byte]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23685160">thread link</a>) | @lowmemcpu
<br/>
June 29, 2020 | http://matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp | <a href="https://web.archive.org/web/*/http://matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
	We sill start off by walking though the different parts of a GIF file.
	(The information on this page is primarily drawn from the
	<a href="http://www.w3.org/Graphics/GIF/spec-gif89a.txt">W3C GIF89a specification</a>.)
	A GIF file is made up of a bunch of different "blocks" of data. The following diagram
	shows all of the different types of blocks and where they belong in the file. The file starts
	at the left and works it's way right. At each branch you may go one way or the other. The
	large "middle" section can be repeated as many times as needed. (Technically, it may
	also be omitted completely but i can't imagine what good a GIF file with no image data
	would be.)
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/gif_file_stream.gif" alt="GIF file stream diagram" width="700" height="220"></p>
	<p>
	I'll show you what these blocks looks like by walking through a sample
	GIF file. You can see the sample file and its corresponding bytes below.
	</p>
	

	<p>
	Note that not all blocks are represented in this sample file. I will provide samples of missing
	blocks where appropriate.
	The different types of blocks include:
		<a href="#header_block">header</a>,
		<a href="#logical_screen_descriptor_block">logical screen descriptor</a>,
		<a href="#global_color_table_block">global color table</a>,
		<a href="#graphics_control_extension_block">graphics control extension</a>,
		<a href="#image_descriptor_block">image descriptor</a>,
		<a href="#local_color_table_block">local color table</a>,
		<a href="#image_data_block">image data</a>,
		<a href="#plain_text_extension_block">plain text extension</a>,
		<a href="#application_extension_block">application extension</a>,
		<a href="#comment_extension_block">comment extension</a>,
		and <a href="#trailer_block">trailer</a>.
	Let's get started with the first block!
	</p>

	<h2><a name="header_block">Header Block</a></h2>
	<p>From Sample File: </p>
	<p>
	All GIF files must start with a header block. The header takes up the first
	six bytes of the file. These bytes should all correspond to
	<a href="http://www.ascii.cl/">ASCII character codes</a>. We actually have two pieces
	of information here. The first three bytes are called the <strong>signature</strong>.
	These should always be "GIF" (ie 47="G", 49="I", 46="F"). The next three specify the
	<strong>version</strong> of the specification that was used to encode the image. We'll only be working
	with "89a" (ie 38="8", 39="9", 61="a"). The only other recognized version string
	is "87a" but i doubt most people will run into those anymore.
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/header_block.gif" alt="GIF header block layout"></p>

	<h2><a name="logical_screen_descriptor_block">Logical Screen Descriptor</a></h2>
	<p>From Sample File: <span> 0A </span><span> 00 </span><span> 0A </span><span> 00 </span><span> 91 </span><span> 00 </span><span> 00 </span></p>
	<p>
	The logical screen descriptor always immediately follows the header. This block
	tells the decoder how much room this image will take up. It is exactly
	seven bytes long. It starts with the <strong>canvas width</strong>. This value
	can be found in the first two bytes. It's saved in a format called the spec
	simply calls <em>unsigned</em>. Basically we're looking at a 16-bit, nonnegative
	integer (0-65,535). As with all the other multi-byte values in the GIF format, the least
	significant byte is stored first (little-endian format). This means where we would read
	<span> 0A </span><span> 00 </span>
	from the byte stream, we would normally write it as <span>000A</span> which is
	the same as 10. Thus the width of our sample image is 10 pixels. As a further example
	255 would be stored as <span> FF </span><span> 00 </span> but 256 would be <span> 00 </span><span> 01 </span>.
	As you might expect, the <strong>canvas height</strong> follows. Again, in this sample we
	can see this value is <span> 0A </span><span> 00 </span> which is 10.
	</p>
	<p>
	Next we have a <em>packed byte</em>. That means that this byte actually has multiple values
	stored in its bits. In this case, the byte <span> 91 </span> can be represented
	as the binary number <span>10010001</span>. (The built in Windows calculator
	is actually very useful when converting numbers into hexadecimal and binary formats. Be sure
	it's in "scientific" or "programmer" mode, depending on the version of
	windows you have.) The first (most-significant) bit is the <strong>global color
	table flag</strong>. If it's 0, then there is none. If it's 1, then a global color table will
	follow. In our sample image, we can see that we will have a global color table (as will usually
	be the case).  The next three bits represent the <strong>color resolution</strong>. The spec
	says this value " is the number of bits per primary color available to the original image,
	minus 1" and "...represents the size of the entire palette from which the colors in the
	graphic were selected." Because i don't much about what this one does, I'll point you to
	a more knowledgeable article on <a href="http://www.devx.com/projectcool/Article/19997/0/page/7">bit and color depth</a>.
	For now 1 seems to work. Note that <span>001</span> represents 2 bits/pixel;
	<span>111</span> would represent 8 bits/pixel.
	The next single bit is the <strong>sort flag</strong>. If the values is 1, then the
	colors in the global color table are sorted in order of "decreasing importance," which
	typically means "decreasing frequency" in the image. This can help the image decoder but
	is not required. Our value has been left at 0. The last three bits are the <strong>
	size of global color table</strong>. Well, that's a lie; it's not the actual size of the
	table. If this value is N, then the actual table size is 2^(N+1). From our sample
	file, we get the three bits <span>001</span> which is the binary version of 1.
	Our actual table size would be 2^(1+1) = 2^2 = 4. (We've mentioned the global color table
	several times with this byte, we will be talking about what it is in the next section.)
	</p>
	<p>
	The next byte gives us the <strong>background color index</strong>. This byte is only meaningful
	if the global color table flag is 1. It represents which color in the global color table
	(by specifying its index) should be used for pixels whose value is not specified in the
	image data. If, by some chance, there is no global color table, this byte should be 0.
	</p>
	<p>
	The last byte of the logical screen descriptor is the <strong>pixel aspect ratio</strong>.
	I'm not exactly sure what this value does. Most of the images I've seen have this value
	set to 0. The spec says that if there was a value specified in this byte, N, the actual
	ratio used would be (N + 15) / 64 for all N&lt;&gt;0.
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/logical_screen_desc_block.gif" alt="GIF logical screen descriptor block layout"></p>





	<h2><a name="global_color_table_block">Global Color Table</a></h2>
	<p>From Sample File: <span> FF </span><span> FF </span><span> FF </span><span> FF </span><span> 00 </span><span> 00 </span><span> 00 </span><span> 00 </span><span> FF </span><span> 00 </span><span> 00 </span><span> 00 </span></p>
	<p>
	We've mentioned the <strong>global color table</strong> a few times already now lets talk
	about what it actually is. As you are probably already aware, each GIF has its own color
	palette. That is, it has a list of all the colors that can be in the image and cannot
	contain colors that are not in that list. The global color table is where that list
	of colors is stored. Each color is stored in three bytes. Each of the bytes represents
	an RGB color value. The first byte is the value for red (0-255), next green, then blue.
	The size of the global color table is determined by the value in the packed byte of the
	logical screen descriptor. As we mentioned before, if the value from that byte is N, then
	the actual number of colors stored is 2^(N+1). This means that the global color table will
	take up 3*2^(N+1) bytes in the stream.
	</p>

	<div>
	<table id="global_color_size">
	<tbody><tr><th>Size In Logical<br>Screen Desc</th><th>Number Of<br>Colors</th><th>Byte<br>Length</th></tr>
	<tr><td>0</td><td>2</td><td>6</td></tr>
	<tr><td>1</td><td>4</td><td>12</td></tr>
	<tr><td>2</td><td>8</td><td>24</td></tr>
	<tr><td>3</td><td>16</td><td>48</td></tr>
	<tr><td>4</td><td>32</td><td>96</td></tr>
	<tr><td>5</td><td>64</td><td>192</td></tr>
	<tr><td>6</td><td>128</td><td>384</td></tr>
	<tr><td>7</td><td>256</td><td>768</td></tr>
	</tbody></table>
	</div>

	<p>
	Or sample file has a global color table size of 1. This means it holds 2^(1+1)=2^2=4 colors.
	We can see that it takes up 12, (3*4), bytes as expected. We read the bytes three at a time to get
	each of the colors. The first color is #FFFFFF (white). This value is given an index of 0.
	The second color is #FF0000 (red). The color with an index value of 2 is #0000FF (blue).
	The last color is #000000 (black). The index numbers will be important when we decode
	the actual image data.
	</p>
	<p>
	Note that this block is labeled as "optional." Not every GIF has to specify a global
	color table. However, if the global color table flag is set to 1 in the logical
	screen descriptor block, the color table is then required to immediately follow that
	block.
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/global_color_table.gif" alt="GIF global color table block layout"></p>



	<h2><a name="graphics_control_extension_block">Graphics Control Extension</a></h2>
	<p>From Sample File: <span> 21 </span><span> F9 </span><span> 04 </span><span> 00 </span><span> 00 </span><span> 00 </span><span> 00 </span><span> 00 </span></p>
	<p>
	Graphic control extension blocks are used frequently to
	specify transparency settings and control animations. They are completely optional.
	Since transparency and animations are bit complicated, I will hold off on many of
	the details of this block until a later section
	(see <a href="http://matthewflickinger.com/lab/whatsinagif/animation_and_transparency.asp">Transparency and Animation</a>).
	In the interest of this page being complete, I will at least tell you what
	the bytes represent.
	</p>
	<p>
	The first byte is the <strong>extension introducer</strong>. All <em>extension</em>
	blocks begin with <span>21</span>. Next is the <strong>graphic
	control label</strong>, <span>F9</span>, which is the value that
	says this is a graphic control extension. Third up is the total <strong>block
	size</strong> in bytes. Next is a packed field. Bits 1-3 are reserved for future
	use. Bits 4-6 indicate <strong>disposal method</strong>. The penult bit is
	the <strong>user input flag</strong> and the last is the <strong>transparent color
	flag</strong>. The <strong>delay time</strong> value follows in the next two bytes
	stored in the unsigned format. After that we have the <strong>transparent color
	index</strong> byte. Finally we have the <strong>block terminator</strong> which
	is always <span>00</span>.
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/graphic_control_ext.gif" alt="GIF graphic control extension block layout"></p>




	<h2><a name="image_descriptor_block">Image Descriptor</a></h2>
	<p>From Sample File: <span> 2C </span><span> 00 </span><span> 00 </span><span> 00 </span><span> 00 </span><span> 0A </span><span> 00 </span><span> 0A </span><span> 00 </span><span> 00 </span></p>
	<p>
	A single GIF file may contain multiple images (useful when creating animated
	images). Each image begins with an image descriptor block. This block is exactly
	10 bytes long.
	</p>
	<p>
	The first byte is the <strong>image separator</strong>. Every image
	descriptor begins with the value <span>2C</span>. The next 8 bytes
	represent the location and size of the following image. An image in
	the stream may not necessarily take up the entire canvas size defined by
	the logical screen descriptor. Therefore, the image descriptor specifies
	the <strong>image left position</strong> and <strong>image top position</strong> of
	where the image should begin on the canvas. Next it specifies the
	<strong>image width</strong> and <strong>image height</strong>. Each of these
	values is in the two-byte, unsigned format. Our sample image indicates that
	the image starts at (0,0) and is 10 pixels wide by 10 pixels tall. (This image
	does take up the whole canvas size.)
	</p>
	<p>
	The last byte is another packed field. In our sample file this byte is 0 so
	all of the sub-values will be zero. The first (most significant) bit in
	the byte is the <strong>local color table flag</strong>. Setting this flag
	to 1 allows you to specify that the image data that follows uses a different
	color table than the global color table. (More information on the local
	color table follows.) The second bit is the <strong>interlace flag</strong>.
	</p>
	<p><img src="http://matthewflickinger.com/lab/whatsinagif/images/image_descriptor_block.gif" alt="GIF image descriptor block layout"></p>





	<h2><a name="local_color_table_block">Local Color Table</a></h2>
	<p>
	The local color table looks identical to the global color table. The local
	color table would always immediately follow an image descriptor but will only
	be there if the local color table flag is set to 1. It is effective only for the
	block of image data that immediately follows it. If no local color table
	is specified, the global color table is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp">http://matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp</a></em></p>]]>
            </description>
            <link>http://matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685160</guid>
            <pubDate>Tue, 30 Jun 2020 00:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord vs. AirSend: Roles and Permissions Explained]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23684930">thread link</a>) | @markshepard
<br/>
June 29, 2020 | https://www.airsend.io/blog/index.php/2020/06/21/discord-vs-airsend-roles-and-permissions-explained/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/06/21/discord-vs-airsend-roles-and-permissions-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1831">
	

	




	<div>
		
<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-7-1024x771.png" alt="" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-7-1024x771.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-7-300x226.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-7-768x578.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-7.png 1229w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<p>We are back with another blog post on <a href="https://discord.com/">Discord</a> vs. <a href="https://www.airsend.io/discover">AirSend</a>: Roles and Permissions Explained. We recently wrote about Discord vs. AirSend Design Edition, which you can read about by clicking <a href="https://www.airsend.io/blog/index.php/2020/05/18/discord-vs-airsend-design-edition/">here</a>. In this blog post, we will be discussing the user roles from each platform. User roles help make managing communities easier. The question then remains, what type of roles are needed to manage a community efficiently?&nbsp;</p>



<p>To answer this question we analyze how user roles are implemented in AirSend and Discord.</p>



<h2>AirSend’s Roles</h2>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-13.png" alt="" width="448" height="562" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-13.png 597w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-13-239x300.png 239w" sizes="(max-width: 448px) 100vw, 448px"></figure>



<p>Typically when creating a community,&nbsp; user roles are established to help run the channel. Airsend takes the approach of fixed user roles to manage a community. Fixed user roles allow simplicity and have the same meaning across channels and servers. We created various roles with this in mind. Beginning with the first role: viewer.&nbsp;</p>



<h3>Viewer</h3>



<p>Viewers have the permissions to view the community and download files. These are for first-time visitors who haven’t joined the community and want to browse before joining. The next role on our list is a collaborator.&nbsp;</p>



<h3>Collaborator</h3>



<p>Collaborators have access to posting messages and uploading files. However, collaborators cannot edit the wiki (the about section).&nbsp;</p>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-14.png" alt="" width="355" height="650" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-14.png 473w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-14-164x300.png 164w" sizes="(max-width: 355px) 100vw, 355px"></figure>



<p>Collaborators are the basis of your community. Ideally, collaborators are what ensure conversation happens. For a little more responsibility, there is the role of a full collaborator.&nbsp;</p>



<h3>Full Collaborators</h3>



<p>A full collaborator can do everything a collaborator does. The only difference is that a full collaborator can edit the wiki. By allowing a full collaborator to help monitor the channel and edit the wiki, managers and admins can focus more on community building and outreach. After the full collaborator role is the manager and admin.&nbsp;</p>



<h3>Manager/Admin</h3>



<p>Like the full collaborator roles, managers and admins also can edit the wiki, upload files, and post messages. However, the difference between the full collaborator and the manager/admin is that managers and admins can manage other users.&nbsp;</p>



<div><p>Now, don’t get confused. Managers and Admins are two different roles, but they mostly carry the same functionality. The difference between a manager and an admin is that the <strong>manager</strong> <strong>can add and remove other users from the channel. Admins have access to adding and removing users and changing the roles of other members. </strong>Having these two roles ensures that your community stays clean from self-promoters, rule breakers, inappropriate messages, etc.</p><p>In general, we believe that having fixed roles helps communities prosper. Fixed roles allow simplicity. For Discord, the central idea behind their roles is customization. Through their customization, complexities arise. </p></div>



<h2>Discord Roles</h2>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15.png" alt="" width="679" height="343" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15.png 1914w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15-300x152.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15-1024x518.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15-768x388.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-15-1536x777.png 1536w" sizes="(max-width: 679px) 100vw, 679px"><figcaption>Member list seen on right panel</figcaption></figure>



<p>Discord takes the approach of dynamic user roles. It is good for communities that want customized user roles. The problem with having dynamic roles and customization is that it adds complexity. </p>



<p>For example, Server A has specified permissions for its members. Members have permission to: </p>



<ul><li>Post in channel</li><li>Share files</li><li><strong>Invite other members to the community</strong></li></ul>



<p>Now, let’s say we want to join another community, Server B. Because there is full-fledged customization, creators of the server can check off specified permissions for their roles that may be different from other servers. In Server B, members can have permission to:</p>



<ul><li>Post in Channel</li><li>Share files</li><li><strong>Add reactions</strong></li></ul>



<p>But they <strong>cannot</strong> invite other members to the community like Server A can. Members cannot view what permissions they have. Now, imagine this with higher roles. </p>



<p>Let’s say there are Moderators in Server A  and Server B. Server A has specific permissions to kick members out. In Server B, those same moderators from Server A do not have the permission to kick members out. This is not apparent to the moderators, thus confusion and complexities are formed. </p>



<h3>How to add a role to Discord</h3>



<p>To add roles, you will need to go to your servers’ settings at the top of the screen.</p>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-16.png" alt="" width="226" height="485" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-16.png 301w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Capture-16-140x300.png 140w" sizes="(max-width: 226px) 100vw, 226px"></figure>



<p>Next, click on the roles button. This button will let you see and add all of your roles.&nbsp;</p>



<figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/06/Untitled.png" alt="" width="649" height="394" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/06/Untitled.png 1027w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Untitled-300x182.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Untitled-1024x621.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/06/Untitled-768x466.png 768w" sizes="(max-width: 649px) 100vw, 649px"><figcaption><em>The red circle is the button you click to get to the current image. The blue circle is where you add roles to your community.</em> The green circle is where you will see all the functions a role member can have. </figcaption></figure>



<p>Click on the plus icon. Doing so will allow you to create a new role.&nbsp;</p>



<p>Below the role color section, are all the functionalities a role member can have. Essentially, each role has specific access but carries a customized name. These names can range from Admins, Community Manager, Mods, Helpers, Servers Guide, etc. And these names come with specific functions.&nbsp;</p>



<p>Additionally, specific access-only channels can be made for specific Discord roles as well. Servers can have a moderator-only chat, an admin-only chat, etc. Access-only channels are excellent use for privacy, carrying specific role meetings, organization, and maintaining order. Furthermore, bots are an excellent tool for role management. Servers can have bots for anything, but when it comes to managing servers, some bots take care of</p>



<ul><li>warning users that violate the rules</li><li>suspending users</li><li>putting users in a time out</li><li>automatically adding new users to the member roles and more.&nbsp;</li></ul>



<p>In sum, Discord’s roles are good for communities who are looking for customized roles and bots. Bots ensure:</p>



<ul><li>The server runs smoothly with automated welcome messages to new members</li><li>Assign new users to the member role</li><li>Alert the community that the server creator put out new content</li><li>Ban or suspend members who do not follow the community rules, and much more.&nbsp;</li></ul>



<h2>Summation</h2>



<p>Both AirSend and Discord are great community platforms. Discord offers quite a bit for community building through dynamic user roles, bots, channel organizations, and more.  The downside to this approach is the complexities and confusion members will have with each community they join.  The common question will be asked, “What permissions do I have with this server that is different from another server?”</p>



<p>On the other hand, AirSend takes the approach of fixed user roles. Fixed user roles are easy to understand and avoid confusion. Fixed user roles have the same meaning across channels and makes it easy for the user onboarding. In the end, it all depends on what the user is comfortable with- having a simplistic role setting or a customized but complex setting. </p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/06/21/discord-vs-airsend-roles-and-permissions-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23684930</guid>
            <pubDate>Mon, 29 Jun 2020 23:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cancel Culture in 1974]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23684815">thread link</a>) | @riverlong
<br/>
June 29, 2020 | https://jayriverlong.github.io/2020/06/28/cancel-culture.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/06/28/cancel-culture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>In 2008, Facebook was the hot new thing, and social media had <em>just</em> started rising. One of my high-school classes was about trying to understand that shift better.<sup id="fnref:1"><a href="#fn:1">1</a></sup> We read about past problems with mass media, and thought about how they might manifest in new media. To that end, we read a German novel called <em>The Lost Honor of Katharina Blum</em> by Heinrich Böll. In recent years, with social media-induced cancel culture becoming a hot issue, that novel has been on my mind frequently.</p> <p>A quick summary:</p> <blockquote> <div><p>Katharina is a 27-year old housekeeper. She’s frugal, earnest, and hard-working – a model citizen. One evening, she meets a man named Ludwig at a party, and sleeps with him. Next day, the police knocks on her door: he’s a known communist terrorist, and suspected for robbery and murder. Katharina is taken in for questioning, and released. </p><p>  This episode is observed by a reporter for the tabloid NEWS. The reporter inquires with neighbors, stretches any statements, and publishes a piece declaring Katharina to be a gold-digging communist criminal, the depraved bride of a murderous terrorist. Katharina is swiftly excluded from society and receives death threats. Under the onslaught of harassment, her hospitalized mother dies from stress. </p><p>  In the meantime, Ludwig is found to have committed no robbery or murder, but by then, the campaign against Katharina has become its own force. One sympathizer argues that the actual facts are good, and that other newspapers are reporting the facts, but – as Katharina points out through her sobs – it doesn’t matter, because <em>everyone</em> reads the NEWS. </p><p>  For no fault of her own, Katharina’s life is in shambles: her career is over, and her friends distance themselves for self-preservation. In desperation, she tries to meet with the reporter who has been hounding her. The reporter tries to extort her for sex, whereupon she shoots him. Remorseless, she turns herself in to the police for justice.</p></div> </blockquote> <p>The 70s were a heyday for tabloid newspapers. Printing any scandal, no matter how thin the facts, the tabloids were like the clickbait outrage mills of today. Their reach was wide and deep: the NEWS of the novel was a depiction in all but name of the leading tabloid in Germany, BILD, which printed six million copies every day, purchased by one in ten Germans. To be depicted unfavorably in BILD was social execution, and – as a paper dealing primarily in outrage and gossip – BILD executed plenty. Capricious and careless, their reporters had the power to ruin lives effectively at random.</p> <p>That sounds a lot like getting cancelled: for effectively no fault of your own, the outrage mob, whether online or offline, can <a href="https://en.wikipedia.org/wiki/Newspeak#Vocabulary">unperson</a> you. While today’s media are global and more plentiful, it’s not clear that there’s been a net change in impact. Getting smeared by your local tabloid was just as radioactive as is getting smeared on Reddit, a career-ender all the same. Further, even though traditional, local media has a much smaller reach than global media, its local reach is what really matters to the person affected. Local media has a much deeper local reach, and a much greater capacity to “investigate” and report locally. While modern media operate at much greater scale, it also carries a dilutive effect. Net-net, people have always been getting disgraced, and I don’t think it’s much likelier now than it was in the past.</p> <p>In my view, cancel culture is an example of a pattern I like to call <em>there’s nothing new under the sun</em>: there are always scary changes between generations, but usually they are just new manifestations of issues as old as time. For example, many people today complain that the young spend less time on necessary schoolwork than the previous generation. But even Socrates said the exact same thing. In many domains, perceptions of progress have been pessimistic since antiquity – perhaps because memories of times past are always rose-colored by nostalgia – but reality works out.</p> <p>If today’s severity and randomness of cancel culture is not actually new, is it different in any important respects? Today’s cancel culture is one of escalating purity tests: born out of the more punitive contingents on the left, it’s not enough to not be a racist or a sexist, but one must take stronger, more condemnatory views, which function as powerful in-group signals.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Cancel culture is thus somewhat performative, and strongly ideologically motivated – some people are likening it to the witch hunts for communists in the 50s under Joseph McCarthy. The left is in a curious, self-damaging position, where lots of center-leaning moderates – who are genuine progressives – are not meeting the ideological standards of those further left, which functions to their exclusion, thereby weakening the left overall.</p> <p>Is that bad? Yes, probably. While I view the aims of social justice as largely correct and well-intentioned, cancel culture seems to produce unnecessary collateral damage that hurts its own cause. It both fragments the left – infighting over purity is a devastating waste in a time beset by serious problems requiring collective action – and it is unfair to the people it ultimately affects. But is any of this new? I don’t think it is. It’s the same old patterns and motivations under new cover. Thus, like everyone else, we acknowledge cancel culture as a trend, but unlike everyone else, we see it as a trend that is very <em>old</em> rather than <em>new</em>. In turn, the question we ask about is radically different: while everyone else asks “how has technology given rise to cancel culture”, we know that it hasn’t, and instead ask “how can we use technology to mitigate cancel culture?”</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/06/28/cancel-culture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23684815</guid>
            <pubDate>Mon, 29 Jun 2020 23:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Learned Watching All 44 AppSec Cali 2019 Talks (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23684134">thread link</a>) | @mooreds
<br/>
June 29, 2020 | https://tldrsec.com/blog/appsec-cali-2019/ | <a href="https://web.archive.org/web/*/https://tldrsec.com/blog/appsec-cali-2019/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        
<p>OWASP AppSec California is one of my favorite security conferences: the talks
are great, attendees are friendly, and it takes place right next to the beach in
Santa Monica. Not too shabby 😎</p>

<p>One problem I always have, though, is that there are some great talks on the
schedule that I end up missing.</p>

<p>So this year I decided to go back and watch <strong>all 44 talks</strong> from last
year’s con, AppSec Cali 2019, and <strong>write a detailed summary</strong> of their key points.</p>

<p>If I had realized how much time and effort this was going to be at the beginning
I probably wouldn’t have done it, but by the time I realized that this endeavor
would take hundreds of hours, I was already too deep into it to quit 😅</p>

<p><strong>Attending AppSec Cali 2020</strong><br>
If you’re attending AppSec Cali this year come say hi! I’m <a href="https://appseccalifornia2020.sched.com/event/XLvs/an-opinionated-guide-to-scaling-your-companys-security?iframe=no&amp;w=100%&amp;sidebar=yes&amp;bg=no">giving a talk</a> and would be happy to chat about all things security.</p>

<h2 id="whats-in-this-post">What’s in this Post</h2>

<p>This post is structured as follows:</p>
<ul>
  <li><a href="#stats">Stats</a>: Some high level stats and trends- which talk categories were most popular? Which companies gave the most talks?</li>
  <li><a href="#overview-of-talks">Overview of Talks</a>: A quick rundown of every talk in a few lines each, so you can quickly skim them and find the talks that are most directly relevant to you.</li>
  <li><em>Summaries</em>: detailed summaries of each talk, grouped by category.</li>
</ul>

<p>Note the navigation bar on the left hand side, which will enable you to quickly
jump to any talk.</p>

<div><p><strong>Feedback Welcomed!</strong><br>
If you’re one of the speakers and I’ve left out something important, please let me know! I’m happy to update this. Also, feel free to let me know about any spelling or grammar errors or broken links.</p><p>
If you find DevSecOps / scaling really interesting, I’d love to chat about what
you do at your company / any tips and tricks you’ve found useful. Hit me up on
Twitter, LinkedIn, or email.</p></div>

<h2 id="stats">Stats</h2>

<p>In total, AppSec Cali 2019 had <strong>44 talks</strong> that were a combined <strong>~31.5</strong> hours of video.</p>

<p>Here are the talks grouped by the category that I believed was most fitting:</p>

<figure>
  <img src="https://tldrsec.com/assets/images/talks/all_appsec_cali_2019/talks_by_category.png" alt="Stats: Talks by Category">
  
    <figcaption>
      Not too much of a surprise here: you’d expect defense (blue team) talks to be emphasized at an OWASP conference, as was web security.

    </figcaption>
  
</figure>

<p>We can also see that containers and Kubernetes were fairly popular topics
(3).</p>

<p>Some things I found surprising were how many talks there were on threat modeling
(4) and account security (4), and how there were only 3 primarily cloud
security-focused talks. Perhaps the biggest surprise was that there were 3 talks on securing
third-party code, with Slack discussing the steps they took to evaluate <a href="https://tldrsec.com/#slack-app-security-securing-your-workspaces-from-a-bot-uprising">Slack
bots</a> and
<a href="#securing-third-party-applications-at-scale">Salesforce</a> discussing the review
process on their AppExchange.</p>

<figure>
  <img src="https://tldrsec.com/assets/images/talks/all_appsec_cali_2019/talks_by_company.png" alt="Stats: Talks by Company">
  
    <figcaption>
      

    </figcaption>
  
</figure>

<p>Here we see Netflix crushing it: they had presence on a panel, gave one of the
keynotes, and collectively had 3 <em>other</em> talks. And of these 5 talks, 3 made my
top 10 list. Not too shabby 👍</p>

<p>In second place, we see Segment coming in strong!</p>

<p>Netflix, Segment, and Dropbox were on at least one panel, while the rest of the
companies listed had separate talks.</p>



<!-- Begin MailChimp Signup Form -->




<!--End mc_embed_signup-->


<h2 id="overview-of-talks">Overview of Talks</h2>

<p>For your ease of navigation, this section groups all of the talks by category, gives a high
description of what they’re about, and provides a link to jump right to their
summary.</p>

<p>Note: the talks in each category are listed in alphabetical order, not in my
order of preference.</p>

<h3 id="my-top-10-talks">My Top 10 Talks</h3>
<p>This section lists my top 10 favorite talks from AppSec Cali 2019 ❤️</p>

<p>It was
incredibly difficult narrowing it down to just 10, as there were so many good
talks. All of these talks were selected because they are information-dense with
detailed, actionable insights. I guarantee you’ll learn something useful from
them.</p>

<p><a href="#a-pragmatic-approach-for-internal-security-partnerships">A​ Pragmatic Approach for Internal Security Partnerships</a><br>
Scott Behrens, Senior AppSec Engineer, Netflix<a href="https://twitter.com/HelloArbit"><i></i>
</a>
<a href="https://linkedin.com/in/scott-behrens-6bb8611"><i></i>
</a>
<br>
Esha Kanekar, Senior Security Technical Program Manager, Netflix<a href="https://linkedin.com/in/eshakanekar"><i></i>
</a>
<br>
How the Netflix AppSec team scales their security efforts via secure defaults,
tooling, automation, and long term relationships with engineering teams.</p>

<p><a href="#a-seat-at-the-table">A Seat at the Table</a><br>
<em>Adam Shostack, President, Shostack &amp; Associates</em><a href="https://twitter.com/adamshostack"><i></i>
</a>
<a href="https://linkedin.com/in/shostack"><i></i>
</a>
<br>
By having a “seat at the table” during the early phases of
software development, the security team can more effectively influence its design. Adam
describes how security can earn its seat at the table by using the right tools,
adapting to what’s needed by the current project, and the soft skills that will
increase your likelihood of success.</p>

<p><a href="#cyber-insurance-a-primer-for-infosec">Cyber Insurance: A Primer for Infosec</a><br>
<em>Nicole Becher, Director of Information Security &amp; Risk Management, S&amp;P Global Platts</em><a href="https://twitter.com/thedeadrobots"><i></i>
</a>
<a href="https://linkedin.com/in/nicolebecher"><i></i>
</a>
<br>
A lovely jaunt through the history of the insurance industry,
the insurance industry today (terminology you need to know, types of players),
where cyber insurance is today and where it’s headed, example cyber insurance
policies and what you need to look out for.</p>

<p><a href="#insecure-development---why-some-product-teams-are-great-and-others-arent">(in)Secure Development - Why some product teams are great and others aren’t…</a><br>
<em>Koen Hendrix, InfoSec Dev Manager, Riot Games</em><a href="https://twitter.com/koen_hendrix"><i></i>
</a>
<a href="https://linkedin.com/in/hendrixk"><i></i>
</a>
<br>
Koen describes analyzing the security maturity of Riot product
teams, measuring that maturity’s impact quantitatively using bug bounty data,
and discusses 1 lightweight prompt that can be added into the sprint planning
process to prime developers about security.</p>

<p><a href="#lessons-learned-from-the-devsecops-trenches">Lessons Learned from the DevSecOps Trenches</a><br></p>
<p><em>Clint Gibler, Research Director, NCC Group</em><a href="https://twitter.com/clintgibler"><i></i>
</a>
<a href="https://linkedin.com/in/clintgibler"><i></i>
</a>
<br></p>
<p><em>Dev Akhawe, Director of Security Engineering, Dropbox</em><a href="https://twitter.com/frgx"><i></i>
</a>
<a href="https://linkedin.com/in/devdattaakhawe"><i></i>
</a>
<br></p>
<p><em>Doug DePerry, Director of Product Security, Datadog</em><a href="https://twitter.com/dugdep"><i></i>
</a>
<a href="https://linkedin.com/in/douglas-deperry-959aab8"><i></i>
</a>
<br></p>
<p><em>Divya Dwarakanath, Security Engineering Manager, Snap</em><a href="https://twitter.com/Divya_Dw"><i></i>
</a>
<a href="https://linkedin.com/in/divyadw"><i></i>
</a>
<br></p>
<p><em>John Heasman, Deputy CISO, DocuSign</em><a href="https://linkedin.com/in/john-heasman"><i></i>
</a>
<br></p>
<p><em>Astha Singhal, AppSec Engineering Manager, Netflix</em><a href="https://twitter.com/astha_singhal"><i></i>
</a>
<a href="https://linkedin.com/in/singhalastha"><i></i>
</a>
<br></p>
<div><p>Learn how Netflix, Dropbox, Datadog, Snap, and DocuSign think
about security. A masterclass in DevSecOps and modern AppSec best practices.</p></div>

<p><a href="#netflixs-layered-approach-to-reducing-risk-of-credential-compromise">Netflix’s Layered Approach to Reducing Risk of Credential Compromise</a><br>
<em>Will Bengston, Senior Security Engineer, Netflix</em><a href="https://twitter.com/__muscles"><i></i>
</a>
<a href="https://linkedin.com/in/william-bengtson-26837953"><i></i>
</a>
<br>
<em>Travis McPeak, Senior Security Engineer, Netflix</em><a href="https://twitter.com/travismcpeak"><i></i>
</a>
<a href="https://linkedin.com/in/travismcpeak"><i></i>
</a>
<br>
An overview of efforts Netflix has undertaken to scale their
cloud security, including segmenting their environment, removing static keys,
auto-least privilege of AWS permissions, extensive tooling for dev UX (e.g.
using AWS credentials), anomaly detection, preventing AWS creds from being used
off-instance, and some future plans.</p>

<p><a href="#starting-strength-for-appsec-what-mark-rippetoe-can-teach-you-about-building-appsec-muscles">Starting Strength for AppSec: What Mark Rippetoe can Teach You About Building AppSec Muscles</a><br>
<em>Fredrick “Flee” Lee, Head Of Information Security, Square</em><a href="https://twitter.com/fredrickl"><i></i>
</a>
<a href="https://linkedin.com/in/fredrickdlee"><i></i>
</a>
<br>
Excellent, practical and actionable guidance on building an AppSec program, from
the fundamentals (code reviews, secure code training, threat modeling), to
prioritizing your efforts, the appropriate use of automation, and common
pitfalls to avoid.</p>

<p><a href="#the-call-is-coming-from-inside-the-house-lessons-in-securing-internal-apps">The Call is Coming From Inside the House: Lessons in Securing Internal Apps</a><br>
<em>Hongyi Hu, Product Security Lead, Dropbox</em><a href="https://twitter.com/hongyihu"><i></i>
</a>
<a href="https://linkedin.com/in/hongyi-hu-6b473746"><i></i>
</a>
<br>
A masterclass in the thought process behind and technical
details of building scalable defenses; in this case, a proxy to protect
heterogenous internal web applications.</p>

<p><a href="#startup-security-starting-a-security-program-at-a-startup">Startup Security: Starting a Security Program at a Startup</a><br>
<em>Evan Johnson, Senior Security Engineer, Cloudflare</em><a href="https://twitter.com/ejcx_"><i></i>
</a>
<a href="https://linkedin.com/in/ejcxx"><i></i>
</a>
<br>
What it’s like being the first security hire at a startup, how
to be successful (relationships, security culture, compromise and continuous
improvement), what should inform your priorities, where to focus to make an
immediate impact, and time sinks to avoid.</p>

<p><a href="#working-with-developers-for-fun-and-progress">Working with Developers for Fun and Progress</a><br>
<em>Leif Dreizler, Senior AppSec Engineer, Segment</em><a href="https://twitter.com/leifdreizler"><i></i>
</a>
<a href="https://linkedin.com/in/leifdreizler"><i></i>
</a>
<br>
Resources that have influenced Segment’s security program
(talks, books, and quotes), and practical, real-world tested advice on how to:
build a security team and program, do effective security training, successfully
implement a security vendor, and the value of temporarily embedding a security
engineer in a dev team.</p>

<h3 id="account-security">Account Security</h3>

<p><a href="#automated-account-takeover-the-rise-of-single-request-attacks">Automated Account Takeover: The Rise of Single Request Attacks</a><br>
<em>Kevin Gosschalk, Founder and CEO, Arkose Labs</em><a href="https://twitter.com/kgosschalk"><i></i>
</a>
<a href="https://linkedin.com/in/kgosschalk"><i></i>
</a>
<br>
Defines “single request attacks,” describes challenges of preventing account takeovers, gives examples of the types of systems bots attack in the wild and how, and recommendations for preventing account takeovers.</p>

<p><a href="#browser-fingerprints-for-a-more-secure-web">Browser fingerprints for a more secure web</a><br>
<em>Julien Sobrier, Lead Security Product Owner, Salesforce</em><a href="https://linkedin.com/in/juliensobrier"><i></i>
</a>
<br>
<em>Ping Yan, Research Scientist, Salesforce</em><a href="https://linkedin.com/in/pingpingyan"><i></i>
</a>
<br>
How Salesforce uses browser fingerprinting to protect users
from having their accounts compromised. Their goal is to detect sessions being
stolen, including by malware running on the same device as the victim (and thus
has the same IP address).</p>

<p><a href="#contact-center-authentication">Contact Center Authentication</a><br>
<em>Kelley Robinson, Dev Advocate, Account Security, Twilio</em><a href="https://twitter.com/kelleyrobinson"><i></i>
</a>
<a href="https://linkedin.com/in/kelleyrobinson"><i></i>
</a>
<br>
Kelley describes her experiences calling in to 30 different company’s call
centers: what info they requested to authenticate her, what they did well, what
they did poorly, and recommendations for designing more secure call center
authentication protocols.</p>

<p><a href="#leveraging-users-engagement-to-improve-account-security">Leveraging Users’ Engagement to Improve Account Security</a><br>
<em>Amine Kamel, Head of Security, Pinterest</em><a href="https://twitter.com/dontlivetwice"><i></i>
</a>
<a href="https://linkedin.com/in/aminekamel"><i></i>
</a>
<br>
Pinterest describes how it protects users who have had their
credentials leaked in third-party breaches using a combination of programmatic
and user-driven actions.</p>

<h3 id="blue-team">Blue Team</h3>

<p><a href="#ciso-panel-baking-security-into-the-sdlc">CISO Panel: Baking Security Into the SDLC</a><br>
<em>Richard Greenberg, Global Board of Directors, OWASP</em><a href="https://twitter.com/RAGreenberg"><i></i>
</a>
<a href="https://linkedin.com/in/richardagreenberg"><i></i>
</a>
<br>
<em>Coleen Coolidge, Head of Security, Segment</em><a href="https://twitter.com/coleencoolidge"><i></i>
</a>
<a href="https://linkedin.com/in/ecoleenc"><i></i>
</a>
<br>
<em>Martin Mazor, Senior VP and CISO, Entertainment Partners</em><a href="https://linkedin.com/in/martin-mazor-8560b94"><i></i>
</a>
<br>
<em>Bruce Phillips, SVP &amp; CISO, Williston Financial</em><a href="https://linkedin.com/in/brucephillips"><i></i>
</a>
<br>
<em>Shyama Rose, Chief Information Security Officer, Avant</em><a href="https://linkedin.com/in/shyama"><i></i>
</a>
<br>
Five CISOs share their perspectives on baking security into
the SDLC, DevSecOps, security testing (DAST/SAST/bug bounty/pen testing),
security training and more.</p>

<p><a href="#it-depends">It depends…</a><br>
<em>Kristen Pascale, Principal Techn. Program Manager, Dell EMC</em><a href="https://linkedin.com/in/kristen-pascale-26b00631"><i></i>
</a>
<br>
<em>Tania Ward, Consultant Program Manager, Dell</em><a href="https://linkedin.com/in/taniacorrieward"><i></i>
</a>
<br>
What a PSIRT team is, Dell’s PSIRT team’s workflow, common
chalenges, and how PSIRT teams can work earlier in the SDLC with development
teams to develop more secure applications.</p>

<p><a href="#on-the-frontlines-securing-a-major-cryptocurrency-exchange">On the Frontlines: Securing a Major Cryptocurrency Exchange</a><br>
<em>Neil Smithline, Security Architect, Circle</em><a href="https://twitter.com/appsecneil"><i></i>
</a>
<a href="https://linkedin.com/in/neilsmithline"><i></i>
</a>
<br>
Neil provides an overview of cryptocurrencies and cryptocurrency exchanges, the
attacks exchanges face at the application layer, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tldrsec.com/blog/appsec-cali-2019/">https://tldrsec.com/blog/appsec-cali-2019/</a></em></p>]]>
            </description>
            <link>https://tldrsec.com/blog/appsec-cali-2019/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23684134</guid>
            <pubDate>Mon, 29 Jun 2020 22:29:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global circus company Cirque du Soleil files for bankruptcy protection]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23684026">thread link</a>) | @finphil
<br/>
June 29, 2020 | https://www.cbc.ca/news/canada/montreal/cirque-du-soleil-bankruptcy-1.5631354 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/montreal/cirque-du-soleil-bankruptcy-1.5631354">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Cirque du Soleil, the circus company that was once one of Quebec's most successful businesses, filed for bankruptcy protection on Monday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5439533.1593458405!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/the-land-of-fantasy.jpg"></p></div><figcaption>Cirque du Soleil, like much of the entertainment industry, has had to lay off workers and halt productions due to COVID-19.<!-- --> <!-- -->(Submitted by Cirque du Soleil)</figcaption></figure><p><span><p>Cirque du Soleil, one of Quebec's most internationally recognizable brands, filed for bankruptcy protection on Monday following months of meagre revenues because of the COVID-19 pandemic.&nbsp;</p>  <p>A group of existing investors, with backing from the Quebec government's investment wing, Investissement Québec, has&nbsp;already tabled a bid to take over the company, inject $300 million US and provide financial support for 3,500 laid-off workers.</p>  <p>The involvement of Investissement Québec, in the form of&nbsp;$200 million US in debt financing, requires the investors to commit to keeping the company's headquarters in Montreal.&nbsp;</p>  <p>In statement made early Monday afternoon, Cirque du Soleil said Quebec Superior Court will hear its application for bankruptcy protection tomorrow. If granted, the company said it will also seek bankruptcy protection in the United States.</p>  <p>The circus company was forced to cancel dozens of productions around the world since March, when public health guidelines began barring live entertainment events.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/168250715.jpg 300w,https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/168250715.jpg 460w,https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/168250715.jpg 620w,https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/168250715.jpg 780w,https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/168250715.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5187115.1561327542!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/168250715.jpg"></p></div><figcaption>Investissement Québec's involvement requires the investors to commit to keeping the company's headquarters in Montreal.  <!-- --> <!-- -->(Isaac Brekken/Getty Images)</figcaption></figure></span></p>  <p>"For the past 36 years, Cirque du Soleil has been a highly successful and profitable organization," president and CEO Daniel Lamarre said in the statement released Monday.</p>  <p>"However, with zero revenues since the forced closure of all of our shows due to COVID-19, management had to act decisively to protect the company's future."</p>  <h2>Heavily indebted before pandemic</h2>  <p>Even before the pandemic struck, Cirque du Soleil was heavily indebted following a string of major acquisitions aimed at diversifying its business operations beyond the lavish live spectacles it's known for around the world.</p>  <p>It was estimated the company owed creditors around $900 million US, meaning they had effective control of the company.</p>  <p>The current Quebec government, headed by a nationalist centre-right party,&nbsp;came to power on a pledge to do more to prevent foreign takeovers of the province's marquee brands.</p>  <p>In May, as the Cirque's financial position looked increasingly shaky,&nbsp;Economy Minister Pierre Fitzgibbon expressed concerns about the possibility of creditors seeking liquidity.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/covid-que-20200428.jpg 300w,https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/covid-que-20200428.jpg 460w,https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/covid-que-20200428.jpg 620w,https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-que-20200428.jpg 780w,https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-que-20200428.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5548053.1588098748!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/covid-que-20200428.jpg"></p></div><figcaption>In May, as the Cirque's financial position looked increasingly shaky, Economy Minister Pierre Fitzgibbon expressed concerns about the possibility of creditors seeking liquidity.<!-- --> <!-- -->(Jacques Boissinot/The Canadian Press)</figcaption></figure></span></p>  <p>He said&nbsp;Investissement Québec would back a recapitalization plan by the circus company's three major shareholders:&nbsp;Texas-based TPG Capital, Chinese firm Fosun and Quebec pension fund manager&nbsp;the Caisse de depot et placement.</p>  <p>That money, he said at the time, was incumbent on the investors meeting a number of political requirements, in addition to the pledge to keep the head office in Montreal.</p>  <p>Under the terms of the deal, the investors are also committing to maintaining key company leadership positions in Quebec and rehiring as many Quebec-based workers as possible. These are on top of financial commitments that include:</p>  <ul>   <li>$15&nbsp;million US in financial help for laid-off workers.</li>   <li>$5 million US to settle outstanding contracts (especially Quebec-based contractors).</li>   <li>Refunds for shows cancelled because of the pandemic.</li>  </ul>  <p>The bid by the existing investors is what's known as a stalking horse agreement, meaning it sets a minimum price and sale conditions for the company.&nbsp;</p>  <p>Other interested parties have&nbsp;45 days to table competing offers, a process that will be supervised by the court.</p>    <p>Lamarre&nbsp;told Radio-Canada five other groups have expressed interest&nbsp;in the company.&nbsp;They too would benefit from&nbsp;Investissement Québec's financing, if they agree to its conditions, Fitzgibbon said.&nbsp;</p>  <p>The list of other potential investors is likely to include the company's co-founder and former CEO, Guy Laliberté, who sold his controlling stake back in 2015 for a reported $1.5 billion US.&nbsp;</p>  <p>Laliberté&nbsp;has publicly stated his interest&nbsp;in once again having an ownership share.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/montreal/cirque-du-soleil-bankruptcy-1.5631354</link>
            <guid isPermaLink="false">hacker-news-small-sites-23684026</guid>
            <pubDate>Mon, 29 Jun 2020 22:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Master the Front-End Development]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23683572">thread link</a>) | @bajcmartinez
<br/>
June 29, 2020 | https://livecodestream.dev/post/2020-06-29-how-to-master-the-front-end-development/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-06-29-how-to-master-the-front-end-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    
    <h2>Learn how to focus your skills to become a master at front-end development</h2>
    
    
    <section>
        <figure>
            
            <img alt="Feature Image" src="https://livecodestream.dev/post/2020-06-29-how-to-master-the-front-end-development/featured_huab90dae8822c16d81bf6ceed19fd7ca3_155709_680x0_resize_q75_box.jpg">
        </figure>
        <p>A few years back doing front-end work, especially on the web, was rather simple compared to the back-end where all the app logic used to reside. Nowadays, that changed. Front-end development has evolved thanks to powerful frameworks and libraries,  supported by the evolution of the browsers and their respective APIs. In a modern web application, the front-end plays a crucial role, where not only front-end developers are dealing with the presentation, but also with logic, and algorithms implementations.</p>
<p>With all these new challenges into the picture, how do we, as front-end developers, can stay up to date with the latest, and learn more in deep the languages and frameworks that we use to build amazing app experiences?</p>
<p>Let me walk you through 5  things you should be doing to master the front-end development</p>
<hr>
<h2 id="learn-a-bit-about-back-end">Learn a bit about back-end</h2>
<p>With the increased focus on user experience and usability, the importance of front-end has been increasing, and problems that traditionally were handled in the back-end are now being shifted to the front-end. It is also true that while front-end is reducing the complexity of the back-end in some areas, back-end is also evolving and specializing, introducing a new set of challenges for back-end developers.</p>
<p>As some of these problems are shifted to the front-end, having experience in how back-end deal with them, can be of great help when implementing solutions in our code. It is also true, that traditionally it was more important for the back-end to have more concepts from algorithms and data structures, while front-end was all about CSS+HTML, but now having that kind of knowledge is crucial for any front-end developer. So learn back-end, to be a better front-end developer.</p>
<p>But that’s not the only reason why learning back-end development is important, maybe even more important is to do it for the team. Teams can achieve greater collaboration when both sides sort of “speak the same language” and understand each other points of view. And you can even tackle some work from back-end to help out.</p>
<p>Front-end or Back-end, we are all developers, and we can help each other out as part of the same team.</p>
<hr>
<h2 id="practice-practice-and-practice-some-more">Practice, practice and practice some more</h2>
<p>To master any skill you need practice. Period. And this is particularly true for development. It is indeed true that we can acquire knowledge through books or posts like this, but if you want to master the art of development, you will have to code a lot.</p>
<p>Is it all practice good? Maybe not, practice new things, do coding challenges, sign up to hacker rank and smash it! Work on open source projects, re-write all projects, see what you can do better, etc.</p>
<p>Practice also by reading other people’s code, check out that amazing open source project you like so much, see how they do things, play with their code, it can introduce you to new points of view, patterns, designs, etc.</p>
<hr>
<h2 id="let-others-review-your-code">Let others review your code</h2>
<p>If you truly want to master front-end development (or development in general) you need to find people who will review your code. When we write code for ourselves, or when no one questions our code, sure, we can get better as we learn and practice more, but it will be a slow process. By having someone with more experience, or maybe just a different point of view review your code, you can learn from their experience as well.</p>
<p>But for this strategy to be effective, you have to trust whoever is doing the review, and you need to be able to admit when you are wrong. Sometimes it is hard as development can be very opinionated and there could be more than one solution to a problem, but if we want to learn from others, we need to accept when our solution wasn’t the best.
I’m not saying you should accept any change mentioned by your reviewer, but start a dialog with him/her, expose each other’s points, and then decide if you incorporate the feedback or not. Both sides, the reviewer and the reviewed can learn from this interaction.</p>
<hr>
<h2 id="learn-about-design">Learn about design</h2>
<p>Design, user experience, and technology work together to deliver great products. Designers are amazing at building the best screens, and interactions, and animations, in their own tools. And it’s your work as a front-end developer to transform that into products. Having a good understanding of design can help you bring the two worlds together, and increase the collaboration between designers and developers.</p>
<p>The product will be as good as its design and how its implemented, thus the communication between designers and front-end developers is crucial so that the code can reproduce the designer’s vision for the app.</p>
<p>And if in your team you have no designers, maybe you should consider getting one, but if that’s out of the question, knowing basic design concepts can help you build much better apps for your users.</p>
<hr>
<h2 id="hang-out-with-awesome-people">Hang out with awesome people</h2>
<p>We are social creatures after all, and learning or practicing a new skill can be easier and more fun when you have somebody who’s awesome at something, and who can point you at the right things and in the right direction.</p>
<p>Do your networking, include other developers in your circle, but also designers, bloggers, architects, product owners, etc… There’s something you can learn from everybody.</p>
<p>And finally, you can be a model for others as well. For me, it was crucial when I started to always have someone who was there to support me. From people I hang out with, to strangers in amazing communities, to bloggers and YouTubers who produced content for people like me. It’s amazing how many people are willing to help. And for me… writing for this blog, and all I do is my way to continue building the community that made me the developer I’m today.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>Mastering the front-end is not about knowing all the functions in a framework or language, nor about writing perfect code, but learning to listen to others, know how to look for solutions to the problems, and have a good amount of experience. Rely on your team, and other fellow developers to help you out.</p>
<p>Note to be made, I’m still mastering my front-end and back-end skills, it’s a never-ending game, but I enjoy it every day!</p>
<p>Is there any area I discussed that you like the most? Or perhaps you see another point I could have listed? Please let me know in the comments. I’d love to hear about it.</p>
<p>Thanks for reading!</p>

    </section>
    <section>
        
        
        
    </section>

    <section>
    <h2>Join the Free Newsletter</h2>
    <p>A free, weekly e-mail with the best new articles.</p>

    
    
    <p>
        We won't send you spam. Unsubscribe at any time.
    </p>
</section>


    
</article></div>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-06-29-how-to-master-the-front-end-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23683572</guid>
            <pubDate>Mon, 29 Jun 2020 21:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Icicle Tree with static JSON data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23683264">thread link</a>) | @lowmemcpu
<br/>
June 29, 2020 | https://philogb.github.io/jit/static/v20/Jit/Examples/Icicle/example1.html# | <a href="https://web.archive.org/web/*/https://philogb.github.io/jit/static/v20/Jit/Examples/Icicle/example1.html#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <h4>
    Icicle Tree with static JSON data
  </h4>
  
            <p>Some static JSON tree data is fed to this visualization.</p>
            <p>
              <b>Left click</b> to set a node as root for the visualization.
            </p>
            <p>
              <b>Right click</b> to set the parent node as root for the visualization.
            </p>
            

  <div>
    <p><label for="s-orientation">Orientation: </label>
    </p><p><label for="i-levels-to-show">Max levels: </label>
    
    </p>
  </div>
</div></div>]]>
            </description>
            <link>https://philogb.github.io/jit/static/v20/Jit/Examples/Icicle/example1.html#</link>
            <guid isPermaLink="false">hacker-news-small-sites-23683264</guid>
            <pubDate>Mon, 29 Jun 2020 21:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross-cluster traffic mirroring with istio, Cilium 1.8 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23682724">thread link</a>) | @paniq1991
<br/>
June 29, 2020 | https://nativecloud.dev/cnn-2020-26/ | <a href="https://web.archive.org/web/*/https://nativecloud.dev/cnn-2020-26/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
            <article>
    <ul><li><a href="https://events.linuxfoundation.org/open-source-summit-north-america/"><strong>Open Source Summit</strong></a><br>OSS starts this week and goes from the 29th of June till the 02nd of July. For $50 you can attend the #ossummit online and <a href="https://events.linuxfoundation.org/open-source-summit-north-america/program/schedule/">explore the virtual schedule</a>.</li><li><a href="https://www.cncf.io/blog/2020/06/25/kubecon-cloudnativecon-eu-virtual-new-schedule-is-live/"><strong>KubeCon + CloudNativeCon EU Virtual – NEW schedule is live!</strong></a><br>Sadly we can't meet in person in Amsterdam, however, the new schedule is out!</li><li><a href="https://blog.nativecloud.dev/p/1da0a887-e933-4367-863c-47c962d0f074/Cloud%20Native%20Computing%20Foundation%20Announces%20Harbor%20Graduation"><strong>Announcing Harbor graduation</strong></a><br>As the 11th graduating CNCF project Harbor proves its stability, community support and reach.</li><li><a href="https://github.com/cncf/toc/pull/382"><strong>SPIFFE/SPIRE moves on to Incubating</strong></a><br>The<strong> </strong>Secure Production Identity Framework For Everyone and its implementation SPIRE leaving the Sandbox to join the Incubating class of CNCF.</li></ul><h2 id="processes-guides-articles">Processes / Guides / Articles</h2><ul><li><a href="https://thenewstack.io/persistent-volumes-separating-compute-and-storage/"><strong>Persistent Volumes: Separating Compute and Storage</strong></a><br>"The logical separation of compute and storage has become increasingly formalized in Kubernetes via subsystems like the Container Storage Interface (CSI), and in this article, I [Brian Pawlowski] argue that the physical separation of compute and storage leads to improved economics and more efficient operations; and so it is a powerful strategy to employ with Kubernetes."</li><li><a href="https://cloud.google.com/blog/products/containers-kubernetes/google-kubernetes-engine-clusters-can-have-up-to-15000-nodes"><strong>Bayer Crop Science seeds the future with 15.000-node GKE clusters</strong></a><br>The documented limit of nodes in a Kubernetes cluster is at 5.000. This post explains what was necessary to make GKE operate with three times the amount. Including an answer to the question: what do you do with a 15.000 node cluster?</li><li><a href="https://tech.trivago.com/2020/06/10/cross-cluster-traffic-mirroring-with-istio/"><strong>Cross-Cluster Traffic Mirroring with Istio</strong></a><br>Mirroring production traffic to a staging cluster: possible with Istio and done at Trivago.</li><li><a href="https://www.magalix.com/blog/how-to-enforce-kubernetes-network-security-policies-using-opa"><strong>How To Enforce Kubernetes Network Security Policies Using OPA</strong></a><br>In a nutshell, a network policy in Kubernetes enables you to enforce restrictions on pod intercommunication. However, a policy is only as good as its implementation.</li><li><a href="https://itnext.io/implementing-ldap-authentication-for-kubernetes-732178ec2155"><strong>Implementing LDAP authentication for Kubernetes</strong></a><br>"This article shows how to implement <a href="https://connect2id.com/products/ldapauth/auth-explained" rel="noopener">LDAP authentication</a> for Kubernetes with the <a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#webhook-token-authentication" rel="noopener">Webhook Token</a> authentication plugin. The article includes a tutorial taking you from zero to the complete system with step-by-step instructions. No previous knowledge about Kubernetes authentication is required."</li><li><a href="https://medium.com/flant-com/configmaps-in-kubernetes-f9f6d0081dcb"><strong>ConfigMaps in Kubernetes: how they work and what you should remember</strong></a><br>Kubernetes ConfigMaps marked the beginning of a new era of configuring applications. The article is focusing on different approaches of application configuration.</li><li><a href="https://itnext.io/using-aws-nlb-manually-targeting-an-eks-service-exposing-udp-traffic-17053ecd8f52"><strong>Using AWS NLB manually targeting an EKS Service exposing UDP traffic</strong></a><br>With EKS 1.16 it is currently not easily possible to create a Kubernetes service of type Network Loadbalancer for routing UDP traffic. This article analyzes the issue and proposes a workaround.</li></ul><ul><li><strong><a href="https://cilium.io/blog/2020/06/22/cilium-18">Cilium 1.8</a></strong><br>Comes with a huge load of new features and improvements: eXpress Data Path (XDP) Load Balancing support, Cluster-wide Flow API, performance optimizations across the board, better policy visibility and control and so on.</li><li><a href="https://github.com/thanos-io/thanos/releases/tag/v0.13.0"><strong>Thanos 0.13</strong></a><br>A whole bunch of fixes improve the general stability of Thanos. Also the querier performance has increased.</li><li><strong><a href="https://www.prnewswire.com/news-releases/d2iq-unveils-kudo-for-kubeflow-to-accelerate-enterprise-grade-machine-learning-on-kubernetes-301083592.html">D2IQ: KUDO for Kubeflow</a></strong><br>Brings you a secure, scalable and portable deployment of Kubeflow. The predefined configurations and deployments cover best practices and prevent, like happened in many cases the last months, the exposure of dashboard to the internet.</li></ul><p><em>Photo by <a href="https://unsplash.com/@jonasjacobsson">Jonas Jacobsson</a> on <a href="https://unsplash.com/photos/2xaF4TbjXT0">Unsplash</a></em></p>
</article>





    </div></div>]]>
            </description>
            <link>https://nativecloud.dev/cnn-2020-26/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23682724</guid>
            <pubDate>Mon, 29 Jun 2020 20:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lots of FizzBuzz (yes, that old thing)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681999">thread link</a>) | @redshirt
<br/>
June 29, 2020 | https://dearlovesoftware.com/category/code/ | <a href="https://web.archive.org/web/*/https://dearlovesoftware.com/category/code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

				

<!-- .page-header -->


	
	<div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
										<div id="blog-entries">

							
							
								
								
	<article id="post-115">

		<div>

			

<!-- .blog-entry-header -->







<p>
            In previous posts (here and here), I have used concurrency features to do FizzBuzz in C#. In this post, I have created a FizzBuzz example in C++ that uses the…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/05/fizzbuzz-c-raftlib-example/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz C++ Raftlib example</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-110">

		<div>

			

<!-- .blog-entry-header -->







<p>
            In a previous post, I created a concurrent implementation of FizzBuzz using Tasks and BlockingCollections. In this post, I use FizzBuzz to with the Dataflow (Task Parallel Library) to demonstrate…        </p><!-- .blog-entry-summary -->



<p><a href="https://dearlovesoftware.com/2020/05/fizzbuzz-using-the-dataflow-task-parallel-library/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz example using the Dataflow (Task Parallel Library)</span>
</p><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-104">

		<div>

			

<!-- .blog-entry-header -->







<p>
            Previously, I used tasks to enable multithreaded processing. In this post, I create a pipelined FizzBuzz example with multiple threads. Each stage in the pipeline is a separate Task which…        </p><!-- .blog-entry-summary -->



<p><a href="https://dearlovesoftware.com/2020/05/fizzbuzz-example-with-multithreaded-pipelined-processing/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz example with multithreaded pipelined processing</span>
</p><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-80">

		<div>

			

<!-- .blog-entry-header -->







<p>
            Similar to the C++ example, Tasks can be used to create a multi-threaded version of FizzBuzz: using System; using System.Threading.Tasks; namespace FizzBuzz { class Program { static void Main(string[] args)…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/03/fizzbuzz-with-tasks-in-c/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz with Tasks in C#</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-75">

		<div>

			

<!-- .blog-entry-header -->







<p>
            Using multi-threading for FizzBuzz is totally over the top but, since C++11, it is really easy to use multiple threads using futures: #include &lt;future&gt; #include &lt;iomanip&gt; #include &lt;iostream&gt; #include &lt;string&gt;…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/02/multi-threaded-fizzbuzz-in-c/" title="Continue Reading">Continue Reading</a>
    <span>Multi-threaded FizzBuzz in C++</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-71">

		<div>

			

<!-- .blog-entry-header -->







<p>
            For completeness, here is my C# version of FizzBuzz: using System; namespace FizzBuzz { class Program { static void Main(string[] args) { for (int x = 1; x &lt;= 20;…        </p><!-- .blog-entry-summary -->



<!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-65">

		<div>

			

<!-- .blog-entry-header -->







<p>
            Last time, I showed my solution to FizzBuzz in Python. Here is my C++ version: #include &lt;iomanip&gt; #include &lt;iostream&gt; int main(void) { for(int x = 1; x &lt;= 20; ++x)…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/02/fizzbuzz-in-cpp/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz in C++</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-33">

		<div>

			

<!-- .blog-entry-header -->







<p>
            Naming is hard. I do not have a good name for a concept but I found this useful. In my code, I have something like: public class Hardware { IRobotArm…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/02/naming-is-difficult/" title="Continue Reading">Continue Reading</a>
    <span>Naming is difficult</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
								
								
	<article id="post-47">

		<div>

			

<!-- .blog-entry-header -->







<p>
            FizzBuzz is a simple problem, often used in interviews to filter out non-programmers. The program prints out the word "Fizz" for every number that is divisible by 3, "Buzz" for…        </p><!-- .blog-entry-summary -->



<div>
    <p><a href="https://dearlovesoftware.com/2020/01/fizzbuzz-in-python/" title="Continue Reading">Continue Reading</a>
    <span>FizzBuzz in Python</span>
</p></div><!-- .blog-entry-readmore -->


		</div><!-- .blog-entry-inner -->

	</article><!-- #post-## -->


								
							
						</div><!-- #blog-entries -->

						
				
				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		

<!-- #right-sidebar -->


	</div><!-- #content-wrap -->

	

        </div></div>]]>
            </description>
            <link>https://dearlovesoftware.com/category/code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681999</guid>
            <pubDate>Mon, 29 Jun 2020 20:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declining eyesight could improve by looking at deep red light]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681788">thread link</a>) | @finphil
<br/>
June 29, 2020 | https://nuadox.com/post/622287875646668801/red-light-therapy-eyesight | <a href="https://web.archive.org/web/*/https://nuadox.com/post/622287875646668801/red-light-therapy-eyesight">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="622287875646668801">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/622287875646668801/red-light-therapy-eyesight"><h2>Declining eyesight could improve by looking at deep red light</h2></a>
                                <figure data-orig-width="5184" data-orig-height="3456"><img src="https://66.media.tumblr.com/9fefa475a050be6c8547f4032266d350/beb4db66c671a561-63/s1280x1920/83bf1e82ee1325e673c2ac44c8ac5cccec41835f.jpg" alt="image" data-orig-width="5184" data-orig-height="3456" width="1280" height="853"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.ucl.ac.uk%2F&amp;t=YjQzYTRhYWQzOWE3ZGE1NDdjNjZlZjI3MDM3ODE0OGU1NzU1OWYzMixxWUFGMmRTdA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F622287875646668801%2Fred-light-therapy-eyesight&amp;m=0">University College London</a> -</b></p><p>Staring at a deep red light for three minutes a day can significantly improve declining eyesight, finds a new University College London (UCL)-led study, the first of its kind in humans.</p><p>Scientists believe the discovery, published in the&nbsp;<i><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1093%2Fgerona%2Fglaa155&amp;t=MzM4MDE5NzZiOTE1NjA3YTRjNjA4MjQyMTg1Yjc2YmJjOWUyOWI1NSxxWUFGMmRTdA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F622287875646668801%2Fred-light-therapy-eyesight&amp;m=0">The Journals of Gerontology</a></i>, could signal the dawn of new affordable home-based eye therapies, helping the millions of people globally with naturally declining vision.</p><p>In the UK there are currently around 12 million people aged over 65: in 50 years this will increase to around 20 million and all will have some degree of visual decline because of retinal ageing.</p><p>Lead author, Professor Glen Jeffery (UCL Institute of Ophthalmology) said: “As you age your visual system declines significantly, particularly once over 40.</p><p>"Your retinal sensitivity and your colour vision are both gradually undermined, and with an ageing population, this is an increasingly important issue.</p><p>"To try to stem or reverse this decline, we sought to reboot the retina’s ageing cells with short bursts of longwave light.”</p><p>In humans around 40 years-old, cells in the eye’s retina begin to age, and the pace of this ageing is caused, in part, when the cell’s mitochondria, whose role is to produce energy (known as ATP) and boost cell function, also start to decline.</p><p>Mitochondrial density is greatest in the retina’s photoreceptor cells, which have high energy demands. As a result, the retina ages faster than other organs, with a 70% ATP reduction over life, causing a significant decline in photoreceptor function as they lack the energy to perform their normal role.</p><p>Researchers built on their previous findings in mice, bumblebees and fruit flies, which all found significant improvements in the function of the retina’s photoreceptors when their eyes were exposed to 670 nanometre (long wavelength) deep red light.</p><p>“Mitochondria have specific light absorbance characteristics influencing their performance: longer wavelengths spanning 650 to 1000nm are absorbed and improve mitochondrial performance to increase energy production,” said Professor Jeffery.</p><p>The retina’s photoreceptor population is formed of cones, which mediate colour vision and rods, which provide peripheral vision and adapt vision in low/dim light.</p><p>For the study, 24 people (12 male, 12 female), aged between 28 and 72, who had no ocular disease, were recruited. All participants’ eyes were tested for the sensitivity of their rods and cones at the start of the study. Rod sensitivity was measured in dark adapted eyes (with pupils dilated) by asking participants to detect dim light signals in the dark, and cone function was tested by subjects identifying coloured letters that had very low contrast and appeared increasingly blurred, a process called colour contrast.</p><figure data-orig-width="1440" data-orig-height="1080"><img src="https://66.media.tumblr.com/dfa0f5629384ca65ba39a6989cc09429/beb4db66c671a561-60/s1280x1920/51debf645da77092b6af1dd5c931a63ffe6d3947.jpg" alt="image" data-orig-width="1440" data-orig-height="1080" width="1280" height="960"></figure><p><i>Image:&nbsp;This is an example of hand held LED torch used in study. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F235928.php&amp;t=MGNjZTFjMmRhMjA0YzFjOTNhYjQ3NjVkMzU3Yjc5NTQzZGJkZDBhZixxWUFGMmRTdA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F622287875646668801%2Fred-light-therapy-eyesight&amp;m=0">UCL</a>.</i></p><p>All participants were then given a small LED torch to take home and were asked to look into* its deep red 670nm light beam for three minutes a day for two weeks. They were then re-tested for their rod and cone sensitivity</p><h2><b>Results</b></h2><p>Researchers found the 670nm light had no impact in younger individuals, but in those around 40 years and over, significant improvements were obtained.</p><p>Cone colour contrast sensitivity (the ability to detect colours) improved by up to 20% in some people aged around 40 and over. Improvements were more significant in the blue part of the colour spectrum that is more vulnerable in ageing.</p><p>Rod sensitivity (the ability to see in low light) also improved significantly in those aged around 40 and over, though less than colour contrast.</p><p>Professor Jeffery said: “Our study shows that it is possible to significantly improve vision that has declined in aged individuals using simple brief exposures to light wavelengths that recharge the energy system that has declined in the retina cells, rather like re-charging a battery.</p><p>"The technology is simple and very safe, using a deep red light of a specific wavelength, that is absorbed by mitochondria in the retina that supply energy for cellular function.</p><p>"Our devices cost about £12 to make, so the technology is highly accessible to members of the public.”</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fpub_releases%2F2020-06%2Fucl-dei062620.php&amp;t=ZGQwZWM2NTU0MjI5NmFmYmIyMmU5M2U2NTgyNjcwNjRkYTRjZThjNixxWUFGMmRTdA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F622287875646668801%2Fred-light-therapy-eyesight&amp;m=0">University College London</a></b></p><p><b>Full Study:&nbsp;</b>“Optically improved mitochondrial function redeems aged human visual decline”,&nbsp;<i>The Journals of Gerontology</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1093%2Fgerona%2Fglaa155&amp;t=MzM4MDE5NzZiOTE1NjA3YTRjNjA4MjQyMTg1Yjc2YmJjOWUyOWI1NSxxWUFGMmRTdA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F622287875646668801%2Fred-light-therapy-eyesight&amp;m=0">https://doi.org/10.1093/gerona/glaa155</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/190287508747/blue-light-mbti">Blue light could help heal mild traumatic brain injury (mTBI)</a></p><p><a href="https://nuadox.com/post/186713391337/future-of-sight">Stepping into the future of sight</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/red-light-therapy">red light therapy</a>
                                    
                                        <a href="https://nuadox.com/tagged/vision">vision</a>
                                    
                                        <a href="https://nuadox.com/tagged/eye-sight">eye sight</a>
                                    
                                        <a href="https://nuadox.com/tagged/gerontology">gerontology</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/622287875646668801/red-light-therapy-eyesight</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681788</guid>
            <pubDate>Mon, 29 Jun 2020 19:49:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5 Best Books on Algorithms for Mastering the Code Interview]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23681762">thread link</a>) | @MirandaLemons
<br/>
June 29, 2020 | https://booksoncode.com/articles/best-books-on-algorithms | <a href="https://web.archive.org/web/*/https://booksoncode.com/articles/best-books-on-algorithms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5e012d584401aa74ad984455" id="sections">
  
    <section data-section-id="5e012d584401aa74ad984457" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;dark&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5ef0eef80919c101f8264a89"><div><div><div data-aspect-ratio="63.02003081664098" data-block-type="5" id="block-yui_3_17_2_1_1593459477621_11804"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e0129c5956b7a5624566864/1593459523494-C9TTA8GYYIR5QTJDZIM8/ke17ZwdGBToddI8pDm48kHw2LVDpuXvIbSYsytov_Cd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0oGwQPSn8VqSSM4mc7rOnohm8iZzjZZiV57hS9hqyB8Ody3g5Rn_hJsCwbmGBjKdjg/best-books-on-algorithms" data-image="https://images.squarespace-cdn.com/content/v1/5e0129c5956b7a5624566864/1593459523494-C9TTA8GYYIR5QTJDZIM8/ke17ZwdGBToddI8pDm48kHw2LVDpuXvIbSYsytov_Cd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0oGwQPSn8VqSSM4mc7rOnohm8iZzjZZiV57hS9hqyB8Ody3g5Rn_hJsCwbmGBjKdjg/best-books-on-algorithms" data-image-dimensions="2500x3204" data-image-focal-point="0.4240219465648855,0.875" alt="best-books-on-algorithms" data-load="false" data-image-id="5efa4343b1e1f242994a0220" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-c00ea63a02869c0a6ec3"><div><p>To master the code interview for top companies like Amazon, Microsoft, Google, and Apple, you can select one of the best books on algorithms to be your companion — to teach you how to build, test, and optimize algorithms based on common algorithms. These skills are essential to passing a traditional whiteboard coding interview or simply to becoming a better programmer.</p><p>The best books on algorithms gives programmers a common language to talk and think about code. The best books on algorithms also teach us the most important algorithms to plug-and-play or understand algorithm design. With algorithms, we can measure what is effective or less-so. We can have metrics to optimize our code.</p><p>Why do code interviews test your knowledge of algorithms? It shows that you are a good programmer and a good thinker. As programmers, we are ultimately problem-solvers, and common algorithms give us the tools to design solutions to our coding problems.</p><p>As self-taught programmers or as programmers studying for a coding interview, books can help us reach our goals</p><h2>Overview</h2><p>What makes the best books on algorithms? Good algorithms books do several, but perhaps not all, of the following:</p><ul data-rte-list="default"><li><p>They teach the most important algorithms.</p></li><li><p>They teach with precision and clarity.</p></li><li><p>They have good problems and questions for you to work on your own.</p></li><li><p>They allow you to not just think of algorithms as templates, but allow you to think of and design your own solution based on metrics such as clean code and code efficiency.</p></li><li><p>Friendly toward self-taught programmers. Not too heavy in mathematics. Does not have a high barrier to entry.</p></li><li><p>[Bonus] They have an engaging, conversational style and introduce novelty to keep you interested.</p></li></ul><p>If you know me and <a href="https://booksoncode.com/"><em>Books on Code</em></a>, I am a big advocate of bringing <em>joy</em> into the learning experience. With a heavy topic like algorithms, the texts themselves tend to be heavy and serious as well, easily clocking in at over 1000 pages of dense text. While texts that are dense and academic are in this list for their valuable content and breadth, I also include some titles to remind you that learning can also be fun.</p><h2>Best Books on Algorithms</h2><p>The following books are the best books on algorithms according to the criteria set out in the <em>Overview</em> section.</p><h3>Book 1: <em>Algorithms </em>by Robert Sedgewick</h3></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1592848121753_4728"><p><a target="_blank" href="https://www.amazon.com/gp/product/032157351X/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=032157351X&amp;linkCode=as2&amp;tag=booksoncode-20&amp;linkId=ef103bc0f144bb443e11a6741f70ea04"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=032157351X&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=booksoncode-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=booksoncode-20&amp;l=am2&amp;o=1&amp;a=032157351X" width="1" height="1" alt=""></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1592849025353_14448"><div><p><a href="https://amzn.to/3eoKCs9" target="_blank"><em>Algorithms</em></a> is a book that delivers on exactly what you want from an <em>algorithms</em> book: clean, simple, straightforward explanations of the most important algorithms. With examples based in Java, the book is well-organized and thorough, reaching nearly 1000 pages.</p><p>For more information about what this book is about, look to the introduction of <em>Algorithms</em>:</p><blockquote><p>This book is intended to survey the most important computer algorithms to use today, and to teach fundamental techniques to the growing number of people in need of knowing them. […] Before developing our fundamental approach to studying algorithms, we develop data types for stacks, queues, and other low-level abstractions that we use throughout the book. Then we survey fundamental algorithms for sorting, searching, graphs, and strings. The last chapter is an overview placing the rest of the material in the book inn a larger context.</p></blockquote><p>I like this. Why? It puts you in the weeds <em>first</em> and saves the theory for later. This is how people learn best. Once we know how to use something, we become hungry for the ‘why,’ but if we get the ‘why’ first, it hardly sticks.</p><p>The book is divided into six of the following chapters:</p><ul data-rte-list="default"><li><p><strong>Chapter 1 </strong>covers fundamentals such as primitive data types, loops, arrays, objects, APIs, linked lists, Tilde notation, and memory usage.</p></li><li><p><strong>Chapter 2</strong> covers sorting algorithms such as mergesort and quicksort.</p></li><li><p><strong>Chapter 3</strong> covers searching algorithms and data types such as binary search and hash tables.</p></li><li><p><strong>Chapter 4</strong> covers graph algorithms such as shortest-path algorithms and depth-first search.</p></li><li><p><strong>Chapter 5</strong> covers algorithms related to streams such as string sort, tries, substring search, data compression, and regular expressions.</p></li><li><p><strong>Chapter 6</strong> covers topics around context-reliant algorithms such as B-trees, reductions, suffix arrays, and event-driven simulation.</p></li></ul><p>As you may gather from the chapter outline, the book covers “classic methods that have been taught since the 1960s and new methods that have been invented in recent years.” The goal is to reach the widest audience possible with the most important algorithms. To reach that goal, the information is well organized and explained.</p><p>If you are a self-taught programmer, I recommend this book if you are serious about supplementing a traditional computer science course curriculum.</p><h3>Book 2: <em>Introduction to Algorithms </em>(The MIT Press)</h3></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1592848121753_7890"><p><a target="_blank" href="https://www.amazon.com/gp/product/0262033844/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0262033844&amp;linkCode=as2&amp;tag=booksoncode-20&amp;linkId=56f51123fd5297f06c27992df65f4f67"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0262033844&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=booksoncode-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=booksoncode-20&amp;l=am2&amp;o=1&amp;a=0262033844" width="1" height="1" alt=""></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1592849485204_5238"><div><p><a href="https://amzn.to/2YoYdtW" target="_blank"><em>Introduction to Algorithms</em></a> is not light for an ‘introduction’. It begins with basics, like defining what ‘pseudocode’ is, but it gets deep. It is not just an algorithm cookbook; it teaches “techniques of algorithm design and analysis so that you can develop algorithms on your own.” This skill is valuable for writing great code — and of course, it’s great for the coding interview. </p><p>The book asks good questions and truly sets the intention to help you have a good and correct philosophy about algorithms. </p><p>The book is divided into only seven of the following chapters:</p><ul data-rte-list="default"><li><p>Chapter 1 covers foundational concepts such as the role of algorithms and some basic algorithms and thoughts of algorithm development like insertion sort, notations, the divide-and-conquer method and randomized algorithms.</p></li><li><p>Chapter 2 covers sorting and order statistics such a Quicksort.</p></li><li><p>Chapter 3 covers data structures such as hash tables and trees.</p></li><li><p>Chapter 4 covers advanced design and analysis techniques such as dynamic programming and greedy algorithms.</p></li><li><p>Chapter 5 covers advanced data structures such as B-trees, Fibonacci heaps, and disjoint sets.</p></li><li><p>Chapter 6 covers graph algorithms such as Dijkstra’s algorithm.</p></li><li><p>Chapter 7 covers “selected topics” such as multithreaded algorithms, matrix operations, and linear programming.</p></li></ul><p>As you can see from the book’s outline, an ‘introduction’ does not quite cover what this book offers. It goes into ‘advanced’ topics by chapter 4 and it <em>just keeps going</em>. As someone who feels comfortable and confident in the ‘data structures &amp; algorithms’ taught in the classroom, this book helped me see how I can vastly improve as a programmer. This book is recommended not just for beginners but for anyone who is serious about improving in this dimension of programming.</p><h3>Book 3: <em>The Algorithm Design Manual</em></h3></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1593459344972_11917"><p><a target="_blank" href="https://www.amazon.com/gp/product/1848000693/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1848000693&amp;linkCode=as2&amp;tag=booksoncode-20&amp;linkId=dc0c8be3237901ef61cd98e19b06d37d"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1848000693&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=booksoncode-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=booksoncode-20&amp;l=am2&amp;o=1&amp;a=1848000693" width="1" height="1" alt=""></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1593459344972_13997"><div><p><a href="https://amzn.to/2BRBBJu" target="_blank"><em>The Algorithms Design Manual</em></a><em> </em>is branded as a reader-friendly guide, which is great for self-taught programmers. The book is designed to take the mystery out of designing algorithms so that you can analyze their efficiency.</p><p>This book is about algorithm <em>design</em>, as the title says. For example, the introduction of the book states that there are three desirable properties for a good algorithm: <em>correct</em>, <em>efficient</em>, and <em>easy to implement</em>. Memorize this for a programming interview right now.</p><p>A book that focuses on design specifically is extremely valuable for a coding interview, since you can’t just memorize important algorithms, but you need to think and reason around them.</p><p>This book is great for its conversational writing style. Other books that focus on algorithms design use mathematical formulas to explain this concept. This book is friendly to self-taught programmers.</p><p>What content is in this book? Quite a lot. The book is around 700 pages and 19 chapters. The first part of the book, titled “Practical Algorithm Design, covers the following:</p><ul data-rte-list="default"><li><p>Introduction to algorithm design, which covers how to reason about correctness and modeling the problem.</p></li><li><p>Algorithm analysis</p></li><li><p>Data structures</p></li><li><p>Sorting and searching</p></li><li><p>Graph traversal</p></li><li><p>Weighted graph algorithms</p></li><li><p>Combinatorial search and Heuristic methods</p></li><li><p>Dynamic programming</p></li><li><p>Intractable problems and approximation algorithms</p></li></ul><p>The rest of the book focuses on a series of problems, grouped into types such as linear equations and combinatorial problems such as sorting and searching.</p><p>This book is practical, with lots of problems. Even though the book is more reader friendly than other algorithm design books, the text is still heavy. Be prepared to work.</p><h3>Book 4: <em>Grokking Algorithms</em></h3></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1592848121753_8864"><p><a target="_blank" href="https://www.amazon.com/gp/product/1617292230/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1617292230&amp;linkCode=as2&amp;tag=booksoncode-20&amp;linkId=d398c85d5dc304028b0657b35d5730da"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1617292230&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=booksoncode-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=booksoncode-20&amp;l=am2&amp;o=1&amp;a=1617292230" width="1" height="1" alt=""></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1592849025353_15491"><div><p>With charming graphics, <a href="https://amzn.to/2YWMxgZ" target="_blank"><em>Grokking Algorithms</em></a> illustrates common algorithms and data structures that we might learn in a data structures &amp; algorithms class. Some of the concepts covered include Big-O notation, hash tables, trees, quicksort, and recursion — all extremely valuable concepts for writing efficient code and for code interviews.</p><p>I highly <a href="https://booksoncode.com/articles/data-structures-algorithms">recommend <em>Grokking Algorithms</em> for beginner programmers</a> because the guide is brain friendly. What do I mean by brain friendly? Learning is easier for us when books use techniques to engage us: conversational style, direct questions, breakpoints for reflection, and novelty. </p><p>Some of the topics covered in <em>Grokking Algorithms</em>:</p><ul data-rte-list="default"><li><p>Binary search </p></li><li><p>Big O notation </p></li><li><p>Arrays and linked lists </p></li><li><p>Selection sort </p></li><li><p>Recursion </p></li><li><p>Stacks </p></li><li><p>Quicksort </p></li><li><p>Hash tables </p></li><li><p>Breadth-first search</p></li></ul><p>This book does a fantastic job of explaining complex concepts to complete understanding using few pages but <em>extremely clear</em> visual explanations. If you have ever struggled with recursion, just five pages in this book will the concept real quick.</p><h3>Book 5: <em>Cracking the Code Interview</em></h3></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1592848121753_9804"><p><a target="_blank" href="https://www.amazon.com/gp/product/0984782850/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0984782850&amp;linkCode=as2&amp;tag=booksoncode-20&amp;linkId=6bd3a8b0c24bfd09827ae79603a7cba3"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0984782850&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=booksoncode-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=booksoncode-20&amp;l=am2&amp;o=1&amp;a=0984782850" width="1" height="1" alt=""></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1592849025353_8328"><div><p><a href="https://amzn.to/3do5LkR" target="_blank"><em>Cracking the Code Interview</em> </a>sets out to do exactly what the title says: crack the code interview. Traditional whiteboard interviews rely on designing algorithms to solve a problem. This book presents 189 algorithm problems and a breakdown of their solutions. The book is massive and intimidating, but it is also smart and well-crafted, considering it was written by someone who conducted interviews at major companies.</p><p>Each programming problem opens …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://booksoncode.com/articles/best-books-on-algorithms">https://booksoncode.com/articles/best-books-on-algorithms</a></em></p>]]>
            </description>
            <link>https://booksoncode.com/articles/best-books-on-algorithms</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681762</guid>
            <pubDate>Mon, 29 Jun 2020 19:46:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use nearly anything as an input device with fingertip-based gesture sensor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681595">thread link</a>) | @homarp
<br/>
June 29, 2020 | https://www.hackster.io/news/a-very-touchy-subject-fda3e3788d21 | <a href="https://web.archive.org/web/*/https://www.hackster.io/news/a-very-touchy-subject-fda3e3788d21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p>Tapping and swiping are a very intuitive means for interaction with electronic devices, and as such, have become a very popular mechanism for capturing user input in recent years. Extending touch sensing beyond the confines of a touchscreen means additional instrumentation is required. Whether electrical, optical, or acoustic sensing is employed, it calls for additional setup effort and cost.</p><p><span>A group based at The University of Auckland, New Zealand have developed a method they call </span><a href="https://dl.acm.org/doi/pdf/10.1145/3397309" rel="nofollow">ActualTouch</a><span> that enables touch gestures to be collected from a large number of unmodified, everyday surfaces. The device itself is a tiny inertial measurement unit (IMU) sensor attached to a fingertip. Specifically, they redesigned a SparkFun MPU9250 IMU breakout board to achieve a smaller (7mm x 9mm) form factor.</span></p><p>The basic theory of operation resulted from the observation that a finger held in the air exhibits microvibrations, and these microvibrations stop when the finger rests on a surface. Similarly, when a finger is moving through the air, it has a tendency to jitter around a bit. When moving across a surface, the finger is more restricted and movement is noticeably smoother. The researchers initially eyeballed some IMU data to confirm that these phenomena were detectable and that the signals appeared to be distinct from one another.</p><p>With signals that appeared to be distinct, it seemed like a task that would be well suited to classification via machine learning. The authors collected data from the IMU sensor with an Arduino Due while performing various gestures. This data was used to train a customized variant of a LeNet convolutional neural network model.  Training took place on a dedicated workstation with two NVIDIA GTX 1080 Ti GPUs.  Testing of the model yielded a very respectable true-positive and true-negative gesture detection rate of 98.6% and 98.5%, respectively.</p><p>Perhaps some of the more obvious applications for ActualTouch are in creating virtual touch surfaces for mixed reality and using any surface in the area to act as a mouse for your laptop. The authors also demonstrated some additional very interesting uses — in one case, they used the back of their smartphone to control a cursor with the hand they were holding it with. The other very interesting use demonstrated was an extension of a smartwatch input surface to the hand and arm around it.  Check out the video below to see ActualTouch in action.</p><figure><figcaption>Demonstration</figcaption></figure></div></section></div>]]>
            </description>
            <link>https://www.hackster.io/news/a-very-touchy-subject-fda3e3788d21</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681595</guid>
            <pubDate>Mon, 29 Jun 2020 19:35:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid vaccine approved for military use in China]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681512">thread link</a>) | @Animats
<br/>
June 29, 2020 | https://www.cbc.ca/news/health/covid-vaccine-approved-military-use-china-1.5630947 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/covid-vaccine-approved-military-use-china-1.5630947">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>China's military has received the green light to use a COVID-19 vaccine candidate developed by its research unit and CanSino Biologics after clinical trials proved it was safe and showed some efficacy, the company said on Monday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5630955.1593432922!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/china-vaccines.JPG"></p></div><figcaption>A researcher works in a lab of Chinese vaccine maker CanSino Biologics. The company's  COVID-19 vaccine candidate has been given the green light for use in members of the Chinese military.  <!-- --> <!-- -->(Stringer/Reuters)</figcaption></figure><p><span><p>China's military has received the green light to use a COVID-19 vaccine candidate developed by its research unit and CanSino Biologics after clinical trials proved it was safe and showed some efficacy, the company said on Monday.</p>  <p>The Ad5-nCoV is one of China's eight vaccine candidates approved for human trials at home and abroad for the respiratory disease caused by the new coronavirus. The shot also won approval for human testing in Canada.</p>  <p>China's Central Military Commission approved the use of the vaccine by the military on June 25 for a period of one year, CanSino said in a filing. The vaccine candidate was developed jointly by CanSino and a research institute at the Academy of Military Science.</p>  <p>"The Ad5-nCoV is currently limited to military use only and its use cannot be expanded to a broader vaccination range without the approval of the logistics support department," CanSino said, referring to the Central Military Commission department which approved the military use of the vaccine.</p>  <p>CanSino declined to disclose whether the inoculation of the vaccine candidate is mandatory or optional, citing commercial secrets, in an email to Reuters.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1214311776.jpg 300w,https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1214311776.jpg 460w,https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1214311776.jpg 620w,https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1214311776.jpg 780w,https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1214311776.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5630963.1593433358!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1214311776.jpg"></p></div><figcaption>People's Liberation Army soldiers march next to the entrance to the Forbidden City in Beijing. China's Central Military Commission approved the use of the vaccine by the military for a period of one year. <!-- --> <!-- -->(Nicolas Asfouri/AFP/Getty Images)</figcaption></figure></span></p>  <p>The military approval follows China's decision earlier this month to offer two other vaccine candidates to employees at state-owned firms travelling overseas.</p>  <p>The Phase 1 and 2 clinical trials of the CanSino's vaccine candidate showed it has the potential to prevent diseases caused by the coronavirus, which has killed more than&nbsp;500,000 people globally, but its commercial success cannot be guaranteed, the company said.</p>  <p>Phase 3, which tests a vaccine's&nbsp;efficacy and safety on many thousands of people,&nbsp;is still to be completed.&nbsp;This step is usually considered the most important for wide spread approval, according to the U.S.&nbsp;Centers for Disease Control and Prevention.&nbsp;</p>  <p>Separately, AMS received an approval earlier this month to test its second experimental coronavirus vaccine in humans.</p>  <p><em><strong>WATCH |&nbsp;WHO gives update on vaccine development for COVID-19:</strong></em></p>  <p><span><span><span></span><span>The World Health Organization's chief scientist says AstraZeneca appears to be in the lead in the effort to develop a coronavirus vaccine, but Chinese companies are making significant strides.&nbsp;&nbsp;<!-- --> <!-- -->2:10</span></span></span></p>  <h2>A defining summer</h2>  <p>No vaccine has yet been approved for commercial use against the illness caused by the new coronavirus, but more than a dozen vaccines from more than 100 candidates globally are being tested in humans.</p>  <p>People on six continents already are getting jabs in the arm as the race for a vaccine enters a defining summer, with even bigger studies poised to prove if any shot really works — and maybe offer a reality check.</p>  <p>United Kingdom and Chinese researchers are already chasing the coronavirus beyond their borders, testing potential vaccines in Brazil and the United Arab Emirates because there are too few new infections at home to get clear answers.</p>    <p>The U.S. is set to open the largest trials — 30,000 people to test a government-created shot starting in July, followed about a month later with another 30,000 expected to test a U.K. one.</p>  <p>Those likely will be divided among Americans and volunteers in other countries such as Brazil or South Africa, Dr. Anthony Fauci of the National Institutes of Health told The Associated Press.</p>  <p>While he's optimistic, "we've been burned before," Fauci said.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/china-vaccines.JPG 300w,https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/china-vaccines.JPG 460w,https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/china-vaccines.JPG 620w,https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/china-vaccines.JPG 780w,https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/china-vaccines.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5630957.1593433075!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/china-vaccines.JPG"></p></div><figcaption>The Ad5-nCoV is one of China's eight vaccine candidates approved for human trials at home and abroad. <!-- --> <!-- -->(Stringer/Reuters)</figcaption></figure></span></p>  <p>"This isn't a race of who gets there first. This is&nbsp;get as many approved, safe and effective vaccines as you possibly can," he said.</p>  <p>Vaccine experts say it's time to set public expectations. Many scientists don't expect a coronavirus vaccine to be nearly as protective as the measles shot.</p>  <p>If the best COVID-19 vaccine is only 50 per cent&nbsp;effective, "that's still to me a great vaccine," said Dr. Drew Weissman of the University of Pennsylvania.</p>    <p>"We need to start having this conversation now," so people won't be surprised, he said.</p>  <p>And for all the government promises of stockpiling doses in hopes of starting vaccinations by year's end, here's the catch: Even if a shot pans out — and it's one that your country stockpiled — only some high-risk people, such as essential workers, go to the front of a very long line.</p>  <p>"Will you and I get vaccinated this year? No way," said Duke University health economist David Ridley.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/covid-vaccine-approved-military-use-china-1.5630947</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681512</guid>
            <pubDate>Mon, 29 Jun 2020 19:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Engineering Products vs. Engineering Primitives]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681493">thread link</a>) | @yoloswagins
<br/>
June 29, 2020 | https://iheanyi.com/journal/2019/07/12/engineering-products-vs-engineering-primitives/#fnref5 | <a href="https://web.archive.org/web/*/https://iheanyi.com/journal/2019/07/12/engineering-products-vs-engineering-primitives/#fnref5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <p>Throughout the duration of my career, I’ve noticed that you can divide engineers into two groups, <strong>primitive engineers</strong> and <strong>product engineers</strong>. The primitive engineers enjoy building primitives that are used within various systems. A primitive<sup id="fnref1"><a href="#fn1">1</a></sup> is a building block<sup id="fnref2"><a href="#fn2">2</a></sup> of software that can be used by other pieces of software to build a larger part of a system. Examples of these primitives could be anything from an internal database<sup id="fnref3"><a href="#fn3">3</a></sup>, a rate limiting service, or even something such as a job queuing service. The other group, product engineers, then use these primitives while building out systems and products for their end-users. These engineers are the ones who work more closely with product managers and designers in order to build a product for users.</p>

<p>In my career, I’ve always leaned towards product engineering, because I enjoy being close to the user. When I worked on the Networking Products team at DigitalOcean and helped build the Cloud Firewalls and Virtual Private Cloud products, people often assume that I helped build the firewall and VPC daemons that live on the hypervisors. In reality, other engineers created the primitives that talked to the hypervisors and handled the networking rules. Then my team used these primitives in order to create a product for our users. Our systems had the responsibility of storing and updating the state of things such as firewall rules and making sure they were applied correctly on the hypervisor, while also ensuring that they were correctly being shown back to the user. It’s a joint collaboration between the primitive engineers and the product engineers, everybody has a part.</p>

<p>There is an intersection of product and primitive engineering (often in the cloud computing space), in which a primitive is so valuable internally that it is open-sourced and/or developed into a product for customers. This is how various software and products were released to the public, such as <a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB</a>, <a href="https://cloud.google.com/spanner/">Google Cloud Spanner</a>, and <a href="https://github.com/kubernetes/kubernetes">Kubernetes</a><sup id="fnref4"><a href="#fn4">4</a></sup>. What makes this intersection interesting is when a primitive is first created but then transforms into a full-fledged product offering, it indirectly causes the primitive engineer to assume a hybrid role as both a primitive and product engineer.</p>

<p>Expanding more on this thought of primitives as a product, a fair amount of SaaS<sup id="fnref5"><a href="#fn5">5</a></sup> that is used within developer tooling can be thought of as a “primitive as a service”. When developing a product, you have the classic “build” vs. “buy” situation for a lot of functionality. Do you have the time to build your own transactional email service? Proably not. <a href="https://mailgun.com/">Mailgun</a>, <a href="https://sendgrid.com/">SendGrid</a>, and <a href="https://postmarkapp.com/">Postmark</a> are primitives for sending transactional emails. Similarly, <a href="https://stripe.com/">Stripe</a> and <a href="https://braintree.com/">Braintree</a> are primitives for online payments and billing for products. Lastly, <a href="https://aws.amazon.com/s3/">Amazon S3</a>, <a href="https://cloud.google.com/storage/">Google Cloud Storage</a>, and <a href="https://azure.microsoft.com/en-us/services/storage/">Azure Storage</a> are primitives for object storage. Additionally, a lot of these services have been battle-tested and are known to scale<sup id="fnref6"><a href="#fn6">6</a></sup>, so it allows engineers to spend more time focusing on building out the actual system and product. Knowing these primitives exist and how to use them is invaluable to all engineers.</p>

<p>While a lot of the focus of this article has been back-end systems focused, this distinction also applies to the front-end as well. From a front-end engineering perspective, this distinction can also be seen, especially when thinking about <a href="https://www.designsystems.com/">design systems</a>. In various engineering organizations, there normally are entire teams dedicated to maintaining a design system for the user interfaces<sup id="fnref7"><a href="#fn7">7</a></sup>. These front-end engineers responsible for building and maintaining the various components of a design system can be seen as primitive engineers. The front-end engineers who then use these components to build out the user interfaces for their products can be seen as product engineers. In some situations, an engineer may both build and maintain these design system components and build out products<sup id="fnref8"><a href="#fn8">8</a></sup>, thus becoming a hybrid, similar to what we discussed earlier.</p>

<p>As with a lot of things, product and primitive engineering are not mutually exclusive. A product engineer may build a new primitive for their system that does not yet exist, which can then be extracted and reused across an engineering organization. Or, like we discussed earlier, a primitive engineer may create something that evolves into a product. An engineer may be working on both products and primitives at the same time. In conclusion, while there are differences in what product and primitive engineers create, one is not smarter or better than the other. A healthy and successful engineering organization requires a mixture of both product and primitive engineers, who have a symbiotic relationship. What kind of engineer do you think you are: primitive or product?</p>

<p><em>Special thanks to <a href="https://kellysutton.com/">Kelly Sutton</a> and <a href="https://jacky.wtf/">Jacky Alcine</a> for reading early drafts of this post.</em></p>



    </article></div>]]>
            </description>
            <link>https://iheanyi.com/journal/2019/07/12/engineering-products-vs-engineering-primitives/#fnref5</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681493</guid>
            <pubDate>Mon, 29 Jun 2020 19:27:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What software teams can learn from rock bands]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23681435">thread link</a>) | @ohjeez
<br/>
June 29, 2020 | https://www.functionize.com/blog/4-lessons-software-teams-can-learn-from-rock-bands/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/4-lessons-software-teams-can-learn-from-rock-bands/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/ft-software-teams-can-learn-from-rock-bands.jpg" alt="4 lessons software teams can learn from rock bands" srcset="https://www.functionize.com/wp-content/uploads/2020/06/ft-software-teams-can-learn-from-rock-bands.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/06/ft-software-teams-can-learn-from-rock-bands-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/06/ft-software-teams-can-learn-from-rock-bands-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/06/ft-software-teams-can-learn-from-rock-bands-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <p><strong>You wouldn’t put together a band where all four musicians played the guitar. <em>Somebody</em> needs to drum and sing. Similarly, QA teams need specialists across a range of skill sets and experience. And that’s just one of the rock-and-roll lessons that creative teams can learn.</strong></p>
<p>Even if you’re a software developer or tester by trade, you might also play a mean guitar in your spare time. Certainly there is <a href="https://www.researchgate.net/publication/265164952_A_History_of_Programming_and_Music" target="_blank" rel="noopener noreferrer">a long history of synergy between music-making and software</a>. What are the factors behind the synergies? How does one inform the other? And in particular: What can software teams learn from rock bands and other musical groups?</p>
<p>Veteran software pro Kevin Trowbridge played trumpet and guitar in a jazz band when he was in college. He sees connections among mathematics, software, and music. “Qualities shared by musicians and mathematicians are a love of abstraction, extreme attention to detail, and willingness to invest thousands of hours into learning very esoteric skills,” says Trowbridge, who worked on 15 different software teams in the San Francisco area before joining Qwoted as CTO.</p>
<p>Don Gregori, currently COO of First Factory, made similar observations during a company hackathon. “Late at night, I noticed a few developers taking a break, one playing the saxophone. Two others had brought guitars,” he says. “I was surprised at the number of co-workers who played instruments.”</p>
<p>“Music is mathematical with its time signatures, bar measures, scales, intervals and patterns,” Gregori adds. “Software is also mathematical with its reliance on fundamentals such as algorithms and computational science.”</p>
<p>Of course, parallels between musical and software creation hardly end there. Musicians and software pros work both collaboratively and independently. Musicians practice long hours on their own to perfect their craft; so do software developers and testers.</p>
<p>Plus, both musicians and software developers need to hold in their heads both the entire song and the individual notes that comprise it. That’s true of creating software – and the impact you have on the world. Sometimes, accomplishing that feat requires acknowledging contradictions.</p>
<blockquote><p>“When I walk out onstage I’ve got to feel like it’s the most important thing in the world. Also I’ve got to feel like, well, it’s only rock and roll. Somehow you’ve got to believe both these things.”<br>
<span>– Bruce Springsteen</span></p></blockquote>
<p><a href="https://www.functionize.com/blog/software-qa-in-the-time-of-coronavirus/">Great teamwork matters</a>. One contributor might have an initial idea; then you work together to evolve it into something better. Developers, operations, and testers each bring knowledge to an endeavor – and see themselves as part of a single team.</p>
<p>“I call this the ‘Garcia effect,’” maintains Tom Mercaldo, president of Aquinas Consulting. “<a href="https://www.youtube.com/watch?v=Qj8Q3o2J4A4" target="_blank" rel="noopener noreferrer">The Grateful Dead </a>had a unique style of developing music. One band member would say, ‘I am going to do this on the drums,’ and the next would say, ‘I am going to do this on the guitar,’ and then the next would say, ‘Why don’t you try this on the bass?’ And the music they were playing would evolve until it sounded nothing like where they started,” says Mercaldo.</p>
<p>Here are four lessons you can learn from musical groups that might help you manage and inspire a development team.</p>
<h3>1. Aim for more than one ‘axis of diversity’</h3>
<p>A band probably wouldn’t have just four musicians all playing guitars and singing at the same time, right? You wouldn’t put together a rock band of four flute players, four keyboardists, one drummer, and zero guitarists, either. Michael Fritzius, president of Arch DevOps, suggests that understanding of roles and skills is a lesson for managers of software teams.</p>
<p>“You don’t want to have nothing but Java programmers or nothing but people who know Microsoft.NET,” Fritzius elaborates. All developers do programming, and although many testers don’t code, some of them do.</p>
<p>Diversity in tech extends beyond race, ethnicity, or gender, Fritzius notes. You need to bring in different viewpoints. Counterbalance the eager recent college graduates with older folks who’ve been around the block a lot more times. Teams should also strive for a range of skill sets and experience across technologies, industry sectors, and development methodologies.</p>
<p>That even extends to personality types, Fritzius says, such as cheerleader, leader, and followers. “You want multiple ‘axes of diversity.’ That way, you’re enhancing your gene pool.”</p>
<p>Sometimes, diversity creates friction. That can be healthy – and even <a href="https://www.cio.com/article/2373792/four-non-obvious-things-pink-floyd-can-teach-your-team.html" target="_blank" rel="noopener noreferrer">inspire team members to turn frustration into creativity</a>, as was the case for the members of Pink Floyd – as long as team members respect one another.</p>
<p>What if a project comes up requiring talent you lack? Hiring a consultant is a common approach. After all, bands bring in <a href="https://amzn.to/2YEhjLm" target="_blank" rel="noopener noreferrer">session musicians</a> if a recording requires a phenomenal guitar lead, backup vocals, bongo drums, or a harmonica riff. Alternatively, you can forge partnerships with outside organizations. That’s sort of like what Aerosmith did when the band recruited hip-hop superstars Run-DMC to co-record a revamped version of <a href="about:blank">Walk This Way</a> – which became the first crossover rap/rock hit.</p>
<h3>2. Build a climate of respect</h3>
<p>Band members spend a considerable amount of time together; so do software teams. If rockers can’t figure out how to get along, you know what happens: They split up. <a href="https://www.nme.com/photos/30-mighty-bands-we-ve-lost-this-millennium-1432788" target="_blank" rel="noopener noreferrer">Where did Oasis, The Verve</a>, and<a href="https://www.youtube.com/watch?v=dLxpNiF0YKs%20" target="_blank" rel="noopener noreferrer"> REM </a>go? How about Guns N Roses, The Clash, and Smashing Pumpkins? Even Crosby, Stills, Nash and Young quit after<a href="https://www.youtube.com/watch?v=4B_UYYPb-Gk" target="_blank" rel="noopener noreferrer"> 50 years of playing together</a>.</p>
<p>To maintain harmony in the software workplace, team leaders should encourage respect for one and all, Gregori advises. <a href="https://www.functionize.com/blog/5-things-qa-testers-wish-programmers-understood/">Testers can sometimes get the proverbial short end of the stick</a> when it comes to respect, he acknowledges.</p>
<p>For example, says Gregori, development teams sometimes finish their rounds of scrums and sprints at the very last minute, suddenly delivering a project to testing. Developers need to keep in mind that testers have deadlines, too. As a result, Gregori makes sure that <a href="https://www.functionize.com/blog/in-search-of-the-full-stack-testing-team/">all developers spend some time working in QA</a>, so they can familiarize themselves with the role.</p>
<h3>3. Allow for individuality</h3>
<p>Collaboration does not suggest that team members are clones. Software organizations need to take risks for the company to move forward with innovation, Fritzius says.</p>
<p>That’s another parallel for math, music, and software development. “Within the mathematical framework, composers can be creative with the notes they use and with the instructions as to how those notes should be played; emphasizing a staccato rhythm is one example. Musicians will play the same notes differently, once again being able to offer their own interpretation,” Gregori illustrates.</p>
<p>Similarly, every programming language offers more than one way to express an intent. “This is the art of programming: the creativity to use science as a framework to build something,” Gregori points out. “And in parallel to how musicians collaborate to create a song, developers generally do not work in isolation. Rather, they work on a piece of the product, merging their code into a repository with submissions of other developers.</p>
<h3>4. Keep your cool</h3>
<p>Life in a rock band can get– well, rocky. Life in a software organization isn’t always smooth, although certainly, it usually isn’t nearly as wild and wooly.</p>
<p>“There are constant obstacles: paying for things, making tradeoffs, team members arriving and departing. If you let it become drama, it will become drama, so you have to be patient and mature and constantly deescalate. For a lighthearted example, think of the band in <em>This is Spinal Tap,</em>” Trowbridge says.</p>
<p>To find true success in either field, says Trowbridge, you need to keep perspective and to learn how to “switch off” occasionally for an escape.</p>
<p>Human beings <a href="https://www.functionize.com/blog/3-lessons-from-big-software-failures/">learn from both successes and failures</a>, a fact to which many a rock band can attest. After all, even <a href="https://www.youtube.com/watch?v=KPon7i1-T1U" target="_blank" rel="noopener noreferrer">The Beatles </a>had a tough time <a href="https://www.thedailybeast.com/the-beatles-succeeded-through-talent-ambition-and-a-lot-of-arrogance" target="_blank" rel="noopener noreferrer">landing their first record contract</a> – and hey, it didn’t stop them.</p>
<blockquote><p>One element in playing music well – and creating quality software – is recognizing when <a href="https://www.functionize.com/project/todays-testing-getting-past-the-hype-of-machine-learning/">a hyped technology helps or hinders</a> the team’s efforts. Our white paper helps you make sense of the real value of machine learning – and when its advantages are overblown.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/author-Jacqueline-Emigh.jpg" alt="Jacqueline Emigh"></p>
<div>
<p><span>by</span> Jacqueline Emigh</p>
<p>Jacqueline Emigh (pronounced “Amy”) is an award-winning journalist specializing in technologies used by enterprises, small businesses, and consumers. She has worked full time as an editor for TechTarget, BetaNews, and Ziff Davis. Her stories have also appeared in dozens of other major tech publications, including CIO, Linux Planet, and PC World. Jacqueline holds a B.S. degree in mass communications from Emerson College, with a journalism concentration. From 2017 to the present, she has served as a contributing editor to SD (Software Development) Times.</p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/4-lessons-software-teams-can-learn-from-rock-bands/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681435</guid>
            <pubDate>Mon, 29 Jun 2020 19:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The World Destroyer in Your Shampoo]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23681334">thread link</a>) | @mickfaraday
<br/>
June 29, 2020 | http://cshl.nautil.us/article/577/the-world-destroyer-in-your-shampoo | <a href="https://web.archive.org/web/*/http://cshl.nautil.us/article/577/the-world-destroyer-in-your-shampoo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>A</span>s little as two centuries ago, the northern edge of the island of Borneo, home to Malaysiaâ€™s Sarawak state, was covered in a verdant canopy that stretched, uninterrupted, from shore to shore. It was a forest that had persisted for more than 100 million years, sheltering a dizzying abundance of plants, animals, and fungi that were found nowhere else on Earth. It survived the extinction of the dinosaurs and countless cycles of glaciation. It housed humans for 40,000 years while our species grew and grew around the world. 
  </p>

<p>Then, over the past few decades, the forests of Sarawak faced threats unlike any before. The canopy began to recoil, its edges assaulted by the expansion of hydroelectric power, logging, and, most impactful of all, palm oil plantations. To many people, these changes look like the necessary costs of progress. Development has consumed almost a third of the forest, but it has also lifted millions out of poverty. The first wave of palm oil plantations, from the 1970s to the 1990s, provided farmers with seven times the income of subsistence-food croppers in the same regions. Industry has brought paved roads, better schools, and modern information infrastructure. 
  </p>
<p>The oil palm (formally <em>Elaeis guineensis)</em> is a Shiva of the modern consumer economy, a great creator and a great destroyer. A startling amount of human happiness and wellbeing depends on our relationship with this one plant. Presently palm oil accounts for 60 percent of all cooking oil, more than 62 million tons in total. Itâ€™s found in half of supermarket goods, from instant noodles to ice cream, air fresheners to shampoos. You may not see it but you are eating it and washing your hair with it. Consumer-product manufacturers prefer palm oil because it blends well with other oils and is the ideal elixir to create various consistencies. Savvy food marketers love it because it contains low levels of artery-clogging trans fats. 
  </p>
<p>Youâ€™d have to look far and wide to find a major company that doesnâ€™t have palm oil on its hands. They include Walmart, Colgate-Palmolive, Kelloggâ€™s, Nestle, McDonalds, Ikea, Target, and Whole Foods. Palm oil is mixed into animal feed and <a href="https://www.cshl.edu/podcasts/base-pairs-episode-16-big-plans-for-a-tiny-plant/" target="_blank">biofuels</a>.
  </p>
<blockquote>The oil palm is a Shiva of the modern consumer economy, a great creator and a great destroyer.</blockquote>
<p>Malaysia accounts for 26 percent of the vast production of palm oil today, making it a great creator for the local economy as well. Almost half of oil palms in that country are grown by smallholders rather than large-scale agribusiness. The crop is so important that government insiders consider its development synonymous with the eradication of poverty in Malaysia. Between 1980 and 2010, palm oil cultivation doubled in Malaysia. Then, in just four years, it doubled again. 
  </p>
<p>Therein lies the seemingly intractable dilemma of humanityâ€™s intimate relationship with this tropical tree. Palm oil production is phenomenally important to local peoples and international economies. But it is also tremendously <a href="https://www.iucn.org/resources/issues-briefs/palm-oil-and-biodiversity">destructive to natural ecosystems</a> and to the global climate.</p>
<p>Tropical forests and peatlands are great storehouses of carbon dioxide, the main gas indicted in global warming. Malaysiaâ€™s forests are especially rich in carbon. They can hold up to 220 pounds of carbon per square mile. â€œThat's equivalent to the emissions from driving an average car from New York to San Francisco and back&nbsp;76 times,â€� the Union for Concerned Scientists tells us. Razing forests and peatlands unleashes carbon dioxide into the atmosphere in calamitous amounts. Deforestation for palm cultivation in Indonesia accounted for 2 to 9 percent of all tropical land use emissions from 2000 to 2010. Palm oil expansion is also robbing orangutans, tigers, rhinos, and elephants of their natural habitats. Global demand for palm oil is expected to increase from 76 million tons in 2019 to over 400 million tons in 2050.</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/cshl_7d5d608e69937c125ebffd060a1867b2.png" alt="palm_oil_sec_3_final_blurred"><figcaption><span>A sobering summary of the environmental effects of palm-oil cultivation, summarized by the International Union for Conservation of Nature. </span><br><span>Credit: IUCN</span></figcaption></figure>
<p>Environmentalists are realists enough to know that&nbsp;palm oil is here to stay. Too much money and too many powerful government and community interests are tied up in its production. You donâ€™t overturn the world economy overnight. Plenty of nonprofits are pushing sustainable harvesting of palm oil and an international movement, Roundtable on Sustainable Palm Oil, is signing up companies to pledge to employ smart environmental practices. These grassroots efforts, though important, may amount to little more than a superficial solution, however.</p>
<p>Whatâ€™s most needed is way to reboot our relationship with the oil palm—to find a way to produce more oil on less land. Here is where plant scientists must step in. And they have. They have crafted a novel genetic technique to induce each palm oil tree to produce more fruit, containing more of the precious oil. Itâ€™s a way to keep the ice-cream makers happy while saving the rainforest, and it can be scaled up now.</p>
<p><span>R</span>ob Martienssen, a plant biologist at <a href="https://www.cshl.edu/" target="_blank">Cold Spring Harbor Lab</a>, has been one&nbsp;of the worldâ€™s key researchers into the puzzles of palm oil production: why scientific methods have gone wrong in the past, and how to right those wrongs today. Launching a project to grow more palm oil on less land was the easy part, he knew. Scientists locked in on that goal some decades ago and set out to clone a single â€œeliteâ€� palm, one that produced a bounty of oil, into 50,000 palms just like it. They even succeeded, up to a point. â€œThey thought this was going to solve all problems,â€� Martienssen says, but cloning the elite palm in the lab turned out to offend the plantâ€™s natural growth processes. Once planted, the identical trees were â€œmantledâ€�: Instead of yielding the promised bounty, the plants produced gnarled fruit that gave no oil.&nbsp;</p>
<p>It took an international collaboration between <a href="https://www.cshl.edu/research/faculty-staff/rob-martienssen/#news" target="_blank">Martienssenâ€™s group</a> at Cold Spring Harbor Lab and their colleagues at the Malaysian Palm Oil Board nearly 20 years to unravel the mystery of the mantled fruit. They started by assembling and analyzing the whole genome sequence of the <em>Elaeis guineensis </em>oil palm. That enormous effort only made the problem more puzzling, however, because they found no genetic differences between normal and mantled clones.</p>
<p>Rather than give up, the researchers dove even deeper, beyond the DNA of the oil palm and into the layer of biology that regulates how DNA is read and translated: the epigenome. To their astonishment, <a href="https://www.cshl.edu/what-s-behind-million-dollar-crop-failures-in-oil-palm-would-you-believe-bad-karma/" target="_blank">they found</a> that the huge difference in the mantled clones was the result of a single, tiny epigenetic change. Palms that produce mangled fruit have an altered molecular switch that interferes with expression levels of genes relevant to healthy fruit production. Previously that miscreant switch had been identified in rice plants and was named â€œkarma.â€� The palm clones literally suffered from <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4857894/" target="_blank">bad karma</a>.</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/cshl_e0b979cd9ee928ce965e9001019fee92.png" alt="palm_oil_sec_2_final_resized850_500"><figcaption><span>Getting rid of palm oil would come with its own drawbacks, so researchers are focusing on making it more benign. </span><br><span>Credit:  International Union for Conservation of Nature (IUCN)</span></figcaption></figure>
<p>â€œIn terms of individual palms, if you have bad karma, then it's going to literally get no oil,â€� Martienssen says. With the mechanism behind mantling unmasked, a third partner—Orion Genomics, a private startup founded by Martienssen—was able to develop a simple <a href="https://www.youtube.com/watch?v=b9Dj-MKgBkc" target="_blank">DNA test</a> that predicts whether a designer seedling will bear robust or withered fruit. Then only the genuine, high-yield clones will make their way into the field.</p>
<p>That epigenetic test could be making a difference in the oil-palm plantations very soon. â€œIt's currently being commercialized jointly by the Malaysian Palm Oil Board and Orion Genomics,â€� Martienssen says. He projects that reliable clonal stocks could increase yields by 30 to 50 percent, drastically reducing the pressure for illegal forest clearing. And thatâ€™s just the start. Other scientists are working on dwarf varieties of the oil palm that are easier to harvest, that come to maturity faster, and that stay in production for longer. The epigenetic test can be applied to <a href="https://www.cshl.edu/nobelist-sir-richard-roberts-talks-gmos-at-cshl/" target="_blank">genetically modified</a> palm varieties for a synergistic effect, but—important for many consumers and environmentalists—it provides major benefits on the non-GMO clones as well.</p>
<p>In Malaysia, the government is finally acting to protect whatâ€™s left of Sarawakâ€™s ancient forest canopy. New policies limit the expansion of palm plantations to 6.5 million hectares, which leaves just 1 million more hectares of land for cultivation. These moves create strong incentives to enact a better, smarter relationship between humans and the plants they rely on. â€œFrom a world production point of view, palm oil is not going away,â€� Martienssen says. â€œReducing its footprint is the best thing we can do to help the rainforest.â€�
      </p>
<ul><li> is a biologist and the co-creator of the Demystifying Science blog. </li>
<li><span>Michael Shilo DeLay</span> is a biologist and the co-creator of the Demystifying Science blog. </li></ul>
<p><em>Top photo:&nbsp;A palm oil plantation and mill in Sabah, Malaysia. By CEPhoto/Uwe Aranas.</em><strong></strong></p>





            </article></div>]]>
            </description>
            <link>http://cshl.nautil.us/article/577/the-world-destroyer-in-your-shampoo</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681334</guid>
            <pubDate>Mon, 29 Jun 2020 19:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Programming Is Fun”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23681213">thread link</a>) | @filiph
<br/>
June 29, 2020 | https://selfimproving.dev/programming-is-fun/ | <a href="https://web.archive.org/web/*/https://selfimproving.dev/programming-is-fun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main"><article id="post-133"><div><div><p>They once asked a famous Czech mountaineer why he’s doing what he’s doing. Why does he risk his life climbing huge, cold, barren rocks? His reply:</p><blockquote><p>It’s fun.</p></blockquote><p>Let’s unwrap that for a moment. Mountaineering, at that level, entails the following things:</p><ul><li>Walking long distances in snow</li><li>Sleeping in a sleeping bag</li><li>Eating low amounts of food</li><li>Having difficulty breathing</li><li>Suffering frostbite</li></ul><p>Does this sound like fun?</p><p>Of course it doesn’t. But there are different meanings of “fun”, and one of them is the feeling when you overcome a significant challenge in the real world. It’s the “fun” of being in a life-threatening situation, where all your decisions have real meaning, and any misstep can have dire consequences.</p><p>In other words, it’s not the same meaning of “fun” as when I say “this movie was fun”, or “it was fun talking to you”, or “let’s play a fun videogame”.</p><h3 id="funinprogramming">Fun in programming</h3><p>Software engineering doesn’t give you frostbite, thankfully. It’s not a life-threatening situation.</p><p>But the thing about software development: it’s incredibly frustrating. Once you’re trying to build — <em>and finish</em> — a real world software project, you’ll encounter these things:</p><ul><li>Failing to solve hard algorithmic problems</li><li>Encountering frustrating faults in your tooling</li><li>Having to redo days of work from scratch</li><li>Trying (and often failing) to understand incredibly difficult concepts on a regular basis</li><li>Reading long articles that turn out to be irrelevant to your problem</li><li>Debugging for hours, with an anti-climax solution (like finding a typo)</li></ul><p>And yet, some people insist that programming is “fun”. I’m one of them.</p><h3 id="braceyourself">Brace yourself</h3><p>The trick is to accept that software engineering is frustrating. Yes, it is. Nobody owes you an easy, frustration-free experience — especially once you’re past the codelabs/experimentation stage, and into the real world.</p><p>Here’s a scenario I’m seeing way too often (in and outside of programming):</p><ol><li>Start doing something</li><li>Encounter a problem</li><li>Fail to solve the problem</li><li>Get angry at yourself</li><li>As a result of your state of mind, become less able to solve the problem</li><li>Go back to #3, or quit.</li></ol><p>You see this a lot when people are using any kind of technology: computers, phones, apps, appliances. And of course, you see it with programming, too.</p><p>The only solution is to embrace the frustration. To embrace the failures. To try and avoid being angry at yourself. Then, go back to problem-solving. That single thing can separate you from a lot of failing developers.</p><p>Just keep going, keep improving.</p><p>And at some point, someone will ask you why you’re doing what you’re doing. Why are you sitting in front of the computer for hours on end, biting your lip, staring at a screen full of gibberish? And you know what you’ll tell them.</p><hr> </div></div></article></div></div>]]>
            </description>
            <link>https://selfimproving.dev/programming-is-fun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681213</guid>
            <pubDate>Mon, 29 Jun 2020 19:04:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Donnie Pump” a Presidential Press Conference Trading System]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23681103">thread link</a>) | @ardme
<br/>
June 29, 2020 | https://www.ard.ninja/blog/2020-06-28-donnie-pump-covid-press-conference-trading-system/ | <a href="https://web.archive.org/web/*/https://www.ard.ninja/blog/2020-06-28-donnie-pump-covid-press-conference-trading-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://www.ard.ninja/images/blog/press-conf-screenshot-1.png" alt="Screencap of the March 13th 2020 Rose Garden Press Conference">
<em>Screencap of the March 13th 2020 Rose Garden Press Conference.</em></p>

<h2 id="the-inspiration">The Inspiration</h2>

<p>The photo above is a screenshot of the CNBC stream of the infamous <a href="https://www.youtube.com/watch?v=mB6mzESzUf0">Rose Garden Coronavirus press conference</a> where the Trump administration trotted out a bunch of fortune 500 CEOs on March 13 2020. This was a few weeks into the COVID-19 pandemic and after the market had started to sell off earnest. The market had hit a 7% down trading halt the day before, so they were trying to instill confidence.</p>

<p>I was watching this live, dumbstruck as they brought out one CEO after another of a major publicly traded corporation and I watched the charts as stocks for these individual companies spiked almost immediately after each CEO spoke.</p>

<p>This was the inspiration for building a tool to help trade these daily Coronavirus press conferences.</p>

<p>It seemed like just about every press conference the president would mention a specific publicly traded company and then seconds later the stock would start to move up. Typically, I noticed the stock might move up anywhere from 3% to 10% over the course of about 5 or 10 minutes and then either even out or revert back to where it was.</p>

<p>To me, this seemed like an easy thing to profit from programatically. My friend <a href="https://www.marcuswood.io/">Marcus Wood</a> agreed.</p>

<h2 id="the-idea">The Idea</h2>

<p>I went to work with Marcus on the idea that weekend. At first we were thinking we could just do this without human interaction <a href="https://medium.com/@maxbraun/this-machine-turns-trump-tweets-into-planned-parenthood-donations-4ece8301e722">as people do with Trump’s tweets</a> but after toying with that idea we realized how complex it actually it is.</p>

<p>The process goes somewhat like this:</p>

<ol>
  <li>You need to transcribe the speech from the press conference to text</li>
  <li>You need to pick out individual public traded companies that are mentioned (e.g. “McDonalds”)</li>
  <li>You need to convert these company names to ticker symbols (“McDonalds” –&gt; “MCD”)</li>
  <li>Understand if this is good, bad, or old news (wont move the market).</li>
  <li>Make an appropriate trade</li>
  <li>Exit the trade at an appropriate time</li>
</ol>

<p>Well, as you can see that is fairly complex and there is a lot to go wrong in there. What we settled for is something that instead of taking the human out of the loop just makes it easy for a human to quickly make the trade and operate the system.</p>

<h2 id="the-product">The Product</h2>

<p>What we ended up with was this:</p>

<ol>
  <li>The system would transcribe the speech and match company names to tickers from a curated list</li>
  <li>We show these in the UI and make it easy to trade into them quickly</li>
  <li>The orders would go in and then automatically exit after a certain move up or a stop loss when they moved against us.</li>
</ol>

<p>So for this system the user would enter the trade with the click of a button (e.g. allocate 50% of the cash to this trade) and would be able to quickly exit with the click of a button as well. The trades would also automatically exit if the position moved a certain amount.</p>

<h2 id="the-implementation">The Implementation</h2>

<p>I had been wanting to try out the <a href="https://alpaca.markets/docs/">Alpaca trading API</a> for a long time and finally this was my chance. I implemented the backend APIs to connect to the account, make trades, stream data, look up quotes, track positions, and basically everything you need to do open up a trading account.</p>

<p>Marcus went to work on the UI and we built out what ended up being the basis of a trading platform we could implement multiple ideas in (<a href="https://www.marcuswood.io/products/suri">which he wrote a little bit more about here</a>).</p>

<p>The backend is written in Node.js, where in addition to connecting to Alpaca to trade and get market data I wrote the component which would take transcribed speech from the client and try to match this to a list of known publicly traded companies. This was harder than it seemed. There are a lot of common words like “corporation”, “technologies”, “partners” and even “health” which came up frequently in press conference but were also in the names of many companies.</p>

<p>There are thousands of companies listed on NYSE and NASDAQ so what we ended up doing is building a curated list of names we thought were worth trading against. If I had a lot of time and a team of people I could do this a lot better against every listed company and would solve the problem differently.</p>

<p>Developing the rest of the platform was interesting - I hadn’t worked on many things where a realtime UI was so important. Sure, server side code has to be fast. But its a little different when the client and server need to be in sync so tightly.</p>

<p>What we ended up doing was shoving basically everything through a websocket connection. No restful architecture or GraphQL for this one! Everything was a websocket event. Marcus moved the client to use <a href="https://mobx.js.org/README.html">MobX</a> which was designed for this sort of thing. The UI is written in React.</p>

<p>One other thing to note: the speech transcription was surprisingly easy because modern browsers actually have speech to text built in. We used the <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition">Speech Recognition API and it worked great</a>.</p>

<h2 id="a-demo">A Demo</h2>

<p>I made a little GIF of a clip of the Rose Garden press conference when the president brings out the CEO of Target and he name drops some other companies. You can see our system taking the raw text and finding the company and ticker. By the way, don’t worry: this is just a paper trading account for testing orders, I don’t actually have negative $123k in my account.</p>

<p><img src="https://www.ard.ninja/images/blog/rose-garden-presser-demo-1.gif" alt="gif of the rose garden press conference demo"></p>

<p><a href="https://www.ard.ninja/images/blog/rose-garden-presser-demo-1.gif">Here is a link to the fullsize version</a></p>

<h2 id="placing-orders">Placing Orders</h2>

<p>Alpaca has some cool order types. One of which <a href="https://alpaca.markets/docs/api-documentation/api-v2/orders/">is a “Bracket” order</a> which allows you do multiple things at once. For this project I wanted to enter a market buy when I heard the name e.g. “McDonalds” but then I also wanted to put in 2 limit orders based on this market order. I wanted to put in a stop loss to sell out of the position in case it moved against me, and I wanted to put in a limit order to sell at a higher price to take profits if I was right.</p>

<p>They allow you do just this with a single API Call. The payload looks like this:</p>

<figure><pre><code data-lang="javascript"><span>{</span>
  <span>"</span><span>side</span><span>"</span><span>:</span> <span>"</span><span>buy</span><span>"</span><span>,</span>
  <span>"</span><span>symbol</span><span>"</span><span>:</span> <span>"</span><span>SPY</span><span>"</span><span>,</span>
  <span>"</span><span>type</span><span>"</span><span>:</span> <span>"</span><span>market</span><span>"</span><span>,</span>
  <span>"</span><span>qty</span><span>"</span><span>:</span> <span>"</span><span>100</span><span>"</span><span>,</span>
  <span>"</span><span>time_in_force</span><span>"</span><span>:</span> <span>"</span><span>gtc</span><span>"</span><span>,</span>
  <span>"</span><span>order_class</span><span>"</span><span>:</span> <span>"</span><span>bracket</span><span>"</span><span>,</span>
  <span>"</span><span>take_profit</span><span>"</span><span>:</span> <span>{</span>
    <span>"</span><span>limit_price</span><span>"</span><span>:</span> <span>"</span><span>302</span><span>"</span>
  <span>},</span>
  <span>"</span><span>stop_loss</span><span>"</span><span>:</span> <span>{</span>
    <span>"</span><span>stop_price</span><span>"</span><span>:</span> <span>"</span><span>299</span><span>"</span><span>,</span>
    <span>"</span><span>limit_price</span><span>"</span><span>:</span> <span>"</span><span>298.5</span><span>"</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<p>So this is saying I want to buy at market, and then take profit at 302 (if we get that high), or I want to put in a stop limit that will hit the books if we get to 299 and then trigger if get down to 298.5.</p>

<p>Another thing I did was make sure we had a “Liquidate Positions” button on the UI so we could manually exit things if we wanted to, as well as a “Cancel Orders” button in case we wanted to cancel any limit orders sitting on the books. I initially wanted a big red “DUMP EVERYTHING!” button just in case I wanted to get out fast and panicked, but we made some reasonably sized and accurately named buttons instead.</p>

<h2 id="summary">Summary</h2>

<p>I’ve written a few automated systems based on trend following and mean reversion patterns before, but I’ve never built anything to make myself a platform to trade as a human operator directly. It presented some unique things to think about, and I keep thinking of new ideas I want to implement.</p>

<p>I really hope that Alpaca starts to support options trading a futures markets soon because I have a couple of ideas around doing psuedo-arbitrage between commodities and equities related to those underlying commodities in a programatic manner. They have a really great API that is easy to work with but I’d like to see a lot more features from it. I’m still using Quant Connect for backtesting new ideas at this point.</p>

<p>Till next time!</p>


  </div></div>]]>
            </description>
            <link>https://www.ard.ninja/blog/2020-06-28-donnie-pump-covid-press-conference-trading-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23681103</guid>
            <pubDate>Mon, 29 Jun 2020 18:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things to know before starting a Patreon page]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23680591">thread link</a>) | @colebowl
<br/>
June 29, 2020 | http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&mc_eid=5ac3a20371 | <a href="https://web.archive.org/web/*/http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&mc_eid=5ac3a20371">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0e74a9a2acebd70c05fe"><div><p>For the three years starting in April of 2017, I ran much of <a href="http://theprepared.org/newsletter" target="_blank">The Prepared’s</a> (and ultimately my family’s) income through Patreon. I started doing so as an experiment - one that by any measure has been a success. But while Patreon was instrumental in that process, I recommend that creators <strong>not</strong> structure their incomes and careers around Patreon. Here’s why.</p><p>Like many creators, I chose Patreon’s “pay by the creation” (rather than “pay by the month) mode. This directly incentivizes creators to continue doing the actual work, and keeps them accountable to the commitments they make. </p><p>But what Patreon doesn’t tell you is that fans can optionally set a monthly cap on their spending, and that cap can be arbitrarily low - even <strong>less than your per-creation commitment level.</strong> In other words, a reader of my weekly newsletter could pledge $5 per newsletter, but then set a $2 monthly cap. The worst part about this is that there’s literally nowhere in the Patreon backend that I can see this cap. I spoke to Patreon’s product team about this in late 2018, and they told me that the best thing I could do is to look at my creation-by-creation analytics at the end of the month and see which of my patrons paid for which creations; if a person doesn’t show up at the end of the month, then they must have set a cap.</p><p>This is a totally unscalable solution, and it makes the process of issuing patron rewards excruciatingly hard to manage. Creators need the ability to quickly and easily determine <strong>who</strong> is paying them for <strong>what</strong>; Patreon makes this impractically hard.</p><p>Further:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593267194369_49688"><div><ul data-rte-list="default"><li><p>Patreon provides email alerts for when a new patron makes a pledge, but has <strong>no email or push notifications for when patrons delete pledges.</strong> </p></li><li><p>Patreon has no creator-side notification system for declined charges or charges that are flagged for fraud. Worse yet, their patron-side notification system appears to be totally ineffective; many long time patrons (and personal friends of mine) were genuinely shocked to hear, many months later, that their monthly charges had been declined - leading to their pledges being automatically canceled by Patreon. Even worse, Patreon’s “Declines” page, which shows the total declined amount on a month by month basis, has no way of showing which patrons’ pledges were declined - you instead need to go into the “Relationship Manager” and filter by “Declined” to see whose charges have gone through, and when.</p></li><li><p>If you, as a creator, go through all of the effort to find charges that<em> </em>have been declined or marked as fraud, it can then be really difficult to recoup that revenue. This is mostly a result of the fact that most Patreon creators charge a small amount of money (a couple dollars) per month. In theory you could email or message the patron when their charge doesn’t go through, but in practice it feels a bit weird to be hounding someone over (say) $4. If the pledge was billed on an annual basis, though, it might be a big enough sum to warrant the effort. </p></li><li><p>Patreon uses accounting terms with little regard for their generally accepted meaning. See the screenshot above, which is titled “Earnings Projections” but then actually lists <em>gross revenue.</em> In accounting, <em>earnings</em> is the same as <em>profit - </em>it’s what a company has left <strong>after every expense is paid, </strong>whereas <em>gross revenue</em> is the total amount that a company takes in and doesn’t take into account expenses at all. In other words, Patreon is suggesting that the numbers here are what will be deposited into my bank account - but once Patreon takes their platform fees, it’ll actually be significantly less. This kind of sloppy terminology is all over Patreon’s creator backend, and no matter how you slice it is either the result of gross incompetence or a deliberate desire to deceive creators.</p></li></ul><p>Between credit card processing fees (2.9% plus $0.30 per transaction) and Patreon’s cut (between 5% and a whopping 12%), your earnings will be <em>significantly</em> less than your top line pledged amount. In practice, I saw total fees of between 8-12%. (Note: I signed up for Patreon before they shifted to tiered pricing, and now have a “Founder” Pro plan at a 5% platform fee rate. If you signed up for a Pro or Premium account today, you’d pay Patreon 3% or 7% more than I do, respectively.)</p><p>If Patreon were actively bringing customers to me - if normal people were just out there browsing Patreon for awesome things to support - then that might make sense. <strong>But the reality is that success on Patreon is inextricably tied to having your own platform and community.</strong> All Patreon does is manage recurring payment processing - a commodity service that many companies do for a drastically lower fee structure. Sure, ostensibly you can also be having conversations with patrons, generating some kind of community there, etc - but every step you take to encourage users to interact with you on Patreon, the more you undermine your own platform. In other words, Patreon engages in rent seeking - but they ultimately do it on <strong>your</strong> platform, and don’t bring a built-in audience with which to raise you higher.</p><p>When I transitioned off of Patreon, I moved to a combination of Quickbooks Online ($645/year; note that <a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank">Intuit is a terrible company</a>) and Squarespace’s ($480/year) recurring products feature. The result is that my processing fees dropped dramatically. At my peak Patreon earnings, I was spending almost $300/month ($3600/year) on Patreon’s platform fees. My current revenue is roughly 3x what it was then, but I’m paying 68% less than I used to be.<strong> My current payments, web hosting, and accounting software outlay is $1,125 a year; if I had remained on Patreon my annual fees would be about $10,000.</strong></p><p>Okay, you’re saying - so Patreon isn’t the perfect all-in-one platform that will allow me to bill, chat with, and build my audience. But maybe it’s a piece of a larger puzzle?</p><p>It’s a great idea, but unfortunately Patreon does a terrible job integrating with the other services that I use to run my business.</p><p>The first thing I’d want from Patreon is an easy way to automatically share my content (which most creators distribute elsewhere - for me, it’s Mailchimp) to Patreon. But while Patreon does have a public API, it’s poorly developed (there is no sandbox/testing area, and the most recent updates to <a href="https://github.com/Patreon/patreon-python" target="_blank">their API libraries</a> are from January of 2019) and only allows browsing/looking up data on Patreon; you cannot post content to your Patreon account via the API. This lack of functionality also exists in Zapier’s implementation of the Patreon API: You can use Patreon as a trigger, but not as an action.</p><p>What this means is that creators are inherently tied to Patreon’s terrible, horrible, clicky clicky GUI. You are completely tied to the limitations that are built into Patreon’s web product, and don’t have the ability to build automations that’ll speed up your content and customer management.</p><p>Patreon also fails to integrate well with accounting software - something that flies in the face of their promise to give creators “the stability you need to build an independent creative&nbsp;career.” Their API (and Zapier’s implementation of it) only provides <em>pledge</em> activity, and is therefore inaccurate (caps, declines, and fraud aren’t factored in - it’s a guesstimate at what you might make in the future) in all of the ways described above.</p><p>I really can’t stress this enough: <strong>If your intention is to build a meaningful income, there are much better options out there than Patreon. </strong>What Patreon <em>does</em> offer is a quick way to see whether people on the internet will pay you a little money for something that you’re already doing for free. </p><p>This is a nontrivial thing, but it’s something that you should really think through before you start a Patreon page. If it’s a success, then it’ll likely make a lot of sense for you to transition <em>off</em> of Patreon at some point in the foreseeable future. That might be fine - especially if you’re really early on and success feels like a longshot - but The Prepared’s transition off of Patreon required a lot of management on my part and resulted in roughly 1/3 of my patrons dropping their pledges. </p><p>To be clear: I’m deeply appreciative of all of the people and companies who supported me through Patreon, and it really is true that those first couple of dollars made a big impact in the path of my career. But Patreon as a platform did remarkably little to support me along that journey, even after I became a moderately successful creator and took quite a bit of time to explain my frustrations to both their customer service &amp; user research teams.</p></div></div></div>]]>
            </description>
            <link>http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&amp;mc_eid=5ac3a20371</link>
            <guid isPermaLink="false">hacker-news-small-sites-23680591</guid>
            <pubDate>Mon, 29 Jun 2020 18:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyCaret: The solution to simplify machine learning?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23680166">thread link</a>) | @runningmike
<br/>
June 29, 2020 | https://nocomplexity.com/pycaret/ | <a href="https://web.archive.org/web/*/https://nocomplexity.com/pycaret/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>PyCaret is a new ML framework. And since it is FOSS and has some potentials you can find it in the <a rel="noreferrer noopener" href="https://nocomplexity.com/foss-ml/" target="_blank">FOSS-ML Guide</a><strong>.</strong></p>



<p>Many machine learning products claim make using machine learning simple and easy. Recently the new <a href="https://pycaret.org/" target="_blank" rel="noreferrer noopener">PyCaret </a>machine learning hit our radar.  PyCaret is a promising product.  Attractive enough to  play a bit with this product. And to figure out whether this product really simplifies machine learning. </p>



<p>You can find my observations in this<a rel="noreferrer noopener" href="https://nocomplexity.com/wp-content/uploads/2020/06/SimplifyML_PyCaret.pdf" target="_blank"> simple overview</a>.</p>



<div><p><a href="https://freeandopenmachinelearning.readthedocs.io/en/latest/index.html" target="_blank" rel="noreferrer noopener">Read and share the FOSS ML Guide </a></p></div>




	</div></div>]]>
            </description>
            <link>https://nocomplexity.com/pycaret/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23680166</guid>
            <pubDate>Mon, 29 Jun 2020 17:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tribute to Bill Shannon – A Giant of the Java Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23680147">thread link</a>) | @illuminated
<br/>
June 29, 2020 | https://reza-rahman.me/2020/06/27/a-tribute-to-bill-shannon-a-giant-of-the-java-ecosystem/ | <a href="https://web.archive.org/web/*/https://reza-rahman.me/2020/06/27/a-tribute-to-bill-shannon-a-giant-of-the-java-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-490">

	

	
	<div>
		
<blockquote><p>Know you not that a good man does nothing for appearance sake, but for the sake of having done right?</p><cite>Epictetus</cite></blockquote>



<p>Bill Shannon passed away a few days ago after a long, valiant battle with cancer. The reality is Bill had a very long standing, selfless and profound impact on the entire Java ecosystem if not IT at large. It is also reality that far too few people understand this truth. In this blog post, I am going to attempt to do my part in closing this gap and honor a very good man that will be missed greatly.</p>



<p>Bill started his storied career with DEC and UNIX. He was the 11th employee of Sun Microsystems, alongside luminaries like <a href="https://en.wikipedia.org/wiki/Bill_Joy" target="_blank" rel="noreferrer noopener">Bill Joy</a>. When J2EE was being formed, Bill was recruited to help lead the effort and remained in that role through the technology’s transition to Java EE and now Jakarta EE under the Eclipse Foundation. Bill is listed as lead or co-lead on all of Java EE platform releases. He played an instrumental role in the historic transfer of the technology from the JCP to the Eclipse Foundation. Bill was also the principal developer for Java Mail, now Jakarta Mail.</p>



<p>The following excerpt from his farewell note to his colleagues represents his accomplishments well:</p>



<blockquote><p>I started at Sun (as employee #11) by bringing SunOS to life. Just as wild success was within reach, we stretched a little too far and signed a deal with AT&amp;T. That set us back almost 5 years, but at least I have the “black edition” of Solaris signed by Eric Schmidt – “I’m Sorry”. Next it was time to move on to learn about window systems, desktop applications, and industry consortiums in the form of CDE. CDE was moving much too slowly and in 1996 a new opportunity presented itself – Java. We tried a Java machine, a JavaOS, and a Java desktop environment – Hotjava Views. None of that really panned out until Java found its home as an application server environment, first named J2EE and then named Java EE. I was recruited as leader of this new effort, which has subsequently been given a new name and new leadership – Jakarta EE at the Eclipse Foundation.</p></blockquote>



<p>His contributions to Java, Java EE and Jakarta EE truly cannot be overstated. He left his mark on the technology set in a way few other people have. His interactions with me, while anecdotal, perhaps is a good reflection of who he really was, what he did and why he will be missed.</p>



<p>I first encountered Bill when I began contributing to Java EE 5 as an independent consultant, on my own time. Bill made sure I felt welcome, behind the scenes gave me background technical information that I needed and encouraged me to be outspoken. He valued my contributions and understood they came at the cost of significant personal sacrifices. I believe he also implicitly understood the challenges of being an immigrant, a person of color, someone with obvious Islamic heritage, at heart a non-conformist and a non-vendor in a forum and industry that lacked diversity and still does. Without that early support from Bill, I am not sure I would have continued on with Java EE. I still vividly remember what he once told me:</p>



<blockquote><p>Don’t underestimate your impact. I appreciate your passion. You can make a difference in a way I don’t think you understand. There will be resistance, but don’t give up. </p></blockquote>



<p>Bill was equally welcoming and supportive when I joined Oracle as Java EE evangelist. He made sure my ideas were voiced, heard and considered, even if we did not always agree. He was happy to empower me to fulfill my community facing role even at JavaOne while shunning the limelight himself. I now also know how many good fights he tirelessly fought behind the scenes so that the effort we both cared about kept moving forward.</p>



<p>Beyond Oracle, Bill was always quietly supportive of community efforts like the <a href="https://jakartaee-ambassadors.io/" target="_blank" rel="noreferrer noopener">Java EE Guardians and the Jakarta EE Ambassadors</a> after it. He remained supportive until the end of his days – taking the time to help draft the <a href="https://jakartaee-ambassadors.io/getting-involved/guide-for-helping-deliver-jakarta-ee-9/" target="_blank" rel="noreferrer noopener">Guide to Helping Deliver Jakarta EE 9</a>.</p>



<div><figure><a href="http://www.ugu.com/sui/ugu/show?I=info.Bill_Shannon" target="_blank"><img data-attachment-id="499" data-permalink="https://reza-rahman.me/ebenlh8vaaa8_rz/" data-orig-file="https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg" data-orig-size="163,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ebenlh8vaaa8_rz" data-image-description="" data-medium-file="https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg?w=163" data-large-file="https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg?w=163" src="https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg?w=163" alt="" srcset="https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg 163w, https://rezarahmanme.files.wordpress.com/2020/06/ebenlh8vaaa8_rz.jpg?w=97 97w" sizes="(max-width: 163px) 100vw, 163px"></a><figcaption>Bill is included in the Usenix association 25th anniversary of Unix, card deck (1994)</figcaption></figure></div>



<p>Bill passed at home with his family and close friends. He is succeeded by his wife and two daughters. Rest in peace Bill. Bill and his family were private people. With the blessings of his family, I hope to hold a virtual tribute event to honor Bill together publicly as a community. If this materializes, I will keep folks posted.</p>



<div><figure><img data-attachment-id="502" data-permalink="https://reza-rahman.me/shannon-bill-and-anil-gaur-may-2015-c/" data-orig-file="https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg" data-orig-size="478,688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="shannon-bill-and-anil-gaur-may-2015-c" data-image-description="" data-medium-file="https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg?w=208" data-large-file="https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg?w=478" src="https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg?w=478" alt="" srcset="https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg 478w, https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg?w=104 104w, https://rezarahmanme.files.wordpress.com/2020/06/shannon-bill-and-anil-gaur-may-2015-c.jpg?w=208 208w" sizes="(max-width: 478px) 100vw, 478px"><figcaption>Bill Shannon with Anil Gaur (then Oracle Group VP responsible for Java EE), celebrating Java’s 20th anniversary</figcaption></figure></div>



<p>I believe the best way to truly honor Bill is to carry forward his life’s work embodied in Jakarta EE. I hope you will take a moment to consider the long service of this good man on all our behalf and also consider being a part of the <a href="https://jakarta.ee/" target="_blank" rel="noreferrer noopener">Jakarta EE</a> journey.</p>



<div><figure><img data-attachment-id="509" data-permalink="https://reza-rahman.me/2020/06/27/a-tribute-to-bill-shannon-a-giant-of-the-java-ecosystem/hike-mt-pulag-philippines-lead/" data-orig-file="https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg" data-orig-size="2500,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;DMC-LX3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1267295627&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.002&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="hike-mt-pulag-philippines-LEAD" data-image-description="" data-medium-file="https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=300" data-large-file="https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=750" src="https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=1024" alt="" srcset="https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=1024 1024w, https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=2048 2048w, https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=150 150w, https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=300 300w, https://rezarahmanme.files.wordpress.com/2020/06/hike-mt-pulag-philippines-lead.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>







<p><em>Please note these views are my own and do not reflect the views of Microsoft as a company.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://reza-rahman.me/2020/06/27/a-tribute-to-bill-shannon-a-giant-of-the-java-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23680147</guid>
            <pubDate>Mon, 29 Jun 2020 17:53:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep it simple: First a POC than a MVP]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23680129">thread link</a>) | @runningmike
<br/>
June 29, 2020 | https://nocomplexity.com/poc-vs-mvp/ | <a href="https://web.archive.org/web/*/https://nocomplexity.com/poc-vs-mvp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4467">
		<!-- .entry-header -->

	
	<div>
		
<p>To build and test new functionality for your customers you can create a POC (Proof Of Concept) or develop a MVP (Minimum Viable Product). But creating a MVP from scratch is often not simple, since quality aspects such as security and privacy can rise severe realisation challenges.&nbsp;</p>



<p>There is no general accepted definition of what exactly a POC or MVP is. Definitions are a bit context dependent, depending on your specific project, product and organisation. But in general sense it is good to clearly separate a POC from a MVP. </p>



<p>In short:</p>



<ul><li>A MVP is a product that is usable for customers in production and is maintained. So a MVP is implemented in your business processes and IT landscape and can be used for real production usages.</li><li>A POC is a way to examine a solution or an aspect of a solution to gather information. E.g collect evidence if the idea is viable to create. Most of the time you perform a POC to minimize risks before creating a MVP. Developing a POC is the quickest way to validate or invalidate assumptions about a concept or idea.</li></ul>



<figure><table><thead><tr><th data-align="left">POC</th><th data-align="left">MVP</th></tr></thead><tbody><tr><td data-align="left">Examine viability of an idea or concept.</td><td data-align="left">Create a product that delivers value in the simplest way possible. It just needs to work.</td></tr><tr><td data-align="left">Used to determine development and implementation time and cost.</td><td data-align="left">Used to learn how customers will use and respond to a new product.</td></tr><tr><td data-align="left">Needs a clear focus and goal.</td><td data-align="left">Goal is clear. A working product in production.</td></tr><tr><td data-align="left">No need to be tested in a production environment.</td><td data-align="left">Involves more time than a POC since basic quality criteria (security/privacy/reliability etc) must be met.</td></tr><tr><td data-align="left">Minimal investment</td><td data-align="left">Enables learning by collecting data when your MVP is implemented in production.</td></tr><tr><td data-align="left">Gives better understanding of problem or solution</td><td data-align="left">Can be used to evolve towards an even more valuable product in future.</td></tr><tr><td data-align="left">Can be real simple.</td><td data-align="left">Create a product that has value as simple as possible.</td></tr></tbody></table></figure>



<p>The outcome of a POC can be used to speed up creation of a MVP. But improving a software prototype until it is ready for production, so evolving a POC towards a MVP, is not recommended. But reusing the generating knowledge of a POC to create a MVP simplifies the creation of a MVP.</p>




	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://nocomplexity.com/poc-vs-mvp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23680129</guid>
            <pubDate>Mon, 29 Jun 2020 17:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I lost 50k Chrome extension users after adding required permissions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23679472">thread link</a>) | @smaddock
<br/>
June 29, 2020 | https://blog.samuelmaddock.com/posts/losing-50000-chrome-extension-users/ | <a href="https://web.archive.org/web/*/https://blog.samuelmaddock.com/posts/losing-50000-chrome-extension-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Last week I shipped an update to <a href="https://chrome.google.com/webstore/detail/metastream-remote/fakegmdomhmegokfomgmkbopjibonfcp">my Chrome extension</a> which added an additional required permission. Here’s what the permission requests access for:</p><blockquote><p>Change your settings that control websites’ access to features such as cookies, JavaScript, plugins, geolocation, microphone, camera etc.</p></blockquote><p>When the extension auto-updates with the newly required permissions, Chrome disables the extension and prompts the user to approve these new permissions.</p><p>Because of this, my extension lost 50,000 users over a few days. For comparison, around 700 users uninstall the extension on an average day.</p><figure><img src="https://blog.samuelmaddock.com/images/extension/webstore-uninstalls.png" alt="Chrome Web Store uninstalls with a huge spike during recent days"></figure><figure><img src="https://blog.samuelmaddock.com/images/extension/discord-feedback.png" alt="Discord community members rightfully asking what’s up."><figcaption><p>Discord community members rightfully asking what’s up.</p></figcaption></figure><figure><img src="https://blog.samuelmaddock.com/images/extension/webstore-feedback.png" alt="Chrome Web Store feedback."><figcaption><p>Chrome Web Store feedback.</p></figcaption></figure><p>These reactions are all justified, the permissions I asked for are broad and could cause harm if used maliciously.</p><p>I initially made these changes to workaround a problem in my webapp where two popups are needed and one gets blocked by Chrome’s popup blocker. Using the requested permissions (<a href="https://developer.chrome.com/extensions/contentSettings">contentSettings API</a>), I can force allowing all popups to be opened from the companion website which requires the extension.</p><figure><img src="https://blog.samuelmaddock.com/images/extension/metastream-popups.jpg" alt="Left: Netflix in a popup - synchronized in a session, Right: session chat and user management"><figcaption><p><strong>Left:</strong> Netflix in a popup - synchronized in a session, <strong>Right:</strong> session chat and user management</p></figcaption></figure><p>Of course, as the developer, I know my use case for this permission is harmless, but a lack of granular permissions and messaging to the end-user means they must accept more than they’d like. Or not, in this case.</p><p>I ended up deciding to revert this permission change and make it optional—asking only when needed in the right context. This causes a bit more friction for my app, but the needed permissions are just too much.</p><p>Sadly, because of review times, I had to incur further loss of users until Google approved of the changes 12 hours later (not that bad, relatively). In any case, it gave me time to reflect on not making such changes so hastily in the future… 🙃</p><figure><img src="https://blog.samuelmaddock.com/images/extension/webstore-pending.png" alt="Yes, that’s correct. I somehow ended up with “fake” in my extension ID."><figcaption><p>Yes, that’s correct. I somehow ended up with “fake” in my extension ID.</p></figcaption></figure><p>In reality, the users I lost because of this were likely those who haven’t used the extension in some time, but rather kept it installed until prompted for additional permissions. And while the effects were of my own doing, there’s more that bothers me about this situation.</p><p>The change I needed to make to the extension was to allow all popups to be opened on a website. However, the permissions I asked for had to include geolocation, microphone, and camera access among other things. Why do these permissions need to be so broad?</p><p>When a Chrome Web Store developer asks for permissions in their extension, they’re required to write a reason for each (this was added somewhat recently).</p><figure><img src="https://blog.samuelmaddock.com/images/extension/webstore-permission-justification.png" alt="Chrome Web Store permission justifications listed for each API requested."></figure><p>It’d be great if these could also be displayed to the user when asked to allow an extension. Developers could always stretch the truth here, but it might be better than the permission description alone.</p><p>I suspect this particular case might not be as necessary in the future as the web <a href="https://developer.mozilla.org/en-US/docs/Web/API/Permissions_API">Permissions API</a> further develops (<a href="https://github.com/w3c/permissions/issues/210">please add popups to the list!</a> 🙇‍♂️).</p><p>In addition to my extension being on the Chrome Web Store, <a href="https://addons.mozilla.org/en-US/firefox/addon/metastream-remote/">it’s also available as a Firefox Addon.</a></p><p>In the Firefox Addon store, it’s listed as part of their Recommended Addons program. This is a huge differentiator from the Chrome Web Store. It comes with benefits for both developers and end users.</p><p><em><strong>Real humans</strong></em> review addon updates and provide technical feedback when something isn’t quite right. Seeing firsthand the effort that goes into these reviews gives me much greater trust in their other recommended addons.</p><figure><img src="https://blog.samuelmaddock.com/images/extension/firefox-addon-review.png" alt="An excerpt from a past review by the Firefox Addon team."><figcaption><p>An excerpt from a past review by the Firefox Addon team.</p></figcaption></figure><p>For the permission issue I ran into, the update I made was only needed for Chrome. Firefox allows me to open two popups without one being blocked. Had that not been the case though, I suspect their review team could have had helpful feedback for me.</p><p>Ultimately, the takeaway here is that if you need to ask for more permissions in an extension, maybe think more carefully on whether it’s really needed or if you can get by with an optional prompt—even if the friction added to the user experience is painful.</p><p><em><a href="https://news.ycombinator.com/item?id=23679472" target="_blank">Discuss on Hacker News</a><br><a href="https://www.reddit.com/r/programming/comments/hi3tgf/i_lost_50000_chrome_extension_users_after_adding/" target="_blank">Discuss on Reddit</a><br><a href="https://github.com/samuelmaddock/blog.samuelmaddock.com/commits/master/content/posts/losing-50000-chrome-extension-users.md" target="_blank">View changelog</a></em></p><ul><li><a href="https://blog.samuelmaddock.com/tags/browser-extension">browser extension</a></li><li><a href="https://blog.samuelmaddock.com/tags/chrome-web-store">chrome web store</a></li><li><a href="https://blog.samuelmaddock.com/tags/firefox-addon">firefox addon</a></li><li><a href="https://blog.samuelmaddock.com/tags/metastream">metastream</a></li></ul></section></div>]]>
            </description>
            <link>https://blog.samuelmaddock.com/posts/losing-50000-chrome-extension-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679472</guid>
            <pubDate>Mon, 29 Jun 2020 17:05:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[50 Years of LGBTQ+ Progress: A Founder's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23679386">thread link</a>) | @philipcamilleri
<br/>
June 29, 2020 | https://founderslist.com/blog/50-years-of-lgbtq-progress-a-founder-s-perspective-UlIbkBG2 | <a href="https://web.archive.org/web/*/https://founderslist.com/blog/50-years-of-lgbtq-progress-a-founder-s-perspective-UlIbkBG2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://cdn.founderslist.com/assets/od/odrllkK38r8m8IagrsZk9FB8NFiyoQD2.png" data-filename="image.png" data-width="1200" data-height="675" data-size="2123681" data-caption=""><br></p><p>Each year, June marks a special time for LGBTQ+ individuals, particularly in the US and across parts of Europe, as early summer Gay Pride parades and celebrations have become part of the annual calendars of most major cities.</p><p>But looking back just 50 years to the first Pride Parade in New York, or “Christopher Street Liberation Day” as it was then known, should cause us to reflect not only on how far we’ve come, but possibly also on how limited this progress may be, particularly for certain groups within, and without, the LGBTQ+ community.</p><p>I used to have this small tradition of bringing a few LGBTQ+ founders and entrepreneurs together this time each year, generally in San Francisco or New York. But given the new reality of 2020, I found myself like everyone else, stuck indoors and socially distanced. So instead for this year, I decided to speak with a few founders in the community, to learn about their experiences over the past few decades and how they view the progress and change we’ve achieved.</p><h3>The Shock Factor</h3><p>I recall one particular story from a friend of mine in NYC: as a black man, he says, he cannot recount how many times people look surprised when he tells them he went to Harvard Law School. “I don’t think they mean to be disrespectful, but that look and automatic reaction: ‘Harvard, really?!’ just gives it all away. And that’s because they can see I’m black. Imagine telling them I’m gay too.”&nbsp;</p><p>It’s 2020, and like it or not, we’ve still got some deeply ingrained prejudice.</p><p>That said, being a gay founder or entrepreneur in 2020, particularly in major cities like San Francisco, LA, New York or London might have lost its shock factor. According to most of the founders I spoke with, that may generally be attributed to a few considerations: political progress (particularly since the US Supreme Court’s 2015 marriage equality decision and the 2020 ruling concerning employment discrimination based on sexual orientation and gender identity); cultural progress and depictions of gay characters in movies and mass media; and the emergence of LGBTQ+ role models in various spheres: Tim Cook, Sam Altman, Arlan Hamilton, Anderson Cooper, Don Lemon, Ellen DeGeneres, Leo Varadkar or Pete Buttigieg, to name but a few.</p><p>However, as many also pointed out, there’s a certain “hetero-normalization” that still seems to be expected. Thus, being white, male and gay might be very easily accepted – for two possible reasons: the cultural shift, or the fact that hiding one’s sexual orientation is very doable: most gay, lesbian or bisexual individuals have probably hidden, or at least not disclosed, their sexual orientation on more than one occasion. But what about trans individuals, LGBTQ+ people of color, or straight and LGBTQ+ women?</p><p>A recent piece by McKinsey paints a rather disturbing picture of the current US workplace environment. Over 70% of straight women and LGTBQ+ employees reported facing microaggressions in the workplace. Straight and LGBTQ+ women also experienced sexual harassment or were subjected to inappropriate jokes and comments at much higher rates than straight and LGBTQ+ men.</p><p><img src="https://cdn.founderslist.com/assets/rQ/rQaEyUAb1X2OToQPICKsXkU4WBnGKhQT.png" data-width="1490" data-height="1074" data-size="130362" data-caption=""></p><p>Gender disparity clearly remains an issue. Add race into the mix, and the story gets even more complicated. Several studies have been published around unconscious biases in hiring for instance – seeing a foreign, ethnic or woman’s name on a resume triggers automatic (and usually unintentional) reactions. This same issue also carries over to founders and entrepreneurs, and their experiences with clients, investors, business networks and their early employees and teams.</p><p>Jason, a black LGBTQ+ founder and executive at Google, for example, said he can recall several occasions where people (consciously or unconsciously) flashed a look of surprise when he walked into college classes, and later investor meetings. In his words, “I could easily not talk about being gay; but being black is something people see immediately and often see first.”</p><p>Irma Mesa, a founder in Indianapolis, echoed similar sentiments: for her, being Latina, a woman and gay just makes it feel like she’s got three sets of prejudices to overcome. Finding like-minded individuals with whom she can share experiences, concerns and feel part of a community with similar goals and objectives is not that easy – partly due to the smaller network in Indianapolis, but also since most LGBTQ+ tech groups tend to be dominated by gay white or Asian men. In fact, Irma says groups like Lesbians Who Tech are opening up more opportunities for founders and entrepreneurs of different backgrounds, and with different experiences and helping to create a broader support system.</p><h3>Role Models&nbsp;</h3><p>As a gay founder myself, I never really considered my role within the team or my own company. In fact, for several years many of my colleagues were unaware of my sexual orientation – it just wasn’t something I felt I needed to discuss, so much so that some were surprised when I even mentioned it. Looking back now, I realize this was a missed opportunity to be a better and more authentic leader, and to allow others on my team the chance to feel more represented or welcome to speak out.</p><p>David, an Irish LGBTQ+ founder expressed how grateful he was for having been exposed to various LGBTQ+ role models (and groups) during his college years. Growing up in a small town outside Belfast, he did not often encounter LGBTQ+ people and culture growing up. But upon entering Cambridge, he was suddenly immersed in a culture that embraced LGBTQ+ diversity and allowed him to discover himself and flourish. That support is something he consciously brings to the table within his own startup.</p><p>On the other hand, Gordon, another LGBTQ+ founder, discovered he lacked the support and role models during college, making his coming out experience problematic. However, he’s now based in San Francisco and is first to admit that he feels privileged there, particularly since he fits a certain mold that the city and the investor and startup communities are now comfortable with.</p><p>Thus having role models, particularly ones we can connect with directly within our own networks, rather than simply see in the media, makes a huge difference. Those same role models may allow others to feel more comfortable at work or within their teams – rather than to feel isolated – and to express themselves more openly and freely.&nbsp;</p><p>Lorenzo Thione, one of the founders at StartOut, says this has always been a key goal for the organization – allowing LGBTQ+ individuals to connect, but to also stand out as role models for others and future generations of business leaders. StartOut has also been keen to engage members in diverse communities, whether through partnerships with other organizations or through events and programs focused around bringing under-represented groups together.</p><p>On the flip side, a number of individuals I spoke with mentioned the added responsibilities of being held up as a role model. Some half-seriously joked about being asked to vet products, statements or press-releases to ensure they were “inclusive”, especially in the current racially and politically charged environment in the USA.&nbsp; Others spoke about being held to higher standards, because they were (knowingly or unknowingly) representing generally under-represented groups. And while most of the founders and entrepreneurs I spoke with embraced these added responsibilities, they also admitted the added burden of potentially failing to fulfill these unwritten expectations.<span>&nbsp;</span></p><h3>Being Gay is Still Illegal</h3><p>One thing I was clearly reminded of while interviewing people for this article is that, despite the real need for further progress here in the US, in Europe, and around the world, there are nevertheless several places where even basic rights for LGBTQ+ individuals are still a pipe dream.</p><p>Eugene is a founder, originally from Kyrgyzstan, educated in Russia and now lives between San Francisco and London. He knows first-hand what it is like to live in a country where being gay might not be technically illegal, but could get you arrested, or worse.&nbsp;</p><p>I’m sure we’ve also all read news reports of the “anti-gay purges” in Chechnya, or the very recent story of Sarah Hegazi, a gay Egyptian who was arrested and tortured for waving a rainbow flag during a concert, and ended up committing suicide barely a few weeks ago.</p><blockquote> Today, in 2020, some 68 countries criminalize homosexuality, and almost a dozen carry the death penalty for same-sex activity.&nbsp; </blockquote> <h3>Our Responsibilities</h3><p>I will admit that when I started writing this piece, I was uncertain of where it would lead, particularly given the recent Black Lives Matters protests, and the current political climate in the US. However, speaking with these LGBTQ+ founders and business leaders, I realized there are a few conclusions to be drawn.&nbsp;</p><p>Firstly, while we cannot deny the progress that has been made over the past 50 years, not everyone has benefited equally from this progress. We therefore cannot become complacent and must remember that it took several communities to help us get here today. And unless we continue to support each other, not only will fail to progress any further, but we risk losing what we have gained.&nbsp; So whether it’s supporting women’s rights, Black, Asian, Native American, Latinx, Muslim groups, equality for all, Immigrant rights, and other under-represented minorites, we will not be able to move forward unless we do so together.&nbsp;</p><p>Secondly, as LGBTQ+ founders, and business leaders, we have an added responsibility, whether we like it or not. We can directly impact our teams, our companies, and ensure we are taking positive action to encourage diversity, make everyone in the team feel included, and proactively hire and support all groups within our organizations. We certainly aren’t going to change the world at once, but change starts from within. Investing in these goals is more than the right thing to do societally, it is good for business – there is a large body of research …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://founderslist.com/blog/50-years-of-lgbtq-progress-a-founder-s-perspective-UlIbkBG2">https://founderslist.com/blog/50-years-of-lgbtq-progress-a-founder-s-perspective-UlIbkBG2</a></em></p>]]>
            </description>
            <link>https://founderslist.com/blog/50-years-of-lgbtq-progress-a-founder-s-perspective-UlIbkBG2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679386</guid>
            <pubDate>Mon, 29 Jun 2020 16:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Lets Us Monitor 30k API calls/min]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23679310">thread link</a>) | @yarapavan
<br/>
June 29, 2020 | https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/ | <a href="https://web.archive.org/web/*/https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>At Bearer, we are a polyglot engineering team. Both in spoken languages and programming languages. Our stack is made up of services written in Node.js, Ruby, Elixir, and a handful of others in addition to all the languages our agent library supports. Like most teams, we balance using the right tool for the job with using the right tool for the time. Recently, we reached a limitation in one of our services that led us to transition that service from Node.js to Rust. This post goes into some of the details that caused the need to change languages, as well as some of the decisions we made along the way.</p><h2 id="a-bit-of-context"><strong>A bit of context</strong></h2><p>We are building a solution to help developers monitor their APIs. Every time a customer’s application calls an API, a log gets sent to us where we monitor and analyze it.</p><p>At the time of the issue, we were processing an average of 30k API calls per minute. That's a lot of API calls made across all our customers. We split the process into two key parts: Log ingestion and log processing.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion-service---node.jpg" alt="Original architecture with Node.js" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion-service---node.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion-service---node.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion-service---node.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion-service---node.jpg 2400w"></figure><p>We originally built the ingestion service in Node.js. It would receive the logs, communicate with an elixir service to check customer access rights, check rate limits using Redis, and then send the log to CloudWatch. There, it would trigger an event to tell our processing worker to take over.</p><p>We capture information about the API call, including the payloads (both the request and response) of every call sent from a user's application. These are currently limited to 1MB, but that is still a large amount of data to process. We send and process everything asynchronously and the goal is to make the information available to the end-user as fast as possible.</p><p>We hosted everything on AWS Fargate, a serverless management solution for Elastic Container Service (ECS), and set it to autoscale after 4000 req/min. Everything was great! Then, the invoice came 😱.</p><p>AWS invoices based on CloudWatch storage. The more you store, the more you pay.</p><p>Fortunately, we had a backup plan.</p><h2 id="kinesis-to-the-rescue"><strong>Kinesis to the rescue?</strong></h2><p>Instead of sending the logs to CloudWatch, we would use<a href="https://aws.amazon.com/kinesis/data-firehose/"> Kinesis Firehose</a>. Kinesis Firehose is basically a Kafka equivalent provided by AWS. It allows us to deliver a data stream in a reliable way to several destinations. With very few updates to our log processing worker, we were able to ingest logs from both CloudWatch and Kinesis Firehose. With this change, daily costs would drop to about 0.6% of what they were before.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---node_kinesis.jpg" alt="Architecture after adding Kenesis" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---node_kinesis.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---node_kinesis.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---node_kinesis.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---node_kinesis.jpg 2400w"></figure><p>The updated service now passed the log data through Kinesis and into s3 which triggers the worker to take over with the processing task. We rolled the change out and everything was back to normal... or we thought. Soon after, we started to notice some anomalies on our monitoring dashboard.</p><p><strong>We were Garbage Collecting</strong>, a lot. Garbage collection (GC) is a way for some languages to automatically free up memory that is no longer in use. When that happens, the program pauses. This is known as a <em>GC pause</em>. The more writes you make to memory, the more garbage collection needs to happen and as a result, the pause time increases. For our service, these pauses were growing high enough that they caused the servers to restart and put stress on the CPU. When this happens, it can look like the server is down—because it temporarily is—and our customers started to see 5xx errors for roughly 6% of the logs our agent was trying to ingest.</p><p>Below we can see the pause time and pause frequency of the garbage collection:</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/gc-pause.jpg" alt="GC pause and frequency charts" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/gc-pause.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/gc-pause.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/gc-pause.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/gc-pause.jpg 2400w"></figure><p>In some instances, the pause time breached <strong>4 seconds</strong> (as shown on the left), with up to <strong>400 pauses per minute</strong> (as shown on the right) across our instances.</p><p>After some more research, we appeared to be another victim of a<a href="https://github.com/aws/aws-sdk-js/issues/329"> memory leak in the AWS Javascript SDK</a>. We tried increasing the resource allocations to extreme amounts, like autoscaling after 1000 req/min, but nothing worked.</p><h2 id="possible-solutions"><strong>Possible solutions</strong></h2><p>With our backup plan no longer an option, we moved on to new solutions. First, we looked at those with the easiest transition path.</p><h3 id="elixir"><strong>Elixir</strong></h3><p>As mentioned earlier, we are checking the customer access rights using an Elixir service. This service is private and only accessible from within our Virtual Private Cloud (VPC). We have never experienced any scalability issues with this service and most of the logic was already there. We could simply send the logs to Kinesis from within this service and skip over the Node.js service layer. We decided it was worth a try.</p><p>We developed the missing parts and tested it. It was better, but still not great. Our benchmarks showed that there were still high levels of Garbage Collecting, and we were still returning 5xx to our users when consuming the logs. At this point, the heavy load triggered a <a href="https://github.com/benoitc/hackney/issues/594">(now resolved) issue</a> with one of our elixir dependencies.</p><h3 id="go"><strong>Go</strong></h3><p>We considered Golang as well. It would have been a good candidate, but in the end, it is another Garbage Collected Language. While likely more efficient than our previous implementation, as we scale there is a high chance we'd run into similar problems. With these limitations in mind, we needed a better option.</p><h2 id="re-architecting-with-rust-at-the-core"><strong>Re-architecting with Rust at the core</strong></h2><p>In both our original implementation and our backup, the core issue remained the same: garbage collection. The solution was to move to a language with better memory management and no garbage collection. Enter Rust.</p><p>Rust isn't a garbage-collected language. Instead, it relies on a concept called <em>ownership</em>.</p><blockquote>Ownership is Rust’s most unique feature, and it enables Rust to make memory safety guarantees without needing a garbage collector. <br>— <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">The Rust Book</a></blockquote><p>Ownership is the concept that often makes Rust difficult to learn and write, but also what makes it so well suited for situations like ours. Each value in Rust has a single owner variable and as a result a single point of allocation in memory. Once that variable goes out of scope the memory is immediately returned.</p><p>Since the code required to ingest the logs is quite small, we decided to give it a try. To test this we addressed the very thing that we had issues with—sending large amounts of data to Kinesis.</p><p>Our first benchmarks proved to be very successful.</p><p>From that point, we were pretty confident that Rust could be the answer and we decided to flesh out the prototype into a production-ready application.</p><p>Over the course of these experiments, rather than directly replacing the original Node.js service with Rust, we restructured much of the architecture surrounding log ingestion. The core of the new service is an <a href="https://www.envoyproxy.io/">Envoy</a> proxy with the Rust application as a sidecar.</p><p>Now, when the Bearer Agent in a user's application sends log data to Bearer, it goes into the Envoy proxy. Envoy looks at the request and communicates with Redis to check things like rate limits, authorization details, and usage quotas. Next, the Rust application running alongside Envoy prepares the log data and passes it through Kinesis into an s3 bucket for storage. S3 then triggers our worker to fetch and process the data so Elastic Search can index it. At this point, our users can access the data in our dashboard.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---rust.jpg" alt="Diagram of new rust service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---rust.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---rust.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---rust.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---rust.jpg 2400w"></figure><p>What we found was that with fewer—and smaller—servers, we are able to process even more data without any of the earlier issues.</p><p>If we look at the latency numbers for the Node.js service, we can see peaks with an average response time nearing 1700ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/before-latency.png" alt="Latency with original Node.js service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/before-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/before-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/before-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/before-latency.png 2400w"></figure><p>With the Rust service implementation, the latency dropped to below 90ms, even at its highest peak, keeping the average response time below 40ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/after-latency.png" alt="Latency after re-architecture" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/after-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/after-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/after-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/after-latency.png 2400w"></figure><p>The original Node.js application used about 1.5GB of memory at any given time, while the CPUs ran at around 150% load. The new Rust service used about 100MB of memory and only 2.5% of CPU load.</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>As with most startups, we move fast. Sometimes the best solution at the time isn't the best solution forever. This was the case with Node.js. It allowed us to move forward, but as we grew we also outgrew it. As we started to handle more and more requests, we needed to make our infrastructure evolve to address the new requirements. While this process started with a fix that merely replaced Node.js with Rust, it led to a rethinking of our log ingestion service as a whole.</p><p>We still use a variety of languages throughout our stack, including Node.js, but will now consider Rust for new services where it makes sense.<br></p>
                </div>

                


            </section>

            

            <section>
    <h3>Monthly, hand-curated content<br> <span>for API
            developers.</span></h3>
    <p>Newsletter for dev, by dev.</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679310</guid>
            <pubDate>Mon, 29 Jun 2020 16:52:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to add support for dark mode on your website in 3 steps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23679278">thread link</a>) | @diamantidis_io
<br/>
June 29, 2020 | https://diamantidis.github.io/tips/2020/06/29/how_to_add_support_for_dark_mode | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/06/29/how_to_add_support_for_dark_mode">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>In recent years, dark mode has grown in popularity as more and more devices and browsers are adding support for it.</p> <p>Those reasons make it a great little feature that we can add on our websites to improve the experience of the users who prefer to use dark mode.</p> <p>Let’s see how we can support this feature in 3 steps!</p> <p>First, we will take advantage of another great CSS feature: <a href="https://diamantidis.github.io/tips/2020/06/17/css-variables">CSS variables</a></p> <p>On the <code>:root</code> level, we will define two variables; one with the color of the background and one with the color of the text.</p> <div><div><pre><code><span>:root</span> <span>{</span>
    <span>--background-color</span><span>:</span> <span>#FFF</span><span>;</span>
    <span>--text-color</span><span>:</span> <span>#000</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>Then, we will define a <code>prefers-color-scheme</code> media query for the dark color theme. In this media query, we will override the values of the variables that we defined in the previous step.</p> <div><div><pre><code><span>@media</span> <span>(</span><span>prefers-color-scheme</span><span>:</span> <span>dark</span><span>)</span> <span>{</span>
    <span>:root</span> <span>{</span>
        <span>--background-color</span><span>:</span> <span>#000</span><span>;</span>
        <span>--text-color</span><span>:</span> <span>#FFF</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Lastly, we will use those variables to assign their values to CSS properties. In our case, we will use the variable to set the background and the color of the body.</p> <div><div><pre><code><span>body</span> <span>{</span>
    <span>background</span><span>:</span> <span>var</span><span>(</span><span>--background-color</span><span>);</span>
    <span>color</span><span>:</span> <span>var</span><span>(</span><span>--text-color</span><span>);</span>
<span>}</span>
</code></pre></div></div> <p>Now all you have to do is to find a color palette for the dark theme and apply it following those steps!</p> </div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/06/29/how_to_add_support_for_dark_mode</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679278</guid>
            <pubDate>Mon, 29 Jun 2020 16:50:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure DNS Scam (DNSSEC) Targets WordPress Bloggers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23679072">thread link</a>) | @massacre
<br/>
June 29, 2020 | https://howtohosting.guide/secure-dns-scam-dnssec/ | <a href="https://web.archive.org/web/*/https://howtohosting.guide/secure-dns-scam-dnssec/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div itemprop="text"><p><em>According to Sophos cybersecurity researchers, a new scam targeted at WordPress bloggers is currently circling the web. Over the weekend, the researchers received a well-crafted scam message that looked more convincing than many other scams out there. </em></p>
<h2>DNS Scam Targeting WordPress Bloggers</h2>
<p><a href="https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth.jpg" target="_blank" rel="noopener noreferrer"><img src="https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth-300x160.jpg" alt="" width="300" height="160" srcset="https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth-300x160.jpg 300w, https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth.jpg 640w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="//howtohosting.guide/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth-300x160.jpg" data-srcset="https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth-300x160.jpg 300w, https://howtohosting.guide/wp-content/uploads/2020/06/wordpress-image-hth.jpg 640w"></a>The message pretended to come from WordPress itself, claiming that DNS security features would soon be added for their domain.</p>
<p>Hereâ€™s an excerpt from the fake email message that Sophos received:</p>
<blockquote><p>From: WordPress<br>
Subject: nakedsecurity.sophos.com DNS Update<br>
Weâ€™re upgrading your domain DNS for something even better, freely!<br>
We care about your privacy and the protection of your domains, so we will soon be upgrading them, from basic Domain Name System (DNS) to Domain Name System Security Extensions (DNSSEC).</p></blockquote>
<p>And hereâ€™s an actual screenshot of the scam message’s contents:<br>
<a href="https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_.png" target="_blank" rel="noopener noreferrer"><img src="https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_.png" alt="" width="610" height="820" srcset="https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_.png 610w, https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_-223x300.png 223w" sizes="(max-width: 610px) 100vw, 610px" data-old-src="//howtohosting.guide/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_.png" data-srcset="https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_.png 610w, https://howtohosting.guide/wp-content/uploads/2020/06/dns-email-scam-sophos-howtohosting.guide_-223x300.png 223w"></a><br>
<em>Image Source: <a href="https://nakedsecurity.sophos.com/" rel="noopener noreferrer" target="_blank">Sophos</a></em></p>
<p>Most users today are aware that DNS stands from domain name system, the globally distributed databases that turns server names into network numbers. In fact, as pointed out by the security experts, DNSSEC which is mentioned in the message (see above) does exist. It is a protocol that adds authentication to DNS data transfers with the idea to prevent cybercriminals from filling the DNS database with fake entries that hijack web traffic.</p>
<hr>
<p><span size="+2" color="#ffcc00"></span> Also Read <a href="https://howtohosting.guide/dns-propagation/" rel="noopener noreferrer" target="_blank">DNS Propagation â€“ What Is It and How It Works</a></p>
<hr>
<p>DNSSEC means domain name system security extensions, and it has been available for more than 20 years. However, since DNSSEC is usually a feature used by service providers to help sustain their own DNS databases, most bloggers and website owners most likely have never set it up by themselves. This means that receiving this message could most likely trick bloggers into believing its authentic, which could lead recipients into revealing sensitive information, which is what usually scammers are after.</p>
<blockquote><p>Any data you enter here goes straight to the crooks, and if you donâ€™t have two-factor authentication enabled on your account, the crooks may very well be able to log on to your website or blog right away and take it over completely, Sophos warns.</p></blockquote>
<h3>What can WordPress bloggers like you do to protect themselves?</h3>
<p>Here are a couple of simple but useful tips:</p>
<ul>
<li>
Donâ€™t reveal your login credentials via links you received in unexpected emails. Usually, most companies and services donâ€™t support this practice, and would find a more appropriate way to inform you about any changes that concern you.</li>
<li>Use two-factor authentication to increase your accountâ€™s security.</li>
</ul>
<p>Follow us for more useful <a href="https://howtohosting.guide/tag/web-hosting-news/" rel="noopener noreferrer" target="_blank">WordPress and web hosting news</a>.</p>
</div><div itemprop="author" itemscope="" itemtype="https://schema.org/Person"><p><img src="https://howtohosting.guide/wp-content/uploads/2020/02/howtohosting-logo.png" data-lazy-type="image" data-src="https://howtohosting.guide/wp-content/uploads/2020/02/howtohosting-logo.png" width="50" height="36" alt="HTH_Editors"></p><div><h3><a href="https://howtohosting.guide/author/hth_editors/" title="HTH_Editors">HTH_Editors</a></h3><p itemprop="description">HowToHosting.guide provides expertise and insight into the process of creating blogs and websites, finding the right hosting provider, and everything that comes in-between.</p><p><a href="https://howtohosting.guide/author/hth_editors/" title="More posts by HTH_Editors">More Posts</a> </p></div></div>



</div></div>]]>
            </description>
            <link>https://howtohosting.guide/secure-dns-scam-dnssec/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679072</guid>
            <pubDate>Mon, 29 Jun 2020 16:28:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Chernoff Faces]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23679014">thread link</a>) | @pxx
<br/>
June 29, 2020 | https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html | <a href="https://web.archive.org/web/*/https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-7486848344071731398" itemprop="description articleBody"><p>
One of my favorite<a href="#foot1" id="cite1">¹</a> concepts for multi-dimensional data visualization is the <a href="https://en.wikipedia.org/wiki/Chernoff_face">Chernoff Face</a>. The idea here is that for a dataset with many dependent variables, it is often difficult to immediately understand the influences one variable may have on another. However, humans are great at recognizing small differences in faces, so maybe we can leverage that!</p><h2>
Tired: traditional plotting</h2><p>
The example from Wikipedia plots the differences between a few judges on some rating dimensions:</p><p><a href="https://1.bp.blogspot.com/-I_lJGg7QnmM/Xvl1rXrnm-I/AAAAAAAA534/0wm9LMMmQ0kgtxdNq9exqELo-jgSsqCMACLcBGAsYHQ/s1600/1000px-Chernoff_faces_for_evaluations_of_US_judges.svg.png"><img data-original-height="750" data-original-width="1000" height="240" src="https://1.bp.blogspot.com/-I_lJGg7QnmM/Xvl1rXrnm-I/AAAAAAAA534/0wm9LMMmQ0kgtxdNq9exqELo-jgSsqCMACLcBGAsYHQ/s320/1000px-Chernoff_faces_for_evaluations_of_US_judges.svg.png" width="320"></a></p><p>
which already improves on the "traditional" way to present such data, which is something similar to a line chart:</p><p><a href="https://1.bp.blogspot.com/-vFSg9Y-NJYg/XvmB6rUCFmI/AAAAAAAA54g/pXmUUEPqWf4QXqrasbL_WxSjN3zWu1_TwCLcBGAsYHQ/s1600/x.png"><img data-original-height="353" data-original-width="583" height="193" src="https://1.bp.blogspot.com/-vFSg9Y-NJYg/XvmB6rUCFmI/AAAAAAAA54g/pXmUUEPqWf4QXqrasbL_WxSjN3zWu1_TwCLcBGAsYHQ/s320/x.png" width="320"></a></p>
<p>
or a radar chart:</p><p><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://1.bp.blogspot.com/-Dh3hoPt0f5A/XvmBsL-eM7I/AAAAAAAA54c/r0KXd9byh1wQ06Yp5Y3Ds-LV44p_DEfpQCLcBGAsYHQ/s1600/x.png"><img data-original-height="356" data-original-width="591" height="192" src="https://1.bp.blogspot.com/-Dh3hoPt0f5A/XvmBsL-eM7I/AAAAAAAA54c/r0KXd9byh1wQ06Yp5Y3Ds-LV44p_DEfpQCLcBGAsYHQ/s320/x.png" width="320"></a></p>


<p>
Clearly<a href="#foot2" id="cite2">²</a> the Chernoff faces are the best way to present this data, but they leave some of the gamut unexplored.</p>

<h2>
Wired: using GANs to synthesize faces</h2>


<p>
The GAN technique is pretty easily summarized. You set up two neural networks, a generator, which tries to generate realistic images, and a discriminator, which tries to distinguish between the output of the generator and a real corpus of images. By training the networks together, adding more layers, fooling around with hyperparameters and overall "the scientific process", you manage to get results where the generator network is able to fool the discriminator (and humans) with high-quality images of faces that do not actually map to anybody in the real world. StyleGAN improves on some of the basic structure here by using a novel generator architecture that stacks a bunch of layers together and ends up with an intermediate latent space that has "nice" properties.</p>

<p><a href="https://1.bp.blogspot.com/-JxAnoglX3VU/Xvl-BPsI1XI/AAAAAAAA54I/HTbKb0qKkhE88y4HzqyHwele2NAzZM0WgCLcBGAsYHQ/s1600/n9fgba8b0qr01.png"><img data-original-height="1461" data-original-width="1600" height="292" src="https://1.bp.blogspot.com/-JxAnoglX3VU/Xvl-BPsI1XI/AAAAAAAA54I/HTbKb0qKkhE88y4HzqyHwele2NAzZM0WgCLcBGAsYHQ/s320/n9fgba8b0qr01.png" width="320"></a></p>
<p><i>Basically how it works.</i></p>
<br>
<div><p>
A trained StyleGAN (1 or 2; the architecture for the dimensions does not change between versions), at the end of the day, takes a 512 element vector in the latent space "Z", then sends it through some </p><strike>nonsense</strike><p> fully-connected layers to form a "dlatent"<a href="#foot3" id="cite3">³</a> vector of size 18x512. The 18 here indicates how many layers there are in the generator proper—the trained networks that NVIDIA provides produce 1024x1024 images; there are 2 layers for each of the dimensions from 2^2=4 to 2^10=1024.</p></div>

<p><a href="https://1.bp.blogspot.com/-RLpfhFZBSuo/Xvl-Wzo0B2I/AAAAAAAA54Q/ztjxSsS_JJYSz9MZBXnXBYuGC2IkT9SAACLcBGAsYHQ/s1600/x.png"><img data-original-height="767" data-original-width="267" height="320" src="https://1.bp.blogspot.com/-RLpfhFZBSuo/Xvl-Wzo0B2I/AAAAAAAA54Q/ztjxSsS_JJYSz9MZBXnXBYuGC2IkT9SAACLcBGAsYHQ/s320/x.png" width="111"></a></p>
<p><i>What part of STACK MORE LAYERS did you not get?</i></p>
<br>
<div>
<p><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a>The upshot is that the 18x512 space has nice linearity properties that will be useful to us when we want to generate photorealistic faces that only differ on one axis of importance. The authors of the NVIDIA paper call each of the 18 layers a "style", and the observation is that copying qualities from each style gives qualitatively different results.</p><p>

The styles that correspond to coarse resolutions bring high-level aspects like pose, hair style, face shape; the styles that correspond to fine resolutions bring low-level aspects like color scheme. But they only roughly correspond to these, so it's going to be somewhat annoying to play around with the latent space! What we need is some way to automatically classify these images for the properties we want to use in our Chernoff faces...</p></div>
<p>
<br>
<h3>
Putting it all together</h3>
</p>
<div><p>
What I did was take an <a href="https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x">unofficial re-implementation of StyleGAN2</a> and run it to generate 4096 random images (corresponding actually to random seeds 0 - 4095 in the original repository). The reason why we're using an unofficial implementation is that the unofficial implementation ports everything to TensorFlow 2, which also enabled me to run it with (a) less GPU RAM (I only have a GTX 1080 at home) and (b) on the CPU if needed for a future project where I serve these images dynamically.</p><p>

I was also too lazy to train a network to recognize any features, so I fed these images through <a href="https://www.kairos.com/pricing">Kairos</a>'s free trial, receiving API responses that roughly looked like <a href="https://pastebin.com/PXWDKkYf">this</a>. (There's no code for this part, you can just do it with cURL<a href="#foot4" id="cite4">⁴</a>).</p><p>

<a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a>Then, somewhere in this <a href="https://github.com/patrickxia/StyleGAN2-TensorFlow-2.x/blob/master/play_around_with_directions.ipynb">gigantic unorganized notebook</a>&nbsp;that I need to clean up, I train some <a href="https://en.wikipedia.org/wiki/Support_vector_machine#Linear_SVM">linear SVMs</a> to split our sample of the latent space; eventually I will clean this up and make it so it's a little more automated than the crazy experimentation I was doing. After I train the SVMs and receive the normal vector from their separating hyperplanes, I manually explore the latent space by considering only one style's worth of elements from each of the normal vectors, plotting the results, and seeing what changes about the photos (which could be different than the feature from the API response!). This could probably be automated; I should likely use the <a href="https://en.wikipedia.org/wiki/Conditional_entropy">conditional entropy</a> of the Kairos API responses given the SVM result to rank which styles are most important and then automatically return that instead of manually pruning styles.<br>
<span><br></span>
<span>I ended up with seven usable properties plus one I threw out before I got tired of doing this by hand.</span></p><ul>
<li>yaw</li>
<li>eye squint</li>
<li>age</li>
<li>smile</li>
<li>skin tone</li>
<li>gender</li>
<li>hair length</li>
<li>quality of photo</li>
</ul>
<div><p>
I decided not to use quality of photo (you can see the results in the notebook results) because I didn't want half the photos to just look terrible. The good news is that I made <a href="https://github.com/patrickxia/StyleGAN2-TensorFlow-2.x/blob/master/chernoff_faces.ipynb">a new notebook</a> for generating the actual faces, one that should actually work for you if you clone the repo.</p><p>

After generating a few images and using the `montage` command from ImageMagick, we get our preliminary results!</p><p><a href="https://1.bp.blogspot.com/-BUwEV9KxEHU/XvmKsnDLQdI/AAAAAAAA54w/LRRwtnI9zl80FV5sIQMEQfcmGFcX8cYCQCLcBGAsYHQ/s1600/out.png"><img data-original-height="426" data-original-width="512" height="331" src="https://1.bp.blogspot.com/-BUwEV9KxEHU/XvmKsnDLQdI/AAAAAAAA54w/LRRwtnI9zl80FV5sIQMEQfcmGFcX8cYCQCLcBGAsYHQ/s400/out.png" width="400"></a></p>

<br></div>
<p>
Now that's the future!</p>



<p><a href="#cite1" id="foot1">¹</a>&nbsp;"Favorite" might be code for "useless," going with the theme of this blog.<br>
<a href="#cite2" id="foot2">²</a>&nbsp;Clearly.<br>
<a href="#cite3" id="foot3">³</a>&nbsp;It's called a dlatent in the code, but the paper calls it the space W and the vectors w. I don't know.<br>
<a href="#cite4" id="foot4">⁴</a></p><tt>for q in `seq 0 4095`; do i=$(printf "%04d" $q); curl -d '{"image": "http://cantina.patrickxia.com/faces/seed'$i'.png"}' -H "app_id: xxx" -H "app_key: xxx" -H 'store_image: "false"' -H "Content-Type: application/json" http://api.kairos.com/detect &gt; $i.json; sleep 1; done</tt><p> and something similar for the `media` API, which gives you landmarks. If you care enough, I've hosted the images <a href="http://cantina.patrickxia.com/faces">here</a>, which lets you just look through them if you want.</p></div>

</div></div>]]>
            </description>
            <link>https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679014</guid>
            <pubDate>Mon, 29 Jun 2020 16:21:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Online Course on Gravitational Waves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23679009">thread link</a>) | @wwarner
<br/>
June 29, 2020 | http://astro-gr.org/online-course-gravitational-waves/ | <a href="https://web.archive.org/web/*/http://astro-gr.org/online-course-gravitational-waves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


 <!-- / END HOME SECTION  -->
<div id="content">

	<div>

		
		<div>

			
			<div id="primary">

				<main id="main">

					<article id="post-1484" class="page">

	<!-- .entry-header -->

	<div>

		<h4>An Online Course On Gravitational Waves Organised and designed by Kip S Thorne, Mihai Bondarescu and Yabei Chen</h4>
<p><strong><span>COURSE DESCRIPTION</span></strong></p>
<p><img src="http://astro-gr.org/wp-content/uploads/2016/03/Pau_Presentation_FullRes.jpg" alt="" width="337" height="216"></p>
<p>This course is an introduction to all major aspects of gravitational waves, as imparted in Caltech <a href="http://elmer.tapir.caltech.edu/ph237/CourseOutlineA.html" target="_blank" rel="noopener">Gravitational Waves course ph237</a> (see <a href="http://caltech.tind.io/record/656049" target="_blank" rel="noopener">this URL</a> and <a href="https://www.library.caltech.edu/eds/detail?db=cat04350a&amp;an=caltech.656049" target="_blank" rel="noopener">this URL</a>):</p>
<ol>
<li>Their physical and mathematical descriptions;</li>
<li>Their generation, propagation and interaction withdetectors;</li>
<li>Their astrophysical sources (the big bang, early-universe phenomena, binary stars, black holes, supernovae, neutron stars, …); and</li>
<li>Gravitational wave detectors (their design, underlying physics, noise and noise control, and data analysis) with emphasis on earth-based interferometers (LIGO, VIRGO, GEO600, TAMA) and space-based interferometers (LISA), but also including resonant-mass detectors, doppler tracking of spacecraft, pulsar timing, and polarization of the cosmic microwave background.</li>
</ol>
<p>The course is divided in</p>
<p>A. <a href="#PartA">Gravitational-wave theory and sources</a><br>
B. <a href="#PartB">Gravitational-wave detectors</a></p>
<p>I’ve uploaded the movies to youtube because the original ones in HD were about 75GB, and I’ve also uploaded the slides (as pdf) to google drive. The structure of the course we offer here is the “alternative” one. The original order of the lectures was dictated in part by the availability of the guest lecturers. I’m following an order more adapted to the topics.</p>
<hr>
<h2 id="PartA">PART A: GRAVITATIONAL-WAVE THEORY AND SOURCES</h2>
<p><strong>1- Overview of Gravitational-Wave Science </strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeYlUyMlM4WmZXS00">slides</a>, <a href="https://drive.google.com/open?id=0B5DjnMovgoFeenhfYVNyVzEtYjA">assignments and solutions</a></p>
<ol>
<li>The nature of gravitational waves (slides, assignment, solutions)</li>
<li>The GW spectrum: HF, LF, VLF, ELF bands</li>
<li>Detection techniques (slides)</li>
<li>GW data analysis</li>
<li>GW sources and science (slides, assignment, solutions)</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“Overview of Gravitational-Wave Science (1/3)”</strong><br>
<a href="https://youtu.be/ZZhNzvUqE18" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/ZZhNzvUqE18/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Overview of Gravitational-Wave Science (2/3)”</strong><br>
<a href="https://youtu.be/CNV5LjxEc1k" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/CNV5LjxEc1k/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Overview of Gravitational-Wave Science (3/3)”</strong><br>
<a href="https://youtu.be/qOW0nn0Jjak" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/qOW0nn0Jjak/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>2- Introduction to General Relativity</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFebThHQk9qc0ZpWXc" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Tidal gravity in Newtonian theory</li>
<li>The mathematics underlying general relativity</li>
<li>The Einstein field equations</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“Introduction to General Relativity (1/5)”</strong><br>
<a href="https://youtu.be/ym0ncc6hRf8" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/ym0ncc6hRf8/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Introduction to General Relativity (2/5)”</strong><br>
<a href="https://youtu.be/jU7sYqhYnHA" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/jU7sYqhYnHA/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Introduction to General Relativity (3/5)”</strong><br>
<a href="https://youtu.be/cOoKw3UIIJE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/cOoKw3UIIJE/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Introduction to General Relativity (4/5)”</strong><br>
<a href="https://youtu.be/BlCnAMjP9p4" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/BlCnAMjP9p4/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Introduction to General Relativity (5/5)”</strong><br>
<a href="https://youtu.be/4CEkqfzp9pE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/4CEkqfzp9pE/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>3- Weak Gravitational Waves in Flat Spacetime</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeV3lMTDBNSDBIVkE" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Wave equation for Riemann tensor</li>
<li>Transverse-traceless GW field, + and x polarizations</li>
<li>GW’s tidal forces (relative motion of freely falling particles)</li>
<li>Metric perturbations, TT gauge and other gauges</li>
<li>Proper reference frame of an observer</li>
<li>Physical measurements of GW’s in a proper reference frame</li>
<li>Generation of GW’s: The linearized Einstein field equations</li>
<li>Projecting out the TT GW field</li>
<li>Slow-motion, weak-stress approximation for GW sources</li>
<li>The quadrupole formula for GW generation</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (1/6)”</strong><br>
<a href="https://youtu.be/nM0Ym9N2hGo" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/nM0Ym9N2hGo/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (2/6)”</strong><br>
<a href="https://youtu.be/xBOZh9wqFz0" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/xBOZh9wqFz0/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (3/6)”</strong><br>
<a href="https://youtu.be/CP3mv7vln7E" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/CP3mv7vln7E/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (4/6)”</strong><br>
<a href="https://youtu.be/BqBW22xyqBY" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/BqBW22xyqBY/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (5/6)”</strong><br>
<a href="https://youtu.be/rjN73uufoEo" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/rjN73uufoEo/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Weak Gravitational Waves in Flat Spacetime (6/6)”</strong><br>
<a href="https://youtu.be/azQhaa5n6ZE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/azQhaa5n6ZE/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>4- Propagation of Gravitational Waves Through Curved Spacetime</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFebGRmZ3BCYmdjbHc" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Short wavelength approximation; two-lenghscale expansion</li>
<li>Curved-spacetime wave equation for Riemann tensor</li>
<li>Solution of wave equation via eikonal approximation (geometric optics) – Foundations</li>
<li>Geometric optics – Details</li>
<li>Propagation of GW’s through homogeneous matter</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“Propagation of Gravitational Waves Through Curved Spacetime (1/4)”</strong><br>
<a href="https://youtu.be/XtUMTEuOS_k" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/XtUMTEuOS_k/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Propagation of Gravitational Waves Through Curved Spacetime (2/4)”</strong><br>
<a href="https://youtu.be/2Rf3OzzEaCo" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/2Rf3OzzEaCo/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Propagation of Gravitational Waves Through Curved Spacetime (3/4)”</strong><br>
<a href="https://youtu.be/GszdpO0uKoo" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/GszdpO0uKoo/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Propagation of Gravitational Waves Through Curved Spacetime (4/4)”</strong><br>
<a href="https://youtu.be/pPknJihcsiE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/pPknJihcsiE/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>5- Generation of GWs by Slow-Motion Sources in Curved Spacetime</strong></p>
<ol>
<li>Strong-field region, weak-field near zone, local wave zone, distant wave zone</li>
<li>Multipolar expansions of metric perturbation in weak-field near zone and local wave zone</li>
<li>Application to a binary star system with circular orbit</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“Generation of GWs by Slow-Motion Sources in Curved Spacetime (1/2)”</strong><br>
<a href="https://youtu.be/5Spk8wdQAGs" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/5Spk8wdQAGs/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Generation of GWs by Slow-Motion Sources in Curved Spacetime (2/2)”</strong><br>
<a href="https://youtu.be/MCQxwB1FRgI" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/MCQxwB1FRgI/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>6- Astrophysical Phenomenology of Binary-Star GW Sources</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeQTAzeG5ZcVZmMDA">slides</a>, <a href="https://drive.google.com/open?id=0B5DjnMovgoFedHl4bnRHSmc3ckE" target="_blank" rel="noopener">assignments and solutions</a>, <a href="https://drive.google.com/open?id=0B5DjnMovgoFeN040bGFRV1c5TVk">complementary reading: “An overview of gravitational-wave sources”, by Cutler and Thorne 2002</a></p>
<ol>
<li>GW’s from Binary Star Systems</li>
<li>Issues relevant to estimating numbers of binary GW sources and their merger rates</li>
<li>Estimates of numbers of binary GW sources and inspiral/merger rates</li>
<li>Estimates of numbers of binary GW sources for LISA and inspiral/merger rates for LIGO</li>
</ol>
<p>Lecturer Sterl Phinney: <strong>“Astrophysical Phenomenology of Binary-Star GW Sources (1/5)”</strong><br>
<a href="https://youtu.be/xHE3Oa9NxQs" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/xHE3Oa9NxQs/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Sterl Phinney: <strong>“Astrophysical Phenomenology of Binary-Star GW Sources (2/5)”</strong><br>
<a href="https://youtu.be/3ixPTPnNKFs" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/3ixPTPnNKFs/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Sterl Phinney: <strong>“Astrophysical Phenomenology of Binary-Star GW Sources (3/5)”</strong><br>
<a href="https://youtu.be/xz8MTjbx5JQ" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/xz8MTjbx5JQ/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Sterl Phinney: <strong>“Astrophysical Phenomenology of Binary-Star GW Sources (4/5)”</strong><br>
<a href="https://youtu.be/oDj8N5xQE-g" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/oDj8N5xQE-g/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Astrophysical Phenomenology of Binary-Star GW Sources (5/5)”</strong><br>
<a href="https://youtu.be/cm7fLAdMAek" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/cm7fLAdMAek/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>7- Binary Inspiral: Post-Newtonian Gravitational Waveforms for LIGO and Its Partners</strong></p>
<ol>
<li>Matched-filtering data analysis to detect inspiral waves</li>
<li>Foundations for post-Newtonian approximations to General Relativity</li>
<li>Post-Newtonian inspiral waveforms for circular orbits and vanishing spins</li>
<li>Expansion parameter</li>
<li>Phase evolution governed by energy balance</li>
<li>Waveform in time domain</li>
<li>Waveform in frequency domain, via stationary-phase approximation</li>
<li>Influence of spin-orbit and spin-spin coupling: Orbital and spin precession; waveform modulation</li>
<li>Innermost stable circular orbit (ISCO) and transition from inspiral to plunge</li>
<li>The IBBH problem: failure of post-Newtonian waveforms in late inspiral; methods to deal with this</li>
</ol>
<p>Lecturer Alessandra Buonanno: <strong>“Binary Inspiral: Post-Newtonian Waveforms (1/1)”</strong><br>
<a href="https://youtu.be/JLpzc1nZevs" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/JLpzc1nZevs/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>8- Supermassive Black Holes and their Gravitational Waves</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeSDlXLXY2aDFMX0U" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Astrophysical phenomenology of SMBH’s in galactic nuclei</li>
<li>Mergers of galaxies</li>
<li>Evolution of SMBH binary</li>
<li>Capture and inspiral of stars by a SMBH</li>
<li>Gravitational waves from SMBH binary inspiral, as measured by LISA</li>
<li>GW’s from inspiral of a compact star (or BH) into a SMBH</li>
</ol>
<p>Lecturer Sterl Phinney: <strong>“Supermassive Black Holes and their Gravitational Waves (1/4)”</strong><br>
<a href="https://youtu.be/FS3_I3bX0eY" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/FS3_I3bX0eY/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Sterl Phinney: <strong>“Supermassive Black Holes and their Gravitational Waves (2/4)”</strong><br>
<a href="https://youtu.be/GtAH2Aj1JSc" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/GtAH2Aj1JSc/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Supermassive Black Holes and their Gravitational Waves (3/4)”</strong><br>
<a href="https://youtu.be/XccsWWkt_-s" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/XccsWWkt_-s/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“Supermassive Black Holes and their Gravitational Waves (4/4)”</strong><br>
<a href="https://youtu.be/2nFhkQ4oz7E" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/2nFhkQ4oz7E/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>9- GW’s from Big Bang: Amplification of Vacuum Fluctuations by Inflation</strong></p>
<ol>
<li>Basic idea: same as parametric amplification of classical waves</li>
<li>Mathematical details</li>
</ol>
<p><strong>10- GW’s from Neutron-Star Rotation and Pulsation</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeeGVaY0d1WHdrd0U" target="_blank" rel="noopener">assignments</a></p>
<ol>
<li>GW’s from a structurally deformed, rotating NS</li>
<li>GW’s from pulsations in a rotating NS</li>
</ol>
<p>Lecturer Lee Lindblom: <strong>“GW’s from Neutron-Star Rotation and Pulsation (1/2)”</strong><br>
<a href="https://youtu.be/aZZr6aelMGw" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/aZZr6aelMGw/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Lee Lindblom: <strong>“GW’s from Neutron-Star Rotation and Pulsation (2/2)”</strong><br>
<a href="https://youtu.be/5lg6Qm-pnmY" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/5lg6Qm-pnmY/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>11- Numerical Relativity as a Tool for Computing GW Generation</strong></p>
<ol>
<li>Motivation: Sources that require numerical relativity for their analysis</li>
<li>Mathematical underpinnings of numerical relativity</li>
<li>Mathematical details</li>
<li>Current state of the art in numerical relativity; current efforts on BH/BH inspiral &amp; merger</li>
</ol>
<p>Lecturer Marc Scheel: <strong>“Numerical Relativity as a Tool for Computing GW Generation (1/2)”</strong><br>
<a href="https://youtu.be/9eMmWzPlyRM" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/9eMmWzPlyRM/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Marc Scheel: <strong>“Numerical Relativity as a Tool for Computing GW Generation (2/2)”</strong><br>
<a href="https://youtu.be/yP445W0HOyM" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/yP445W0HOyM/0.jpg" alt="" width="150" height="150"></a></p>
<h2 id="PartB">PART B: GRAVITATIONAL-WAVE DETECTORS</h2>
<p><strong>1- The Physics Underlying Earth-Based GW Interferometers</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeS0pxbi11VVVPTEE" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Idealized Interferometer: Conceptual design and crude analysis</li>
<li>General relativity: Proper reference frame of an accelerated observer</li>
<li>Optics</li>
<li>Statistical Physics: The theory of random processes</li>
</ol>
<p>Lecturer Kip Thorne: <strong>“The Physics Underlying Earth-Based GW Interferometers (1/4)”</strong><br>
<a href="https://youtu.be/mGdbI24FvXQ" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/mGdbI24FvXQ/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“The Physics Underlying Earth-Based GW Interferometers (2/4)”</strong><br>
<a href="https://youtu.be/JwLZ_1joqC8" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/JwLZ_1joqC8/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“The Physics Underlying Earth-Based GW Interferometers (3/4)”</strong><br>
<a href="https://youtu.be/BkOwOALmP54" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/BkOwOALmP54/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Kip Thorne: <strong>“The Physics Underlying Earth-Based GW Interferometers (4/4)”</strong><br>
<a href="https://youtu.be/p0_yXJpSJQc" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/p0_yXJpSJQc/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>2- Overview of Real LIGO Interferometers</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFebFg3RVVWN0x0R1k" target="_blank" rel="noopener">assignments and solutions</a>, <a href="https://drive.google.com/open?id=0B5DjnMovgoFeMnNyR1AyeHF0dmc">additional reading: PhD of Martin Regehr</a></p>
<ol>
<li>Overview of noise sources &amp; how they are controlled</li>
<li>Optics</li>
<li>Suspensions for mirrors and other optical elements</li>
</ol>
<p>Lecturer Alan Weinstein: <strong>“Overview of Real LIGO Interferometers (1/2)”</strong><br>
<a href="https://youtu.be/AotoBHX2_hk" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/AotoBHX2_hk/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Alan Weinstein: <strong>“Overview of Real LIGO Interferometers (2/2)”</strong><br>
<a href="https://youtu.be/xdGk0h3KqqM" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/xdGk0h3KqqM/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>3- Thermal Noise in LIGO Interferometers and its Control</strong></p>
<ol>
<li>Motivation: Brownian motion of a dust grain buffeted by molecules of an ideal gas</li>
<li>Fluctuation-dissipation theorem</li>
<li>Damped pendulum: suspension thermal noise derived from fluctuation-dissipation theorem</li>
<li>Dissipation in a LIGO test mass or suspension described via imaginary part of generalized elastic modulus</li>
<li>Dissipation/fluctuation processes for a LIGO test mass</li>
</ol>
<p>Lecturer Phil Willems: <strong>“Thermal Noise in LIGO Interferometers and its Control (1/2)”</strong><br>
<a href="https://youtu.be/K1Gx5dnE2vg" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/K1Gx5dnE2vg/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Phil Willems: <strong>“Thermal Noise in LIGO Interferometers and its Control (2/2)”</strong><br>
<a href="https://youtu.be/amMj9KxKtec" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/amMj9KxKtec/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>4- Control Systems and Laser Frequency Stabilization</strong> – <a href="https://drive.google.com/open?id=0B5DjnMovgoFeam9hR3VsN3BNYTQ" target="_blank" rel="noopener">assignments and solutions</a></p>
<ol>
<li>Introduction</li>
<li>General, linear control theory</li>
<li>Laser frequency stabilization via locking to eigenmode of an optical cavity: an example of linear control theory</li>
</ol>
<p>Lecturer Erik Black: <strong>“Control Systems and Laser Frequency Stabilization (1/2)”</strong><br>
<a href="https://youtu.be/DnxsknKjkGE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/DnxsknKjkGE/0.jpg" alt="" width="150" height="150"></a></p>
<p>Lecturer Erik Black: <strong>“Control Systems and Laser Frequency Stabilization (2/2)”</strong><br>
<a href="https://youtu.be/tX884B8GrEE" target="_blank" rel="noopener"><img src="http://img.youtube.com/vi/tX884B8GrEE/0.jpg" alt="" width="150" height="150"></a></p>
<p><strong>5- Interferometer …</strong></p></div></article></main></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://astro-gr.org/online-course-gravitational-waves/">http://astro-gr.org/online-course-gravitational-waves/</a></em></p>]]>
            </description>
            <link>http://astro-gr.org/online-course-gravitational-waves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679009</guid>
            <pubDate>Mon, 29 Jun 2020 16:21:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boredom, the Disregarded Fuel of Productivity and Creativity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23678732">thread link</a>) | @bbreakfast
<br/>
June 29, 2020 | https://realisticwanderlust.com/2020/06/29/boredom-fuels-productivity-creativity/ | <a href="https://web.archive.org/web/*/https://realisticwanderlust.com/2020/06/29/boredom-fuels-productivity-creativity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
        

        <div>
            
                <!-- 

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/profile.jpg" />
            <h2 id="name">Eric</h2>
            <h3 id="title">You won&#39;t find a Twitter handle or an email list here. 🏖️</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Normally around Los Angeles</span>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                65
                <span>posts</span>
            </div>
            <div class="article-info-block">
                166
                <span>tags</span>
            </div>
        </div>
        
    </div>
</aside> -->

            
            <section id="main"><article id="post-boredom-fuels-productivity-creativity" itemscope="" itemprop="blogPost">
    <div>
        
            
	
		<p><img src="https://realisticwanderlust.com/assets/images/boredom-fuel/banner.jpg"></p><header>
                
    
        
    

                
                    <div>
                        
    


                        
    

                        
    

                        <p>
    
    
    7 minutes Read (About 1031 Words)
</p>

                    </div>
                
            </header>
        
        
        <div itemprop="articleBody">
        
            
            <p>If you were dropped on a deserted island (let’s call it Island 1) that is absolutely barren, aside from an unlimited buffet and an empty cabin with a huge stack of paper and some pens. After the novelty of the buffet wore off, how long would it take for you to get so bored that you start writing, drawing, folding the paper, or playing with the food and making different things? How long would it take for you to start creating and producing things?</p>
<p>Now imagine a clone of that island (let’s call this one Island 2) except along with the cabin, buffet, pen and paper, you have a magical rock. This magical rock is the gateway to an endless catalog of entertainment, media, books, shows, news, comics, articles, games.</p>
<p>Now how long would it take for you to start creating and producing things on Island 2, and how would you feel about it?</p>
<hr>
<p>My goal is to go on my computer this morning and write this blog post. Unfortunately I live on Island 2. I have to use some willpower to not check the news, or browse social media and see what the world is up to. The very nature of my computer, my smartphone, my tablet, my smart speaker, all these devices that can connect me to an endless catalog of entertainment, makes it so that a state of distraction saturates my life. The side effect of this life is that the anticipation of doing something ‘productive’ fills me with a sense of dreadful obligation.</p>
<p>If I lived on the barren Island 1, this task of writing a blog post would be the farthest thing from an obligation, it would be a massively welcome oasis in the desert of boredom that I would be stewing in. Focus, distraction, would not be concepts I would even have to think about because I would be jumping at the opportunity to do something other than stare at the wall. I would have been so full of boredom just waiting to be burnt to make something.</p>
<p>This example is extreme but it highlights the obvious ability for boredom to drive us to do something, to create, change or produce something. The uncomfortable state of doing absolutely nothing generates boredom, which fuels us with the drive to do something to get out of that state.</p>
<p>Boredom acts like a pressure that builds up within us. After a certain point, it becomes extremely uncomfortable to hold in, and we feel the need to release it. We all learn as kids or teenagers that entertainment is a black hole for boredom, it can eat up a seemingly endless amount of our boredom, so as we grow up, we use most of our leisure time (and sometimes more than just our leisure time) engaging in this systemic destruction of our boredom.</p>
<p>Unfortunately we may have gotten too good at it.</p>
<hr>
<p><img src="https://realisticwanderlust.com/assets/images/boredom-fuel/boredom-graph.jpg" alt=""></p>
<p>Boredom as shown on Island 1, and evidenced by the universal anecdote of ‘I did it because I was bored’, can fuel productivity and creativity but it’s rarely remembered as a driving force to create. Other more fuels of productivity and creativity are vastly more popular: survival/necessity (an increasingly rare motivator for those of us fortunate to live in developed countries), willpower and inspiration. The latter mental resources are some of our favorite fuels when we try and ‘be more productive’ or ‘create’. But although they can be effective, we are all too familiar with the ill side effects of relying solely on willpower or inspiration to help us get things done: we procrastinate or we burn out.</p>
<p>However if boredom is the fuel for your productivity and creativity, it produces none of these nasty by products. If you’re writing out of boredom, the concept of procrastinating on the task is ridiculous. If you’re building something because you’re bored, the concept of burning out makes no sense.</p>
<p>But how do we direct boredom to drive us to the things we want to get done? Well we don’t have any playbooks yet, because we’ve vilified it too much to explore the possibilities on a mainstream scale. We’ve been taught that being bored is a waste of time: <em>Carpe Diem, YOLO, Live every day as if it were your last</em>. These mainstream mantras are the antithesis of the engine of boredom. We tell ourselves we don’t have time to be bored, there’s too much to do and we need to do all of it. So we drive ourselves to the edge of our limited capacity of willpower and run on what small fumes of inspiration we have sputtering from our brains. Often, we produce more frustration than results. We spend large chunks of time procrastinating, dreading the things we have to push ourselves to do, and eventually we’ll need to recover from the inevitable burn out of squeezing our willpower and inspirations dry.</p>
<p>Yet this resource called boredom, that we all know can motivate us to create and produce things, piles up for free in our brains. We can’t even get rid of it fast enough, it keeps coming back, replenishing naturally, no matter what we do. We invent new forms of entertainment, gadgets and activities to try and decimate it, but it defies every attempt to clear it for good and inevitably comes back, more plentiful than before. What a crazy, endlessly renewable resource. </p>
<p>What if we experimented and learned how to harness it to fuel the things we want to do, instead of disregarding it because of it’s rough edges.</p>
<hr>
<p><em>I’ve been practicing letting myself be bored for about 4 weeks now, just to see what happens. Instead of reaching for my screens as soon as I feel a little sprout of boredom poking out, I just do nothing, maybe stare out the window. Initially it was awkward and uncomfortable but after a while it became very refreshing. I find myself more focused, clear headed, and looking forward to work and writing because I’m so bored. Also my house is the cleanest and most organized it has ever been.</em></p>

        
        </div>
        
    </div>
    
        
  <nav id="article-nav">
      
      
          <a href="https://realisticwanderlust.com/2020/04/27/photo-journal-shanghai/" id="article-nav-older">
              <strong>Previous Post</strong>

              
              <img src="https://realisticwanderlust.com/assets/images/photo-journal-shanghai/banner.jpg">

              <p>Living for a Month in Shanghai</p>
<p>
    
    
    7 minutes Read (About 1065 Words)
</p>
              <p>I arrived in Shanghai via train on February 6th, 2019; I did not know that this would be the last stop on my trip. I came into this city with a different mindset. I didn’t care to explore or see the sights here, I wanted a place to call home for a while, so that I wouldn’t have to be constantly planning where I was going to sleep the follow week. I also wanted to see if I would enjoy living in a busy urban city like Shanghai. I’ve traveled many times to...</p>

          </a>
      
  </nav>


    
</article>


    
    


</section>
            
                

            
        </div>
        

        


    
        
        
        
        
        
        
        
        
        
    
    
        
    
    



<!-- Custom Scripts -->


    </div></div>]]>
            </description>
            <link>https://realisticwanderlust.com/2020/06/29/boredom-fuels-productivity-creativity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678732</guid>
            <pubDate>Mon, 29 Jun 2020 15:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The History of Usenet and FidoNet]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23678687">thread link</a>) | @cfmcdonald
<br/>
June 29, 2020 | https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Between roughly 1975 and 1995, access to computers accelerated much more quickly than access to computer networks. First in the United States, and then in other wealthy countries, computers became commonplace in the homes of the affluent, and nearly ubiquitous in institutions of higher education. But if users of those computers wanted to connect their machines together – to exchange email, download software, or find a community where they could discuss their favorite hobby, they had few options. Home users could connect to services like CompuServe. But, until the introduction of flat monthly fees in the late 1980s, they charged by the hour at rates relatively few could afford. Some university students and faculty could connect to a packet-switched computer network, but many more could not. By 1981, only about 280 computers had access to ARPANET. CSNET and BITNET would eventually connect hundreds more, but they only got started in the early 1980s. At that time the U.S. counted more than 3,000 institutions of higher education, virtually all of which would have had multiple computers, ranging from large mainframes to small workstations.</p>
<p>Both communities, home hobbyists and those academics who were excluded from the big networks, turned to the same technological solution to connect to one another. They hacked the plain-old telephone system, the Bell network, into a kind of telegraph, carrying digital messages instead of voices, and relaying messages from computer to computer across the country and the world.</p>
<p>These were among the earliest peer-to-peer computer networks. Unlike CompuServe and other such centralized systems, onto which home computers latched to drink down information like so many nursing calves, information spread through these networks like ripples on a pond, starting from anywhere and ending up everywhere. Yet they still became rife with disputes over politics and power. In the late 1990s, as the Internet erupted into popular view, many claimed that it would flatten social and economic relations. By enabling anyone to connect with anyone, the middle men and bureaucrats who had dominated our lives would find themselves cut out of the action. A new era of direct democracy and open markets would dawn, where everyone had an equal voice and equal access. Such prophets might have hesitated had they reflected on what happened on Usenet and Fidonet in the 1980s. Be its technical substructure ever so flat, every computer network is embedded within a community of human users. And human societies, no matter how one kneads and stretches, always seem to keep their lumps.</p>
<h2>Usenet</h2>
<p>In the summer of 1979, Tom Truscott was living the dream life for a young computer nerd. A grad student in computer science at Duke University with an interest in computer chess, he landed an internship at Bell Labs’ New Jersey headquarters, where he got to rub elbows with the creators of Unix, the latest craze to sweep the world of academic computing.</p>
<p>The origins of Unix, like those of the Internet itself, lay in the shadow of American telecommunications policy. Ken Thompson and Dennis Ritchie of Bell Labs decided in the late 1960s to build a leaner, much pared-down version of the massive MIT Multics system to which they had contributed as software developers. The new operating system quickly proved a hit within the labs, popular for its combination of low overhead (allowing it to run on even inexpensive machines) and high flexibility. However, AT&amp;T could do little to profit from their success. A 1956 agreement with the Justice Department required AT&amp;T to license non-telephone technologies to all comers at a reasonable rate, and to stay out of all business sectors other than supplying common carrier communications.</p>
<p>So AT&amp;T began to license Unix to universities for use in academic settings on very generous terms. These early licensees, who were granted access to the source code, began building and selling their own Unix variants, most notably the Berkeley Software Distribution (BSD) Unix created at the the University of California’s flagship campus. The new operating system quickly swept academia. Unlike other popular operating systems, such as the DEC TENEX / TOPS-20, it could run on hardware from a variety of vendors, many of them offering very low-cost machines. And Berkeley distributed the software for only a nominal fee, in addition to the modest licensing fee from AT&amp;T.<sup id="fnref-13802-fee"><a href="#fn-13802-fee">1</a></sup></p>
<p>Truscott felt that he sat at the root of all things, therefore, when he got to spend the summer as Ken Thompson’s intern, playing a few morning rounds of volleyball before starting work at midday, sharing a pizza dinner with his idols, and working late into the night slinging code on Unix and the C programming language. He did not want to give up the connection to that world when his internship ended, and so as soon as he returned to Duke in the fall, he figured out how to connect the computer science department’s Unix-equipped PDP 11/70 back to the mothership in Murray Hill, using a program written by one of his erstwhile colleagues, Mike Lesk. It was called <em><span>uucp</span></em> – Unix to Unix copy – and it was one of a suite of “uu” programs new to the just-released Unix Version 7, which allowed one Unix system to connect to another over a modem. Specifically, <em>uucp</em> allowed one to copy files back and forth between the two connected computers, which allowed Truscott to exchange email with Thompson and Ritchie.</p>
<figure data-shortcode="caption" id="attachment_14009" aria-describedby="caption-attachment-14009"><img data-attachment-id="14009" data-permalink="https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/truscott/" data-orig-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg" data-orig-size="171,187" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="truscott" data-image-description="" data-medium-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=171" data-large-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=171" src="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=739" alt="truscott" srcset="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg 171w, https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=137 137w" sizes="(max-width: 171px) 100vw, 171px"><figcaption id="caption-attachment-14009">Undated photo of Tom Truscott</figcaption></figure>
<p>It was Truscott’s fellow grad student, Jim Ellis, who had installed the new Version 7 on the Duke computer, but even as the new upgrade gave with one hand, it took away with the other. The news program that was distributed by the Unix users’ group, USENIX, which would broadcast news items to all users of a given Unix computer system, no longer worked on the new operating ssytem. Truscott and Ellis decided they would replace it with their own 7-compatible news program, with more advanced features, and return their improved software back to the community for a little bit of prestige.</p>
<p><span>At this same time, Truscott was also using <em>uucp</em> to connect with a Unix machine at the University of North Carolina ten miles to the southwest in Chapel Hill, and talking to a grad student there named Steve Bellovin.<sup id="fnref-13802-bellovin"><a href="#fn-13802-bellovin">2</a></sup> Bellovin had also started building his own news program, which notably included the concept of topic-based <em>newsgroups</em>, to which one could subscribe, rather than only having a single broadcast channel for all news. Bellovin, Truscot and Ellis decided to combine their efforts and build a networked news system with newsgroups, that would use <em>uucp</em> to share news between sites. They intended to distributed provide Unix-related news for USENIX members, so they called their system Usenet.&nbsp;</span></p>
<p>Duke would serve as the central clearinghouse at first, using its auto-dialer and <em>uucp</em> to connect to each other site on the network at regular intervals, in order to pick up it local news updates and deposit updates from its peers. Bellovin wrote the initial code, but it used shell scripts that operated very slowly, so Stephen Daniel, another Duke grad student, rewrote the program in C. Daniel’s version became know as A News. Ellis promoted the program at the January 1980 Usenix conference in Boulder, Colorado, and gave away all eighty copies of the software that he had brought with him. By the next Usenix conference that summer, the organizers had added A News to the general software package that they distributed to all attendees.</p>
<p>The creators described the system, cheekily, as a “poor man’s ARPANET.” Though one may not be accustomed to thinking of Duke as underprivileged, it did not have the clout in the world of computer science necessary at the time to get a connection to that premiere American computer network. But access to Usenet required no one’s permission, only a Unix system, a modem, and the ability to pay the phone bills for regular news transfers, requirements that virtually any institution of higher education could meet by the early 1980s.</p>
<p>Private companies also joined up with Usenet, and helped to facilitate the spread of the network. Digital Equipment Corporation (DEC) agreed to act as an intermediary between Duke and UC Berkeley, footing the long-distance telephone bills for inter-coastal data transfer. This allowed Berkeley to become a second, west-coast hub for Usenet, connecting up UC San Francisco, UC San Diego, and others, including Sytek, an early LAN business. The connection to Berkeley, an ARPANET site, also enabled cross-talk between ARPANET and Usenet (after a second re-write by Mark Horton and Matt Glickman to create B News). ARPANET sites began picking up Usenet content and vice versa, though ARPA rules technically forbid interconnection with other networks. The network grew rapidly, from fifteen sites carrying ten posts a day in in 1980, to 600 sites and 120 posts in 1983, and 5000 sites and 1000 posts in 1987.<sup id="fnref-13802-sitesandposts"><a href="#fn-13802-sitesandposts">3</a></sup></p>
<p>Its creators had originally conceived Usenet as a way to connect the Unix user community and discuss Unix developments, and to that end they created two groups, <em>net.general</em> and <em>net.v7bugs</em> (the latter for discussing problems with the latest version of Unix). However they left the system entirely open for expansion. Anyone was free to create a new group under “net”, and users very quickly added non-technical topics such as <em>net.jokes</em>. Just as one was free to send whatever one chose, recipients could also ignore whatever groups they chose, e.g. a system could join Usenet and request data only for <em>net.v7bugs,</em> ignoring the rest of the content. Quite unlike the carefully planned ARPANET, Usenet self-organized, and grew in an anarchic way overseen by no central authority.</p>
<p>Yet out of this superficially democratic medium a hierarchical order quickly emerged, with a certain subset of highly-connected, high-traffic sites recognized as the “backbone” of the system. This process developed fairly naturally. Because each transfer of data from one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/">https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678687</guid>
            <pubDate>Mon, 29 Jun 2020 15:52:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Government of India has decided to ban on 59 Chinese apps, including Tik Tok]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23678438">thread link</a>) | @ericzawo
<br/>
June 29, 2020 | https://www.indiatoday.in/india/story/centre-announces-ban-chinese-apps-privacy-issues-1695265-2020-06-29 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/india/story/centre-announces-ban-chinese-apps-privacy-issues-1695265-2020-06-29">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The government of India has decided to ban 59 apps of Chinese origin as border tensions simmer in Ladakh after a violent, fatal face-off between the Indian and Chinese armies. The list of apps banned by the government includes TikTok, which is extremely popular.</p><p>The government announced the ban on the 59 Chinese apps (full list below) Monday night. The government said these apps were engaged in activities that were prejudicial to the sovereignty, integrity and defence of India.</p><p>A government press release announcing the ban stated: "The Ministry of Information Technology, invoking it’s power under section 69A of the Information Technology Act read with the relevant provisions of the Information Technology (Procedure and Safeguards for Blocking of Access of Information by Public) Rules 2009 and in view of the emergent nature of threats has decided to block 59 apps since in view of information available they are engaged in activities which is prejudicial to sovereignty and integrity of India, defence of India, security of state and public order".</p><p>The press release further said that the Ministry of Information Technology has received "many representations raising concerns from citizens regarding security of data and risk to privacy relating to operation of certain apps".</p><p><a href="https://www.indiatoday.in/technology/news/story/tiktok-us-web-shareit-mi-video-call-and-over-50-other-chinese-apps-banned-by-india-full-list-here-1695272-2020-06-29" target="_blank"><strong>SEE FULL LIST OF BANNED CHINESE APPS HERE</strong></a></p><p>"The Computer Emergency Response Team (CERT-IN) has also received many representations from citizens regarding security of data and breach of privacy impacting upon public order issues," the press release mentioned.</p><p>It further says that the move to ban these Chinese apps move will "safeguard the interests of crores of Indian mobile and internet users". This decision is a targeted move to ensure safety and sovereignty of Indian cyberspace, it said.</p><p><span><strong>Chinese apps' popularity deteriorated after Galwan clash</strong></span></p><p>Earlier this month, data from the Finland-based mobile-ranking platform, AppFollow, indicated that applications like TikTok have borne the brunt of Indian anger over Ladakh tensions.</p><p>The popular short-form video app was ranked 5 in top-ten free applications on Apple’s platform in India before the May 5 scuffle between Indian and Chinese troops.</p><p>A month later, TikTok slipped down to number 10 on App Store.</p><p>Among Android users, the same Chinese application dropped from number 3 to number 5 in India ranking.</p><p>But it still remained on the list of top-ten popular apps in India.</p><p><span><strong>India not the only country to act against Chinese apps</strong></span></p><p>The move to ban these Chinese apps predates violent faceoff at LAC in Ladakh. The government had issued an advisory on April 16 in this regard in the wake of security concerns over zoom meetings.</p><p>India is not the only country to act against Chinese apps citing privacy and cyber security issues. Taiwan has banned some Chinese apps. So has Germany including zoom.</p><p>Earlier, the US national security advisor Robert O'Brian had said all Chinese apps function as arms of the Communist Party of China (CPC) to further its ideological and geopolitical agendas.</p><p>The move was speeden up after June 15 clashes between Indian and Chinese troops.</p><p><span><strong>Popularity of Tik Tok in India</strong></span></p><p>Popular among youngsters, TikTok has the maximum number of users in India, followed by China and the US.</p><p>TikTok crossed the 2 billion mark soon after surpassing the 1.5 billion mark in the first quarter of 2020. Out of the 2 billion, India turned out to be the biggest driver with over 611 million downloads.</p><p>According to the report by Sensor Tower, TikTok’s surge in popularity was due to the coronavirus pandemic. People found TikTok to be most entertaining and engaging in quarantine.</p><div><p><span><strong>Here's a list of the apps that have been banned by the government:</strong></span></p><p>TikTok<br>Shareit<br>Kwai<br>UC Browser<br>Baidu map<br>Shein<br>Clash of Kings<br>DU battery saver<br>Helo<br>Likee<br>YouCam makeup<br>Mi Community<br>CM Browers<br>Virus Cleaner<br>APUS Browser<br>ROMWE<br>Club Factory<br>Newsdog<br>Beutry Plus<br>WeChat<br>UC News<br>QQ Mail<br>Weibo<br>Xender<br>QQ Music<br>QQ Newsfeed<br>Bigo Live<br>SelfieCity<br>Mail Master<br>Parallel Space<br>Mi Video Call Xiaomi<br>WeSync<br>ES File Explorer<br>Viva Video QU Video Inc<br>Meitu<br>Vigo Video<br>New Video Status<br>DU Recorder<br>Vault- Hide<br>Cache Cleaner DU App studio<br>DU Cleaner<br>DU Browser<br>Hago Play With New Friends<br>Cam Scanner<br>Clean Master Cheetah Mobile<br>Wonder Camera<br>Photo Wonder<br>QQ Player<br>We Meet<br>Sweet Selfie<br>Baidu Translate<br>Vmate<br>QQ International<br>QQ Security Center<br>QQ Launcher<br>U Video<br>V fly Status Video<br>Mobile Legends<br>DU Privacy</p></div></div><div><p><em><strong>IndiaToday.in</strong> has plenty of useful resources that can help you better understand the coronavirus pandemic and protect yourself. <a href="https://www.indiatoday.in/india/story/coronavirus-pandemic-covid-19-precautions-symptoms-global-impact-complete-guide-1657761-2020-03-20" target="_blank">Read our comprehensive guide</a> (with information on how the virus spreads, precautions and symptoms), <a href="https://www.indiatoday.in/newsmo/video/coronavirus-outbreak-5-big-myths-busted-1654318-2020-03-11" target="_blank">watch an expert debunk myths</a>, and access our <a href="https://www.indiatoday.in/coronavirus" target="_blank">dedicated coronavirus page</a>.</em></p></div><div><p>Get real-time alerts and all the <a href="https://www.indiatoday.in/news.html">news</a> on your phone with the all-new India Today app. Download from</p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/india/story/centre-announces-ban-chinese-apps-privacy-issues-1695265-2020-06-29</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678438</guid>
            <pubDate>Mon, 29 Jun 2020 15:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worrying about the NPM Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23678409">thread link</a>) | @diiq
<br/>
June 29, 2020 | https://sambleckley.com/writing/npm.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/npm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3>
<p>The <acronym>npm</acronym> ecosystem seems unwell. If you are concerned with security, reliability, or long-term maintenance, it is almost impossible to pick a suitable package to use — both because there are 1.3 million packages available, and even if you find one that is well documented and maintained, it might depend on hundreds of other packages, with dependency trees stretching ten or more levels deep — as one developer, it’s impossible to validate them all.</p>

<p>I spend some time measuring the extent of the problem.</p>

<p>I suggest that this is a social problem, more than a technical one, and propose a semi-social solution: a human-maintained subset of the total registry, based on shared criteria by which a “healthy” package can receive a seal of approval. One criterion would be to only depend on other approved packages.</p>

<h3 id="the-premise">The premise</h3>

<p>I don’t like the way I feel when I’m installing packages with npm. Selecting a package, installing it, discovering the 93 additional packages that were installed along with it, and hoping all of <em>them</em> are also suitable for my project… it feels out of control.</p>

<p>I feel unhappy because picking dependencies is hard, so I blame npm, and that way my problems are not my fault.</p>

<p>Is there some way for me to measure this badness, and thus more thoroughly escape the blame?</p>

<h3 id="thinking-a-bit-like-a-scientist-but-not-too-much">Thinking a bit like a scientist, but not too much</h3>

<p>Can we make meaningful empirical measurements of the health of the <acronym>npm</acronym> registry? I think so; but before I do, in order to maintain the slightest semblance of impartiality, I want to lay out what I <em>expect</em> a healthy package registry to look like. If it turns out that npm, taken as a whole, mostly looks the way I expect a healthy registry to look, I’ll have to put my tail between my legs and take ownership of my struggles. If it looks wildly different, I’ll still have hope for blaming the system.</p>

<h3 id="imagining-a-healthy-repository">Imagining a healthy repository</h3>

<p>In my ideal world there are, mostly, 4 types of packages:</p>

<ul>
  <li>
    <p><strong>Utilities:</strong></p>

    <p>A utility is a simple package, with no dependencies, that accomplishes a single small but onerous task. For example: lodash is a collection of utilities (and you can install each one separately). Controversially, left-pad.</p>
  </li>
  <li>
    <p><strong>Libraries:</strong></p>

    <p>A library is one step up in abstraction. It may depend on a handful of utilities, and it accomplishes a whole set of related tasks. For example: urlib has just a few simple dependencies, and while it does many things, it respects a clear unifying principle.</p>
  </li>
  <li>
    <p><strong>Frameworks:</strong></p>

    <p>A framework provides scaffolding for an entire project, and may depend on multiple libraries and utilities. You should only ever need zero or one of these in your project. Examples: React, angular, express.</p>
  </li>
  <li>
    <p><strong>Plugins:</strong></p>

    <p>A plugin enhances a framework with additional, special-use functionality. For a plugin, the framework should be a peer dependency, not a true dependency. It might also depend directly on a library, or a handful of utilities. Examples: an angular component or a jquery plugin.</p>
  </li>
</ul>

<p>Obviously, the world is messy! I don’t expect 100% of packages to fit into such simple categories, nor are any of these definitions strict and unyielding. But overall, I’d hope <em>many</em> or even <em>most</em> packages to <em>mostly</em> conform to a categorization <em>something</em> like that, with most packages being utilities and libraries, and the fewest packages being frameworks.</p>

<h3 id="what-would-that-mean-statistically">What would that mean statistically?</h3>

<p>In a world where packages fit mostly into that hierarchy, a registry of many packages would have these qualities:</p>

<ul>
  <li>No dependency cycles</li>
  <li>Most packages would have dependency trees 0-4 levels deep, leaning towards lower numbers</li>
  <li>Even the deepest and broadest frameworks would depend on fewer than 250 packages, including dependencies of dependencies (3-4 steps deep, with 3-4 dependencies per package, &lt;= 4<sup>4</sup> max). Most packages would install well under 30 other packages. These numbers are extremely generous; smaller numbers would make me even happier.</li>
</ul>

<h3 id="what-do-we-actually-see">What do we actually see?</h3>

<p>I downloaded the metadata for all 1.3 million packages in the npmjs.org repository and attempted to crunch some numbers. (For more technical details on how I did this, see the final section, titled “Appendix: Methods”)</p>

<p>I’m going to use “the number of other packages that depend on this one” as a poor-man’s proxy for how popular a package is. It’s not a <em>good</em> proxy, but neither is the other common choice: the number of downloads (see the section <a href="https://packaging.python.org/guides/analyzing-pypi-package-downloads/#background">“Background”</a>, from PyPI). The number of downloads would have been much more computationally expensive to acquire, so I used dependents.</p>

<h3 id="circular-dependencies">Circular dependencies</h3>

<p>Of those 1.3 million packages, 1,700 depend directly on themselves, either perfectly circularly, or a different version of the same package. I have no explanation for that.</p>

<p>2500 packages are part of a two-package dependency cycle.</p>

<p>Then ~500, ~125, and ~25 are part of 3-, 4-, and 5-package cycles, respectively. (These are not always simple circles; it may be three codependent packages in any loopy arrangement)</p>

<p>My immediate reaction was that those numbers seemed like good news; out of a million packages, only a tiny percentage of oddball packages have circular dependencies, and the rest are fine. Right?</p>

<p>Unfortunately, what I discovered was that almost 150,000 packages — more than 1 in 10 — had at least one of these circular dependencies <em>somewhere</em> in their dependency graph. That means at least a few of those “oddballs” are actually major, highly-referenced packages. Some examples:</p>

<ul>
  <li><code>babel-core</code> depends on <code>babel-register</code>, which depends on <code>babel-core</code>.</li>
  <li><code>yeoman-generator</code> depends on <code>yeoman-environment</code> which depends on <code>yeoman-generator</code>.</li>
</ul>

<p>Those are not isolated instances; I plucked them as the most easily recognizable out of a list of dozens of highly-depended-upon packages with circular dependencies.</p>

<p>I need to be clear, here, that this is not <em>technically</em> a problem! <acronym>npm</acronym> can install these packages just fine. They can circularly-depend on one another; there’s no technical problem. They work. Obviously. If <code>babel-core</code> didn’t work, someone would have said something by now.</p>

<p>But I’m not particularly comfortable with it. I’m especially uncomfortable when the cycles involved are longer than two packages, which makes them seem less intentional. Maybe there’s a good reason; these folks are smart, and I always try to assume that odd choices were made for important reasons. And yet…</p>

<h3 id="what-about-devdependencies">What about <code>devDependencies</code>?</h3>

<p>Among the most-depended-upon packages are</p>

<ul>
  <li><code>@types/</code>[something]</li>
  <li>compilers like <code>typescript</code> and <code>babel</code></li>
  <li>build systems like <code>gulp</code> and <code>webpack</code>.</li>
</ul>

<p>I’m <strong>not</strong> measuring that using <code>devDependencies</code> — <code>typescript</code> appears in over 12,000 “dependency” lists.</p>

<p>So while I am less concerned with packages having large and deep <code>devDependency</code> trees (I <em>am</em> still concerned, but less so), it seems that a large proportion of packages aren’t making use of the distinctions between <code>dependencies</code> and <code>devDependencies</code> in the first place. That <em>is</em> concerning.</p>

<h3 id="dependency-tree-depths">Dependency tree depths</h3>

<p>I am defining the depth of a package’s dependency tree as the longest dependency-of-a-dependency-of-a-dependency chain I can find. Especially deep dependency trees are a problem because of how difficult they make it to audit all the packages that will get installed when including a single new package.</p>

<p>The <em>average</em> dependency tree depth in npmjs.org is just under 4. Which doesn’t sound too bad!</p>

<p>As often happens, though, the mean does not tell the whole story. Almost half of all packages have no dependencies at all — which is a good thing! — but all those zeros dramatically drop the average of the packages that <em>do</em> have dependencies.</p>

<p>If we charted of the number of packages with each dependency tree depth greater than zero, then based on the idealized registry I imagined above, here’s what I’d hope to see:</p>

<p><strong>Imagined:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_ideal.svg" alt="Imaginary chart of package counts per tree depth"></p>

<p>And here’s what we actually get:</p>

<p><strong>Reality:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth.svg" alt="Real chart of package counts per tree depth"></p>

<p>Remember that we were hoping for mostly 2, 3, and 4. Instead, there is still a long tail of packages with tree depths <em>above 20</em>. 20 is… much larger than I was expecting, and I was expecting to be disappointed.</p>

<p>But let’s re-use the “oddball” theory: perhaps all those packages with extremely deep dependency trees are rarely used, and not worth worrying about. Let’s check.</p>

<p>Here’s a scatterplot, where each package is placed based on its tree depth plotted and how many other packages reference it. On the right of the plot are the most-referenced (~popular) packages; on the top are the deepest dependency trees. Again, my hopes first:</p>

<p><strong>Imagined:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_and_dependents_ideal.svg" alt="Imaginary scatterplot of package counts per tree depth"></p>

<p>Followed by reality:</p>

<p><strong>Reality:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_and_dependents.svg" alt="Real scatterplot of package counts per tree depth"></p>

<p>There are heaps of 10+ tree-depths up among even the most popular packages, and a few even reach 20+. Extremely deep trees are not just a problem of “oddball” packages.</p>

<h3 id="direct-dependencies-branching-factor">Direct dependencies (branching factor)</h3>

<p>The average number of direct dependencies (among packages with any dependencies at all) is 5. That, by itself, doesn’t seem to bad. It feels a little alarming when combined with high tree depths, though. Does that mean some of these packages have 5<sup>10</sup> total dependencies? (Spoiler: no.)</p>

<p>Here’s a graph of how many packages have 1 dependency, 2 dependencies… up to 30 — a nice, neat exponential decay.</p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_direct_dependencies.svg" alt="Chart of package counts per direct dependencies"></p>

<p>This curve is clean enough that I would not be surprised to see something pretty similar in any package registry — maybe not the exact same parameters, but a similar shape. Not shown here is an <em>incredibly</em> long tail; there are 4 packages tied for the most direct dependencies with exactly 1000, and there are runners-up spread pretty smoothly up to that maximum.</p>

<h3 id="indirect-dependencies">Indirect dependencies</h3>

<p>Knowing the average depth and branching factor, you have to imagine that counting the total dependencies of each package, including dependencies-of-dependencies, is not going to yield good news. But many of the branches of a large dependency tree are shared — multiple packages in the tree all depend on the same library. And the tree depth I have measured is the <em>maximum</em> depth for each package — not the average. So the picture is not necessarily as dire as an initial …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sambleckley.com/writing/npm.html">https://sambleckley.com/writing/npm.html</a></em></p>]]>
            </description>
            <link>https://sambleckley.com/writing/npm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678409</guid>
            <pubDate>Mon, 29 Jun 2020 15:21:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicToBrick is a software to generate mosaics from digital pictures]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23678400">thread link</a>) | @Tomte
<br/>
June 29, 2020 | http://www.pictobrick.de/en/pictobrick.shtml | <a href="https://web.archive.org/web/*/http://www.pictobrick.de/en/pictobrick.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centercontent">
	<!-- <img src="../pictures/sreen_frontpage_300_217.png" alt="Screenshot" /> -->
		
		
		<p>PicToBrick is a <span>software to generate mosaics</span> from digital pictures. The materials to construct the mosaic as well as their colours and forms can be chosen freely. For mosaics constructed  by <span>Ministeck®</span> and <span>LEGO®</span> PicToBrick provides complete system configurations. These configurations contain information for current colours and respectively forms of elements and can be modified and enlarged user-defined.</p>
		<p>To get results as good as possible for different master illustrations seven methods of  colour definition (quantisation) are at your disposal. In addition you can choose between five methods to define the element forms (tiling).</p>
		<p>Besides the produced mosaic picture PicToBrick provides a multitude of different output documents. Among other things they contain a list of materials, a construction manual as well as information about the utilised colours and forms of  material.</p>
		<p>PicToBrick was completely developed in <span>JAVA</span> and can be used <span>cross platform</span> (Windows, Linux, Mac). The software is published as <span>open source</span> under GPL2. Furthermore PricToBrick is <span>free</span>.</p>
		<p>For more information see the following pages in the menu.</p>
		<p><img src="http://www.pictobrick.de/pictures/main/frontpage_600_300.png" alt="Workflow"></p>
	</div><div id="bottomcontent">
	<p>Last modified on 2010/04/29 - Copyright 2006-2018 - <a href="mailto:pictobrick@t-reichling.de" rel="email">Tobias Reichling</a>, <a href="mailto:pictobrick@basezero.net" rel="email">Adrian Schütz</a></p>
	<p><a href="http://validator.w3.org/check?uri=referer" rel="external">XHTML 1.0 Validator</a>, <a href="http://jigsaw.w3.org/css-validator/check/referer" rel="external">CSS Validator</a>, optimal representation in <a href="http://www.mozilla.org/products/firefox" rel="external">Mozilla Firefox</a></p>
</div></div>]]>
            </description>
            <link>http://www.pictobrick.de/en/pictobrick.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678400</guid>
            <pubDate>Mon, 29 Jun 2020 15:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A simple Rust CLI for debugging transient errors]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23678270">thread link</a>) | @cbzehner
<br/>
June 29, 2020 | https://www.cbzehner.com/introducing-stress/ | <a href="https://web.archive.org/web/*/https://www.cbzehner.com/introducing-stress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>

<p>Introducing <a href="https://lib.rs/crates/stress"><code>stress</code>, a simple tool for debugging inconsistent errors</a>. No one likes seeing a test fail in (CI) and then pressing <code>Up</code> + <code>Enter</code> every 3 minutes locally to catch a flake!<sup><a href="https://cbzehner.com/introducing-stress/#lovemanuallytesting">1</a></sup></p>
<p>Try it out! <code>cargo install stress &amp;&amp; stress --output --bail -- ls -a</code></p>
<h2 id="motivation">Motivation</h2>
<p>This is frustratingly common in tests due to a variety of factors including</p>
<ul>
<li>Code-skew as the code changes without updating the tests</li>
<li>Poor test isolation</li>
<li>Transient errors as tests interact with multiple pieces of infrastructure. Ex: frontend + backend + database</li>
</ul>
<p>Often the fix is either <del>deleting the test</del><sup><a href="https://cbzehner.com/introducing-stress/#deletingflakes">2</a></sup> editing the test code or changing something about the environment where the test is running, increasing available memory or tweaking the config.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>Pass in a command say <code>ls -a</code> and it will be run a specified number of times (default: 10). The exit codes encountered and the number of occurrences will be printed out along with the command output (with the <code>--output</code> flag). </p>
<p>If all that's needed is to see if any runs fail there's a <code>--bail</code> flag that stops the program on the first command run that ends with a failure (non-zero exit code).</p>

<p>Definitely! That's also a great option if it works for you! A while-loop in bash should be sufficient, as one of my coworkers wisely pointed out.</p>
<p>So why do this, you might wonder? Just to scratch my own itch.</p>
<p>Next time I need to debug a test, I can focus on the problem instead of the tooling.</p>
<h2 id="thanks-for-reading">Thanks for reading</h2>
<p>Leave your thoughts and feedback <a href="https://github.com/cbzehner/stress/issues">on GitHub</a>.</p>
<p>If you're using <code>stress</code> <a href="https://github.com/cbzehner/stress/issues">let me know</a> how I can improve it for <em>you</em>.</p>
<h3 id="footnotes">Footnotes</h3>
<p><a name="lovemanuallytesting">1</a>: If you love manually trying to catch flakes...uh...🤯</p>
<p><a name="deletingflakes">2</a>: This is obviously a joke! But it's not always the wrong approach. Test flakes, especially in CI, are a burden on your entire engineering team. They slow down continuous development and reduce trust in the test suite. Empowering engineers to turn off flakes forces engineering teams to confront a <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>, failed CI runs.</p>
</div>

</article></div>]]>
            </description>
            <link>https://www.cbzehner.com/introducing-stress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678270</guid>
            <pubDate>Mon, 29 Jun 2020 15:08:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Service Workers Explained – Introduction to the JavaScript API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23678179">thread link</a>) | @fgerschau
<br/>
June 29, 2020 | https://felixgerschau.com/service-workers-explained-introduction-javascript-api/ | <a href="https://web.archive.org/web/*/https://felixgerschau.com/service-workers-explained-introduction-javascript-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group" id="gatsby-focus-wrapper"><div><div><div><div><div><p><span>
<a href="https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/c2d13/service-workers-explained-cover.png" target="_blank" rel="noopener">
<span></span>
<img alt="Service Workers Explained Thumbnail" title="Service Workers Explained Thumbnail" src="https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/5a190/service-workers-explained-cover.png" srcset="https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/772e8/service-workers-explained-cover.png 200w,https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/e17e5/service-workers-explained-cover.png 400w,https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/5a190/service-workers-explained-cover.png 800w,https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/c1b63/service-workers-explained-cover.png 1200w,https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/29007/service-workers-explained-cover.png 1600w,https://felixgerschau.com/static/f61937883cf90d31747372e52ce359ef/c2d13/service-workers-explained-cover.png 2560w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>On this blog, I already wrote a <a href="https://felixgerschau.com/tags/pwa">few articles about Progressive Web Apps (PWAs)</a> — including a full tutorial that
walks you through <a href="https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/">converting your React app into a PWA</a>.
Because Service Workers are such an important part of PWAs, I found myself explaining what they are over and over again.</p><p>This article is an introduction to the Service Worker API of JavaScript, walking you through the registration of a Service Worker that will serve
some content from the cache.</p><h5 id="table-of-contents"><a href="#table-of-contents" aria-label="table of contents permalink"></a>Table of Contents</h5><ul><li><p><a href="#what-are-service-workers">What are Service Workers?</a></p></li><li><p><a href="#how-can-i-register-a-service-worker">How can I register a Service Worker?</a></p></li><li><p><a href="#what-features-do-service-workers-enable">What features do Service Workers enable?</a></p><ul><li><a href="#offline-capabilities">Offline capabilities</a></li><li><a href="#periodic-background-syncs">(Periodic) background syncs</a></li><li><a href="#push-notifications">Push notifications</a></li></ul></li><li><p><a href="#service-worker-browser-support">Service Worker Browser Support</a></p></li><li><p><a href="#conclusion">Conclusion</a></p></li><li><p><a href="#further-reading">Further reading</a></p></li></ul><undefined></undefined><h2 id="what-are-service-workers"><a href="#what-are-service-workers" aria-label="what are service workers permalink"></a>What are Service Workers?</h2><blockquote><p><em>A Service Worker is a scriptable network proxy in a web browser that manages network requests for a webpage.</em> — Wikipedia</p></blockquote><video autoplay="" muted="" loop=""><source src="https://felixgerschau.com/video/service-worker-explained-animation.mp4" type="video/mp4"></video><p>Service Workers enable a set of features that previously were exclusive to native applications.
The first draft for Service Workers has been <a href="https://www.w3.org/TR/2014/WD-service-workers-20140508/">published in 2014</a> and now they are supported by <a href="https://jakearchibald.github.io/isserviceworkerready/">all major browsers</a>.</p><p>Like the definition already pointed out, Service Workers are network proxies. This means that that they can <strong>control all
network requests</strong> from the page and they can be programmed to respond with a <strong>cached response</strong>.</p><p>Just like Web Workers, their code is executed in a <strong>separate thread</strong>, which allows them to be active even though all tabs of the webpage are closed.
The browser, however, will terminate and re-activate them depending on whether they are being used or not.</p><p>The Service Worker API <strong>relies heavily on promises</strong>, which is why it's recommended to learn about them first. A good point to start if you're new to
promises is <a href="https://web.dev/promises/">Google's developer blog</a>.</p><h2 id="how-can-i-register-a-service-worker"><a href="#how-can-i-register-a-service-worker" aria-label="how can i register a service worker permalink"></a>How can I register a Service Worker?</h2><p>Registering a Service Worker doesn't involve much code at all. All you need is a JavaScript file
for the Service Worker code (I'll call it <code>service-worker.js</code>) and a place in your application where you'll register it.
In my example, <code>service-worker.js</code> is located at the root of the project and hosted under the same domain.</p><div data-language="javascript"><pre><code>
<span>if</span> <span>(</span><span>'serviceWorker'</span> <span>in</span> navigator<span>)</span> <span>{</span>
<span>  navigator<span>.</span>serviceWorker</span><span>    <span>.</span><span>register</span><span>(</span><span>'/service-worker.js'</span><span>)</span></span>    <span>.</span><span>then</span><span>(</span><span>function</span><span>(</span><span>registration</span><span>)</span> <span>{</span>
      console<span>.</span><span>log</span><span>(</span>registration<span>)</span><span>;</span>
    <span>}</span><span>)</span>
    <span>.</span><span>catch</span><span>(</span><span>function</span><span>(</span><span>err</span><span>)</span> <span>{</span>
      console<span>.</span><span>log</span><span>(</span>err<span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Place this code somewhere in your project where it will always be called.</p><h2 id="what-features-do-service-workers-enable"><a href="#what-features-do-service-workers-enable" aria-label="what features do service workers enable permalink"></a>What features do Service Workers enable?</h2><p>In this section, I'll go a little more into detail about the features of Service Workers, including some small code
examples.</p><p>Service Workers enable the following features, which are the core of Progressive Web Apps:</p><ul><li>Offline capabilities</li><li>Periodic background syncs</li><li>Push notifications</li></ul><h3 id="offline-capabilities"><a href="#offline-capabilities" aria-label="offline capabilities permalink"></a>Offline capabilities</h3><blockquote><p><em>Since this is the main selling point of Service Workers, I'll go a little more into the details of how this works.</em></p></blockquote><p>Service Workers provide offline capabilities by <strong>caching</strong> resources and <strong>intercepting</strong> network requests, which can
be served with the previously cached resources instead of requesting the server.</p><p>We can derive two steps from this:</p><ul><li>Precaching</li><li>Serving requests from the cache</li></ul><p>Both of these steps make use of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Cache">Cache API</a>, which can be used by Web Workers and the browser and which provides us
with a <strong>storage mechanism for network requests</strong>.</p><p>Access to localStorage is blocked for the context of Web- and Service Workers to prevent concurrency issues.
As an alternative, IndexedDB can be used for storing larger amounts of data.</p><h4 id="precaching"><a href="#precaching" aria-label="precaching permalink"></a>Precaching</h4><p>Precaching is a term that describes downloading and caching files <em>before</em> the Service Worker becomes active.
It's done during the "<a href="https://felixgerschau.com/service-worker-lifecycle-update#installing">Installing</a>" step of the Service Worker's lifecycle.
Once the Service Worker has become active, it will then be ready to serve the files from the cache.</p><blockquote><p><em>I wrote an entire <a href="https://felixgerschau.com/service-worker-lifecycle-update">article on the Service Worker lifecycle</a>, which is why I won't go deeper on this topic right now.</em></p></blockquote><p>Usually, we want to cache the <a href="https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/#application-shell">Application Shell</a>,
which is the minimal amount of code required to run your website. It's the <strong>bundle of code that you would upload to
an app store</strong> if you developed a native application. This includes all the basic JavaScript, HTML, and pictures necessary.</p><p>service-worker.js</p><div data-language="javascript"><pre><code>self<span>.</span><span>addEventListener</span><span>(</span><span>'install'</span><span>,</span> <span>function</span><span>(</span><span>event</span><span>)</span> <span>{</span>
  event<span>.</span><span>waitUntil</span><span>(</span>
    caches<span>.</span><span>open</span><span>(</span>currentCache<span>.</span>offline<span>)</span><span>.</span><span>then</span><span>(</span><span>function</span><span>(</span><span>cache</span><span>)</span> <span>{</span>
      <span>return</span> cache<span>.</span><span>addAll</span><span>(</span><span>[</span>
        <span>'/static/images/offline.svg'</span><span>,</span>
        <span>'/static/html/offline.html'</span><span>,</span>
      <span>]</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
  <span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre></div><p> In case you wonder: The <code>waitUntil</code> function is part of the <em>ExtendableEvent</em> interface, which is only available
for the <code>install</code> and <code>activate</code> events of the Service Worker (read the documentation <a href="https://developer.mozilla.org/en-US/docs/Web/API/ExtendableEvent">here</a>).</p><h5 id="what-about-bundled-files"><a href="#what-about-bundled-files" aria-label="what about bundled files permalink"></a>What about bundled files?</h5><p>You might not always know the name of the files you want to precache because you are using a bundler that auto-generates
files with hashes in their names (like Webpack or Rollup for example).</p><p>For those cases, you can use <a href="https://developers.google.com/web/tools/workbox">Workbox</a>,
which provides tools that integrate into your build and automatically create a precaching list for you
(check out the Workbox plugin for <a href="https://www.npmjs.com/package/rollup-plugin-workbox">Rollup</a> and <a href="https://www.npmjs.com/package/workbox-webpack-plugin">Webpack</a>).</p><h4 id="serving-requests-from-the-cache"><a href="#serving-requests-from-the-cache" aria-label="serving requests from the cache permalink"></a>Serving requests from the cache</h4><p>At this stage we already have all our application code stored in the cache and the Service Worker has become active and is controlling the page.</p><p>Now the only thing missing is listening to the <code>fetch</code> event and returning results from the cache.</p><p>service-worker.js</p><div data-language="javascript"><pre><code>self<span>.</span><span>addEventListener</span><span>(</span><span>'fetch'</span><span>,</span> <span>function</span><span>(</span><span>event</span><span>)</span> <span>{</span>
  event<span>.</span><span>respondWith</span><span>(</span>
    caches<span>.</span><span>match</span><span>(</span>event<span>.</span>request<span>)</span><span>.</span><span>then</span><span>(</span><span>function</span><span>(</span><span>response</span><span>)</span> <span>{</span>
      <span>return</span> response <span>||</span> <span>fetch</span><span>(</span>event<span>.</span>request<span>)</span><span>;</span>
    <span>}</span><span>)</span>
  <span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre></div><p>In this case, we respond with the cached content whenever possible. As a fallback, we make a network request.</p><p>This is called a <strong>cache first</strong> strategy. There are a few others, like <strong>network first</strong>, <strong>cache only</strong> and <strong>network only</strong>.
The names are already pretty self-explaining but if you want to read more about it you can read more on
<a href="https://developers.google.com/web/ilt/pwa/caching-files-with-service-worker">Google's developer blog</a>.</p><h3 id="periodic-background-syncs"><a href="#periodic-background-syncs" aria-label="periodic background syncs permalink"></a>(Periodic) background syncs</h3><p>As I already mentioned in the introduction, Service Workers run on a <strong>separate thread</strong> from the other Service Workers and they can even
execute their code when the page is closed. This ability is important for doing background synchronizations and providing push notifications.</p><p>I put "periodic" in parentheses because background syncs and periodic background syncs are not quite the same.
So let's have a look at what they can do:</p><h4 id="background-syncs"><a href="#background-syncs" aria-label="background syncs permalink"></a>Background syncs</h4><p>Background syncs are usually used for synchronizing data after the user navigated away from the page.</p><p>As an example, after editing a document on your phone you will hit "save" and leave the page. If your internet
connection drops during editing the document, you would have to wait for the connection to come back
to save the document.</p><p>Background syncs intend to solve this problem by <strong>automatically sending the data once the connection is re-established</strong>.</p><p>Instead of actively waiting for the connection to come back, your UI can give immediate feedback that the changes will be saved
in the background and you can put the phone back without losing time.</p><p>Let's have a look at a code example:</p><p>app.js</p><div data-language="javascript"><pre><code>navigator<span>.</span>serviceWorker<span>.</span>ready<span>.</span><span>then</span><span>(</span><span>(</span><span>registration</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> registration<span>.</span>sync<span>.</span><span>register</span><span>(</span><span>'sync-save-document'</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre></div><p>This codes registers a one-time sync in the Service Worker.</p><p>service-worker.js</p><div data-language="javascript"><pre><code>self<span>.</span><span>addEventListener</span><span>(</span><span>'sync'</span><span>,</span> <span>(</span><span>event</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>event<span>.</span>tag <span>===</span> <span>'sync-save-document'</span><span>)</span> <span>{</span>
    event<span>.</span><span>waitUntil</span><span>(</span><span>saveDocument</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre></div><p>We can identify the sync by its <code>tag</code> attribute.</p><p><code>saveDocument</code> is a function that returns a promise that can either be resolved or rejected. If it's being rejected — due to
network issues for example — the sync will automatically try again.</p><p>One important thing to note is that the <strong>sync tags have to be unique</strong>. If I want to schedule 5 background syncs of the type
"message" for example, only the last one will go through. That's why in this case, each tag should have a unique identifier.</p><h4 id="periodic-background-syncs-1"><a href="#periodic-background-syncs-1" aria-label="periodic background syncs 1 permalink"></a>Periodic background syncs</h4><p>Periodic background syncs are supposed to solve a different problem than normal background syncs. This API can be used
for <strong>updating data in the background</strong> without having to wait for any interaction of the user.</p><p>This can be useful for a broad range of apps. With this technology, the user might be able to read the latest news articles without
having an internet connection.</p><p>To prevent websites from abusing this, <strong>the frequency of those synchronizations depends on the site-engagement score</strong>,
which the browser sets for every website. If you open a specific web app a lot, this frequency can go up to a maximum of 12 hours.</p><p>Another requirement for this to work is that the website is installed and added to the home screen as a Progressive Web App on mobile
devices.</p><p>At the time of writing this article, the <code>periodicSync</code> API is only supported by Chrome (v80) and Edge and thus not ready for
production use.</p><h3 id="push-notifications"><a href="#push-notifications" aria-label="push notifications permalink"></a>Push notifications</h3><p>Another native-like feature that Service Workers enable is push-notifications.
We usually know them from our phones in the form of messages or social media notifications, but they are also available on desktop computers.</p><p>They are supported on <strong>all major browsers except Safari</strong>, which has its own implementation for the desktop app.</p><p>To use push notifications, you need to set up a server, that will be <em>pushing</em> the notification to all clients.
Since the Service Worker runs in the background on a different thread, the user will be able to see push notifications <strong>even though
the page isn't currently open</strong>.</p><blockquote><p><em>The implementation is a little more complicated and worth of an article on its own, that's why I won't include any code examples
here. You can check out <a href="https://developers.google.com/web/ilt/pwa/introduction-to-push-notifications">this introduction</a> if you are curious.</em></p></blockquote><h2 id="service-worker-browser-support"><a href="#service-worker-browser-support" aria-label="service worker browser support permalink"></a>Service Worker Browser Support</h2><p data-feature="serviceworkers" data-periods="future_1,current,past_1,past_2" data-accessible-colours="false">
<picture>
<source type="image/webp" srcset="https://caniuse.bitsofco.de/image/serviceworkers.webp">
<source type="image/png" srcset="https://caniuse.bitsofco.de/image/serviceworkers.png">
<img src="https://caniuse.bitsofco.de/image/serviceworkers.jpg" alt="Data on support for the serviceworkers feature across the major browsers from caniuse.com">
</picture>
</p><p>Nowadays, Service Workers are widely supported and ready to be used in production. Features like periodic background sync aren't ready yet but
the core, which is providing a rich offline experience, is supported by all modern browsers.</p><p>It's good to remember that Service Workers are part of Progressive Web Apps, where <em>progressive</em> means enhancing functionality.
This means that even though parts of it won't work in all …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://felixgerschau.com/service-workers-explained-introduction-javascript-api/">https://felixgerschau.com/service-workers-explained-introduction-javascript-api/</a></em></p>]]>
            </description>
            <link>https://felixgerschau.com/service-workers-explained-introduction-javascript-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678179</guid>
            <pubDate>Mon, 29 Jun 2020 14:58:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Saleswhale Email Webinar AI Assistant (Free Tool)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23678024">thread link</a>) | @sg_gabriel
<br/>
June 29, 2020 | https://www.saleswhale.com/webinar-ai-assistant | <a href="https://web.archive.org/web/*/https://www.saleswhale.com/webinar-ai-assistant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_1593024113883237" data-hs-cos-general-type="widget" data-hs-cos-type="module"><section>
  <div>
    
    <h3>Automating inhuman work for your marketing team</h3>
    <p><span>Here's how it works.</span></p><p>Your Webinar Email AI assistant sends a natural, human-like email to invite people for your upcoming webinar.</p><p>The call-to-action is simple: "Do you want me to register you for this webinar? Just reply 'I'm in', and I'll take care of the rest." </p>

<p><span>When someone replies with a positive intent, our AI assistant understands, and takes action accordingly.</span></p>
<p><span><br>The person is automatically registered on your webinar platform (Zoom, ON24, WebEx etc.), and synced to your CRM and marketing automation platform. </span></p>

<p><span>We dogfooded this product internally for our previous webinar, and it led to <span>200+ additional registrants</span>.&nbsp;</span></p>

<p><span>We would love to put the power of human + AI Collaborative Intelligence in your hands too.</span></p><p>No more tedious work for you.</p>

<p><span>No friction for your users.</span></p>

<p><span>More webinar conversions. </span><span></span></p>
    
    
  </div>
</section>
</div>

</div><!--end widget-span -->
</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://www.saleswhale.com/webinar-ai-assistant</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678024</guid>
            <pubDate>Mon, 29 Jun 2020 14:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Culture of the Codebase]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23678012">thread link</a>) | @btables
<br/>
June 29, 2020 | https://www.firehydrant.io/blog/the-culture-of-the-codebase/ | <a href="https://web.archive.org/web/*/https://www.firehydrant.io/blog/the-culture-of-the-codebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the earliest bits of code in Laddertruck, the Ruby on Rails app that powers FireHydrant, consistently gets a mention in our Slack. Here it is:</p><pre><p><span>fun_creator = FunctionalityCreator.new(organization, actor: actor, account: account)</span></p><p><span>fun_creator.create(fun).tap do |funfunfun_looking_forward_to_the_weekend|</span></p><p><span>  if funfunfun_looking_forward_to_the_weekend.successful?</span></p><p><span>    service.functionalities &lt;&lt; funfunfun_looking_forward_to_the_weekend.object</span></p><p><span>  end</span></p><p><span>end</span></p></pre><p>If you’re unfamiliar, this is an homage to the oh so catchy,&nbsp;<a href="https://www.youtube.com/watch?v=kfVsfOSbJY0">Rebecca Black’s “Friday.”</a></p><p>This tiny chunk of code adds functionality to a service in a user’s FireHydrant organization. As far as the user knows, this code could be anything, with any variables, and any class names.&nbsp;<strong>They only care that it works.</strong>&nbsp;But to us, this piece of code is much more, it’s a reflection of who we are as a team.</p><h3>The codebase should be a fun place to work</h3><p>We’re remote first, especially now, at FireHydrant. With no office, watercooler, or team outings, it can be challenging to talk to your peers. The place that we do “talk” to each other is our code. Our codebase is our metaphorical office, it’s where we collaborate and solve problems together. So why do so many companies have a codebase that’s sterile and devoid of any fun?</p><p>At FireHydrant, there’s a consistent laugh when you work in our codebases. You’ll find all sorts of things ranging from YouTube links that you have no idea where they go (it’s not a Rickroll, I promise), funny test arguments, and witty mentions to a phrase a teammate uses.</p><p>Take this piece that needs to clear a cache on the record in Laddertruck</p><pre><p><span># THE FRESH MAKER</span></p><p><span># &lt;https://www.youtube.com/watch?v=JqgqgcE8Zck&gt;</span></p><p><span>incident.reload</span></p></pre><p>Another example is one of our engineers saying “dig” when he likes something. I believe it means “I dig it.” It caught on a little bit in the team, so when voting on runbooks was introduced, this line of code came with it.</p><pre><p><span>case params[:direction]</span></p><p><span>when ‘up’, ‘dig’</span></p><p><span>  # … voting up logic</span></p><p><span>when ‘down’</span></p><p><span>  # …</span></p><p><span>end</span></p></pre><p>Beyond having fun in code, we also write comments as if we were talking to each other in person. You can almost tell who wrote the comment without needing to git blame. They are entertaining to read, and I sometimes wonder if I would skip it entirely if it had no personality.</p><p>Said another way, our codebase has a personality:&nbsp;<strong>our company’s personality</strong>. Yours does, too.</p><h3>Your codebase is a result of your culture.</h3><p>You can see codebase culture in programming language communities. If you’re a Rubyist like I am, you probably know about the fun rubygem names like capybara, faraday, and puma. It’s not a surprise that the Ruby community has this commonality with personalities like Aaron “Tenderlove” Patterson and Bryan “test all the f***ng time” Liles, to name only two. Both of whom were exceptionally early in the Ruby community itself.</p><p>It’s incredibly likely that your company’s codebase mimics the personality of the engineers contributing to it. If you want a no-frills codebase, you should hire people that exhibit that behavior in their day to day work. If you wish to have a codebase that is fun and will make you laugh from time to time as I do, you need to hire people with that personality. It truly is your decision on what type of codebase culture you want, and it starts with hiring.</p><h3>Culture is set early.</h3><p>Probably everyone at FireHydrant has heard me say this: The trajectory of anything is set the second time you do something.</p><p>If you want to have a test-driven development culture, do it early and often. If you want a good code review culture, do it on as many pull requests as possible. If you want to see fun variables, Easter egg links, and descriptive comments… you get the idea.</p><h3>What type of codebase do you want?</h3><p>If your codebase doesn’t have your team’s personality, or worse, has a toxic one, what does that say about it? What constraints are teams operating within that they think exist, but don’t? Are people not writing comments because there is another group that thinks comments are useless? Are there no tests because it feels pointless to write one now?</p><p>A codebase with no personality makes me think of an office with bright fluorescent lights, plain walls, and no windows. I’d also assume product and project managers write a Jira issue, wad it up, and throw it to engineers saying it needs to be done by the end of the week.</p><p>We’re designing a company at FireHydrant. The early decisions we’ve made like the name of the application itself (Laddertruck), object names and even Slack channels like <code>#wtf_is_happening_with_my_code</code> are going to end up in our customer’s hands either directly, or indirectly. We want FireHydrant to be a fun and uplifting place to work, and looking at our codebase is one of the many ways to verify we’re doing that successfully.</p><p>Your codebase(s) are where you work, and having one that lacks any personality will make engineers feel like they don’t have agency in their contributions to it. I’m not advocating that you should name every single variable something funny, or that you should always write comments in first-person. Doing so would lead to a funhouse codebase where you have no idea what is up, down, left, or right. But every once in awhile, it’s a great idea to add some pizzazz to the codebase.</p><p>So why name a variable <code>functionality_creator</code> when you can call it <code>fun_creator</code> ?</p></div></div>]]>
            </description>
            <link>https://www.firehydrant.io/blog/the-culture-of-the-codebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678012</guid>
            <pubDate>Mon, 29 Jun 2020 14:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to scan local files for secrets in Python using the GitGuardian API]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23677824">thread link</a>) | @mackenzie-gg
<br/>
June 29, 2020 | https://blog.gitguardian.com/scan-secrets/ | <a href="https://web.archive.org/web/*/https://blog.gitguardian.com/scan-secrets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.gitguardian.com/content/images/size/w300/2020/06/20W19-BLOG-Banner-Algorithm-Final.png 300w,
                            https://blog.gitguardian.com/content/images/size/w600/2020/06/20W19-BLOG-Banner-Algorithm-Final.png 600w,
                            https://blog.gitguardian.com/content/images/size/w1000/2020/06/20W19-BLOG-Banner-Algorithm-Final.png 1000w,
                            https://blog.gitguardian.com/content/images/size/w2000/2020/06/20W19-BLOG-Banner-Algorithm-Final.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.gitguardian.com/content/images/size/w2000/2020/06/20W19-BLOG-Banner-Algorithm-Final.png" alt="How to scan local files for secrets in python using the GitGuardian API">
            </figure>

            <section>
                <div>
                    <p><strong>Do you how many secrets, like API keys or credentials, are hidden in your local files? Today, we're going to show you how you can scan files and directories for sensitive information like secrets. To accomplish this, we'll use the GitGuardian API and python wrapper. &nbsp;By the end of this tutorial you will understand how the API works so you can start building your own, custom secrets detections scripts.</strong></p><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: html--><div>
 <p><b>Terminology</b><br>
      <b>Policy Break:</b> GitGuardian scans more than just secrets, we also scan for high risk file extension (example: keystore) and file names (example: .env), when we detect something that breaks the rules of our policies, we call this a policy break. 
</p><p>
<b>Match: </b>A match is the component that triggered a policy break, for example the match of a detected secret will be the secret string itself. A policy break can have multiple matches.</p></div><!--kg-card-end: html--><!--kg-card-begin: html--><hr id="test"><!--kg-card-end: html--><h2 id="what-our-script-will-do">What our script will do</h2><p>We will create a python script that will scan all files within a local directory for secrets. To do this we will be using the <a href="https://api.gitguardian.com/docs">GitGuardian API</a> and the <a href="https://github.com/GitGuardian/py-gitguardian">API python wrapper</a>, we recommend reviewing these resources before starting.</p><p>Our script will:</p><ul><li>Detect secrets and other policy breaks from your file directory.</li><li>Print the filename, policy break and matches for all policy breaks found.</li><li>Output the result to a JSON format.</li></ul><!--kg-card-begin: html--><hr id="gettingsetup"><!--kg-card-end: html--><h2 id="getting-setup">Getting setup</h2><p>Before we get started writing our script, let's get the necessary components setup.</p><h3 id="installing-the-gitguardian-python-api-client">Installing the GitGuardian python API client</h3><p>Install the GitGuardian python API client using de facto package manager ‘pip’.</p><p>In your terminal or command line execute the command:</p><!--kg-card-begin: html--><div>
    <header>
    
    
    

    
    

    
</header>
<pre>  <span>pip3 install --upgrade pygitguardian
</span></pre></div><!--kg-card-end: html--><h3 id="obtaining-the-gitguardian-api-token">Obtaining the GitGuardian API token</h3><p>Sign up for a free developer account from GitGuardian using your GitHub account or email at <a href="https://dashboard.gitguardian.com/api/v1/auth/user/github_login/authorize?utm_source=blog&amp;utm_medium=referral&amp;utm_campaign=secrets-scan">https://dashboard.gitguardian.com</a>.</p><p>From the menu, navigate to the ‘API’ tab, scroll to ‘Generate new API key’ and select ‘Create new API key’. Make sure you give it an appropriate name.</p><p>You will not be able to view the API key again so make sure you immediately copy it to your clipboard before navigating away.</p><h3 id="setting-up-the-directory-and-files">Setting up the directory and files</h3><p>Open your terminal or command line. </p><p>Create a new directory in the local you wish to save your script:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Enter into the directory using:</p><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="setting-environment-variables">Setting environment variables</h3><p>As a stickler for good coding practices, this tutorial will use environment variables to store our API token (rule number one, never hardcode secrets in source code!).</p><p>I recommend using a tool called <a href="https://pypi.org/project/python-dotenv/">python-dotenv</a> which will allow you to import environment variables, or you can set the API token in your console. </p><p>Create a new file called .env:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Open this file in your chosen text editor and create a variable to store our API:</p><!--kg-card-begin: html--><div> 
<pre>  <span>GG_API_KEY=**INSERT API TOKEN**
</span></pre></div><!--kg-card-end: html--><!--kg-card-begin: html--><hr id="writingourscript"><!--kg-card-end: html--><h2 id="writing-our-script">Writing our script </h2><h3 id="importing-the-modules-and-setting-up-our-client">Importing the modules and setting up our client</h3><p>Next let's create a file called directory_scan.py:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Open this file with your chosen text editor.</p><p>First we need to import the modules we need:</p><!--kg-card-begin: html--><div>
<pre><span>
<span color="#64259C">import </span> glob
<span color="#64259C">import </span> os
<span color="#64259C">import </span> sys
<span color="#64259C">import </span> traceback</span></pre></div><!--kg-card-end: html--><p>In addition to standard modules. We will also be importing and using <a href="https://docs.python.org/3/library/glob.html">‘glob’</a>. This will allow us to get the path and file names of all the files within our directory.</p><h3 id="importing-environment-variables">Importing environment variables</h3><p>If you are using python-dotenv then we need to load in our API token from our .env file and use the API token within:</p><!--kg-card-begin: html--><div>
<pre>  <span>         
<span color="#64259C">from </span> dotenv <span color="#64259C">import</span> load_dotenv
load_dotenv()
API_KEY = os.getenv("GG_API_KEY")
</span></pre></div><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>Now, thanks to <code>load_dotenv()</code>, you’ll be able to retrieve the <code>GG_API_KEY</code> this way and store it in a variable.</p>
<!--kg-card-end: markdown--><h3 id="importing-our-gitguardian-api-client-modules">Importing our GitGuardian API client modules</h3><p>Next load the GitGuardian API client.</p><!--kg-card-begin: html--><div>
<pre>  <span>         
<span color="#64259C">from </span>pygitguardian <span color="#64259C">import</span> GGClient
<span color="#64259C">from </span>pygitguardian.config <span color="#64259C">import</span> MULTI_DOCUMENT_LIMIT
</span></pre></div><!--kg-card-end: html--><p>‘GGClient’ is the core module for our API client, it will handle the data we are scanning, send it to the GitGuardian scanning engine and receive the results. </p><!--kg-card-begin: markdown--><p>The GitGuardian API only allows a maximum package of 20 files or a total size of 2mb for each request to allow for asynchronous scanning. Our  <code>MULTI_DOCUMENT_LIMIT</code> module imports these parameters so we don’t send invaild requests to the server.</p>
<!--kg-card-end: markdown--><p>This does not mean you can only scan 20 files at a time. Our script will handle this by breaking the files into ‘chunks’ that meet the maximum API requirements and send multiple requests before collating the information at the end.</p><p>Now we just need to initialize the GGClient by attaching our API key:</p><!--kg-card-begin: html--><div id="loadingarray">
<pre>  <span>         
<span color="#13821F"># Initializing GGClient</span>
client = GGClient(api_key=API_KEY) 
</span></pre></div>
<!--kg-card-end: html--><h3 id="loading-files-into-an-array">Loading files into an array</h3><p>We now need to load in all the files and file paths within our current directory. Our script scans recursively from the working directory (the directory from which the script is called):</p><!--kg-card-begin: html--><div>
<pre>  <span>         
<span color="#13821F"># Create a list of dictionaries for scanning</span>
to_scan = []
<span color="”#64259C”">for</span> name in glob.glob("**/*", recursive=True):
	<span color="”#64259C”">if</span> ".env" <span color="”#64259C”">in</span> name: <span color="”#64259C”">or</span> os.path.isdir(name):
		<span color="”#64259C”">continue</span>
	<span color="”#64259C”">with</span> open(name) <span color="”#64259C”">as</span> fn:
		to_scan.append({"document": fn.read(), "filename": os.path.basename(name)})) 
</span></pre></div>
<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>The ‘glob’ module allows us create a list of files and path names that we will add into an array called <code>to_scan</code> so we can scan them.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We are going to also add a <code>if</code> statement that will exclude both our <code>.env</code> file and also ignore any folders we are trying to add into our array which will create an error (the files within the folders will still be added).</p>
<p>This will scan files recursively (from the working directory the script is within), but if you want to scan a different directory you can add the in the file path.</p>
<p><em>Example</em><br>
<code>for name in glob.glob("users\user\documents\**", recursive=True):</code></p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><!--kg-card-end: html--><blockquote><em>If you want to check your code is working so far. On a new line add ‘print(to_scan)’. You should get a list of all the files and their contents within your current directory. Comment out or remove before continuing. </em><br></blockquote><h3 id="process-the-files-in-chunks-and-making-the-api-request">Process the files in ‘chunks’ and making the API request</h3><p>As previously mentioned the API will only accept 20 files per request with a maximum of 1MB per file. So we are going to break up our files into acceptable chunks to send as a request:</p><!--kg-card-begin: html--><div>
<pre>  <span>         
<span color="#13821F"># Process in a chunked way to avoid passing the multi document limit</span>
to_process = []
<span color="#64259C">for </span>i in range(0, len(to_scan), MULTI_DOCUMENT_LIMIT):
   chunk = to_scan[i : i + MULTI_DOCUMENT_LIMIT]
   <span color="#64259C">try:</span>
       scan = client.multi_content_scan(chunk)
 <span color="#64259C">  except</span> Exception as exc:
  <span color="#13821F">     # Handle exceptions such as schema validation</span>
       traceback.print_exc(2, file=sys.stderr)
       <span color="C87F15">print</span>(str(exc))
  <span color="#64259C"> if not</span> scan.success:
       <span color="C87F15">print</span>("Error scanning some files. Results may be incomplete.")
       <span color="C87F15">print</span>(scan)
   to_process.extend(scan.scan_results)
</span></pre></div><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>First, create an empty array to hold the scan results from the API, we call this array <code>to_process</code>.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>We are going to loop through our <code>to_scan</code> array containing our file paths and break them into chunks. To do this we are using a ‘range’ function which we will pass a start value, end value and stepping value.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><code>range(start_value, end_value, step)</code></p>
<!--kg-card-end: markdown--><p>We are going to load the current values of our array into a variable called ‘chunk’.</p><p>Using a try block, we will scan our current chunk using the <a href="https://api.gitguardian.com/docs#operation/multiple_scan">multi content scan</a> command of the GG API client.</p><p>Of course we need to handle any expectations where the scan will fail, for example if the filename is too long for our schema.</p><p>The traceback will show the exact line it failed. </p><p>Let's add in a message in the scenario our scan fails.</p><p>Finally we are going to append our scan results to our array ‘to_process’.</p><!--kg-card-begin: html--><div id="printingresults"><!--kg-card-end: html--><blockquote><em>FAQ: If I need to scan 200 files, will this count as 1 or 10 API requests in my dashboard? It will count as 10 but don’t worry you have 1,000 API requests a month.</em></blockquote><h3 id="printing-results">Printing results</h3><!--kg-card-begin: markdown--><p>Now we will loop through our results. If a policy break is detected it will be captured by the <code>.has_secrets</code> tag, if this is true, we will print that result:</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><div>
<pre>  <span>
<span color="#13821F"># Printing the results</span>
<span color="#64259C">for</span> i, scan_result in enumerate(to_process):
   <span color="#64259C">if</span> scan_result.has_policy_breaks:
       <span color="#C87F15">print</span>(f"{chunk[i]['filename']}: {scan_result.policy_break_count} break/s found")
</span></pre></div><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>Now we will loop through our results. If a policy break is detected it will be captured by the <code>.has_policies_breaks</code> tag, if this is true, we will print that result.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><hr id="checkpoint1"><!--kg-card-end: html--><h2 id="code-checkpoint-1">Code Checkpoint 1</h2><p>We are ready to run our first scan so let's quickly make sure our code is the same.</p><!--kg-card-begin: html--><div>
<pre>  <span>
<span color="#64259C">import </span> glob
<span color="#64259C">import </span> os
<span color="#64259C">import </span> sys
<span color="#64259C">import </span> traceback
<span color="#64259C">from </span> dotenv <span color="#64259C">import</span> load_dotenv
load_dotenv()
API_KEY = os.getenv("GG_API_KEY") 

<span color="#64259C">from </span>pygitguardian <span color="#64259C">import</span> GGClient
<span color="#64259C">from </span>pygitguardian.config <span color="#64259C">import</span> MULTI_DOCUMENT_LIMIT

<span color="#13821F"># Initializing GGClient</span>
client = GGClient(api_key=API_KEY) 

<span color="#13821F"># Create a list of dictionaries for scanning</span>
to_scan = []
<span color="#64259C">for</span> name in glob.glob("**/*", recursive=True):
	<span color="#64259C">with</span> open(name) <span color="#64259C">as</span> fn:
		to_scan.append({"document": fn.read(), "filename": os.path.basename(name)})) 

<span color="#13821F"># Process in a chunked way to avoid passing the multi document limit</span>
to_process = []
<span color="#64259C">for </span>i in range(0, len(to_scan), MULTI_DOCUMENT_LIMIT):
   chunk = to_scan[i : i + MULTI_DOCUMENT_LIMIT]
   <span color="#64259C">try:</span>
       scan = client.multi_content_scan(chunk)
 <span color="#64259C">  except</span> Exception as exc:
  <span color="#13821F">     # Handle exceptions such as schema validation</span>
       traceback.print_exc(2, file=sys.stderr)
       <span color="C87F15">print</span>(str(exc))
  <span color="#64259C"> if not</span> scan.success:
       <span color="C87F15">print</span>("Error scanning some files. Results may be incomplete.")
       <span color="C87F15">print</span>(scan)
   to_process.extend(scan.scan_results)

<span color="#13821F"># Printing the results</span>
<span color="#64259C">for</span> i, scan_result in enumerate(to_process):
   <span color="#64259C">if</span> scan_result.has_secrets:
       <span color="#C87F15">print</span>(f"{chunk[i]['filename']}: {scan_result.policy_break_count} break/s found")

</span></pre></div>
<!--kg-card-end: html--><!--kg-card-begin: html--><hr id="runscript"><!--kg-card-end: html--><h2 id="running-the-script">Running the script</h2><p>We are now ready to run our first directory scan. </p><p>You can download some example files that contain expired secrets <a href="https://github.com/GitGuardian/py-gitguardian/tree/master/tests/cassettes">here</a> so you can test your script.</p><p>Move the directory_scan.py file into the directory you want to scan.</p><p>Open your terminal, navigate to the directory and run the command:</p><!--kg-card-begin: html--><div>
    <header>
    
    
    

    
    
    
</header>
<pre>  <span>python3 directory_scan.py
</span></pre></div><!--kg-card-end: html--><p>Congratulations you just scanned your directory for policy breaks! </p><p>Af…</p></div></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gitguardian.com/scan-secrets/">https://blog.gitguardian.com/scan-secrets/</a></em></p>]]>
            </description>
            <link>https://blog.gitguardian.com/scan-secrets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677824</guid>
            <pubDate>Mon, 29 Jun 2020 14:18:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a $5K/Month Newsletter Tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23677522">thread link</a>) | @marz0
<br/>
June 29, 2020 | https://www.radletters.com/blog/how-i-built-a-5k-month-newsletter-tool | <a href="https://web.archive.org/web/*/https://www.radletters.com/blog/how-i-built-a-5k-month-newsletter-tool">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2><strong>Hi there! Who are you and whatâ€™s your background?</strong></h2>

<p>Howdy! Iâ€™m Justin Duke. I run two newsletters, both centered around my product (itself, fittingly, a newsletter tool) â€” <a href="https://buttondown.email/">Buttondown Monthly</a> and <a href="https://weeknotes.buttondown.email/">Weeknotes from Buttondown</a>. </p>

<p>When Iâ€™m not geeking out about newsletters, I â€¦ geek out about other things.  (Itâ€™s a habit.). Iâ€™m a big poetry and weightlifting nerd, and it's summer right now in Seattle so Iâ€™ve been trying to spend as much time outside as I can. (In my day job, I work as a software engineer at <a href="https://stripe.com/">Stripe</a>, making it easier for folks to start and grow their online business.)</p>

<p>Prior to Stripe, I cut my teeth working at Amazon building out infrastructure for Kindle content.</p>

<h2><strong>What are your newsletters about?</strong></h2>

<p>As you might guess, both of my newsletters focus on <a href="https://buttondown.email/">Buttondown</a>: the tool itself, the landscape, and my journey both as a developer and as a creator in the indie hackers niche.  It started out as a fairly typical product development newsletter (â€œhereâ€™s what we launched this monthâ€�, â€œhereâ€™s whatâ€™s coming down the pipelineâ€�) but I realized early on that folks were resonating <em>way</em> more with the trivial pieces: the bugs I ran into, the things I learned, and my personal stories rather than the â€œcorporateâ€� side of things.</p>

<p>When I launched paid newsletters, I knew I wanted to <a href="https://deviq.com/dogfooding/">dogfood</a>, and so I thought Iâ€™d pull out some of the most interesting bits for a paid weekly newsletter.  The intended audience of my main newsletter was, first and foremost, folks who used Buttondown as a product â€” I thought it would be more fun to generalize the paid newsletter a bit, to appeal to folks who were more interested in following my journey less from the â€œnewslettersâ€� point of view and more from the â€œcreatorâ€� point of view.</p>

<h2><strong>What is Buttondown? What motivated you to create the product?</strong></h2>

<p>Buttondown is a tool Iâ€™ve built for technical newsletters! Think â€œ<a href="https://tinyletter.com/">TinyLetter</a> or <a href="https://substack.com/">Substack</a>, except with <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> and more APIsâ€� â€” itâ€™s a niche product for people like me, who are a bit more programmatically inclined but still want something quick and easy to manage emails and subscribers.</p>

<p>I was motivated to build Buttondown after I had been using TinyLetter for a while, and had perhaps the worst thought that any developer can have: â€œI bet I can build a better version of this in a weekend.â€�  It took quite a bit longer than that to get the entire thing done, but I was able to use my own tool instead of TinyLetter at the end of two weeks; after I showed it off to a few friends they convinced me to make it something more than just a self-hosted tool.</p>

<p>Iâ€™ve been building Buttondown for over three years now, after mistakenly thinking it would be a quick one-and-done project.  I got my first paying customer after around a month and itâ€™s now just shy of $5,000/month.</p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBbmdDIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--32e0faa0c0d26f19431f0d9cd8755781d782cd30/btndwn2.png" alt="buttondown-product"></p>

<h2><strong>What are some of the difficulties youâ€™ve encountered in running your newsletters?</strong></h2>

<p>Motivation and timing is absolutely the hardest part for me.  Iâ€™ve been fortunate the past few months to get into a very strict schedule and rhythm (every Saturday morning, without fail, I sit down and write), but I experience a bit of a slipping effect every now and then: I forget (or life gets in the way) one weekend, so I miss it, and then the following weekend I get so anxious that I miss that one too, and so on.  The important part is <em>consistency</em>, both for yourself and for your readers.</p>

<h2><strong>Do you have a monetization strategy for your newsletters?</strong></h2>

<p>Having two newsletters means I get to segment a little bit!  My main updates newsletter is free, but you have to pay $4/month for weeknotes.  Theyâ€™re both ad-free (they advertise Buttondown, but that hardly counts ;)). Weeknotes brings in a solid $900/month, which is not exactly a life-changing amount but is still wonderful and humbling (and pays for my two biggest vices, coffee and Green Chartreuse.)</p>

<h2><strong>What newsletters are you subscribed to?</strong></h2>

<ol>
<li><p><a href="https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine">Money Stuff</a> is Bloombergâ€™s daily finance newsletter written by Matt Levine.  It is, for my money, the perfect newsletter: witty, informative, and precise.  Matt does an amazing job of breaking down things like credit default swaps or investor buyouts in a way that youâ€™ll grasp them easily <em>and</em> understand the bigger picture.</p></li>
<li><p><a href="https://letterstosummer.com/">Letters to Summer</a> is an intimate, sweet look at a conversation between two friends.  Iâ€™ve been turned onto this one from my friend Jasdev and itâ€™s been great: Iâ€™ve discovered new games, new music, and (clichÃ© as it is to say) a little bit of a new outlook on life.</p></li>
</ol>

<h2><strong>What goals do you have for the future?</strong></h2>

<p>If you had told me two years ago Buttondown would become as large as it has, I would have laughed â€” it was a tool I made for myself first and foremost, and secondarily for my friends who also wanted an easier way to build newsletters.  Thatâ€™s equally true for the newsletters: the fact that a hundred or so folks are willing to pay me for the privilege of following me on my journey is super humbling!</p>

<p>Honestly, I hope for more of the same down the line.  Buttondown â€” both as a newsletter and a tool â€” is something that I donâ€™t think Iâ€™ll ever want to do full time, because itâ€™s a privilege that it can be a place where I <em>retreat</em> from my day job.  </p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBbmNDIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--002bf58fe441b67dfae8b4d33322e2c4019c9bce/btndwn1.png" alt="buttondown-example"></p>

<h2><strong>Where can readers go to learn more about you and your newsletter?</strong></h2>

<p>Readers can visit the <a href="https://buttondown.email/">website</a>, find Buttondown on <a href="https://twitter.com/buttondown">Twitter</a>, or sign up for Weeknotes from Buttondown at <a href="https://weeknotes.buttondown.email/">weeknotes.buttondown.email</a>!</p>

    </div></div>]]>
            </description>
            <link>https://www.radletters.com/blog/how-i-built-a-5k-month-newsletter-tool</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677522</guid>
            <pubDate>Mon, 29 Jun 2020 13:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sidetable Gives You the Pandas Methods You Didn't Know You Needed]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23677462">thread link</a>) | @klarahorton
<br/>
June 29, 2020 | https://beta.deepnote.com/article/sidetable-pandas-methods-you-didnt-know-you-needed | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/sidetable-pandas-methods-you-didnt-know-you-needed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="project"><div><div><div><p>Quickly make DataFrames for missing values, frequency counts, subtotals, and more 🎉
</p><p><img src="https://storage.googleapis.com/published-content/sidetable-pandas-methods-you-didnt-know-you-needed/chinstrap-penguins.jpg" alt="Sidetable Gives You the Pandas Methods You Didn't Know You Needed
 - preview image"></p></div><div><div><div><div><div><div><div><p>Sidetable <span>is</span> a new Python library that adds several helpful pandas DataFrame methods<span>.</span> It <span>is</span> nice <span>for</span> exploratory data analysis <span>and</span> presenting information<span>.</span>
In this guide I'll show you how to use sidetable <span>and</span> where it could be a good fit <span>in</span> your data science workflow<span>.</span> 

As we explore sidetable<span>,</span> we'll use the penguins dataset that was recently added to the <span>[</span>seaborn<span>]</span><span>(</span>https<span>:</span><span>//</span>seaborn<span>.</span>pydata<span>.</span>org<span>/</span><span>)</span> visualization library<span>.</span> The penguins dataset <span>is</span> mean to be a replacement <span>for</span> the overused <span>[</span>iris<span>]</span><span>(</span>https<span>:</span><span>//</span>archive<span>.</span>ics<span>.</span>uci<span>.</span>edu<span>/</span>ml<span>/</span>datasets<span>/</span>iris<span>)</span> dataset<span>.</span> If nothing <span>else</span><span>,</span> it adds some variety <span>and</span> allows us to show some penguin pictures<span>.</span> 😀</p></div></div></div></div></div></div><div><div><div><div><div><div><p>
Pandas <span>is</span> the exploration tool <span>for</span> data analysts <span>and</span> data scientists who use Python<span>.</span> 🐼  The pandas API <span>is</span> large <span>and</span> oriented around data cleaning <span>and</span> data wrangling<span>.</span>
The new <span>[</span>sidetable<span>]</span><span>(</span>https<span>:</span><span>//</span>github<span>.</span>com<span>/</span>chris1610<span>/</span>sidetable<span>)</span> package adds convenience methods to DataFrames<span>.</span> These methods make it easier to see missing values<span>,</span> counts of values per column<span>,</span> subtotals<span>,</span> <span>and</span> grand totals<span>.</span> </p></div></div></div></div></div></div><div><div><div><div><div><div><p>

To get the latest versions of necessary packages <span>and</span> their dependencies<span>,</span> uncomment <span>and</span> run the following code one time<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>Let's <span>import</span> the packages <span>and</span> check the versions<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p><span>import</span> sys
<span>import</span> pandas <span>as</span> pd
<span>import</span> sidetable 

<span>print</span><span>(</span><span><span>f"Python version </span><span><span>{</span>sys<span>.</span>version<span>}</span></span><span>"</span></span><span>)</span>
<span>print</span><span>(</span><span><span>f"pandas version: </span><span><span>{</span>pd<span>.</span>__version__<span>}</span></span><span>"</span></span><span>)</span>
<span>print</span><span>(</span><span><span>f"sidetable version: </span><span><span>{</span>sidetable<span>.</span>__version__<span>}</span></span><span>"</span></span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>If your Python version <span>is</span> less than <span>3.6</span><span>,</span> I suggest you updated it<span>.</span> Same goes <span>for</span> pandas <span>if</span> your version <span>is</span> less than <span>1.0</span><span>.</span> To learn more about the pandas <span>1.0</span> update<span>,</span> check out my article <span>[</span>here<span>]</span><span>(</span>https<span>:</span><span>//</span>towardsdatascience<span>.</span>com<span>/</span>whats<span>-</span>new<span>-</span><span>in</span><span>-</span>pandas<span>-</span><span>1</span><span>-</span><span>0</span><span>-</span>ffa99bd43a58<span>)</span><span>.</span>
</p></div></div></div></div></div></div><div><div><div><div><div><div><p>

We<span>'ll read in the Antartica penguins dataset directly from a .csv file at the GitHub repository that hosts seaborn'</span>s datasets<span>.</span> 

The data were collected <span>and</span> made available by Dr<span>.</span> Kristen Gorman <span>and</span> the Palmer Station<span>,</span> Antarctica LTER<span>.</span> See more info <span>[</span>here<span>]</span><span>(</span>https<span>:</span><span>//</span>github<span>.</span>com<span>/</span>allisonhorst<span>/</span>palmerpenguins<span>)</span><span>.</span>

Let's put the data <span>in</span> a pandas DataFrame <span>and</span> check out the first few rows<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins <span>=</span> pd<span>.</span>read_csv<span>(</span><span>'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv'</span><span>)</span>
df_penguins<span>.</span>head<span>(</span><span>2</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Alright<span>,</span> looks like we've got some penguins<span>.</span> 👍 

Alternatively<span>,</span> this dataset can be loaded through seaborn <span>if</span> you install <span>[</span>seaborn<span>]</span><span>(</span>http<span>:</span><span>//</span>seaborn<span>.</span>pydata<span>.</span>org<span>/</span><span>)</span><span>,</span> `<span>import</span> seaborn <span>as</span> sns` <span>and</span> run `df_penguins <span>=</span> sns<span>.</span>load_dataset<span>(</span><span>'penguins'</span><span>)</span>`<span>.</span> 

After reading a new dataset into DataFrame<span>,</span> my <span>next</span> move <span>is</span> to use `df<span>.</span>info<span>(</span><span>)</span>` to get some information about it<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>We see some basic info about our <span>6</span> columns <span>and</span> <span>344</span> rows<span>.</span>

Let's see how sidetable can <span>help</span> us explore our data<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>!<span>[</span>Adelie Penguin<span>.</span> source<span>:</span> pixabay<span>.</span>com<span>]</span><span>(</span>https<span>:</span><span>//</span>storage<span>.</span>googleapis<span>.</span>com<span>/</span>published<span>-</span>content<span>/</span>sidetable<span>-</span>pandas<span>-</span>methods<span>-</span>you<span>-</span>didnt<span>-</span>know<span>-</span>you<span>-</span>needed<span>/</span>adelie_penguin<span>.</span>png<span>)</span> Adelie Penguin<span>.</span> source<span>:</span> pixabay<span>.</span>com</p></div></div></div></div></div></div><div><div><div><div><div><div><p>
All sidetable methods use the `<span>.</span>stb` accessor<span>.</span> For more about the pandas accessor API<span>,</span> see this <span>[</span>post<span>]</span><span>(</span>https<span>:</span><span>//</span>pbpython<span>.</span>com<span>/</span>sidetable<span>.</span>html<span>)</span> by Chris Moffit<span>,</span> the author of sidetable<span>.</span>


The first sidetable DataFrame method we<span>'ll check out is `stb.missing()`. Here'</span>s how to use it<span>:</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>missing<span>(</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>The result <span>is</span> a DataFrame <span>with</span> the number of missing values per column<span>,</span> ordered by most to fewest<span>.</span> It also displays the total number of rows <span>and</span> the percentage of missing values <span>for</span> each column<span>.</span>

With `df<span>.</span>info<span>(</span><span>)</span>`<span>,</span> we would have had to do the arithmetic <span>in</span> our head<span>.</span> 🤔

Alternatively<span>,</span> we could see <span>all</span> the missing values by column <span>with</span> `df<span>.</span>isna<span>(</span><span>)</span><span>.</span><span>sum</span><span>(</span><span>)</span>`<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>But `df<span>.</span>isna<span>(</span><span>)</span><span>.</span><span>sum</span><span>(</span><span>)</span>` doesn<span>'t include the percentages and isn'</span>t nicely formatted<span>.</span> Speaking of nice formatting<span>,</span> let<span>'s make sidetable'</span>s output prettier<span>.</span> 💐</p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>missing<span>(</span>style<span>=</span><span>True</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Passing `style<span>=</span><span>True</span>` cleans up the <span>*</span>Percent<span>*</span> column formatting<span>.</span>

I plan to use `stb<span>.</span>missing<span>(</span><span>)</span>` whenever I have a bunch of columns <span>with</span> missing data<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>

Now let's look at the sidetable DataFrame method `<span>.</span>stb<span>.</span>freq<span>(</span><span>)</span>`<span>,</span> the main course <span>in</span> the sidetable package<span>.</span> 🍲

Let's check out the <span>*</span>species<span>*</span> category<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'species'</span><span>]</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>The result of `stb<span>.</span>freq<span>(</span><span>)</span>` <span>is</span> like combining value_counts <span>with</span> <span>and</span> without the `normalize<span>=</span><span>True</span>` argument<span>,</span> the cumulative count<span>,</span> <span>and</span> the cumulative percentage<span>.</span> As <span>with</span> `stb<span>.</span>missing<span>(</span><span>)</span>`<span>,</span> we can make the styling even nicer by passing `style<span>=</span>true`<span>.</span> 🎉</p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'species'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Note that <span>all</span> the sidetable methods operate on DataFrames <span>and</span> <span>return</span> a DataFrame<span>.</span> </p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p><span>type</span><span>(</span>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'species'</span><span>]</span><span>)</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>You know<span>,</span> <span>with</span> this data being nominal <span>-</span> <span>not</span> ordinal <span>-</span> we might <span>not</span> want the cumulative columns<span>.</span> We can get rid of those columns by passing `cum_cols<span>=</span><span>False</span>` like this<span>:</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'species'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>,</span> cum_cols<span>=</span><span>False</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>!<span>[</span>Gentoo Penguins<span>]</span><span>(</span>https<span>:</span><span>//</span>storage<span>.</span>googleapis<span>.</span>com<span>/</span>published<span>-</span>content<span>/</span>sidetable<span>-</span>pandas<span>-</span>methods<span>-</span>you<span>-</span>didnt<span>-</span>know<span>-</span>you<span>-</span>needed<span>/</span>gentoo_penguins<span>.</span>jpg<span>)</span>
Gentoo Penguins<span>.</span> source<span>:</span> pixabay<span>.</span>com</p></div></div></div></div></div></div><div><div><div><div><div><div><p>Let's see how things look <span>if</span> we <span>pass</span> multiple columns to `stb<span>.</span>freq<span>(</span><span>)</span>`<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'species'</span><span>,</span> <span>'island'</span><span>,</span> <span>'sex'</span><span>]</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>That<span>'s quite a breakdown. Let'</span>s look at just the <span>*</span>island<span>*</span> column to explore some more optional arguments<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>What <span>if</span> we just want to include islands that make up <span>50</span><span>%</span> of the total count? That example <span>is</span> a little contrived<span>,</span> but we're trying to show functionality<span>,</span> so work <span>with</span> me here<span>.</span> 😉

Pass `thresh<span>=</span><span>.5</span>` to show only the islands contributing up to <span>50</span><span>%</span> of the total<span>.</span> </p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>,</span> thresh<span>=</span><span>.5</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Notice that this might be a bit confusing<span>.</span> We aren't showing <span>all</span> the islands <span>with</span> at least <span>50</span><span>%</span> of the total<span>.</span> We are showing <span>all</span> the islands up to a cumulative threshold<span>.</span> 

Here's how things look <span>with</span> a threshold of <span>.9</span><span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>,</span> thresh<span>=</span><span>.9</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>If you want to change the label <span>for</span> the values ommitted<span>,</span> you can <span>pass</span> `other_label<span>=</span><span>'my_label'</span>` like this<span>:</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>,</span> style<span>=</span><span>True</span><span>,</span> thresh<span>=</span><span>.9</span><span>,</span> other_label<span>=</span><span>'Other Islands'</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Pass `value<span>=</span><span>'my_column'</span>` to <span>sum</span> <span>and</span> dislay by the values <span>in</span> that column<span>,</span> instead of counting the occurrences<span>.</span> This doesn<span>'t really make sense to do with the current dataset, but it'</span>s a nice feature to know about<span>.</span> Here's how the output looks<span>:</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>,</span> value<span>=</span><span>'flipper_length_mm'</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>In our case<span>,</span> the original columns aren't capitalized<span>,</span> but the new columns created by sidetable are<span>.</span> If you want the column capitalization to match<span>,</span> you can adjust the resulting DataFrame<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>freq_table <span>=</span> df_penguins<span>.</span>stb<span>.</span>freq<span>(</span><span>[</span><span>'island'</span><span>]</span><span>)</span>
freq_table<span>.</span>columns <span>=</span> freq_table<span>.</span>columns<span>.</span><span>str</span><span>.</span>title<span>(</span><span>)</span>
freq_table</p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>
Sidetable<span>'s `stb.freq()` is nice because it'</span>s lightweight <span>and</span> informative<span>.</span> In some cases you'll want a different tool<span>.</span>


If I'm looking <span>for</span> descriptive statistics on numeric data<span>,</span> I often use `df<span>.</span>describe<span>(</span><span>)</span>`<span>.</span> </p></div></div></div></div></div></div><div><div><div><div><div><div><p>Passing `include<span>=</span><span>'all'</span>` shows some information about the non<span>-</span>numeric columns<span>,</span> but then things are a little messy<span>.</span> 🙁</p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>describe<span>(</span>include<span>=</span><span>'all'</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>If you want a lot of information about your data<span>,</span> check out the <span>[</span>Pandas Profiling<span>]</span><span>(</span>https<span>:</span><span>//</span>github<span>.</span>com<span>/</span>pandas<span>-</span>profiling<span>/</span>pandas<span>-</span>profiling<span>)</span> package<span>.</span> It provides a comprehensive report <span>with</span> descriptive stats<span>,</span> histograms<span>,</span> correlations<span>,</span> <span>and</span> more<span>.</span> It's pretty awesome<span>.</span> However<span>,</span> it can take a <span>while</span> to run <span>and</span> be a bit much <span>for</span> many use cases<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>Now let's see the final sidetable method<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><p>If you want to display a DataFrame <span>with</span> a <span>*</span>Grand Total<span>*</span> row that shows the sums of the numeric columns<span>,</span> use `stb<span>.</span>subtotal<span>(</span><span>)</span>`<span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>stb<span>.</span>subtotal<span>(</span><span>)</span><span>.</span>tail<span>(</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>This <span>is</span> handy <span>for</span> financial documents <span>and</span> other cases where you want to show the data <span>and</span> the totals <span>in</span> the same table<span>.</span> 

By combining `df<span>.</span>groupby<span>(</span><span>)</span>` <span>with</span> `stb<span>.</span>subtotal<span>(</span><span>)</span>` you get a grand total <span>and</span> nicely formatted subtotals<span>.</span>

Here's a groupby of <span>*</span>species<span>*</span> <span>and</span> <span>*</span>sex<span>*</span><span>,</span> <span>with</span> a count of <span>*</span>island<span>*</span><span>.</span></p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>groupby<span>(</span><span>[</span><span>'species'</span><span>,</span> <span>'sex'</span><span>]</span><span>)</span><span>.</span>agg<span>(</span><span>dict</span><span>(</span>island<span>=</span><span>'count'</span><span>)</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Not earth<span>-</span>shattering information <span>in</span> our case<span>,</span> but it shows the counts <span>in</span> each group<span>.</span> 

The information would be easier to comprehend at a glance <span>with</span> some subtotals <span>and</span> a grand total<span>.</span> `stb<span>.</span>subtotal<span>(</span><span>)</span>` adds those <span>for</span> us<span>.</span> 🎉</p></div></div></div></div></div></div><div><div><div><div><div><div><div data-cy="code-cell"><div><p>df_penguins<span>.</span>groupby<span>(</span><span>[</span><span>'species'</span><span>,</span> <span>'sex'</span><span>]</span><span>)</span><span>.</span>agg<span>(</span><span>dict</span><span>(</span>island<span>=</span><span>'count'</span><span>)</span><span>)</span><span>.</span>stb<span>.</span>subtotal<span>(</span><span>)</span></p></div></div></div></div></div></div></div></div><div><div><div><div><div><div><p>Subtotals are often helpful <span>with</span> financial data <span>or</span> ordinal data<span>.</span> `stb<span>.</span>subtotal<span>(</span><span>)</span>` makes it more pleasant to do budgeting <span>and</span> financial reporting tasks that I would normally do <span>in</span> Google Sheets <span>or</span> Microsoft Excel<span>.</span> </p></div></div></div></div></div></div><div><div><div><div><div><div><p>

Yo<span>u've seen how you can use sidetable to quickly display missing values, make nicely formatted frequency tables, and show grand totals and subtotals. It'</span>s a handy little library<span>.</span> 👍



Here's a recap of the API<span>:</span>
<span>-</span> `stb<span>.</span>missing<span>(</span><span>)</span>` <span>-</span> display helpful information about missing values<span>.</span>
<span>-</span> `stb<span>.</span>freq<span>(</span><span>)</span>` <span>-</span> display counts<span>,</span> percents<span>,</span> <span>and</span> cumulative information <span>for</span> columns<span>.</span>
<span>-</span> `stb<span>.</span>subtotal<span>(</span><span>)</span>` <span>-</span> add a grand total row to a DataFrame<span>.</span> If applied to a groupby<span>,</span> add subtotal information <span>for</span> each group<span>.</span>

Passing `style<span>=</span><span>True</span>` to `stb<span>.</span>missing<span>(</span><span>)</span>` <span>and</span> `stb<span>.</span>freq<span>(</span><span>)</span>` makes the output nicely formatted<span>.</span> There are a nubmer of other arguments you can <span>pass</span> to `stb<span>.</span>freq<span>(</span><span>)</span>` to modify the output<span>.</span>
</p></div></div></div></div></div></div><div><div><div><div><div><div><p>I hope you found this introduction to sidetable to be helpful<span>.</span> If you did<span>,</span> please share it on your favorite social media so other folks can find it<span>,</span> too<span>.</span> 😀

If you have questions <span>or</span> comments<span>,</span> please share them <span>with</span> me on <span>[</span>Twitter<span>]</span><span>(</span>https<span>:</span><span>//</span>twitter<span>.</span>com<span>/</span>discdiver<span>)</span> <span>or</span> <span>[</span>LinkedIn<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>linkedin<span>.</span>com<span>/</span><span>in</span><span>/</span><span>-</span>jeffhale<span>/</span><span>)</span><span>.</span>

Happy sidetabling! 🚀</p></div></div></div></div></div></div><div><div><div><div><div><div><p>!<span>[</span>Gentoo Penguin<span>]</span><span>(</span>https<span>:</span><span>//</span>storage<span>.</span>googleapis<span>.</span>com<span>/</span>published<span>-</span>content<span>/</span>sidetable<span>-</span>pandas<span>-</span>methods<span>-</span>you<span>-</span>didnt<span>-</span>know<span>-</span>you<span>-</span>needed<span>/</span>gentoo_penguin<span>.</span>jpg<span>)</span>
Gentoo Penguin<span>.</span> source<span>:</span> pixabay<span>.</span>com</p></div></div></div></div></div></div></div><div><div><div><p>Deepnote is a new kind of data science notebook. Jupyter-compatible and with real-time collaboration.</p><p>Sign-up for the waitlist below, or find out more<!-- --> <a target="_blank" rel="noopener noreferrer" href="https://deepnote.com/">here.</a></p></div><p><img src="https://beta.deepnote.com/static/to-be-continued.jpg" alt="To be continued..."></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/sidetable-pandas-methods-you-didnt-know-you-needed</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677462</guid>
            <pubDate>Mon, 29 Jun 2020 13:40:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[15 ways to get paid with less hassle as a freelancer (or consultant)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23677450">thread link</a>) | @jtrtoo
<br/>
June 29, 2020 | https://joshrichards.net/2014/01/23/15-ways-to-get-paid-with-less-hassle-as-a-freelancer-or-consultant/ | <a href="https://web.archive.org/web/*/https://joshrichards.net/2014/01/23/15-ways-to-get-paid-with-less-hassle-as-a-freelancer-or-consultant/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<figure><img data-attachment-id="118" data-permalink="https://joshrichards.net/9345483102_5a3996cda9_c/" data-orig-file="https://joshrichards.files.wordpress.com/2019/02/9345483102_5a3996cda9_c.jpg" data-orig-size="800,534" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="9345483102_5a3996cda9_c" data-image-description="" data-medium-file="https://joshrichards.files.wordpress.com/2019/02/9345483102_5a3996cda9_c.jpg?w=300" data-large-file="https://joshrichards.files.wordpress.com/2019/02/9345483102_5a3996cda9_c.jpg?w=800" src="https://joshrichards.files.wordpress.com/2019/02/9345483102_5a3996cda9_c.jpg" alt=""></figure>



<p>These are the techniques I’ve found most effective to get paid fast when doing technology freelancing.<br></p>



<p><strong>1. Ask for a portion of the fee upfront.</strong></p>



<p>This one seems obvious to me now, but I went several years before I moved beyond the “work a bunch of hours then send an invoice and wait” model. You can do this whether you are fixed fee or hourly, basing the latter on an estimate.</p>



<p><strong>2. Ask for the entire fee upfront.</strong></p>



<p>You’d be surprised how acceptable this becomes once you simply start making it your convention. And, really, it’s not all that strange when you consider that you can’t drive away with a car (or even walk out of Walmart) before paying for your purchase, as well as the fact that in most cases you are taking on greater risk than the client is by working on a project for a client for a few weeks or months with only the “hope” that you’ll get paid at the end. You are a freelancer, not your client’s banker/lender.</p>



<p><strong>3. Set expectations upfront.</strong></p>



<p>If the buyer can make the full investment decision upfront, rather than hope or guess, it’s easier to get paid faster. A lot of delayed payments are really because the buyer is disappointed with either the fee, the value, or the result. If your fees are fixed and thus entirely set upfront, this is easy. If you charge hourly/daily/weekly, estimate conservatively and… see the next item.</p>



<p><strong>4. Offer compelling value.</strong></p>



<p>I prefer to not only discuss the project upfront, but to then come back to the client with a written summary (which ends up being the proposal). The summary is in my own words but drawn entirely from our discussions. It contains, at a minimum, with a nod to the value-based fee model taught by Alan Weiss:</p>



<ul><li>The situation appraisal</li><li>The business objectives (outputs/improved conditions) tied to the work</li><li>The believed value of the work (business-wise and sometimes personally and professionally for the buyer)</li><li>The implicit or explicit metrics or indicators of success for the work against the objectives</li></ul>



<p>In this way, the buyer and I don’t proceed until there is a true “meeting of the minds” over the value of the work. It’s easy to get into a discussion about the inputs (tasks), but the real value is in the results. The better understanding I have of the ideal result that the client has in mind, the closer I can tie my work to compelling value. And the happier the client will be to pay, period.</p>



<p><strong>5. Constantly communicate.</strong></p>



<p>You know when you should be providing updates. Generally it is whenever you’ve promised to, just before or after major milestones, when there are hiccups that may impact scheduling or results, or any other time you know you should but are avoiding doing so only because you are concerned about the reaction. 🙂</p>



<p><strong>6. Meet commitments.</strong></p>



<p>If you make a promise, meet it. Simple, but not always easy. If something isn’t going as planned, just communicate that and adjust. Unless you make a pattern of it – or don’t learn from your mistakes – it’ll be probably okay.</p>



<p><strong>7. Use plain language. (Avoid legalese.)</strong></p>



<p>Don’t create proposals that require legal departments / attorneys to get involved. And if you can’t avoid it entirely, keep them sane. Business is risk.[1]</p>



<p><strong>8. Make it easy to pay you.</strong></p>



<p>Accept checks, eChecks (ACH), and all major credit and debit cards as well as, if possible, via multiple processors. I accept payment via PayPal, Google Checkout, and Stripe. There is overlap between these, but every buyer/client has their own favorite service. I don’t care which they use, just as long as they pay as promptly or – preferably – as rapidly as possible.</p>



<p>If you are concerned about paying 2% to 3% on credit card transactions, you are overlooking that you are in a high margin business. Paying 3% on credit card transactions will make you cringe sometimes, but don’t overlook the big picture. You are providing a service with an 80%-90% profit margin. And, having money in your hand – rather than “in the mail” – is the difference between an actual sale and just talk. It’s also the difference between putting food on the table and starving waiting for money to arrive in the indefinite future.</p>



<p><strong>9. Follow-up when a payment is late. Do so immediately and in a professional, consistent, and assertive manner.</strong></p>



<p>I suggest clear language that doesn’t whine (it’s not their problem you can’t pay your mortgage, but it is their problem they are failing to fulfill their commitment). I prefer automated follow-up so that it always happens, otherwise I will put it off. Most on-line invoicing solutions can be set-up to do this automatically for you after a configured number of days.</p>



<p><strong>10. Always make payment arrangements and discuss payment problems with your buyer (the decision maker / business sponsor), not the client’s bookkeeper or accounts payable department.</strong></p>



<p>The buyer can escalate, assert their authority, and negotiate when there are problems. They are also the one who is impacted if a missed payment results in a project delay. The A/P department on the other hand isn’t any of these things.</p>



<p><strong>11. Generate professional invoices that are easy-to-read.</strong></p>



<p>They should clearly describe the work, account for every hour (if you are billing for time), and reference the project, proposal, and buyer clearly. Make them very simple, without any extra language or legalese.</p>



<p><strong>12. Send invoices in a timely manner and do so consistently.</strong></p>



<p>Immediately upon gaining agreement on a proposal. Consistently at milestones or the agreed upon dates. If possible, generate and schedule delivery ahead of time. If a series of invoices is likely, you can even provide them all upfront with rolling due dates, if that seems like it’ll be helpful.</p>



<p><strong>13. State a late fee on every invoice generated that applies if it is not the balance is paid in a timely manner.</strong></p>



<p>Pretty self-explanatory. A flat fee or charging interest are fine, but if the latter make sure you understand usurp your state/country specific restrictions on charging interest.</p>



<p><strong>14. State all invoices as being “Due upon receipt.”</strong></p>



<p>If you learn an organization is taking advantage of this phrasing to not pay within 7-10 business days, change their next invoice to be “Net 15” (due in 15 days). If they can’t pay on time, tell them to use a credit card.</p>



<p><strong>15. Offer a small discount for pre-payment in full upfront.</strong></p>



<p>I always ask for a portion of the fee upfront for every project, while offering a small discount for pre-payment in full upfront (in the 5% to 10% range). For projects I consider to be relatively small (e.g. &lt;$5,000) I don’t offer a discount, but outright require full payment upfront.</p>



<p>Photo credit:&nbsp;<a href="http://www.flickr.com/photos/damianspain/9345483102/">http://www.flickr.com/photos/damianspain/9345483102/</a></p>



<hr>



<ol><li>I am not a lawyer.</li></ol>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://joshrichards.net/2014/01/23/15-ways-to-get-paid-with-less-hassle-as-a-freelancer-or-consultant/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677450</guid>
            <pubDate>Mon, 29 Jun 2020 13:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof that there are servers in serverless]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23677411">thread link</a>) | @discodave
<br/>
June 29, 2020 | http://blog.drgriffin.com.au/posts/2020-06-28-servers-in-serverless.html | <a href="https://web.archive.org/web/*/http://blog.drgriffin.com.au/posts/2020-06-28-servers-in-serverless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Ever since the <em>serverless</em> buzzword first took off around 2015, people
<a href="https://twitter.com/search?q=%22servers%20in%20serverless%22">have</a>
<a href="https://www.google.com/search?q=%22servers+in+serverless%22">been</a>
<a href="https://www.ibm.com/cloud/learn/serverless#toc-are-there--aDx9w_gl">asking</a>.</p>
<div><p>
Are there servers in serverless?
</p>

</div>

<p>Today, after some thorough research, and drawing on my experience working in
the deepest bowels of Amazon's gargantuan cloud, I can share the definitive
answer with you. Hover your mouse over the grey box below to find out.
</p>
<p>As you can see, since the word <em>serverless</em> contains the word <em>server</em>, we have
found evidence for <em>servers</em> in <em>serverless</em>! </p>
<p>Ok, so now you think I'm a smart-ass. Also, if you were
looking closely we only found <em>one</em> server, singular.</p>
<p>If you'll just bear with me for one second, I think we can do better.</p>


<p>Whoa! It turns out, there are server<em>s</em> (plural) in server<em>less</em> after
all! <a href="#fn1"><sup>1</sup></a></p>
<h2>A more serious answer</h2>
<p>First, let's start with a definition of <em>serverless</em>. I'm going to use one
<a href="https://aws.amazon.com/serverless">from AWS</a>, because they popularized the
term, and seem to be the leader in the space.</p>
<blockquote>
<p>Serverless allows you to build and run applications and services without
thinking about servers</p>
</blockquote>
<p>That's a pretty good definition. Developers always say they just want to think
about business logic. They don't want to worry about messy details, so this
sounds great.  But why do very smart people get so <a href="https://twitter.com/g_bonfiglio/status/1052680017249996800">passionate and
agitated</a> about the
word <em>serverless</em>. It seems to trigger almost a primal reaction in many
engineers, because they <em>know</em> there are some computers somewhere doing <em>the
thing</em> and if they're in a datacenter, you can probably call them servers.</p>
<p>I think the answer is: <em>serverless often fails spectacularly to deliver on it's
core promise</em>. Developers using serverless technologies are often finding
themselves dealing with servers, but in weird and unusual ways.</p>
<h3>Outrageous example: Aurora Serverless</h3>
<p>This example makes me suspect that some marketing team slapped the <em>serverless</em>
name on a feature that was designed with less lofty goals. I don't know for
sure, but I can't think of a better explanation.</p>
<p>The <a href="https://aws.amazon.com/rds/aurora/faqs/">Aurora Serverless FAQ states</a>:</p>
<blockquote>
<p>In Aurora Serverless [...] you pay a flat rate per second [...] with a
minimum of 5 minutes of usage each time the database is activated.</p>
</blockquote>
<p>AWS Lambda, the original service that popularized the <em>serverless</em> model has
100 <em>millisecond</em> increments for billing. But Aurora will bill me for FIVE
MINUTES For one request? That's like making one request to AWS Lambda, but
then getting charged for 3,000.</p>
<p>For comparison, the minimum billing increment for both a <a href="https://cloud.google.com/compute/vm-instance-pricing">Google Cloud Virtual
Machine (VM)</a>, or an <a href="https://aws.amazon.com/ec2/pricing/#Per_Second_Billing">AWS
EC2 VM</a> is one minute.
Both of those products are actual (virtual) servers.</p>
<p>The bottom line? Aurora serverless has a less granular pricing model than
<em>actual servers</em>. That's a fail in my book.</p>
<h3>Subtle example: hunt the chips</h3>
<p>No current serverless technology<a href="#fn2"><sup>1</sup></a> abstracts the underlying
CPU. For instance, <a href="https://alestic.com/2014/11/aws-lambda-environment/">Eric
Hammond</a> found that his
Lambda function was running on an Intel Xeon E5-2680 in 2014. I think that's
the same CPU as the EC2 C3 instance type. AWS can probably migrate Lambda
functions to later-and-greater <em>Intel</em> EC2 instances without any customers
noticing too much.</p>
<p>However, AWS has recently been spruiking their ARM based Graviton2 chips as
being better value than Intel chips.</p>
<blockquote><p lang="en" dir="ltr">Excited to bring customers the next gen of Amazon EC2 instances powered by <a href="https://twitter.com/hashtag/AWS?src=hash&amp;ref_src=twsrc%5Etfw">#AWS</a>-designed, Arm-based Graviton2 processors that deliver up to 40% better price/performance than comparable current x86 instances. Should be a game changer! <a href="https://t.co/UCmidWcTmP">https://t.co/UCmidWcTmP</a></p>— Andy Jassy (@ajassy) <a href="https://twitter.com/ajassy/status/1271264376394149888?ref_src=twsrc%5Etfw">June 12, 2020</a></blockquote>

<p>
Normally I would expect the Lambda team to migrate workloads to these newer,
cheaper EC2 instances. AWS loves to talk about how they <a href="https://aws.amazon.com/blogs/aws/aws-storage-update-s3-glacier-price-reductions/">"work relentlessly to
reduce [costs] and to pass the resulting savings
along"</a>.
However, with Graviton and Lambda, I don't think they can. A lot of code that
was written for the Intel, or x86 architecture will likely break on ARM, even
if it's running inside virtual machines like Python, or NodeJS. AWS doesn't
know if your Python, or JavaScript code depends on <a href="https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">subtle or less
subtle</a> features of
x86 architecture. If you're using their <a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-custom.html#runtimes-custom-build">custom
runtimes</a>
then it's even worse.</p>
<p>Contrast this to services like S3 and DynamoDB. How would you, a customer know
if the S3, or DynamoDB team migrated from x86 to ARM? You wouldn't. You just
see data going in, and data going out. Everything else is Amazon's problem.</p>
<p>Will serverless hit a speed-bump as the
<a href="https://en.wikipedia.org/wiki/Mac_transition_to_ARM">industry</a>
<a href="https://www.top500.org/news/japan-captures-top500-crown-arm-powered-supercomputer/">shifts</a>
from Intel to ARM? Will we have to recompile our serverless functions to ARM to
get the lowest prices? I haven't seen anybody else talking about this yet, so
either I'm early, or it's less of an issue than I thought.</p>
<h2>Conclusion</h2>
<p>I've just shown one joke way, and two real ways where "servers", or the
underlying hardware are not fully abstracted by serverless. I suspect this is
one reason why people like to
<a href="https://twitter.com/IamStan/status/1018755075827814400">make</a>
<a href="https://twitter.com/findgriffin/status/1205214120569556992">fun</a> of serverless
on Twitter. Additionally, I think those who argue
<a href="https://www.youtube.com/watch?v=Hq3Nx0S27dU">passionately</a> that serverless
isn't the future of our industry have a point. Surely there will be future
waves of innovation that deliver better abstractions, performance, and pricing
than serverless currently does.</p>
<hr>
<p>If you want to help me figure out what might come after serverless, please get
in touch, I have a few ideas.</p>
<hr>
<p><sup id="fn1">1</sup> There is actually a serious point to be made here, which
is to define your branding around what you're <em>for</em> rather than what you're
<em>against</em>. The point of serverless isn't that servers are bad. It's that I (a
developer) don't want to think about them. A better name for serverless might
have been something like "developer-centric", "zero-fixed-cost", or
"granular-scalability"<a href="#fn3"><sup>3</sup></a>.</p>
<p><sup id="fn2">2</sup> I'm only counting <em>compute</em> services here. In other
words, services that execute code. Examples include AWS Lambda, Google Cloud
Functions, Azure Functions, CloudFlare Workers, and Fastly <a href="http://blog.drgriffin.com.au/cdn-cgi/l/email-protection" data-cfemail="a0e3cfcdd0d5d4c5e0e5c4c7c58e">[email&nbsp;protected]</a></p>
<p><sup id="fn3">3</sup> Ok, none of these are great, but hopefully you get the
idea. This is why I don't work in marketing.</p></div></div>]]>
            </description>
            <link>http://blog.drgriffin.com.au/posts/2020-06-28-servers-in-serverless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677411</guid>
            <pubDate>Mon, 29 Jun 2020 13:35:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FastAPI for Flask Users]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23677163">thread link</a>) | @amitness
<br/>
June 29, 2020 | https://amitness.com/2020/06/fastapi-vs-flask/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/06/fastapi-vs-flask/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">

<p>While Flask has become the de-facto choice for API development in Machine Learning projects, there is a new framework called FastAPI that has been getting a lot of community traction.</p>
<p><img src="https://amitness.com/images/flask-to-fastapi.png" alt="Flask and FastAPI Logo"></p>
<p>I recently decided to give FastAPI a spin by porting a production project written in Flask. FastAPI was very easy to pick up coming from Flask and I was able to get things up and running in just a few hours.</p>
<p>The added benefit of automatic data validation, documentation generation and baked-in best-practices such as pydantic schemas and python typing makes this a strong choice for future projects.</p>
<p>In this post, I will introduce FastAPI by contrasting the implementation of various common use-cases in both Flask and FastAPI.</p>
<div>
<p><strong>Version Info:</strong></p><p>
At the time of this writing, the Flask version is 1.1.2 and the FastAPI version is 0.58.1
</p>
</div>
<h2 id="installation">Installation</h2>
<p>Both Flask and FastAPI are available on PyPI. For conda, you need to use the <code>conda-forge</code> channel to install FastAPI while it’s available in the default channel for Flask.</p>
<p><strong>Flask:</strong></p>
<div><div><pre><code>pip <span>install </span>flask
conda <span>install </span>flask
</code></pre></div></div>
<p><strong>FastAPI:</strong></p>
<div><div><pre><code>pip <span>install </span>fastapi uvicorn
conda <span>install </span>fastapi uvicorn <span>-c</span> conda-forge
</code></pre></div></div>
<h2 id="running-hello-world">Running “Hello World”</h2>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span># app.py
</span><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>home</span><span>():</span>
    <span>return</span> <span>{</span><span>'hello'</span><span>:</span> <span>'world'</span><span>}</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>app</span><span>.</span><span>run</span><span>()</span>
</code></pre></div></div>
<p>Now you can run the development server using the below command. It runs on port 5000 by default.</p>

<p><strong>FastAPI</strong></p>
<div><div><pre><code><span># app.py
</span><span>import</span> <span>uvicorn</span>
<span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span>

<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>

<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>home</span><span>():</span>
    <span>return</span> <span>{</span><span>'hello'</span><span>:</span> <span>'world'</span><span>}</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>uvicorn</span><span>.</span><span>run</span><span>(</span><span>app</span><span>)</span>
</code></pre></div></div>
<p>FastAPI defers serving to a production-ready server called <code>uvicorn</code>. We can run it in development mode with a default port of 8000.</p>

<h2 id="production-server">Production server</h2>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span># app.py
</span><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>home</span><span>():</span>
    <span>return</span> <span>{</span><span>'hello'</span><span>:</span> <span>'world'</span><span>}</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>app</span><span>.</span><span>run</span><span>()</span>
</code></pre></div></div>
<p>For a production server, <code>gunicorn</code> is a common choice in Flask.</p>

<p><strong>FastAPI</strong></p>
<div><div><pre><code><span># app.py
</span><span>import</span> <span>uvicorn</span>
<span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span>

<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>

<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>home</span><span>():</span>
    <span>return</span> <span>{</span><span>'hello'</span><span>:</span> <span>'world'</span><span>}</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>uvicorn</span><span>.</span><span>run</span><span>(</span><span>app</span><span>)</span>
</code></pre></div></div>
<p>FastAPI defers serving to a production-ready server called <code>uvicorn</code>. We can start the server as:</p>

<p>You can also start it in hot-reload mode by running</p>

<h2 id="http-methods">HTTP Methods</h2>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>'POST'</span><span>])</span>
<span>def</span> <span>example</span><span>():</span>
    <span>...</span>
</code></pre></div></div>
<p><strong>FastAPI:</strong></p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>post</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>example</span><span>():</span>
    <span>...</span>
</code></pre></div></div>
<p>You have individual decorator methods for each HTTP method.</p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>app</span><span>.</span><span>put</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>app</span><span>.</span><span>patch</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>app</span><span>.</span><span>delete</span><span>(</span><span>'/'</span><span>)</span>
</code></pre></div></div>
<h2 id="url-variables">URL Variables</h2>
<p>We want to get the user id from the URL e.g. <code>/users/1</code> and then return the user id to the user.</p>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/users/&lt;int:user_id&gt;'</span><span>)</span>
<span>def</span> <span>get_user_details</span><span>(</span><span>user_id</span><span>):</span>
    <span>return</span> <span>{</span><span>'user_id'</span><span>:</span> <span>user_id</span><span>}</span>
</code></pre></div></div>
<p><strong>FastAPI:</strong></p>
<p>In FastAPI, we make use of type hints in Python to specify all the data types. For example, here we specify that <code>user_id</code> should be an integer. The variable in the URL path is also specified similar to f-strings.</p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/users/{user_id}'</span><span>)</span>
<span>def</span> <span>get_user_details</span><span>(</span><span>user_id</span><span>:</span> <span>int</span><span>):</span>
    <span>return</span> <span>{</span><span>'user_id'</span><span>:</span> <span>user_id</span><span>}</span>
</code></pre></div></div>
<h2 id="query-strings">Query Strings</h2>
<p>We want to allow the user to specify a search term by using a query string <code>?q=abc</code> in the URL.</p>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span>from</span> <span>flask</span> <span>import</span> <span>request</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/search'</span><span>)</span>
<span>def</span> <span>search</span><span>():</span>
    <span>query</span> <span>=</span> <span>request</span><span>.</span><span>args</span><span>.</span><span>get</span><span>(</span><span>'q'</span><span>)</span>
    <span>return</span> <span>{</span><span>'query'</span><span>:</span> <span>query</span><span>}</span>
</code></pre></div></div>
<p><strong>FastAPI:</strong></p>
<div><div><pre><code><span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/search'</span><span>)</span>
<span>def</span> <span>search</span><span>(</span><span>q</span><span>:</span> <span>str</span><span>):</span>
    <span>return</span> <span>{</span><span>'query'</span><span>:</span> <span>q</span><span>}</span>
</code></pre></div></div>
<h2 id="json-post-request">JSON POST Request</h2>
<p>Let’s take a toy example where we want to send a JSON POST request with a <code>text</code> key and get back a lowercased version.</p>
<div><div><pre><code><span>#</span><span> </span><span>Request</span><span>
</span><span>{</span><span>"text"</span><span>:</span><span> </span><span>"HELLO"</span><span>}</span><span>

</span><span>#</span><span> </span><span>Response</span><span>
</span><span>{</span><span>"text"</span><span>:</span><span> </span><span>"hello"</span><span>}</span><span>
</span></code></pre></div></div>
<p><strong>Flask:</strong></p>
<div><div><pre><code><span>from</span> <span>flask</span> <span>import</span> <span>request</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/lowercase'</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>'POST'</span><span>])</span>
<span>def</span> <span>lower_case</span><span>():</span>
    <span>text</span> <span>=</span> <span>request</span><span>.</span><span>json</span><span>.</span><span>get</span><span>(</span><span>'text'</span><span>)</span>
    <span>return</span> <span>{</span><span>'text'</span><span>:</span> <span>text</span><span>.</span><span>lower</span><span>()}</span>
</code></pre></div></div>
<p><strong>FastAPI:</strong><br>
If you simply replicate the functionality from Flask, you can do it as follows in FastAPI.</p>
<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Dict</span>

<span>@</span><span>app</span><span>.</span><span>post</span><span>(</span><span>'/lowercase'</span><span>)</span>
<span>def</span> <span>lower_case</span><span>(</span><span>json_data</span><span>:</span> <span>Dict</span><span>):</span>
    <span>text</span> <span>=</span> <span>json_data</span><span>.</span><span>get</span><span>(</span><span>'text'</span><span>)</span>
    <span>return</span> <span>{</span><span>'text'</span><span>:</span> <span>text</span><span>.</span><span>lower</span><span>()}</span>
</code></pre></div></div>
<p>But, this is where FastAPI introduces a new concept of creating Pydantic schema that maps to the JSON data being received. We can refactor the above example using pydantic as:</p>
<div><div><pre><code><span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span>

<span>class</span> <span>Sentence</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>text</span><span>:</span> <span>str</span>

<span>@</span><span>app</span><span>.</span><span>post</span><span>(</span><span>'/lowercase'</span><span>)</span>
<span>def</span> <span>lower_case</span><span>(</span><span>sentence</span><span>:</span> <span>Sentence</span><span>):</span>
    <span>return</span> <span>{</span><span>'text'</span><span>:</span> <span>sentence</span><span>.</span><span>text</span><span>.</span><span>lower</span><span>()}</span>
</code></pre></div></div>
<p>As seen, instead of getting a dictionary, the JSON data is converted into an object of the schema <code>Sentence</code>. As such, we can access the data using data attributes such as <code>sentence.text</code>. This also provides automatic validation of data types. If the user tries to send any data other than a string, they will be given an auto-generated validation error.</p>
<p><strong>Example Invalid Request</strong></p>

<p><strong>Automatic Response</strong></p>
<div><div><pre><code><span>{</span><span>
    </span><span>"detail"</span><span>:</span><span> </span><span>[</span><span>
        </span><span>{</span><span>
            </span><span>"loc"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>"body"</span><span>,</span><span>
                </span><span>"text"</span><span>
            </span><span>],</span><span>
            </span><span>"msg"</span><span>:</span><span> </span><span>"none is not an allowed value"</span><span>,</span><span>
            </span><span>"type"</span><span>:</span><span> </span><span>"type_error.none.not_allowed"</span><span>
        </span><span>}</span><span>
    </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>
<h2 id="modular-views">Modular Views</h2>
<p>We want to decompose the views from a single app.py into separate files.</p>
<div><div><pre><code><span>-</span><span> </span><span>app.py</span><span>
</span><span>-</span><span> </span><span>views</span><span>
  </span><span>-</span><span> </span><span>user.py</span><span>
</span></code></pre></div></div>
<p><strong>Flask:</strong><br>
In Flask, we use a concept called blueprints to manage this. We would first create a blueprint for the user view as:</p>
<div><div><pre><code><span># views/user.py
</span><span>from</span> <span>flask</span> <span>import</span> <span>Blueprint</span>
<span>user_blueprint</span> <span>=</span> <span>Blueprint</span><span>(</span><span>'user'</span><span>,</span> <span>__name__</span><span>)</span>

<span>@</span><span>user_blueprint</span><span>.</span><span>route</span><span>(</span><span>'/users'</span><span>)</span>
<span>def</span> <span>list_users</span><span>():</span>
    <span>return</span> <span>{</span><span>'users'</span><span>:</span> <span>[</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'c'</span><span>]}</span>

</code></pre></div></div>
<p>Then, this view is registered in the main <code>app.py</code> file.</p>
<div><div><pre><code><span># app.py
</span><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>from</span> <span>views.user</span> <span>import</span> <span>user_blueprint</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>app</span><span>.</span><span>register_blueprint</span><span>(</span><span>user_blueprint</span><span>)</span>
</code></pre></div></div>
<p><strong>FastAPI:</strong><br>
In FastAPI, the equivalent of a blueprint is called a router. First, we create a user router as:</p>
<div><div><pre><code><span># routers/user.py
</span><span>from</span> <span>fastapi</span> <span>import</span> <span>APIRouter</span>
<span>router</span> <span>=</span> <span>APIRouter</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>get</span><span>(</span><span>'/users'</span><span>)</span>
<span>def</span> <span>list_users</span><span>():</span>
    <span>return</span> <span>{</span><span>'users'</span><span>:</span> <span>[</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'c'</span><span>]}</span>
</code></pre></div></div>
<p>Then, we attach this router to the main app object as:</p>
<div><div><pre><code><span># app.py
</span><span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span>
<span>from</span> <span>routers</span> <span>import</span> <span>user</span>

<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>
<span>app</span><span>.</span><span>include_router</span><span>(</span><span>user</span><span>.</span><span>router</span><span>)</span>
</code></pre></div></div>
<h2 id="data-validation">Data Validation</h2>
<p><strong>Flask</strong><br>
Flask doesn’t provide any input data validation feature out-of-the-box. It’s common practice to either write custom validation logic or use libraries such as <a href="https://marshmallow.readthedocs.io/en/stable/">marshmalllow</a> or <a href="https://pydantic-docs.helpmanual.io/">pydantic</a>.</p>
<p><strong>FastAPI:</strong></p>
<p>FastAPI wraps pydantic into its framework and allow data validation by simply using a combination of pydantic schema and python type hints.</p>
<div><div><pre><code><span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span>
<span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span>

<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>

<span>class</span> <span>User</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>age</span><span>:</span> <span>int</span>

<span>@</span><span>app</span><span>.</span><span>post</span><span>(</span><span>'/users'</span><span>)</span>
<span>def</span> <span>save_user</span><span>(</span><span>user</span><span>:</span> <span>User</span><span>):</span>
    <span>return</span> <span>{</span><span>'name'</span><span>:</span> <span>user</span><span>.</span><span>name</span><span>,</span>
            <span>'age'</span><span>:</span> <span>user</span><span>.</span><span>age</span><span>}</span>
</code></pre></div></div>
<p>This code will perform automatic validation to ensure <code>name</code> is a string and <code>age</code> is an integer. If any other data type is sent, it auto-generates validation error with a relevant message.</p>
<p>Here are some examples of pydantic schema for common use-cases.</p>
<h3 id="example-1-key-value-pairs">Example 1: Key-value pairs</h3>
<div><div><pre><code><span>{</span><span>
  </span><span>"name"</span><span>:</span><span> </span><span>"Isaac"</span><span>,</span><span>
  </span><span>"age"</span><span>:</span><span> </span><span>60</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>
<div><div><pre><code><span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span>

<span>class</span> <span>User</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>age</span><span>:</span> <span>int</span>
</code></pre></div></div>
<h3 id="example-2-collection-of-things">Example 2: Collection of things</h3>
<div><div><pre><code><span>{</span><span>
  </span><span>"series"</span><span>:</span><span> </span><span>[</span><span>"GOT"</span><span>,</span><span> </span><span>"Dark"</span><span>,</span><span> </span><span>"Mr. Robot"</span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>
<div><div><pre><code><span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span>
<span>from</span> <span>typing</span> <span>import</span> <span>List</span>

<span>class</span> <span>Metadata</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>series</span><span>:</span> <span>List</span><span>[</span><span>str</span><span>]</span>
</code></pre></div></div>
<h3 id="example-3-nested-objects">Example 3: Nested Objects</h3>
<div><div><pre><code><span>{</span><span>
  </span><span>"users"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"xyz"</span><span>,</span><span>
      </span><span>"age"</span><span>:</span><span> </span><span>25</span><span>
    </span><span>},</span><span>
    </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"abc"</span><span>,</span><span>
      </span><span>"age"</span><span>:</span><span> </span><span>30</span><span>
    </span><span>}</span><span>
  </span><span>],</span><span>
  </span><span>"group"</span><span>:</span><span> </span><span>"Group A"</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>
<div><div><pre><code><span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span>
<span>from</span> <span>typing</span> <span>import</span> <span>List</span>

<span>class</span> <span>User</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>age</span><span>:</span> <span>int</span>

<span>class</span> <span>UserGroup</span><span>(</span><span>BaseModel</span><span>):</span>
    <span>users</span><span>:</span> <span>List</span><span>[</span><span>User</span><span>]</span>
    <span>group</span><span>:</span> <span>str</span>
</code></pre></div></div>
<p>You can learn more about Python Type hints from <a href="https://fastapi.tiangolo.com/python-types/">here</a>.</p>
<h2 id="automatic-documentation">Automatic Documentation</h2>
<p><strong>Flask</strong><br>
Flask doesn’t provide any built-in feature for documentation generation. There are extensions such as <a href="https://pypi.org/project/flask-swagger/">flask-swagger</a> or <a href="https://flask-restplus.readthedocs.io/en/stable/swagger.html">flask-restful</a> to fill that gap but the workflow is comparatively complex.</p>
<p><strong>FastAPI:</strong><br>
FastAPI automatically generates an interactive swagger documentation endpoint at <code>/docs</code> and a reference documentation at <code>/redoc</code>.</p>
<p>For example, say we had a simple view given below that echoes what the user searched for.</p>
<div><div><pre><code><span># app.py
</span><span>from</span> <span>fastapi</span> <span>import</span> <span>FastAPI</span>

<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>

<span>@</span><span>app</span><span>.</span><span>get</span><span>(</span><span>'/search'</span><span>)</span>
<span>def</span> <span>search</span><span>(</span><span>q</span><span>:</span> <span>str</span><span>):</span>
    <span>return</span> <span>{</span><span>'query'</span><span>:</span> <span>q</span><span>}</span>
</code></pre></div></div>
<h3 id="swagger-documentation">Swagger Documentation</h3>
<p>If you run the server and goto the endpoint <code>http://127.0.0.1:8000/docs</code>, you will get an auto-generated swagger documentation.</p>
<p><img src="https://amitness.com/images/fastapi-swagger.png" alt="OpenAPI Swagger UI in FastAPI"></p>
<p>You can interactively try out the API from the browser itself.</p>
<p><img src="https://amitness.com/images/fastapi-swagger-interactive.png" alt="Interactive API Usage in FastAPI"></p>
<h3 id="redoc-documentation">ReDoc Documentation</h3>
<p>In addition to swagger, if you goto the endpoint <code>http://127.0.0.01:8000/redoc</code>, you will get an auto-generated reference documentation. There is information on parameters, request format, response format and status codes.<br>
<img src="https://amitness.com/images/fastapi-redoc.png" alt="ReDoc functionality in FastAPI"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Thus, FastAPI is an excellent alternative to Flask for building robust APIs with best-practices baked in. You can refer to the <a href="https://fastapi.tiangolo.com/">documentation</a> to learn more.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://fastapi.tiangolo.com/">FastAPI Documentation</a></li>
<li><a href="https://pydantic-docs.helpmanual.io/">Pydantic Documentation</a></li>
<li><a href="https://www.uvicorn.org/">Uvicorn: The lightning-fast ASGI server</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/2020/06/fastapi-vs-flask/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677163</guid>
            <pubDate>Mon, 29 Jun 2020 13:01:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to keep moving fast (As your startup grows)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23677128">thread link</a>) | @sabbakeynejad
<br/>
June 29, 2020 | https://www.veed.io/blog/how-to-move-fast/ | <a href="https://web.archive.org/web/*/https://www.veed.io/blog/how-to-move-fast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/MovingFAST.png 300w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/MovingFAST.png 600w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/MovingFAST.png 1000w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/MovingFAST.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/MovingFAST.png" alt="How to move fast">
            </figure>

            <section>
                <div>
                    <p>Why do startups move fast and enterprises move slowly?</p><p>I recently had a call with an ex-employee of a well known and a well-funded startup that has been around for a few years, let's say it was a household name.</p><p>She told me that getting anything done was slow, painful and costing the company growth and even worse, stopping the company quickly capitalising on new opportunities.</p><p>She then preceded to say that speed was one of our biggest strategic advantages as an early-stage startup.</p><p>I don't disagree.</p><p>Over the last 12 months, our startup VEED has moved extremely fast and grown even faster. It has been a lot of fun. Now that our team is getting close to 20 (Yikes :S) I can feel things slowing down a little.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/Screenshot-2020-06-29-at-11.42.34.png"><figcaption>Growth At VEED - Indie Hackers</figcaption></figure><p>I am somewhat cool with that...</p><p>However, I want to try and uncover the exact formula that has allowed startups like ours to move fast so we can continue to do so in the future the bigger we grow. The main questions I would like to answer in this post are:</p><ul><li>What are the advantages of moving fast?</li><li>Can you build an infrastructure to allow your company to move fast?</li><li>How to build and hire a fast team?</li><li>And finally, how to continue moving fast as your company gets bigger?</li></ul><p>As this article is all about moving fast, let's get onto the first topic?</p><h3 id="what-are-the-advantages-of-moving-fast">What are the advantages of moving fast?</h3><p>By moving fast you can amplify the speed of learning in your company. The speed of learning is important because this gives the ability to make better-informed decisions on real data. This allows you to validate your ideas and hypothesis quicker.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/SpeedOfLEarning-.png"><figcaption>Publish fast, learn fast</figcaption></figure><p>If you can Build -&gt; Measure -&gt; Learn a product feature in just 1 week instead of 4, you will be 4 times closer to satisfying your customers needs in the same period of time. Simple, of course, but this means your are quicker to market and by building a better product quicker you help the company to start making money on these features faster.</p><p>For example, If we added billing to VEED 4 month earlier, our revenue would be double what it is now, that's a big deal and a lot of money. </p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/Add-Text-Copy-145.png"><figcaption>Cost of delay @ VEED.IO</figcaption></figure><p>However, by doing so you are obviously going to have to compromise. You absolutely have to "cut the fat" to see results quicker. This might mean reducing the desired feature set for launch, not having pixel-perfect implementation or handing over ownership to your team.</p><p>All the three points above perfectly sum up the first few months of our startup journey as we hacked together VEED. These were our humble scrappy beginnings ❤️</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/IMG_6063-1.jpg"><figcaption>First Office</figcaption></figure><p>One of my tutors at art school (Rebecca Ross) said something to me that I will never forget. "Perfectionism is a form of procrastination" As many early-stage startup founders come from a product background, it's easy to convince yourself that building polished feature after feature is a good use of your time, however, you might just be heading in the completely wrong direction.</p><p>The final strategic advantage for a startup to move fast is that you are able to simply outpace your competition before they have time to react and capture market share.</p><p>For example, we could easily assume competitors of ours such as Adobe are working on competing product offerings, however, they are not able to to move as fast as us.</p><p>It is crazy! Think about it, a bootstrapped company can move faster than corporate such as Adobe with a $190Bn Market cap!</p><h3 id="why-can-startups-move-fast">Why can startups move fast?</h3><p>Startups are fast.</p><p>Big companies are slow.</p><p>But why?</p><p>One common idea is related to network latency. The idea is simple, in a small team, information passing, validation of ideas and decision making can be made quickly as all of these things don't need to go through layers of bureaucracy.</p><p>Let's look at an example.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/moving-fast-veed.png"><figcaption><strong>Why can startups move fast?</strong></figcaption></figure><p>Above we can see that by reducing the number of stakeholders, information can flow quicker and therefore decisions can be made much faster. Amazon believes that 2 pizzas should feed each team. By keeping teams small, cross-functional and agile you can avoid holdups and eat the pizza while it is still hot!</p><blockquote><em>For more on this topic, I recommend reading the The Everything Store - by Brad Stone where he goes into detail how Amazon builds cross-functional teams.</em></blockquote><p><br>In the early days of VEED the team was just Tim and myself, between us we covered design, product, dev and marketing. Our next two hires Mate &amp; Veljko were also not afraid to step out of their comfort zone and work with new challenges outside their designated roles.</p><h3 id="how-can-you-build-an-infrastructure-to-allows-you-to-move-fast">How can you build an infrastructure to allows you to move fast?</h3><p>Another reason startups can move fast is they don not yet have the same infrastructure to maintain vs their enterprise counterparts. As your company gets bigger, so does your codebase, your user needs, testing surface area and more.</p><p>So how do you build an infrastructure that allows you to move fast. The answer is simple, you don't! Here is a good example I recently came across.</p><p>Superhuman is a popular email client that has raised over $33M in funding. A few weeks ago I went to update my billing information on the app and saw they were using Stripe's default checkout. Superhuman has the resources to build a custom checkout, however, they opted to use the default option provided by stipe.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/EXfLrkMWoAA57EN.jpeg"><figcaption>Keep it simple</figcaption></figure><p>I have a lot of respect for this. Superhuman is clearly focusing on building more value into the core reason why the user originally bought the product. Not spending time making a nice checkout process.</p><p>As I reflect on this, we have spent way too much time building custom login systems, custom checkouts and marketing automations that could have been spent building a better video editor.</p><p>In light of this, we have now moved all of our marking sites to Webflow and all of our marketing automation to Zappier. The idea is to use 3rd party tools / low code / no code wherever you can, so we can focus on building a great video editor. Everything else outside of video editing and our core value proposition is not where we should be spending our time, it is not what we are good at. By doing this you are reducing technical debt, engineering time and allowing your entire team to move faster.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/IMG_20200629_115539.jpg"><figcaption>Building Marketing Sites in Webflow</figcaption></figure><p>Let's look at building a login system from engineering point of view, as it is a good example. A customer login system requires connecting a mail provider, building password reset, protecting users data, adding the ability to update email and so much more. In addition, we had more than 10 customer service tickers every day with users who were unable to login. Most of the time they simply forgot the password or entered their email wrong. VS opting for passwordless login, we don't need to think about any of the above while also benefiting from incredibly low maintenance.</p><h3 id="how-to-build-a-fast-team">How to build a fast team?</h3><p>Just like when putting together Jamaica's first bobsled team, picking candidates that are already fast is a proven way to to make sure you have the DNA for speed. We like to look for side projects, self-initiated work, hunger to learn. We also look for candidates that show the ability to manage their own time well and also have the attitude to do their best work. &nbsp;However, we just don't have enough experience with hiring right now to effectively comment on this.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/06/cool-2.jpg"><figcaption>Moving Fast - Cool Runnings</figcaption></figure><p>Fortunately, the one thing we do have a lot of experience in is messing up! We believe that having a no-blame culture helps provide an environment that allows our team to experiment and make mistakes and if we are not making mistakes, we are not taking enough risks. If you had to attempt a backflip without a soft landing, there is little chance that you would attempt it, however knowing fully well that there is a soft landing, there is a good chance you will give it a go.</p><blockquote><em>The idea of a no-blame culture is partly stolen from Creativity, Inc - Amy Wallace and Edwin Catmull.</em></blockquote><h3 id="how-to-continue-moving-fast-as-your-company-gets-bigger">How to continue moving fast as your company gets bigger?</h3><p>Now we have explored all the main points that I wanted to cover, its time to put together a list of our key learnings for this post to help us to continue to move fast as we get bigger.</p><p><strong>Teams</strong></p><p>Keep teams small &amp; cross-functional. Keep information moving between the teams fast and avoid any outside stakeholders/gatekeepers. You should fully trust your team to do an amazing job, that's why you hired them.</p><p><strong>Individuals</strong></p><p>Give your team members the freedom to do their best work. Have a no-blame culture by never pointing the finger and celebrating failure.</p><p><strong>Infrastructure</strong></p><p>Less code = the better! More off-the-shelf products means there is no need to reinvent the wheel. Don't block the team and empower everyone to push work/changes to production fast.</p><p><strong>The road ahead</strong></p><p>Provide top-line strategies, but provide enough flexibility to go off-piste... Rules are there to be broken! Remember validated learning with quicker feedback loops = faster team!</p><p>Final thoughts, there are going to be many things I have missed from this article, and in the spirit of moving fast, if this resonates with readers, we will be back to update it with more info. If you need an online video editing app or an amazing subtitle tool, this is something we can definitely help you out with.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to VEED Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.veed.io/blog/how-to-move-fast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23677128</guid>
            <pubDate>Mon, 29 Jun 2020 12:56:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook's News Tab is shifting media distribution through private virality]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676993">thread link</a>) | @exanimo_sai
<br/>
June 29, 2020 | https://4thquadrant.io/articles/transformations/facebook-is-shifting-media-distribution-through-private-virality/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/articles/transformations/facebook-is-shifting-media-distribution-through-private-virality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_afa">

<div>
<p>Facebook’s rise popularised the ‘News Feed’ as a social, infinitely scrollable aggregation of content posted by your family, friends and liked pages. Made up of ‘news’ closer to the home, the feed was largely composed of personal milestones, announcements, photo albums etc. But in late 2019 Facebook introduced a beta feature called the ‘News Tab’ that’s now been rolled out in the US this month, an entirely separate feature to the News Feed that focuses on aggregating news from vetted sources based on user curation. Though not immediately obvious, this is in fact a step toward its more private and personal approach to the platform – here we’re talking about the aggregation and distribution of news and journalism moving closer to its readership, with user-curated and distributed news bringing mainstream media into the fold of the user’s smaller, more personal circles.&nbsp;</p>



<p>Given that the premise of Facebook remains largely social, the introduction of this feature doesn’t necessarily mean all users will jump at the opportunity to actively curate and share news. It’s even located oddly offscreen where users need to click on the three-line “hamburger” and then find the news box amid other menu options. The News Tab rather represents a point of distribution, where the users who do actively participate will take on the role of curators for their respective networks within the platform. If successful, the News Tab represents a shift in the power of news distribution – away from publications and toward power users who have the ability to propagate information through the social network.&nbsp;</p>



<h3>Why do users hold more distribution power within the Facebook ecosystem?&nbsp;</h3>



<p>There are two factors that enable users to hold more distribution power within the Facebook ecosystem and they’re very much intertwined.&nbsp;</p>



<ol><li>Private virality&nbsp;</li><li>Improved efficiency of sharing, discovery and signalling</li></ol>



<p>While private virality sounds like an oxymoron, it simply alludes to the nature of virality (the quick circulation of some media from one internet user to another) within the more private context of a circles-based social media platform like Facebook. To understand why the ‘private’ is an operative term lets explore the characteristics of user propagated information within social circles:&nbsp;</p>



<ol><li>Greater levels of trust as the point of distribution gets closer to the inner circle → <strong>improved efficiency of sharing</strong></li><li>Greater alignment of interests as the point of distribution gets closer to the inner circle → <strong>improved efficiency of discovery&nbsp;</strong></li><li>Greater level of social signalling – social capital generated from social signalling to family and friends is stickier than capital generated in forums like Twitter and Reddit → <strong>improved efficiency of signalling</strong></li></ol>



<p>The virality of user propagated news on Facebook is stronger for the traits it carries as it passes through social channels, even the most tenuous social link is stronger than the links that currently exist between the public and media sources.&nbsp;</p>



<p>The nature of private virality creates improved efficiency of discovery, sharing and signalling –&nbsp; creating a feedback loop that makes it a stronger and stronger proposition each time. Imagine that you, as a reader, discover an article that resonates with you on the source’s primary website (e.g. a NY times or WSJ) and decide to share it with your social or professional circles – at present this requires the added step of ‘porting’. Either follow a share link or copy and paste the article onto another platform. While this step is trivial in nature it signifies a disconnect between the source and destination of information in social networks, a disconnect that the Facebook News Tab would transform into one fluid motion (News Tab to News Feed) making private virality even easier.&nbsp;</p>



<p>The efficiency in sharing, both in terms of ease and relevance, creates better discoverability and in turn, makes for stronger signalling. The incentive to remain a connector node or user who distributes information and the incentive to continue consuming user propagated news appear much clearer and stronger than in the absence of the feature. Publishers, who are still able to tap into other avenues of propagation can expect to relinquish the propagation power within social networks to such connectors or power users –&nbsp; who in this instance are simply more effective distributors.&nbsp;</p>



<h3>Why has Facebook empowered its users as its distributors of information?&nbsp;</h3>



<p>Typically news aggregators or publications act as the point of distribution, resulting in externally curated news feeds. Facebook is banking on shifting the externally determined distribution of news from Facebook or publishers, towards user-centric curation and propagation. It’s important to note that this adds value to the core user base of Facebook (regardless of whether they interact with the News Tab or not), where most consumption will take place in the personal feeds that these connector nodes share news to.&nbsp;</p>



<p>The combination of Facebook’s social capital and a news aggregator tab is not typically available to other mediums of news distribution. This places Facebook in a unique position to not only become an effective news aggregator but also compound on the user stickiness to the platform – essentially extending their core value proposition.&nbsp;</p>



<h3>Why the News Tab is different to previous attempts</h3>



<p>Facebook’s previous iterations of news features like the Open Graph platform in 2011 and Instant Articles in 2015, failed to gain traction and were eventually phased out. This was primarily because Facebook introduced the news as an extraneous element to users’ primary use of Facebook which is to connect with friends and family. Open Graph, which auto shared articles users were reading at the time, came at a time when the platform was still consolidating its social focus. When Facebook changed its feed post design and deprioritised social reader apps in 2012, the platform was abandoned. Instant Articles – an in-application news content hosting feature – suffered a similar fate, it was abandoned in 2017 when Facebook’s restrictions around the content was affecting subscription conversions and ad revenue for the publishers using the feature.&nbsp;</p>



<p>In 2018, Facebook decreased the presence of news in users’ personal feed from 5% to 4% to prioritize content from friends and family. This was Facebook deprioritizing news when it remained a peripheral element of the social network. The introduction of the News Tab, in a time when Facebook is more comfortably able to expand its proposition, speaks to Facebook’s newer strategy of prioritizing user-centricity across all of the platform’s experiences. The quote below, found on Facebook’s media page, is indicative of the platform’s shift to bring news into the fold of more personal experiences:</p>



<p>“Our goal with News Feed is to show you the stories that matter most to you, every time you visit Facebook. Your News Feed is a personalised, ever-changing collection of photos, videos, links and updates from the friends, family, <strong>businesses and news sources</strong> that you’ve connected to on Facebook.”</p>





<p>
<h3><span>Down the Rabbit Hole</span></h3>
</p>



<h3>1. Connectors and the tipping point for information dissemination in social networks</h3>



<p>In his magnum opus, The Tipping Point, Malcolm Gladwell introduces the actors within a network who all have a role to play in the dissemination of information within a network. He references the ‘maven’ – a person who is innately knowledgeable or pursues knowledge and information, the ‘salesman’ – a person with the innate ability to convince others and ‘connector’ – a person with vast social reach and a predisposition for connecting others together.</p>



<p>“But in the case of Connectors, their ability to span many different worlds is a function of something intrinsic to their personality, some combination of curiosity, self-confidence, sociability, and energy.”</p>



<p>Gladwell’s litany on Lois Weisberg, a socialite in 1950s Chicago, is demonstrative of the power of ‘connectors’ to marry information from disparate ends of a network into cohesive and emphatic outcomes.</p>



<p>“if you looked harder at Weisberg’s life you could probably subdivide her experiences into fifteen or twenty worlds… The point about Connectors is that by having a foot in so many different worlds, they have the effect of bringing them all together.</p>



<p>“I [Lois Weisberg] said, do you know anyone in Chicago interested in talking to Arthur Clarke. He said, yeah, Isaac Asimov is in town.”… This is in some ways the archetypal Lois Weisberg story. First, she reaches out to somebody, to someone outside her world. Then, equally important, that person responds to her.”</p>



<p>Extrapolating to modern social networks, the concept of the ‘connector’ is very much still at the heart of information dissemination – where the networking platforms themselves are now the connector – democratising access to information and reach for their millions of users.</p>



<p>Source: The Tipping Point by <a href="https://www.gladwellbooks.com/titles/malcolm-gladwell/the-tipping-point/9780316316965/" target="_blank" rel="noreferrer noopener">Malcolm Gladwell</a></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/articles/transformations/facebook-is-shifting-media-distribution-through-private-virality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676993</guid>
            <pubDate>Mon, 29 Jun 2020 12:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676967">thread link</a>) | @elvismcdermit
<br/>
June 29, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676967</guid>
            <pubDate>Mon, 29 Jun 2020 12:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Klutz Press: books built for learning stuff]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23676862">thread link</a>) | @whatrocks
<br/>
June 29, 2020 | https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>Create wonderful things, be good, have fun</p>
</blockquote>
<p>This is the credo of Klutz Press, the most important book publisher of my childhood. It being summer and all, Hobbes, ol' buddy... let's going exploring!</p>
<h2>What makes a Klutz Press book so good for learning stuff?</h2>
<p>If you've heard of Klutz, then you've likely seen their debut: <a href="https://www.amazon.com/gp/product/0932592007/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0932592007&amp;linkId=adaa512e8af09feab7c571ec8f2863cc">Juggling For the Complete Klutz</a>. </p>
<p><span>
      <a href="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/1cfc2/juggling.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="juggling" title="juggling" src="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/a6d36/juggling.png" srcset="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/222b7/juggling.png 163w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/ff46a/juggling.png 325w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/a6d36/juggling.png 650w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/1cfc2/juggling.png 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>If not, I highly suggest seeking out a copy. Keep in mind, it's more than just a <em>book</em> -- <em>Juggling for the Complete Klutz</em> has these amazing attributes:</p>
<ul>
<li>It's spiral-bound</li>
<li>It has hilarious drawings</li>
<li>It comes attached with three real-life bean bags!</li>
</ul>
<p>These are book super-powers, in my book (a Klutz-worthy pun?). In our day, my sister and I owned, devoured, and treasured these Klutz titles:</p>
<ul>
<li><a href="https://www.amazon.com/gp/product/0932592082/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0932592082&amp;linkId=5bb878d785a02edc2b01eeffd63f9a76">Country and Blues Harmonica for the Musically Hopeless</a> (comes with instructional cassette and a gen-u-ine Hohner harmonica)</li>
<li><a href="https://www.amazon.com/gp/product/1591747007/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1591747007&amp;linkId=bf0dda95c016b59824316ebe42f872ec">Friendship Bracelets Craft Kit</a> (comes with string and supplies for making friendship bracelets)</li>
<li><a href="https://www.amazon.com/gp/product/1878257501/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257501&amp;linkId=7315967f85fba1c812b20b480b0bd966">Table Top Football: A Guide to the Classic Lunchroom Sport</a> (comes with an amazing leather-ish table top football)</li>
<li><a href="https://www.amazon.com/gp/product/1878257536/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257536&amp;linkId=58c3235cd298baf5ec29fb13ee806ced">Cats Cradle</a> (comes with a tie-die cat's cradle string)</li>
<li><a href="https://www.amazon.com/gp/product/1591745047/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1591745047&amp;linkId=905fbe99f4844c375f00baa92f1beee0">Bead Loom Bracelets: Learn to Make Beautiful Beaded Bracelets</a> (comes with beads and string)</li>
<li><a href="https://www.amazon.com/gp/product/1878257412/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257412&amp;linkId=d283508248a4016cd908bd8e37fcea68">Kids Shenanigans</a> (comes with a Whoopie cushion!)</li>
<li><a href="https://www.amazon.com/gp/product/1878257749/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257749&amp;linkId=99f448476dd4b6ce6baae76dbf048446">Earthsearch: A Kid's Geography Museum in a Book</a> (comes with interactive spinners, a sand-powered clock, and a real-life penny)</li>
<li><a href="https://www.amazon.com/gp/product/1878257145/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257145&amp;linkId=6b93493aa3d2cd5660e5e24c404ad5e6">Explorabook: A Kid's Science Museum in a Book</a> (comes with a bunch more interactive projects and whatnots inside the book, like mirrors, spinners, and a packet of algae that you can grow)</li>
</ul>
<p>As a kid, there was nothing better than getting a new Klutz book (ok, maybe a Super Nintendo game). But unlike a replay of <em>Super Mario RPG</em>, these Klutz books require no nostaglia goggles. Here's why I think they're magic:</p>
<h3>Klutz books are spiral-bound</h3>
<p>Books for learning stuff should be able to open up and stay flat. The old 1980s computer manuals for computers like the Commodore VIC-20, the Commodore 64, and <a href="https://www.charlieharrington.com/my-new-old-apple-iie-computer">my new old Apple IIe</a> knew this much -- their manuals were spiral-bound and spell-binding.</p>
<p>So, why don't we see more spiral-bound books? Without knowing that much about printing costs, I imagine they're more expensive. Also, they do look slightly worse on a bookshelf, especially if you're going for that 'grammable color pattern look (so, just don't do this).</p>
<h3>Klutz books come with the required materials</h3>
<p>The little "paper" football that came with the <em>Table Top Football: A Guide to the Classic Lunchroom Sport</em> was a revered grail of mine. I remember that my dad took a sheetrock knife and made a small incision in its plastic case attached to the book so that the football could be slid in and out, with the explicit rule that the football must either be <em>in the case</em> or <em>being used in a game</em>. This is much like the inexorable <a href="https://hypercritical.co/">Jon Siracusan</a> rule for Airpods. Obey, or the Airpods will be instantly lost forever.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="football" title="football" src="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg" srcset="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/d2f63/football.jpg 163w,
https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/c989d/football.jpg 325w,
https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg 334w" sizes="(max-width: 334px) 100vw, 334px" loading="lazy">
  </a>
    </span></p>
<p>Side note that there are some people who just love making small cuts into the plastic cases for things, so that you easily return them to their "pristine" condition. I, myself, don't understand these people. I like wripping these cases to shreds instantly.</p>
<p>Anyway, back to these Klutz books. By including juggling bean bags, yarn for friendship bracelets, or a real harmonica, Klutz Press books gave you everything you needed to get your hands dirty. "Active learning", or something like that. Playing = learning. Etcetera.</p>
<h3>Klutz books have hilarious art</h3>
<p><span>
      <a href="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="shenanigan" title="shenanigan" src="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg" srcset="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/d2f63/shenanigan.jpg 163w,
https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/c989d/shenanigan.jpg 325w,
https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg 450w" sizes="(max-width: 450px) 100vw, 450px" loading="lazy">
  </a>
    </span></p>
<p>Just look at that paper airplane stuck in the teacher's hair!</p>
<p>Klutz had a particular art direction that spoke to me as a child. The goofy people in their guides made me feel like it was <em>okay to be a klutz</em>. </p>
<p>Which brings me to the most important reason that Klutz books are special.</p>
<h3>Klutz books embrace the Beginner's Mindset</h3>
<blockquote>
<p>In the beginner's mind there are many possibilities. In the experts mind there are few - Shunryū Suzuki</p>
</blockquote>
<p>Everyone starts out as a klutz. No matter what. That means it's okay to make mistakes. It can even be funny - in fact, it should be funny! Because it's fun to learn new things.</p>
<p>Being a klutz, making mistakes, having fun, this is the path to wonderful things.</p>
<h2>Who's behind Klutz Press?</h2>
<p>According to <a href="https://en.wikipedia.org/wiki/Klutz_Press">Wikipedia</a>, Klutz Press was founded in 1977 by three friends in Palo Alto.</p>
<p>The apocryphal story is that <a href="https://en.wikipedia.org/wiki/John_Cassidy_(author)">John Cassidy</a>, a recent Stanford grad working as a high school teacher, brought a bucket of tennis balls and some hand-written instructions for juggling to his remedial reading class. The laughs and learning and genuine reading and genuine juggling that ensued inspired Cassidy and his buddies from Stanford to publish <em>Juggling For the Complete Klutz</em> under their new company: Klutz Press.</p>
<p><em>Juggling For the Complete Klutz</em> has sold over 2.5 million copies. But Googling for Klutz Press is somewhat challenging these days. In 2000, Klutz was acquired by a company called Nelvana for $74 million, and in 2002 Klutz became a subsidiary of Scholastic, Inc. This latter merger is a good match in my book, as the Scholastic Book Fair also ranks heavily in my childhood memories of learning to love reading. The only other company I'd feel comfortable with owning Klutz Press is Pizza Hut - thanks to their delicious <a href="https://www.bookitprogram.com/">BOOK-IT!</a> reading program, which brought me dozens of delicious cheese Personal Pan Pizzas during the 1990s. My parents couldn't decide if they hated or loved Pizza Hut for this.</p>
<p>Nowadays, Klutz.com redirects to the Scholastic website, and it's unclear what's out-of-print or available from the voluminous Klutz catalog. So if you do find a genuine Klutz book and kit, I'd snag them quickly!</p>
<p>Luckily, I was able to find a good interview with Cassidy from 1995 on the <a href="https://web.archive.org/web/20110616182712/http://findarticles.com/p/articles/mi_m1154/is_n5_v83/ai_16857996/">Wayback Machine</a>. In 1995, Klutz was at the height of their power and influence in kid's minds. Here are some choice quotes from Cassidy:</p>
<p>On their company culture at Klutz Press:</p>
<blockquote>
<p>"In terms of being laid back, we take a back seat to nobody."</p>
</blockquote>
<p>On their "teaching" style:</p>
<blockquote>
<p>"Talk to a kid about fun and math, and it's like you're talking about two different sides of the universe. If we can climb this mountain, there's nothing we can't tackle."</p>
</blockquote>
<blockquote>
<p>"Kids don't learn all that much by listening or reading. They need to get elbow-deep in a subject and touch it, feel it, and smell it."</p>
</blockquote>
<p>This reminds me of Seymour Paypert's <a href="https://www.amazon.com/gp/product/0465046746/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0465046746&amp;linkId=2949aefc36d4bd9d9f632170d2ac23de">Mindstorms book</a> about his work with LOGO and the Turtle machine (you can check out <a href="https://www.charlieharrington.com/mindstorms">my notes</a> on the book)</p>
<p>The article explains a bit about their business:</p>
<ul>
<li>All of Klutz' books sell for less than $20</li>
<li>They can have low prices because: (1) the books (with their accompanying "stuff") are viewed as more than books - but "toys/novelties", so more retailers than booksellers are interesting in carring them, and (2) they do large printing runs (150k copies vs the usual 10k for children's books)</li>
</ul>
<p>And, importantly, the final word from Cassidy:</p>
<blockquote>
<p>"I can hang a spoon off my nose," Cassidy boasts, "and I take a lot of pride in that".</p>
</blockquote>
<h2>Create wonderful things, be good, have fun</h2>
<p>I just wanted to write that out again. I've decided to adopt their credo as my own life motto.</p>
<p>I learned so much from Klutz Press as a kid. I'm still learning now. Thank you, John Cassidy and team, for making these wonderful books. My juggling is finally starting to get pretty good, but I'll always be a klutz.</p></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676862</guid>
            <pubDate>Mon, 29 Jun 2020 12:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effortless Versioning of Go Tools for Your Project? BinGo]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676587">thread link</a>) | @witcher
<br/>
June 29, 2020 | https://www.bwplotka.dev/2020/bingo/ | <a href="https://web.archive.org/web/*/https://www.bwplotka.dev/2020/bingo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://bwplotka.dev/images/blog/bingo/demo.gif"></p><p><em>See bigger version of the above demo as .gif <a href="https://raw.githubusercontent.com/bwplotka/bingo/master/examples/bingo-demo.gif" rel="nofollow noreferrer" target="_blank">here</a></em></p><p>In this blog post, I would like to introduce <a href="https://github.com/bwplotka/bingo" rel="nofollow noreferrer" target="_blank"><code>bingo</code></a>, a simple and efficient CLI (Command Line Interface) Tool ,
I wrote for managing versions of Go binaries that are required for your project development.</p><p><strong>TL;DR: <code>bingo</code> is built on top of the native <a href="https://github.com/golang/go/wiki/Modules" rel="nofollow noreferrer" target="_blank">Go Modules dependency management</a> and in my opinion,
it solves the hard problem of flexible versioning developer tools written in Go. It already improves our integration with tools in the
production-grade projects like <a href="https://thanos.io/" rel="nofollow noreferrer" target="_blank">Thanos</a>. Check it out and contribute!🤗</strong></p><figure><img src="https://bwplotka.dev/images/ring.svg" data-sizes="auto" data-src="https://bwplotka.dev/images/blog/bingo/automation.gif" alt="This is NOT what you want to do in your project..."><figcaption>This is NOT what you want to do in your project...</figcaption></figure><blockquote><p>Automation is <strong>amazing</strong>.</p></blockquote><p>Especially nowadays, all projects, whether open or closed source, use at least bunch of tools to automate some tasks. For example in Go community
you can see following popular tools:</p><ul><li>Running tests: <code>go test</code>, <code>go test -race</code></li><li>Benchmarks: <code>go bench</code>, <a href="https://pkg.go.dev/golang.org/x/tools/cmd/benchcmp?tab=doc" rel="nofollow noreferrer" target="_blank"><code>benchcmp</code></a>, <a href="https://godoc.org/golang.org/x/perf/cmd/benchstat" rel="nofollow noreferrer" target="_blank"><code>benchstat</code></a>, <a href="https://github.com/prometheus/test-infra/tree/master/funcbench" rel="nofollow noreferrer" target="_blank"><code>funcbench</code></a></li><li>Auto formatters: <code>go fmt</code>, <a href="https://godoc.org/golang.org/x/tools/cmd/goimports" rel="nofollow noreferrer" target="_blank"><code>goimports</code></a></li><li>Static analysis: <code>go vet</code>, <a href="https://github.com/golang/lint" rel="nofollow noreferrer" target="_blank"><code>lint</code></a>, <a href="https://github.com/golangci/golangci-lint" rel="nofollow noreferrer" target="_blank"><code>golangci-lint</code></a>, <a href="https://github.com/fatih/faillint" rel="nofollow noreferrer" target="_blank"><code>faillint</code></a></li><li>Documentation Generators: <a href="https://github.com/campoy/embedmd" rel="nofollow noreferrer" target="_blank"><code>embedmd</code></a>, <a href="https://github.com/thanos-io/thanos/tree/master/scripts/cfggen" rel="nofollow noreferrer" target="_blank">docs auto generators</a></li><li>Build tools: <a href="https://github.com/goreleaser/goreleaser" rel="nofollow noreferrer" target="_blank"><code>goreleaser</code></a>, <a href="https://github.com/prometheus/promu" rel="nofollow noreferrer" target="_blank"><code>promu</code></a></li><li>Other projects (!) you want to run integrations tests against.</li><li>…and millions of other tools: <a href="https://gohugo.io/" rel="nofollow noreferrer" target="_blank">website builder</a>, <a href="https://github.com/raviqqe/liche" rel="nofollow noreferrer" target="_blank">link check</a>, <a href="https://github.com/thanos-io/thanos/tree/master/scripts/copyright" rel="nofollow noreferrer" target="_blank">copyright checker</a>, protobuf + gRPC generation, jsonnet generators and bundlers, <a href="https://github.com/brancz/gojsontoyaml" rel="nofollow noreferrer" target="_blank">YAML tools</a>, etc…</li></ul><p>I could list even more, and to be honest, I am so amazed with the amount of things we have <strong>for free</strong>! They help to maintain a very good quality of the
project, and saves an enormous amount of time.</p><p>So what projects do? They obviously tend to use gazillion of those tools, reusing amazing ideas and solid code that someone else in open source wrote
and maintains every day with love.</p><p>That’s great, but how many times you have cloned the project, want to contribute run <code>make</code> and see things like:</p><pre><code>$ make 
zsh: command not found: clang
zsh: command not found: goimports
zsh: command not found: goreleaser
zsh: command not found: hugo
</code></pre><p>And that’s even a nice error! Usually, you get a confusing error that does not make any sense like:</p><pre><code>$ make 
dafg;lkghd;lsfjgpdsjgp 
zsh: exit 1
</code></pre><p>…because you have the required tool installed but <strong>WRONG version</strong> of it!</p><p>Now, if you want to be a nice project to work with, you give a hand and either print meaningful errors and tells how
to install a dependant tool and what version of it, in case of users not having a tool or have the wrong version installed. This is
a step in a good direction, but in my opinion <strong>we can do much better.</strong></p><p>In all projects I maintain, we tried hard to be even more explicit and helpful by ensuring our scripts will install all dependencies
needed manually. We also largely leverage a good, old school <a href="https://www.gnu.org/software/make/manual/make.html" rel="nofollow noreferrer" target="_blank"><code>Makefile</code></a> for tasks like this.
It is as easy as:</p><pre><code>DEPENDENCY_TOOL = $(GOBIN)/tool 

task: $(DEPENDENCY_TOOL)
	@do task using $(DEPENDENCY_TOOL)

# Will be built only if $(GOBIN)/tool file is missing.
$(DEPENDENCY_TOOL):
	@install tool
</code></pre><h2 id="always-pin-the-version">Always Pin the Version</h2><p>The above example works great, but obviously will not always work if you require a <strong>certain</strong> version of the tool.
If you would remember only one thing from this blog post, remember this:</p><blockquote><p>You really want to pin version of ALL the tools your project depends on!</p></blockquote><p>Why? Well, the quick answer is that versioning is hard and things are constantly moving. Tools are being improved and changed every day.</p><p>Trust me, the last things you want to do is to investigate why CI constantly fails or have the spam of bugs and issues, about someone, somewhere
being unable to build your project because of an obsolete, or a too new tool that was required.</p><p>We can easily extend our above <code>Makefile</code> example to improve resiliency and development experience by pinning tools’ versions
and maintaining immutable binary files.</p><p>Immutable binary names safeguard us from accidental usage of the wrong version that might have been installed outside. There is nothing worse than chasing a non-existing issue, only to realize you use the wrong version.</p><p>Without immutability, we would have to checksum and verify all build to ensure the correct version which is doable, just a bit more complex to maintain. (BTW, how nice it would
be to have CLI <code>man</code> equivalent for printing <code>version</code>! (: ).</p><p>We can achieve immutable binary names, as follows:</p><pre><code>DEPENDENCY_TOOL_VERSION = v1.124.3
DEPENDENCY_TOOL        = $(GOBIN)/tool-$(DEPENDENCY_TOOL_VERSION)

task: $(DEPENDENCY_TOOL)
   @do task using $(DEPENDENCY_TOOL) 

# Will be built only if $(GOBIN)/tool-v1.124.3 file is missing.
$(DEPENDENCY_TOOL):
   @install tool@$(DEPENDENCY_TOOL_VERSION)
   @cp tool $(DEPENDENCY_TOOL)
</code></pre><p>Version pinning was easy, right? Now, fun stuff, how can we reliably install those tools in the required version? Let’s look at possible solutions:</p><h3 id="commit-built-dependant-binaries-straight-to-your-vcs-e-g-git">Commit built, dependant binaries straight to your VCS (e.g git) 😱</h3><p>This is usually <strong>a bad idea</strong>. While it might work for you, other users would probably want to run your software on different
machines with different architectures and different operating systems, etc. And even if you would host all permutations of
each required binary, each can “weight” from 10-100MB which is most likely too much for common VCSs (e.g <code>git</code>). This
will make it extremely slow, if not impossible to clone your project. Plus there is no merge conflict resolution that
works well for binary files.</p><p>Hope I made this clear: Please don’t do this. (:</p><h3 id="use-package-manager">Use Package Manager</h3><p>Now, this is what’s usually recommended, and it looks innocent.</p><figure><img src="https://bwplotka.dev/images/blog/bingo/pkg.jpg" data-sizes="auto" data-src="https://bwplotka.dev/images/blog/bingo/pkg.jpg" alt="Use Package Manager they said..."><figcaption>Use Package Manager they said...</figcaption></figure><p>The idea would be to use the package manager available on the user’s OS e.g. <code>apt</code> <code>yum</code>, etc.</p><p>I will stop here because in practice this is impossible. Let’s look at the following reasons:</p><ul><li>While there are standard package managers for major operating systems, some people might not use it (you can disable it).
On top of there are 99% chances that the amazing tool you need is not packaged there or the version available is extremely old.</li><li>There are other custom pkg managers like <code>snap</code>, <code>brew</code>, <code>npm</code>, <code>pacman</code> <code>NuGet</code> <code>pip</code> but not everybody has them
preinstalled, so it’s <code>chicken &amp; egg</code> problem.</li><li>Most of the tools work only with tools written in a certain programming language that is NOT Go (:</li></ul><h3 id="curl-released-binaries">Curl Released Binaries</h3><p>You can probably get quite far with just automatic <code>curl</code> of pre-built binary against the certain operating system, released on
GitHub by authors. Unfortunately, again, in practice, not many projects maintain that. Especially, for a small tool, it’s an overkill.</p><h3 id="pre-build-container-images">Pre-Build Container Images</h3><p>That is quite a fancy solution and has many benefits (portability, isolation, etc). This is great but comes with the tradeoff of
long and non-trivial bake times, overhead, and latency when running a job inside a container.</p><p>On top of that, you have to most likely share files between guests and hosts, which is always clunky and problematic (permissions, paths, file ownership, etc).</p><h3 id="solution-pin-certain-version-of-source-code-instead">Solution: Pin Certain version of Source Code Instead!</h3><p>Have you spotted a certain pattern among all the tools I mentioned in <a href="#automate-all-the-things">Automate all the things!</a> section?</p><p><strong>Yes! They all are written in <a href="https://golang.org/" rel="nofollow noreferrer" target="_blank">Go</a>.</strong> The Go community believes in automation, so the amount of tools that was produced is <strong>impressing</strong>. And those are NOT only useful for Go projects but actually any project of it. Tools written in Go tend to be extremely reliable and very easy to maintain and fix. You should try writing your own tooling in Go as well, check <a href="https://www.youtube.com/watch?v=oxc8B2fjDvY" rel="nofollow noreferrer" target="_blank">this amazing video</a> from our friend <a href="https://twitter.com/fatih" rel="nofollow noreferrer" target="_blank">Fatih</a> ❤️ on how to write language tool (e.g linter).</p><p>So, if we assume all our tools will be written in Go, does this simplify our life? The answer is: Yes!</p><h4 id="rant-about-go-modules">Rant About Go Modules</h4><figure><img src="https://bwplotka.dev/images/blog/bingo/gomod.jpg" data-sizes="auto" data-src="https://bwplotka.dev/images/blog/bingo/gomod.jpg" alt="Calling Go Modules for help!"><figcaption>Calling Go Modules for help!</figcaption></figure><p>A few years ago Go Team released its sophisticated answer for dependency problem in Go Community: <a href="https://github.com/golang/go/wiki/Modules" rel="nofollow noreferrer" target="_blank">Go Modules</a>.
It (usually) works and it’s quite amazing for many reasons:</p><ul><li>It is decentralized. Anyone can publish their code, anywhere.</li><li>Finally, Go projects do not need to be inside <code>$GOPATH</code></li><li>Supports using multiple different (major) versions of the same module in the same build.</li><li>It is ~secure. HTTPS and SSH are the default and <code>go.sum</code> exists to verify checksums.</li><li>Supports caching proxies/mirroring.</li><li>Semantic Import Versioning</li><li>It is an official tool, which means finally a single standard. They are also built-in other Go tools.</li></ul><p>But let me say this loud and clear: <strong>It’s also far from being perfect.</strong> Consider the following reasons:</p><ul><li>It assumes everyone uses <strong>semantic versioning</strong> properly.</li></ul><blockquote><p>Halo Go Team, can I have your attention for a second? 🤗</p></blockquote><p><strong>99.9% of Go projects do NOT use semantic versioning properly and NEVER will be!</strong></p><p>It’s because maintainers either have no time, don’t care or they simply semantically version their APIs or part of packages only. See <a href="https://groups.google.com/forum/#!searchin/prometheus-developers/Go$20Modules%7Csort:date/prometheus-developers/F1Vp0rLk3TQ/TyF2WxlkBgAJ" rel="nofollow noreferrer" target="_blank">detailed
discussion on this matter in Prometheus (30k stars’ project) mailing list.</a></p><p>This leads to most of the problems users experience. You can’t escape from a huge amount of <code>replace</code> hacks.
Plus, instead of making it easier for such use cases, Go blames others. ):</p><p>This is also why <code>bingo</code> was needed and why I built it.</p><ul><li><p>We build and import packages, but version modules. If you add an overhead of maintaining modules and releasing it (see the above issue),
it’s clear that maintaining multiple modules is not a good answer. That’s why <a href="https://www.bwplotka.dev/2020/bingo/Helcaraxan" rel="nofollow noreferrer" target="_blank">Duco’s</a> amazing <a href="https://github.com/modularise/modularise" rel="nofollow noreferrer" target="_blank"><code>modularise</code></a>
the project was born. It would be better if we have good out of box solution instead.</p></li><li><p>Managing Major versions are painful. Rewriting path for everything to include this <code>v2</code> is very nasty and tedious, but the only
way of doing a major release and still support multi-version of the same dependency. I hope it will get redesigned someday.</p></li><li><p>Vendoring is allowed and sometimes even (😱) recommended. This is opinionated and controversial, but <strong>why would you use <code>git</code> if you want
version things in subdirectories, are we in 2005 again?</strong> If for cache purposes, then let’s use cache instead. (: Probably a
good topic for the next blog post. I would love to see better and easier ways to use proxies instead. For now, you can read some details <a href="https://groups.google.com/d/msg/prometheus-developers/WLQQd_uNRlw/zKyTD9C4BQAJ" rel="nofollow noreferrer" target="_blank">here</a></p></li></ul><blockquote><p>I was complaining a bit, but keep in mind that building solution that meets all the requirements
from tiny projects to madly huge mono-repos in both close …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bwplotka.dev/2020/bingo/">https://www.bwplotka.dev/2020/bingo/</a></em></p>]]>
            </description>
            <link>https://www.bwplotka.dev/2020/bingo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676587</guid>
            <pubDate>Mon, 29 Jun 2020 11:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping Anything with BSicons]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676585">thread link</a>) | @zetter
<br/>
June 29, 2020 | https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/ | <a href="https://web.archive.org/web/*/https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>If you go to the Wikipedia page for the <a href="https://en.wikipedia.org/wiki/Forth_and_Clyde_Canal">Forth and Clyde Canal</a>, the <a href="https://en.wikipedia.org/wiki/Trans-Siberian_Railway">Trans-Siberian Railway</a> or <a href="https://en.wikipedia.org/wiki/Circle_line_(London_Underground)">the London Circle Line</a> you may notice that they all have route maps with a similar visual style.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicons.png" alt="A diagram of the Glasgow subway loop that shows the route of the subway alongside station names and connecting rail services">
  
  <figcaption>A route map of the <a href="https://en.wikipedia.org/wiki/Glasgow_Subway">Glasgow subway</a> from Wikipedia.</figcaption>
</figure>

<p>How do the many Wikipedia contributors create all these similar-looking maps? The answer is <strong>BSicons</strong>.</p>

<h2 id="bsicons">BSicons</h2>

<p><a href="https://commons.wikimedia.org/wiki/BSicon">BSicons</a> are the building blocks for these route maps. They are an SVG icon set that Wikipedia contributors use to map railways, subways, footpaths, waterways, cycle paths and roads. Any transport system that they want to produce a simplified schematic for.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicon_grid.png" alt="A diagram of the Glasgow subway. The diagram is made up of square icons in a grid which is highlighted">
  
  <figcaption>The Glasgow subway map is made up of many BSicons icons. Most are square, but there are a few half-width icons too that allow for a more compact map.</figcaption>
</figure>

<p>The icons were first used on the German Wikipedia which is why most of their names are based on German words.
‘BSicons’ comes from the German word Bahnstrecken (Railway Lines).</p>

<p>Each icon has a shorthand name that follows some conventions:</p>
<ul>
  <li>A <strong>Root</strong> picks a given icon such as a station or a crossing.</li>
  <li><strong>Prefixes</strong> change it’s status, such as if it’s underground or disused.</li>
  <li><strong>Suffixes</strong> denote direction and positioning, such as if it curves to the left or is one way.</li>
</ul>

<p>Here are some of the icons:</p>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_STR.svg">
    <h3>STR</h3>
  </header>
  <p>A rail line</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_WASSER.svg">
    <h3>WASSER</h3>
  </header>
  <p>A river or other waterway</p><p>
  Root: WASSER (water)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_KRZu.svg">
    <h3>KRZu</h3>
  </header>
  <p>Two rail lines crossing with one going under the other</p><p>
  Root: <b>KRZ</b> → <b>KR</b>eu<b>Z</b>ung (crossing)<br>
  Suffix: <b>u</b> → <b>u</b>nter (under)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_STR%2Bl.svg">
    <h3>STR+l</h3>
  </header>
  <p>A rail line that comes from the left</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)<br>
  Suffix: <b>+l</b> → <b>+</b> (from), <b>l</b>inks (left)</p><p> Directions are relative to the line (which is drawn from top to bottom) rather than the page. This is why the suffix says the line is from the left rather than going to the right.</p>
</div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_utkBHF%2B1.svg">
    <h3>utkBHF+1</h3>
  </header>
  <p>A station on an underground light rail line that comes from the first corner</p><p>
  Root: <b>BHF</b>  →  <b>B</b>ahn<b>H</b>o<b>F</b> (station)<br>
  Prefix: <b>utk</b> → <b>u</b>-bahn, <b>t</b>unnel, <b>k</b>ombination (Compound)</p><p>the <b>k</b> denotes that the icon is for drawing compound turns that span four columns of icons.</p>
</div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_RP2r.svg">
    <h3>RP2r</h3>
  </header>
  <p>A two-lane paved road with a roundabout</p><p>
  Root: <b>RP2</b> → <b>R</b>oad <b>P</b>aved <b>2</b>-lane<br>
  Suffix: <b>r</b>  → <b>r</b>oundabout<sup id="fnref:clash"><a href="#fn:clash">1</a></sup><br>
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_tSTRa.svg">
    <h3>tSTRa</h3>
  </header>
  <p>A rail line that goes into a tunnel</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)
  Prefix: <b>t</b> → <b>t</b>unnel<br>
  Suffix: <b>a</b> → <b>a</b>nfang (start)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_mhKRZho.svg">
    <h3>mhKRZho</h3>
  </header>
  <p>An elevated rail line going over a light elevated rail line</p><p>
  Root: <b>KRZ</b> → <b>KR</b>eu<b>Z</b>ung (crossing)<br>
  Prefix: <b>mh</b> → <b>m</b>ischbetrieb (mixed), <b>h</b>ochbahn (high level/elevated)<br>
  Suffix: <b>ho</b> → <b>h</b>ochbahn (high level/elevated), <b>o</b>verpass
</p></div>

<p>These are a few examples. The <a href="https://commons.wikimedia.org/wiki/BSicon/Catalogue">BSicon Catalogue</a> explains many more conventions.</p>

<h2 id="building-maps">Building maps</h2>

<p>To help put all these icons together into a map Wikipedia has a <a href="https://en.wikipedia.org/wiki/Template:Routemap">Routemap template</a>. The template defines a syntax to provide shortcuts to build maps.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicons_row.png" alt="A diagram of the Glasgow subway loop that shows one line of icons highlighted.">
  
  <figcaption>Routemaps are made up of rows of icons </figcaption>
</figure>

<p>Here is the code used to generate the single highlighted row:</p>

<div><div><pre><code>
{{Subway|Hillhead}}! !\utkBHF+1\\\utkBHF+4\tSTRa~~{{Subway|St George's Cross}}

</code></pre></div></div>

<p>The syntax is a bit cryptic and uses the shorthand icons names we saw above. Here is what each part does:</p>

<ul>
  <li><strong><code>{{Subway|Hillhead}}</code></strong> is a link to the Wkipedia article about this station</li>
  <li><strong><code>! !</code></strong> separates the text on the left from the icons</li>
  <li><strong><code>\utkBHF+1</code></strong> is the first icon a light rail station in a tunnel that curves</li>
  <li><strong><code>\\</code></strong> adds in two empty icon-sized spaces</li>
  <li><strong><code>\utkBHF+4</code></strong> adds in the second icon, similar to the last but towards top-left corner</li>
  <li><strong><code>\tSTRa</code></strong> adds in the third icon, a start of a stretch of tunnel</li>
  <li><strong><code>~~~</code></strong> separates the icons from the text on the right</li>
  <li><strong><code>{{Subway|St George's Cross}}</code></strong>  a link to the Wikipedia article about this station.</li>
</ul>

<h2 id="hundreds-of-thousands-of-icons">Hundreds of thousands of icons</h2>

<p>There are <a href="https://commons.wikimedia.org/w/index.php?title=Special:Search&amp;search=File%3A+intitle%3A%22BSicon%22+intitle%3A%2FBSicon+.%2A%5C.svg%2F&amp;ns0=1&amp;ns6=1&amp;ns12=1&amp;ns14=1&amp;ns100=1&amp;ns106=1">more than 290,000 BSicons</a> out there due to an explosive number of combinations needed for different colours, rotations, intersections, bridges, curves, embankments and tunnels. Many obscure BSicons might only be used a few times across Wikipedia (like <a href="https://commons.wikimedia.org/wiki/File:BSicon_BHFABZgl%2Bl.svg">BHFABZgl+l</a>)<sup><a href="#fn:triangle">2</a></sup>.</p>

<p>Each icon is simple, so simple many of them are marked as ineligible for copyright on Wikipedia. Together the icons can combine to map more complex systems.
Seeing how these icons can be combined inspired me to make a <strong><a href="https://mapmaker.chriszetter.com/">random BSicon map generator</a></strong>.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/tiles-random-2.png" alt="A gird of icons showing train lines crossing over and under each other with stations.">
  
  <figcaption>A random tiling image made by my <a href="https://mapmaker.chriszetter.com/">random map generator</a></figcaption>
</figure>



</div></div>]]>
            </description>
            <link>https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676585</guid>
            <pubDate>Mon, 29 Jun 2020 11:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I used HEY for a week, but I’m going back to Gmail]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23676521">thread link</a>) | @jakevoytko
<br/>
June 29, 2020 | https://www.bitlog.com/2020/06/28/i-used-hey-for-a-week-but-im-going-back-to-gmail/ | <a href="https://web.archive.org/web/*/https://www.bitlog.com/2020/06/28/i-used-hey-for-a-week-but-im-going-back-to-gmail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I’ve been trying alternatives to Google services lately. No offense to Google. I just used their services uncritically for years. Now I want to evaluate them against their competitors. For example, <a href="https://www.bitlog.com/2020/03/06/duckduckgo-is-good-enough-for-regular-use/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">I now use DuckDuckGo instead of Google.</a></p>
<p>Basecamp released HEY recently. It is a privacy-focused email client that aims to give power back to the user. This sounded like something that I might appreciate. Every Gmail account I’ve owned uses a similar combination of features. Priority inbox, some specific settings that must be checked, a bunch of filters, etc. It’s always the result of iteration and resignation. It never feels quite right. It’s easy for me to believe that an email client could provide me a “wow” experience by encoding my workflow into the UI, and providing an “I’ve never known it before, but I’ve always wanted that!” moment.</p>
<p>I got a launch invite and decided to try it for a week.</p>
<p>Let’s cut to the chase: HEY is a good email client, but it’s not a good fit for my relationship with email. I’m not going to pay for it. But this post isn’t a hit piece. Negativity is cheap and lazy. I’m going to explain the value that HEY provides. I will also explain why it wasn’t a good fit for me.</p>

<p>I forwarded my personal Gmail into my <a href="https://hey.com/">hey.com</a> account for one week. I got ~120 emails from ~80 senders. I only sent a handful of emails. This matches my personal email load for a typical week.</p>
<p>I kept a running Google Doc with notes. I especially wanted to split my negative notes into a few piles: bugs, dislikes, and mismatches.</p>
<p>I want to focus on mismatches in this post. When did HEY make me feel uncertain or afraid? When was I fighting it?</p>
<p>I’m not going to mention bugs. Do you really want to hear about a problem with using keyboard shortcuts to scroll through email? They probably fixed it before I published this post.</p>
<p>I’m not going to tell you about nitpicky choices that I didn’t like. This post would become a monument to my own change aversion. “The information density is too low! I can only see 9 emails on my laptop!” Jake. Chill. You’ll get used to it.</p>
<p>Anyways, I used HEY on a variety of platforms. I used the iOS client on my iPhone X. On desktop, I accessed it through Firefox on my 15″ Macbook Pro and my Windows gaming machine.</p>
<figure><img src="https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1024x769.jpg" alt="A picture of me in a pumpkin mask." srcset="https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1024x769.jpg 1024w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-300x225.jpg 300w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-768x577.jpg 768w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1536x1154.jpg 1536w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-2048x1538.jpg 2048w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-624x469.jpg 624w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1024x769.jpg 1024w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-300x225.jpg 300w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-768x577.jpg 768w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1536x1154.jpg 1536w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-2048x1538.jpg 2048w, https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-624x469.jpg 624w" data-src="https://www.bitlog.com/wp-content/uploads/2020/06/IMG_2355-1024x769.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Thanks to coronavirus, I had two modes this week: feeling unsafe outside and testing HEY inside. I wore my mask for both.</figcaption></figure>

<p>I like HEY’s privacy stance. HEY explicitly blocks pixel trackers and loads images through a proxy. It will also “name and shame” companies that send emails with trackers by putting a special binoculars icon over the email.</p>
<figure><img src="https://lh6.googleusercontent.com/J4_gTcVhCBBrzFWcXv0bWMaRyeUOkgmeuhY5fWewv-wzvCf98oK3pt7eVzDpF2JZarDMRGDmTzaYV32i1hWmCcCJqyKgw4F_OLd4X8wwx7NW5Lk9HfFAU5A1W0upESqUtxVhi6hp" alt="An example showing a pixel tracker notification from Etsy"><figcaption><em>An example showing a pixel tracker notification</em></figcaption></figure>
<p>Some digital marketers don’t like this. Mailing list health is an important metric. If they can’t track open rates, then they can’t know how people are “progressing through the funnel” of reading their emails.</p>
<p>Fine by me. It’s hard to imagine receiving any benefit from telling a remote server, “psst, I opened your email.” I like that people can opt-out of ads with ad blockers. I also like that HEY focuses on opting-out of tracking pixels.</p>
<p>I didn’t care about the “name and shame” part of their pixel tracking. I’d be happy if they just had a counter saying “We stopped 531 tracking pixels this month.” I’m not interested in learning who sent an email with trackers. I just like that the filtering works.</p>

<p>HEY requires you to “screen in” every email recipient. When someone sends you an email for the first time, HEY shows a button asking you to “screen them in.” You will receive all future emails from them if you say “yes.” You will never get their email if you say “no.”</p>
<p>Do you receive a lot of unsolicited email? Promotional email you never read? Recruiter spam? Then you should seriously consider using HEY. Imagine saying “no thank you” to a spammy recruiter and never thinking about their emails again. Imagine the promotional emails never grabbing your attention. Imagine opening your email every day and only seeing the emails you want to see. That seems to be HEY’s vision, and I like it.</p>
<p>I interacted with the Screener a lot. I received email from ~80 different senders this week. I screened five of them out.</p>
<p>I don’t receive much unsolicited email. I aggressively unsubscribe from promotional mailers. I turn off email notifications that I don’t want. I sometimes delete services if I get too much email as a result of being a member. As a sidebar, deleting my LinkedIn account was a huge email quality-of-life improvement. The constant parade of recruiters dropped to manageable levels. You should consider it.</p>
<p>I spent lots of time considering some of the Screener decisions. I used to have a Netlify project that I have since deleted. I don’t need to receive email from them now. Maybe I should say “no” to a promotional email that they sent me. But what if I want to use Netlify in the future? I liked Netlify. I might use it again. Would my “no” still apply? I would be missing email that I need to receive. What if I lose my job in the recession and Netlify contacted me about a job opportunity? Would it be screened out? I had this kind of debate repeatedly throughout the week. Who is a sender? Is it a single email address? Is it a company? Is it an individual who could be represented by multiple email addresses? What about catch-all addresses like noreply? When can I safely reject email? I only felt safe using the Screener in a few narrow cases. In cases like Netlify, I screened them in and unsubscribed from the mailing list.</p>
<p>I’d like to make two caveats to this section. First: it seems that Gmail does not forward spam to HEY. I don’t know how good HEY’s spam filtering is and I don’t know how important the Screener would be in relation to it. Second: I only used HEY for a week. The Screener was a constant presence in the beginning. It appeared less as the week went on. I imagine that it wouldn’t appear much next week.</p>

<p>When you screen an email into HEY, you can choose one of three categorizations.</p>
<p>The primary location is the Imbox. This is the <strong>IM</strong>portant <strong>BOX</strong>. It’s an intentional spelling, and is designed as an inversion of an email inbox. The logic goes like this: Other people get to decide when stuff appears in your inbox. You need to intervene to stop it. On the other hand, something only appears in your IMbox when you declare it IMportant enough. This means that you have reclaimed power over the email that you receive.</p>
<p>This is also why HEY provides The Feed and Paper Trail. These represent common email types that you may not need to see right away. This is designed to further improve the Imbox experience by moving these emails out of sight until you want to see them.</p>
<p>The Feed is “The place for newsletters, marketing emails, or anything you want to casually browse.” I put a word-of-the-day email, some Google Alerts, and some newsletters into The Feed. Instead of acting like an email inbox, it is designed to be a content reader. You can periodically skim this content. But it’s not front-and-center in your Imbox.</p>
<p>Paper Trail is “The place for receipts, confirmations, and other transactional emails you receive.” I put automated notifications into here: online order confirmations, credit card purchase notifications, Twitch’s “this streamer is now online” notifications, etc.</p>
<p>After using the categorization for a week, it was clear that I struggled with both of them. I receive a daily newsletter with lengthy emails (<a href="https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine">Money Stuff</a> by Matt Levine). It’s too big to read all at once during my workday. In practice, I sneak 5 minutes here, 10 minutes there. When it’s in The Feed, this means that it was not an email. Instead it’s a card that is slowly being pushed down by other things in The Feed. The later in the day I started reading it, the harder it becomes to complete it 5 minutes at a time. Maybe I’d move this specific newsletter out of The Feed. There’s not much left at this point. I’d have to keep polling to find when the two or three remaining things ended up in The Feed. Everything might as well be in the Imbox.</p>
<p>I also regretted putting many of my emails into Paper Trail. When I buy something, I want to see the purchase receipt Right Now. I also receive credit card alerts for every purchase I make. This helps me identify recurring purchases that I no longer need. When these are in my inbox, I can read and clear the notification immediately. When things are in Paper Trail, they don’t seem to have “Unread” markers. You need to scrutinize timestamps and dates to figure out what might be new. If my Amazon order ships, I want to say “Cool” and then delete the notification. I definitely want to see it.</p>
<p>I fought against this workflow all week. HEY does a good job of explaining its categorization system. But I struggled to live in it. I really just wanted everything to appear in the Imbox. This is the same reason that I stopped using the “Multiple Inbox” feature in Gmail: I’d rather stop unwanted emails at their source, instead of moving it into a separate low-frequency box.</p>
<p>To be clear, this is a good system that is a mismatch with my relationship with my emails. I don’t “casually browse” my newsletters, and I want to read all of my transaction receipts while my brain is still thinking about the purchase I just made.</p>

<p>There are other advanced features that I didn’t use, or used lightly.</p>
<p>Search worked well. I looked for a few things. I found what I was looking for.</p>
<p>HEY has a pair of features called “Reply Later” and “Reply Focus Mode.” This allows you to put off sending replies to emails. Later, you can enter a focused mode that allows you to reply to these specific emails without any UI distractions. I forwarded myself a few emails to put into here when I was experimenting with HEY, but I didn’t end up using the mode with any real seriousness. I don’t receive a ton of email in my personal account, so I don’t run into this problem much.</p>
<p>You can “Set aside” an email if you need to reference it. I can imagine needing this at work. If …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bitlog.com/2020/06/28/i-used-hey-for-a-week-but-im-going-back-to-gmail/">https://www.bitlog.com/2020/06/28/i-used-hey-for-a-week-but-im-going-back-to-gmail/</a></em></p>]]>
            </description>
            <link>https://www.bitlog.com/2020/06/28/i-used-hey-for-a-week-but-im-going-back-to-gmail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676521</guid>
            <pubDate>Mon, 29 Jun 2020 11:27:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Antic Cyber Graphics Software (2002)]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23676333">thread link</a>) | @pavlov
<br/>
June 29, 2020 | https://doudoroff.com/atari/ | <a href="https://web.archive.org/web/*/https://doudoroff.com/atari/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="frame">

<div id="contentcenter">

<p><img src="https://doudoroff.com/atari/gfx/masthead-large.gif" alt="(Masthead) The Antic Cyber Graphics Software and the Pre-History of Autodesk 3D Studio and Discreet 3ds max" width="785" height="86">
		
<img src="https://doudoroff.com/atari/gfx/anthrobot_02.gif" width="275" height="186" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_03.gif" width="369" height="84" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_05.gif" width="227" height="132" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_07.gif" width="292" height="95" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_09.gif" width="217" height="45" alt=""></p><p>By Martin Doudoroff<br>Edited by Monica J. Smith</p>


<p>This Web site documents some moderately obscure computer graphics software history: a suite of animation products produced in the late 1980’s for the Atari ST personal computer platform. Although the fact is not widely known, this Atari software, published by a defunct computer magazine called Antic, directly preceded and led to the Autodesk 3D Studio and Discreet 3ds max products used by thousands of people today.</p>
<p>The articles herein basically comprise an oral history: the information is drawn from interviews and hands-on exploration of the software, running under emulation or on original equipment.</p>
<p>The site is organized into a chronological history, followed by in-depth discussions of each major product.</p>


<p>Thanks to my editor, Monica Smith, for making this documentation more respectable.</p>
<p>Thanks to Gary Yost, Tom Hudson, Mark Kimball, Jim Kent, Andy Eddy, Maurice Molyneaux, Boris Tsikanovsky, Darrel Anderson, and Jack Powell for their enthusiastic participation in this project, which is really their project.</p>
<p>Thanks to James Green and Heidi Brumbaugh for their assistance.</p>
<p>Special thanks to Tom Hudson, Corey Kaup, Mike Mee (Liverpool), Tim Forcade, Richard Davey (<a href="http://www.atari.st/">The Little Green Desktop</a>) and Kevin Savetz (<a href="http://www.atarimagazines.com/"><em>Classic Computer Magazine Archive</em></a>) for their invaluable technical assistance and resources.</p>



		
</div>

<!--<br clear="all" />--><!-- without this little BR, NS6 and IE5PC do not stretch the frame div down to encopass the content DIVs -->




</div></div>]]>
            </description>
            <link>https://doudoroff.com/atari/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676333</guid>
            <pubDate>Mon, 29 Jun 2020 10:57:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurons that fire together, wire together, but how?]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23676233">thread link</a>) | @Anon84
<br/>
June 29, 2020 | http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/ | <a href="https://web.archive.org/web/*/http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="et-boc">
			
			<div><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div>
					
<p>One of my little pet projects is a neurology book for psychologists, coaches and the like. What most people in these fields imagine about the brain is somewhere between perplexing, preposterous and potentially poisonous. (Seriously, I could tell you stories…) So I kind of wanted to write something like this for them.</p>
<p>Now I do consider it a tall order for me – I have some knowledge of neurology, but actually writing a SENSIBLE, understandable guidebook to neurology, with some practical applications too, that’s a challenge. (Senseless guidebooks to neurology are a dime a dozen, of course. In fact, I’ve walled in at least two people in one library, using only senseless pop-neurology books and as far I can tell, the rotting skeletons still haven’t been found. But then again the rotting corpse smell really doesn’t stand out much in most libraries I’ve been to, so I shouldn’t be surprised.)</p>
<p><a href="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg"><img src="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg" alt="" width="1920" height="1280" srcset="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg 1920w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-300x200.jpg 300w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-768x512.jpg 768w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-1024x683.jpg 1024w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-1080x720.jpg 1080w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-610x407.jpg 610w" sizes="(max-width: 1920px) 100vw, 1920px"></a></p>
<p>But back to my main point. The great thing about trying to write a book like that, even attempting to prepare for doing it at one point in the future, when you know enough, is finding all the lovely little holes in how you’re telling the story to yourself. The teeny-tiny little jumps in understanding, the „lies-to-children”, the simplifications.</p>

<p>And one of these, for me, was how neurons get to connect.</p>

<p>And when I asked around, it turned out I wasn’t the only one missing this little bit.</p>

<p>I mean, yeah, we all know Hebb. „Neurons that fire together, wire together”, the neurology mantra in flesh. I can just imagine NeuroZen masters, walking around meditating neurologists, „fiiiiiiiiireeee toooooogeeeether” instead of „ommmm” going around.</p>

<p>That’s how neurons connect. When two fire at once, their connection becomes stronger. The synapse gains long term potentiation/LTP, by both an increase in the neurotransmitters produced, and an increase in the postsynaptic receptors for the neurotransmitters. Short-term it happens through utilizing some of the additional AMPA receptors available near to the synaptic membrane in the postsynaptic cell, long term by changes in protein synthesis and gene expression, in order to ensure a larger number of receptors. So far so good, in one way or another pretty much anyone who understands anything about neurology understands this bit. It might be more or less simplistic, you might have the AMPA receptors memorized or not, but you get the gist of it.&nbsp;(Although this begs the question: does Dale’s principle means that the increase in presynaptic neurotransmitter production influence not just this single synapse, but also the concentration of neurotransmitters in all synaptic connections of the presynaptic neuron? Or perhaps does a reverse mechanism happen, with other connections of the presynaptic neuron being stripped bare of their neurotransmitters? Something I need to check! )</p>

<p>Now here’s the kicker: how do neurons that AREN’T already connected connect? How does their “fire/wire” rule go?</p>

<p>I mean, that still applies, doesn’t it?</p>

<p>Actually, it doesn’t apply in the original Hebb’s law, since that required the neurons to be connected already and a couple of other things as well. But still, the general principle is how we tend to explain things like associative learning, conditioning, etc. The direct wording of Hebb’s law can’t apply there, because then we’d need every neural network to be connected to every other neural network at once, and that’d be a mess that wouldn’t really work all that well. But the general principle seems to apply.</p>

<p>And when I started asking around, no one could tell me how exactly.</p>

<p>How does a neuron know to extend new axonal or dendric connections towards another neuron, so that they might actually form a synapse between the two? Because this has to happen somehow, and this has to happen in a fairly structured way. If it didn’t happen, if we were only left to the remains of the synaptic pruning we got since birth, then our neural networks would become pretty much immovable after were what, twelve? I mean yeah, I’ve met these people, and so have you, but they’re in the small minority… well, large minority… well, OK, a small majority. But even so, there are quite a few people who aren’t that way. And if the neural growth was haphazard, then we’d get a far more random jumble of associations, then the fairly clean ones we tend to get in any conditioning/associative learning experiences.</p>

<p>So I knew there must be some kind of system for neurons to detect other neurons it should be „aiming for” in their development.</p>

<p>And – this was about two or three years ago as of writing this – no one I asked could tell me what it was. I’ve reached out to a lot of people I’ve considered very competent in the field, including some of my old Uni professors, and no one could direct me. Nor could I find the answer in any of the textbooks I’ve referred to.</p>

<p>As it turns out, the answer is fairly recent, as articles about it only started to appear in the 2000s. Since it took me some time to find it back then, I figured I’d make this article to share it now, making the whole thing easier to find for others.</p>

<p>We’ve known from about 1890 that the endings of both the axon and the dendrites are covered in something known as a growth cone. Like the tip of the branch, this is the part where the cell can further develop and extend, either in original growth, in regeneration, or as a reaction to some factors (including a decrease in overall electric activity which causes a form of synaptic scaling – hence explaining the „devouring” of unused neural pathways of amputated body parts by nearby active structures). But how do the growth cones know how exactly to grow? The brain is a complex three-dimensional web of interconnected neurons, so „hitting” the right point is definitely too hard if the neurons just kept on growing until they hit anything at all.</p>

<p>Now, the synaptic scaling process is still a piece of the answer – even if a neuron forms a new synaptic connection with a different neuron, if the target neuron already has too many connections, it will tend to remove the weakest ones, and this includes the most recent ones. The scaling goes both ways after all – it goes for more synapses when it starts with too few, but for less, if it starts with too many.</p>

<p>But synaptic scaling is not everything. As it turns out, the tips of the growth cone constantly produce structures called filopodia, and these react to specific chemical attractants and repellents. These chemicals are produced by both cells at the target area, and by so-called guidepost cells along the way. There are suggestions that the system for such targeting is fairly robust, especially in early development (and its limitations in later life might explain why spinal cord injuries and the like are so hard to fix).</p>

<p>(There is one other process for directing cells, the growth along the radial glia, but since it mainly refers to embryonic development, it’s really not all that interesting for us in this topic.)</p>

<p>Now, the more perceptive of you will already have noticed that while what I’ve given is AN answer, it is not THE answer to the question I’ve originally asked. Or at least, not necessarily.</p>

<p>It might be possible, that the interaction of the three systems:<br>– a pre-set network of attractor/repellent chemical pathways for guiding axon/dendrite growth,<br>– the synaptic scaling mechanism of homeostatic plasticity, which limits the max connections and promotes new connections if existing neural excitability falls below what is the baseline for the network,<br>– and the good old Hebbian mechanism for strengthening existing neural connections,<br>is in fact enough. That the interplay of these systems does answer our basic question, and simple enough rules result in sufficient flexibility to explain what is observed.</p>

<p>But, obviously, the process might be a bit more complicated. There isn’t that much literature about it, unfortunately, so what I’m doing here is more of an (un)educated guess, but since guidepost cells tend to be neurons which have yet to develop an axon – but already have dendrites and can receive signals, a slightly more complex – but better targeted – system can be imagined, where guidepost cells would be a part of a wider neural network, the stimulation of which „calls forth” further cells to build connections. This, in my understanding (Again, limited, so don’t take my word for it. I mean it.) would be a more effective explanation of how we can rapidly learn to connect fairly new information, even across huge (neurologically-scaled) swaths of neural space. A strongly agitated system produces a stronger „call for connections”, hence mediating the faster development of new and broader associations.</p>

<p>So there you have it, a quick summary of one part of neural connectivity I’ve yet to see described in a textbook about the brain, but which really should be given out there, along with the classic Hebbian principle. Hope it’s useful 🙂</p>
				</div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->			</div>
			
		</div>					</div></div>]]>
            </description>
            <link>http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676233</guid>
            <pubDate>Mon, 29 Jun 2020 10:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has GitHub been down more since its acquisition by Microsoft?]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 138 (<a href="https://news.ycombinator.com/item?id=23676199">thread link</a>) | @tdrnd
<br/>
June 29, 2020 | https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/ | <a href="https://web.archive.org/web/*/https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				    
				<div>
    <article id="post-775">
	
	            
            

                
        <div>
                        
            
            
<p>Two years ago, on June 4th of 2018, Microsoft announced its acquisition of GitHub, unicorn darling of the developer tools startup ecosystem, <a rel="noreferrer noopener nofollow" href="https://techcrunch.com/2018/06/04/microsoft-has-acquired-github-for-7-5b-in-microsoft-stock/" target="_blank" data-wpel-link="external">for $7.5B in stock</a>. The announcement unearthed a wide range of <a href="https://news.ycombinator.com/item?id=17221527" data-wpel-link="external" target="_blank" rel="nofollow">opinions and pontifications</a>, ranging from “GitHub is doomed” to “Microsoft is smart”, with many predictions about GitHub’s future. Some thought Microsoft’s growing investments in its cloud offering, Azure, might help GitHub. Could an investment by Microsoft improve GitHub’s reliability or harden them against outages like <a href="https://www.wired.com/story/github-ddos-memcached/" data-wpel-link="external" target="_blank" rel="nofollow">DDOSes</a>? Have any of these predictions come true?</p>



<p>We set out to analyze one angle of the GitHub acquisition: Has GitHub become more reliable since its acquisition by Microsoft? Our service, <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>, monitors more than 700 status pages of cloud providers and SaaS companies large and small. We aggregate and normalize status page data and make it available to our subscribers however they need: in notifications by email, Slack, Teams, or webhook, and in a <a href="https://nimbleindustries.io/2020/01/24/how-to-save-precious-minutes-during-incident-response/" data-wpel-link="internal" rel="follow">unified status dashboard</a> for all service dependencies.</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png" alt="" srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-300x180.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-768x460.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1536x919.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-720x431.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-580x347.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-320x192.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For more than 5 years, we have analyzed the <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">GitHub status page</a> constantly. Every 5 minutes, StatusGator takes a screenshot and <a href="https://statusgator.com/services/github" data-wpel-link="internal" rel="follow">collects relevant data</a> about their service status. That means we are uniquely positioned to offer analysis of the downtime that GitHub themselves announce via their status page.</p>



<p>What does the data tell us? In the two years since the acquisition announcement, GitHub has reported a 41% increase in status page incidents. Furthermore, there has been a 97% increase in incident minutes, compared to the two years prior to the announcement. Does this actually point to a decrease in reliability? We can’t say. This could simply mean GitHub has increased its transparency, publishing to their status page more frequently.</p>



<h2>Incident Counts</h2>



<p>We calculated an incident count in the 24 months preceding the announcement and the 24 months after. We <a href="https://nimbleindustries.io/2019/12/26/under-the-hood-inside-a-status-page-aggregator/" data-wpel-link="internal" rel="follow">classify status pages</a> into four states: <em>up</em>, <em>warn</em>, and <em>down</em>, and <em>maintenance</em>. GitHub does not expose scheduled maintenance on their status page. For these calculations we consider an incident to be any change in status between <em>up</em> and <em>warn</em> or <em>down</em>.</p>



<p>Before the acquisition, there were 89 incidents published on the GitHub status page. After, there were 126 incidents. A 41% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png" alt="89 Incidents before the acquisition, 126 incidents after, a 41% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-300x124.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-768x316.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1536x633.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-2048x844.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1920x791.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-720x297.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-580x239.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-320x132.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident counts by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png" alt="Graph showing GitHub incidents by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-768x400.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1536x799.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-720x375.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-580x302.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-320x167.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<h2>Incident Minutes</h2>



<p>We calculated incident minutes by subtracting the start and end time of time of incidents. Although not 100% realtime, StatusGator checks frequently: every 5 minutes, so status page changes are detected quickly. We counted time where the page was not in an overall <em>up</em> state.</p>



<p>In the 24 months prior to the acquisition announcement, there were 6,110 minutes of downtime. During the 24 months after, there were 12,074 minutes of downtime, a 97% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png" alt="6,110 Incidents before the acquisition, 12,074 incidents after, a 97% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-300x123.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-768x315.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1536x630.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-2048x840.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1920x788.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-720x295.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-580x238.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-320x131.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident minutes by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png" alt="Graph showing GitHub downtime minutes by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-768x399.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1536x797.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-2048x1063.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1920x997.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-720x374.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-580x301.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-320x166.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Status Page Evolution</h2>



<p>During these four years, GitHub has made enormous improvements in their status page information granularity and design. In December 2018, they switched from a home grown status page to one operated by Atlassian’s StatusPage service, <a href="https://nimbleindustries.io/2019/03/11/2019-statusgator-status-page-awards/" data-wpel-link="internal" rel="follow">the most popular status page provider</a>. In doing so, they added numerous <a href="https://nimbleindustries.io/2019/11/22/component-status-filtering-is-here/" data-wpel-link="internal" rel="follow">individual component statuses</a>. Here’s what GitHub’s status page looked like before their switch to Atlassian StatusPage:</p>



<h3>GitHub’s Old Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png" alt="GitHub status page showing only a single status across all GitHub services." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png 645w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-300x187.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-580x361.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-320x199.png 320w" sizes="(max-width: 645px) 100vw, 645px"><figcaption>GitHub status page showing only a single status across all GitHub services.</figcaption></figure>



<p>When they switched to their new status page format, GitHub took a huge step towards increased accountability and transparency by detailing the following individual service components:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Issues, PRs, Dashboard, Projects</li><li>Notifications</li><li>Gists</li><li>GitHub Pages</li></ul>



<p>Overtime, they have expanded and refined their component statuses. They also started showing historical data right on their status page. As you can see in their newest and most detailed status page format, it shows the following service component statuses:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Webhooks</li><li>Issues, PRs, Projects</li><li>GitHub Actions</li><li>GitHub Packages</li><li>GitHub Pages</li></ul>



<h3>GitHub’s New Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png" alt="GitHub status page showing detailed statuses of each of the major components of their service." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png 944w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-277x300.png 277w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-768x833.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-720x781.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-580x629.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-320x347.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new.png 1280w" sizes="(max-width: 944px) 100vw, 944px"><figcaption>GitHub status page showing detailed statuses of each of the major components of their service.</figcaption></figure>



<p>They also moved their status page to a dedicated domain, <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">githubstatus.com</a>, <a href="https://nimbleindustries.io/2020/04/21/your-status-page-deserves-its-own-domain/" data-wpel-link="internal" rel="follow">which follows a best practice we recommend</a> to anyone who hosts a status page. All of this additional transparency, details, and historical data is a commendable effort to relay the most up-to-date information about the status of all GitHub systems. More providers of critical cloud infrastructure should emulate what GitHub has done. <a href="https://nimbleindustries.io/2019/12/07/your-status-page-is-useless-if-you-dont-use-it/" data-wpel-link="internal" rel="follow">Your status page is useless if you don’t use it.</a></p>



<h2>Conclusion</h2>



<p>What can we conclude from all of this data? Objectively, we can conclude that GitHub has published to their status page more frequently in the two years after their acquisition announcement. They have posted more incidents of disruption and downtime. Those incidents have been longer in duration. According to the data they provided, GitHub has been down more since the acquisition by Microsoft. </p>



<p>But that could be all a part of coordinated effort to be more transparent about their service status, an effort that should be applauded.</p>



<p>Our goal at StatusGator is not to shame anyone for disruptions and outages. Everyone experiences unexpected downtime. We simply strive to make status page data available and accessible in more useful ways. From Slack and <a href="https://nimbleindustries.io/2020/04/03/status-page-monitoring-in-microsoft-teams/" data-wpel-link="internal" rel="follow">Microsoft Teams</a>, to <a href="https://nimbleindustries.io/2020/04/30/status-page-webhooks-new-and-improved/" data-wpel-link="internal" rel="follow">webhooks</a>, an API, and more. StatusGator aggregates status page data and empowers you to keep your team informed. </p>



<h2>Try StatusGator</h2>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png" alt="StatusGator logo" srcset="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png 1024w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-300x51.png 300w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-768x131.png 768w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1920x329.png 1920w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-720x123.png 720w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-580x99.png 580w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-320x55.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Is your team dependent on GitHub? Consider trying out <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>,&nbsp;free for 30 days. You can get notifications about GitHub and more than 670 other services with status pages we monitor. You can receive notifications in Microsoft Teams, Slack, by email, SMS, or webhook. Our favorite feature is a Slack integration with a <code>/statuscheck</code> slash command that allows querying the status of any service, right from where your team hangs out.</p>



<p><a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">Try a 30 day free trial</a>&nbsp;of StatusGator and let us know what you think.</p>

                        
                            
            
        </div>
        
                             
    </article>
</div>
				
								
							</div>

		
	



			

		</div></div>]]>
            </description>
            <link>https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676199</guid>
            <pubDate>Mon, 29 Jun 2020 10:31:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zooming on Zoom's Privacy Controversies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676180">thread link</a>) | @oczek
<br/>
June 29, 2020 | https://blog.graphqleditor.com/zoom-security-controversies/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/zoom-security-controversies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Coronavirus and the lockdowns it forced has probably sped up the transition to working from home in many jobs by at least a decade. Workers who previously spend time sitting in cubicles or offices found out they could have just as well worked from home. Millions started looking for software that would help them do that. </p>
<p>Enter Zoom, a somewhat popular video-conferencing program made all the way back in 2011. It was already fairly popular before the pandemic, but this year it’s popularity has exploded. The daily average user numbers went from around 10 million in December to over 300 million in April. </p>
<h2>The Good</h2>
<p>Zoom became the go-to choice for many mainly because it’s really easy to use and free (well at least the basic version is) The usually highlighted advantages of Zoom are:</p>
<ul>
<li>simple and easy to use interface</li>
<li>good audio and video quality</li>
<li>smooth and easy to set up conference calls even for large groups up to 100 people</li>
<li>compatibility with various systems: Windows, macOS, Linux, Android, and iOS</li>
<li>ability to share slides and content</li>
<li>scheduling conferences via a calendar that can be shared with others</li>
<li>virtual backgrounds</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/00d43/video_call.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Leading video-call platfrom" title="Leading video-call platfrom" src="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/fcda8/video_call.png" srcset="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/12f09/video_call.png 148w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/e4a3f/video_call.png 295w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/fcda8/video_call.png 590w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/efc66/video_call.png 885w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/00d43/video_call.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>Zoom also helped itself by making the program free to use for K-12 schools in the US since early March, just as the lockdowns were starting. It also received a lot of free publicity from famous users, even the UK government used it to host sessions.</p>
<h2>The Bad</h2>
<p>Well, it’s not all as rosy as it sounds. Zoom has been involved in some controversies that have become more and more apparent as it gained popularity. The main point of criticism has been lackluster security. </p>
<ul>
<li>In 2019 Apple was forced to remove Zoom from Macs after it turned out a security flaw could let websites hijack users’ cameras. Although the company quickly addressed this with fixes and a lengthy blog post, it wasn’t a good look.</li>
<li>Zoom has no end-to-end encryption, despite some advertising materials claiming otherwise. It stores all the keys involved in user data encryption in its own cloud infrastructure. Which means it can access user data at will.</li>
<li>Zoom calls have random generated IDs consisting between 9 and 11 digits and these can apparently be brute-forced or even randomly guessed which means hackers can get into meetings.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/00d43/hack.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Security controversies" title="Security controversies" src="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/fcda8/hack.png" srcset="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/12f09/hack.png 148w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/e4a3f/hack.png 295w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/fcda8/hack.png 590w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/efc66/hack.png 885w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/00d43/hack.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>The flaws were pretty notorious and led to a phenomenon called <em>zoom bombing</em> where pranksters would join meetings to broadcast inappropriate content. It got so bad the FBI had to officially warn schools.</p>
<h2>The Ugly</h2>
<p>Remember that thing about Zoom having access to user data? Well, it turns out that’s not an accident.</p>
<ul>
<li>This month Zoom admitted to closing three meetings commemorating the Tiananmen Square crackdown and suspended the accounts of activists who organized them. This led to teachers voicing concerns about how they’re supposed to cover such topics in classes hosted on the platform.</li>
<li>In April the New York Times found out Zoom’s data mining feature was automatically sending user’s names and emails to LinkedIn allowing participants to access other users’ profile data.</li>
<li>In March Motherboard found out Zoom’s iOS app was automatically sending device analytics to Facebook without informing the user and did it even if the user did not have a Facebook account. There was no mention of this in the privacy policy either.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/00d43/privacy.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Privacy concerns" title="Privacy concerns" src="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/fcda8/privacy.png" srcset="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/12f09/privacy.png 148w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/e4a3f/privacy.png 295w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/fcda8/privacy.png 590w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/efc66/privacy.png 885w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/00d43/privacy.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>So far this has led to a couple of lawsuits, an inquiry by the Federal Trade Commission and outright bans from some tech companies and the UK’s ministry of defense. Not good news for the company to put it mildly. Yet despite all that Zoom is still hugely popular and looks like it will stay that way despite its flaws. To be fair it’s not like it’s main competitors like Microsoft Teams and Google Hangouts don’t have any either, so pick your poison.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/zoom-security-controversies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676180</guid>
            <pubDate>Mon, 29 Jun 2020 10:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Age-related decline in eyesight may be improved by staring at red light LEDs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23676095">thread link</a>) | @speakeron
<br/>
June 29, 2020 | http://www.bioquicknews.com/node/5509 | <a href="https://web.archive.org/web/*/http://www.bioquicknews.com/node/5509">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- google_ad_section_start --><p><img src="https://media.eurekalert.org/multimedia_prod/pub/web/235928_web.jpg" height="200" width="200">Staring at a deep red light for three minutes a day can significantly improve declining eyesight, finds a new University College of London (UCL)-led study, the first of its kind in humans. Scientists believe the discovery, published online on June 29, 2020 in The Journals of Gerontology, Series A, could signal the dawn of new, affordable, home-based eye therapies, helping the millions of people globally with naturally declining vision. The article is titled “Optically Improved Mitochondrial Function Redeems Aged Human Visual Decline.” In the UK, there are currently presently 12 million people aged over 65: in 50 years, this will increase to approximatley 20 million and all will have some degree of visual decline because of retinal aging. Lead author, Professor Glen Jeffery, PhD, UCL Institute of Ophthalmology, said: "As you age your visual system declines significantly, particularly once over 40. Your retinal sensitivity and your color vision are both gradually undermined, and with an aging population, this is an increasingly important issue. To try to stem or reverse this decline, we sought to reboot the retina's aging cells with short bursts of longwave light."In humans around 40 years-old, cells in the eye's retina begin to age, and the pace of this aging is caused, in part, when the cell's mitochondria, whose role is to produce energy (known as ATP) and boost cell function, also start to decline. Mitochondrial density is greatest in the retina's photoreceptor cells, which have high energy demands. As a result, the retina ages faster than other organs, with a 70% ATP reduction over life, causing a significant decline in photoreceptor function as these receptors lack the energy to perform their normal role. Researchers built on their previous results in mice, bumblebees, and fruit flies, which all demonstrated significant improvements in the function of the retina's photoreceptors when their eyes were exposed to 670 nanometer (long-wavelength) deep red light. </p>
<p>"Mitochondria have specific light absorbance characteristics influencing their performance: longer wavelengths spanning 650 to 1000 nm are absorbed and improve mitochondrial performance to increase energy production," said Professor Jeffery. </p>
<p>The retina's photoreceptor population is formed of cones, which mediate color vision and rods, which provide peripheral vision and adapt vision in low/dim light. </p>
<p>For the study, 24 people (12 male, 12 female), aged between 28 and 72, who had no ocular disease, were recruited. All participants' eyes were tested for the sensitivity of their rods and cones at the start of the study. Rod sensitivity was measured in dark-adapted eyes (with pupils dilated) by asking participants to detect dim light signals in the dark, and cone function was tested by subjects identifying colored letters that had very low contrast and appeared increasingly blurred, a process called color contrast. </p>
<p>All participants were then given a small LED torch to take home and were asked to look into its deep red 670 nm light beam for three minutes a day for two weeks. They were then re-tested for their rod and cone sensitivity.</p>
<p>COLOR &amp; NIGHT VISION BOTH IMPROVED BY SIMPLE APPROACH</p>
<p>Researchers found the 670 nm light had no impact in younger individuals, but in those around 40 years and over, significant improvements were obtained. </p>
<p>Cone color contrast sensitivity (the ability to detect colors) improved by up to 20% in some people aged around 40 and over. Improvements were more significant in the blue part of the color spectrum that is more vulnerable in aging.<br>
Rod sensitivity (the ability to see in low light) also improved significantly in those aged around 40 and over, though less than color contrast.</p>
<p>Professor Jeffery said: "Our study shows that it is possible to significantly improve vision that has declined in aged individuals using simple brief exposures to light wavelengths that recharge the energy system that has declined in the retina cells, rather like re-charging a battery.</p>
<p>"The technology is simple and very safe, using a deep red light of a specific wavelength, that is absorbed by mitochondria in the retina that supply energy for cellular function.</p>
<p>"Our devices cost about £12 (~$15) to make, so the technology is highly accessible to members of the public." </p>
<p>WARNING</p>
<p>Be aware these are preliminary results of a very small study. This approach should not be attempted by anyone until further studies are completed to determine the safety and efficacy of this novel approach. Please consult your ophthalmologist to determine the status of this developing approach to possibly reducing vision loss associated with aging. </p>
<p>IMAGE</p>
<p>This is an example of hand held LED flashlight used in study. (Credit: UCL).</p>
<p>[<a href="https://www.eurekalert.org/pub_releases/2020-06/ucl-dei062620.php" height="400" width="400">Press release</a>] [<a href="https://academic.oup.com/biomedgerontology/article-abstract/doi/10.1093/gerona/glaa155/5863431?redirectedFrom=fulltext" height="400" width="400">Journals of Gerontology, Series A abstract</a>]</p>
<!-- google_ad_section_end -->  </div></div>]]>
            </description>
            <link>http://www.bioquicknews.com/node/5509</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676095</guid>
            <pubDate>Mon, 29 Jun 2020 10:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arduino FIDO2 Authenticator]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 87 (<a href="https://news.ycombinator.com/item?id=23676006">thread link</a>) | @snakeye
<br/>
June 29, 2020 | https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/ | <a href="https://web.archive.org/web/*/https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<section>



<article>
<p>After publishing the URU Key project people keep asking me to make it open source. I have tried to organize sources in a more readable way but I still think that plain C and ESP IDF are too difficult for the broad audience. And, unfortunately, the biometrics part is covered by NDA and can not be published.</p>
<p>Therefore I am starting a new project to address these and other issues.</p>
<h2 id="size-and-form-factor">Size and form factor</h2>
<p>A few months ago I have finalized the <a href="https://en.ovcharov.me/2020/04/06/uru-key-final-hardware-design/">URU Key hardware design</a> and started working on housing for it. Yes, it is very small and lightweight but carrying it around is a kind of a problem. The device is too fragile to be worn on the keyring and a bit thick to put in the pocket. The necklace is not my style.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-key-w150.jpg 150w, /uploads%2Fresized%2Furu-key-w300.jpg 300w, /uploads%2Fresized%2Furu-key-w600.jpg 600w, /uploads%2Fresized%2Furu-key-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Key with the battery" title="URU Key with the battery" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w"><figcaption>URU Key with the battery</figcaption></figure>
<p>However, my wallet is always with me. The PCB sized as a standard credit card should perfectly fit there. The power source becomes a problem, that’s true. But, wait, is it difficult to find a charger or power bank with Micro USB nowadays?</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, /uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, /uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, /uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card in the wallet" title="URU Card in the wallet" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w"><figcaption>URU Card in the wallet</figcaption></figure>
<p>The name <strong>URU Card</strong> makes a lot of sense for this project, isn’t it?</p>
<h2 id="user-interface">User interface</h2>
<p>As on one hand, I can not use biometrics for open source project and on other hand, I do not want to omit the authentication completely leaving the device insecure there is a need for some form of user verification. Simple touch keyboard and OLED screen should allow people to enter pin code or password.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, /uploads%2Fresized%2Furu-card-2-w300.jpg 300w, /uploads%2Fresized%2Furu-card-2-w600.jpg 600w, /uploads%2Fresized%2Furu-card-2-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - touch keyboard and OLED screen" title="URU Card - touch keyboard and OLED screen" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w"><figcaption>URU Card - touch keyboard and OLED screen</figcaption></figure>
<p>The keyboard should be implemented with the <strong>MPR121</strong> I2C touch-sensor controller, and the screen is a widely available <strong>OLED</strong> screen with the <strong>SSD1306</strong> controller. The screen is placed in the special cut in the PCB keeping the device thickness below 2 millimetres.</p>
<h2 id="framework-for-the-development">Framework for the development</h2>
<p>Fortunately, the <strong>Arduino</strong> framework is ported to the <strong>ESP32</strong> platform. There are hundreds of libraries for almost every use case and this factor should significantly simplify the project. There are libraries for <strong>ATECC508A</strong>, <strong>MPR121</strong> and <strong>SSD1306</strong> already. All that is needed is to wire everything together.</p>
<p>However, the Arduino IDE will be hardly usable for a project complex like this one. I am going to use Visual Studio Code + <strong>PlatformIO</strong> for the development and recommend others to do the same.</p>
<h2 id="the-current-state-of-the-project">The current state of the project</h2>
<p>At the moment the working <strong>BLE server</strong> with <strong>FIDO2</strong> endpoints is implemented. The device is “visible” and the computer connects to it in order to perform an authentication procedure. However, the commands are not implemented yet - it’s going to be the next step.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, /uploads%2Fresized%2Furu-card-3-w300.jpg 300w, /uploads%2Fresized%2Furu-card-3-w600.jpg 600w, /uploads%2Fresized%2Furu-card-3-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - the components" title="URU Card - the components" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w"><figcaption>URU Card - the components</figcaption></figure>
<p>There is a PCB design as well and you can try to build the device, but do it on your own risk - it’s in a very early stage now.</p>
<h2 id="joining-the-project">Joining the project</h2>
<p>Sweetest part. The project is free to join for everyone. The minimal requirement is just an ESP32 development board like the one below.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-srcset="/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, /uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, /uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, /uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="ESP32 development board" title="ESP32 development board" srcset="https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w"><figcaption>ESP32 development board</figcaption></figure>
<p>The security element, screen and keyboard can be purchased separately and attached as external modules.</p>
<p>The links to the GitHub repository and other useful resources are given below.</p>
<p>I will be really thankful if consider sharing the project and leave comments with your thoughts and suggestions.</p>
<h2 id="references">References</h2>
<ul>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/uru-card/uru-card">GitHub repository</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://hackaday.io/project/173443-uru-card">Project on Hackaday.io</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://platformio.org/">PlatformIO</a></li>
</ul>
</article>
</section>
</div>
</div>
</section>
</div></div>]]>
            </description>
            <link>https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676006</guid>
            <pubDate>Mon, 29 Jun 2020 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A dataset of 1M programming solutions with state changes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23675957">thread link</a>) | @FraserGreenlee
<br/>
June 29, 2020 | https://fraser-greenlee.github.io/2020/06/25/A-dataset-of-ran-code.html | <a href="https://web.archive.org/web/*/https://fraser-greenlee.github.io/2020/06/25/A-dataset-of-ran-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Existing ML for code methods often learn from <a href="https://github.blog/2019-09-26-introducing-the-codesearchnet-challenge/">raw source code</a> and sometimes use <a href="https://slideslive.com/38917598/program-understanding-synthesis-and-verification-with-graph-neural-networks">data flow</a> to understand programs.
While these offer large amounts of data they don’t actually show what code fundamentally does, changes state.</p>

<p>With that in mind I’ve created a dataset of over 1 million ran python programming solutions with state changes shown after each line of code. <a href="https://www.kaggle.com/frasergreenlee/ran-hackerrank-solutions">Get it here</a></p>

<ol id="markdown-toc">
  <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a>    <ol>
      <li><a href="#an-example" id="markdown-toc-an-example">An example</a></li>
    </ol>
  </li>
  <li><a href="#how-i-got-this-data" id="markdown-toc-how-i-got-this-data">How I got this data</a>    <ol>
      <li><a href="#recording-state-changes" id="markdown-toc-recording-state-changes">Recording State Changes</a></li>
    </ol>
  </li>
  <li><a href="#initial-results" id="markdown-toc-initial-results">Initial Results</a>    <ol>
      <li><a href="#pre-training" id="markdown-toc-pre-training">Pre-Training</a></li>
      <li><a href="#a-downstream-task" id="markdown-toc-a-downstream-task">A Downstream Task</a></li>
    </ol>
  </li>
  <li><a href="#future-work" id="markdown-toc-future-work">Future Work</a></li>
</ol>

<h2 id="motivation">Motivation</h2>

<p>Most AI for code models only learn from reading code. This lets AI models recognise patterns in the code &amp; generate sensible-looking code.</p>

<p>But do these models really understand code? If you were to read code without running anything and had no prior knowledge of programming would you know how to use it?</p>

<h3 id="an-example">An example</h3>

<p>Lets try learning about a single program character the way an AI would.</p>

<p>Below is a simple program with just 1 character replaced by a Chinese character making the code inscrutable. This is a similar experience for an AI seeing the true character for the first time.</p>

<p>As you can see the code is inscrutable.</p>

<div><div><pre><code><span>C</span> <span>=</span> <span>A六B</span>
<span>D</span> <span>=</span> <span>B六C</span>
<span>E</span> <span>=</span> <span>A六D</span>
<span>D</span> <span>=</span> <span>C六E</span>
</code></pre></div></div>

<p>How could I make this understandable without showing the true character?</p>

<p>Since all code does is change state, lets show state changes between each line.</p>

<p>Below shows state changes but the values are also represented by Chinese characters.</p>

<div><div><pre><code><span>..</span> <span>A</span> <span>=</span> <span>书</span>
<span>..</span> <span>B</span> <span>=</span> <span>書</span>
<span>C</span> <span>=</span> <span>A六B</span>
<span>..</span> <span>C</span> <span>=</span> <span>書</span>
<span>D</span> <span>=</span> <span>B六C</span>
<span>..</span> <span>D</span> <span>=</span> <span>书</span>
<span>E</span> <span>=</span> <span>A六D</span>
<span>..</span> <span>E</span> <span>=</span> <span>书</span>
<span>D</span> <span>=</span> <span>C六E</span>
<span>..</span> <span>D</span> <span>=</span> <span>書</span>
</code></pre></div></div>

<p>Lets look at all the operations with the values substituted in:</p>

<p><code>书六書=書</code>, <code>書六書=书</code>, <code>书六书=书</code>, <code>書六书=書</code></p>

<p>If you are familiar with programming you may be able to guess that <code>六</code> is an <code>and</code> operator with <code>书</code> being <code>True</code> &amp; <code>書</code> being <code>False</code>.</p>

<p>Here’s the original code with swapped words:</p>

<div><div><pre><code><span>#  and is 六
#  True is 书
#  False is 書
</span><span>C</span> <span>=</span> <span>A</span> <span>and</span> <span>B</span>
<span>A</span> <span>=</span> <span>A</span> <span>and</span> <span>C</span>
<span>D</span> <span>=</span> <span>C</span> <span>and</span> <span>B</span>
<span>D</span> <span>=</span> <span>D</span> <span>and</span> <span>D</span>
</code></pre></div></div>

<p>Think how much more code you would need to read to figure out what <code>六</code> meant if you couldn’t see state changes. For this reason I rekon showing state changes will help AI models understand code.</p>

<h2 id="how-i-got-this-data">How I got this data</h2>

<p>I first found the <a href="https://www.kaggle.com/arjoonn/codechef-competitive-programming">CodeChef dataset</a> it’s got 1 million solutions to programming problems but few are in Python and many aren’t runnable.</p>

<p>HackerRank is a site where programmers can practice for interviews on their huge range of programming problems. It has a “See Solutions” button that lets you read other peoples solutions.
I used <a href="https://selenium-python.readthedocs.io/getting-started.html">Selenium</a> to click on that button for every problem to get solution URLs. Then I used <a href="https://requests.readthedocs.io/en/master/">Requests</a> to download those solutions.
After a few days I had 1 million solution code snippets with on average 1k solutions per problem.</p>

<h3 id="recording-state-changes">Recording State Changes</h3>

<p>Once I had my runnable code snippets I used <a href="https://github.com/alexmojaki/snoop">Snoop</a> to record all the state changes occurring in each program run.</p>

<p>Snoop dynamically adds logs to your code showing what has executed &amp; which state values have changed. To see how this works check out this <a href="https://www.youtube.com/watch?v=Wm47491S-Fo">talk</a>.</p>

<p><img src="https://fraser-greenlee.github.io/images/snoops-output.png" alt="Some Snoop output." title="Some Snoop output."></p>

<p>Next step was to run all the code snippets. The script used to run the code and progress logs can be found <a href="https://app.wandb.ai/fraser/run-code-snippets/runs/3q9pzype/files/code/data/run_code/hacker-rank/get_problem_snoops.py">here</a>. Thankfully running all these code snippets didn’t cause many issues, I just had to watch out for some the occasional massive code snippet.</p>

<p>An interesting yet worrying feature of the Snoop files is that they are highly compressible, the zip file is 1/10th the size of the txt file. This is likely due to repetitions in the snoop due to the same code being ran repeatedly in for loops and method calls.</p>

<h2 id="initial-results">Initial Results</h2>

<p>With the dataset completed I trained <a href="http://jalammar.github.io/illustrated-gpt2/">gpt2</a> to perform causal language modelling on the raw text. I wanted to see if the Snoops text offers the model any unique insights about code.</p>

<h3 id="pre-training">Pre-Training</h3>

<p><a href="https://app.wandb.ai/fraser/lm_snoop">Here</a> you can see some initial results on training gpt2 &amp; <a href="http://jalammar.github.io/illustrated-bert/">BERT</a> on the data.</p>

<p><img src="https://fraser-greenlee.github.io/images/snoops-gpt2-training.png" alt="Eval loss while training gpt2-medium from-scratch/pre-trained on the Snoop text." title="Eval loss while training gpt2-medium from-scratch/pre-trained on the Snoop text."></p>

<p>Surprisingly gpt2 with OpenAI pre-training (blue) is actually already very accurate on the Snoop text.</p>

<p>When having it generate text with short prompts I found it to be far less accurate than the 1.1 evaluation perplexity. It seems like the gpt2 model is spotting patterns in it’s prefix string &amp; is using them to predict future tokens rather than having a probabilistic model of an interpreter.</p>

<h3 id="a-downstream-task">A Downstream Task</h3>

<p><a href="https://app.wandb.ai/fraser/conala">Here</a> you can see it fine-tuned on <a href="https://conala-corpus.github.io/">CoNaLa</a> (a description-to-code translation task). The Snoop data is better than no pre-training but not as good as gpt2 with OpenAI pre-training. Of course the Snoops model hasn’t had the same amount of training time nor has it seen natural language before so its not a fair test.</p>

<p><img src="https://fraser-greenlee.github.io/images/conala-gpt2.png" alt="Fine-tuning gpt2 from scratch vs pre-trained." title="Fine-tuning gpt2 from scratch vs pre-trained."></p>

<p><img src="https://fraser-greenlee.github.io/images/conala-gpt2-pretrained.png" alt="Fine-tuning Snoop pre-trained vs OpenAI pre-trained." title="Fine-tuning Snoop pre-trained vs OpenAI pre-trained."></p>

<h2 id="future-work">Future Work</h2>

<p>There’s a lot of potential in using state changes to understand code. Right now I don’t think just reading the raw snoops text is the way to go but I think a well formatted, compressed version could do better.
Next time I’ll show how well a compressed version of this dataset can teach a transformer to act as a Python interpreter.</p>

<p>Here’s some other investigations you could do with this dataset:</p>

<ul>
  <li>Further testing on how this helps downstream tasks, try training a language model on just the code &amp; just the Snoop, see which does better on downstream tasks &amp; by how much. These downstream tasks could include bug detection, data type prediction, search &amp; description2code generation.</li>
  <li>Run Snoop on the Django source code with the <a href="https://ahcweb01.naist.jp/pseudogen/">English2Django dataset</a> comments in the code. That way a language model will learn NLP, code &amp; state all at the same time. Warning I got a lot of <code>STATE_UNAVAILABLE</code> messages when I tried this so be ready to filter a lot of data.</li>
  <li>Try applying this method to another programming language, maybe there’s a similar tool for Java or Javascript?</li>
  <li>Try filtering &amp; rearranging the data for new tasks. It offers a valuable insight as to what parts of the source code are useful to humans.</li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://fraser-greenlee.github.io/2020/06/25/A-dataset-of-ran-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675957</guid>
            <pubDate>Mon, 29 Jun 2020 09:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Learning for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23675850">thread link</a>) | @thanato0s
<br/>
June 29, 2020 | https://thevaluable.dev/learning-developer-efficiently-effectively/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/learning-developer-efficiently-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/learning_developer/no-mistake.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/learning_developer/no-mistake.jpg" alt="Learning ">
                </picture>
            

            <p>“I’m trying to go down a bottomless pit. I’ll never make it till the end.”</p>
<p>That’s what I thought when I tried to create my own video game. I was young, beautiful, and I was struggling to use <code>for</code> loops and <code>arrays</code> at the same time.
There was so much to learn!</p>
<p>Fortunately, I found the strength to continue. More and more, the concepts behind programming began to make sense. From there, learning wasn’t a chore anymore, but an intrepid journey. Going through a book about C and trying to create my own adventure on MS-DOS was a crazy Indiana Jone’s-like discovery I’ll never forget.</p>
<p>My first video game wasn’t great, but it was mine. It was <em>my</em> creation. Yet, what I remember today, with a tear in my left eye, is not the result, but the learning process itself. It was these “Aha!” moments which brought me the most joy!</p>
<p>I love learning. For a long, long time. That’s why I tried, through the years, to make my learning gradually more effective and efficient.</p>
<p>Learning is essential for developers. We need to learn about the new breakthroughs, discoveries, and changes in the industry.</p>
<p>We need to learn about our history, to know what’s really new, what’s not, and what to do with it, <em>in what context</em>.</p>
<p>We need to learn about the business domain of the company we’re working with.</p>
<p>We need to learn how to better communicates with our teammates.</p>
<p>We need to learn about what our customers really want.</p>
<p>The list goes on and on.</p>
<p>As you might have guessed, this article will brush over the wide subject of learning, as a developer. We’ll try to answer these questions together:</p>
<ul>
<li>What’s learning?</li>
<li>Why do we learn? Should learning serve a goal?</li>
<li>How to avoid ineffective learning methods, procrastination, and distractions?</li>
<li>Should we have a mentor or learn by ourselves?</li>
<li>Is practice only makes perfect?</li>
<li>How to test ourselves to avoid the illusion of competence?</li>
<li>Are feedback important? What kind of feedback can you get? What feedback should you be interested in?</li>
</ul>
<p>Ready to dive? Good. Take your machete and let’s go together through the Deep Jungle of Knowledge.</p>
<h2 id="whats-learning">What’s learning?</h2>
<p>Sometimes, we can be very surprised of the meaning of common words. Especially if we never question their definitions.</p>
<p>For example, I’m always surprised to hear people saying that learning is only a question of memory. It’s not wrong, but it’s incomplete.</p>
<p>According to the <a href="https://www.lexico.com/definition/learning">oxford dictionary</a>, learning means:</p>
<blockquote>
<p>The acquisition of knowledge or skills through study, experience, or being taught.</p>
</blockquote>
<p>This gives us clues about how to learn (study, experience, or being taught), but not really about the meaning of “acquisition of knowledge”.</p>
<p>Let’s look at the definition of <a href="https://www.lexico.com/definition/knowledge">knowledge</a>:</p>
<blockquote>
<p>Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.</p>
</blockquote>
<p>We can already see, thanks to these definitions, two main foundations for learning:</p>
<ol>
<li>Understanding</li>
<li>Remembering (acquisition)</li>
</ol>
<p>I’ll add a third one:</p>
<ol start="3">
<li>Transfer</li>
</ol>
<p>Transfer is applying the knowledge from the learning context to another context. For example, it could be applying the programming knowledge your learned at school to the side project you always dreamt to build.</p>
<p>Transfer is not a necessity for learning. After all, you can understand and remember something without ever using what you learned.</p>
<p>However, most of the time, we learn in hope to apply the knowledge acquired. That’s why it’s still a major component of our learning experiences.</p>
<h2 id="why-learning">Why Learning?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learn-good.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learn-good.jpg" alt="There is only good in learning">
</picture>



<h3 id="enriching-your-life">Enriching Your Life</h3>
<p>Learning will enrich your life in multiple ways:</p>
<ul>
<li>Your opinions will evolve.</li>
<li>Your vision on the world will change.</li>
<li>You’ll feel strong connections with people who share your interests, creating passionate and mind-binding conversations.</li>
</ul>
<p>Learning can open doors in your professional life:</p>
<ul>
<li>It can help you climbing the corporate ladder.</li>
<li>It can help you to negotiate a better salary. After all, we are <a href="https://en.wikipedia.org/wiki/Knowledge_worker">knowledge workers</a>: our worth is <em>partly</em> our knowledge.</li>
<li>It will create opportunities for <a href="https://thevaluable.dev/guide-debate-software-developer-skill/">healthy debates with your fellow colleagues</a>.</li>
<li>Your CTO might call you <a href="https://thevaluable.dev/software-developer-titles-junior-senior/">“Rockstar” or “Ninja”</a> too, you lucky pit of knowledge!</li>
</ul>
<h3 id="learning-with-or-without-goals">Learning With or Without Goals?</h3>
<p>When you try to learn something, it’s useful to have concrete goals you want to achieve with the knowledge acquired. These goals could be a good occasion to <em>transfer</em> your knowledge.</p>
<p>For example, you want to learn programming because you always dreamt to create a revolutionary video game, where you can break bricks with a ball. Maybe you want to learn what’s the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, to finally refactor your favorite legacy application.</p>
<p>Without meaningful goals, it will be difficult to be motivated in the long run. Learning is not easy. Understanding can be a daunting task (depending of what you learn), remembering even more so, and transfer is maybe the worst of all.</p>
<p>It takes time, too. That’s why being able to reach concrete goals with your new skills and knowledge can be very satisfying. It will give you the needed motivation to continue on your learning path.</p>
<p>It’s even more true when you try to learn complex topics. Your motivation is something you should try to assess and even measure along the way, to see if you need to boost it by making (and finishing) something important to you.</p>
<p>It’s always possible to learn for the sake of learning. Heck, I do it quite a lot myself. Yet, you need to have a good confidence on your motivation, and you need to be aware of the benefits of the learning journey itself.</p>
<p>If you have difficulties to find concrete ideas and goals where you can transfer your new knowledge, I wrote a whole article about techniques <a href="https://thevaluable.dev/generate-programming-side-project-ideas/">to generate project ideas</a>.</p>
<h2 id="how-deep-do-you-want-to-go">How Deep Do You Want to Go?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/experts.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/experts.jpg" alt="Being an expert is not necessarily your goal">
</picture>



<p>Now that you have your goals, you need to decide <em>how much</em> you want to learn.</p>
<p>After all, you don’t need to be an expert in everything.</p>
<p>Moreover, knowledge acquisition is not like buying a new table for your living room. You need some maintenance not to forget the knowledge and skills acquired.</p>
<p>It means that you need to constantly refresh your knowledge and skills, for everything you want to be an expert at. It takes time, energy, and require, again, a lot of motivation.</p>
<p>For example, let’s say that your life’s dream is to write a PHP script to rename automatically thousands of your holidays pictures. You don’t need to be a PHP evangelist to answer your needs. Trying to understand superficially how PHP works to accomplish what you want might be enough.</p>
<p>Superficial learning works well if you don’t have any goal, too. You can read about programming paradigms for example, by pure curiosity, to have a global overview of all of them. You can still dive deeper if you wish later.</p>
<p>Beyond the superficial, the <a href="https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition">Dreyfus model of competence</a> can help you deciding how competent you want to become:</p>
<ul>
<li><strong>Novice</strong> - Shallow understanding, or no understanding at all.</li>
<li><strong>Advanced Beginner</strong> - Can make things works, often rely on following a series of steps.</li>
<li><strong>Competent</strong> - Can spot the roots of problems (background understanding), know all the rules and can select a rule depending of the situation. Still make many mistakes.</li>
<li><strong>Proficient</strong> - Very conscious about performance, know perfectly what approaches to take in what situation.</li>
<li><strong>Expert</strong> - Intuition very well developed, apply his skills without thoughts, performances look magical.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=i1nzADdV6zk">Choose your destiny</a>, depending on your needs!</p>
<h2 id="preparing-your-learning-sessions">Preparing Your Learning Sessions</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.jpg" alt="You need to prepare your environment to learn efficiently">
</picture>



<p>Let’s see now how you should prepare yourself before learning anything.</p>
<p>The following advice won’t change your life from one day to another. You need to work on it, actively seeking to apply these advice, day after day. The rewards are, however, huge. I promise.</p>
<h3 id="the-mistakes-to-avoid">The Mistakes to Avoid</h3>
<p>Let’s go back years in your past, when you were young, innocent, and not a caffeine junky yet.</p>
<p>You’re at school. The teacher is speaking about whatever subject he wants you to learn. His tone is monotonous, he doesn’t believe in what he’s saying, you think about what you’ll eat at lunch.</p>
<p>You’re bored.</p>
<p>The seconds feel like minutes. Minutes feel like hours. You can’t do anything, except waiting. Will it ever end? Will you feel joy again? Is it the end of time?</p>
<p>Finally, against all odds, the course end. The teacher ask you to learn a new chapter of your book. He will test you next time.</p>
<p>At home, you read again and again the learning material. You have difficulties to concentrate, but you’re a serious boy (or girl), so you push yourself through. After five reading, you judge yourself good enough to pass the next test.</p>
<p>You close your book, satisfied with yourself, and switch on the TV, because Youtube might not exist yet.</p>
<p>What I just described is the worst way to learn something. <em>Passively</em> listening to somebody, then <em>passively</em> going through some learning materials might teach you something, but very, very slowly. You don’t need to be in a class for that: just switch on Youtube and consume <em>passively</em> any video on programming.</p>
<p>When you close your book after your passive learning, you think you learned something. Yet, when you’ll pass your test, you’ll understand that you really didn’t.</p>
<p>This is called <strong>illusion of competence</strong>: we have often the <em>impression</em> we learned something, even if we didn’t.</p>
<p>You should spend most of your time <em>actively learning</em>. You need to be an actor in your own learning, not only consuming it like you would consume Netflix.</p>
<p>I would compare active learning as playing a video game. Yes, I was a video game junky.</p>
<p>When you play, you’re actively doing something. Consequently, I’m sure you can remember many more video games than what you read in your last books.</p>
<p>This is due to two things:</p>
<ol>
<li>Video games are fun. You can make your learning experience fun, too. More you’ll learn what you love, more you’ll like the process of learning.</li>
<li>Playing is an active endeavor, not a passive one.</li>
</ol>
<p>That being said, before actively learning, you need first …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/learning-developer-efficiently-effectively/">https://thevaluable.dev/learning-developer-efficiently-effectively/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/learning-developer-efficiently-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675850</guid>
            <pubDate>Mon, 29 Jun 2020 09:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure's keyword namespacing convention Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23675502">thread link</a>) | @tosh
<br/>
June 29, 2020 | https://vvvvalvalval.github.io/posts/clojure-key-namespacing-convention-considered-harmful.html | <a href="https://web.archive.org/web/*/https://vvvvalvalval.github.io/posts/clojure-key-namespacing-convention-considered-harmful.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <ol><li><a href="#the_great_benefits_of_namespaced_keys">The great benefits of namespaced keys</a></li><li><a href="#advantages_of_'snake_case':_portability_and_ubiquity">Advantages of 'snake case': portability and ubiquity</a></li><li><a href="#frequent_objections">Frequent objections</a></li><ol><li><a href="#'this_is_not_idiomatic_clojure'">'This is not idiomatic Clojure'</a></li><li><a href="#'the_lisp-case_convention_lets_me_destructure_keywords'">'The lisp-case convention lets me destructure keywords'</a></li><li><a href="#'but_clojure.spec_encourages_the_use_of_clojure-namespaced_keywords!'">'But clojure.spec encourages the use of Clojure-namespaced keywords!'</a></li><li><a href="#'this_will_create_inconsistencies_in_our_code_style'">'This will create inconsistencies in our code style'</a></li><li><a href="#'but_i_can_just_write_a_key-translation_layer_at_the_edge_of_my_clojure_program...'">'But I can just write a key-translation layer at the edge of my Clojure program...'</a></li><li><a href="#'you_will_need_a_data-marshalling_layer_anyway,_so_why_not_convert_keys_while_you're_at_it?'">'You will need a data-marshalling layer anyway, so why not convert keys while you're at it?'</a></li><li><a href="#'my_stack_is_full-clojure,_keywords_supported_everywhere,_so_i_don't_need_a_portable_naming_convention'">'My stack is full-Clojure, keywords supported everywhere, so I don't need a portable naming convention'</a></li></ol><li><a href="#conclusion">Conclusion</a></li></ol>
    <p>Thank you for taking the bait of this inflammatory and simplistic title. I promise you that the rest of the article will be more reasoned and nuanced.</p><p><strong><i>In summary:</i></strong> for far-ranging data attributes, such as database columns and API fields, <strong>I recommend namespacing keys using 'snake case', contrary to the current Clojure convention of using 'lisp-case' (for example: favour <code>:myapp_user_first_name</code> over <code>:myapp.user/first-name</code>)</strong>, because the portability benefits of the former notation outweigh whatever affordances Clojure provides for the latter. This is an instance of trading local conveniences for system-wide benefits.</p><p>You may already be convinced at this point, in which case the rest of this article will be of little value to you. Otherwise, I want to provoke you to go through the following mental process:</p><ol><li><strong>Consider <code>:namespacing_keys_in_snake_case</code> for data attributes</strong> in Clojure, rather than the conventional <code>:namespacing.keys/in-lisp-case</code>.</li><li><strong>Get angry</strong>, because that's disgusting to any self-respecting Clojure-bred programmer.</li><li>Recognize that you're angry because you've got <strong>attached to an arbitrary convention,</strong> and superficial ergonomics around it.</li><li>Optional: try to bargain with reality, by attempting to find some hacky mechanisms to keep both notations around. Realize that it's not satisfactory.</li><li>Give up, be at peace, and reap the benefits of designing your programs <strong>system-first rather than language-first</strong>.</li></ol><p>I went slowly through this process myself, with some maintenance pains in the way, which hopefully this article can spare you.</p><h2 id="the_great_benefits_of_namespaced_keys">The great benefits of namespaced keys</h2><p>First, it's worth emphasizing that <strong>the naming of data attributes is an important issue, however innocuous it may feel.</strong> Data attributes such as database columns or API fields are not only the bread and butter of our code, they're also some of the strongest commitments we make when growing an information system, often stronger that the choice of programming language. Once a data attribute is part of the contract between several components the system, it becomes very hard to change. This is true even of small systems such as web or mobile apps.</p><p>In recent years, Clojure has encouraged the programming convention of conveying data using <i>namespaced</i> keys, e.g using <code>:myapp.user/id</code> rather than just <code>:id</code>. Namespacing is great, because by reducing the potential for name collisions, it eliminates a lot of ambiguity about names.</p><p>The <strong>significant benefits</strong> of this approach are:</p><ol><li><strong>context-free readability:</strong> when you see <code>:myapp.user/id</code> in your code, thanks to the <code>myapp.user</code> part, you can tell immediately what kind of data it conveys, and what type of entity it operates on. If you just saw <code>:id</code>, you'd have to figure that out from context.</li><li><strong>data traceability:</strong> with a simple text search in the code, you can immediately follow all the places where this piece of data is used across your entire system, whatever the language used at each place. This basic ability is significantly helpful for maintenability. I think many developers don't realize how big a difference it makes.</li></ol><p>Observe that these benefits apply regardless of the choice of namespacing notation: you would reap them whether you write <code>:myapp.user/id</code>, <code>:myapp-user-id</code>, <code>:myappUserId</code> or <code>:myapp_user_id</code>. <strong>It does not matter which namespacing notation you choose, as long as you use it everywhere.</strong></p><p>In other languages, programmers have traditionally relied on type systems to remove such ambiguity. Type systems are not as good for this purpose, because they don't reach beyond language boundaries.</p><p>Clojure's specific convention also offers some comparatively <strong>insignificant benefits:</strong></p><ul><li><strong>prettiness:</strong> <i>"look at <code>:myapp.user/first-name</code>, it's so beautiful! I can use slashes and dashes in programmatic names, this is THE POWER OF LISP!"</i></li><li><strong>concision affordances:</strong> in Clojure code, using namespace aliases, you can write <code>::user/first-name</code> as a shorthand for <code>:myapp.user/first-name</code>. Big deal. I mean, I can relate to how pleasing this feels when coding, but again, please consider that thinking of the whole system may be more important than this sort of local preferences.</li></ul><h2 id="advantages_of_'snake_case':_portability_and_ubiquity">Advantages of 'snake case': portability and ubiquity</h2><p>In a real-world system, data attributes are bound to travel through many media: SQL columns, ElasticSearch fields, GraphQL fields, JSON documents... if the system involves other languages as Clojure, they may be represented as class members. As mentioned above, using the same name - spelled in <i>exactly</i> the same way - for the data attribute in all these representations is a precious thing, because you can trace it across your codebase with one basic text search. You can track its usage not only in Clojure code, but also in SQL queries, ElasticSearch queries, JavaScript client code, etc.</p><p>Clojure's conventional notation for keys (e.g <code>myapp.person/first-name</code>), <strong>a.k.a lisp-case, is portable to almost none of these other platforms:</strong> it's not suitable for SQL column names, nor for GraphQL field names, nor for ElasticSearch fields, nor for Java/Python class members... Some people have argued that in those systems you should just drop the entity-name part (<code>myapp.person</code>), as it will be represented in another construct such as the SQL table name, but that's generally misguided IMO, because you're back to having to disambiguate meaning from context, and you're making the fragile assumption that colocated keys should always have the same entity-name part (think e.g of <code>:myapp.person/name</code> and <code>myapp.admin/password</code>).</p><p>On the other hand, as far as I can tell, <strong>it's hard to come by a platform that does not support <code>snake_case</code>.</strong> Using it may not always be idiomatic, but it's almost always supported. That's reason enough to make snake_case a better default, because having one ubiquitous notation is much preferrable to having many locally idiomatic ones.</p><h2 id="frequent_objections">Frequent objections</h2><h3 id="'this_is_not_idiomatic_clojure'">'This is not idiomatic Clojure'</h3><p>Arguably, your programs have more important requirements than being idiomatic. Programming history is riddled with bad design decisions made in the name of being idiomatic. Anyone who's worked through a nasty Scala class hierarchy knows how much incidental complexity some programmers are willing to inflict upon themselves for the sake of being idiomatic (<i>"because it's SO much better to write <code>subject.verb(complement)</code> than <code>verb(subject, complement)</code>. It's more idiomatic, you see."</i>). Let's avoid doing that to your program, or the Clojure ecosystem.</p><h3 id="'the_lisp-case_convention_lets_me_destructure_keywords'">'The lisp-case convention lets me destructure keywords'</h3><p><i>I like the ability of destructuring my keywords into an entity-name part and an attribute part, for instance:</i></p><pre><code>(namespace :myapp.user/first-name)
=&gt; "myapp.user"

(name :myapp.user/first-name)
=&gt; "first-name"
</code></pre><p><i>I can leverage that to manipulate my data attributes generically in my programs.</i></p><p>Don't do that. Don't treat Clojure keywords as composite data structures. This is accidental complexity waiting to happen. Programmatic names are meant for humans to read, not for programs to interpret. Changing an attribute name should not be able to change the behaviour of your program. In Hickeyian terms: you'd be complecting naming with structure.</p><p>As a basic example of how this may break, consider that it's normal and expected to find in the same entity keys with different namespaces, e.g <code>:person/first-name</code> and <code>:myapp.user/signup-date</code>. If you have a SQL database, there's a high chance that you need both attributes as columns of the same table (1): yet the default behaviour of a namespace-aware tool like <a href="https://cljdoc.org/d/seancorfield/next.jdbc/1.1.547/doc/readme"><code>next.jdbc</code></a> is to constrain both keywords to have the same namespace, which would be problematic in this case, and may be viewed as revealing a complecting of attribute naming and storage layout (2).</p><p><i>Notes:</i></p><ul><li><i>(1) Yes, I know about SQL tables normalization... and that you can do too much of it.</i></li><li><i>(2) Don't worry, that won't prevent you from using <code>next.jdbc</code>: this default behaviour is easily opted out of.</i></li></ul><h3 id="'but_clojure.spec_encourages_the_use_of_clojure-namespaced_keywords!'">'But clojure.spec encourages the use of Clojure-namespaced keywords!'</h3><p>Yeah... I know. In a way, Clojure Spec does what I've told you not to do in the previous section: relying programmatically on a naming convention for keywords, as Spec expects the keys you register to be Clojure-namespaced. Pushing further in that direction would be, in my opinion, a design error of clojure.spec.</p><p>That said, clojure.spec does quite sensibly make room for other namespacing conventions (via <code>:req-un</code> and <code>:opt-un</code>), and so clojure.spec is compatible with the recommendation this article is making. The semantics of Clojure Spec would be completely broken if name collisions were allowed, and so it's understandable that it's decided to check for namespacing.</p><h3 id="'this_will_create_inconsistencies_in_our_code_style'">'This will create inconsistencies in our code style'</h3><p><strong>What might worry you:</strong> some parts of your code might be forced to use keywords in lisp-case - for instance, because libraries like Integrant impose them on you. Having these keys in lisp-case and other in snake_case might be disturbing.</p><p>If that's troubling you, you're in for a pleasant surprise: the visual constrast between <code>snake_case</code> and <code>lisp-case</code> actually makes the code <i>more</i> readable, because it's signals which keys are meant for local use and which are meant to travel across the system.</p><p>By the way, you have already seen an instance of readability enhanced by contrasted notation: in Clojure's syntax itself, where parens <code>(... )</code> are used to denote invocations, and square brackets <code>[... ]</code> are used to denote lexical bindings, departing from the Lisp tradition of using …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vvvvalvalval.github.io/posts/clojure-key-namespacing-convention-considered-harmful.html">https://vvvvalvalval.github.io/posts/clojure-key-namespacing-convention-considered-harmful.html</a></em></p>]]>
            </description>
            <link>https://vvvvalvalval.github.io/posts/clojure-key-namespacing-convention-considered-harmful.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675502</guid>
            <pubDate>Mon, 29 Jun 2020 08:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do call yourself a programmer, and other career advice (2013)]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23675363">thread link</a>) | @luu
<br/>
June 29, 2020 | http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This is a (very late) reply to Patrick McKenzie's "<a href="http://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">Don't Call Yourself A Programmer, And Other Career Advice</a>". I find much of his advice very sensible, and it might be very helpful to someone in the beginning of their career – assuming they can act upon it (and I really don't know whether my 20-year-old self could actually use the advice to improve his negotiation skills, for example).</p>
<p>A few things in the article I disagree with, however. Here I'll mostly focus on those few things, recommending you to read the original article so that you don't miss the rest of it.</p>
<p>"Disagree" is not necessarily the right word – a more precise way to put it would be "it's different in my experience". Which is to be expected because both of us are speaking based on our own careers, which have been rather different. Patrick McKenzie is a small business owner running <a href="http://www.bingocardcreator.com/">Bingo Card Creator</a> and a successful consultant. I'm a lead chip architect at a billion-dollar company. Both of us have thus traveled some distance away from "purely programming" (whatever that means), but in rather different directions.</p>
<p><strong>What company are you going to work for?<br>
</strong></p>
<p>Patrick McKenzie says 90% of the jobs involve things like implementing an internal travel expense reporting form, rather than a product shipped to external customers. He advises you to get used to the idea, even though such software is "soul-crushingly boring" as he puts it.</p>
<p>How bad is it, and is it really 90% of the jobs? Spolsky <a href="http://www.joelonsoftware.com/items/2007/12/04.html">thinks</a> it's maybe 80% – and that it's bad enough to "drain the life out of you". He goes on to elaborate why it "sucks to be an in-house programmer":</p>
<ul>
<li>There's rarely a business reason to improve in-house software past the point of "barely good enough". "Forget any pride of craftsmanship – you're going to churn out embarrassing junk".</li>
<li>At software companies, what you do is more directly related to the way the company makes money, so you're more likely to be respected. "A programmer is never going to rise to become CEO of Viacom, but you might well rise to become CEO of a tech company." "…no matter how critical it was for Viacom to get this internet thing  right, when it came time to assign people to desks, the in-house  programmers were stuck with 3 people per cubicle in a dark part of the  office".</li>
</ul>
<p>Note that McKenzie and Spolsky are in almost complete agreement over these points. But then Spolsky says you should be gunning for a position in a software company – the environment where creatures of your kind naturally thrive. Conversely, McKenzie explains how to prosper as a programmer outside software companies – <em>moving in the opposite direction of where things go by default</em> (being stuck in a dark part of the office while they're trying to outsource your job.)</p>
<p>So the question is which path you prefer. "Not so fast", you say: one of these jobs is way easier to land – 80-90% of the chances are you're not getting inside a software company – so it's not just a question of preference.</p>
<p>Here I disagree: even if only 10-20% of programmers work in software companies (where are the stats?..), and even if they're "the best" (according to what metric?), McKenzie himself says in that same article:</p>
<blockquote><p>You radically overestimate the average skill of the competition because of the crowd you hang around with:&nbsp; Many people already successfully employed as senior engineers cannot actually implement FizzBuzz.</p></blockquote>
<p>But if competition is relatively unskilled on average, you probably can land a job in the 10-20% of the sector that you want – as did most people who graduated around the time I did. So I rather firmly believe that it's a matter of choice: do you <em>want</em> to work on in-house software or one-off businessy projects of that kind, or do you prefer a software company?</p>
<p>Let's proceed to McKenzie's advice to in-house programmers – which should in itself help one make that choice.</p>
<p><strong>How to call yourself<br>
</strong></p>
<p>One such advice is:</p>
<blockquote><p>Don't call yourself a programmer. “Programmer” sounds like “anomalously high-cost peon who types some mumbo-jumbo into some other mumbo-jumbo.” Instead, describe yourself by what you have accomplished for previous employers vis-a-vis increasing revenues or reducing costs.</p></blockquote>
<p>Sure – an in-house programmer is likely doing some type of expensive mumbo-jumbo in the eyes of his non-technical MBA-wielding manager.</p>
<p>To me, however, a programmer is who I'm looking for, while a resume full of revenue increases and cost reductions sounds like an "anomalously high-cost parasite who types some mumbo-jumbo into Excel and PowerPoint, claiming credit for others' work".</p>
<p>McKenzie says a software company looks at this just like a company hiring internal programmers, essentially. His example is "the guy who wrote the backend billing code that 97% of Google’s revenue passes through – he’s now an angel investor". The guy apparently got rich by being near a "profit center" rather than through his unusual skills.</p>
<p>The thing is, in this case I believe he's talking about <a href="http://www.flownet.com/ron/">Ron Garret</a>, the PhD from NASA's Jet Propulsion Laboratory. Do you think they hired him because he described his work at the JPL in terms of revenues and costs? (BTW he didn't like working on the billing code, bought his stock options and quit, instead of choosing a career at the company's biggest "profit center".)</p>
<p>Did any unusual skills go into the billing code? Ron Garret <a href="http://www.flownet.com/ron/xooglers.html">says</a>:</p>
<blockquote><p>I did end up writing the credit card billing and accounting system, which is a nontrivial thing to get right. Fortunately for me, just before coming to Google I had taken some time to study computer security and cryptography, so I was actually well prepared for that particular task. …I designed the billing system to be secure against even a dishonest employee with root access (which is not such an easy thing to do). I have no idea if they are still using my system, but if they are then I'd feel pretty confident that my credit card number was not going to get stolen.</p></blockquote>
<p>Sounds to me that his technical knowledge and programming ability was the bulk of his contribution, whereas deep thoughts such as realizing that there will be some "cost reduction" due to not having credit card numbers stolen is not something an employer needs to hire anyone for.</p>
<p>So if I ever send out a resume as a chip architect, I will focus on my technical role in transitioning from fixed-function hardware accelerators to programmable processors, more than the manpower this saved and the business we won as a result (which I think were real outcomes of our work, but which is rather hard to quantify – as these things often are unless you're a business-friendly-sounding liar.)</p>
<p>Incidentally, I'm not sure <em>when </em>I'll send out that resume, which brings us to the next point.</p>
<p><strong>On job hopping, backstabbing, and the lack thereof </strong></p>
<blockquote><p>Co-workers and bosses are not usually your friends: You will spend a lot of time with co-workers.&nbsp; You may eventually become close friends with some of them, but in general, you will move on in three years…</p>
<p>&lt;your boss will&gt; attempt to do things that none of your actual friends would ever do,  like try to talk you down several thousand dollars in salary or  guilt-trip you into spending more time with the company when you could  be spending time with your actual friends. &nbsp;You will have other  coworkers who — affably and ethically — will suggest things which go  against your interests…</p></blockquote>
<p>There is a certain internal consistency to a view that your coworkers are not your friends, because you will move on in 3 years. In fact, it's a bit circular. They aren't your friends – because you'll move on. And why will you move on? Well, I dunno, maybe for a 10% salary increase. What's there to lose? Relationships with coworkers? But coworkers aren't your friends!</p>
<p>Again, I don't disagree, but rather offer an alternative view, equally internally consistent. I have stayed at one job for more than a decade, in large part because I'm rather attached to the people I work with. To be sure, I got raises, and I was ready to quit over employment terms – but it'd take much more than 10%.</p>
<p>Isn't it just a quantitative difference in preferences – a 10% raise not being fundamentally different than, say, 100%? Well, sufficiently large quantitative changes add up to qualitative changes, as Marxian dialectics or some other Soviet philosophy thingie that my parents sometimes quote taught us. What's going on is that both approaches can lead to career advancement, but they do so very differently.</p>
<p>If you're willing to change jobs over a small raise, you'll be changing them frequently. You won't get attached to people, or to the work you're doing together. You will be very good at finding jobs and you will know what's generally going on in the industry and what's in demand. You will <em>not </em>know that many things specific to any of your employers. <em>You and your employer will become very useful to each other fairly quickly, but you'll also be somewhat expendable for each other.</em></p>
<p>Alternatively, you can keep a job as long as it's a fun environment, requiring a significant raise once in a while. Your relationships with people combined with your long-term outlook can let you do things together that you otherwise couldn't plan or execute, and learn things you wouldn't have learned.</p>
<p>Much of my knowledge about chip design comes from ASIC hackers I worked with, and their willingness to develop their biggest ideas together with me came from trust that necessarily took time to build. It takes time to learn that none of you is in the habit of "suggesting things going against the other's interest", or pulling other unfriendly shenanigans.</p>
<p>Incidentally, if you stay at one place for a long while, then your worth to the employer grows to the point where you can get the significant raise that you'd quit over without actually quitting. Your worth can also grow well above what employers are willing to pay to experienced new hires, so there's no longer a point in switching jobs. This is somewhat analogous to becoming a consultant after having switched a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html">http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html</a></em></p>]]>
            </description>
            <link>http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675363</guid>
            <pubDate>Mon, 29 Jun 2020 07:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chasing a Bad Commit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23675080">thread link</a>) | @pvsukale3
<br/>
June 28, 2020 | https://vishaltelangre.com/chasing-a-bad-commit/ | <a href="https://web.archive.org/web/*/https://vishaltelangre.com/chasing-a-bad-commit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>
      <span></span>
  <img alt="Discussion between a frustrated developer and a happy developer about git bisect" title="Discussion between a frustrated developer and a happy developer about git bisect" src="https://vishaltelangre.com/static/d06b624db0d11519e917870a94ca2b19/29114/frustrated-dev-unaware-of-git-bisect.png" srcset="https://vishaltelangre.com/static/d06b624db0d11519e917870a94ca2b19/e85cb/frustrated-dev-unaware-of-git-bisect.png 480w,https://vishaltelangre.com/static/d06b624db0d11519e917870a94ca2b19/d9199/frustrated-dev-unaware-of-git-bisect.png 960w,https://vishaltelangre.com/static/d06b624db0d11519e917870a94ca2b19/29114/frustrated-dev-unaware-of-git-bisect.png 1920w,https://vishaltelangre.com/static/d06b624db0d11519e917870a94ca2b19/2b984/frustrated-dev-unaware-of-git-bisect.png 2164w" sizes="(max-width: 1920px) 100vw, 1920px" loading="lazy">
    </span></p><h2 id="background"><a href="#background" aria-label="background permalink"></a>Background</h2><p>While working on a big project where multiple teams merge their feature branches frequently into a <span title="Click to find out more">release Git branch</span>, developers often run into situations where they find that some of their work have been either removed, modified or affected by someone else's work accidentally. It can happen in smaller teams as well. Two features could have been working perfectly fine until they got merged together and broke something. That's a highly possible case. There are many other cases which could cause such hard to understand and subtle bugs which even continuous integration (CI) systems running the entire test suite of our projects couldn't catch.</p><p>We are not going to discuss how such subtle bugs can get into our release branch because that's just a wild territory out there. Instead, we can definitely discuss about how to find a commit that deviated an expected outcome of a certain feature. The deviation could be any behaviour of our code that we can measure distinctively — either good or bad in general.</p><table><thead><tr><th>Examples of deviations</th><th>Measurement</th></tr></thead><tbody><tr><td>A commit that introduced a bug or a regression</td><td><code>Good</code> or <code>Bad</code></td></tr><tr><td>A commit that changed the code style</td><td><code>New</code> or <code>Old</code></td></tr><tr><td>A commit caused a benchmark's performance</td><td><code>Fast</code> or <code>Slow</code></td></tr><tr><td>A commit that fixed a bug</td><td><code>Fixed</code> or <code>Broken</code></td></tr></tbody></table><p>Finding the exact point where it changed the course of our code base in terms of either of such deviations could be difficult to trace down and involves a lot of efforts if we have to do it manually.</p><h2 id="a-common-problem"><a href="#a-common-problem" aria-label="a common problem permalink"></a>A common problem</h2><p>Let's assume an example.</p><p>We are looking for a commit that broke something in our shipment feature which was working perfectly fine until the last release. We had tagged that release commit with <code>v12.1.0-rc4</code>. We also have a few tests in our test suite that can help us identify whether that commit is good or bad. Then just recently, some teams merged their feature branches that introduced about close to hundred of commits into our release branch. That's a normal practice in our project assuming we have a bunch of teams working on different feature branches constantly. Then suddenly our CI service reports a red build for the tests run on the latest release branch. CI marked that build as failed since it found that the tests related to the shipment feature were failing. That's very unfortunate and all teams are worried now. But why everyone has to worry? Because everyone have to start with the code in the release branch as the base code and build features atop meaning they would get same test failures in their feature branches, too and won't be able to merge that without a succsessful build on CI. Such a cascaded effect slows down the overall progress and morale of the teams, right?!</p><div>
  <div>
    <figure>
      <span>
      <span></span>
  <img alt="Cancel the team lunch! :(" title="Cancel the team lunch! :(" src="https://vishaltelangre.com/static/a9f9facc755138f691e78fa3bf1ab903/218a4/bleeding-ci.png" srcset="https://vishaltelangre.com/static/a9f9facc755138f691e78fa3bf1ab903/e85cb/bleeding-ci.png 480w,https://vishaltelangre.com/static/a9f9facc755138f691e78fa3bf1ab903/d9199/bleeding-ci.png 960w,https://vishaltelangre.com/static/a9f9facc755138f691e78fa3bf1ab903/218a4/bleeding-ci.png 1052w" sizes="(max-width: 1052px) 100vw, 1052px" loading="lazy">
    </span>
      <figcaption>Cancel the team lunch! :(</figcaption>
    </figure>
  </div></div><p>Because we are the team responisble for the shipment feature, we need to fix those failing tests in the release branch. But everyone in our team is pretty sure that it's not our fault because the overall shipment feature was working until we released <code>v12.1.0-rc4</code>. But anyway we need to triage and fix it, right? So we start with the <code>HEAD</code> commit in the latest release branch. We confirm that the shipment feature breaks on it by running our test suite. Then we keep checking out to each of the previous commits in the Git history until we find a commit where our test suite passes. In a worst case scenario, that succsessful commit could be the one which is tagged with <code>v12.1.0-rc4</code> — meaning we have to checkout to about hundred commits one-by-one to find a good commit. The commit made just after that <strong>good commit</strong> in the commit history tree is what we can refer a <strong>bad commit</strong>.</p><p>If we take such a route, we would end up spending unimaginable hours (or days) chasing down a bad commit. That's definitely not an ideal solution.</p><h2 id="a-bunch-of-solutions"><a href="#a-bunch-of-solutions" aria-label="a bunch of solutions permalink"></a>A bunch of solutions!</h2><p>So what options do we have?</p><ul><li><strong>Option 1</strong>: We can equally divide the commits between a well known good commit and a bad commit among the team members and manually checkout to each commit accordingly to reduce the overall efforts. This excercise suits that popular saying, <em>work as a team!</em></li><li><strong>Option 2</strong>: <code>The Nerd John</code> in our team has a clever idea to implement a fancy tool that would utilize a  binary search algorithm that automatically keeps dividing the commits equally by running the test suite until it finds a commit which was the first bad commit in the commit history. We all know, John's so nerdy!</li><li><strong>Option 3</strong>: Use a readymade tool <code>git bisect</code> which comes built-in with <code>git</code> that <code>The Nerd John</code> could have been end up building — but only in its half-baked form.</li></ul><h2 id="git-bisect-a-good-solution"><a href="#git-bisect-a-good-solution" aria-label="git bisect a good solution permalink"></a>git bisect: a good solution</h2><p>The <code>git bisect</code> command uses an efficient binary search algorithm to help us find a commit that we are looking for. It requires us to specify a bad commit and at least a good commit (can specify many good commits though to further narrow down the search). It then keeps <strong><span title="Click to find out more">bisecting</span></strong> the commits between the specified bad and good commits until it finds the first commit in the commit history that caused the <span title="Click to find out more">deviation</span>.</p><p>The <code>git bisect</code> command can run in either manual (interactive) mode or in a fully automated mode. Before each iteration, bisect needs to know whether the given commit is a bad commit or a good commit.</p><div>
  <div>
    <figure>
      <span>
      <span></span>
  <img alt="A very high level depiction of how git bisect works!" title="A very high level depiction of how git bisect works!" src="https://vishaltelangre.com/static/052949deaa115c2f2954722248437f69/29114/chasing-a-bad-commit.png" srcset="https://vishaltelangre.com/static/052949deaa115c2f2954722248437f69/e85cb/chasing-a-bad-commit.png 480w,https://vishaltelangre.com/static/052949deaa115c2f2954722248437f69/d9199/chasing-a-bad-commit.png 960w,https://vishaltelangre.com/static/052949deaa115c2f2954722248437f69/29114/chasing-a-bad-commit.png 1920w,https://vishaltelangre.com/static/052949deaa115c2f2954722248437f69/b29d9/chasing-a-bad-commit.png 1989w" sizes="(max-width: 1920px) 100vw, 1920px" loading="lazy">
    </span>
      <figcaption>A very high level depiction of how git bisect works!</figcaption>
    </figure>
  </div></div><h3 id="interactive-bisect"><a href="#interactive-bisect" aria-label="interactive bisect permalink"></a>Interactive bisect</h3><p>Let's try the interactive mode first.</p><p>We need to start a git bisect session in a clean Git directory.</p><p>Then we need to tell the SHA of a bad commit to git bisect. We can also use the branch name or a tag name pointing to a commit if we want. Let's assume that in our release branch (which is master branch), the latest commit is a bad commit. Therefore, we can specify that the current <code>HEAD</code> is a bad commit.</p><div data-language="bash"><pre><code>
$ <span>git</span> branch
bug/shipment-leg-misconfigured
feature/shipment-calculator
* master
production


$ rspec spec/models/shipment_spec.rb spec/controllers/shipments_controller_spec.rb
<span>..</span>.
Finished <span>in</span> <span>53.9</span> seconds
<span>238</span> examples, <span>3</span> failures


<span>$ <span>git</span> bisect bad HEAD </span></code></pre></div><p>Now let's find the SHA or tag of a good commit that we are aware of.</p><div data-language="bash"><pre><code>
$ <span>git</span> log --oneline --graph





$ <span>git</span> checkout v12.1.0-rc4


$ rspec spec/models/shipment_spec.rb spec/controllers/shipments_controller_spec.rb
<span>..</span>.
Finished <span>in</span> <span>45.8</span> seconds
<span>221</span> examples, <span>0</span> failures</code></pre></div><p>Because we are already checked out to a good commit, we can simply ask git bisect to mark the current commit as a good commit.</p><div data-language="bash"><pre><code>


<span>$ <span>git</span> bisect good</span><span>Bisecting: <span>46</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>6</span> steps<span>)</span></span><span><span>[</span>02b0b29<span>]</span> Fix: Flicker <span>in</span> insights graph on dashboard</span></code></pre></div><p>Notice the output of <code>git bisect good</code> command above. It automatically checked out to a commit which is in the middle of the range of about 91 commits between the <code>HEAD</code> of master branch (bad) and <code>v12.1.0-rc4</code> (good) commits. That's what bisecting is in general — dividing something in the middle! That output also shows that it would require just about 6 more steps to find out a culprit commit. Ain't that awesome?!</p><p>We can use <code>git bisect visualize</code> or <code>git bisect view</code> to see the boundary commits and the current HEAD commit.</p><div data-language="bash"><pre><code>$ <span>git</span> bisect view --oneline
<span>* 5b91861 <span>(</span>master, origin/master<span>)</span> Merge <span>'feature/new-logistics-reports'</span> branch into <span>'origin/master'</span> branch</span>* <span>..</span>.
* <span>..</span>.
<span>* 02b0b29 <span>(</span>HEAD<span>)</span> Fix: Flicker <span>in</span> insights graph on dashboard</span>* <span>..</span>.
* <span>..</span>.
<span>* 4748ff8 <span>(</span>v12.1.0-rc4<span>)</span> Release v12.1.0-rc4</span></code></pre></div><p>Let's check if the relevant tests pass or fail here and mark the current HEAD as either good or bad accordingly.</p><div data-language="bash"><pre><code>$ rspec spec/models/shipment_spec.rb spec/controllers/shipments_controller_spec.rb
<span>..</span>.
Finished <span>in</span> <span>42.8</span> seconds
<span>221</span> examples, <span>0</span> failures</code></pre></div><p>Tests are passing meaning it's a good commit. So let's tell git bisect the same.</p><div data-language="bash"><pre><code>$ <span>git</span> bisect good
Bisecting: <span>23</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>5</span> steps<span>)</span>
<span>[</span>794197a<span>]</span> Update profile mutation to allow changing middle name</code></pre></div><p>We keep doing this excercise 5 more times until <code>git bisect</code> reports us the first bad commit.</p><div data-language="bash"><pre><code>
$ <span>git</span> bisect bad
Bisecting: <span>11</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>4</span> steps<span>)</span>
<span>..</span>.


$ <span>git</span> bisect bad
Bisecting: <span>5</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>3</span> steps<span>)</span>
<span>..</span>.


$ <span>git</span> bisect bad
Bisecting: <span>2</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>1</span> step<span>)</span>
<span>..</span>.


$ <span>git</span> bisect good
Bisecting: <span>0</span> revisions left to <span>test</span> after this <span>(</span>roughly <span>1</span> step<span>)</span>
<span>..</span>.


$ <span>git</span> bisect bad
<span>efd1083e15670fe6443e5b569b3c0be0e39e212d is the first bad commit</span>commit efd1083e15670fe6443e5b569b3c0be0e39e212d
Author: Brandon Ross <span>&lt;</span>brandon.ross@bigcorp.com<span>&gt;</span>
Date:   Fri Jun <span>19</span> <span>14</span>:02:09 <span>2020</span> -0400

    Change the courier <span>service</span> provider to DHL</code></pre></div><p>There's that bad commit we were looking for! Thanks to <code>git bisect</code> — only in about 6 steps, we found the culprit commit which introduced a bug due to which our shipment feature started failing afterwards in our release branch. Now we can have a chat with Bandon who had pushed that commit and see if we can fix the bug that broke the shipment feature and made our poor CI cry!</p><p>Since we are done here, let's cleanup the bisect session as a final step. This way, git will return back to the original HEAD before the bisect session was started.</p><div data-language="bash"><pre><code>$ <span>git</span> bisect reset
Previous HEAD position was efd1083 Change the courier <span>service</span> provider to DHL
Switched to branch <span>'master'</span>
Your branch is up to <span>date</span> with <span>'origin/master'</span><span>.</span></code></pre></div><h3 id="fully-automated-bisect"><a href="#fully-automated-bisect" aria-label="fully automated bisect permalink"></a>Fully automated bisect</h3><p>Until now, we have been determining ourselves whether a commit is a good commit or a bad commit and were telling the same to <code>git bisect</code> accordingly. That means our manual intervention was needed all the times.</p><p>Cannot we do any better?</p><p>Yes, we can!</p><p><code>git bisect run</code> can execute any command or script. If that command or script exits with code <code>0</code> then <code>git bisect</code> would mark the current commit as a good commit. On the other hand, if that command or script exits with any other code between <code>1</code> and <code>127</code> (inclusive) <span title="Click to find out more">except 125</span> then <code>git bisect</code> would mark the current commit as a bad one.</p><p>And we already know that once a commit is marked as either good or bad, <code>git bisect</code> bisects and checks out to the middle commit of the current range and would keep executing the same command or script we provided to <code>git bisect run</code> until it …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vishaltelangre.com/chasing-a-bad-commit/">https://vishaltelangre.com/chasing-a-bad-commit/</a></em></p>]]>
            </description>
            <link>https://vishaltelangre.com/chasing-a-bad-commit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675080</guid>
            <pubDate>Mon, 29 Jun 2020 06:57:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Importance of Logging – Introducing Logality]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23675078">thread link</a>) | @thanpolas
<br/>
June 28, 2020 | https://thanpol.as/nodejs/why-logs-are-important-introducing-logality | <a href="https://web.archive.org/web/*/https://thanpol.as/nodejs/why-logs-are-important-introducing-logality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>

      
      <p><time datetime="2020-06-27 00:00:00 +0000">27 Jun 2020</time></p><p>Having your application produce the right amount and quality of logs will help you debug faster, optimize better and keep your data safe and secure. I was always fascinated with logging and tried to figure out the best ways to log and create telemetry for my applications.</p>

<p>Having the opportunity to work with multiple startups, I came into close contact with all of Node.js’ major logging packages. Lately, I had the luck to work with highly security aware businesses, for whom security is an existential threat. When tasked with the challenge of creating secure applications for them, I knew without hesitation that I had to create a new library to meet all the new requirements that were at play.</p>

<p>I want to introduce you to <a href="https://github.com/thanpolas/logality">Logality</a>, a versatile and powerful logger for Node.js.</p>

<p><img src="https://thanpol.as/assets/blogimg/planning.jpg" alt="Logging Flow"></p>

<h2 id="the-logging-requirements">The Logging Requirements</h2>

<p>These are the logging requirements that were on the drawing board when Logality was first implemented. I could find some of them in some packages, but not all of them in one package:</p>

<ul>
  <li><a href="#a-common-logging-schema"><strong>Complete Flexibility on Properties</strong></a>. In order for my organization to have a common logging schema, it is required of the logging library to allow the definition of properties from scratch. A lot of the packages make those decisions for you leaving you with no options to normalize the logging schema. The most common example for this is the date field, you can find it as <code>dt</code>, <code>date</code>, <code>timestamp</code> or any other variance, without any option to change the name.</li>
  <li><a href="#serializers-of-data-objects"><strong>Serializers of Data Objects</strong></a>. As <a href="https://github.com/thanpolas/logality">Logality</a> is primarily a JSON logger, dealing with data is the most common operation. Being able to serialize known data structures is key in this case. Just drop your user data object to logality and the built-in or your custom serializer will make sure to transform the object so only what you want will be logged.</li>
  <li><a href="#custom-output-and-pretty-print"><strong>Support Custom Outputs</strong></a>. Logality’s Default output is JSON but the library should not limit you as to the kind of output you want, for instance print human readable logs while on development. Custom outputs also allow you to filter log messages so you can suppress dynamically certain types or log levels of messages.</li>
  <li><a href="#logging-metadata"><strong>Logging Metadata</strong></a>. Have the logger automatically log the location of the file that the log originated from. As well as other useful system information (OS version, runtime info, etc).</li>
  <li><a href="#the-power-of-middleware"><strong>Middleware Support</strong></a>. Supporting middleware is a very powerful way to transform and augment each one of your log messages. The options that this feature opens up are endless.</li>
  <li><a href="#linking-multiple-logality-instances"><strong>Logging for Libraries</strong></a>. All open source contributors must have faced this challenge at least once: How do I output logs from my library? This is no easy task, Logality provides an eloquent and powerful solution to this problem.</li>
</ul>

<p>With these requirements in place, <a href="https://github.com/thanpolas/logality">Logality</a> was created on May 18, 2018. Ever since then the library has been iteratively improving and bug fixed. Today, the current Version is 3.0.0, which was released on April of 2020. In the following sections, we will go through a more detailed analysis of the features and powerful capabilities of Logality.</p>

<h2 id="a-common-logging-schema">A Common Logging Schema</h2>

<p>The more standardized your log messages are, the easier it will be to query, parse and subsequently analyze them. Consequently, your log messages need to have a schema. As we all know, the most ubiquitous format for text based serialization today, is JSON.</p>

<p>Logality is a JSON logger that provides an initial recommendation of a logging schema but allows you to define your own schemas down to the last property.</p>

<p>This is a very important feature. When you are trying to have a common logging schema across multiple operating systems, platforms and programming languages, it is essential that your tooling allows you to be flexible and versatile.</p>

<p>Schema mutation in Logality happens through <a href="#the-power-of-middleware">Middleware</a> and <a href="#serializers-of-data-objects">Serializers</a>, both of which we touch on below.</p>



<p>Logality will take care of all your metadata needs so you won’t need to log any additional information. In particular, Logality will automatically resolve and log for you:</p>

<ul>
  <li>The location of the file where the log originated from.</li>
  <li>The hostname of the machine that runs the application.</li>
  <li>The process id.</li>
  <li>The process name.</li>
</ul>

<p>A simple <code>log.info('hello world')</code> log will produce the following log message (expanded):</p>

<div><div><pre><code><span>{</span><span>
    </span><span>"severity"</span><span>:</span><span> </span><span>6</span><span>,</span><span>
    </span><span>"level"</span><span>:</span><span> </span><span>"info"</span><span>,</span><span>
    </span><span>"dt"</span><span>:</span><span> </span><span>"2018-05-18T16:25:57.815Z"</span><span>,</span><span>
    </span><span>"message"</span><span>:</span><span> </span><span>"hello world"</span><span>,</span><span>
    </span><span>"event"</span><span>:</span><span> </span><span>{},</span><span>
    </span><span>"context"</span><span>:</span><span> </span><span>{</span><span>
        </span><span>"runtime"</span><span>:</span><span> </span><span>{</span><span>
            </span><span>"application"</span><span>:</span><span> </span><span>"testLogality"</span><span>
        </span><span>},</span><span>
        </span><span>"source"</span><span>:</span><span> </span><span>{</span><span>
          </span><span>"file_name"</span><span>:</span><span> </span><span>"/test/spec/surface.test.js"</span><span>
        </span><span>},</span><span>
        </span><span>"system"</span><span>:</span><span> </span><span>{</span><span>
            </span><span>"hostname"</span><span>:</span><span> </span><span>"localhost"</span><span>,</span><span>
            </span><span>"pid"</span><span>:</span><span> </span><span>36255</span><span>,</span><span>
            </span><span>"process_name"</span><span>:</span><span> </span><span>"node ."</span><span>
        </span><span>}</span><span>
    </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>With the use of <a href="#the-power-of-middleware">Middleware</a> you can create and attach your own metadata on each one of your log messages.</p>

<h2 id="serializers-of-data-objects">Serializers of Data Objects</h2>

<p>As standardization of logging data is a primary requirement for Logality, serializers were introduced to solve the problem of consistently logging known data objects.</p>

<p>Let’s take for example the User Data Object (UDO) and the action of logging in, you could log the event as:</p>

<div><div><pre><code><span>log</span><span>.</span><span>info</span><span>(</span><span>`User </span><span>${</span><span>user</span><span>.</span><span>email</span><span>}</span><span> logged in`</span><span>);</span>
</code></pre></div></div>

<p>But that is not a JSON log message, that is a string log message and it is not easily query-able. Let’s try this again with Logality’s JSON logging feature:</p>

<div><div><pre><code><span>log</span><span>.</span><span>info</span><span>(</span><span>'</span><span>User logged in</span><span>'</span><span>,</span> <span>{</span><span>user</span><span>});</span>
</code></pre></div></div>

<p>Now we passed the UDO to logality, however, Logality has no instruction of what portions of the UDO we want logged and here is where serializers come in. Serializers are simple functions that take the objects that you pass as input and output the properties that you want to have logged.</p>

<p>This way, you standardize how your models are logged across your infrastructure and protect your system from logging sensitive fields like a user’s password or unnecessary information like meta data of a product.</p>

<h2 id="the-power-of-middleware">The Power of Middleware</h2>

<p>Logality introduces middleware which allows you to manipulate and mutate the logging messages as you see fit:</p>

<div><div><pre><code><span>logality</span><span>.</span><span>use</span><span>((</span><span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// Remove user data object from logging</span>
    <span>delete</span> <span>context</span><span>.</span><span>user</span><span>;</span>

    <span>// Add debugging flag on all messages</span>
    <span>context</span><span>.</span><span>debug</span> <span>=</span> <span>1</span><span>;</span>
<span>});</span>
</code></pre></div></div>

<p>With Middleware, you can create powerful data flows, augmenting log messages as they come in with rich metadata information collected from the environment and runtime.</p>

<p>You can also have conditional transformations of the data that pass through logality for absolute control over the data flows and your compliance requirements.</p>

<h2 id="linking-multiple-logality-instances">Linking Multiple Logality Instances</h2>

<p>As an open source contributor, one of the biggest problems I have been challenged with is how to log on open source libraries. If you want to have logging on your library you are challenged with quite a few problems:</p>

<ul>
  <li>Provide an option to turn off logging.</li>
  <li>Provide a way to filter the logging level.</li>
  <li>How do you format the logs according to your downstream application’s standards?</li>
  <li>Should you log to stdout, an event or a function?</li>
</ul>

<p>These are very challenging problems, to the point where no practical solution exists. Until today that is, as Logality introduces piping. You can pipe one Logality instance into another and have all the middleware functions handle the piped logality’s log messages. When Logality is piped, the log messages get passed as pure data objects so that the downstream consuming function can properly parse and manipulate them.</p>

<p>This is huge as it enables your application to granularly control how much information is logged from the libraries you are using. And at the same time have your third-party libraries log in the exact same format-schema that your entire infrastructure is logging. Isn’t that great?</p>

<p>Piping happens simply by providing the child Logality instance to the parent’s <code>pipe()</code> method:</p>

<div><div><pre><code><span>const</span> <span>thirdPartyLibrary</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>thirdparty</span><span>'</span><span>);</span>

<span>/* ... */</span>

<span>applicationLogality</span><span>.</span><span>pipe</span><span>(</span><span>thirdPartyLibrary</span><span>.</span><span>logality</span><span>);</span>
</code></pre></div></div>

<h2 id="custom-output-and-pretty-print">Custom Output and Pretty Print</h2>

<p>Finally, after all the processing the log message has gone through, you can control how the final serialization and output is handled. By default Logality will JSON serialize and output to stdout but you may have other plans.</p>

<p>This operation also enables you to filter certain log messages based on your custom criteria. This is particularly useful when managing multiple log streams from various upstreams (third-party libraries) that are piping their logs to your main application Logality logger.</p>

<p>Logality also offers a built-in pretty print functionality that, as the word suggests, will print the log messages in a human readable format, with nice colors, emojis and all. This is particularly useful when you are developing the application and don’t want to see JSON serialized log messages.</p>

<h3 id="outline-of-logalitys-lifecycle-and-piping">Outline of Logality’s Lifecycle and Piping</h3>

<p><img src="https://thanpol.as/assets/blogimg/logality-lifecycle-outline.svg" alt="Logality Lifecycle Outline"></p>

<h2 id="synchronous-or-asynchronous">Synchronous or Asynchronous?</h2>

<p>With a flick of a switch you can have Logality become asynchronous and reveal its Promise API. When in async mode, Logality’s Middleware and Custom Output functions will be able to handle a promise and allow you to capture log messages en-route.</p>

<p>Say you want to push all log messages to a queue, or for any reason, you want to store some, or all, of the log messages into your database. By enabling async mode on Logality you can easily and safely perform those tasks:</p>

<div><div><pre><code><span>// Security middleware for logality, store the log message</span>
<span>// in our database as well and send it to our queue for</span>
<span>// further processing and alerting</span>
<span>logality</span><span>.</span><span>use</span><span>(</span><span>async</span> <span>(</span><span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>context</span><span>.</span><span>security</span><span>)</span> <span>{</span>
        <span>await</span> <span>db</span><span>.</span><span>store</span><span>(</span><span>context</span><span>);</span>
        <span>await</span> <span>queue</span><span>.</span><span>send</span><span>(</span><span>context</span><span>);</span>
    <span>}</span>
<span>});</span>

<span>/* ... */</span>

<span>// login failed, log it</span>
<span>await</span> <span>log</span><span>.</span><span>warn</span><span>(</span><span>'</span><span>Login Failed</span><span>'</span><span>,</span> <span>{</span><span>security</span><span>:</span> <span>true</span><span>});</span>
</code></pre></div></div>

<p>As you rightfully observed, when async mode is enabled Logality’s logging is, well, async, and thus returns a promise that needs to be resolved. Therefore, that is why you see the <code>await</code> before the <code>log.warn()</code> invocation.</p>

<p>Personally, my use case for using async mode and secondary data stores <a href="https://srop.co/" title="SROP The Secure Drop">at SROP</a> was for auditing log trails. When an audit log event occurred, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thanpol.as/nodejs/why-logs-are-important-introducing-logality">https://thanpol.as/nodejs/why-logs-are-important-introducing-logality</a></em></p>]]>
            </description>
            <link>https://thanpol.as/nodejs/why-logs-are-important-introducing-logality</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675078</guid>
            <pubDate>Mon, 29 Jun 2020 06:57:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive Python CheatSheet, now with Pandas and more libraries]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23674693">thread link</a>) | @chirau
<br/>
June 28, 2020 | https://gto76.github.io/python-cheatsheet/ | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt;)                      
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;collection&gt;, to_exclusive)
&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive [, +step_size])
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=person)
<span>'187'</span>
</code></pre></div>

<div><h3 id="generaloptions">General Options</h3><pre><code>{&lt;el&gt;:&lt;<span>10</span>}                                     
{&lt;el&gt;:^<span>10</span>}                                     
{&lt;el&gt;:&gt;<span>10</span>}          …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet/">https://gto76.github.io/python-cheatsheet/</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23674693</guid>
            <pubDate>Mon, 29 Jun 2020 05:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Once, Build Anywhere]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23674501">thread link</a>) | @todsacerdoti
<br/>
June 28, 2020 | https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/ | <a href="https://web.archive.org/web/*/https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Cross-compiling self-contained Java desktop application launchers.</p><h2 id="backstory">Backstory</h2><p>Java’s promise of <em>write once, run anywhere</em> still resonates with me, perhaps because I cut my teeth on JDK 1.0.2b. It was amazing to write cross-platform networking applications without concern for variations in POSIX implementations, or having to worry about nuances between C compilers, or even needing to grok <code>htons</code>. Someone else could wrestle with <code>#ifdef</code>s, shielding others by high-level, standard abstractions. Although Smalltalk had concocted platform-independence punch in 1983, it wasn’t until 1996 that Java’s virtual machine (VM) and subsequent OEM distributions made drinking the mantra of cross-platform development an easy reality.</p><p>Strategically—and selfishly—Microsoft smote that future with a sledgehammer: it moved to <em>embrace and extend</em> Java to achieve vendor lock-in, splintering the platform.</p><p>Developers can no longer rely on systems having a Java VM available. This implies that end-users must download (and install) two independent programs: a suitable VM and a Java archive. It also means that developers now have choices ahead of them that were once bygone worries. Choices that burden end-users and developers alike. Asking people to download a VM for their operating system and CPU architecture is a barrier to product adoption. What’s worse is that some VMs now support “full” Java while others don’t support JavaFX modules at all.</p><p>We’ll address that last point later.</p><p>In late 2019, <a href="https://github.com/kevinrushforth">Kevin Rushforth</a>, of Oracle’s Java Team, <a href="https://youtu.be/ZGW9AalZLN4?t=504">presented</a> a solution to the packaging problem: <code>jpackage</code> and <code>jlink</code>. During the presentation he listed some of the tooling’s shortcomings, which include:</p><ul><li>No cross-platform deployment</li><li>No cross-compilation (must run on MacOS to produce <code>.dmg</code>)</li></ul><p>Let’s not mince words: Java developers could once build applications on their preferred operating system and deploy anywhere; now, they must build installers for every individual platform they intend to target on those very systems.</p><p>Was that the <em>punch-line</em> to a two-decade lead up?</p><p>Requiring developers to have at least two commercial operating systems (Windows, MacOS X), even if emulated inside of a virtualized container—as opposed to using physical hardware—for a platform-independent programming language is an ironic barrier to entry. <em>Especially</em> for people bereft of bankroll.</p><p>Yes, those tools—alongside modules—help produce minimal executables. Who cares? What they don’t do is make it possible to create a set of native, standalone launcher binaries from a single build machine. Let’s fix that by pouring over the big splashes of how to cross-compile application launchers for Java on one build machine. We’ll use Linux because it’s free.</p><h2 id="software-requirements">Software Requirements</h2><p>You will need:</p><ul><li><a href="https://github.com/dgiagio/warp">Warp Packer</a>, a tool for building native application launchers</li><li><a href="https://git-scm.com/">git</a>, a source code management tool</li><li><a href="https://www.gnu.org/software/wget/">wget</a>, a tool for fetching files</li><li><a href="https://gradle.org/">gradle</a> version 6.4.1, a build system</li><li><a href="https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/build-template">build-template</a>, my own starter shell script (MIT licensed)</li></ul><p>Install <code>git</code> and <code>wget</code> using the package manager for your Linux distro.</p><h3 id="install-warp-packer">Install Warp Packer</h3><p>The installation instructions for Warp Packer are a bit buried. Install the software on a Linux system as follows (change the version number to suit):</p><pre><code>mkdir -p $HOME/bin
cd $HOME/bin
wget -O warp-packer \
  https://github.com/dgiagio/warp/releases/download/v0.3.0/linux-x64.warp-packer
chmod +x warp-packer</code></pre><p>If needed, include <code>$HOME/bin</code> in the <code>PATH</code> environment variable by adding the following line to <code>$HOME/.bashrc</code>:</p><pre><code>export PATH="$PATH:$HOME/bin"</code></pre><p>Apply the new environment settings by opening a new terminal or <code>source</code>’ing the <code>.bashrc</code> file directly.</p><p>Warp Packer is installed.</p><h3 id="install-build-template">Install Build Template</h3><p>Copy, move, or download <code>build-template</code> into <code>$HOME/bin</code>.</p><p>The build template is installed.</p><h2 id="javafx">JavaFX</h2><p>Before we get into building a Java application, a little more history is warranted. Originally, the Abstract Window Toolkit (AWT) came bundled with Java, for the same reasons that having a bundled networking API was useful. The AWT lacked aesthetic, both in appearance and as a library. Swing, the AWT’s successor, made strides to address both, but fell short. JavaFX, which was also initially bundled with Java (versions 8 to 10), is a modern graphical user interface (GUI) library for developing desktop applications, as well as a superb replacement for Swing.</p><p>It has been argued that JavaFX should never have been bundled with Java. Nevertheless, the decision to un-bundle JavaFX from Java 11 onwards has led to Java projects that will be stuck with old Java versions for years to come—possibly leading to their abandonment—because it takes <em>a lot</em> of effort to migrate a build process to support these new, un-bundled Java Development Kits (JDKs).</p><p>Part of that effort entails re-bundling JavaFX. There are a few ways this can be accomplished:</p><ul><li>Create a single <em><a href="https://stackoverflow.com/a/11947093/59087">überjar</a></em> that contains native libraries for all intended platform targets.</li><li>Create separate <em>überjars</em>, with each JAR containing native libraries specific to its target platform.</li></ul><p>It’s almost a <a href="https://en.wikipedia.org/wiki/Hobson%27s_choice">Hobson’s choice</a> because we have to create launcher binaries for each target platform anyway. Meaning bundling all of the target platform libraries into each native launcher is wasteful; however, bundling them in a single JAR file for those who have a Java VM installed already may be somewhat useful.</p><p>Java has introduced the concept of modules, looking to simplify the build process. Sometimes, though, modules cannot be included because of outdated dependencies. Problems can arise when running <code>jlink</code> against old dependencies. Compounding the issue is when the projects have been sundowned or have long release schedules. Nevertheless, for our purposes, we’ll want to download a version of OpenJDK that supports JavaFX.</p><p>With that background in mind, let’s go cross-compile some binaries.</p><h2 id="java-application">Java Application</h2><p>We’ll create native application launchers for <a href="https://github.com/DaveJarvis/scrivenvar/">Scrivenvar</a>, a JavaFX-based text editor that I’ve been developing.</p><p>Dive in by cloning the latest version as follows:</p><pre><code>mkdir -p $HOME/dev
cd $HOME/dev
git clone https://github.com/DaveJarvis/scrivenvar.git
cd scrivenvar</code></pre><p>The application is downloaded.</p><h2 id="build-scripts">Build Scripts</h2><p>Let’s review the scripts that help build the application, which include:</p><ul><li><code>build.gradle</code> — builds application Java Archive (JAR) files</li><li><code>installer</code> — builds native, standalone binaries</li></ul><p>Separating the <code>installer</code> script’s responsibilities from <code>build.gradle</code> is not necessary, technically. When running third-party executables (e.g., <code>warp-packer</code>), my first inclination is to use a shell script, rather than gradle’s <code>exec</code>.</p><p>The <code>installer</code> script invokes <code>gradle</code> when requested.</p><h2 id="gradle-script">Gradle Script</h2><p>Open up <code>build.gradle</code> to review a few pertinent code blocks.</p><h3 id="target-operating-system">Target Operating System</h3><p>The first snippet determines what native JavaFX libraries (i.e., target platform code) to include within the JAR file:</p><pre><code>String[] os = ["win", "mac", "linux"]

if (project.hasProperty('targetOs')) {
  if ("windows".equals(targetOs)) {
    os = ["win"]
  }
  else {
    os = [targetOs]
  }
}</code></pre><p>Unless instructed otherwise, the build script will create a JAR file that includes JavaFX binaries for Windows, Linux, and MacOS embedded. We can target a specific platform by using the <code>-P</code> command line option when building, such as:</p><pre><code>gradle clean build jar -PtargetOs=linux</code></pre><p>There’s a catch here in that <code>win</code> and <code>windows</code> are different names. The <code>installer</code> script needs to use <code>windows</code> because that’s part of the JDK file name being downloaded. Arguably, we could move that logic into the <code>installer</code> script, but the point is that the JDK filename and JavaFX refer to Windows using different terminology. The difference must be captured somwhere.</p><h3 id="javafx-dependencies">JavaFX Dependencies</h3><p>The second snippet tells the build system to include JavaFX for a given set of operating systems, as follows:</p><pre><code>def fx = ['controls', 'graphics', 'fxml', 'swing']

fx.each { fxitem -&gt;
  os.each { ositem -&gt;
    runtimeOnly "org.openjfx:javafx-${fxitem}:${javafx.version}:${ositem}"
  }
}</code></pre><p>The application uses JavaFX controls, graphics, fxml, and notice that it also lists a JavaFX-Swing integration. Using <code>.each</code> is a tidy way of not having to maintain a list of JavaFX-specific imports for each operating system, should either or both need to change.</p><h3 id="javafx-exclusions">JavaFX Exclusions</h3><p>Of lesser importance are exclude groups:</p><pre><code>implementation('de.jensd:fontawesomefx-fontawesome:4.7.0-11') {
  exclude group: 'org.openjfx'
}</code></pre><p>Without excluding JavaFX from certain JavaFX-related dependencies, the build will fail. Unfortunately, the build fails in such a way that the developer must investigate what package caused the conflict. Ideally, the build failure would pinpoint any collisions for the developer.</p><h3 id="run-application">Run Application</h3><p>The last point of note are the following lines:</p><pre><code>applicationDefaultJvmArgs = [
    "--add-opens=javafx.controls/javafx.scene.control=ALL-UNNAMED",
    "--add-opens=javafx.controls/javafx.scene.control.skin=ALL-UNNAMED",
    "--add-opens=javafx.graphics/com.sun.javafx.css=ALL-UNNAMED",
]</code></pre><p>These lines address permissions issues encountered when running the application using gradle, such as:</p><pre><code>gradle clean build run</code></pre><p>Now that we understand how this build script works, let’s move on to the <code>installer</code> shell script.</p><h2 id="installer-script">Installer Script</h2><p>Looking at the big picture, the <code>installer</code> script performs the following steps to create a native launcher binary:</p><ol type="1"><li>Configure platform-specific parameters for extraction.</li><li>Rebuild the <em>überjar</em> for the target platform.</li><li>Clean out the distribution directory for a fresh build.</li><li>Extract the target JDK into the distribution directory.</li><li>Create a platform-dependent launch script to run the application.</li><li>Copy the <em>überjar</em> into the distribution directory.</li><li>Wrap the distribution into a standalone binary.</li></ol><p>These high-level steps can be found in the <code>execute()</code> function.</p><p>Let’s take a closer look at how the script works.</p><h3 id="build-template">Build Template</h3><p>The <code>build-template</code> script is described in depth in the first three parts of my Typesetting Markdown series. We reuse the script here because it simplifies writing user-friendly shell scripts.</p><p>Downloading and extracting a requisite JDK is pivotal. JDKs can be downloaded from a few places, but most of them have …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/">https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/</a></em></p>]]>
            </description>
            <link>https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23674501</guid>
            <pubDate>Mon, 29 Jun 2020 05:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Unix Pipes to Improve Chromecast Playback]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23673825">thread link</a>) | @lowmemcpu
<br/>
June 28, 2020 | https://alexdelorenzo.dev/linux/2020/03/14/pipes | <a href="https://web.archive.org/web/*/https://alexdelorenzo.dev/linux/2020/03/14/pipes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">  <p>When casting from YouTube to a Chromecast, sometimes the audio playback will <a href="https://support.google.com/chromecast/thread/13807879?hl=en">skip</a> and <a href="https://support.google.com/youtube/thread/17251626?hl=en">stutter</a>. This issue is independent of the quality of the video, the FPS, or the internet connection. Trying to watch certain videos will reliably cause playback issues on the Chromecast.</p> <p>According to <a href="https://support.google.com/chromecast/thread/13807879">this thread</a>, the playback issue only appeared in the latest and final firmware update for the Chromecast. Successful playback of the videos was possible in the past, and casting the downloaded YouTube videos eliminates the problem entirely. The problem exists solely when casting certain videos using the YouTube app.</p>  <p>Given that the problem only occurs with the YouTube app, you can download a video and cast it via <a href="https://github.com/xat/castnow"><code>castnow</code></a> or <a href="https://github.com/skorokithakis/catt"><code>catt</code></a>, skipping the YouTube app entirely.</p> <p>You could do something like:</p> <div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>export </span><span>url</span><span>=</span><span>"https://youtu.be/Kas0tIxDvrg"</span>

<span>function </span>cast<span>()</span> <span>{</span>
    <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>
    
    <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
    youtube-dl <span>"</span><span>$url</span><span>"</span>
    
    <span># wait a bit to download the file</span>
    castnow <span>"</span><span>$filename</span><span>"</span>
    <span>rm</span> <span>"</span><span>$filename</span><span>"</span>
<span>}</span>

cast <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>But having to skip using the YouTube app to cast is already a clunky solution, and downloading every video before playing them is an even worse user experience. Instant playback and ephemeral streams are what make for a pleasant video streaming experience in 2020, and this solution implements neither of them</p>  <p><a href="https://github.com/ytdl-org/youtube-dl/blob/master/README.md">Since <code>youtube-dl</code> allows us to output to <code>stdout</code></a>, if we can hook its <code>stdout</code> to a casting app, we could emulate the instant playback and ephemeral videos we expect because we don’t have to wait for an entire file to download.</p> <p>Unfortunately, <code>castnow</code> and <code>catt</code> won’t cast from <code>stdin</code>. You’re expected to pass it file locations to cast from.</p> <p>This is where one of my favorite shell features really shines: <a href="https://tldp.org/LDP/abs/html/process-sub.html">process substitution</a>.</p> <p>With process substitution, Bash gives us a convenient way to make ephemeral <a href="https://en.wikipedia.org/wiki/Anonymous_pipe">anonymous pipes</a>. This method is both efficient and concurrent, making this primitive an apt choice to build a solution to the problem at hand. A process reading the <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">pipe</a> blocks until the pipe is opened by another process for writing. A process writing to the pipe will suspend until the pipe’s buffer is read by another process. The anonymous pipe will automatically remove itself, and when it is manually removed, its dependent processes will be terminated.</p> <p>When using process substitution, a process’ <code>stdout</code> is hooked up to an anonymous pipe. That pipe can be accessed from a file descriptor, and the location of the pipe is given to the calling process.</p> <div><div><pre><code><span>$ </span><span>echo</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
/dev/fd/63

<span>$ </span><span>cat</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
Content sent to pipe
</code></pre></div></div> <p>In the example above, the <code>&lt;(command)</code> syntax is how we invoke process substitution in Bash. The output of <code>command</code> is written to an anonymous pipe, and the calling process is given the location of the file descriptor to access that pipe.</p> <p>Using that example, we can take advantage of process substitution:</p> <div><div><pre><code>vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>The command above will play the YouTube video locally with <a href="https://www.videolan.org/vlc/index.html">VLC</a>, and illustrates that process substitution can work for our use case.</p> <p>However, when we try to use <code>castnow</code>, we can’t cast from the pipe:</p> <div><div><pre><code><span>$ </span>castnow &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: Load failed
</code></pre></div></div> <p>Nor can we cast with <code>catt</code>:</p> <div><div><pre><code><span>$ </span>catt cast &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: The chosen file does not exist.
</code></pre></div></div> <p>We know we can use VLC locally, and VLC also lets you cast to a Chromecast using its IP address.</p> <p>Let’s try that again using VLC:</p> <div><div><pre><code><span>function </span>cast_vlc<span>()</span> <span>{</span>
    <span>path</span><span>=</span><span>"</span><span>$1</span><span>"</span>

    <span># get the ip address for chromecast.lan host</span>
    <span>ip</span><span>=</span><span>$(</span>dig +short chromecast.lan | <span>tail</span> <span>-n</span> 1<span>)</span>

    vlc <span>-I</span> ncurses <span>\</span>
      <span>--sout</span> <span>'#chromecast'</span> <span>\</span>
      <span>--sout-chromecast-ip</span><span>=</span><span>"</span><span>$ip</span><span>"</span> <span>\</span>
      <span>--demux-filter</span><span>=</span>demux_chromecast <span>\</span>
      <span>"</span><span>$path</span><span>"</span> &lt; /dev/tty
<span>}</span>

cast_vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>That works.</p> <p>As an aside, we hook VLC’s <code>stdin</code> to <code>/dev/tty</code> so that we can use the ncurses interface even if we invoke the function from a script.</p> <p>Let’s look at the <a href="https://wiki.videolan.org/Documentation:Modules/ncurses/">ncurses interface</a>.</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/d0822203c304db88f3cbec618e94a3d9f55cd269/c5939/assets/imgs/converted/vlc-fs8.webp" loading="lazy"> </p> </div> <p>It only displays the file descriptor, and very little about the video itself. I’m not a fan of that.</p>  <p>Instead of using anonymous pipes, we can use <a href="https://en.wikipedia.org/wiki/Named_pipe">named pipes</a>. Named pipes are like anonymous pipes, except they are not anonymous (they have a name) nor are they ephemeral. Named pipes still give us the efficiency and concurrency benefits that anonymous pipes give us, but Bash lacks the syntactic sugar it has for process substitution when it comes to named pipes.</p> <p>This is how we create named pipes, write to them, read from them and remove them.</p> <div><div><pre><code><span>$ </span><span>mkfifo </span>ourpipe
<span>$ </span><span>echo</span> <span>"Content in pipe"</span> <span>&gt;</span> ourpipe &amp;
<span>$ </span><span>cat </span>ourpipe
Content <span>in </span>pipe
<span>$ </span><span>rm </span>ourpipe
</code></pre></div></div> <p>Not as pretty as <code>&lt;(command)</code>, but it gets the job done.</p> <p>We can give a named pipe the same name as our YouTube video, and that way, the VLC interface will show the name of what we’re watching.</p> <div><div><pre><code><span>function </span>cast_ytdl<span>()</span> <span>{</span>
  <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>

  <span># create a temporary named pipe</span>
  <span># why? because vlc will show the file descriptor path if we just use process substitution</span>
  <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
  <span>path</span><span>=</span><span>"/tmp/</span><span>$filename</span><span>"</span>
  <span>mkfifo</span> <span>"</span><span>$path</span><span>"</span>

  <span># download in background, push to named pipe</span>
  youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span> <span>&gt;</span> <span>"</span><span>$path</span><span>"</span> &amp;
  <span>pid</span><span>=</span><span>"</span><span>$!</span><span>"</span>
  <span>disown</span> <span>$pid</span>

  <span># cast from named pipe</span>
  cast_vlc <span>"</span><span>$path</span><span>"</span>

  <span># cleanup process and named pipe</span>
  <span>kill</span> <span>-9</span> <span>"</span><span>$pid</span><span>"</span> &amp;&gt; /dev/null
<span>}</span>

cast_ytdl <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>This works, too.</p> <p>We need to manually create a named pipe with <a href="https://linux.die.net/man/1/mkfifo"><code>mkfifo</code></a>, redirect <code>youtube-dl</code>’s <code>stdout</code> to the named pipe while running the process in the background, and then cleanup the process after casting from it via VLC, otherwise it might linger in the background. Each of those tasks would have been handled for us automatically using process substitution.</p> <p>But it does look a bit better:</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/25d68fb2085191adb26bb931e9bb31c638e5a634/f664c/assets/imgs/converted/vlc3-fs8.webp" loading="lazy"> </p> </div>  <p>Pipes, anonymous pipes and named pipes are also known by another name because of the way they behave: <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)#Pipes">FIFOs</a>, or <strong>f</strong>irst <strong>i</strong>n, <strong>f</strong>irst <strong>o</strong>ut. What’s written to the pipe is read from the pipe in first in, first out order. This behavior maps well to video streaming.</p> <p>While you can interact with anonymous and named pipes like you would a file, the interface isn’t 1:1 with a <a href="https://en.wikipedia.org/wiki/Unix_file_types#Regular_file">standard file</a>. You cannot <code>seek()</code> forward or backward in pipe, you can just read the next forward values. For our use case, that means we cannot skip forward or backward in our streaming videos. We can only play, pause or stop the video.</p> <p>That’s not a problem for me, however it’s something that can be mitigated if it’s a problem for you. The first solution I can think of would be to write to a temporary file via <code>youtube-dl</code> and read from it. Or <a href="https://alexdelorenzo.dev/programming/2019/04/14/buffer">perhaps a temporary spooled file can act as a buffer for the pipe</a>, such that you can <code>seek()</code> through the buffer, but the buffer itself is ephemeral unlike a normal file.</p> </div></div>]]>
            </description>
            <link>https://alexdelorenzo.dev/linux/2020/03/14/pipes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673825</guid>
            <pubDate>Mon, 29 Jun 2020 02:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redash Is Joining Databricks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673728">thread link</a>) | @weitingliu
<br/>
June 28, 2020 | https://blog.redash.io/redash-joins-databricks/ | <a href="https://web.archive.org/web/*/https://blog.redash.io/redash-joins-databricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>We’re happy to announce that Redash is joining Databricks. We’ve been an open-source company grounded in helping our community of users make sense of their data. We found this same culture and values in Databricks, and we’re excited to be able to carry on our vision to democratize access to data — now in a larger home where we can bring this to even more people.</p><p>We’re excited to be one of the many open-source projects that Databricks supports. They’re the original creators of Apache Spark™, the standard for large-scale data processing, as well as Delta Lake for reliable data lakes, MLflow for the machine learning lifecycle, Koalas for data science productivity on Spark. Now, Redash joins this community of open source projects for collaborative SQL queries and dashboarding. We look forward to growing the Redash engineering team and have a lot of plans in our road map to deliver an even better experience with Redash, with more functionality, security and support. Open Source Redash remains in its current code repo, and we will be releasing a new v9 shortly so stay tuned for more details.</p><p>As part of this acquisition, we will be offering a new way to use Redash from directly within Databricks. For our current Redash SaaS paid customers, your service will continue unchanged, and we will be sharing more details in the coming months on how we’re planning to expand the service. You can learn more in our <a href="https://redash.io/help/faq/databricks">customer FAQ</a>.</p>
                </div>
            </section>

            


        </article>


    </div>
</div></div>]]>
            </description>
            <link>https://blog.redash.io/redash-joins-databricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673728</guid>
            <pubDate>Mon, 29 Jun 2020 02:09:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rant about new Windows console]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673694">thread link</a>) | @xiaodai
<br/>
June 28, 2020 | https://clips.twitch.tv/TalentedSparklyDoveVoHiYo | <a href="https://web.archive.org/web/*/https://clips.twitch.tv/TalentedSparklyDoveVoHiYo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://clips.twitch.tv/TalentedSparklyDoveVoHiYo</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673694</guid>
            <pubDate>Mon, 29 Jun 2020 02:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My venture in hacking a fake vintage radio]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673673">thread link</a>) | @ca98am79
<br/>
June 28, 2020 | https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html | <a href="https://web.archive.org/web/*/https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img src="https://media0.giphy.com/media/dCcLQ5TLFANMj0p3Uh/giphy.gif" alt="Press F to pay respects"></p>
<p>For a year or so I have owned a nice fake-vintage radio/bluetooth speaker that originally caught my eye for sale in a FedEx office. The front has a quite nice VFD-style LED to show the status, a volume knob and four hard buttons. It has Bluetooth, USB, AUX and FM input. The radio and bluetooth was not bad, but there was nothing to be impressed about. It was definitely not "smart."</p>
<p>I decided to hack it to make it a bit smarter: to do AirPlay and be a smart alarm clock and whatever else I could think of. Since it was inexpensive, I had nothing to lose and everything to win. I thought putting a Raspberry Pi 0 or something in it would be nice.</p>
<p>My original plan was to somehow figure out how to hijack all the external components and control them to make the front and back of the radio as neat-looking as possible. At least I hoped to hijack the speaker, the volume knob, and the buttons. The problem I foresaw was that those components are often not documented and there was little chance that I could get a datasheet for them. I was very worried that I might have to give up the fake-VFD LED screen.</p>
<p>It turns out that I had to spend a year hacking it on and off. Here goes.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/fedex-sale.jpg" alt="FedEx sale"></p>
<p>First, I gutted the radio and saw that it has a main PCB with the LED panel directly soldered to it.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/radio-disassembled.jpg" alt="Disassembled radio"></p>
<p>The chip on the PCB isn't something I recognized. Luckily, the knob and the hard buttons are on a separate breakout board and are connected to the mainboard via a connector.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/main-pcb.jpg" alt="Main PCB"></p>
<h2 id="the-speaker">The speaker</h2>
<p>The speaker is also easy to deal with, as it is completely ordinary. It only required me to desolder it from the mainboard. As the Pi 0 has no built-in soundcard, I had to get a separate sound card for it.</p>
<h3 id="audio-injector-zero">Audio Injector Zero</h3>
<p>Initially, I used the Audio Injector Zero that I have no use for normally. To save space, I decided to permanently sandwich the Audio Injector to the Pi 0. I also had to buy a cheap amp for it, as the sound card can't directly drive the speaker.</p>
<p>One little issue was that the sound card produces stereo input, and the amp is also stereo, but I only have one speaker. I needed to mix both channels left and right to that speaker somehow. To that end, I am sure a Linux guru could make it work with configuring the sound card in software. However, I am not extremely well-versed with how ALSA or Pulse Audio works. I just wired both channels left and right of the amp to one channel input of the amp to mix the channels. For power, the amp needs 5V input, so I siphoned the two power pins from the Raspberry Pi.</p>
<p>I was surprised when the amp produced a very annoying hum. The hum was extremely noticeable when the Pi is under load. I don't know exactly why this happens, but I spent way too much time on this with no significant improvement. Ultimately, I decided it's the cheap amp that was giving me a hard time, because it was way too noisy. I know the Audio Injector itself was okay because the headphones output was clean.</p>
<h3 id="google-aiy-voice-hat">Google AIY voice hat</h3>
<p>After giving up on the Audio Injector Zero + Amp solution, I tried a different route: Drive the speaker directly with the Google AIY voice bonnet hat. Because the Google AIY sound card doesn't provide an easy way to set up on a plain raspbian, I just got their distro and started from there.</p>
<p>The speaker was hum-free after switching to the Google AIY soundcard. The tradeoff was that the Google Voice Bonnet V2 sound card made the stack quite a bit thicker. It has a female row of pins soldered on it, so I couldn't solder it directly on top of the Pi Zero.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/sound-cards.jpg" alt="Sound cards"></p>

<p>The front panel of the radio has two sets of elements: A knob of some sort to control the volume and four hard buttons. It has four wires hanging out of it. After I inspected the traces on the PCB, it was apparent that there is one common ground. The three other pins are for the buttons and the knob. All of the buttons are connected to a single pin, and the volume knob is connected to the other two.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/buttons-knob.jpg" alt="Buttons and knobs"></p>
<p>As a software person, I didn't know what the knob is called. <a href="http://dbindner.freeshell.org/">Dr. Don Bindner</a> suggested that the button might be a rotary encoder, and that turned out to be true. It seemed <a href="http://www.learningaboutelectronics.com/Articles/Rotary-encoder-circuit.php">trivial enough to read the knob</a>.</p>
<p>The buttons are more interesting. After poking around with a multimeter, it turned out that the buttons were tactile but each of them is connected in series to a different resistor. Then they all connect out to the same pin. The software in the chip scans the pin and figures out what button was pressed by sampling from an Analog-to-Digital (ADC) Converter reading. As the Pi has no ADC, we need something else that has an ADC to figure out what the button was pressed. Of course, I could as well hijack the tactile buttons and not have to deal with the ADC stuff but that seemed too aesthetically unpleasant for me.</p>
<p>I decided to pull out anArduino Pro Micro clone that I bought from China years ago. My reasoning for using the Pro Micro:</p>
<ol>
<li>The Arduino Pro Micro is super cheap: $2 cheap.</li>
<li>Even if I could add an ADC to the Pi, I need to continuously read the ADC from the Pi. That is a pain in the neck. I can't guarantee the timings on the Pi without going to a lot of care.</li>
<li>The Pro Micro can emulate a keyboard over USB, so the Pi can use triggerhappy to catch it.</li>
</ol>
<p>So with that, I made my arduino sketch and it worked out. I wanted to emulate the Winamp-style buttons ZXCV for multimedia keys and UD for volume up/down. Later on, I was quite annoyed with it because the keyboard dumps the keystrokes to the terminal, and <a href="https://androidcommunity.com/very-odd-bug-found-in-jailbreaking-process-20081109/">it could be bad</a>. I decided to implement the keys as multimedia keys. Unfortunately, you need a HID library to implement multimedia keys. Luckily, there is a library called <a href="https://github.com/NicoHood/HID">HID-Project</a> to achieve exactly what I wanted. After some tweakings for debounce, I could get the volume knob and the buttons to work exactly as I expected:</p>
<div><div><pre><code><span>void</span> <span>pressKey</span><span>(</span><span>uint16_t</span> <span>k</span><span>,</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
  <span>Consumer</span><span>.</span><span>write</span><span>(</span><span>k</span><span>);</span>
  <span>if</span> <span>(</span><span>d</span><span>)</span> <span>{</span>
    <span>delay</span><span>(</span><span>d</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>void</span> <span>kbd_loop</span><span>()</span> <span>{</span>
  <span>if</span> <span>(</span> <span>millis</span><span>()</span> <span>&lt;</span> <span>debounce</span> <span>+</span> <span>debouncerMs</span><span>)</span> <span>{</span>
    <span>return</span><span>;</span>
  <span>}</span>
  
  <span>// Volume rotary handling</span>
  <span>boolean</span> <span>encoderA</span> <span>=</span> <span>digitalRead</span><span>(</span><span>encoderPinA</span><span>);</span>
  <span>boolean</span> <span>encoderB</span> <span>=</span> <span>digitalRead</span><span>(</span><span>encoderPinB</span><span>);</span>

  <span>if</span> <span>((</span><span>encoderA</span> <span>==</span> <span>HIGH</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderB</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
    <span>if</span> <span>((</span><span>encoderALast</span> <span>==</span> <span>LOW</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderBLast</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_VOL_UP</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span> <span>else</span> <span>if</span> <span>((</span><span>encoderBLast</span> <span>==</span> <span>LOW</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderALast</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_VOL_DOWN</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span>
  <span>}</span>
  
  <span>encoderALast</span> <span>=</span> <span>encoderA</span><span>;</span>
  <span>encoderBLast</span> <span>=</span> <span>encoderB</span><span>;</span>

  <span>// Multimedia buttons</span>
  <span>int</span> <span>pushBtnRead</span> <span>=</span> <span>analogRead</span><span>(</span><span>pushBtnPin</span><span>);</span>
  <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>900</span> <span>&amp;&amp;</span> <span>debounce</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
    <span>debounce</span> <span>=</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&lt;=</span> <span>264</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>200</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_NEXT</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Next</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>150</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_PREVIOUS</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Prev</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>115</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_STOP</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Stop/M</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_PLAY_PAUSE</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Play pause</span>
    <span>}</span>
  <span>}</span>
  
  <span>debounce</span> <span>=</span> <span>millis</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>I could test the Arduino implementation right on my development computer with <code>xev</code> so that was really nice.</p>
<h2 id="the-fake-vfd-led-screen">The fake VFD LED screen</h2>
<p>The screen was the part that I had the most doubt about being able to control, because I have never worked with such a device before. Before trying to reverse-engineer it, I tried to look up similar 7-segment LED screens online hoping to find something similar. Those screens often have more than 8 pins (1 for the ground, 7 for each segment, and some more to select the digit. This one is nothing like that: It has only 7 pins. I wanted to give it up and just buy another screen that has a datasheet to save myself from trouble but I couldn't find anything that would fit into the original cutout for the screen. So I had to bite the bullet and hack the LED screen (I had nothing better to do in the craziness of the pandemic).</p>
<h3 id="general-workings">General workings</h3>
<p>There was no giveaway from the PCB what the ground pin for the display might be. I only had a multimeter in hand so what I did was set it to the diode tester mode. Then I probed pairs of pins to see what lights up. As luck would have it, I found out that each pair of pins lit up a different segment on the screen. So there was no common ground at all! I drew the screen and noted what pin pair light up each segment (excuse my nasty draft paper):</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/matrix-draft.jpg" alt="Draft Matrix"></p>
<p>First, I was really annoyed because the screen is yet another custom device I had to reverse engineer. Then, it really impressed me that this screen is quite well designed for such a cheap device. There were exactly 42 segments on this LED screen! The number of different segments is exactly the maximum number of permutations between any 2 pins: P(7,2) = 42. After some more digging, I found out that this wiring scheme is called <a href="https://hackaday.com/tag/charlieplexing/">Charlieplexing</a>. So each LED segment has a voltage drop of 1.860V, and my Arduino is 5V. I assumed a 20mA current and used a LED calculator and to figure out that I need to connect a 150K resistor to the LED. Because of the charlieplexing setup, I actually need half of that resistance for each pin (it will be apparent as you read on), so I soldered a 68K resistor to each pin.</p>
<h3 id="control-the-led-screen-programmatically">Control the LED screen programmatically</h3>
<p>The question then became how to control this LED screen programmatically. It was clear to me I can't possibly draw every segment by toggling the pins on and off in one whole sweep. Then I realized that I need to think of the LED screen like an <a href="https://www.youtube.com/watch?v=r38nVmxBfvM">analog TV screen</a>. Thus, each of the pins can be thought of as a horizontal scanline – except they are not on the same “line”! This might be quite obvious to those who have dealt with CRTs in the past (which I have not), but it might be hard to imagine for those who grew up with LCDs.</p>
<p>Let's say I want to draw the screen with segment 17, 18, and 11 lit up. That means I have to do two sweeps. First, pull pin 1 to GND and pull pin 2 to V_LED to light up segment 18. Then, pull pin 4 to GND and pull pin 1 and 7 to V_LED to light up segment 17 and 11 at once. Do it fast enough, and my eyes won't be able to tell we are flashing them!</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html">https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html</a></em></p>]]>
            </description>
            <link>https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673673</guid>
            <pubDate>Mon, 29 Jun 2020 01:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23673286">thread link</a>) | @yasp
<br/>
June 28, 2020 | https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    
    <section>
        <p>Local economies around the U.S. have continued to change quickly and dramatically – states and cities are slowly reopening, unemployment rates are starting to decline from the recent all-time high, COVID-19 cases are increasing in some states while decreasing in others, and communities are responding to the social unrest and George Floyd protests with city-wide curfews having impacted many businesses that were just able to reopen.</p>
        <p>Yelp last reported on the state of the local economy in <a target="_blank" href="https://www.yelpeconomicaverage.com/yea-q1-2020.html">our quarterly Yelp Economic Average report on April 28</a>, showing how much consumer activity in major swathes of Main Street had dropped off in just a couple of weeks in March. Now as states start to reopen and the nation responds to anti-Black racism and police brutality, a new set of challenges lay ahead for local economies.</p>
    </section>
    
    <section>
      <h2>Some Businesses Slowly Reopen, While Many Permanently Close</h2>
        <p>As of June 15, there were nearly 140,000 total business closures on Yelp since March 1. In April we reported more than 175,000 business closures, indicating that more than 20% of businesses closed in April have reopened. Las Vegas, NV, endured the highest number of closures relative to the number of businesses in the city (1,921 total closures), while Los Angeles, CA, had the largest total number of closures (11,774 total closures).</p>
    </section>
    
    <section>
    	<h3>Some Businesses are Slowly Reopening, Many Remain Closed</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Of all business closures on Yelp since March 1, 41% are permanent closures. Our data shows the largest spikes of permanent closures occurred in March, followed by May and June, indicating that the businesses that were already struggling had to permanently close right away and the businesses that were trying to hold on, but unable to weather the COVID-19 storm, were forced to shutter in recent months.</p>
    </section>
    
    <section>
      <h2>Retail and Restaurant Businesses Continue Innovating Amid High Closure Rates</h2>
        <p>While many business sectors have struggled during COVID-19 there are a few industries that have endured especially high closure rates. Among those with the highest rate of business closures are shopping and retail (27,663 closed businesses), restaurants (23,981 closed businesses), beauty (15,348 closed businesses) and fitness (5,589 closed businesses).</p>
        <p>Retail was by far the hardest hit, experiencing the highest number of total closures, with the average daily rate continuing to increase since March. Of all closures on Yelp since March 1, 20% are for retail businesses and 35% of closed retail businesses are indicated as permanent on Yelp.</p>
        <p>In March, Restaurants had the highest number of business closures, compared to other industries, and have continued to close at high rates. Of the businesses that closed, 17% are restaurants, and 53% of those restaurant closures are indicated as permanent on Yelp. Restaurants run on thin margins and can sometimes take months or even years to break even, resulting in this higher rate of permanent closures.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail have been Hit Hardest</h3>
    	<h4>Number of businesses marked temporarily or permanently closed on Yelp that were open on March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Though some businesses have shut down permanently, many have found <a target="_blank" href="https://blog.yelp.com/2020/04/businesses-creatively-adapt-coronavirus-response?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">innovative ways</a> to weather the storm and continue serving consumers. Many restaurants pivoted to offering takeout and delivery, while some experimented with take home meal and drink kits, and even virtual cooking classes. Some are finding new ways to use existing technology, like <a target="_blank" href="https://blog.yelp.com/2020/04/use-waitlist-online-takeout-restaurants?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">Yelp Waitlist to manage curbside pickup</a>. Servicing food to-go produces high margins for restaurants, and we’ve seen a 10X increase in searches for takeout since March 10.</p>
        <p>With many retail businesses shifting to curbside pickup, we’ve seen consumer interest spike in obtaining their goods in this way with a 20% increase in searches for curbside pickup. In the beauty industry we’ve seen hair stylists offering video hair cutting tutorials, estheticians offering virtual consultations, and small shops shifting their focus to ecommerce. Fitness in particular has seen a significant shift in their business model with gyms and studios offering virtual classes and personal trainers offering one-on-one virtual training sessions. If nothing else, local businesses owners have proven themselves to be resilient and creative during these trying times.</p>
    </section>
    
    <section>
      <h2>The Desire to Support Black-Owned Businesses Continues to Grow</h2>
        <p>As acknowledgement of anti-Black racism and police brutality become more wide-spread across the nation people are continuing to look for ways to support the Black community. Since May 25, we’ve seen a 1785% relative increase in searches for Black-owned businesses, compared to the three weeks prior. Review mentions of “Black-owned” (and related terms) also skyrocketed, up 426%, as people look to support and surface these businesses to the community.</p>
        <p>D.C. had the highest number of Black-owned searches, accounting for nearly 1% of all searches on Yelp, followed by Minnesota, Maryland, Michigan and Georgia. In fact, every state has shown an increase in searches for Black-owned businesses. Looking at metros, Ann Arbor, MI has the highest increase in searches for Black-owned, up 105X (accounting for 3% of all searches), followed by Denver (up 27X), Minneapolis (up 23X) and Baltimore (up 19X).</p>
    </section>
    
    <section>
    	<h3>Interest Increased in Supporting Black-Owned Businesses</h3>
    	<h4>Percent of Yelp searches for Black-owned businesses by state</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>While searches for Black-owned businesses have increased across all categories, there has been a particular increase in review content for Black-owned restaurants and food businesses (up 9X), beauty businesses (up 3X), nightlife (up 13X) and shopping (up 3X).</p>
    </section>
    
    <section>
      <h2>The Recovering Economy May Look Different Than the Old Economy</h2>
        <p>While some normal activity is starting to bounce back, due to the many changes impacting local economies — state rules, consumer behavior, and social unrest — many of the consumer interest shifts we saw in March and April started to rebound in May, with dramatic shifts in June.</p>
        <p>Outdoor activities that became popular at the height of the pandemic as people were finding ways to stay active while social distancing – such as mountain biking (down 40%), lakes (down 34%), golf (down 33%) and hiking (down 28%) – have dropped in consumer interest since May 1 relative to other active activities. People are starting to feel more comfortable participating in indoor activities, with increased consumer interest for escape games (up 182%), Go Karts (up 147%), axe throwing (up 113%), gyms (up 81%), bowling (up 63%) and yoga (42%). That said, in some instances people are still finding ways to stay outdoors while social distancing with an increased interest in mini golf (up 132%), amusement parks (up 28%) and horseback riding (up 21%).</p>
        <p>The previous spike in community supported agriculture and grocery has started to dip (down 54% and 26%, respectively) as people start heading back into restaurants. In fact, Yelp’s diners seated data shows significantly more people are dining-in at restaurants. During the peak of the pandemic, the number of diners seated across Yelp Reservations and Waitlist dropped essentially to zero. In early June, we've seen diners seated come back substantially – now down 57% compared to pre-pandemic levels. Restaurants that cater to group dining are among those making a comeback – fondue (up 123%), tapas bars (up 98%), hot pot (up 49%) and surprisingly, even buffets (up 17%) – as foods that gained increased interest through takeout and delivery have started to fall – pizza (down 28%), chinese (down 26%), fast food (down 18%). That said, takeout and delivery has continued to sustain interest on Yelp, still up 148% based on consumer interest relative to pre-pandemic levels, indicating this could be a trend that’s here to stay.</p>
        <p>People are also headed back into malls with outlet stores, shopping centers and thrift stores all up (up 84%, 81%, 72%, respectively), as well as hosting or attending formal events with increased interest in bridal (up 70%) and formal wear (up 102%). The previous increase in cannabis dispensaries, head shops and tobacco shops has declined (down 40%, 35% and 32%, respectively). There have also been significant shifts in consumer interest for health and wellness businesses with an increased interest in saunas (up 75%), reflexology (up 69%) and dentists (up 28%), while skilled nursing (down 46%) and hospitals (down 37%) decline.</p>
    </section>
    
    <section>
      
    </section>
    
    <section>
      <h3>How Business Categories are Faring</h3>
      <h4>Change in share of relative consumer interest on Yelp for select business types</h4>
    	
      <!--<p class='q12020-footer'>Read about the methodology <a href='./yea-q1-2020.html#methodology' class=underline>here</a></p>-->
    </section>
    
    <section>
        <p>As economies reopen, warm summer months arrive and consumers start spending more time out of their homes, we expect these shifts to continue changing at a dramatic rate. We'll continue to measure and report on these changes in local economies in our upcoming Q2 Yelp Economic Average.</p>
        <p>—Daniel Gole and Amy Shapiro contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#c9b9bbacbaba89b0aca5b9e7aaa6a4"><span data-cfemail="463634233535063f232a366825292b">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
        <p><em>Want to work with Yelp data yourself? We make a sample of our data available for academic use, and we’ve just added a <a href="https://engineeringblog.yelp.com/2020/06/how-businesses-have-reacted-to-covid-19-using-yelp-features.html" target="_blank">new batch of data</a> that reflects how businesses have reacted to the pandemic. Read more …</em></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</a></em></p>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673286</guid>
            <pubDate>Mon, 29 Jun 2020 00:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673053">thread link</a>) | @Lukas1994
<br/>
June 28, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673053</guid>
            <pubDate>Mon, 29 Jun 2020 00:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finishing a side project]]>
            </title>
            <description>
<![CDATA[
Score 423 | Comments 141 (<a href="https://news.ycombinator.com/item?id=23672686">thread link</a>) | @hugozap
<br/>
June 28, 2020 | https://hugozap.com/posts/how-to-finish-your-side-project/ | <a href="https://web.archive.org/web/*/https://hugozap.com/posts/how-to-finish-your-side-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><img src="https://hugozap.com/img/hands.jpg" alt="Illustration by Angélica Delvalle IG: ylikdelvalle"></p>
<p>It's no secret that finishing a side project is hard.</p>
<p>I've struggled with some side projects and had success with others. In this post, I'll focus on the actions and adjustments that have worked for me.</p>
<p>It's possible to work on and finish side projects even with a busy schedule, the key is to optimize for interruptability. You will be interrupted so instead of counting on having hours of deep work available, it's better to be realistic and make some adjustments to use available time in a better way and reducing the cost of interruptions by having tricks to switch context fast.</p>
<h2 id="a-failed-side-project-story">A failed side project story <a href="#a-failed-side-project-story">#</a></h2>
<p>Maybe you are familiar with a similar situation</p>
<p>At the beginning:</p>
<ul>
<li>High motivation.</li>
<li>Priority over other tasks.</li>
<li>Working long hours because it's fun.</li>
<li>Desire to work with a new technology</li>
<li>No problem working on weekends.</li>
</ul>
<p>After some time:</p>
<ul>
<li>Motivation decreases.</li>
<li>Feels overwheelming.</li>
<li>Harder to justify working on the project when there are other responsibilities.</li>
<li>Other stuff seems more interesting now.</li>
<li>Forgot how to set things up to continue working on the project.</li>
<li>Not sure what I was working on.</li>
<li>Forgetting about the project and archiving it.</li>
</ul>
<h2 id="the-challenges-with-side-projects">The challenges with side projects <a href="#the-challenges-with-side-projects">#</a></h2>
<ul>
<li>Context switching and high cognitive load is exhausting.</li>
<li><strong>Losing interest/ motivation</strong>.</li>
<li>Perfectionism - never ending projects.</li>
<li>Impostor syndrome.</li>
<li>Lack of focus.</li>
<li>Lack of time.</li>
<li>Unexpected life events.</li>
</ul>
<h2 id="re-framing-the-goal">Re framing the goal <a href="#re-framing-the-goal">#</a></h2>
<p>I believe you can set yourself for failure from the start if the goal is not clear.</p>
<p>I've been excited about ideas but later found that I was not really invested in the idea and just wanted to explore a cool feature/tool. It's good to go deeper to your true motivation.</p>
<p>Feeling overwhelmed can also contribute to abandoning the project, I'll talk about <strong>small steps</strong> and why it's key.</p>
<p>If your track record includes lots of ambitious projects and none of them finished, then starting with something smaller seems like the logical approach.</p>
<p>Pick a small battle, maybe just the key feature first, maybe support for just one platform. Cut off features for the first version, remember that there's a lot of forces against you completing your project so reducing load is important.</p>
<h2 id="the-approach">The approach <a href="#the-approach">#</a></h2>
<p>Now that you have a clear idea of what you want to finish, there's some actions and adjustments to your process that will increase the chance of winning the battle (shipping).</p>
<ul>
<li>Preparing your environment (painless context switch)</li>
<li>Work in <strong>Small steps</strong></li>
<li>Mental warm-up before each session.</li>
<li>Anticipate and expect interruptions.</li>
<li>Changing your physical location.</li>
<li>Writting down the ideas on your mind at the end of the session.</li>
</ul>
<h2 id="small-steps-are-key">Small steps are key <a href="#small-steps-are-key">#</a></h2>
<p>I like the idea of not having too many open boxes at the same time, where each box is a task/feature or something that you  started but haven't finished yet.</p>
<p>It's demoralizing to wait weeks or months for a win. Small steps give you small wins, it keeps the journey fun. There's less change of feeling stuck.</p>
<p><a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a> shares excellent resources on the topic of small steps in software.</p>
<h2 id="warming-up-before-each-session-to-reduce-cognitive-exhaustion">Warming up before each session to reduce cognitive exhaustion <a href="#warming-up-before-each-session-to-reduce-cognitive-exhaustion">#</a></h2>
<p>Before starting actual work, write about what would be good to achieve in the session. I find this ritual valuable as it helps me figure out the next small step. Writing the project goal (high level) every session is also a good way to switch context and reminding yourself what's it all about.</p>
<p>I'll talk about having a "context" log, where you write the current progress, and what to do next. If you have this file, reading the previous session log let's you resume your work faster.</p>
<h2 id="immediate-context-switching">Immediate context switching <a href="#immediate-context-switching">#</a></h2>
<p>With the limited amount of mental energy, is crucial to reduce the number of setup tasks required to do a working session on your project. The goal here is reducing the number of small decisions you have to make to have a working environment.</p>
<p>This is one of the most important things for me, and the way I approach it is:</p>
<ul>
<li>Creating a separated system User on my laptop.</li>
<li>Having an email address only for my project.</li>
<li>Having a "context" file where I log what's currently happening with my project, usually at the end of a work session.</li>
</ul>
<p>These have been valuable tools for me, let me explain why:</p>
<h3 id="a-separate-system-user-for-your-side-project">A separate system user for your side project <a href="#a-separate-system-user-for-your-side-project">#</a></h3>
<p>By creating a separate user, you automatically have all the operative system tools (calendar/notes/reminders , etc.) available ONLY for your project.</p>
<p>All the files on your desktop will have a relation to your project. This may not seem impressive but think about all the small distractions you find if you use the same user for your personal/work tasks:</p>
<ul>
<li>Time to find a file (filtering unrelated stuff will bring memories of other things)</li>
<li>Reminders/calendar notifications not related to your project</li>
<li>Dealing with other project setups can be stressful.</li>
</ul>
<p>I think it was Seth Godin who recommended having a separate laptop for a side project like writing a book. This is an alternative too.</p>
<p>You can add more extreme measures like redirecting distracting sites like news or reddit. If you need to login to one of those sites, it's better to switch user accounts. Try to keep your project user clean.</p>
<h3 id="having-an-separate-email-for-your-project">Having an separate email for your project <a href="#having-an-separate-email-for-your-project">#</a></h3>
<p><a href="https://hugozap.com/posts/ultimate-info-capturing-tool/">I'm a fan of email</a> as a note taking tool, it's available everywhere, the UI is simple. Having a separate email account lets you capture related notes/ideas/links from any device. This has been useful for me when I'm doing something else and have an idea, or find a resource that can be used to do something I want to incorporate into the project.</p>
<p>Later, when I log in to my project environment I'll get the emails with relevant information, no chance of getting distracted with other stuff.</p>
<h3 id="the-context-file%2C-(brain-dump).">The context file, (brain dump). <a href="#the-context-file%2C-(brain-dump).">#</a></h3>
<p>A context file is just a text file where you add a short summary of the current project status and what's on your mind at the time.</p>
<p>This has been valuable to me, because the act of writing it down helps me have a clear idea of things I could do next and next time I have time to work on my project I'll have a starting point and it reduces the cognitive load which maximizes the session efficiency.</p>
<h2 id="location">Location <a href="#location">#</a></h2>
<p>Going to a library or café (when possible) or event to another room and have a dedicated space for your current side project will make a difference.</p>
<p>Not sure about why, but using the same desk for different work and side projects is not ideal for me. If you can I recommend having a different place that helps you switch context quickly.</p>
<h2 id="abandoned-projects-may-not-be-a-failure-after-all.">Abandoned projects may not be a failure after all. <a href="#abandoned-projects-may-not-be-a-failure-after-all.">#</a></h2>
<p>Some abandoned projects end up being an inspiration to create something else years later. Maybe you learned something new, explored an idea, or found a problem not possible to solve with the knowledge and resources you had at the time.</p>
<p>It's good to have an open mind and be ok with finding dead-ends, they are powerful teachers.</p>
<p>However, shipping projects <strong>is awesome</strong> and by reducing scope and anticipating interruptions you will be able to complete your project and release it to the world.</p>
<h2 id="resources">Resources <a href="#resources">#</a></h2>
<p>For more information about the benefits of a "small step" approach to software development check the excellent resources from <a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a></p>
<h2 id="credits">Credits <a href="#credits">#</a></h2>
<p>Illustration by <a href="https://www.instagram.com/ylikdelvalle/">Angelica Delvalle</a> (In case you need art for your company products contact her, she does awesome stuff!)</p>


<p><a href="https://hugozap.com/">← Home</a></p>

    </div></div>]]>
            </description>
            <link>https://hugozap.com/posts/how-to-finish-your-side-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672686</guid>
            <pubDate>Sun, 28 Jun 2020 22:48:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from my first three years of freelancing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23672532">thread link</a>) | @JayClouse
<br/>
June 28, 2020 | https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/ | <a href="https://web.archive.org/web/*/https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#00aeff" data-width="10" data-mute="" data-fgopacity="1.00" data-mutedopacity="0.80" data-placement="bottom" data-placement-offset="0" data-content-offset="0" data-placement-touch="bottom" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#00aeff" data-rtl=""><p>It’s safe to say that we’ll all remember 2020.</p><p>There are a lot of reasons that we’ll look back on 2020 and cringe. As of this writing, we’re still in the middle of a global pandemic that the United States seems to have just given up on.</p><p>We’re in seeing a renewed fight for social justice, with more of us fighting against centuries of racial inequality than ever before.</p><p>The first two quarters of 2020 have taken an emotional toll on me just like they probably have on you. Everyone is hurting – individuals and business owners included.</p><p>But for the last two years, I’ve written an annual reflection on my own business.</p><p>To be honest, the anniversary snuck up on me this year!</p><p>But I wanted to go a little deeper on this year’s reflection. I wanted to bring you some <strong>real numbers</strong>, some <strong>behind-the-scenes</strong>, and the <strong>lessons learned</strong>.</p><p>And it’s important to note – <strong>I do not equate earnings with success</strong>. I certainly don’t equate them with happiness. If you look at earnings alone, my 2019 would look like a&nbsp;<em>huge&nbsp;</em>step backwards. But in reality, I believe 2019 to be far more impactful than 2018.</p><p>I’m optimizing for flexibility, fulfillment, and long-term vision. So as you’ll see in my 2019 breakdown, I accepted a short-term earnings compromise to get there.</p><p>If you want the tl;dr version, here’s a visual overview of my P&amp;L every year from 2017. It includes the my actual figures for January through June of 2020, as well as a projection for the full year based upon those numbers.</p><p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.webp 822w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.webp 300w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.webp 768w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.webp 100w" sizes="(max-width: 822px) 100vw, 822px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png 822w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.png 300w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.png 768w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.png 100w" sizes="(max-width: 822px) 100vw, 822px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20822%20462'%3E%3C/svg%3E" height="462" width="822" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png 822w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.png 300w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.png 768w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.png 100w" data-lazy-sizes="(max-width: 822px) 100vw, 822px" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png"></picture></p><p>If you’re ready to dig into what happened each of those years and why those trends look the way they do, let’s get started.</p><h2><strong>Year One: 2017</strong></h2><p>I spent the first four months of 2017 gainfully employed! Those earnings are <em>not</em> reflected in the numbers above or below, but it does mean that I had four fewer months to work with.</p><p>I quit my job in late April 2017. It came about a month sooner than I anticipated, but the timing seemed right for both me and the company I was leaving.</p><p>You can read more detail about that decision <a href="https://jayclouse.com/chapter-three/" target="_blank" rel="noopener noreferrer">here</a>, but it was a pretty half-baked move, truth be told.</p><p>I didn’t really have much of a plan, and I don’t recommend jumping into the deep end like I did!</p><p>The biggest victory was getting my first 15-member paid cohort of the Unreal Collective Accelerator off the ground.</p><p>Here’s my cringe-worthy first promotional video for Unreal Collective:</p><p>Pulling that first cohort together wasn’t<em>&nbsp;</em>easy. I ran a beta group of five members for a couple of months prior, and I was able to turn their stories into testimonials.</p><p>But I was still coming in with very little credibility.</p><p>The model behind the Unreal Collective Accelerator is pretty straightforward, and it’s similar to a typical mastermind program.</p><p>You take a small number of great people with ambitious goals, you force them into meeting once per week, and magic happens. <strong>Progress</strong> is made, <strong>goals</strong> are met, <strong>transformation</strong> is experienced.</p><p>Getting the right number of people, who mesh together well, ready to start the program at the same time is where you find the challenge.</p><p>But I’ve always been good at logistics and timelines, so I’m able to make it work – even if it was through brute force of a <em>lot </em>of conversations.</p><p>I wasn’t even calling it an accelerator at the time! I wasn’t sure what it was going to be – I <a href="https://jayclouse.com/on-unreal-collective/" target="_blank" rel="noopener noreferrer">thought</a> it might be a live events company.</p><p>After that first program ended, it was October. And I realized I wasn’t going to be able to pull another group together before the end of the year due to Thanksgiving, Christmas, and the new year.</p><p>So my financial engine was put on pause until 2018.</p><p>And I was broke.</p><p>To scrape by, I picked up a couple of freelance gigs building simple WordPress websites, writing email sequences, and helping a friend launch his podcast.</p><p>Then in late December, I got a surprise email: an opportunity to become a LinkedIn Learning instructor. I walked through the application process and was accepted shortly thereafter.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; Creating a budget was absolutely critical</li><li>👍&nbsp; Investing in mentorship and my own education was well worth it</li><li>👍&nbsp; When I’m in a bind, I look for work from the people close to me</li><li>👎&nbsp; I need to learn how to predict my cash flow</li><li>👎&nbsp; Things take longer to get started than I expect</li><li>👎&nbsp; When I underprice myself, it’s problematic through the project and for months afterward</li></ul><h3><strong>By the Numbers</strong></h3><ul><li><strong>Gross income</strong>: $29,468</li><li><strong>Expenses</strong>: $18,289</li><li><strong>Net income</strong>: $11,179</li></ul><h2><strong>Year Two: 2018</strong></h2><p>The start of the new year couldn’t come soon enough. When the year began, I was still working on a freelance marketing contract that saved my butt at the end of 2017.</p><p>But I wanted to start a new cohort of the Unreal Collective Accelerator.</p><p>And actually, 2018 was the first time I started calling it an Accelerator. I put a lot of thought into Unreal Collective as a business, because I wanted it to be a brand that meant more than just the 12-week program.</p><p>In February, I pulled my thoughts together and decided Unreal would split into three core product offerings:</p><ol><li>The 12-week program (Unreal Collective Accelerator)</li><li>A community membership (Unreal Collective)</li><li>Digital products and courses (called Guides at the time)</li></ol><p>I broke it all down in this 24-minute monologue called “Unreal Collective 2.0” that I shared with the community (then about 35 people):</p><p>To start the year, I brought together another cohort of 15 people. At the same time, I began writing my first LinkedIn Learning course and even accepted a part-time Entrepreneur In Residence position with Columbus’s Smart City team.</p><p>So things got off to a strong start.</p><p>But I burned myself out. Outside of my business, I was:</p><ul><li>Serving as Entrepreneur in Residence for Smart Columbus</li><li>Helping organize a track of events for Columbus Startup Week</li><li>Organizing a hackathon for Smart Columbus</li><li>Serving as Vice Chair of a nonprofit organization</li><li>Organizing a 6-month outdoor music series</li></ul><p>…and most of that was a volunteer effort.</p><p>The Smart Columbus role was fantastic – I was able to make an impact for the team and we put on an incredible event.</p><p>And somehow I also wrote 4 courses for LinkedIn Learning, ran two cohorts of the Unreal Collective Accelerator, and launched our podcast, <a href="https://upside.fm/" target="_blank" rel="noopener noreferrer">upside</a>.</p><p><a href="https://jayclouse.com/two-years-into-the-journey/" target="_blank" rel="noopener noreferrer">You can read my full 2018 reflection here</a></p><p>It was a strong year of earnings, but I really wanted to focus and devote more time to my core business. So I stepped away from the Smart Columbus role, the Vice Chair role, and the music series.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; Creating LinkedIn courses were great for cash flow and creating my own content</li><li>👍&nbsp; Coaching others was a viable service that people benefitted from</li><li>👍&nbsp; Freelance work can pay pretty well</li><li>👍&nbsp; I can pick up freelance work pretty easily</li><li>👎&nbsp; Freelancing can also be a diversion from my core business goals</li><li>👎&nbsp; Volunteering a lot of my time was hurting my business</li><li>👎&nbsp; Earning more doesn’t matter if my costs increase</li><li>👎&nbsp; Earning close to my previous salary doesn’t matter if I’m saving far less</li></ul><h3><strong>By the Numbers</strong></h3><ul><li><strong>Gross income</strong>: $72,713 (<strong><span>147% increase</span></strong>)</li><li><strong>Expenses</strong>: $45,834 (<strong><span>151% increase</span></strong>)</li><li><strong>Net income</strong>: $26,879 (<strong><span>140% increase</span></strong>)</li></ul><h2><strong>Year Three: 2019</strong></h2><p>In 2019, I resolved to do <em>less </em>so that I could do <em>more</em>. I <a href="https://jayclouse.com/doing-fewer-doing-more/" target="_blank" rel="noopener noreferrer">wrote</a> in January 2019:</p><blockquote><p>This year is all about doing fewer so that I can do more. Fewer projects, fewer opportunities that are outside of my core intention, in order to do more with the things I am focusing on.</p><p><strong>It’s not unlikely that I actually earn less this year</strong> than I did last year. A large part of my income in 2018 was from contracting and ad hoc projects, and those take time away from building my core business.</p></blockquote><p>Turns out, I was right. My income dropped 25% percent in 2019.</p><p>I decided to take on less freelance work – including courses from LinkedIn.</p><p>Instead, I focused on more Unreal Collective Accelerator cohorts and developing my own proprietary content.</p><p>That content took a few forms:</p><ul><li>Freelancing School courses</li><li>More episodes of upside</li><li>Planning for the launch of a new podcast (Creative Elements)</li><li>My weekly newsletter, Work In Progress</li></ul><p>I spent most of the first six months of 2019 producing the <a href="https://freelancing.school/" target="_blank" rel="noopener noreferrer">three courses within Freelancing School.</a> It was a <em>massive </em>effort and the courses get really great reviews from students.</p><p><iframe loading="lazy" src="about:blank" frameborder="0" allowfullscreen="allowfullscreen" data-rocket-lazyload="fitvidscompatible" data-lazy-src="https://player.vimeo.com/video/419356632?color=109aa1&amp;byline=0&amp;portrait=0"></iframe></p><p>And all the while, I facilitated three sessions of the Unreal Collective Accelerator – welcoming 50 new members across three cohorts.</p><p>…and that was exhausting. The program itself is 12 weeks long with about 4 weeks of marketing and onboarding required up front.</p><p>Some quick math will show you that 16 weeks across 3 sessions equals 48 weeks out of the year…and I wanted to finish before Thanksgiving!</p><p>I ended up staggering the second and third cohorts a bit, with two sessions overlapping for two weeks. And it was intense.</p><p>But, at the same time, my courses were published and beginning to sell.</p><p>Our podcast, upside, even earned more than $20,000 in gross income through sponsorships and partnerships (not reflected in the numbers below).</p><p>Over the summer, that podcast business produced a full-length documentary about the startup ecosystem in Columbus, Ohio, called <em>Test City, USA.</em></p><p>The film is 94 minutes long, features prominent voices in Columbus’s tech scene, and was shot <em>beautifully</em>.</p><p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.webp 1000w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.webp 300w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.webp 768w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.webp 100w" sizes="(max-width: 1000px) 100vw, 1000px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg 1000w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.jpg 100w" sizes="(max-width: 1000px) 100vw, 1000px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201000%20563'%3E%3C/svg%3E" alt="Mallory and I at the Test City, USA Premiere" height="563" width="1000" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg 1000w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.jpg 100w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg"></picture></p><p>We spent the entire summer filming and editing, and due to some lucky timing, we premiered the film at the Film Festival of Columbus in September where it won Best Ohio Feature. It was also accepted into the Columbus International Film Festival in April 2020.</p><p>I don’t know if I’ll ever produce another film in my life, but I’m so glad that <em>Test City, USA </em>exists. <a href="https://upside.fm/test-city-usa/" target="_blank" rel="noopener noreferrer">You can watch it here</a>.</p><p>To finish out the year, I created another course for LinkedIn Learning and signed an agreement with the Podglomerate, the network that I’ve partnered with for Creative Elements.</p><p>So while my overall income took a hit, I <em>really </em>put a lot of pieces in place to begin to build a larger, more scalable business through content and digital products.</p><p>And by cutting expenses, my net income was still up 24% from the year before! After a 2018 where I saved very little, I was able to dedicate money consistently to savings and retirement in 2019 as well.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; There is power in focus</li><li>👍&nbsp; It’s worth living cheaply while I still can to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/">https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/</a></em></p>]]>
            </description>
            <link>https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672532</guid>
            <pubDate>Sun, 28 Jun 2020 22:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life is 90% of my use cases for org-mode]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 236 (<a href="https://news.ycombinator.com/item?id=23672473">thread link</a>) | @billwear
<br/>
June 28, 2020 | http://stormrider.io/ninety-pct.html | <a href="https://web.archive.org/web/*/http://stormrider.io/ninety-pct.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <h2>
      life is 90% of my use cases for org-mode
      <br>
      <small>
	<em>so what's the other 10%?</em><br>
      </small>
    </h2>
    <hr>
    <a href="http://stormrider.io/index.html">blog index</a><br>
    <hr>
    <p>
      To really explain why I use org-mode for <bold>everything</bold>, I probably first have to explain my rules, which also requires a backstory.  I'll keep it short, no problem.
    </p>
    <p>
      I jacked into Unix the first time at Calhoun Community College, in Decatur, Alabama, during the summer of 1974.  I was 15, and my dad was a part-time programming instructor.  Having been an avid reader since the age of 6 (I read the entire elementary school library before the middle of second grade), text and text-processing was much on my mind.
    </p>
    <p>So when I encountered a system where plain text is the raw material flowing through the pipes, I was hooked.
    </p>
    <blockquote>
      <br>
      ...what I really learned was that the rules of Unix could be adapted to life.
      </blockquote>
    
    <p>
      This led me to undertake an informal study of Unix, all the way back to the Tech Model Railroad Club and all the hackers that came from there.  Yeah, I read the story about Margaret and the groceries and the Volkswagen; I understand his pain.
    </p>
    <p>
      But what I really learned was that the rules of Unix could be adapted to life.
    </p>
    <p>
      After about 30 years as a tech writer and frequent programmer, I finally settled on a set that works for me.  Little did I know that these very principles would lead me to org-mode, which would later lead me to find my people.
    </p>
    <hr>
    <h3>
      <center>
	Unix rules for life
      </center>
    </h3>
    <ul>
      <li>Keep it simple: It's cheaper and easier to carry around.</li>
      <li>Do one thing at a time: Multitasking is a lie.</li>
      <li>Network: You were born to connect.</li>
      <li>Say what you mean; nothing is truer than the truth.</li>
      <li>Hack: Trial and error is the only way we learn anything</li>
      <li>Be who you are: Even a bent wire can carry a great light.</li>
      <li>Use leverage; a bigger hammer isn't always the answer.</li>
      <li>Use what you have: never dig diamonds with a brick of gold.</li>
      <li>Have faith; all's possible, except maybe skiing through a revolving door.</li>
      <li>Think ahead, but don't worship your plans; remember today is the first day of the rest of your learning experience.</li>
    </ul>
    <hr>

<h3>
  a vi convert
</h3>
<p>
  I didn't start with org-mode, actually, but with plain journal files labeled YYYYMMDD, in a special directory in <code>/var/log</code>.  I still have those going back to sometime in the 90's.  The format was simple, but using the files soon became complex:
  </p><pre>	  
    *** personal journal of stormrider
    tue, aug 04, 1992 / 712904400
    sweetmorn, confusion 70, 3158 YOLD
    
    *** fortune -s
    Cold hands, no gloves.
    
    *** appts
    09:00  staff meeting, conf rm
    18:30  dinner with amit &amp; bonnie
    
    *** to do
    finish revisions on x-windows book
    do syllabus for advanced C class
    read some in Stevens &amp; Rago
    shower
    shave
    dress
    take out the trash otw to work
    .
    .
    .
    
    *** daily journal
    06:43 - man, didn't sleep well
    last night; i think i'm overdoing
    it on the coffee at work; maybe i
    should cut back some?
    .
    .
    .
  </pre>
  The unwieldy part came with all the repeated tasks, and tasks that got carried over from one day to the next (or didn't get finished). I had to copy yesterday's file, change all the key info, sort out the todo list, erase yesterday's journal, and generally do far too much work to keep my journal up.

<blockquote>
  <br>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck....
  </blockquote>
<p>
  I did it, but intermittently, supplanting it with post-it notes, pads, planners galore, palm pilots, palmtop computers, etc.  It seemed like every day I was badly copying tasks from one day to the next. Meanwhile, my unwillingness to use Windows didn't give the the luxury of Outlook, when it came along.
</p>
<p>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck as my editing platform of choice.
</p>
<p>
But I hadn't discovered org-mode yet. Either he didn't use it, or it hadn't been invented yet.  And to be honest, I kinda went back and forth between vi and emacs, depending on my "mood of the month."
</p>
<h3>
  a modem in the woods
</h3>
<p>
  Eventually, my HP job became a telecommuting-type arrangment, and I moved home to the farm, about an hour outside New Orleans, in the woods.  At that time, Internet was still modem-driven out here, so having command-line Linux with emacs on my laptop was a real lifesaver.
</p>
<p>
  Sometime not long before Katrina hit, I stumbled across org-mode.  I'd already used outline mode for some period of time (can't remember how long), and org-mode seemed like a logical follow-on from there.
      </p>
      <p>
	From there, org-mode just grew, and I grew with it.  All the features made it easy for me to both do what seemed natural for me, and do things in a way that felt like they supported my principles.  Gradually, my other methods of keeping track of things faded away, except for my alarm clock.  </p>
<p>
  Even when smart-phones took off, I was always trying to find some way to send org files over to my phone and use them there.  I think I even wrote some lua code in an iPhone wiki app to emulate org-mode with my files, though it was not fully satisfactory.
</p>
<h3>
  an org-mode resume
</h3>
      <p>
	Fast-forward to last May.  I'd been wanting to get on with Canonical for a long time, but hadn't found the right position, one that really matched my skills.  Then one Saturday, while I was waiting for my wife to meet me for some community event we were hosting, I saw a position that virtually described me.  I started to write a resume, but then decided that I would just take the job description elements, one-by-one, put them in an org file, and send them to the hiring manager.
      </p>
<p>
  Long-story short, almost everyone on this team used emacs, and org-mode, and lots of other .el packages that I also used every day.  I got the job, and so far, I'm very happy and feel like I fit in very well.
      </p>
      <h3>
	org-mode and my principles
      </h3>
      <p>
	Here's how I feel about using org-mode for everything: email, git, irc, web-browsing, organization, time-keeping, and so on.  And yes, I do use org-mode to connect with my email and the web, even though I use other packages (rmail, eww, magit, erc) to do the heavy lifing.  Let me walk it down, principle by principle:
	</p><ul>
	  <li><strong>Keep it simple:</strong> Granted, emacs isn't the simplest user interface, that is, until it becomes second nature.  After that, you'll find yourself accidentally erasing cells in your Google spreadsheet when you hit "C-x C-s" to try to save (good thing there's an undo). But the fact that you can use the same text for multiple functions: appointments, task states, task notes, clocking time, building an agenda, sending email, project planning, percentage completion, ....  The list is too long to quote, but just a simple statement, like "Get the discourse publishing tool working," can become the nucleus for a whole cycle's work and all the actions that go with it.</li><br>
	  <li><strong>Do one thing at a time:</strong> The window-driven nature of emacs makes it easy to switch tasks when you have to (just open another buffer) and then switch back later, and more quickly link back to where you were; not to mention that, if you become adept at using the agenda, you can keep yourself on track and move other things around with ease, and without any fear that they'll get lost.</li><br>
	  <li><strong>Network:</strong> Since I'm set up to send email, IRC, Mattermost, etc., directly from my org-mode tasks, it's easy to track where I am.  But even if I used another app, it's still really easy to just cut and paste a note next to a task and then set a follow-up time to prod, all without breaking your train of thought.  You're literally still looking at the work you're doing while you're messaging about it, so there's that.</li><br>
	  <li><strong>Say what you mean:</strong> You have the entire outline in front of you for whatever you're working on, so presentations, show-and-tell sessions, and status reports are really simple to give, whether verbally or in writing.</li><br>
	  <li><strong>Hack...:</strong> If it doesn't do what you want, you've got customizable variables, a huge library of packages, strong macro capability, and push-come-to-shove, emacs lisp, though I rarely have to go there, TBH.</li><br>
	  <li><strong>Be who you are:</strong> Org-mode matches my thinking style. Not true for everyone, but I tend to outline or mindmap (which you can do with org-mode, with the right .el package).</li><br>
	  <li><strong>Use leverage:</strong> Org-mode seriously leverages the power of plain text, in that you can either use the shortcuts to add an appointment, add tags, search tags -- or you can just do it by hand, because all of the special notation is plain text.  Leveraging human language in this way is helpful to me.</li><br>
	  <li><strong>Use what you have:</strong> Org-mode and emacs give me a stable platform that works everywhere, even on a printout.  I don't need license fees, special extensions, subscriptions, add-on tools, or constant updates to keep my life humming.</li><br>
	  <li><strong>Have faith:</strong> Org-mode has justified my faith, as has emacs.  Lots of tools I've used break, crash, or get killed by absorption (I once liked Astrid, e.g., but it suddenly got sold and went away).  Org-mode and emacs are pretty much here to stay, especially since there is no license fee, and I can keep a self-contained version backed up at home, should it ever stop being distributed.</li><br>
	  <li><strong>Think ahead:</strong> This is where org-mode, and especially the agenda, shine.  If I'm busy, I don't have to worry about keeping my outline clean.  I can stop in the middle of notes for another project, hit return, enter a to do for later (and tag it and schedule it to pop up later), and then move that to someplace more suitable later.  The agenda will clean it up and put it in perspective for me.  Or I can search for it, or pull up all open to-do items …</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://stormrider.io/ninety-pct.html">http://stormrider.io/ninety-pct.html</a></em></p>]]>
            </description>
            <link>http://stormrider.io/ninety-pct.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672473</guid>
            <pubDate>Sun, 28 Jun 2020 22:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL installation on Linux – with database creation]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23672367">thread link</a>) | @lukasbar
<br/>
June 28, 2020 | https://knowledgepill.it/posts/postgresql_installation/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql_installation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>PostgreSQL is open source software so we can install it wthout any limitation, including our personal code changes. It is distributed under own The PostgreSQL License(TPL).</p>
<p>Installation of PostgreSQL is easy on Linux Distributions.<br>
For purpose of tutorial we use CentOS 8.</p>
<p>We shuold get newest PostgreSQL from official repo - version in OS repos are mostly old - like for now when we get with CentOS 8 PostgreSQL 9.6 :)</p>

<hr>
<p>Newest links for repos:
<a href="https://www.postgresql.org/download/">PostgreSQL Official Repos</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf install https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm</span>
Last metadata expiration check: 0:27:00 ago on Sun <span>28</span> Jun <span>2020</span> 09:01:23 PM UTC.
pgdg-redhat-repo-latest.noarch.rpm                                                                                             <span>15</span> kB/s |  <span>11</span> kB     00:00    
Dependencies resolved.
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
 Package                                    Architecture                     Version                             Repository                              Size
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Installing:
 pgdg-redhat-repo                           noarch                           42.0-11                             @commandline                            <span>11</span> k

Transaction Summary
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Install  <span>1</span> Package

Total size: <span>11</span> k
Installed size: <span>11</span> k
Is this ok <span>[</span>y/N<span>]</span>: y
Downloading Packages:
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                                                                                      1/1
  Installing       : pgdg-redhat-repo-42.0-11.noarch                                                                                                      1/1
  Verifying        : pgdg-redhat-repo-42.0-11.noarch                                                                                                      1/1

Installed:
  pgdg-redhat-repo-42.0-11.noarch                                                                                                                             

Complete!
<span>[</span>root@postgres-lab ~<span>]</span>#
</code></pre></div>
<p>As mentioned earlier CentOS 8 has got build in module for PostgreSQL easy install. Despite that version of RDBMS is too old so we will disable it.</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf -qy module disable postgresql</span>
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf install postgresql12-server postgresql12</span>
Last metadata expiration check: 0:02:58 ago on Sun <span>28</span> Jun <span>2020</span> 09:30:47 PM UTC.
Dependencies resolved.
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
 Package                                      Architecture                    Version                                   Repository                       Size
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Installing:
 postgresql12                                 x86_64                          12.3-5PGDG.rhel8                          pgdg12                          1.6 M
 postgresql12-server                          x86_64                          12.3-5PGDG.rhel8                          pgdg12                          5.1 M
Installing dependencies:
 postgresql12-libs                            x86_64                          12.3-5PGDG.rhel8                          pgdg12                          <span>395</span> k

Transaction Summary
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Install  <span>3</span> Packages

Total download size: 7.1 M
Installed size: <span>30</span> M
Is this ok <span>[</span>y/N<span>]</span>: y
Downloading Packages:
<span>(</span>1/3<span>)</span>: postgresql12-libs-12.3-5PGDG.rhel8.x86_64.rpm                                                                          <span>365</span> kB/s | <span>395</span> kB     00:01    
<span>(</span>2/3<span>)</span>: postgresql12-12.3-5PGDG.rhel8.x86_64.rpm                                                                               1.2 MB/s | 1.6 MB     00:01    
<span>(</span>3/3<span>)</span>: postgresql12-server-12.3-5PGDG.rhel8.x86_64.rpm                                                                        3.0 MB/s | 5.1 MB     00:01    
--------------------------------------------------------------------------------------------------------------------------------------------------------------
Total                                                                                                                         4.1 MB/s | 7.1 MB     00:01     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                                                                                      1/1
  Installing       : postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            1/3
  Running scriptlet: postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            1/3
  Installing       : postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 2/3
  Running scriptlet: postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 2/3
  Running scriptlet: postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Installing       : postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Running scriptlet: postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Verifying        : postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 1/3
  Verifying        : postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            2/3
  Verifying        : postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3

Installed:
  postgresql12-12.3-5PGDG.rhel8.x86_64            postgresql12-server-12.3-5PGDG.rhel8.x86_64            postgresql12-libs-12.3-5PGDG.rhel8.x86_64           

Complete!
<span>[</span>root@postgres-lab ~<span>]</span>#
</code></pre></div>
<p>We will create sample data cluster.<br>
First we create directory for all PostgreSQL data:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># mkdir -p /postgresql/data</span>
<span>[</span>root@postgres-lab ~<span>]</span><span># chown postgres:postgres /postgresql -R</span>
</code></pre></div><p>Now from <code>postgres</code> OS user we can create data cluster:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ /usr/pgsql-12/bin/initdb -D /postgresql/data
The files belonging to this database system will be owned by user <span>"postgres"</span>.
This user must also own the server process.

The database cluster will be initialized with locale <span>"en_US.UTF-8"</span>.
The default database encoding has accordingly been set to <span>"UTF8"</span>.
The default text search configuration will be set to <span>"english"</span>.

Data page checksums are disabled.

fixing permissions on existing directory /postgresql/data ... ok
creating subdirectories ... ok
selecting dynamic shared memory implementation ... posix
selecting default max_connections ... <span>100</span>
selecting default shared_buffers ... 128MB
selecting default time zone ... UTC
creating configuration files ... ok
running bootstrap script ... ok
performing post-bootstrap initialization ... ok
syncing data to disk ... ok

initdb: warning: enabling <span>"trust"</span> authentication <span>for</span> local connections
You can change this by editing pg_hba.conf or using the option -A, or
--auth-local and --auth-host, the next time you run initdb.

Success. You can now start the database server using:

    /usr/pgsql-12/bin/pg_ctl -D /postgresql/data -l logfile start
</code></pre></div>
<p>Firt we will enable PostgreSQL service:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl enable postgresql-12</span>
Created symlink /etc/systemd/system/multi-user.target.wants/postgresql-12.service → /usr/lib/systemd/system/postgresql-12.service
</code></pre></div><p>Now we have to modify service to reflect our PostgreSQL directory:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># vi /usr/lib/systemd/system/postgresql-12.service</span>
<span>[</span>...<span>]</span>
<span>[</span>Service<span>]</span>
Type<span>=</span>notify

User<span>=</span>postgres
Group<span>=</span>postgres


Environment<span>=</span>PGDATA<span>=</span>/postgresql/data

<span>[</span>...<span>]</span>
</code></pre></div><p>Reload daemon after service chnages:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl daemon-reload</span>
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl start postgresql-12</span>
<span>[</span>root@postgres-lab ~<span>]</span><span># systemctl status postgresql-12</span>
● postgresql-12.service - PostgreSQL <span>12</span> database server
   Loaded: loaded <span>(</span>/usr/lib/systemd/system/postgresql-12.service; enabled; vendor preset: disabled<span>)</span>
   Active: active <span>(</span>running<span>)</span> since Sun 2020-06-28 21:46:29 UTC; 47s ago
     Docs: https://www.postgresql.org/docs/12/static/
  Process: <span>1972</span> ExecStartPre<span>=</span>/usr/pgsql-12/bin/postgresql-12-check-db-dir <span>${</span>PGDATA<span>}</span> <span>(</span>code<span>=</span>exited, status<span>=</span>0/SUCCESS<span>)</span>
 Main PID: <span>1977</span> <span>(</span>postmaster<span>)</span>
    Tasks: <span>8</span> <span>(</span>limit: 3248<span>)</span>
   Memory: 22.8M
   CGroup: /system.slice/postgresql-12.service
           ├─1977 /usr/pgsql-12/bin/postmaster -D /postgresql/data
           ├─1979 postgres: logger   
           ├─1981 postgres: checkpointer   
           ├─1982 postgres: background writer   
           ├─1983 postgres: walwriter   
           ├─1984 postgres: …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql_installation/">https://knowledgepill.it/posts/postgresql_installation/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql_installation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672367</guid>
            <pubDate>Sun, 28 Jun 2020 21:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardest Part of Working at a Growth Startup]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23671824">thread link</a>) | @svmanager
<br/>
June 28, 2020 | https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/hardest_part_of_startup/office-space.jpeg" alt="The hardest part of working at a growth startup is having to re-interview for your job every year">
Growth startups require both personal and business scaling.</p>

<p>The hardest part of working at a growth startup is having to re-interview for your job every year.</p>

<h3 id="the-challenge-of-scaling">The challenge of scaling</h3>

<p>You’re heading a key function at your 25-person startup. Maybe you’re head of engineering; maybe you run marketing. Hell, maybe you’re the CEO. You kick ass and your startup grows fast – and with that growth, the needs of the company evolve. Things in the new world are now going okay, but perhaps not optimally. Eventually, the CEO and board of directors get in a room to discuss what to do.</p>

<p>I can tell you what will happen in this room. The board will discuss your performance, and compare it to the performance of other, hypothetical executives – just as if you were interviewing for your own job. In your favor: you are a known quantity, presumably viewed as talented, and perhaps even a close friend. Against you: you haven’t done this before, and we need results now.</p>

<p>In many cases this conversation will lead to you being demoted or asked to leave. In extra cruel circumstances, you can literally get fired for having done a great job. This is normal, semi-expected, and sucks. And this happens to everyone – even founding CEOs are not immune.</p>

<p>The hardest part of this situation? These hard truths often go unspoken. Sometimes it’s just too awkward to tell someone who’s been there through thick and thin that they’re expected to be a stand-in for a future big league exec. And if you have a first-time management team, they might not even realize what’s going on – they may also be in the process of not scaling fast enough, either. At least when you’re interviewing, you’re explicitly given the chance to shine; such opportunities may not be spoon-fed to you during hectic growth.</p>

<h3 id="how-to-scale-yourself">How to scale yourself</h3>

<p>To avoid this situation you need to become a self-scaling machine. Read voraciously, and find opportunities to put new skills into practice – during growth mode there’s always too much to do, so take advantage and gain actual battlefield experience. You should constantly have an image in your mind of where you expect your team to be in 6 months and steer towards that future world. Learning to see around corners allows you to scale independently, and independence is a key leadership trait since <a href="https://staysaasy.com/scaling/2020/05/07/startup-is-this-normal.html">startups are constantly on fire</a>. Finding mentors who are at least 2-3 years ahead of you in terms of their own careers is another great way to build these instincts.</p>

<p>And most importantly, <em>ask questions</em>. Ask your manager how they expect your job will be different in 6 months (if you’re the CEO, this advice will be slightly different –&nbsp;a trusted advisor and/or executive coach can help). Ask them what they see as your current trajectory in the role. In my experience people are way too shy about asking direct questions in general, especially to their managers – it is literally your manager’s job to provide high-quality answers to your career questions. If you nail this, it’s a fast track towards increasing responsibility and growth.</p>

<h3 id="this-isnt-a-bad-thing">This isn’t a bad thing!</h3>

<p>From the other perspective, well-run growth startups give you the regular opportunity to interview for roles that are a level higher (or two!). <a href="https://www.linkedin.com/in/marissamayer/">This</a> is a <a href="https://www.linkedin.com/in/marcbenioff/">proven way</a> to <a href="https://www.linkedin.com/in/ericsyuan/">accelerate</a> your <a href="https://en.wikipedia.org/wiki/Sundar_Pichai#Career">career</a>. If you scale with a growing organization, you can pack decades of experience into years.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671824</guid>
            <pubDate>Sun, 28 Jun 2020 20:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 360º panoramic render using my 3D engine]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23671310">thread link</a>) | @atum47
<br/>
June 28, 2020 | https://victorribeiro.com/3Dsphere/ | <a href="https://web.archive.org/web/*/https://victorribeiro.com/3Dsphere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://victorribeiro.com/3Dsphere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671310</guid>
            <pubDate>Sun, 28 Jun 2020 19:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing the Exponential Function]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23671262">thread link</a>) | @hackernewsn00b
<br/>
June 28, 2020 | https://www.pseudorandom.com/implementing-exp | <a href="https://web.archive.org/web/*/https://www.pseudorandom.com/implementing-exp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>I explore several sophisticated approximation techniques for implementing the exponential function, $f(x) = e^x$, including Taylor series approximation, Lagrange interpolation, Chebyshev interpolation, Carathéodory-Fejer approximation and MiniMax approximation. This also serves as a more general introduction to the use of these methods for approximating other functions. In the process I walk through the relevant theory for each method and apply numerical analysis to navigate various forms of error. I also include my own Python and C++ implementations of each algorithm in double precision<label for="cb-1"><sup id="footnote-1"><span>1</span></sup></label><span><p>1:  Note that the implementations included here will both output <strong>and</strong> calculate in double precision. We can still apply sophisticated methods in this setting, but as a general rule you’ll need higher intermediate precision to obtain an approximation which is indistinguishable from the true value in double precision. This is one (but not the only) reason why it’s generally advisable to use an optimized <code>exp(x)</code> function provided by your platform rather than write one from scratch.</p></span> with heavy commentary. Finally, I analyze each implementation’s performance and accuracy characteristics using the hyper-optimized, platform-provided <code>exp(x)</code> function as a benchmark.<label for="cb-2"><sup id="footnote-2"><span>2</span></sup></label><span><p>2:  In most cases, whichever numerical library you’re using will map to the platform-provided <code>exp(x)</code> function. For example, this is what <code>numpy.exp</code> does <a href="https://github.com/numpy/numpy/blob/master/numpy/core/src/npymath/npy_math_internal.h.src#L451-L471">under the hood</a>.</p></span> The Background section opens with the motivating properties of $e^x$ and the basics of floating point systems. The code for each technique is included under the corresponding Implementation heading.</em></p>

<h2 id="section-0"><a href="#section-0">Background</a></h2>

<h3 id="section-1"><a href="#section-1">Taylor series</a></h3>

<p>To motivate the definition of $e$, we will recall some calculus. Let $f$ be a <a href="https://mathworld.wolfram.com/SmoothFunction.html">smooth</a> function at $a$. This is to say that $f$ is infinitely <a href="https://mathworld.wolfram.com/Differentiable.html">differentiable</a> at some real value $a$: for every $k^{\text{th}}$ derivative $f^{(k)}$, we can differentiate $f^{(k)}$ again to obtain the $(k + 1)^{\text{th}}$ derivative $f^{(k + 1)}$. By definition, any function with this property which can also be uniquely represented as a <a href="https://mathworld.wolfram.com/TaylorSeries.html">Taylor series</a> expansion “centered” at $a$ is called <a href="https://mathworld.wolfram.com/RealAnalyticFunction.html">analytic</a>. The Taylor series of $f$ centered at $a$ and evaluated at $x$ is defined to be</p>

<p>$$
f(x) = \frac{f(a)}{0!}(x - a)^0 + \frac{f’(a)}{1!}(x - a)^1 + \ldots + \frac{f^{(k)}(a)}{k!}(x - a)^k + \ldots
$$</p>

<p>This is a <a href="https://mathworld.wolfram.com/PowerSeries.html">power series</a>, or infinite polynomial with one variable. The center of expansion determines a neighborhood of values returned by the Taylor series, and the coefficient of each <em>Taylor term</em> is determined by repeatedly differentiating the function $f$ and evaluating it at $a$. A common center of expansion is $a$ = 0, in which case the Taylor series is also called a <a href="https://mathworld.wolfram.com/MaclaurinSeries.html">Maclaurin series</a> and the series is centered around the origin. This can be considered the “default” setting. If you cut off all terms of the Taylor expansion after some term $k$, you obtain a polynomial with degree $k$. The coefficient of the $k^{\text{th}}$ term of the series (or polynomial, if truncated) is given by</p>

<p>$$
a_{k} = \frac{f^{(k)}(a)}{k!}
$$</p>

<p>where 0! = 1.</p>

<p>For a concrete example, consider the Taylor series expansion of the <a href="https://mathworld.wolfram.com/Sine.html">sine</a> function. The sine function is not only infinitely differentiable, but cyclic.</p>

<p>$$
\begin{aligned}
\sin^{(1)}(x) &amp;= \cos(x), \\
\sin^{(2)}(x) &amp;= \cos^{(1)}(x) = -\sin(x), \\
\sin^{(3)}(x) &amp;= -\sin^{(1)}(x) = -\cos(x), \\
\sin^{(4)}(x) &amp;= -\cos^{(1)}(x) = \sin(x)
\end{aligned}
$$</p>

<p>We determine each $k^{\text{th}}$ coefficient of the Taylor series by evaluating $f^{(k)}$ at $a$ and dividing it by the factorial of $k$. If we want to expand the sine function around the origin ($a$ = 0), we obtain the cyclic coefficients</p>

<p>$$
\begin{aligned}
\sin(0) &amp;= 0, \\
\sin^{(1)}(0) &amp;= \cos(0) = 1, \\
\sin^{(2)}(0) &amp;= \cos^{(1)}(0) = -\sin(0) = 0, \\
\sin^{(3)}(0) &amp;= -\sin^{(1)}(0) = -\cos(0) = -1, \\
\sin^{(4)}(0) &amp;= -\cos^{(1)}(0) = \sin(0) = 0
\end{aligned}
$$</p>

<p>Since $(x - 0)^{k} = x^{k}$, we have the Taylor series expansion</p>

<p>$$
\sin(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \frac{x^9}{9!} - \ldots
$$</p>

<p>Truncating the Taylor expansion of a function $f$ at any term $k$ gives a finite approximation of $f$ using the $k$ degree <em>Taylor polynomial</em>. A Taylor polynomial of $f$ centered at $a$ produces very accurate approximations of $f(x)$ when $x$ is relatively close to $a$. As the absolute value of $x$ increases away from $a$, the accuracy of the Taylor polynomial rapidly decreases, which means it requires more terms of the Taylor series (i.e. a higher degree polynomial) for accurate approximation. Consider the following plot, which shows the values of $\sin(x)$ over the interval $[-20, 20]$ compared to its Taylor polynomials of degree 1, 3, 5, 7 and 9 centered at $a$ = 0.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"></a></p>
  <figcaption>$T_{n}$ denotes the degree $n$ Taylor polynomial of $\sin$</figcaption>
</figure>

<p>Observe that the Taylor approximation of $\sin(x)$ is more accurate when $x$ is near $a$ = 0, but quickly flies away from the true value of $\sin(x)$ further away from 0. The degree 1 Taylor polynomial is only an accurate approximation for $\sin(x)$ for a very small interval near the origin, whereas the degree 9 Taylor polynomial is very accurate within $[-5, 5]$. How long the approximation holds until it becomes extremely inaccurate depends on the number of terms of the Taylor polynomial. A higher degree polynomial will maintain a better approximation of $\sin(x)$ for longer, but any finite polynomial will eventually become extremely inaccurate.</p>

<h3 id="section-2"><a href="#section-2">Defining $e$</a></h3>

<p>The <a href="https://mathworld.wolfram.com/e.html">mathematical constant</a> $e$ is (almost) entirely motivated by the very nice properties it exhibits under exponentiation. In particular, the definition of $e$ was born out of the desire to find a continuous function which is its own derivative and which maps the additive identity 0 to the multiplicative identity 1. This is because solving difficult integration and differentiation problems is vastly more expedient with such a function. By extension a significant fraction of problems in applied mathematics and physics reduce to solving differential equations, for which such a function is fundamental.</p>

<p>As it happens, $f(x) = e^x$ uniquely satisfies this property. We can show this, and define $e$ directly in the process, by starting from the Taylor series representation of an arbitrary function $f$ infinitely differentiable at $a$ = 0. Suppose $a_0, a_1, \ldots$ are the coefficients of the Taylor series of $f$ centered at $a$. Then we have the Taylor series</p>

<p>$$
f(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \ldots
$$</p>

<p>It follows from the linearity of differentiation that the Taylor series expansion of the first derivative $f’$ is</p>

<p>$$
f’(x) = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>To determine a function which is its own derivative, we solve for the coefficients $a_0, a_1, \ldots$ which satisfy $f = f’$:</p>

<p>$$
a_0 + a_1 x + a_2 x^2 + \ldots = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>From here we can see the pattern</p>

<p>$$
\begin{aligned}
a_0 &amp;= a_1, \\
a_1 &amp;= 2a_2, \\
a_2 &amp;= 3a_3
\end{aligned}
$$</p>

<p>and so on, which is equivalent to</p>

<p>$$
\begin{aligned}
a_1 &amp;= a_0, \\
a_2 &amp;= \frac{a_1}{2}, \\
a_3 &amp;= \frac{a_2}{3}
\end{aligned}
$$</p>

<p>By induction we have a <a href="https://mathworld.wolfram.com/RecurrenceEquation.html">recurrence relation</a> which defines the $k^{\text{th}}$ coefficient $a_k$</p>

<p>$$
a_k = \frac{a_{k - 1}}{k}
$$</p>

<p>Given $a_0$ = 1, we find that the Taylor series of a function which is its own derivative is</p>

<p>$$
f(x) = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \ldots.
$$</p>

<p>We denote this function with $e^x$, where $e$ is defined to be the value of this function at $x$ = 1.</p>

<p>$$
e = f(1) = \sum_{k = 0}^{\infty}\frac{1}{k!} = 2.7183\ldots
$$</p>

<p>A more intuitive illustration of why $e^x$ is special is given by the following graph, in which exponential functions with various bases are plotted alongside their derivatives. An exponential function with a base less than $e$, like $b$ = 2, grows more quickly than its derivative. But when the base is greater than $e$, like $b$ = 4, it grows less quickly than its derivative.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"></a></p>
  <figcaption>When $b &lt; e$, we have $f'(x) &lt; f(x)$. When $b &gt; e$, we have $f'(x) &gt; f(x)$. But $b = e$ is the "goldilocks" base at which $f'(x) = f(x)$.</figcaption>
</figure>

<h3 id="section-3"><a href="#section-3">Floating point</a></h3>

<p>There is an intrinsic tension in that we want to determine accurate values of $e^x$ without doing too much work. Before we can consider the efficiency of an algorithm, we need to consider its accuracy. This leads us to define a variety of types of error, the most important of which comes from the way we approximate real numbers. It’s often impossible to calculate the exact value of $f(x)$ for an arbitrary function $f$, because computers can’t work with arbitrary real numbers.<label for="cb-3"><sup id="footnote-3"><span>3</span></sup></label><span><p>3:  <a href="https://en.wikipedia.org/wiki/Almost_all">Almost all</a> real numbers are not <a href="https://mathworld.wolfram.com/ComputableNumber.html">computable</a>. The reals which are computable are frequently not exactly representable to a desirable level of accuracy because they’re either irrational (and therefore have infinite decimal expansions) or rational with very long decimal expansions.</p></span> The best we can do is approximate the value to some acceptable accuracy.</p>

<p>The <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> <em>floating point</em> standard discretizes real intervals into a computable form by mapping all nearby real values in given neighborhoods to a single rounded value. Internally, an IEEE 754 binary floating point number $N$ is represented using the normalized form</p>

<p>$$
N = \pm b_1.b_2b_3 \ldots b_p \times 2^{E_{k}}
$$</p>

<p>where the first bit is allocated for the sign (the <em>sign bit</em>), the $p$ bits $b_1.b_2b_3 \ldots b_p$ comprise the <em>mantissa</em>, or <em>significand</em>, and $E_{k}$ is an integer exponent consisting of $k$ bits. Note that since this form is normalized, $b_1 = 1$, while each of $b_2, \ldots b_p$ may equal 0 or 1. IEEE 754 single precision binary floating point numbers have a total size of $32$ bits: $8$ are allocated for the exponent $E \in [-126, 127]$ and $23$ are allocated for the mantissa (with $p$ = 24 accounting for the normalized bit). Thus you can represent $2^{32}$ different values in single precision floating point, with underflow and overflow limits of $2^{127} \approx 3.4 \times 10^{38}$ and $2^{-126} …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pseudorandom.com/implementing-exp">https://www.pseudorandom.com/implementing-exp</a></em></p>]]>
            </description>
            <link>https://www.pseudorandom.com/implementing-exp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671262</guid>
            <pubDate>Sun, 28 Jun 2020 19:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visual Paper Summary: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23671183">thread link</a>) | @mpaepper
<br/>
June 28, 2020 | https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/ | <a href="https://web.archive.org/web/*/https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="new-blog-series-deep-learning-papers-visualized">New blog series: Deep Learning Papers visualized</h2>
<p>This is the first post of a new series I am starting where I explain the content of a paper in a visual picture-based way.
To me, this helps tremendously to better grasp the ideas and remember them and I hope this will be the same for many of you as well.</p>
<h2 id="todays-paper-accurate-large-minibatch-sgd-training-imagenet-in-1-hour-by-goyal-et-al">Today’s paper: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour by Goyal et al.</h2>
<p>The first paper I’ve chosen is well-known when it comes to training deep learning models on multiple GPUs. Here is the link to the <a href="https://arxiv.org/abs/1706.02677">paper of Goyal et al.</a> on arxiv.
The basic idea of the paper is this: when you are doing deep learning research today, you are using more and more data and more complex models. As the complexity and size rises, of course also the computational needs rise tremendously. This means that you typically need much longer to train a model to convergence.
But if you need longer to train a model, your feedback loop is long which is frustrating as you already get many other ideas in the mean time, but as it takes so long to train, you cannot try them all out.
So what can you do?</p>
<p>You can train on multiple GPUs at the same time and in theory get results faster the more GPUs you use. Assume you need 1 week to train your model on a single GPU, then with 2 GPUs in parallel, you should be able to achieve the same training in about 3.5 days and when using 7 GPUs you only need a day.</p>
<p>So how does it work to train your model on multiple GPUs? Typically, data parallelization is used which simply means that when you have your epoch, you send some distinct data to each distinct GPU. But then how do you get a model that benefits from all the data? Basically, you always synchronize the gradients, so after each batch, you collect the gradients from each GPU, calculate the average of the gradients over all GPUs and then adjust the model weights.</p>
<p>Let’s take a visual look at this:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/multi_gpu_training_batch_sizes.png" alt="Training the same amount of data on 1 vs 2 vs 4 GPUs">
    
      <figcaption>Training the same amount of data on 1 vs 2 vs 4 GPUs</figcaption>
    
  </figure>


<h3 id="increasing-the-batch-size---increasing-the-learning-rate">Increasing the batch size -&gt; increasing the learning rate</h3>
<p>Note what happens when you do this: your batch size is rising!
Let’s say you have 200 images per epoch and your batch size is 10. Then for a single GPU, you have 20 batches per epoch à 10 images. If you train on 2 GPUs, then your batch size is twice the size: 20. That’s because each of your two GPUs gets 10 images and calculates the gradients of those 10 and then you take the average of the gradients of those 2 GPUs, so your gradients are averaged over 20 images. This means that your epoch now only has 10 batches per epoch à 20 images. So by increasing the batch size, your are also reducing the number of batches per epoch and this in turn is exactly why it’s almost (except for the synchronization overhead) twice as fast to train.
Similarly, if you were to use 4 GPUs, then each GPU receives 10 images per batch, so your effective batch size is 40. Thus, you only need 5 batches per epoch to train your 200 images.</p>
<p>But in turn, if you only use 5 batches per epoch instead of 20, that also means that you are only taking 5 gradient descent steps instead of 20 on a single GPU.
We need to take a look what that means:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/formula_3_and_4.png" alt="Equations 3 and 4 from the paper">
    
      <figcaption>Equations 3 and 4 from the paper</figcaption>
    
  </figure>


<p>Equation 3 represents the single GPU case after k iterations, in our case let’s take k = 4, so after 4 batches. This means we were updating our weights 4 times which is the first sum with j &lt; k, so j=0, j=1, j=2 and j=3. The second sum is the loop over the images in the corresponding batch and we calculate the gradient ($\nabla l$) determined by our weights at that time t+j and the image example x. We divide everything by n which is just the batch size, so n=10 in our example case and multiply by the learning rate $\eta$.</p>
<p>In contrast, equation 4 represents the multi GPU case for 4 GPUs (as we had k = 4). The 4 GPUs only take a single gradient descent step as the batch size is 4 times as large ($kn=4*10=40$). In this case, the first sum with j &lt; k is over our 4 GPUs and the seconds sum over the batch of each individual GPU. As we take the average of all of these, we divide by $kn=40$. This means that our step is k times smaller.</p>
<p>Now, the main idea of the paper is that we can make sure that the step size is roughly the same by scaling up our learning rate by the number of GPUs we are using: $\hat{\eta}=k * \eta$.
By doing so, equations 3 and 4 become roughly the same, because $\hat{\eta} * \frac{1}{kn} = k*\eta * \frac{1}{kn} = \eta * \frac{k}{kn} = \eta * \frac{1}{n}$.</p>
<p>Or to visualize:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/four_steps_is_one_step.png" alt="Four SGD steps on a single GPU is a single step with four GPUs">
    
      <figcaption>Four SGD steps on a single GPU is a single step with four GPUs</figcaption>
    
  </figure>


<h3 id="intuition">Intuition</h3>
<p>To summarize so far: when we increase the number of GPUs to train with, we are increasing the effective batch size which leads to less batches per epoch and thus less SGD training steps. To compensate for less steps, we need to scale the learning rate linearly. This is simple: multiply the original single GPU learning rate by the number of GPUs you are using to train now. For example if your learning rate was 1e-3 before with a single GPU and now you train with 4 GPUs, then simply increase it to 4e-3.</p>
<p>Why does it intuitively make sense to scale the learning rate?</p>
<p>When your batch size is larger you will get a better estimate of the direction of the gradient in the right direction -&gt; your gradients are less fuzzy. Thus, when you have a more representative gradient, it makes sense to be able to take a larger step as the likelihood of walking in the wrong direction is reduced by the larger sample of examples.</p>
<p>Here is an illustration with the single GPU model taking 4 small steps (yellow) and the 4 GPU model taking 1 larger step (blue; the learning rate is multiplied by 4, so the step is four times as large):</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/gradients.png" alt="Illustration of gradient steps in the weight space. Red circle is the target / optimal weight configuration. Starting from a weight initialization in the left of the image, the single GPU model (yellow) takes 4 noisy steps. In contrast, the 4 GPU model (blue) takes a single larger step in a better approximated direction.">
    
      <figcaption>Illustration of gradient steps in the weight space. Red circle is the target / optimal weight configuration. Starting from a weight initialization in the left of the image, the single GPU model (yellow) takes 4 noisy steps. In contrast, the 4 GPU model (blue) takes a single larger step in a better approximated direction.</figcaption>
    
  </figure>


<h3 id="problem-initial-large-learning-rates">Problem: initial large learning rates</h3>
<p>The authors note that the learning process is most vulnerable in the beginning, because the weights are initialized at random and steps in the wrong direction can lead to a suboptimal space. Thus, they argue that the learning rate should not be immediately set to the higher value, but rather a learning rate annealing schedule should be used, so it starts low and then increases over time.</p>
<p>They try out different warm-up schedules and conclude that it works best to warm-up over 5 epochs, so that after 5 epochs the maximal learning rate is reached. However, I already observed machine learning models where a longer warm-up period is required, so you should try it out for your own problem.</p>
<p>How does this look like in practice? Assume your learning rate for single GPU training is 1e-3. So you want to end up at 4e-3 when training with 4 GPUs. So you need to add the learning rate (4-1) times to itself over 5 epochs: $lr_{epoch} = lr_{single-gpu} + lr_{single-gpu} * (n-1) * (epoch / 5)$. Here, $lr_{epoch}$ is the learning rate to use in a given epoch, $lr_{single-gpu}$ is the initial learning rate, n is the number of GPUs and epoch is your epoch.</p>
<p>And this is how this warm-up looks like over epochs:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/learning_rate_gradual_warmup.png" alt="Learning rate gradual warmup (orange) for 4 GPUs vs. constant learning rate for a single GPU (blue).">
    
      <figcaption>Learning rate gradual warmup (orange) for 4 GPUs vs. constant learning rate for a single GPU (blue).</figcaption>
    
  </figure>


<h3 id="summary">Summary</h3>
<p>While the paper goes into more details, I discussed the most practical aspects of it and tried to visualize the key parts.</p>
<p>In particular, when training your machine learning model with multiple GPUs, you should scale your learning rate linearly with the number of GPUs you are using.
However, due to initial instability, use a learning rate warmup period which scales the learning rate linearly over the first couple of epochs.
By doing so, you are able to achieve similar loss curves as in the single GPU training.</p>
<p>The authors were able to train a ResNet-50 on ImageNet with a batch size of 8192 (!) on 256 GPUs at the same time and thus needing only 1 hour to train ImageNet. When the increased the batch size further than this, however, the accuracy got worse than the single GPU training, so there is still a (high) limit to how much you can reduce the training time by using more GPUs.</p>
<p>If you want to see how to implement this in PyTorch, check out <a href="https://www.paepper.com/blog/posts/pytorch-multi-gpu-training-for-faster-machine-learning-results/">my article PyTorch multi-GPU training for faster machine learning results</a>.</p>

    </div></div>]]>
            </description>
            <link>https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671183</guid>
            <pubDate>Sun, 28 Jun 2020 19:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Designed the Perfect Startup Logo for $20]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23671160">thread link</a>) | @colinkeeley
<br/>
June 28, 2020 | https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20 | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      

      <main id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5ef8a8243895911144cbe029">
  
  <div>
    <p><time datetime="2020-06-28" pubdate="">
      <p><span>Jun </span><span>28</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-06-28" pubdate="">Jun 28 </time>How I Designed the Perfect Startup Logo for $20</h2>

    
  </div>
  

  <div>
    <article id="article-5ef8a8243895911144cbe029">
      
      
      <div data-controller="BlogProgressBar">
        
        
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593354946896" id="item-5ef8a8243895911144cbe029"><div><div><div data-block-type="2" id="block-669bf59b698de3db9753"><div><p>You can engage a fancy design agency and pay tens of thousands of dollars (or more!) for a nice logo or you can follow what I do.&nbsp;The results are similar. </p><p>With a design agency, you are really paying for their creativity. The technical skills of making a logo are cheap with global labor.&nbsp;</p><p>Here is how I made the <a href="http://avocadoaudio.com/">Avocado</a> logo in under an hour and for less than $20. </p><p><strong>Step 1: Browse Dribbble for inspiration</strong></p><p><a href="https://dribbble.com/">Dribbble</a>&nbsp;is a community for the world’s best designers to post their work. It is the place to go for design inspiration.&nbsp;</p><p>I like to search for related keywords and heart the designs I like to save them for later.&nbsp;</p><p><a href="http://avocadoaudio.com/">Avocado</a> is a platform for the world’s best audio courses and I wanted our design to reflect that. </p><p>For the logo, I wanted to combine an avocado design with an audio design.&nbsp;</p><p>Here are some Avocado designs I liked. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_14665"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png" data-image-dimensions="2436x1366" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-06-28 at 9.53.17 AM.png" data-load="false" data-image-id="5ef8aef13895911144cc9f7d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593355161879_14955"><p>And some audio sound waves designs I liked.&nbsp;</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1593354253719_30245"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png" data-image-dimensions="2446x1374" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-06-28 at 8.47.28 AM.png" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png"></p>
          
            </div>
          

        </div>

        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593354253719_35584"><div><p><strong>Step 2: Sketch out ideas on paper yourself</strong></p><p>I sketched out some ideas I had and got feedback from friends in the office.</p><p>I put the sound wave in the avocado as a seed and played around with what the sound wave could look like.&nbsp;</p><p>Unfortunately, I only had an orange marker for this.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593354253719_36753"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593355142059-AFU85Q1ZI3JF90UV7FMI/ke17ZwdGBToddI8pDm48kNJUD_Xf508KnMqMAKvVaDd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s1LK8gu64hle203mIYOUnpbdT6-oIN-TUtU8fTm8cncKnzEUP5xgLKmtvxj_vUGDA/EV5ITlPWoAAqzlP.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593355142059-AFU85Q1ZI3JF90UV7FMI/ke17ZwdGBToddI8pDm48kNJUD_Xf508KnMqMAKvVaDd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s1LK8gu64hle203mIYOUnpbdT6-oIN-TUtU8fTm8cncKnzEUP5xgLKmtvxj_vUGDA/EV5ITlPWoAAqzlP.jpeg" data-image-dimensions="2500x2015" data-image-focal-point="0.5,0.5" alt="EV5ITlPWoAAqzlP.jpeg" data-load="false" data-image-id="5ef8ab84b23df673eaa46eb7" data-type="image" src="https://colinkeeley.com/blog/EV5ITlPWoAAqzlP.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593354253719_37052"><div><p><strong>Step 3: Iterate yourself</strong></p><p>This is a creative process and it takes time to arrive at something you’re happy with. </p><p>Try out different sketches and give it a few days of background thinking before you pay money to actually get it digitized.&nbsp;</p><p>Trying to iterate with a designer is what will cost you money. </p><p><strong>Step 4: Pay a Fiverr designer to digitize</strong></p><p>Share your sketch and your inspirations with a Fivver designer.&nbsp;<a href="https://track.fiverr.com/visit/?bta=122081&amp;brand=fiverrcpa">Fivver</a>&nbsp;is one of the largest online marketplaces for global talent.&nbsp;</p><p>Finding a quality designer can be hard. Just use&nbsp;<a href="https://track.fiverr.com/visit/?bta=122081&amp;brand=fiverrcpa&amp;landingPage=https%3A%2F%2Fwww.fiverr.com%2Flogo_star40%2Fdesign-simple-logo-for-your-brand%3Fsource%3Dorder_page_summary_gig_link_title%26funnel%3D00e4ecef-7686-40d4-969c-99979a3ef769">the designer I use</a>. I’ve used him for a few different logos and highly recommend him. He does excellent work and will make iterations until you’re happy.&nbsp;</p><p>The first versions won’t be perfect. Feel free to ask for small changes.&nbsp;</p><p>Here were some early versions for Avocado. </p></div></div><div data-aspect-ratio="100" data-block-type="5" id="block-yui_3_17_2_1_1593355161879_18569"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356437258-1K6YUYN7PA4712E0Q6KJ/ke17ZwdGBToddI8pDm48kDaNRrNi77yKIgWxrt8GYAFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7WT60LcluGrsDtzPCYop9hMAtVe_QtwQD93aIXqwqJR_bmnO89YJVTj9tmrodtnPlQ/Avocado2.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356437258-1K6YUYN7PA4712E0Q6KJ/ke17ZwdGBToddI8pDm48kDaNRrNi77yKIgWxrt8GYAFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7WT60LcluGrsDtzPCYop9hMAtVe_QtwQD93aIXqwqJR_bmnO89YJVTj9tmrodtnPlQ/Avocado2.png" data-image-dimensions="255x255" data-image-focal-point="0.5,0.5" alt="Avocado2.png" data-load="false" data-image-id="5ef8b095f6302b5d71e5059b" data-type="image" src="https://colinkeeley.com/blog/Avocado2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_21999"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356497385-UWXN8PPDOQMTID8Y4GB0/ke17ZwdGBToddI8pDm48kOWyE5OVYnQHUXmTlJzahLdZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7R6SWOyAW0y1cpSTASaRj-wpFjVvAVgB0Fbm05Sc9zeDJmvI9K9QhjOgiAXjkI4xEw/Avocado.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356497385-UWXN8PPDOQMTID8Y4GB0/ke17ZwdGBToddI8pDm48kOWyE5OVYnQHUXmTlJzahLdZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7R6SWOyAW0y1cpSTASaRj-wpFjVvAVgB0Fbm05Sc9zeDJmvI9K9QhjOgiAXjkI4xEw/Avocado.png" data-image-dimensions="241x254" data-image-focal-point="0.5,0.5" alt="Avocado.png" data-load="false" data-image-id="5ef8b0d1d960e626a1e17a57" data-type="image" src="https://colinkeeley.com/blog/Avocado.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593355161879_18858"><div><p>We iterated on the shape and quantity of the sound waves until we found a happy medium with more seed-like sound waves. </p><p>The final result for <a href="http://avocadoaudio.com/">Avocado</a>. I’d put up against $100,000+ designs from any major agency. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_16521"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg" data-image-dimensions="2500x1563" data-image-focal-point="0.5,0.5" alt="large avocado logo on rectangle compressed.jpg" data-load="false" data-image-id="5ef8b00f3895911144ccc04c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div></div>

        

        

        
      </div>
      

    </article>
  </div>







  
</div>

      </main>

      

    </div></div>]]>
            </description>
            <link>https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671160</guid>
            <pubDate>Sun, 28 Jun 2020 19:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Geometry Through Graph Theory (2018)]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23671130">thread link</a>) | @prospero
<br/>
June 28, 2020 | http://ideolalia.com/2018/08/28/artifex.html | <a href="https://web.archive.org/web/*/http://ideolalia.com/2018/08/28/artifex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p><img src="http://ideolalia.com/images/artifex-set-operations.png" alt=""></p>

<h3 id="how-i-spent-my-summer">how I spent my summer</h3>

<p>A few months ago, I decided to implement set operations on curved regions.  I had the <a href="https://www.springer.com/us/book/9783540779735">the canonical textbook on computational geometry</a>, which described approaches for polygons comprised of straight lines, and it seemed like <a href="http://paperjs.org/">other projects</a> had extended these techniques to <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">parametric curves</a>.  I figured it would take a couple of weeks.</p>

<p>Unfortunately, the field of computational geometry embodies a fundamental contradiction.  In geometry, the angles of a triangle add up to exactly π radians, and if <em>u</em> is clockwise from <em>v</em> then <em>v</em> must be counter-clockwise from <em>u</em>.  Computers, on the other hand, use floating point representations which make a mockery of these simple Euclidean truths.</p>

<p>The academic literature largely ignores this.  Algorithms are proven to be geometrically sound, and robust implementations are left as an exercise for the reader.  This is akin to a world in which hash collisions caused unavoidable data loss, and the academic response was to implicitly assume the existence of a perfect hash function.  If a paper is predicated on unrealistic assumptions, we cannot evaluate it on its own terms; we must understand, empirically, how well it functions when these assumptions are broken.</p>

<p>With this in mind, we can now look at the existing algorithms for <a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)">polygon clipping</a>, which is the term of art for polygon set operations.  Every technique is a variation on a common theme:</p>

<p><img src="http://ideolalia.com/images/artifex-clipping.png" alt=""></p>

<ul>
  <li>Given two or more rings, find every point of intersection</li>
  <li>Segment the rings at the points of intersection</li>
  <li>Decide whether each segment should be included, based on the operation being performed</li>
</ul>

<p>The dozen or so papers on this subject differ only in the third step.  Since our decision to include a segment typically inverts at an intersection point, they describe a variety of approaches for using our decision to about one segment to inform our decision about adjacent segments.</p>

<p>My textbook described a method using <a href="https://en.wikipedia.org/wiki/Doubly_connected_edge_list">doubly-connected edge lists</a>, which is a generic geometric data structure.  I assumed that meant it could be reused for other problems, so I started my implementation.</p>

<p>A month went by.</p>

<p>I had finished the implementation my first week, but it wasn’t reliable.  A DCEL is a collection of linked loops, which can be incrementally updated.  When performing a set operation, we incrementally bisect the original set of loops, and then determine which should and shouldn’t be included.  Despite my best efforts, I kept finding new shapes that caused adjacent faces to get tangled together, creating a Möbius strip that is simultaneously inside and outside the expected result.</p>

<p>Slowly, I realized the problem wasn’t the data structure, it was the first step that every paper glossed over: finding all the intersections.  The DCEL assumes the edges at a vertex have a total ordering: the previous edge is directly clockwise, and the next one is directly counter-clockwise.  If we miss an intersection, we might conclude two curves are both clockwise relative to the other, causing everything to fall apart.</p>

<p>I began to look for better ways to find intersections, hoping that if I found an approach that was sufficiently accurate, my work on the DCEL could be salvaged.  Unfortunately, the approaches I found in the literature and implemented in the wild were no better than what I had been using.  My data structure demanded precise inputs, without internal contradictions, and I couldn’t deliver.</p>

<p>At that point, I began to wonder if I had missed something fundamental.  I thought maybe if I dissected how other, more mature, libraries handled my pathological shapes, I could work backwards to see where I had gone wrong.  But when I began to feed these shapes into well-established projects like paper.js, I found they failed just as badly.</p>

<p>To find my pathological inputs, I had been using property-based testing.  Given a random combination of shapes, I would perform a point-in-region test and compare it to a reference result, generated by querying each shape individually and combining the results according to the operation.  Most inputs worked fine, but after a few hundred thousand inputs it would inevitably find some failure.</p>

<p>Other projects, it turned out, had been a little less eager to find their own failure modes.  Some only had a handful of example-based tests, others had a static suite of a few thousand inputs they used to validate their changes.  If I had missed something, it appeared to be that no one else expected these operations to be particularly robust.</p>

<hr>

<h3 id="why-is-this-so-hard">why is this so hard?</h3>

<p>Floating point arithmetic is best understood through a simple, maddening fact: <code>a + (b - a)</code> does not necessarily equal <code>b</code>.  It might be equal, or it might be off by just a little, where “little” is relative to the larger of the two numbers.  This means that when we compare two floating point numbers, we cannot do a precise comparison, we have to ask whether they differ by less than some <em>epsilon</em> value.</p>

<p>This epsilon represents the level of numerical uncertainty to which we’ve resigned ourselves.  There is vast folk wisdom around how to minimize this uncertainty, but the fact remains that every arithmetic operation injects a bit of uncertainty, and it grows cumulatively with each successive operation.  When dealing with small numbers, this uncertainty may dwarf the values themselves.</p>

<p>An intersection, in a precise mathematical sense, occurs wherever the distance between the curves is exactly zero:</p>

<p><img src="http://ideolalia.com/images/artifex-precise-intersection.png" alt=""></p>

<p>But in a practical sense, it is wherever the distance between the curves is close enough to zero:</p>

<p><img src="http://ideolalia.com/images/artifex-fuzzy-intersection.png" alt=""></p>

<p>This has at least one intersection, but we could just as easily return three or ten within that overlapping range.  This uncertainty is anathema to the published techniques, which rely on counting these intersections to determine whether we’re inside or outside the other shape.  A single spurious intersection may cause the entire result to vanish.  If two objects with similar curvature move across each other, the result will tend to flicker in and out of existence.</p>

<p>These techniques may suffice for straight lines, which require smaller epsilons, but they are wholly unsuited to the relative imprecision of parametric curves.</p>

<hr>

<h3 id="embracing-the-uncertainty">embracing the uncertainty</h3>

<p>As the weeks passed, the errors uncovered by my tests went from feeling random to feeling malicious.  Floating point arithmetic may be deterministic, but as I watched my screen, waiting for the tests to fail, I imagined a demon in the FPU nudging the values as they flowed past, trying to move them beyond the threshold of self-consistency.</p>

<p>One day, I realized this was exactly the narrative behind <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error-correcting codes</a>; we assume our data has been randomly altered en route, and we want to return it to a consistent state.  It didn’t seem like I could get it right the first time, so why not just fix it afterwards?</p>

<p>Consider the union of two ellipses:</p>

<p><img src="http://ideolalia.com/images/artifex-two-ellipses.png" alt=""></p>

<p>Ostensibly, there should only be three points of intersection, one on the left and two on the right.  But for the reasons described above, any intersection routine will likely find multiple points of intersection on the left as the curves converge on each other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-intersections.png" alt=""></p>

<p>The segments on the left are small enough, and thus imprecise enough, that our spatial intuition for the problem will just mislead us.  For this reason, it’s better to think of it as a graph:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-graph.png" alt=""></p>

<p>Now we have to decide which edges to include, and which to exclude.  Since we’re trying to find the union, we want to keep any segments that are outside the other shape:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-valid-result.png" alt=""></p>

<p>This is a well-formed result; there is a single cycle, and once we remove that cycle there are no leftover edges.  But we can’t rely on getting this lucky; the edges on the left might have succumbed to floating point error and believed they were both inside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-incomplete.png" alt=""></p>

<p>This is not a well-formed result; there are no cycles, and a bunch of leftover edges.  To make this consistent, we need to either close the loop, or remove the leftovers.  The cost of these changes is measured by the aggregate length of the edges we are adding or removing.</p>

<p>The minimal set of changes is equivalent to the shortest path between the dangling vertices.  Having found the path, we then invert the inclusion of every edge it passes through.  In this case, it passes through one of the edges we originally excluded, so we add that edge back in, and return the cycle we just created.</p>

<p>Alternately, both edges might think they are outside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-redundant.png" alt=""></p>

<p>In this case, we have a complete cycle, but once we’ve extracted it there’s a single leftover edge:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-leftover.png" alt=""></p>

<p>Here again, we search through all the remaining edges for the shortest path between the two dangling vertices.  Since it passes through our leftover edge, we remove it.</p>

<p>Every floating point inconsistency will surface as one of these two cases, or some combination thereof.  By searching for the shortest path between the dangling edges, we find the smallest possible edit that will yield a consistent result.  Of course, a consistent result is not necessarily the <em>correct</em> one, but the fact that floating point errors tend to cluster around the smallest edges makes this a reasonable heuristic.  More importantly, it has weathered tens of millions of generative test cases without any issues.</p>

<p>A complete implementation of this algorithm can be found <a href="https://github.com/lacuna/artifex/blob/master/src/io/lacuna/artifex/utils/regions/Clip.java">here</a>.</p>

<hr>

<p>I’m not sure if this is a novel approach, but at the very least it represents a meaningful improvement on the state of the art in open source.  Intuitively, it feels like this might be a means to avoid epsilon hell in a wide range of geometric and numerical algorithms.  If anyone is aware of prior art in this vein, I’d be very interested to see it.</p>

<p>My work on the <a href="https://github.com/lacuna/artifex">Artifex</a> library is ongoing, but I hope it proves useful to others, and look forward to sharing my own projects that it will enable in the near future.</p>

<hr>

<p><em>Thanks to Alex Engelberg, Elana Hashman, Angus Fletcher, Reid McKenzie, and Zack Maril for feedback on early drafts of this post.</em></p>

		</article>
	</div>

</div></div>]]>
            </description>
            <link>http://ideolalia.com/2018/08/28/artifex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671130</guid>
            <pubDate>Sun, 28 Jun 2020 18:56:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Podaero/alpha-3 – a social network of small groups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23670859">thread link</a>) | @newman8r
<br/>
June 28, 2020 | https://podaero.com/info/show-hn | <a href="https://web.archive.org/web/*/https://podaero.com/info/show-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://podaero.com/info/show-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23670859</guid>
            <pubDate>Sun, 28 Jun 2020 18:20:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does DARPA Work?]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 88 (<a href="https://news.ycombinator.com/item?id=23670246">thread link</a>) | @MKais
<br/>
June 28, 2020 | https://benjaminreinhardt.com/wddw | <a href="https://web.archive.org/web/*/https://benjaminreinhardt.com/wddw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="EssayContents">
<div id="EssayContentsInner">
<div>
  <div id="abstract-ish">
  <p>How can we enable more science fiction to become reality?</p>
  <p><span>If you want to do something, it usually pays to study those who have done that thing successfully in the past. Asking </span><span>‘what is this outlier’s production function?’
    </span><span>can provide a starting point. </span></p>
  <p><span>DARPA is an outlier organization in the world of turning science fiction into reality. Since 1958, it has been a driving force in the creation of weather satellites, GPS, personal computers, modern robotics, the
      Internet, autonomous cars, and voice interfaces, to name a few. However, it is primarily limited to the domain of defense technology – there are DARPA-style ideas that are out of its scope. &nbsp;Which emulatable attributes contributed to
      DARPA’s outlier results? </span><span>What does a</span>&nbsp;domain-independent&nbsp;“ARPA Model” look like? <span>Is it possible to
      build other organizations that generate equally huge results in other domains by riffing on that model?</span></p>
  <p>Gallons of ink have been spilled describing <span>how</span><span>&nbsp;DARPA works</span><a id="footnote_source_1" href="#footnote_1"><sup>1</sup></a><span>,
      but </span><span>in a nutshell here is</span><span>&nbsp;</span><span>how DARPA works.</span><span>&nbsp;Around 100 </span><span>program managers (PMs)</span><span>&nbsp;with ~5 year appointments create and run <span>programs</span> to pursue high-level visions like “actualize the idea of man-comp</span><span>uter symbiosis.” In these programs they fund researchers at universities and both
      big and small companies to do research </span><span>projects</span><span>&nbsp;of different sizes. Collectively, groups working on projects are called </span><span>performers</span>.&nbsp;Top-level
      authority lies with a <span>Director </span>who ultimately reports to the Secretary of Defense. </p>
  <p><span>DARPA has an incredibly powerful model for innovation in defense research, and I believe an abstract ‘<span>ARPA Model</span>’ could yield similar results in other domains. In this piece I’ll explain in detail why
      DARPA works. I’ll use that description to feel out and describe to the best of my ability a platonic ARPA Model. &nbsp;I’ll also distill some of the model’s implications for potential riffs on the model. Incidentally,
      I’m working on just such an imitator, and in future essays, I’ll explain why this model could be incredibly powerful when executed in a privately-funded context.</span></p>
  <h4>How to use this document</h4>
  
  <p>This document acts more like a collection of atomic notes than a tight essay – a DARPA-themed tapas if you will. The order of the sections is more of a guideline than a law so feel free to skip around. Throughout you will come across internal links that <a id="self-link" href="#self-link">look like this</a>.
    These links are an attempt to illustrate the interconnectedness of the ARPA Model.</p>
  <p><span>There are two stand-alone pieces to accomodate your time and interest:</span><span> a
    </span><span><a href="#distillation">distillation</a></span><span>, and the </span><span><a href="#h.nbyw8g2b67uk">full work</a></span><span>. </span><span>The
      distillation is meant to capture and compress the main points of the full work. Each section of the distillation internally links to the corresponding section one level deeper so if you want more info and nuance you can get it. </span></p>
      <p><span>I would rather this be read by a few people motivated to take action than by a broad audience who will find it merely interesting. In that vein, if you find yourself wanting to share this on Twitter or Hacker News, consider instead sharing it with one or two friends who will take action on it. Thank you for indulging me!</span></p>
      </div>
  
  <h2 id="program_managers_mini"><span>Program Managers</span></h2><p><span><a href="#at_the_end_of_the_day_the_arpa_model_depends_on_badass_program_managers_which_mirrors_the_obsession_with_“talent”_in_other_disciplines">At the end of the day the ARPA Model depends on badass program managers.</a></span><span>&nbsp;</span><span>Why is this the case? PMs need to
      think for themselves and go up and down the ladder of abstraction in an unstructured environment. On top of that they need to be effective communicators and coordinators because so much of their jobs is building networks. There’s a
      pattern that the abstract qualities that make “great talent” in different high-variance industries boils down to the ability to successfully make things happen under a lot of uncertainty. Given that pattern, the people who would
      make good DARPA PMs would <span>also</span> make good hedge fund analysts, first employees at startups, etc. so digging into </span><span><a href="#why_do_people_become_darpa_program_managers?">people’s motivations for becoming a PM</a></span><span>&nbsp;is important. More precise details about what makes a PM good prevent you from going after the exact same people as every other high-variance industry. When ‘talent’ isn’t code for ‘specialized
      training’ it means the role or industry has not been systematized. Therefore, despite all the talk here and elsewhere about ‘the ARPA Model’ we must keep in mind that we may be attributing more structure to the process than
      actually exists.</span></p><p><span><a href="#darpa_program_managers_pull_control_and_risk_away_from_both_researchers_and_directors">DARPA program managers pull control and risk away from both researchers and directors</a></span><span>.</span><span>&nbsp;PMs pull control away
      from directors by having only one official checkpoint before launching programs and pull control away from performers through their ability to move money around quickly. PMs design programs to be high-risk aggregations of lower-risk projects.
      Only 5–10 out of every 100 programs successfully produce transformative research, while only 10% of projects are terminated early. Shifting the risk from the performers to the program managers enables DARPA to tackle </span><span>systemic </span><span>problems where other models cannot.</span></p><p><span><a href="#the_best_darpa_program_managers_notice_systemic_biases">The best program managers notice systemic biases and attack them. </a></span><span>For example, noticing that all of the finite element modeling literature
      assumes a locally static situation and asking ‘what if it was dynamic?’ </span><span>“The best program managers can get into the trees and still see the forest.”</span><span> Obviously, this
      quality is rather fuzzy but leads to two precise questions:</span></p>
  <ol ="1"="">
    <li><span>How do you find people who can uncover systemic biases in a discipline? </span></li>
    <li><span>How could you systematize finding systemic biases in a discipline?</span></li>
  </ol>
  <p><span>The first question suggests that you should seek out heretics and people with expertise who are not experts. The second question suggests building structured frameworks for mapping a discipline and its assumptions.
    </span></p><p><span><a href="#a_large_part_of_a_darpa_program_manager’s_job_is_focused_network_building">A large part of a DARPA program manager’s job is focused network building</a></span><span>. </span><span>DARPA PMs network in the literal
      sense of creating networks, not just plugging into them. PMs meet disparate people working on ideas adjacent to the area in which they want to have an impact and bring them together in small workshops to dig into which possibilities are not
      impossible and what it would take to make them possible. The PMs host </span><span>performer days</span><span>&nbsp;— small private conferences for all the people working on different pieces of the program where
      performers can exchange ideas on what is working, what isn’t working, and build connections that don’t depend on the PM. </span><span><a href="https://en.wikipedia.org/wiki/J._C._R._Licklider">J.C.R. Licklider</a></span><a id="footnote_source_2" href="#footnote_2"><sup>2</sup></a><span>&nbsp;is a
      paragon here. He brought together all the crazy people interested in human-focused computing. On top of that, &nbsp;he also helped create the first computer science lab groups. PMs also build networks of people in different classes of organizations –
      government, academia, startups, and large companies. These connections smooth the path for technologies to go from the lab to the shelf. </span></p><p><span><a href="#darpa_pms_need_to_think_for_themselves,_be_curious,_and_have_low_ego">DARPA PMs need to think for themselves, be curious, and have low ego.</a></span><span>&nbsp;</span><span>Why does this matter? When you are
      surrounded by smart, opinionated people the easy option is to either 100% accept what they’re saying because it’s eloquent and well-thought through or reject it outright because it sounds crazy or goes against your priors. Thinking
      for yourself allows you to avoid these traps. PMs need to be curious because building a complete picture of a discipline requires genuine curiosity to ask questions nobody else is asking. A large ego would lead to a program manager imposing
      their will on every piece of the program, killing curiosity and the benefits of top down problems and bottom up solutions.</span></p><p><span><a href="#darpa_is_incredibly_flexible_with_who_it_hires_to_be_program_managers">DARPA is incredibly flexible with who it hires to be program managers.</a></span><span>&nbsp;</span><span>There are legal provisions in place that
      let DARPA bypass normal government hiring rules and procedures. Hiring flexibility is important because PMs are the sort of people who are in high demand, so they may be unwilling to jump through hoops. Bureaucracies ensure consistency through
      rules – minimal bureaucracy means there are no safeguards against hiring a terrible program manager so the principle that ‘A players hire A players and B players hire C players’ is incredibly important. &nbsp;</span></p><p><span><a href="#darpa_program_managers_have_a_tenure_of_four_to_five_years">DARPA Program managers have a tenure of four to five years.</a></span><span>&nbsp;</span><span>This transience is important for many reasons.
      Transience can inculcate PMs against the temptation to play it safe or play power games because there’s only one clear objective – make the program work. You’re out regardless of success or failure. Explicitly temporary roles can
      incentivize people with many options to join because they can have a huge impact, and then do something else. There’s no implicit tension between the knowledge that most people will leave eventually and the uncertainty about when that
      will be. Regular program manager turnover means that there is also turnover in ideas.</span></p><p><span><a href="#why_do_people_become_darpa_program_managers?">Why do people become DARPA Program managers? </a></span>From a career and money standpoint, being a program manager seems pretty rough.<span>&nbsp;There are unique benefits though. It offers an outlet for people frustrated with the conservative nature of academia. The prospect of getting to control a lot of money without a ton of oversight appeals to some people.
      Patriotism is definitely a factor, and hard to replicate outside of a government. Being a PM can gain you the respect of a small, elite group of peers who will know what you did. Finally, there may be a particular technological vision they want
      to see out in the world and DARPA gives them the agency to make it happen in unique ways.</span></p>
  <h2 id="incentives_and_structure_mini"><span>Incentives and Structure</span></h2><p><span><a href="#opacity_is_important_to_darpa’s_outlier_success">Opacity is important to DARPA’s outlier success.</a></span><span>&nbsp;</span><span>Congress and the DoD have little default oversight
      into how a PM is spending money and running a program. </span><span>Opacity removes incentives to go for easy wins or to avoid being criticized by external forces. Of course, opacity can also be abused in too many ways to list,
      so it’s important to ask: How does DARPA incentivize people not to abuse opacity? DARPA’s small size and flat structure enable peer pressure to work in …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjaminreinhardt.com/wddw">https://benjaminreinhardt.com/wddw</a></em></p>]]>
            </description>
            <link>https://benjaminreinhardt.com/wddw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23670246</guid>
            <pubDate>Sun, 28 Jun 2020 17:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hacker News front page in the style of a print newspaper]]>
            </title>
            <description>
<![CDATA[
Score 618 | Comments 132 (<a href="https://news.ycombinator.com/item?id=23669650">thread link</a>) | @wolfgang42
<br/>
June 28, 2020 | https://www.wolfgangfaust.com/project/paper-hn/ | <a href="https://web.archive.org/web/*/https://www.wolfgangfaust.com/project/paper-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This looks much nicer if you enable JavaScript.</p><div><section><img src="https://assets.mofoprod.net/network/images/mozilla-og-image-min.original.jpg"><h2><a href="https://foundation.mozilla.org/en/campaigns/oppose-earn-it-act/">Oppose the Earn IT Act</a></h2><p><code>mozilla.org</code> — While the senators championing the bill, which they’ve named the Eliminating Abusive and Rampant Neglect of Interactive Technologies Act (EARN IT Act), may have good intentions, they are seriously misguided about the impact of their proposal. Encryption ensures our information, from our sensitive financial and medical details to emails and text messages, is protected. But the EARN IT Act will create a broad path for government actors to seriously undermine strong encryption, putting our information at risk. That’s why Mozilla is joining dozens of other internet health and civil society organizations in calling on the U.S. Congress to vote no on the EARN IT Act. <strong><a href="https://news.ycombinator.com/item?id=23703367">OPPOSE</a>,&nbsp;1</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23702122">Ask HN: Who is hiring? (July 2020)</a></h2><p><code>news.ycombinator.com</code> — Please state the job location and include the keywords REMOTE, INTERNS and/or VISA when the corresponding sort of candidate is welcome. When remote work is not an option, include ONSITE. <strong><a href="https://news.ycombinator.com/item?id=23702122">JULY</a>,&nbsp;2</strong></p></section><section><img src="https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/all-new-f-150-017-1593110070.jpg?crop=0.702xw:0.526xh;0.0401xw,0.339xh&amp;resize=1200:*"><h2><a href="https://www.roadandtrack.com/new-cars/car-technology/a32970167/f-150-generator-pro-power-onboard/">How the 2021 Ford F-150's onboard generator works</a></h2><p><code>roadandtrack.com</code> — Putting household-style electrical outlets in a production vehicle is nothing new. Minivans, trucks, and family cars have long offered onboard power for charging devices or powering low-demand equipment. But for the new F-150, Ford stepped it up significantly. The new truck is equipped with a generator system that can run power tools, mini fridges, loudspeakers, and more. Getting to that level of power, though, wasn't easy. <strong><a href="https://news.ycombinator.com/item?id=23704497">F-150</a>,&nbsp;3</strong></p></section><section><img src="https://whimsical.club/assets/images/screenshots/webrocker.jpg"><h2><a href="https://whimsical.club/">The Whimsical Website Club</a></h2><p><code>whimsical.club</code> — A curated list of sites with an extra bit of fun. <strong><a href="https://news.ycombinator.com/item?id=23704270">WHIMSICAL</a>,&nbsp;4</strong></p></section><section><img src="https://images.wsj.net/im-204654/social"><h2><a href="https://www.wsj.com/articles/who-is-the-mystery-shopper-leaving-behind-all-those-online-shopping-carts-11593617464">A Google bot scrapes pricing info by adding items to carts</a></h2><p><code>wsj.com</code> —  John Smith started shopping early on a recent Wednesday and didn’t stop for days.  <strong><a href="https://news.ycombinator.com/item?id=23704123">BOT</a>,&nbsp;5</strong></p></section><section><h2><a href="https://www.reuters.com/article/us-tesla-shares/tesla-becomes-most-valuable-automaker-in-latest-stock-rally-idUSKBN2426E8">Tesla becomes most valuable automaker in latest stock rally</a></h2><p><code>reuters.com</code> — (Reuters) - Tesla Inc on Wednesday became the highest-valued automaker as its shares surged to record highs and the electric carmaker’s market capitalization overtook that of former front runner Toyota Motors Corp.  <strong><a href="https://news.ycombinator.com/item?id=23705344">BECOMES</a>,&nbsp;6</strong></p></section><section><h2><a href="https://www.youtube.com/watch?v=vuMg0QwKAGI">Not a Wheelchair [video]</a></h2><p><code>youtube.com</code> —                                      <strong><a href="https://news.ycombinator.com/item?id=23701394">WHEELCHAIR</a>,&nbsp;7</strong></p></section><section><img src="https://ciechanow.ski/images/anchor.png"><h2><a href="https://ciechanow.ski/lights-and-shadows/">Lights and Shadows</a></h2><p><code>ciechanow.ski</code> — It’s hard to describe how paramount light is. Ultimately, it is the only thing we see. But just as important the presence of light is, so is its absence. To talk about light we have to start in darkness so let’s jump straight into it. <strong><a href="https://news.ycombinator.com/item?id=23702552">LIGHTS</a>,&nbsp;8</strong></p></section><section><img src="https://diamantidis.github.io/assets/social/tips/list-makefile-targets.png"><h2><a href="https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">How to list all the targets on a Makefile</a></h2><p><code>diamantidis.github.io</code> — make is great tool to orchestrate the setup and build process of a project. It expects a Makefile, where we define targets to execute, like for example install and run. Then we can use make install and make run to execute those tasks. <strong><a href="https://news.ycombinator.com/item?id=23702756">TARGETS</a>,&nbsp;9</strong></p></section><section><img src="https://avatars1.githubusercontent.com/u/16842314?s=400&amp;v=4"><h2><a href="https://github.com/photonlines/Intuitive-Guide-to-Maxwells-Equations">Intuitive Guide to Maxwell's Equations</a></h2><p><code>github.com</code> —  An intuitive and visual guide to understanding Maxwell's equations.  <strong><a href="https://news.ycombinator.com/item?id=23700295">INTUITIVE</a>,&nbsp;10</strong></p></section><section><img src="https://github.com/kotartemiy/pygooglenews/raw/master/pygooglenews-demo.gif"><h2><a href="https://github.com/kotartemiy/pygooglenews">Show HN: Pygooglenews – Python library for advanced Google News data mining</a></h2><p><code>github.com</code> —  If Google News had a Python library  <strong><a href="https://news.ycombinator.com/item?id=23701343">PYGOOGLENEWS</a>,&nbsp;11</strong></p></section><section><img src="https://cdn.cjr.org/wp-content/uploads/2020/07/AdobeStock_170520436-800x419.jpeg"><h2><a href="https://www.cjr.org/special_report/reporting-on-facebook.php">What It’s Like to Report on Facebook</a></h2><p><code>cjr.org</code> — One day in July 2016, Casey Newton, a tech reporter for The Verge, sat down at Facebook headquarters in Menlo Park for the biggest interview of his career. Across from him was Mark Zuckerberg. With his characteristic geeky excitement, Zuckerberg described the promising initial test flight of Aquila, a drone with a wingspan larger than a 737 jet that was part of his plan to provide internet connectivity all over the world.  <strong><a href="https://news.ycombinator.com/item?id=23701304">REPORT</a>,&nbsp;12</strong></p></section><section><img src="https://cdn.substack.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png"><h2><a href="https://yassine.substack.com/p/the-gap-between-learning-code-and">The gap between learning code and producing usable software</a></h2><p><code>substack.com</code> — One of the unspoken areas about software development is building usable software. Learning how to code, coding something, and having it used by thousands is no easy task. In this article, I’ll be discussing the most important pillars that you need to address before launching your product.&nbsp; <strong><a href="https://news.ycombinator.com/item?id=23702061">PRODUCING</a>,&nbsp;13</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23700275">Launch HN: PostEra (YC W20) Medicinal Chemistry-as-a-Service and Covid Moonshot</a></h2><p><code>news.ycombinator.com</code> — Hey everyone! We’re Alpha, Matt and Aaron, co-founders of PostEra (https://postera.ai/). The title above is quite a mouthful (we used all 80 characters) so we'll begin by breaking down what it means. <strong><a href="https://news.ycombinator.com/item?id=23700275">POSTERA</a>,&nbsp;14</strong></p></section><section><h2><a href="https://thestarphoenix.com/pmn/business-pmn/german-stock-trading-platform-xetra-down-all-securities-affected/">German stock trading platform Xetra down, all securities affected</a></h2><p><code>thestarphoenix.com</code> — LONDON — Frankfurt-based electronic trading system Xetra was experiencing a “technical issue,” affecting all securities traded on the platform, a Deutsche Boerse spokesman said on Wednesday. <strong><a href="https://news.ycombinator.com/item?id=23700283">XETRA</a>,&nbsp;15</strong></p></section><section><img src="https://www.cl.cam.ac.uk/research/security/ctsrd/images/20190926-arm-morello-soc-wip.png"><h2><a href="https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-morello.html">The Arm Morello Board</a></h2><p><code>cam.ac.uk</code> — On 18 October 2019, Arm announced Morello, an experimental CHERI-extended, multicore, superscalar ARMv8-A processor, System-on-Chip (SoC), and prototype board to be available from late 2021. Morello is a part of the UKRI £187M Digital Security by Design Challenge (DSbD) supported by the UK Industrial Strategy Challenge Fund, including a commitment of over £50M commitment by Arm. This web page provides more information on Morello, drawing from publicly available Arm content, as well as our own material on CHERI. You can learn more about CHERI by reading our technical report, An Introduction to CHERI. <strong><a href="https://news.ycombinator.com/item?id=23705346">MORELLO</a>,&nbsp;16</strong></p></section><section><img src="https://blog.appsignal.com/images/blog/2020-07/v8-node-facebook.jpg"><h2><a href="https://blog.appsignal.com/2020/07/01/a-deep-dive-into-v8.html">A Deep Dive into V8</a></h2><p><code>appsignal.com</code> — A true sorcerer combines ancient wisdom and new discoveries. We'll provide you with both. Sign up for our JavaScript Sorcery email series and receive deep insights about JavaScript, error tracking and other developments. <strong><a href="https://news.ycombinator.com/item?id=23702771">DIVE</a>,&nbsp;17</strong></p></section><section><img src="https://uploads-ssl.webflow.com/5ec0224560bd6a6ef89a51ae/5ef511e3e1e5cd56c1ea34a8_E4024D7C-D82D-4B56-8495-61494B7A78F8.jpeg"><h2><a href="https://www.blameless.com/blog/slo-adoption-twitter">SLO Adoption at Twitter</a></h2><p><code>blameless.com</code> — This is the second article of a two-part series. Click here for part 1 of the interview with Brian, Carrie, JP, and Zac to learn more about Twitter’s SRE journey. <strong><a href="https://news.ycombinator.com/item?id=23702876">SLO</a>,&nbsp;18</strong></p></section><section><img src="https://www.laphamsquarterly.org/sites/default/files/styles/thumbnail/public/images/roundtable/porcelainteaser.jpg?itok=MTU0jGGj"><h2><a href="https://www.laphamsquarterly.org/roundtable/real-life-rumpelstiltskin">An alchemist who failed to make gold but still made history in porcelain</a></h2><p><code>laphamsquarterly.org</code> — On an alchemist who failed to make gold but still made history in porcelain. <strong><a href="https://news.ycombinator.com/item?id=23698030">ALCHEMIST</a>,&nbsp;19</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23702120">Ask HN: Who wants to be hired? (July 2020)</a></h2><p><code>news.ycombinator.com</code> — Share your information if you are looking for work. Please use this format: <strong><a href="https://news.ycombinator.com/item?id=23702120">HIRED</a>,&nbsp;20</strong></p></section><section><img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png"><h2><a href="https://aws.amazon.com/app2container/">AWS App2Container</a></h2><p><code>amazon.com</code> — AWS App2Container (A2C) is a command-line tool for modernizing .NET and Java applications into containerized applications.&nbsp;A2C analyzes and builds an inventory of all applications running in virtual machines, on-premises or in the cloud. You simply select the application you want to containerize, and A2C packages the application artifact and identified dependencies into container images, configures the network ports, and generates the ECS task and Kubernetes pod definitions. A2C provisions, through CloudFormation, the cloud infrastructure and CI/CD pipelines required to deploy the containerized .NET or Java application into production. With A2C, you can easily modernize your existing applications and standardize the deployment and operations through containers.  <strong><a href="https://news.ycombinator.com/item?id=23704245">APP2CONTAINER</a>,&nbsp;21</strong></p></section><section><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png"><h2><a href="https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">Dynamic Linking</a></h2><p><code>stephenmarz.com</code> — Static vs dynamic linking usually has to do with our tolerance for the size of our final executable. A static executable contains all code necessary to run the executable, so the operating system loads the executable into memory, and it’s off to the races. However, if we keep duplicating code over and over again, such as printf, then it starts to use up more and more space. So, a dynamic executable means that we only store stubs in the executable. Whenever we want to access printf, it goes out to a dynamic linker and loads the code essentially on demand. So, we sacrifice a tiny bit of speed for a much smaller executable. <strong><a href="https://news.ycombinator.com/item?id=23704160">LINKING</a>,&nbsp;22</strong></p></section><section><img src="https://dpkqkssmbsv3o.cloudfront.net/social.png"><h2><a href="https://decentdrops.com/">Show HN: Browse recently expired, pronounceable domain names (Part II)</a></h2><p><code>decentdrops.com</code> — Our goal is to provide you with a goldmine. hide <strong><a href="https://news.ycombinator.com/item?id=23704983">BROWSE</a>,&nbsp;23</strong></p></section><section><img src="https://cdn.nybooks.com/wp-content/uploads/2020/06/richard-wright-1957.jpg"><h2><a href="https://www.nybooks.com/daily/2020/06/25/richard-wright-masaoka-shiki-and-the-haiku-of-confinement/">Richard Wright, Masaoka Shiki, and the Haiku of Confinement</a></h2><p><code>nybooks.com</code> — You can enter multiple addresses separated by commas to send the article to a group; to send to recipients individually, enter just one address at a time. <strong><a href="https://news.ycombinator.com/item?id=23697146">WRIGHT</a>,&nbsp;24</strong></p></section><section><img src="https://b.thumbs.redditmedia.com/jrbVr6SMEdS5qbvrYfDsMlxh9EkFj5dAlDd6VidQ8Ic.jpg"><h2><a href="https://old.reddit.com/r/assholedesign/comments/hj57fv/apple_forcing_app_developers_to_implement/">Apple forcing app developers to implement auto-billing after free trial</a></h2><p><code>reddit.com</code> — the front page of the internet. <strong><a href="https://news.ycombinator.com/item?id=23701292">FORCING</a>,&nbsp;25</strong></p></section><section><img src="https://exploringjs.com/impatient-js/img-homepage/cover-homepage.jpg"><h2><a href="https://exploringjs.com/impatient-js/index.html">JavaScript for Impatient Programmers</a></h2><p><code>exploringjs.com</code> — This book makes JavaScript less challenging to learn for newcomers, by offering a modern view that is as consistent as possible. <strong><a href="https://news.ycombinator.com/item?id=23689280">IMPATIENT</a>,&nbsp;26</strong></p></section><section><h2><a href="https://jvns.ca/blog/2020/06/28/entr/">Entr: Rerun your build when files change</a></h2><p><code>jvns.ca</code> — This is going to be a pretty quick post – I found out about entr relatively recently and I felt like WHY DID NOBODY TELL ME ABOUT THIS BEFORE?!?! So I’m telling you about it in case you’re in the same boat as I was. <strong><a href="https://news.ycombinator.com/item?id=23698305">ENTR</a>,&nbsp;27</strong></p></section><section><h2><a href="https://uk.reuters.com/article/uk-turkey-security-socialmedia/turkey-determined-to-control-social-media-platforms-erdogan-says-idUKKBN2425Y4">Turkey determined to control social media platforms, Erdogan says</a></h2><p><code>reuters.com</code> — ISTANBUL (Reuters) - Turkey will introduce regulations to control social media platforms or shut them down, President Tayyip Erdogan announced on Wednesday, pressing ahead with government plans after he said his family was insulted online.  <strong><a href="https://news.ycombinator.com/item?id=23700999">DETERMINED</a>,&nbsp;28</strong></p></section><section><img src="https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&amp;fit=1280%2C640&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2020%2F03%2FDuckduckgo.jpg&amp;signature=3feb4d25c7b59959c730ce3e6af88980"><h2><a href="https://thenextweb.com/in/2020/07/01/multiple-service-providers-are-blocking-duckduckgo-in-india/">Multiple service providers are blocking DuckDuckGo in India</a></h2><p><code>thenextweb.com</code> — Just a few days after India banned 59 Chinese apps, many users in the country are reporting that privacy-focused search engine DuckDuckGo is inaccessible to them. <strong><a href="https://news.ycombinator.com/item?id=23701953">DUCKDUCKGO</a>,&nbsp;29</strong></p></section><section><p><a href="https://angel.co/company/lazylantern/jobs"><strong>Lazy Lantern (YC S19) is hiring</strong> senior back-end and full-stack engineers</a> <code>angel.co</code></p></section><section><p><a href="https://jobs.lever.co/givecampus/874d7233-b7a3-488d-892e-13ef717ceab7"><strong>GiveCampus (YC S15) hiring</strong> Sr Engineers and Product passionate about education</a> <code>lever.co</code></p></section><section><p><a href="https://www.algolia.com/careers/?job=technical-support-engineer-remote-from-france-or-the-uk-remote"><strong>Algolia (YC W14) is hiring</strong> tech support engineers to help devs implement search</a> <code>algolia.com</code></p></section></div></div>]]>
            </description>
            <link>https://www.wolfgangfaust.com/project/paper-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23669650</guid>
            <pubDate>Sun, 28 Jun 2020 16:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laptop Buying Guide: Workstation Laptop versus Gaming Laptop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23669441">thread link</a>) | @sirkarthik
<br/>
June 28, 2020 | https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4156024826229998353" itemprop="description articleBody">
<h3>My Backdrop</h3><p>As geeky entrepreneur I dabble on many things tech and look for opportunities to see how tech can be leveraged to solve a business problem. I got really dirty learning and hacking Machine Learning problems and dabbled a bit on Deep Learning a couple of years back.&nbsp;</p><p>I always wanted to get back to learning more on the Deep Learning side of things when possible. "Deep Learning" is the key word.</p><p>I haven't played Games after my college days.</p><p>Since the time I started my consulting venture, I end-up working either full-stack or some part of it depending on my consulting gig that I end-up signing for.</p><p>So when I wanted to purchase a laptop, I ended up ordering a <b>Gaming Laptop</b> with Intel -7 processor and RTX 2070 GPU, based on advice of <a href="https://blog.codonomics.com/2020/06/A%20Full%20Hardware%20Guide%20to%20Deep%20Learning" target="_blank">Tim Dettmers</a>. I know very many companies that procure a Gaming Laptop for their ML/DL engineers. Also, you will see almost all ML/DL web-sites advising its readers to go for Gaming Laptops.&nbsp;</p><p>I'm not used to settling down easy and in my quest to understand the world of hardware to see what marries what and solves what kind problems, I stumbled upon <b>Workstation Laptops</b>, and was left wondering how this is both similar to and different from Gaming Laptops.&nbsp;</p><p>The section below summarizes my understanding of the key differences between the two kinds of beasts.</p><h3>Gaming Vs Workstation Laptops</h3><p>I'd drawing a quick comparison table with the metrics that should help you decide the right pick for you.</p><div><table bordercolor="#888"><tbody><tr><td>&nbsp;<b>Metric<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;</span></b></td><td><b>&nbsp;Gaming Laptop</b></td><td><b>Workstation Laptop&nbsp;</b></td><td><b>&nbsp;Comments</b></td></tr><tr><td>&nbsp;Cost</td><td>&nbsp;Cheaper<span>&nbsp;</span></td><td>&nbsp;Expensive</td><td>&nbsp;<span>&nbsp;What is your budget?</span><br></td></tr><tr><td>&nbsp;Built</td><td>&nbsp;Depends on brand and model</td><td>&nbsp;Relatively Sturdier. <br>&nbsp;Typically server/military grade with some certification like ISV to prove it.&nbsp;&nbsp;</td><td>&nbsp;One of the key reasons for price difference.&nbsp;</td></tr><tr><td>&nbsp;Portability</td><td>&nbsp;Relatively less portable because of its size, weight&nbsp;and/or fragility.</td><td>&nbsp;Better portability.&nbsp;</td><td>&nbsp;</td></tr><tr><td>&nbsp;Default Windows OS Type</td><td>&nbsp;Home edition<span>&nbsp;</span></td><td>&nbsp;Pro edition</td><td>&nbsp;You can always install your choice of OS later, though!</td></tr><tr><td>&nbsp;Looks</td><td>&nbsp;Usually more jazzy and less professional</td><td>&nbsp;Usually bland and professional</td><td>&nbsp;Looks do matter!</td></tr><tr><td>&nbsp;Longevity<span>&nbsp;</span></td><td>&nbsp;Comparatively lesser</td><td>&nbsp;Comparatively better</td><td>&nbsp;What is the ROI (bang for the bucks)?</td></tr><tr><td>&nbsp;Audio</td><td>&nbsp;Superior</td><td>&nbsp;Relatively inferior</td><td>&nbsp;</td></tr><tr><td>&nbsp;Display</td><td>&nbsp;Superior<br>&nbsp;The Refresh Rate is key differentiator for smooth AAA game play experience.</td><td>&nbsp;Inferior in terms of Refresh Rate.<br>&nbsp;Usually 60 FPS.</td><td>&nbsp;High refresh rate prevents screen tearing, stuttering, motion blur and ghosting.</td></tr><tr><td>&nbsp;Heat Dissipation</td><td>&nbsp;Better</td><td>&nbsp;Relatively poorer</td><td>&nbsp;</td></tr><tr><td>&nbsp;Control of hardwares</td><td>&nbsp;Depending on the brand and model, you can control/configure Fan speed, CPU under-volting, etc with the help of factory software that gets installed in your OS.</td><td>&nbsp;Absent!</td><td>&nbsp;</td></tr><tr><td>&nbsp;Nvidia GPUs</td><td>&nbsp;Typically comes with GTX or RTX GPUs.<br>&nbsp;(RTX is more performant than GTX.)</td><td>&nbsp; Typically comes with Quadro P series, T series and RTX series GPU processors.<br>&nbsp;(P &lt; T &lt; RTX in terms of performance)</td><td><ul><li>Nvidia Quadro P1000 is a mobile entry-level workstation graphics card for notebooks.&nbsp;</li><li>Nvidia Quadro T1000 for laptops is a professional mobile graphics card that is based on the Turing architecture (TU117 chip).</li><li>Nvidia Quadro RTX 5000 for laptops is a professional high-end graphics card for big and powerful laptops and mobile workstations.&nbsp;</li><li>ProTips: Buy atleast Quadro RTX 3000. Don't go for P/T series, if ML/DL is your primary purpose.</li><li>NVIDIA GeForce and AMD Radeon are graphics cards meant for gaming.</li></ul></td></tr><tr><td>&nbsp;Intel CPUs</td><td>&nbsp;Typically comes with i7 processors for AAA titled gamers play.</td><td>&nbsp;Typically comes with Intel XEON processors as base model these days</td><td>&nbsp;</td></tr><tr><td>&nbsp;ECC Memory</td><td>&nbsp;Not required and so is absent.</td><td>&nbsp;Required and thus present.</td><td><ul><li>Error-correcting code memory (ECC memory) is a type of computer data storage that can detect and correct the most-common kinds of internal data corruption. ECC memory is used in most computers where data corruption cannot be tolerated under any circumstances, such as for scientific or financial computing.</li><li>ProTip: For most gamers and general home office users, ECC RAM will not be worth the additional expense.&nbsp;</li></ul></td></tr></tbody></table><br></div><p>A Gaming Laptop can match your Workstation in performance with right specs. You Workstation Laptop cannot match the gaming and multi-media experience delivered by its Gaming Laptop counterpart. Also you pay more for the workstation models for its improved life-span and sturdier built that relieves you from handling with delicate care every single time.&nbsp;</p><p>If you are someone like me, you should go with Workstation laptop but can opt for Gaming laptop provided you understand the Cons of it.</p><p><b>Bonus :</b> The other things that you shouldn't miss irrespective of the laptop kind you buy, is the maximum years of warranty (preferably onsite) that the company provides and also include ADP cover for maximum number of years. This is an insurance that is often overlooked by buyers only to regret later.&nbsp;</p><p>Hope it serves you well to make an informed decision in your buying the right laptop.&nbsp;</p><h4>References</h4>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23669441</guid>
            <pubDate>Sun, 28 Jun 2020 15:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up function calls with lru_cache in Python]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23668914">thread link</a>) | @Immortal333
<br/>
June 28, 2020 | https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html | <a href="https://web.archive.org/web/*/https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
          
        
        <p>One line summary: Use <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">lru_cache decorator</a></p>

<h3 id="caching">Caching</h3>

<p>If we’re calling expensive functions in the program very frequently, It’s best to save the result of a function call and use it for future purposes rather than calling function every time. This will generally speed up the execution of the program.</p>
<blockquote>
  <p>The expensiveness of function can be in terms of computational (CPU usage) or latency (disk read, fetching a resource from the network).</p>
</blockquote>

<p>The saving result of function calls is generally referred to as caching. The naive way to do caching is to store every function calls. But, this doesn’t scale very well with the number of parameters of function and range of each parameter.</p>

<p>So, we need a smart way to do caching with a fixed amount of memory. And, there are plenty of <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies">caching strategies available</a> depending upon what type of information is available to us.</p>

<blockquote>
  <p>Caching is heavily used in plenty of areas from low-level (hardware/CPU) to high level (network/CDNs).</p>
</blockquote>

<p>In most of the languages, We will choose caching strategies of our choice and implement them using a few data structures (hashmap, priority queue). Depending upon the language, It might take as little as few minutes to few hours to implement the generic solution of our need.</p>

<p>But, Python’s standard library <a href="https://docs.python.org/3/library/functools.html">functools</a> already comes with one strategy of caching called <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">LRU(Least Recently Used)</a>. Thanks to <a href="https://wiki.python.org/moin/PythonDecorators">decorators</a> in python, It only takes one line to integrate into the existing codebase</p>

<h3 id="basic-recursive-implementation-of-fibonacci-numbers">Basic Recursive Implementation of <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci numbers</a></h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output : 
# Time taken: 0.3209421634674072
</span></code></pre></div></div>

<h3 id="speeding-up-recursive-implementation-with-lru">Speeding Up Recursive Implementation with LRU</h3>
<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span># saving all function calls
</span><span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>31</span><span>)</span>
<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
<span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>


<span># Output :
# Time taken: 1.7881393432617188e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>In this example, we have saved all function calls. But, We know that Fibonacci can be implemented using <a href="https://en.wikipedia.org/wiki/Dynamic_programming">DP</a>.</p>

<h3 id="iterative-implementation-of-fibonacci">Iterative implementation of Fibonacci</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib_iterative</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
  <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>n</span><span>-</span><span>1</span><span>):</span>
    <span>t</span> <span>=</span> <span>f</span> <span>+</span> <span>s</span>
    <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>s</span><span>,</span> <span>t</span>
  <span>return</span> <span>t</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib_iterative</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output:
# Time taken: 5.0067901611328125e-06
</span></code></pre></div></div>

<h3 id="different-cache-size">Different Cache size</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span>def</span> <span>lru_size</span><span>(</span><span>max_lru</span><span>):</span>
    <span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>max_lru</span><span>,</span> <span>typed</span><span>=</span><span>False</span><span>)</span>
    <span>def</span> <span>fib_lru</span><span>(</span><span>n</span><span>):</span>
        <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
            <span>return</span> <span>n</span>
        <span>return</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
    <span>return</span> <span>fib_lru</span>

<span>for</span> <span>i</span> <span>in</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>5</span><span>,</span> <span>10</span><span>,</span> <span>31</span><span>]:</span>
    <span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
    <span>fib</span> <span>=</span> <span>lru_size</span><span>(</span><span>i</span><span>)</span>
    <span>fib</span><span>(</span><span>10</span><span>)</span>
    <span>print</span> <span>(</span><span>f"LRU size: </span><span>{</span><span>i</span><span>}</span><span> Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
    <span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>

<span># Output:
# LRU size: 1 Time taken: 0.6930997371673584
# CacheInfo(hits=0, misses=2692537, maxsize=1, currsize=1)
# LRU size: 2 Time taken: 0.012731075286865234
# CacheInfo(hits=8656, misses=41641, maxsize=2, currsize=2)
# LRU size: 5 Time taken: 5.817413330078125e-05
# CacheInfo(hits=28, misses=31, maxsize=5, currsize=5)
# LRU size: 10 Time taken: 3.9577484130859375e-05
# CacheInfo(hits=28, misses=31, maxsize=10, currsize=10)
# LRU size: 31 Time taken: 3.504753112792969e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>As, <strong>we can see the optimal cache size of fib function is 5</strong>. Increasing cache size will not result in much gain in terms of speedup.</p>

<h3 id="important-note">Important Note</h3>

<p>I strictly suggest to use lru decorator in only deterministic functions.</p>

<h4 id="deterministic-functions">Deterministic Functions</h4>
<blockquote>
  <p>In computer science, a deterministic algorithm is an algorithm which, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states. Deterministic algorithms are by far the most studied and familiar kind of algorithm, as well as one of the most practical, since they can be run on real machines efficiently.</p>

  <p>– Wikipedia</p>
</blockquote>

<p>Because,</p>

<blockquote>
  <p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>

  <p>– Phil Karlton</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668914</guid>
            <pubDate>Sun, 28 Jun 2020 14:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Promnesia – an attempt to fix broken web history]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 55 (<a href="https://news.ycombinator.com/item?id=23668507">thread link</a>) | @karlicoss
<br/>
June 28, 2020 | https://beepb00p.xyz/promnesia.html | <a href="https://web.archive.org/web/*/https://beepb00p.xyz/promnesia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
    
    <p>A journey in fixing browser history
    </p></section>
    <!-- are sections appropriate for that? -->

    <section>
    <p>
Promnesia is a browser extension (Chrome/Firefox/Firefox mobile) that serves as a web surfing copilot
by enhancing your browsing history, improving your web exploration experience, and integrating with your knowledge base.
</p>
<p>
<a href="https://github.com/karlicoss/promnesia#readme">The repository</a> contains more information about the project and the setup guide, this post is more about the motivation and the story of what led me to work on it.
</p>
<p>
Also, you can quickly skim through the <a href="https://github.com/karlicoss/promnesia#demos">demos</a> first before reading, if you prefer!
</p>

<div>
<h2 id="singularity_when"><a href="#singularity_when">¶</a><span>1</span> I want my singularity!</h2>
<div id="text-singularity_when">
<p>
I was raised on science fiction and grew up dreaming about technology drastically changing our lives.
Artificial intelligence, augmenting the brain with a math co-processor, head-up displays, neural interfaces, having perfect reaction and memory – many of you are on the same page and know the drill.
</p>
<p>
Years passed, I became a software engineer, and realized just how far we are from all these fancy technologies I wanted.
So my aspirations have become more modest, and I've chosen a more realistic and plausible target:
using my digital trace (such as browser history, webpage annotations and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>) to make up for my limited memory.
</p>
<p>
I'm exploring lots of information on the Internet, and it feels wasteful to use my <a href="https://beepb00p.xyz/tags.html#meatsack">meat resources</a> to keep track of it.
Meanwhile, web browsers keep a record automatically, without any manual and conscious effort.
Surely we can benefit from the immense computing power and memory capabilities of computers?
</p>
<p>
So I figured that I wanted:
</p>
</div>
</div>
<div>
<h2 id="what_i_want"><a href="#what_i_want">¶</a><span>2</span> Ok, maybe a web assistant at least?</h2>
<div id="text-what_i_want">
<p>
A web surfing companion. A copilot.
A <a href="https://en.wikipedia.org/wiki/Memex">Memex</a>.
A <a href="http://alumni.media.mit.edu/~rhodes/Papers/remembrance.html">Remembrance Agent</a>?
</p>
<p>
Call it whatever you like, I <i>wish</i> it were a concept with a widely accepted name. Something that will sit in my browser and:
</p>
<ul>
<li><p>
aid me with <b>information processing</b>
</p>
<p>
Keep track of what I've read, when, on which device, and for how long.
</p></li>
<li><p>
show me my <b>annotations and highlights</b>, within the original page
</p>
<p>
I don't want to keep wondering whether I have my notes and thoughts stashed in some app, I want the computer to let me know instead.
</p></li>
<li><p>
unify my <b>scattered and siloed bookmarks</b>
</p>
<p>
Firefox bookmarks; Reddit/Hackernews saves; "Watch later" on Youtube, saved links in my instant messenger.
</p>
<p>
These are the same damn thing, yet there is no way to oversee and process them through a single interface.
</p>
<p>
<a href="https://jborichevskiy.com/posts/digital-tools/#queue-management-for-inbound-digital-content">"Queue management for inbound digital content"</a>:
a post expanding further on this idea.
</p></li>
<li><p>
connect with my online presence: chats and social networks
</p>
<p>
If I tweeted about a page, surely this should be somehow recorded in the browsing history?
</p>
<p>
In fact, the page that I bothered to tweet about is <b>much</b> more important than a page I merely visited in the browser.
</p></li>
<li><p>
help me explore new information and <b>prioritize</b> it
</p>
<p>
There is so much awesome stuff on the Internet! The biggest problem I have is picking the next cool link to dig into.
</p>
<p>
Imagine if in one click, I could see which of my friends, or the people I follow have read a certain link.
What did they think? Have they posted about it, annotated, or something else? Do they follow the author, perhaps I should too?
</p></li>
<li><p>
bridge the gap between the browser and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>
</p>
<p>
Whatever product I choose for managing my notes: Google Keep, Evernote, Roam Research, or even org-mode files on my disk,
they always end up <b>isolated and disconnected</b> from my web browsing.
</p></li>
</ul>
<p>
I searched for a system like this <a href="https://twitter.com/karlicoss/status/767412935316611072">for</a> several <a href="https://twitter.com/karlicoss/status/896313846159298560">years</a>.
</p>
<p>
After enough failed attempts at finding an <a href="#prior_art">existing solution</a>, I figured it was going to be yet another thing I'd have to implement myself.
</p>
<p>
The journey of building it took longer than I expected, led me through a rabbit hole of <a href="https://beepb00p.xyz/tags.html#dataliberation">data liberation</a>, lots of <a href="https://en.wiktionary.org/wiki/yak_shaving">yak shaving</a>,
and made me realize: <b>browser history is very, very broken</b>.
</p>
<p>
Note: the next two sections are (somewhat technical) rants. If you prefer a more positive/less boring agenda, feel free to skip them straight to <a href="#prior_art">"Existing solutions"</a>
, and you can return back later if you feel like it.
</p>
</div>
</div>
<div>
<h2 id="history_broken"><a href="#history_broken">¶</a><span>3</span> Browser history is broken</h2>
<div id="text-history_broken">
<p>
To a large extent, URLs express <b>relationships and hierarchy</b> between the bits of information. For example:  <code>blog &lt;-&gt; post &lt;-&gt; comment</code>, <code>person &lt;-&gt; tweet</code>, <code>playlist &lt;-&gt; video</code>.
</p>
<p>
With this information you should be easily able to find everything relevant to the current page and trace your jumps through past websites.
Merely by looking at URLs, without "AI" or some dubious machine learning algorithm!
Seems like a low hanging fruit to harvest, right?
</p>
<p>
Web browser history is a rich source of potentially useful information.
Just think about it: it's zero effort <a href="https://beepb00p.xyz/tags.html#lifelogging">lifelogging</a>.
It contains exact timestamps and links which <i>basically</i> address information.
</p>
<p>
Now think about the experience you actually have. What was the last time you used the browser history in any nontrivial way, for something other than reopening an accidentally closed tab?
</p>
<p>
Besides:
</p>
</div>
<div>
<h3 id="not_just_browser"><a href="#not_just_browser">¶</a>it's not just about web browsers</h3>
<div id="text-not_just_browser">
<div><p><span>
When you're using a native phone app (say, for Reddit or Twitter), your history either isn't logged anywhere or if it is, it's only stored locally on your phone.

</span></p></div>
<div><p><span>
On Android, it's likely to be in an Sqlite database in <code>/data/data/app.name</code>.
This directory is not accessible to normal users <b>unless your phone is rooted</b>.
Just think about how ridiculous this is. It's <b>your own data</b>, yet your OS babysits you, preventing access to it.

And yes, I know sandboxing and security are important, but locking my data inside the app is hardly an acceptable tradeoff.
</span></p></div>
<p>
As a specific example, the <a href="https://github.com/ccrama/Slide">Reddit Slide</a> app keeps your view history in <code>/data/data/me.ccrama.redditslide/SEEN</code>.
Okay, say you root your phone and access the database. Turns out the the app isn't persisting the data forever, it's merely keeping a few weeks' cache.
And I can hardly blame the developer for this: because of the data model, no one expects regular users to access this database.
</p>
<p>
So if you want your complete history, you have to backup this database regularly, keep the snapshots and <a href="https://beepb00p.xyz/exports.html#synthetic">somehow</a>
reconstruct it.
</p>
<p>
You may dismiss this as nitpicking and obsession over every last bit of my data.
But when <b>all</b> of your phone apps are doing this you're missing out on quite a lot of useful information.
</p>
</div>
</div>
<div>
<h3 id="siloed"><a href="#siloed">¶</a>it's scattered and siloed</h3>
<div id="text-siloed">
<p>
Building on the previous point:
</p>
<ul>
<li>for the most part, you can't access history in your phone apps</li>
<li>lots of data which <i>ought</i> to be counted as web history is scattered across silos

<ul>
<li><div><p><span>in the cloud: behind APIs (best case), GDPR and manual exports (worst case)

It is never easy to get hands on, <i>even</i> if you're an experienced software engineer.</span></p></div></li>
<li><p>
on the filesystem, for example in markdown/org-mode files
</p>
<p>
A slightly better scenario, but as far as the web browser is concerned, it doesn't make any difference.
</p></li>
</ul></li>
</ul>
<p>
Even <i>regular</i> browser history is not easy to get:
</p>
<ul>
<li>Firefox <a href="https://support.mozilla.org/en-US/questions/1080942">used to</a> silently 'expire' your browser history</li>
<li><p>
Chrome deletes history older than <a href="https://superuser.com/a/364475/300795">90 days</a>
</p>
<p>
The only way to access older history I'm aware of is <a href="https://myactivity.google.com/">Google Activity</a> and Takeout.
</p></li>
<li>Google Takeout <a href="https://beepb00p.xyz/takeout-data-gone.html">quietly recycles your history</a></li>
<li><p>
Migration is limited to the most popular browsers
</p>
<p>
The retention limits the migration as well.
E.g. if you migrate from Chrome to Firefox, history older than 90 days is locked and siloed in your Google Account.
</p></li>
<li><p>
You're going to have a hard time if you're not using Google/Mozilla sync
</p>
<p>
Your history will be scattered across devices and lost on OS reinstalls.
</p>
<p>
There are ways of self-hosting Firefox sync, and (<a href="https://superuser.com/questions/614744/how-to-set-up-a-own-chrome-sync-server">allegedly</a>) even Chrome sync,
but as you can imagine, is quite tedious.
</p></li>
</ul>
</div>
</div>
<div>
<h3 id="significance"><a href="#significance">¶</a>it's got varying significance</h3>
<div id="text-significance">
<p>
Not all links in your history are equally important:
</p>
<ul>
<li>some are clicked on by accident</li>
<li>some you've just skimmed</li>
<li>some are on your reading list</li>
<li>some you've been reading for hours and are full of your highlights and annotations</li>
<li>some you reference in your knowledge base/personal wiki</li>
<li>some of them you've shared with others on social media</li>
</ul>
<p>
The current browser history experience makes no distinction between these scenarios.
</p>
</div>
</div>
</div>
<div>
<h2 id="urls_broken"><a href="#urls_broken">¶</a><span>4</span> URLs are broken</h2>
<div id="text-urls_broken">
<p>
This topic probably deserves a separate post, but I'll keep it section-sized for now.
</p>
<p>
URLs might seem great because they mostly address content and are semi-descriptive: people <i>try</i> to keep URLs somewhat reasonable, tidy and working.
But in the real world:
</p>
<ul>
<li><p>
links <b>rot</b>
</p>
<p>
Many URLs are <a href="https://www.gwern.net/Archiving-URLs#link-rot"><b>literally</b> broken</a>.
We're lucky to have <a href="https://web.archive.org/">archive.org</a>, so you can at least access dead pages.
</p>
<p>
But there is no way to migrate your browser history, e.g. point old URLs to their respective archive.org entries or a new domain.
Similarly if you had the page annotated, your annotations become orphans without an easy way to relink them.
</p></li>
<li><p>
links are <b>obfuscated</b> by shortening and redirects
</p>
<div><p><span>
What happens to all the <code>t.co</code> links when Twitter as a service dies?

</span></p></div></li>
<li><p>
links are <b>obscured</b>
</p>
<p>
There is no easy way to know what's behind <code>https://www.instapaper.com/read/1265139707</code> without querying the Instapaper API.
</p>
<p>
Relations between data are often obscured as well. For example:
</p>
<ul>
<li><code>https://news.ycombinator.com/item?id=22918980</code> is a submission link</li>
<li><code>https://news.ycombinator.com/item?id=22919718</code> is a comment to that submission</li>
</ul>
<p>
These links are clearly related, but there is no way to tell it just from <samp>id</samp>.
</p>
<p>
Compare this to Reddit links:
</p>
<ul>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is</code> is a post link</li>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is/fo9qnen</code> is a comment to that post</li>
</ul>
<p>
The ids are obscure, but at least we can clearly see the <code>post &lt;-&gt; comment</code> relation merely by looking at the URLs.
Alas, browsers are just ignoring this useful information.
</p></li>
<li><p>
links are <b>unstandardized</b>
</p>
<p>
For example, <a href="https://en.wikipedia.org/wiki/Query_string">queries</a>
</p>
<ul>
<li>typically don't point to anything persistent and are used for querying (duh)</li>
<li>but other times they are used to address information: <code>http://wiki.c2.com/?LispLanguage</code> or <code>https://www.scottaaronson.com/blog/?p=2694</code></li>
<li>and in many cases are utter garbage used for <a href="https://en.wikipedia.org/wiki/Query_string#Tracking">tracking</a></li>
</ul>
<p>
The worst part is that these use cases overlap. For example, take a look at <code>youtube.com/watch?v=wHrCkyoe72U&amp;feature=share&amp;t…</code></p></li></ul></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beepb00p.xyz/promnesia.html">https://beepb00p.xyz/promnesia.html</a></em></p>]]>
            </description>
            <link>https://beepb00p.xyz/promnesia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668507</guid>
            <pubDate>Sun, 28 Jun 2020 13:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Producing a deepfake – a faceswap workflow on AWS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23668404">thread link</a>) | @botoxparty
<br/>
June 28, 2020 | https://adamham.dev/posts/producing-a-deepfake-on-aws/ | <a href="https://web.archive.org/web/*/https://adamham.dev/posts/producing-a-deepfake-on-aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For a music video project I worked on we had to produce a deep fake. I had previously made some attempts at deepfakes using a local machine with an NVIDIA GeForce GTX 1080. Now I'll be using a MacBook Pro and an AWS account with a generous credit (the running cost of the server only ended up being about $30 per 24 hours).</p>
<p>If you want to understand more about how machine learning works I would recommend <a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo">this video</a>.</p>
<h2>Setting up</h2>
<p>The first thing was to choose a library, the two main players in the open-source deepfake space are <a href="https://github.com/deepfakes/faceswap">Faceswap</a> and <a href="https://github.com/iperov/DeepFaceLab">DeepFaceLab</a>. I chose to go with Faceswap because the GUI and the CLI seemed more user-friendly to me, it supports multiple GPUs, has a solid workflow and great community and support.</p>
<p>I had originally planned to do the inital tests on my local machine but my MacBook Pro has an ATI graphics card 🥺. So straight to the cloud I go... I used a <a href="https://aws.amazon.com/ec2/instance-types/g4/">g4dn.xlarge EC2 instance</a> and loaded it with the <a href="https://aws.amazon.com/machine-learning/amis/">AWS Deep Learning AMI</a>. After wrestling with the <a href="https://github.com/deepfakes/faceswap/blob/master/INSTALL.md">installation of faceswap</a> (had some dependancy issues that may have been related to using the deep learning AMI) I managed to get it up and running on the remote instance.</p>
<h3>Preliminary tests</h3>
<p>To start we did a test run first to see what kind of results we could get using mostly default settings and with minimal intervention, just to get an idea of what was really possible with our material. For this I used the same footage for Face A from the target video that I wanted to convert, and for Face B I recorded 60 seconds of the subject performing basic facial movements from different angles.</p>
<p>From the preliminary results I could identify what the parameters that I was working within were. I noticed that a lot of my faces are a profile view, deepfakes work much better with a frontal view. Also my source material is a very low resolution (480p YouTube rip of an 80s video). This makes faces harder to detect, particularly smaller faces.</p>
<p>I would highly suggest doing a few tests before fully training your model. It'll also help you to tell which angles and expressions are lacking from your source footage.</p>
<h3>Project structure</h3>
<p>My initial tests also encouraged me to define a folder structure, I found this to be an efficient structure for deepfake projects</p>

        <deckgo-highlight-code>
          <code slot="code">/my-project
/my-project/src
/my-project/src/faceA/              // - Source footage/images for Face A
/my-project/src/faceB/              // - "                       " Face B
/my-project/src/target/             // - Footage to convert
/my-project/extract/faceA           // - Extracted faces from Face A
/my-project/extract/faceB           // - "                  " Face B
/my-project/model/                  // - Trained model
/my-project/output/                 // - Converted media (final exports)</code>
        </deckgo-highlight-code>
      
<h2>1. Extract</h2>
<h3>Face A - 6586 faces extracted</h3>
<p>I used 3 video clips of Robin Gibb that I could find from that era and cut out the footage that was worth extracting.</p>
<p><a href="https://www.youtube.com/watch?v=A-U058BIAGo">https://www.youtube.com/watch?v=A-U058BIAGo</a> <strong>(This is also the target video)</strong></p>
<p><a href="https://www.youtube.com/watch?v=oMvRLLPd8Ak">https://www.youtube.com/watch?v=oMvRLLPd8Ak</a></p>
<p><a href="https://www.youtube.com/watch?v=W_Nykcs7Zhg">https://www.youtube.com/watch?v=W_Nykcs7Zhg</a></p>
<h3>Face B - 7382 faces extracted</h3>
<p>I recorded 5 minutes of footage of the subject replicating the facial movements from the target source.</p>
<p>To prepare the extracted faces for training they need to be cleaned up. The better your source material is the better your result will be. This part of the process took about 10 hours.</p>
<ul>
<li>Remove any extracted faces that are of poor quality</li>
<li>Remove any bad detected faces</li>
<li>Regenerate alignments file to remove the deleted faces</li>
<li>Manually go through each face and clean up the alignment</li>
<li>Generate new masks</li>
</ul>
<p>After extracting the faces to use for training I cleaned and sorted the faces to remove any poor quality faces or things that were detected by error. Faceswap actually has a tool to allow you to sort the extracted faces by relevance to help you filter them out. After deleting the bad faces you'll also need to remove them from your alignments file using the alignments tool.</p>
<h2>2. Train</h2>
<p>There are a few different types of models you can train it all depends on what material you have and the results you want to achieve. I had time and computing power on my side so I decided to launch 3 instances and train variations of models to 20,000 iterations and then select the best one from there. I chose to go with Dfaker using a VCC-Clear mask.</p>
<p>Note: I made an error and accidentally deleted the full timelapse permanently but I have a few captures here for demo purposes. The final model was much more defined than shown in this timelapse.</p>
<p>My final model was trained for 75,000 iterations. I started it again and ran it for another 10,000 where I could see that the loss level was not improving, therefore the model was no longer learning and I could conclude that my model was trained.</p>
<p><img src="https://adamham.dev/posts/producing-a-deepfake-on-aws/training.gif" alt="Timelapse of model being trained in faceswap"></p>
<h2>3. Convert</h2>
<p>To prepare the target footage to be converted we need to repeat step 1 (extract) again being as meticulous as possible with the alignments. I spent about 4 hours on ~4,100 frames to achieve my result.</p>
<p>I definitely ran into difficulties with the face detection because of the low resolution of my source footage.</p>
<h2>Result</h2>
<h3>Converted Video</h3>
<p> <iframe src="https://www.youtube.com/embed/Sqc8EvnyyBM?rel=0&amp;showinfo=0" allowfullscreen=""></iframe>  </p>
<h3>Original Video</h3>
<p> <iframe src="https://www.youtube.com/embed/A-U058BIAGo?rel=0&amp;showinfo=0" allowfullscreen=""></iframe>  </p>
<h2>Final thoughts</h2>
<p>The abilities of the technology is really hyped up in the media. To achieve an undetectable result you really do need source footage that fits into the parameters of what a deepfake can work with.</p>
<p>For this project the aim wasn't to have a perfectly undetectable deepfake, the limitations weren't a problem but infact contributed to the concept. The song is a cover and seeing artifacts from the deepfake reinforces this idea.</p>
<p>The cost of processing the deepfake on AWS comes at about $30 per day. If you were doing a couple of renders a year then it's an amazing option rather than using your own hardware. However, things like manual alignments are really tricky using a remote machine so ideally you would want to have a CUDA capable graphics card in your local. A dedicated graphics machine with comparable specs would start at about $1400 (about 46 days of AWS EC2 usage) plus electricity bills.</p></div></div>]]>
            </description>
            <link>https://adamham.dev/posts/producing-a-deepfake-on-aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668404</guid>
            <pubDate>Sun, 28 Jun 2020 12:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Controversies and Challenges in fMRI (2018)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23668279">thread link</a>) | @saadalem
<br/>
June 28, 2020 | http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/ | <a href="https://web.archive.org/web/*/http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-294">
	<!-- .entry-header -->

	
	
	<div>
		<h2><em><strong>•Neurovascular Coupling</strong></em><em><strong>•Draining Veins</strong></em><em><strong>•Linearity</strong></em><em><strong>•Pre-undershoot</strong></em><em><strong>•Post-undershoot</strong></em><em><strong>•Long duration</strong></em><em><strong>•Mental Chronometry</strong></em><em><strong>•Negative Signal Changes</strong></em><em><strong>•Resting state source</strong></em><em><strong>•Dead fish activation</strong></em><em><strong>•Voodoo correlations</strong></em><em><strong>•Global signal regression</strong></em><em><strong>•Motion artifacts</strong></em><em><strong>•The decoding signal</strong></em><em><strong>•non-neuronal BOLD</strong></em><em><strong>•relationship to other measures</strong></em><em><strong>•contrast: spin-echo vs gradient-echo</strong></em><em><strong>•contrast: SEEP contrast</strong></em><em><strong>•contrast: diffusion changes</strong></em><em><strong>•contrast: neuronal currents</strong></em><em><strong>•contrast: NMR phase imaging</strong></em><em><strong>•lie detection</strong></em><em><strong>•correlation ≠ connection</strong></em><em><strong>•clustering conundrum</strong></em><em><strong>•reproducibility</strong></em><em><strong>•dynamic connectivity changes</strong></em></h2>
<hr>
<h4><em><strong>This will be a chapter in my upcoming book “Functional MRI” </strong><strong>in the MIT Press Essential Knowledge Series&nbsp;</strong></em></h4>
<hr>
<p>Functional MRI is unique in that, in spite of being almost 30 years old as a method, it continues to progress in terms of sophistication of acquisition, hardware, processing, in our understanding of the signal itself. There has been no plateau in any of these areas. In fact, by looking at the literature, one gets the impression that this advancement is accelerating. Every new advance opens the potential range where it might have an impact, allowing new questions about the brain to be addressed.</p>
<p>In spite of its success – perhaps as a result of its success – it has had its share of controversies coincident with methods advancements, new observations, and novel applications. Some controversies have been more contentious than others. Over the years, I’ve been following these controversies and have at times performed research to resolve them or at least better understand them. A good controversy can help to move the field forward as it can focus and motivate groups of people to work on the issue itself, shedding a broader light on the field as these are overcome.</p>
<p>While a few of the controversies or issues of contention have been fully resolved, most remain to some degree unresolved. Understanding fMRI through its controversies allows a deeper appreciation for how the field advances as a whole – and how science really works – the false starts, the corrections, and the various claims made by those with potentially useful pulse sequences, processing methods, or applications. Below is the list of twenty-six major controversies in fMRI – in approximately chronological order.</p>
<h2>#1: The Neurovascular coupling debate.</h2>
<p>Since the late 1800’s, the general consensus, hypothesized by Roy and Sherrington in 1890 (1), was that activation-induced cerebral flow changes were driven by local changes in metabolic demand. In 1986, a publication by Fox et al. (2)challenged that view, demonstrating that with activation, localized blood flow seemingly increased beyond oxidative metabolic demand, suggesting an “uncoupling” of the hemodynamic response from metabolic demand during activation. Many, including Louis Sokolof, a well-established neurophysiologist at the National Institutes of Health, strongly debated the results. Fox nicely describes this period in history from his perspective in “The coupling controversy” (3).</p>
<p>I remember well, in the early days of fMRI, Dr. Sokolof standing up from the audience to debate Fox on several circumstances, arguing that the flow response should match the metabolic need and there should be no change in oxygenation. He argued that what we are seeing in fMRI is something other than an oxygenation change.</p>
<p>In the pre-fMRI days, I recall not knowing what direction the signal should go – as when I first laid eyes on the impactful video presented by Tom Brady during his plenary lecture on the future of MRI at the Society for Magnetic Resonance (SMR) Meeting in August of 1991, it was not clear from these time series movies of subtracted images the direction he performed the subtraction operation. Was it task minus rest or rest minus task? Did the signal go up or down with activation? I also remember very well, analyzing my first fMRI experiments, expecting to see a decrease in BOLD signal – as Ogawa, in an earlier paper(4), hypothesized that metabolic rate increases would lead to a decrease blood oxygenation thus a darkening of the BOLD signal during brain activation. Instead, all I saw were signal increases. It was Fox’s work that helped me to understand why the BOLD signal should <em>increase</em>with activation. Flow goes up and oxygen delivery exceeds metabolic need, leading to an increase in blood oxygenation.</p>
<p>While models of neurovascular coupling have improved, we still do not understand the precise need for flow increases. First, we had the “watering the whole garden to feed one thirsty flower” hypothesis which suggested that flow increases matched metabolic need for one area but since vascular control was coarse, the abundant oxygenation was delivered to a wider area than was needed, causing the increase in oxygenation. We also had the “diffusion limited” model, where it was hypothesized that in order to deliver enough oxygen to the furthest neurons from the oxygen supplying vessels, an overabundance of oxygen was needed at the vessel itself since the decrease of oxygen as it diffused from the vessel to the furthest cell was described as an exponential. &nbsp;This theory has fallen a bit from favor as the increases in CMRO<sub>2</sub>or the degree to which the diffusion of oxygen to tissue from blood is limited tend to be higher than physiologic measures. The alternative to the metabolic need hypothesis involves neurogenic “feed-forward” hypotheses – which still doesn’t get at the “why” of the flow response.</p>
<p>Currently, this is where the field stands. We know that the flow response is robust and consistent. We know that in active areas, oxygenation in healthy brains always increases, however we just don’t understand specifically why it’s necessary. Is it a neurogenic, metabolic, or some other mechanism to satisfy some evolutionary critical need that extends beyond simple need for more oxygen? We are still figuring that out. Nevertheless, it can be said that whatever the reason for this increase in flow, it is fundamentally important, as the BOLD response is stunningly consistent.</p>
<h2>#2: The Draining Vein Effect</h2>
<p>The question: “what about the draining veins?” I think was first posited at an early fMRI conference by Kamil Ugurbil of the University of Minnesota. Here and for the next several years he alerted the community to the observation that, especially at low field, draining veins are a problem as they smear and distort the fMRI signal change such that it’s hard to know specifically where the underlying neuronal activation is with a high degree of certainty. In the “20 years of fMRI: the science and the stories” special issue of NeuroImage, Ravi Menon writes a thorough narrative of the “Great brain vs vein” debate (5). &nbsp;When the first fMRI papers were published, only one, by Ogawa et al. (6), was at high field – 4 Tesla – and relatively high resolution. In Ogawa’s paper, it was shown that there was a differentiation between veins (very hot spots) and capillaries (more diffuse weaker activation in grey matter). Ravi followed this up with another paper (7)using multi-echo imaging, to show that blood in veins had an intrinsically shorter T2* decay than gray matter at 4T and appeared as dark dots in T2* weighted structural images yet appeared as bright functional hot spots in the 4T functional images. Because of the low SNR and CNR at 1.5T, allowing only the strongest BOLD effects to be seen, and because models suggested that at low field strengths, large vessels contributed the most to the signal, the field worried that all fMRI was looking at was veins – at least at 1.5T.</p>
<p>The problem of large vein effects is prevalent using standard gradient-echo EPI – even at high fields. Simply put, the BOLD signal is directly proportional to the venous blood volume contribution in each voxel. If the venous blood volume is high – as with the case of a vein filling a voxel – then the potential for high BOLD changes is high if there is a blood oxygenation change in the area. At high field, indeed, there is not much intravascular signal left in T2* weighted Gradient-echo sequences, however, the extravascular effect of large vessels still exists.&nbsp; Spin-echo sequences (sensitive to small compartments) still are sensitive to the susceptibility effects around intravascular red blood cells within large vessels – even at 7T where intravascular contribution is reduced. Even with some vein sensitivity, promising high resolution orientation column results have been produced at 7T using gradient-echo and spin-echo sequences (8). The use of arterial spin labeling has potential as a method insensitive to large veins, although the temporal efficiency, intrinsic sensitivity, and brain coverage limitations blunt its utility. Vascular Space Occupancy (VASO), a method sensitive to blood volume changes, has been shown to be exquisitely sensitive to blood volume changes in small vessels and capillaries. Preliminary results have shown clear layer dependent activation using VASO where other approaches have provided less clear delineation(9).</p>
<p>Methods have arisen to identify and mask large vein effects – including thresholding based on percent signal change (large veins tend to fill voxels and thus exhibit a larger fractional signal change), as well as temporal fluctuations (large veins are pulsatile thus exhibit more magnitude and phase noise). While these seem to be workable solutions, they have not been picked up and used extensively. With regard to using the phase variations as a regressor to eliminate pulsatile blood and tissue, perhaps the primary reason for this not being adopted is because standard scanners do not produce these images readily, thus users do not have easy access to this information.</p>
<p>The draining vein issue is least problematic at voxel sizes larger than 2mm, as at these resolutions, mostly the region of activation- as defined as &gt;1 cm “blob” is used and interpreted. Other than enhancing the magnitude of activation, vein effects do not distort these “blobs” thus are typically of no …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</a></em></p>]]>
            </description>
            <link>http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668279</guid>
            <pubDate>Sun, 28 Jun 2020 12:27:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Server-Side Tracking Without Cookies in Go]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23668212">thread link</a>) | @marvinblum
<br/>
June 28, 2020 | https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl | <a href="https://web.archive.org/web/*/https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <small>Published on 22. June 2020</small>
    <p>I was looking for an alternative to Google Analytics to track visitors on a website. Analytics (and most of its competitors) provide detailed information and real-time data at the cost of privacy. Google can track you across sites using a bunch of different techniques and through their Chrome browser. Combined, this can be assembled to a detailed profile that can not only be used for tracking, but for marketing too.</p><p>I found some (open source) alternatives like <a href="https://www.goatcounter.com/" target="_blank" rel="noreferrer">GoatCounter</a>, which anonymously collect data without invading the user's privacy. But all of the tools I found either rely on cookies, which the visitor needs to opt-in for or cost money for the server-side only tracking solution. While I'm willing to pay for good software, especially when it comes from a small team or just one developer, I was wondering if I could build something that I can integrate into my Go applications.</p><p>This post is about my solution called <em>Pirsch</em>, an open-source Go library that can be integrated into your applications to tracks visitors on the server-side, without setting cookies. I will write about the technique used and what the advantages and disadvantages are.</p><blockquote><h2>TL;DR</h2><p>Invading the privacy of your website visitors is evil. Pirsch is a privacy-focused tracking library for Go that can be integrated into your applications. Check it out on <a href="https://github.com/emvi/pirsch" target="_blank" rel="noreferrer">GitHub</a>!</p><p>You can find a live demo <a href="https://marvinblum.de/tracking" target="_blank" rel="noreferrer">here</a> on my website and the whole thing on GitHub as a <a href="https://github.com/Kugelschieber/marvinblum" target="_blank" rel="noreferrer">sample application</a>.</p></blockquote><h2>What's With the Name?</h2><p>Pirsch is German and refers to a special kind of hunt:&nbsp;<em>the hunter carefully and quietly enters the area to be hunted, he stalks against the wind in order to get as close as possible to the prey without being noticed.</em></p><p>I found this quite fitting for a tracking library that cannot be blocked by the visitor. Even though it sounds a little sneaky. Here is the Gopher for it create by <a href="https://github.com/Motorschpocht" target="_blank" rel="noreferrer">Daniel</a>.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/0wV4YBIYaCm9JiteSaa3.svg" alt="https://api.emvi.com/api/v1/content/0wV4YBIYaCm9JiteSaa3.svg"><h2>How Does It Work?</h2><p>I will go over each step in more detail later, but here is a high-level overview of how Pirsch tracks visitors.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/vuvopEa9M7yGpKWgwXht.svg" alt="https://api.emvi.com/api/v1/content/vuvopEa9M7yGpKWgwXht.svg"><p>Once someone visits your website, the HTTP handler calls Pirsch to store a new hit and goes on with whatever it intends to do. Pirsch will do its best to filter out bots, calculate a fingerprint, and stores the page hit. You can analyze the data and generate statistics from it later.</p><p>The process must be triggered manually by calling the <code>Hit</code> method and passing the <code>http.Request</code>. This enables you to decide which traffic is tracked and which is not. I'm usually just interested in page visits, so I'll add a call to Pirsch inside my page handlers. Resources are served on a different endpoint and won't be tracked that way.</p><h3>Fingerprinting</h3><p>Fingerprinting is a technique to identify individual devices by combing some parameters. The parameters are typically things like the graphics card ID and other variables that are unique to a device. As we are interested in tracking website traffic, we won't have access to this kind of information. Instead, we can make use of the IP and HTTP protocol. Here are the parameters used by Pirsch to generate a fingerprint:</p><ul><li><p>the IP is the most obvious choice. It might change, as ISPs only have a limited pool of IPs available to them, but that shouldn't happen too frequently</p></li><li><p>the User-Agent HTTP header contains information about the browser and device used by the visitor. It might not be filled though, but it usually is</p></li></ul><p>To generate a unique fingerprint from this information, we can calculate a hash. Pirsch will add the current day to prevent tracking users across days and calculate an MD5 hash. I found this to be the fastest algorithm available in the Go standard library. This will also make the visitor anonymous at the same time as we do not store IPs or other identifiable information.</p><p>This method is called <em>passive</em> fingerprinting, as we're only using data that we have access to anyways. The alternative is called <em>active</em> fingerprinting, which makes use of JavaScript to collect additional information on the client-side and sends it to the backend. But as we're trying to build a privacy-focus tracking solution, passive fingerprinting is the way to go.</p><p>We will use the fingerprint later to count unique visitors.</p><h3>Filtering Bots</h3><p>Filtering out bot traffic is hard, as there is no complete list of all bots and they won't send any special kind of information, like an <em>I'm a bot</em> header. All we can do is to process the IP and the User-Agent header send and make some assumptions. Pirsch will look for terms often used by bots within the User-Agent header. Should it contain words like <em>bot</em> or <em>crawler</em> or an URL, the hit will be dropped. Filtering for IP ranges is not implemented (yet), but you can filter hits that are coming from popular IP ranges, like AWS.</p><h3>Hits</h3><p>Each page request is stored as a <em>Hit</em>. A hit is a data point that can later be analyzed. Here is the definition of a hit:</p><pre><code language="text/x-go">// I removed some details to make it more readable for this blog post
type Hit struct {
	Fingerprint string
	Path        string
	URL         string
	Language    string
	UserAgent   string
	Ref         string
	Time        time.Time
}</code></pre><p>A hit contains the full request URL, the path extracted from the URL, the language, user-agent and reference passed by the client in their corresponding headers and the time the request was made.</p><h3>Analyze</h3><p>Pirsch provides an <em>Analyzer</em> that can be used to extract some basic statistics:</p><ul><li><p>total visitor count</p></li><li><p>visitors by page on each day</p></li><li><p>visitors by hour on each day</p></li><li><p>languages used by visitors</p></li><li><p>active visitors within a time frame</p></li></ul><p>Most of these functions accept a filter to specify a time frame. The data can then be plotted like on my <a href="https://marvinblum.de/tracking" target="_blank" rel="noreferrer">tracking page</a>.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/QOeMcMKi8yS2p4WB2Xlu.png" alt="https://api.emvi.com/api/v1/content/QOeMcMKi8yS2p4WB2Xlu.png"><p>To reduce the amount of data that needs to be processed the hits get aggregated each night and hits are cleaned up afterward.</p><p>Postgres is used as the storage backend at the moment as it is a fantastic open-source database and provides all features needed to read these statistics easily. You can extract more statistics, like the visitor page flow, from the database if you care.</p><h3>Tracking From JavaScript</h3><p>While it is simple to integrate tracking into your backend, you might also want to have some way to track from your frontend as well, in case you're running a single page application for example. In that case, you can add an endpoint to your router and call it using Ajax. The path can manually be overwritten in Pirsch by calling <em>HitPage</em> instead of <em>Hit</em>.</p><h2>How Well Does It Work?</h2><p>As far as I can tell right now, it works pretty well. I still need to collect more sample data and a way to compare it to something like Google Analytics in order to make a more precise statement. Keep in mind that while Analytics and other tools provide more detailed statistics, like the location, age, gender, and so on, they can be blocked by tools like uBlock. Pirsch cannot be blocked by the client and therefore it can track visitors you won't even notice with a client-side solution.</p><p>Bots are probably the weak spot of Pirsch right now, as filtering for them requires adding a whole bunch of keywords to the filter list.</p><p>Another disadvantage of server-side tracking depending on your use-case  might be that you cannot track your marketing campaigns. In case you're using Adsense for marketing, you can track how well your campaigns perform through Analytics. This won't work with Pirsch.</p><h2>Conclusion</h2><p>Tracking on the server-side isn't too hard to archive and all in all, I think it's worth the effort. I hope you gained some insight into how you can use fingerprinting and Pirsch to your advantage. I will continue improving Pirsch and implement it into <a href="https://emvi.com/" target="_blank" rel="noreferrer">Emvi</a> and compare the output to Analytics. I might also add a user interface for Pirsch so that you can host it without integrating it into your application and without the need to generate the charts yourself. In case you would like to send me feedback, have a question, or would like to contribute you can contact me.</p>
</section></div>]]>
            </description>
            <link>https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668212</guid>
            <pubDate>Sun, 28 Jun 2020 12:06:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Linux System Calls (2016)]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23668186">thread link</a>) | @crunchbang123
<br/>
June 28, 2020 | https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/ | <a href="https://web.archive.org/web/*/https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This blog post explains how Linux programs call functions in the Linux kernel.</p><p>It will outline several different methods of making systems calls, how to handcraft your own assembly to make system calls (examples included), kernel entry points into system calls, kernel exit points from system calls, glibc wrappers, bugs, and much, much more. </p><div><p>Create a package repository in less than 10 seconds, free.</p></div><ul id="markdown-toc"><li><a href="#tldr" id="markdown-toc-tldr">TL;DR</a></li><li><a href="#what-is-a-system-call" id="markdown-toc-what-is-a-system-call">What is a system call?</a></li><li><a href="#prerequisite-information" id="markdown-toc-prerequisite-information">Prerequisite information</a><ul><li><a href="#hardware-and-software" id="markdown-toc-hardware-and-software">Hardware and software</a></li><li><a href="#user-programs-the-kernel-and-cpu-privilege-levels" id="markdown-toc-user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</a></li><li><a href="#interrupts" id="markdown-toc-interrupts">Interrupts</a></li><li><a href="#model-specific-registers-msrs" id="markdown-toc-model-specific-registers-msrs">Model Specific Registers (MSRs)</a></li><li><a href="#calling-system-calls-with-assembly-is-a-bad-idea" id="markdown-toc-calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</a></li></ul></li><li><a href="#legacy-system-calls" id="markdown-toc-legacy-system-calls">Legacy system calls</a><ul><li><a href="#using-legacy-system-calls-with-your-own-assembly" id="markdown-toc-using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</a></li><li><a href="#kernel-side-int-0x80-entry-point" id="markdown-toc-kernel-side-int-0x80-entry-point">Kernel-side: <code>int $0x80</code> entry point</a></li><li><a href="#returning-from-a-legacy-system-call-with-iret" id="markdown-toc-returning-from-a-legacy-system-call-with-iret">Returning from a legacy system call with <code>iret</code></a></li></ul></li><li><a href="#fast-system-calls" id="markdown-toc-fast-system-calls">Fast system calls</a><ul><li><a href="#32-bit-fast-system-calls" id="markdown-toc-32-bit-fast-system-calls">32-bit fast system calls</a><ul><li><a href="#sysentersysexit" id="markdown-toc-sysentersysexit"><code>sysenter</code>/<code>sysexit</code></a></li><li><a href="#__kernel_vsyscall-internals" id="markdown-toc-__kernel_vsyscall-internals"><code>__kernel_vsyscall</code> internals</a></li><li><a href="#using-sysenter-system-calls-with-your-own-assembly" id="markdown-toc-using-sysenter-system-calls-with-your-own-assembly">Using <code>sysenter</code> system calls with your own assembly</a></li><li><a href="#kernel-side-sysenter-entry-point" id="markdown-toc-kernel-side-sysenter-entry-point">Kernel-side: <code>sysenter</code> entry point</a></li><li><a href="#returning-from-a-sysenter-system-call-with-sysexit" id="markdown-toc-returning-from-a-sysenter-system-call-with-sysexit">Returning from a <code>sysenter</code> system call with <code>sysexit</code></a></li></ul></li><li><a href="#64-bit-fast-system-calls" id="markdown-toc-64-bit-fast-system-calls">64-bit fast system calls</a><ul><li><a href="#syscallsysret" id="markdown-toc-syscallsysret"><code>syscall</code>/<code>sysret</code></a></li><li><a href="#using-syscall-system-calls-with-your-own-assembly" id="markdown-toc-using-syscall-system-calls-with-your-own-assembly">Using <code>syscall</code> system calls with your own assembly</a></li><li><a href="#kernel-side-syscall-entry-point" id="markdown-toc-kernel-side-syscall-entry-point">Kernel-side: syscall entry point</a></li><li><a href="#returning-from-a-syscall-system-call-with-sysret" id="markdown-toc-returning-from-a-syscall-system-call-with-sysret">Returning from a <code>syscall</code> system call with <code>sysret</code></a></li></ul></li></ul></li><li><a href="#calling-a-syscall-semi-manually-with-syscall2" id="markdown-toc-calling-a-syscall-semi-manually-with-syscall2">Calling a syscall semi-manually with syscall(2)</a><ul><li><a href="#glibc-syscall-wrapper-internals" id="markdown-toc-glibc-syscall-wrapper-internals">glibc <code>syscall</code> wrapper internals</a></li></ul></li><li><a href="#virtual-system-calls" id="markdown-toc-virtual-system-calls">Virtual system calls</a><ul><li><a href="#vdso-in-the-kernel" id="markdown-toc-vdso-in-the-kernel">vDSO in the kernel</a></li><li><a href="#locating-the-vdso-in-memory" id="markdown-toc-locating-the-vdso-in-memory">Locating the vDSO in memory</a></li><li><a href="#vdso-in-glibc" id="markdown-toc-vdso-in-glibc">vDSO in glibc</a></li></ul></li><li><a href="#glibc-system-call-wrappers" id="markdown-toc-glibc-system-call-wrappers"><code>glibc</code> system call wrappers</a></li><li><a href="#interesting-syscall-related-bugs" id="markdown-toc-interesting-syscall-related-bugs">Interesting syscall related bugs</a><ul><li><a href="#cve-2010-3301" id="markdown-toc-cve-2010-3301">CVE-2010-3301</a></li><li><a href="#android-sysenter-abi-breakage" id="markdown-toc-android-sysenter-abi-breakage">Android <code>sysenter</code> ABI breakage</a></li></ul></li><li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li><li><a href="#related-posts" id="markdown-toc-related-posts">Related Posts</a></li></ul><p>When you run a program which calls <code>open</code>, <code>fork</code>, <code>read</code>, <code>write</code> (and many others) you are making a system call.</p><p>System calls are how a program enters the kernel to perform some task. Programs use system calls to perform a variety of operations such as: creating processes, doing network and file IO, and much more.</p><p>You can find a list of system calls by checking the <a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">man page for syscalls(2)</a>.</p><p>There are several different ways for user programs to make system calls and the low-level instructions for making a system call vary among CPU architectures.</p><p>As an application developer, you don’t typically need to think about how exactly a system call is made. You simply include the appropriate header file and make the call as if it were a normal function.</p><p><code>glibc</code> provides wrapper code which abstracts you away from the underlying code which arranges the arguments you’ve passed and enters the kernel.</p><p>Before we can dive into the details of how system calls are made, we’ll need to define some terms and examine some core ideas that will appear later.</p><h2 id="hardware-and-software">Hardware and software</h2><p>This blog post makes the following assumptions that:</p><ul><li>You are using a 32-bit or 64-bit Intel or AMD CPU. The discussion about the methods may be useful for people using other systems, but the code samples below contain CPU-specific code.</li><li>You are interested in the Linux kernel, version 3.13.0. Other kernel versions will be similar, but the exact line numbers, organization of code, and file paths will vary. Links to the 3.13.0 kernel source tree on GitHub are provided.</li><li>You are interested in <code>glibc</code> or <code>glibc</code> derived libc implementations (e.g., <code>eglibc</code>).</li></ul><p>x86-64 in this blog post will refer to 64bit Intel and AMD CPUs that are based on the x86 architecture.</p><h2 id="user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</h2><p>User programs (like your editor, terminal, ssh daemon, etc) need to interact with the Linux kernel so that the kernel can perform a set of operations on behalf of your user programs that they can’t perform themselves.</p><p>For example, if a user program needs to do some sort of IO (<code>open</code>, <code>read</code>, <code>write</code>, etc) or modify its address space (<code>mmap</code>, <code>sbrk</code>, etc) it must trigger the kernel to run to complete those actions on its behalf.</p><p>What prevents user programs from performing these actions themselves?</p><p>It turns out that the x86-64 CPUs have a concept called <a href="https://en.wikipedia.org/wiki/Privilege_level">privilege levels</a>. Privilege levels are a complex topic suitable for their own blog post. For the purposes of this post, we can (greatly) simplify the concept of privilege levels by saying:</p><ol><li>Privilege levels are a means of access control. The current privilege level determines which CPU instructions and IO may be performed.</li><li>The kernel runs at the most privileged level, called “Ring 0”. User programs run at a lesser level, typically “Ring 3”.</li></ol><p>In order for a user program to perform some privileged operation, it must cause a privilege level change (from “Ring 3” to “Ring 0”) so that the kernel can execute.</p><p>There are several ways to cause a privilege level change and trigger the kernel to perform some action.</p><p>Let’s start with a common way to cause the kernel to execute: interrupts.</p><h2 id="interrupts">Interrupts</h2><p>You can think of an interrupt as an event that is generated (or “raised”) by hardware or software.</p><p>A hardware interrupt is raised by a hardware device to notify the kernel that a particular event has occurred. A common example of this type of interrupt is an interrupt generated when a NIC receives a packet.</p><p>A software interrupt is raised by executing a piece of code. On x86-64 systems, a software interrupt can be raised by executing the <code>int</code> instruction.</p><p>Interrupts usually have numbers assigned to them. Some of these interrupt numbers have a special meaning.</p><p>You can imagine an array that lives in memory on the CPU. Each entry in this array maps to an interrupt number. Each entry contains the address of a function that the CPU will begin executing when that interrupt is received along with some options, like what privilege level the interrupt handler function should be executed in.</p><p>Here’s a photo from the Intel CPU manual showing the layout of an entry in this array:</p><p><img src="https://blog.packagecloud.io/images/idt.png" alt="Screenshot of Interrupt Descriptor Table entry diagram for x86_64 CPUs"></p><p>If you look closely at the diagram, you can see a 2-bit field labeled DPL (Descriptor Privilege Level). The value in this field determines the minimum privilege level the CPU will be in when the handler function is executed.</p><p>This is how the CPU knows which address it should execute when a particular type of event is received and what privilege level the handler for that event should execute in.</p><p>In practice, there are lots of different ways to deal with interrupts on x86-64 systems. If you are interested in learning more read about the <a href="http://wiki.osdev.org/8259_PIC">8259 Programmable Interrupt Controller</a>, <a href="http://wiki.osdev.org/APIC">Advanced Interrupt Controllers</a>, and <a href="http://wiki.osdev.org/IOAPIC">IO Advanced Interrupt Controllers</a>.</p><p>There are other complexities involved with dealing with both hardware and software interrupts, such as interrupt number collisions and remapping.</p><p>We don’t need to concern ourselves with these details for this discussion about system calls.</p><h2 id="model-specific-registers-msrs">Model Specific Registers (MSRs)</h2><p>Model Specific Registers (also known as MSRs) are control registers that have a specific purpose to control certain features of the CPU. The CPU documentation lists the addresses of each of the MSRs.</p><p>You can use the CPU instructions <code>rdmsr</code> to <code>wrmsr</code> to read and write MSRs, respectively.</p><p>There are also command line tools which allow you to read and write MSRs, but doing this is <em>not recommended</em> as changing these values (especially while a system is running) is dangerous unless you are really careful.</p><p>If you don’t mind potentially destabilizing your system or irreversibly corrupting your data, you can read and write MSRs by installing <code>msr-tools</code> and loading the <code>msr</code> kernel module:</p><figure><pre><code data-lang="sh">% <span>sudo </span>apt-get install msr-tools
% <span>sudo </span>modprobe msr
% <span>sudo </span>rdmsr</code></pre></figure><p>Some of the system call methods we’ll see later make use of MSRs, as we’ll see soon.</p><h2 id="calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</h2><p>It’s not a great idea to call system calls by writing your own assembly code.</p><p>One big reason for this is that some system calls have additional code that runs in glibc before or after the system call runs.</p><p>In the examples below, we’ll be using the <code>exit</code> system call. It turns out that you can register functions to run when <code>exit</code> is called by a program by using <a href="http://man7.org/linux/man-pages/man3/atexit.3.html"><code>atexit</code></a>.</p><p>Those functions are called from glibc, not the kernel. So, if you write your own assembly to call <code>exit</code> as we show below, your registered handler functions won’t be executed since you are bypassing glibc.</p><p>Nevertheless, manually making system calls with assembly is a good learning experience.</p><div><p>Create a package repository in less than 10 seconds, free.</p></div><p>Using our prerequisite knowledge we know two things:</p><ol><li>We know that we can trigger the kernel to execute by generating a software interrupt.</li><li>We can generate a software interrupt with the <code>int</code> assembly instruction.</li></ol><p>Combining these two concepts leads us to the legacy system call interface on Linux.</p><p>The Linux kernel sets aside a specific software interrupt number that can be used by user space programs to enter the kernel and execute a system call.</p><p>The Linux kernel registers an interrupt handler named <code>ia32_syscall</code> for the interrupt number: 128 (0x80). Let’s take a look at the code that actually does this.</p><p>From the <code>trap_init</code> function in the kernel 3.13.0 source in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/kernel/traps.c</code></a>:</p><figure><pre><code data-lang="c"><span>void</span> <span>__init</span> <span>trap_init</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
        <span>/* ..... other code ... */</span>

        <span>set_system_intr_gate</span><span>(</span><span>IA32_SYSCALL_VECTOR</span><span>,</span> <span>ia32_syscall</span><span>);</span></code></pre></figure><p>Where <code>IA32_SYSCALL_VECTOR</code> is a defined as <code>0x80</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/include/asm/irq_vectors.h</code></a>.</p><p>But, if the kernel reserves a single software interrupt that userland programs can raise to trigger the kernel, how does the kernel know which of the many system calls it should execute?</p><p>The userland program is expected to put the system call number in the <code>eax</code> register. The arguments for the syscall itself are to be placed in the remaining general purpose registers.</p><p>One place this is documented is in a comment in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/ia32/ia32entry.S#L378-L397"><code>arch/x86/ia32/ia32entry.S</code></a>:</p><figure><pre><code data-lang="c"> <span>*</span> <span>Emulated</span> <span>IA32</span> <span>system</span> <span>calls</span> <span>via</span> <span>int</span> <span>0x80</span><span>.</span>
 <span>*</span>
 <span>*</span> <span>Arguments</span><span>:</span>
 <span>*</span> <span>%</span><span>eax</span> <span>System</span> <span>call</span> <span>number</span><span>.</span>
 <span>*</span> <span>%</span><span>ebx</span> <span>Arg1</span>
 <span>*</span> <span>%</span><span>ecx</span> <span>Arg2</span>
 <span>*</span> <span>%</span><span>edx</span> <span>Arg3</span>
 <span>*</span> <span>%</span><span>esi</span> <span>Arg4</span>
 <span>*</span> <span>%</span><span>edi</span> <span>Arg5</span>
 <span>*</span> <span>%</span><span>ebp</span> <span>Arg6</span>    <span>[</span><span>note</span><span>:</span> <span>not</span> <span>saved</span> <span>in</span> <span>the</span> <span>stack</span> <span>frame</span><span>,</span> <span>should</span> <span>not</span> <span>be</span> <span>touched</span><span>]</span>
 <span>*</span></code></pre></figure><p>Now that we know how to make a system call and where the arguments should live, let’s try to make one by writing some inline assembly.</p><h2 id="using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</h2><p>To make a legacy system call, you can write a small bit of inline assembly. While this is interesting from a learning perspective, I encourage readers to never make system calls by crafting their own assembly.</p><p>In this example, we’ll try calling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</a></em></p>]]>
            </description>
            <link>https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668186</guid>
            <pubDate>Sun, 28 Jun 2020 11:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asymptomatic Covid-19 finding dim hopes for herd immunity and immunity passports]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23667904">thread link</a>) | @pseudolus
<br/>
June 28, 2020 | https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A closer look at people who tested positive for COVID-19 but never developed symptoms has found that such asymptomatic carriers have few to no detectable antibodies just weeks after infection, suggesting they may not develop lasting immunity.</p><div><p><span><span><span></span><span>A new study on COVID-19 immunity has found that people who were asymptomatic or mildly symptomatic had their antibodies diminish within two to three months. Though larger studies are needed, the findings cast doubt on antibody testing and herd immunity.<!-- --> <!-- -->2:01</span></span></span></p><p><span><p>A closer look at people who tested positive for COVID-19 but never developed symptoms has found that such asymptomatic carriers&nbsp;have few to no detectable antibodies just weeks after infection, suggesting&nbsp;they may not develop lasting immunity.</p>  <p>There's growing evidence that a significant proportion of people who test positive for COVID-19 never show symptoms, although it's <a href="https://www.cbc.ca/news/health/asymptomatic-testing-1.5585699"><u>not clear what percentage </u></a>of people that is&nbsp;and <a href="https://www.cbc.ca/news/health/who-covid-19-asymptomatic-spread-1.5604353"><u>what role they play</u></a> in spreading the disease.</p>  <p>A Chinese study <a href="https://www.nature.com/articles/s41591-020-0965-6#Sec8">published this&nbsp;week in Nature</a> followed 37 people in Wanzhou District in China who did not show any outward signs of the disease, despite testing positive when their respiratory tracts were swabbed and being kept in hospital for observation.</p>  <p>Some key findings include:</p>  <ul>   <li> <p>Levels of antibodies against COVID-19 were significantly lower in asymptomatic carriers&nbsp;than those with symptoms during active infection.</p> </li>   <li> <p>Antibody levels also dropped off far more quickly in people who never showed symptoms, and 40 per cent of them had no detectable antibodies eight weeks after recovery, compared with&nbsp;13 per cent of symptomatic patients.</p> </li>   <li> <p>Those with asymptomatic infections tested positive for an average of five&nbsp;days longer than people with symptomatic infections — 19 days compared with&nbsp;14 days — suggesting that they were shedding the virus longer.</p> </li>  </ul>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/antibody-test.jpg 300w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/antibody-test.jpg 460w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/antibody-test.jpg 620w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/antibody-test.jpg 780w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/antibody-test.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/antibody-test.jpg"></p></div><figcaption>Unlike nasal swab tests that can only detect an active infection, antibody tests can detect previous infections. But a new study suggests antibodies often don't stick around for long after an infection.<!-- --> <!-- -->(Zuleika Chan)</figcaption></figure></span></p>  <p>The study also found that despite having no outward symptoms, 70 per cent had lung abnormalities detectable in X-rays at some point during infection — mostly spots called "ground-glass opacities," which can indicate inflammation or other signs of disease.</p>  <h2>No antibodies could mean no immunity, but not necessarily</h2>  <p>Dr. Samir Gupta, a clinician-scientist at St. Michael's Hospital in Toronto and assistant professor of medicine at the University of Toronto, noted in an interview with CBC News Network earlier this week that the study was very small.</p>  <p>Gupta, who wasn't involved in the study, added that it wasn't surprising that antibody levels fell a few months after infection. He said that's normal, since it's energy intensive for the body to maintain antibodies it doesn't need.</p>  <p>What was "a little bit surprising," he said, was the fact that 40 per cent of people with asymptomatic infections had no detectable antibodies at all.</p>  <p><em><strong>WATCH | Dr. Samir Gupta on Alberta's testing plans:</strong></em></p>  <p><span><span><span></span><span>Dr. Samir Gupta says Alberta's testing may help to understand how far the coronavirus spread but he's doubtful we've reached herd immunity.<!-- --> <!-- -->8:35</span></span></span></p>  <p>However, Gupta&nbsp;said,&nbsp;people have immunity to coronaviruses that cause common colds for only a few months, and that may also be the case for the coronavirus that causes COVID-19.</p>  <p>On the other hand, he said, "antibodies aren't the whole story."</p>  <p>There are other components of the immune system that play a role, such as memory cells. They remember a pathogen&nbsp;and begin releasing antibodies when they encounter it again, but they are hard to detect, Gupta said.</p>  <h2>What this means for herd immunity and vaccines</h2>  <p>Still, Tania Watts, a professor of immunology at the University of Toronto who was not involved in the study, expressed concern about the implications.</p>  <p>"This suggests that natural infection may not give long-lasting immunity, which is what people have been worried about," she said.</p>  <p>Some countries <a href="https://www.bmj.com/content/369/bmj.m2376"><u>such as Sweden</u></a> and <a href="https://www.cbc.ca/news/politics/herd-immunity-should-not-be-supported-tam-says-1.5545332"><u>at least one Canadian province</u></a> have previously suggested that one way to control the spread of COVID-19 is to allow most of the population to get infected in a controlled fashion to generate <a href="https://www.cbc.ca/news/politics/herd-immunity-should-not-be-supported-tam-says-1.5545332"><u>"herd immunity."</u></a>&nbsp;Once the population reaches a certain threshold of previous infection, there won't be enough susceptible people to spread the virus, and it can't spread exponentially as an epidemic.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-vaccine-race.jpg 300w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-vaccine-race.jpg 460w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-vaccine-race.jpg 620w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-vaccine-race.jpg 780w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-vaccine-race.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-vaccine-race.jpg"></p></div><figcaption>A patient receives a shot in the first-stage safety study clinical trial of a potential vaccine for COVID-19 in March. A vaccine will need to produce a strong and long-lasting immune response, something that natural infection may not always do.<!-- --> <!-- -->(Ted S. Warren/The Associated Press)</figcaption></figure></span></p>  <p>But Watts said the low and short-lived levels of antibodies in asymptomatic infections in this study suggest we can't rely on herd immunity being induced for long enough a period of time to have an impact.</p>  <p>That means we may need to wait for a vaccine that induces a stronger, longer-lived response than many natural infections, she said.&nbsp;"I think this puts even more pressure on vaccine development."</p>  <h2>What this means for antibody tests,&nbsp;'immunity passports'</h2>  <p>Watts said another implication of the study is that serological (blood) or antibody tests — which have been touted as a way to get an idea of who has been previously infected, how much of the population that represents&nbsp;and how close that is to herd immunity —&nbsp;may not work as hoped.</p>  <p>And it throws cold water on the idea of controversial "<a href="https://www.cbc.ca/radio/thehouse/immunity-passes-could-be-an-interim-measure-on-the-way-to-reopening-society-physician-says-1.5544368"><u>immunity passports</u></a>," the idea of allowing more social interactions, such as work, travel&nbsp;and mass gatherings, for people who have previously been infected and therefore are immune and can't spread the virus — which would be based on serological testing.&nbsp;</p>  <p>"Until we know what part of the immune system is protective," Watts said, "it's difficult to be able to do a test and tell someone you're safe or not."</p>  <h2>What this&nbsp;means for disease transmission</h2>  <p>While it's known that presymptomatic people can transmit COVID-19, it's not really known whether people who remain asymptomatic through the course of the disease can.</p>  <p>Watts said she thinks the finding in this study that people without symptoms shed the virus longer than people with&nbsp;symptoms is "shocking" and suggests we need to worry about transmission from asymptomatic people.</p>  <p>"Until we have a vaccine, I think we should have very clear recommendations that everybody wears masks."</p>    <p>She said the longer period of viral shedding is probably because a lack of symptoms indicate a weaker immune response, resulting in a longer time to clear the infection.</p>  <p>On the other hand, too intense an immune response is what puts patients in the ICU struggling to breathe.</p>  <p>The ideal is somewhere in between&nbsp;and what we'd like in a vaccine, Watts&nbsp;said.</p>  <p>"We really need that Goldilocks immune response."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667904</guid>
            <pubDate>Sun, 28 Jun 2020 10:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: BungoSearch – Search free e-books by time-to-read]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23667702">thread link</a>) | @tomomichi
<br/>
June 28, 2020 | https://search.bungomail.com/en | <a href="https://web.archive.org/web/*/https://search.bungomail.com/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books/1342">Pride and Prejudice
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/all/books">Jane Austen
</a><br>
<small>(1775-1817)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
113,166
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Chapter 1   It is a truth universally acknowledged, that a single man in possession of a good for...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books/1342">Pride and Prejudice
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/all/books">Jane Austen
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Chapter 1   It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books/1080">A Modest Proposal For preventing the children of poor people in Ireland, from being a burden on t...
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/all/books">Jonathan Swift
</a><br>
<small>(1667-1745)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books"><p>30min</p>
</a>&nbsp;
<small>
3,153
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
1729    It is a melancholy object to those, who walk through this great town, or travel in the co...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books/1080">A Modest Proposal For preventing the children of poor people in Ireland,...
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/all/books">Jonathan Swift
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>1729    It is a melancholy object to those, who walk through this great town, or travel in the country, when they see the streets, the roads and cabbin-doors crowded with beggars of the female sex,...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books/84">Frankenstein; Or, The Modern Prometheus
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/all/books">Mary Wollstonecraft Shelley
</a><br>
<small>(1797-1851)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
69,388
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Letter 1   St. Petersburgh, Dec. 11th, 17--  TO Mrs. Saville, England  You will rejoice to hear t...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books/84">Frankenstein; Or, The Modern Prometheus
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/all/books">Mary Wollstonecraft Shelley
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Letter 1   St. Petersburgh, Dec. 11th, 17--  TO Mrs. Saville, England  You will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such ...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books/2701">Moby Dick; Or, The Whale
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/all/books">Herman Melville
</a><br>
<small>(1819-1891)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
197,269
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Original Transcriber's Notes:  This text is a combination of etexts, one from the now-defunct ERI...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books/2701">Moby Dick; Or, The Whale
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/all/books">Herman Melville
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Original Transcriber's Notes:  This text is a combination of etexts, one from the now-defunct ERIS project at Virginia Tech and one from Project Gutenberg's archives.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books/43">The Strange Case of Dr. Jekyll and Mr. Hyde
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/all/books">Robert Louis Stevenson
</a><br>
<small>(1850-1894)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
23,888
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
STORY OF THE DOOR   Mr. Utterson the lawyer was a man of a rugged countenance that was never ligh...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books/43">The Strange Case of Dr. Jekyll and Mr. Hyde
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/all/books">Robert Louis Stevenson
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>STORY OF THE DOOR   Mr. Utterson the lawyer was a man of a rugged countenance that was never lighted by a smile; cold, scanty and embarrassed in discourse; backward in sentiment; lean, long, dusty,...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books/98">A Tale of Two Cities
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a><br>
<small>(1812-1870)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
127,234
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Book the First--Recalled to Life     I. The Period   It was the best of times, it was the worst o...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books/98">A Tale of Two Cities
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Book the First--Recalled to Life     I. The Period   It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books/2542">A Doll's House : a play
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/all/books">Henrik Ibsen
</a><br>
<small>(1828-1906)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
24,806
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
DRAMATIS PERSONAE       Torvald Helmer.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books/2542">A Doll's House : a play
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/all/books">Henrik Ibsen
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>DRAMATIS PERSONAE       Torvald Helmer.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books/1661">The Adventures of Sherlock Holmes
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/all/books">Arthur Conan Doyle
</a><br>
<small>(1859-1930)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
97,696
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
ADVENTURE I. A SCANDAL IN BOHEMIA  I.  To Sherlock Holmes she is always THE woman.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books/1661">The Adventures of Sherlock Holmes
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/all/books">Arthur Conan Doyle
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>ADVENTURE I. A SCANDAL IN BOHEMIA  I.  To Sherlock Holmes she is always THE woman.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books/345">Dracula
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/all/books">Bram Stoker
</a><br>
<small>(1847-1912)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
150,214
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I  JONATHAN HARKER'S JOURNAL  (_Kept in shorthand._)   _3 May. Bistritz._--Left Munich at...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books/345">Dracula
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/all/books">Bram Stoker
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I  JONATHAN HARKER'S JOURNAL  (_Kept in shorthand._)   _3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning; should have arrived at 6:46, but tra...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books/11">Alice's Adventures in Wonderland
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/all/books">Lewis Carroll
</a><br>
<small>(1832-1898)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
25,176
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Down the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister o...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books/11">Alice's Adventures in Wonderland
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/all/books">Lewis Carroll
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Down the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was r...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books/1952">The Yellow Wallpaper
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/all/books">Charlotte Perkins Gilman
</a><br>
<small>(1860-1935)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books"><p>30min</p>
</a>&nbsp;
<small>
5,621
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
It is very seldom that mere ordinary people like John and myself secure ancestral halls for the s...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books/1952">The Yellow Wallpaper
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/all/books">Charlotte Perkins Gilman
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>It is very seldom that mere ordinary people like John and myself secure ancestral halls for the summer.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books/46">A Christmas Carol in Prose; Being a Ghost Story of Christmas
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a><br>
<small>(1812-1870)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
26,327
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
PREFACE  I HAVE endeavoured in this Ghostly little book, to raise the Ghost of an Idea, which sha...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books/46">A Christmas Carol in Prose; Being a Ghost Story of Christmas
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>PREFACE  I HAVE endeavoured in this Ghostly little book, to raise the Ghost of an Idea, which shall not put my readers out of humour with themselves, with each other, with the season, or with me.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books/6130">The Iliad
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/all/books">Homer
</a><br>
<small>(-750--650)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
188,032
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
The Iliad of Homer   Translated by Alexander Pope,  with notes by the Rev.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books/6130">The Iliad
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/all/books">Homer
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>The Iliad of Homer   Translated by Alexander Pope,  with notes by the Rev.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books/41">The Legend of Sleepy Hollow
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/all/books">Washington Irving
</a><br>
<small>(1783-1859)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books"><p>1h</p>
</a>&nbsp;
<small>
11,327
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
A pleasing land of drowsy head it was,           Of dreams that wave before the half-shut eye;   ...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books/41">The Legend of Sleepy Hollow
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/all/books">Washington Irving
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>A pleasing land of drowsy head it was,           Of dreams that wave before the half-shut eye;         And of gay castles in the clouds that pass,           Forever flushing round a summer sky.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books/25344">The Scarlet Letter
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/all/books">Nathaniel Hawthorne
</a><br>
<small>(1804-1864)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
78,087
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
[Illustration]                             LIST OF ILLUSTRATIONS.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books/25344">The Scarlet Letter
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/all/books">Nathaniel Hawthorne
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>[Illustration]                             LIST OF ILLUSTRATIONS.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books/205">Walden, and On The Duty Of Civil Disobedience
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/all/books">Henry David Thoreau
</a><br>
<small>(1817-1862)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
107,527
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Contents   =WALDEN=  Economy  Where I Lived, and What I Lived For  Reading  Sounds  Solitude  Vis...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books/205">Walden, and On The Duty Of Civil Disobedience
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/all/books">Henry David Thoreau
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Contents   =WALDEN=  Economy  Where I Lived, and What I Lived For  Reading  Sounds  Solitude  Visitors  The Bean-Field  The Village  The Ponds  Baker Farm  Higher Laws  Brute Neighbors  House-Warmi...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books/219">Heart of Darkness
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/all/books">Joseph Conrad
</a><br>
<small>(1857-1924)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
35,525
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
I   The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at r...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books/219">Heart of Darkness
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/all/books">Joseph Conrad
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>I   The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/76">Adventures of Huckleberry Finn
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a><br>
<small>(1835-1910)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
104,419
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Civilizing Huck.--Miss Watson.--Tom Sawyer Waits.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/76">Adventures of Huckleberry Finn
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Civilizing Huck.--Miss Watson.--Tom Sawyer Waits.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books/1260">Jane Eyre: An Autobiography
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/all/books">Charlotte Brontë
</a><br>
<small>(1816-1855)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
173,902
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Transcribed from the 1897 Service &amp; Paton edition by David Price, email ccx074@pglaf.org      JAN...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books/1260">Jane Eyre: An Autobiography
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/all/books">Charlotte Brontë
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Transcribed from the 1897 Service &amp; Paton edition by David Price, email ccx074@pglaf.org      JANE EYRE AN AUTOBIOGRAPHY   BY CHARLOTTE BRONTE  _ILLUSTRATED BY F. H. TOWNSEND_  London SERVICE &amp; PAT...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books/2591">Grimms' Fairy Tales
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/all/books">Jacob Grimm
</a><br>
<small>(1785-1863)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
95,267
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
FAIRY TALES  By The Brothers Grimm    PREPARER'S NOTE       The text is based on translations fro...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books/2591">Grimms' Fairy Tales
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/all/books">Jacob Grimm
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>FAIRY TALES  By The Brothers Grimm    PREPARER'S NOTE       The text is based on translations from      the Grimms' Kinder und Hausmarchen by      Edgar Taylor and Marian Edwardes.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books/1250">Anthem
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/all/books">Ayn Rand
</a><br>
<small>(1905-1982)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books"><p>1h</p>
</a>&nbsp;
<small>
17,819
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
PART ONE   It is a sin to write this.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books/1250">Anthem
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/all/books">Ayn Rand
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>PART ONE   It is a sin to write this.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books/408">The Souls of Black Folk
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/all/books">W. E. B. (William Edward Burghardt) Du Bois
</a><br>
<small>(1868-1963)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
63,731
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
chapter I have pointed out the slow rise of personal leadership, and criticized candidly the lead...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books/408">The Souls of Black Folk
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/all/books">W. E. B. (William Edward Burghardt) Du Bois
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>chapter I have pointed out the slow rise of personal leadership, and criticized candidly the leader who bears the chief burden of his race to-day.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books/5200">Metamorphosis
<small>
<i></i>
</small>
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/all/books">Franz Kafka
</a><br>
<small>(1883-1924)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
20,419
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Franz Kafka  Translated by David Wyllie    I   One morning, when Gregor Samsa woke from troubled ...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books/5200">Metamorphosis
<small>
<i></i>
</small>
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/all/books">Franz Kafka
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Franz Kafka  Translated by David Wyllie    I   One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books/844">The Importance of Being Earnest: A Trivial Comedy for Serious People
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/all/books">Oscar Wilde
</a><br>
<small>(1854-1900)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
19,113
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Transcribed from the 1915 Methuen &amp; Co.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books/844">The Importance of Being Earnest: A Trivial Comedy for Serious People
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/all/books">Oscar Wilde
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Transcribed from the 1915 Methuen &amp; Co.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/74">The Adventures of Tom Sawyer
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a><br>
<small>(1835-1910)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
66,208
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty--Tom Practices Music--The Challenge--A Pr...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/74">The Adventures of Tom Sawyer
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty--Tom Practices Music--The Challenge--A Private Entrance  CHAPTER II. Strong Temptations--Strategic Movements--The Innocents Beguiled  CHAPTER...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books/1232">The Prince
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/all/books">Niccolò Machiavelli
</a><br>
<small>(1469-1527)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books"><p>3h</p>
</a>&nbsp;
<small>
45,973
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
by Nicolo Machiavelli  Translated by W. K. Marriott   Nicolo Machiavelli, born at Florence on 3rd...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books/1232">The Prince
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/all/books">Niccolò …</a></td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://search.bungomail.com/en">https://search.bungomail.com/en</a></em></p>]]>
            </description>
            <link>https://search.bungomail.com/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667702</guid>
            <pubDate>Sun, 28 Jun 2020 09:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer on the cruel, tacit laws of type-level programming in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23667675">thread link</a>) | @tenslisi
<br/>
June 28, 2020 | https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html | <a href="https://web.archive.org/web/*/https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<h4 id="a-primer-on-the-cruel-tacit-laws-of-type-level-programming-in-haskell"><em>A primer on the cruel, tacit laws of type-level programming in Haskell</em></h4>

<p>Haskell programs are constructed at the junction of two worlds: one of types, and the other of values. Values are operational run-time entities that are denoted syntactically by <em>terms</em> in the code. To this end, types classify terms. They provide a powerful abstraction to organize data, determine how it should be stored in memory, passed through various operations, and more. On a superficial level, the difference between these worlds is simple: <em>types</em> refer to datatypes, which are either built-in (such as <code>Integer</code> and <code>String</code>), or user-declared, for example:</p>

<pre><code>data SpringFlingQueen = Cady | Regina
</code></pre>

<p>By comparison, <em>values</em> are denoted by <em>terms</em> those types categorize (such as <code>1</code> and <code>"abc"</code> described by the standard library’s <code>Integer</code> and <code>String</code> types, or <code>Cady</code> and <code>Regina</code> in the case of our user-declared type, <code>SpringFlingQueen</code>). Thus, the term <code>1</code> denotes a value that exists in memory only when the program is run.</p>

<p>In addition to these two worlds, a third, darker, and more elusive underworld of <em>kinds</em> also lurks in the shadows of Haskell programs. Haskell kinds can be as unpredictable and insidious as the soulless alpha-female of an elite high school clique. While daunting, understanding the coaction between these three worlds lays the foundation for type-level programming, a topic worth learning as it strengthens overall Haskell intuition.</p>

<p><img src="https://user-images.githubusercontent.com/875834/81239044-afe24580-8fd1-11ea-96b0-274cf839e834.png" alt="the haskell type system: a machine of constant, unforgiving judgement and rigid classification"></p>

<h3 id="kindness-is-a-virtue">Kindness is a virtue</h3>

<p>Much like counter-intuitive adolescent social dynamics, mastery of Haskell bears a steep learning curve because of its underlying complexity. It is difficult to wrap one’s head around the language’s typeclass hierarchies, category-theoretic roots, or the intricacies of compiler behavior. However, an intimate understanding of the type system lets programmers look beyond the chaos of code and apply a recognizable template by which to understand it.</p>

<h3 id="kindness-takes-patience">Kindness takes patience</h3>

<p>This topic is also difficult to master because it is both vast and subtle. Ideas underlying type-level programming are scattered across many disconnected resources focused on several corners of the Haskell ecosystem. Authoritative references on the topic (such as relevant library documentation) tend to assume familiarity with domain-specific terminology that may be unknown to non-experts. Due to the paucity of approachable materials on the subject, I’ve attempted to break down type-level programming into explanations of its constituent parts. While I don’t go into extensive depth on any individual section below, I hope to provide a valuable starting point with which readers can explore ideas in greater detail.</p>

<table>
  <thead>
    <tr>
      <th>Table of contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#Types-vs-Values">Types vs. Values</a></td>
    </tr>
    <tr>
      <td><a href="#Kinds">Kinds</a></td>
    </tr>
    <tr>
      <td><a href="#higher-kinded-types">Higher-kinded types</a></td>
    </tr>
    <tr>
      <td><a href="#constraint-kinds">Constraint kinds</a></td>
    </tr>
    <tr>
      <td><a href="#PolyKinds">Kind polymorphism</a></td>
    </tr>
    <tr>
      <td><a href="#DataKinds">DataKinds and type-level literals</a></td>
    </tr>
    <tr>
      <td><a href="#Datatype-promotion">Datatype promotion</a></td>
    </tr>
    <tr>
      <td><a href="#Relationship-between-values-terms-types-and-kinds">Relationship between values, terms, types, and kinds</a></td>
    </tr>
    <tr>
      <td><a href="#The-difference-between-type-and-type-level">The difference between “type” and “type-level”</a></td>
    </tr>
    <tr>
      <td><a href="#type-families">Type families</a></td>
    </tr>
    <tr>
      <td><a href="#associated-types">Associated types</a></td>
    </tr>
    <tr>
      <td><a href="#TypeLits">GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#Distinguishing-between-DataKinds-and-TypeLits">Distinguishing between DataKinds and GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#use-case-Marshaling-ASTs">Use-case: Marshaling ASTs</a></td>
    </tr>
    <tr>
      <td><a href="#The-hype-of-dependently-typed-langs">The hype of dependently-typed languages</a></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="types-vs-values">Types vs. Values</h3>

<p>As mentioned above, Haskell programs are divided into two worlds: the <em>type-level</em> and the <em>value-level</em>. The <em>type-level</em> refers to the part of a program analyzed by the static type-checking phase during compilation. Since every expression is assigned a type, code is checked against Haskell’s type system to ensure it fits <a href="https://www.haskell.org/ghc/">GHC</a>’s specified correctness criteria.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704534-fce9fd80-af27-11ea-9544-13961a56c444.png" alt="types classify terms, just like hostile teens with identity crises classify one another"></p>

<p>If the program is well-typed, the program will compile. However, this type-information evaporates once the compilation process terminates, leaving only <em>values</em> behind at run-time. In this way, types and values can be better distinguished by the phasing distinction, with types being compile-time entities and values being run-time entities.</p>

<p>For example, if a function takes a <code>String</code>, the type-checker doesn’t care if the <code>String</code> has a value denoted by <code>"abc"</code> or <code>"123"</code> or <code>"get in loser"</code>—so long as it’s a <code>String</code>. Type information gets discarded at run-time, leaving only the string’s value (ex.,<code>"get in loser"</code>). In some cases, however, we want the type system to care about what those values are and distinguish between them. The <code>DataKinds</code> extension, which we’ll explore below, lets us do that by allowing us to shove more information about our program into the type system. This lets us add meaning to the value of a <code>String</code> at the type-level, moving them from their usual, strictly run-time existence, into the compile-time phase. The technique allows us to use more information statically in the logical development and abstraction of the program’s behavior. We’re also able to add consequences that can halt compilation if the specific value of <code>String</code> doesn’t conform to the rules we’ve specified, or define classes over them.</p>

<h4 id="distinguishing-types-and-values-in-ghci">Distinguishing types and values in GHCi</h4>

<p>Let’s examine our aforementioned <code>SpringFlingQueen</code> datatype in GHCi. When we query the type of one of its constructors using <code>:t</code> (a handy shorthand for <code>:type</code>), we see that it is indeed of type <code>SpringFlingQueen</code>:</p>

<div><div><pre><code>λ data SpringFlingQueen = Cady | Regina
λ :t Cady
Cady :: SpringFlingQueen
</code></pre></div></div>

<p>Now consider literals <code>1</code>, <code>2</code>, <code>3</code>. These are <em>values</em> of a type that parameterizes the <code>Num</code> class:</p>



<p>Typing <code>:t 1</code> into GHCi gives us <code>Num p =&gt; p</code>, indicating that a literal such as <code>1</code> can be of any polymorphic type <code>p</code> as long as the <code>Num</code> type class has instances for that type (for example, <code>Integer</code> and <code>Float</code> both have <code>Num</code> instances and therefore are valid types that <code>p</code> could be instantiated with). This is possible due to <a href="https://wiki.haskell.org/Type_inference">type inference</a>.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704346-ae3c6380-af27-11ea-8078-6f1ddfc7b238.png" alt="type inference can be used to deduce concrete types wherever they're obvious. If a type looks like a mouse, it's a mouse—duh!"></p>

<h3 id="kinds">Kinds</h3>

<p>Just like types classify terms, <a href="https://www.haskell.org/onlinereport/decls.html#sect4.1.1">kinds</a> classify types, and therefore are frequently described as “types of types”, or referred to be “one level up.” The “star” syntax (i.e., <code>*</code>) denotes kinds. It is defiantly used in this post despite <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0143-remove-star-kind.rst">recent syntactic changes</a>. A prerequisite for understanding the kind system necessitates comprehending the differences between three pairs of ideas:</p>

<ol>
  <li>
    <p><strong>Data constructors vs. type constructors:</strong> data constructors create values, whereas type constructors create types. Type constructors take one or more type arguments and produce a datatype when enough arguments are provided. This means that through <a href="https://wiki.haskell.org/Currying">currying</a>, a type constructor can be <a href="https://wiki.haskell.org/Partial_application">partially applied</a>. For example, the list type constructor <code>[]</code> may take a single type argument (ex. <code>String</code>) to denote the elements of the list (i.e., <code>[String]</code>). <code>[String]</code> is simply syntactic sugar for <code>[] String</code>, where the type <code>[]</code> is applied to <code>String</code>.</p>
  </li>
  <li>
    <p><strong>Full vs. partial application</strong> A partially-applied type, like a <a href="https://wiki.haskell.org/Partial_application">partially-applied function</a>, is one that is missing some of its data constructors. For instance, consider the list type <code>[]</code>. The kind of <code>[]</code> is <code>* -&gt; *</code>. A fully-applied list has data constructors, such as <code>[Int]</code>, and its kind is <code>*</code>.</p>
  </li>
  <li>
    <p><strong>Inhabited types vs. uninhabited types:</strong> An inhabitant of a type is precisely a value of that type. This means that <em>inhabited</em> types refer to the types that contain concrete values, such as the value denoted by the term <code>1 :: Int</code>. This suggests that the type <code>Int</code> is inhabited by value denoted by <code>1</code>. By contrast, <em>uninhabited</em> types refer to type constructors to which no values are abstracted. For instance, <code>Void</code> is uninhabited because it has no data constructors, and thus can not be used to construct a valid term. While <code>Void</code> may seem pointless at first, it can be a useful way to represent that a container is empty (ex., <code>[Void]</code>, which <em>is</em> inhabited by the term <code>[]</code> and the value this term denotes).</p>
  </li>
</ol>

<p>How do these ideas relate to the kind system? Well, all fully-applied runtime values are of kind <code>*</code> <em>and</em> they are inhabited. You can confirm this by typing <code>:k Int</code> and <code>:k String</code> in GHCi. However, this doesn’t work the other way around—just because a type is inhabited, doesn’t necessarily mean it’s fully-applied (ex., <code>[]</code> is not fully-applied but it <em>is</em> inhabited, and its kind signature is <code>* -&gt; *</code>). Conversely, all partially-applied types are uninhabited (since they don’t correspond to a value), but not all uninhabited types are partially applied. <code>Void</code> for instance is not partially-applied, but it is uninhabited.</p>

<p>To get the hang of this idea, consider the following examples:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Inhabited?</th>
      <th>Fully-applied?</th>
      <th>Kind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Int</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>String</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>[]</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>[Int]</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>(,)</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Either</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Void</code></td>
      <td>No</td>
      <td>N/A</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>Either Void Void</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
  </tbody>
</table>

<p>Kind signatures can be specified manually in GHCi using the <a href="https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures"><code>XKindSignatures</code></a> extension. Try extending the above table by investigating the kind signatures of various types.</p>

<h3 id="higher-kinded-types">Higher-kinded types</h3>

<p>Just like there are higher-order functions (functions that take other functions as arguments), there are higher-kinded types (types constructors that take other type constructors as arguments). Type constructors such as <code>[]</code> are a first-class type, but also a higher-kinded type, given they take another type constructor to be reified:</p>



<p>Let’s consider <code>Functor</code>:</p>

<div><div><pre><code>λ :k Functor
Functor :: (* -&gt; *) -&gt; Constraint
</code></pre></div></div>

<p>We see that <code>Functor</code> takes a type constructor <code>* -&gt; *</code> and returns a <code>Constraint</code>. Let’s use <code>:info</code> to examine <code>Functor</code> a bit more closely:</p>

<div><div><pre><code>λ :info Functor
class Functor (f :: * -&gt; *) where
  fmap :: (a -&gt; b) -&gt; f a -&gt; f b
  (&lt;$) :: a -&gt; f b -&gt; f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor ((,,,) a b c) -- Defined in ‘Data.Orphans’
instance Functor ((,,) a b) -- Defined in ‘Data.Orphans’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((-&gt;) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
</code></pre></div></div>

<p>We see that <code>Functor</code> allows type constructors like <code>Maybe</code> and <code>[]</code> to have <code>Functor</code> instances, but not <code>Int</code> or <code>String</code>. This is because <code>Maybe</code> and <code>[]</code> are <code>* -&gt; *</code>, while <code>Int</code> has kind <code>*</code>. Similarly, <code>Either</code> has <code>* -&gt; * -&gt; *</code>, which is why its instance above is parameterized with a type parameter denoting something of kind <code>* -&gt; *</code>: <code>Either a</code>.</p>

<h3 id="constraint-kinds">Constraint kinds</h3>

<p>We got a glimpse of constraint kinds …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</a></em></p>]]>
            </description>
            <link>https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667675</guid>
            <pubDate>Sun, 28 Jun 2020 09:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ELF: Better Symbol Lookup via Dt_gnu_hash (2017)]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23667520">thread link</a>) | @fanf2
<br/>
June 28, 2020 | https://flapenguin.me/elf-dt-gnu-hash | <a href="https://web.archive.org/web/*/https://flapenguin.me/elf-dt-gnu-hash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2017-05-10">2017-05-10</time> |<p><code>DT_GNU_HASH</code> is a better hash table for the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a> used by GNU systems in GNU-compatible software, i.e. in almost every program compiled with gcc or clang for almost any Linux distribution.</p><p>The problem with it is that <code>DT_GNU_HASH</code> is not documented anywhere other than in <a href="https://www.gnu.org/software/binutils/">GNU binutils</a> and <a href="https://www.gnu.org/software/libc/">glibc</a> source code. You can either read source code to get some intel, or read emails with patches in mail list archives (<a href="https://sourceware.org/ml/binutils/2006-10/msg00377.html">Re: GNU_HASH section format</a> is a pretty good one). Those are the only places you can try to find the truth on the matter.</p><p>Of course, there're some articles on the web where people try to break it down. Like this one.</p><p>This article does not aspire to be the ultimate truth either. But I'll try to cover everything about GNU Hash Table and explain all aspects of its work.</p><p>Before reading any further please ensure that you understand what <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.symtab.html">Symbol Table</a> and <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.strtab.html">String Table</a> are in the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a>. Also you may want to read my previous article <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> to know the standard (90s-ish) way of doing symbol lookup.</p><p><code>DT_GNU_HASH</code> has nothing in common with standard <code>DT_HASH</code>, apart from serving the same purpose. It has its own hashing function, its own layout, it adds restrictions for the symbol table and contains an additional <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to stop lookup for missing symbols early.</p><h2>Hashing function</h2><p>Let's start with the hashing function. It can be found in <a href="https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;a=blob;f=bfd/elf.c;h=a08e0f8ea6197f103908364665ec6e5f6c89927d;hb=HEAD#l222">bfd_elf_gnu_hash</a> or in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l569">dl_new_hash</a>.</p><pre><span>#<span>include</span> <span>&lt;stdint.h&gt;</span></span>

<span><span>uint32_t</span> <span>gnu_hash</span><span>(<span>const</span> <span>uint8_t</span>* name)</span> </span>{
    <span>uint32_t</span> h = <span>5381</span>;

    <span>for</span> (; *name; name++) {
        h = (h &lt;&lt; <span>5</span>) + h + *name;
    }

    <span>return</span> h;
}

gnu_hash(<span>""</span>)                == <span>0x00001505</span>
gnu_hash(<span>"printf"</span>)          == <span>0x156b2bb8</span>
gnu_hash(<span>"exit"</span>)            == <span>0x7c967e3f</span>
gnu_hash(<span>"syscall"</span>)         == <span>0xbac212a0</span>
gnu_hash(<span>"flapenguin.me"</span>)   == <span>0x8ae9f18e</span>
</pre><h2>Layout</h2><p>Not a valid C code, but gives an idea:</p><pre><span><span>struct</span> <span>gnu_hash_table</span> {</span>
    <span>uint32_t</span> nbuckets;
    <span>uint32_t</span> symoffset;
    <span>uint32_t</span> bloom_size;
    <span>uint32_t</span> bloom_shift;
    <span>uint64_t</span> bloom[bloom_size]; 
    <span>uint32_t</span> buckets[nbuckets];
    <span>uint32_t</span> chain[];
};
</pre><h2>Bloom filter</h2><p><a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filter</a> is used to stop the lookup for missing symbols early. <code>bloom_size</code>, <code>bloom_shift</code>, and <code>bloom</code> are parts of the structure, as their names suggest.</p><p>Bloom filter behaves slightly differently for various <code>ELFCLASS</code> binaries (defined by <code>EI_CLASS</code> field in <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html#elfid">ELF Identification</a>). Let's define <code>ELFCLASS_BITS</code> to be <code>64</code> for 64-bit binaries (<code>ELFCLASS64</code>) and <code>32</code> for 32-bit binaries (<code>ELFCLASS32</code>).</p><p>Before doing symbol lookup, take <code>bloom[(hash / ELFCLASS_BITS) % bloom_size]</code>. If bits <code>hash % ELFCLASS_BITS</code> and <code>(hash &gt;&gt; bloom_shift) % ELFCLASS_BITS</code> are set then a symbol <strong>may or may not</strong> be in the hash table, and you should proceed with a regular lookup through buckets and chains. But if at least one bit is not set then a symbol is <strong>certainly</strong> absent from the hash table.</p><h2>Buckets and chains</h2><p><code>DT_HASH</code> contains an element per symbol table's element. This leads to a waste of space because <code>STN_UNDEF</code> and some other symbols are in the hash table but are never looked up. GNU hash table allows to skip first <code>symoffset</code> symbols at the beginning of the symbol table.</p><p>Same as in <code>DT_HASH</code>, symbols are put in one of <code>nbuckets</code> buckets depending on their hashes. To be specific, each symbol should be placed into <code>hash % nbuckets</code> bucket.</p><p>Chains in the GNU hash table are nothing like strange linked lists in <code>DT_HASH</code>, they are contiguous sequences of hashes for symbols with the same index (remember that chains' indexes are shifted by <code>symoffset</code> relatively to the symbol table). The last bit in chains' element is discarded and instead used for indicating the chain's end. If it is set then the element is the last one in the chain.</p><p><code>bucket</code> array holds indexes of the first symbols in the chains. Note that those are not indexes for the <code>chain</code> array. Indexes for it will be <code>bucket[foobar] - symoffset</code>.</p><p>Chains being contiguous sequences imply that symbols within the same bucket must be stored contiguously. Order of buckets in the symbol table does not really matter but usually they're stored in an ascending order.</p><p>While looking extraneous, creating such restriction over the symbol table gives great advantage: a hash table now can store almost full hash (without the lowest bit) of a symbol within the same 32 bits. This allows linkers to compare hashes before comparing strings. Also, because <code>DT_GNU_HASH</code> requires symbol table ordering and <code>DT_HASH</code> doesn't, you can fit both into a single binary. This way both standard and GNU linkers can look up symbols in it.</p><h2>Example</h2><p>Nothing is better than a visual representation of the rules. So, let's create one.</p><p>I took the same symbols as in <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> and created <code>DT_GNU_HASH</code> table from them. The example is for 64-bit ELF binaries, for 32-bit you'll need to recalculate bloom word and bits.</p><pre>nbuckets = 4      (because I decided that there will be four buckets)
symoffset = 1    (STN_UNDEF is not a part of the hash table)
bloom_size = 2   (because I decided that 16 byte bloom filter is sufficient)
bloom_shift = 5  (again, just because I can)

ix  bucket[ix]  name of first symbol in chain
--  ----------  -----------------------------
 0  1           cfsetispeed
 1  5           uselib
 2  8           freelocal
 3  13          getspen

Note that:
- symbol table is sorted by bucket
- chain[ix] is the same as hash but with set/cleared lowest bit

       SYMBOL TABLE              |              GNU HASH TABLE
                                 |
    name =                       |    hash %              bloom  bloom bits
ix  symtab[ix].st_name    hash   | ix nbuckets chain[ix]  word   #0    #1
--  ------------------  -------- | -- -------  ---------- -----  ---   ---
 0  &lt;STN_UNDEF&gt;                  |
 1  cfsetispeed         830acc54 |  0    0      830acc54    1    20    34
 2  strsigna            90f1e4b0 |  1    0      90f1e4b0    0    48    37
 3  hcreate_            4c7e3240 |  2    0      4c7e3240    1     0    18
 4  endrpcen            b6c44714 |  3    0      b6c44715    0    20    56
 5  uselib              2124d3e9 |  4    1      2124d3e8    1    41    31
 6  getttyen            fff51839 |  5    1      fff51838    0    57     1
 7  umoun               1081e019 |  6    1      1081e019    0    25     0
 8  freelocal           e3364372 |  7    2      e3364372    1    50    27
 9  listxatt            ced3d862 |  8    2      ced3d862    1    34     3
10  isnan               0fabfd7e |  9    2      0fabfd7e    1    62    43
11  isinf               0fabe9de | 10    2      0fabe9de    1    30    14
12  setrlimi            12e23bae | 11    2      12e23baf    0    46    29
13  getspen             f07b2a7b | 12    3      f07b2a7a    1    59    19
14  pthread_mutex_lock  4f152227 | 13    3      4f152226    0    39    17
15  getopt_long_onl     57b1584f | 14    3      57b1584f    1    15     2

Bloom filter:
   bit #      56       48       40       32       24       16        8        0
        xx..x.xx ...xxx.x xx...... x.x.xx.x ..x...x. ...x..x. ........ ......xx
        .x..x... .....x.. ....x.x. .....x.. xx..x.xx ...xxx.x xx...... x.x.xx.x

Or as two `uint64_t` values:
    cb1dc0ad22120003
    48040a04cb1dc0ad
</pre><p>Knowing the rules and having a built table, let's try to find some symbols by hand.</p><p>Note that when comparing hashes the lowest bit is set on both left and right hand sides.</p><ol><li><p>Existing symbol. <code>strsigna</code>:</p><pre>looking for "strsigna" (hash = 0x90f1e4b0)
checking word 0 in bloom filter for bits 48 and 37
        hash table may contain symbol
starting at ix = 1

compare hashes: (chain) 0x830acc55 == 0x90f1e4b1
wrong hash definitely not "strsigna"
moving to the next symbol

compare hashes: (chain) 0x90f1e4b1 == 0x90f1e4b1
hash matches. compare strings: "strsigna" == "strsigna"
found at index 2
</pre></li><li><p>Missing symbol. <code>foobar</code>:</p><pre>looking for "foobar" (hash = 0xfde460be)
checking word 0 in bloom filter for bits 62 and 5
        not in bloom filter
not found
</pre></li><li><p>Missing symbol with hash collision. <code>vLoun</code>:</p><pre>looking for "vLoun" (hash = 0x1081e019)
checking word 0 in bloom filter for bits 25 and 0
        hash table may contain symbol
starting at ix = 5

compare hashes: (chain) 0x2124d3e9 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0xfff51839 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0x1081e019 == 0x1081e019
hash matches. compare strings: "umoun" == "vLoun"
just hash collision
that was last symbol in this bucket
not found
</pre></li></ol><h2>Code</h2><p>Original algorithm is implemented in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l350">do_lookup_x</a> in <code>ld.so</code> source code.</p><p>Implementation is a little trickier than <code>DT_HASH</code>'s one, but with the example above it should be self-explanatory.</p><pre>
<span>typedef</span> Elf64_Sym Elf_Sym;
<span>typedef</span> <span>bloom_el_t</span> <span>uint64_t</span>;
<span>#<span>define</span> ELFCLASS_BITS 64</span>


<span><span>const</span> Elf_Sym* <span>gnu_lookup</span><span>(
    <span>const</span> <span>char</span>* strtab,      
    <span>const</span> Elf_Sym* symtab,   
    <span>const</span> <span>uint32_t</span>* hashtab, 
    <span>const</span> <span>char</span>* name         
)</span> </span>{
    <span>const</span> <span>uint32_t</span> namehash = gnu_hash(name);

    <span>const</span> <span>uint32_t</span> nbuckets = hashtab[<span>0</span>];
    <span>const</span> <span>uint32_t</span> symoffset = hashtab[<span>1</span>];
    <span>const</span> <span>uint32_t</span> bloom_size = hashtab[<span>2</span>];
    <span>const</span> <span>uint32_t</span> bloom_shift = hashtab[<span>3</span>];
    <span>const</span> <span>bloom_el_t</span>* bloom = (<span>void</span>*)&amp;hashtab[<span>4</span>];
    <span>const</span> <span>uint32_t</span>* buckets = (<span>void</span>*)&amp;bloom[bloom_size];
    <span>const</span> <span>uint32_t</span>* chain = &amp;buckets[nbuckets];

    <span>bloom_el_t</span> <span>word</span> = bloom[(namehash / ELFCLASS_BITS) % bloom_size];
    <span>bloom_el_t</span> mask = <span>0</span>
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; (namehash % ELFCLASS_BITS)
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; ((namehash &gt;&gt; bloom_shift) % ELFCLASS_BITS);

    
    <span>if</span> ((<span>word</span> &amp; mask) != mask) {
        <span>return</span> <span>NULL</span>;
    }

    <span>uint32_t</span> symix = buckets[namehash % nbuckets];
    <span>if</span> (symix &lt; symoffset) {
        <span>return</span> <span>NULL</span>;
    }

    
    <span>while</span> (<span>true</span>) {
        <span>const</span> <span>char</span>* symname = strtab + symtab[symix].st_name;
        <span>const</span> <span>uint32_t</span> hash = chain[symix - symoffset];

        <span>if</span> ((namehash|<span>1</span>) == (hash|<span>1</span>) &amp;&amp; <span>strcmp</span>(name, symname) == <span>0</span>) {
            <span>return</span> &amp;symtab[symix];
        }

        
        <span>if</span> (hash &amp; <span>1</span>) {
            <span>break</span>;
        }

        symix++;
    }

    <span>return</span> <span>NULL</span>;
}
</pre><h2>Total …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flapenguin.me/elf-dt-gnu-hash">https://flapenguin.me/elf-dt-gnu-hash</a></em></p>]]>
            </description>
            <link>https://flapenguin.me/elf-dt-gnu-hash</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667520</guid>
            <pubDate>Sun, 28 Jun 2020 08:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS for Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23667310">thread link</a>) | @jordybg
<br/>
June 28, 2020 | https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/ | <a href="https://web.archive.org/web/*/https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-814">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<p>In this video, we take alike at Twister Os for the Raspberry Pi 4!</p>
<p>This is a new Linux distro from the creators of iRaspbian and RaspbianX and it allows you to swap between the Windows 10 look of Raspbian X nighthawk or the OSX look of iRaspbian!</p>
<p>This version does support Box86, Steam, Android mirroring on the desktop, Box86, Chromium Media edition for watching Netflix, HULU, and Disney Plus!</p>
<p>This Project is Mind-Blowing and works amazingly on The Raspberry Pi4!</p>
<p>Download it here: <a href="https://raspbian-x.com/" target="_blank" rel="noopener noreferrer">https://raspbian-x.com/</a><br>Pilabs YouTube channel: PiLabs Channel: <a href="https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g" target="_blank" rel="noopener noreferrer">https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g</a><br>PiLabs Discord: <a href="https://discord.com/invite/Fh8sjmu" target="_blank" rel="noopener noreferrer">https://discord.com/invite/Fh8sjmu</a></p>
<p><strong>Need a Pi4?</strong><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/sWKS">SD Cards</a><br><a href="https://geni.us/rPFYi">Ice Tower cooler</a></p>
<p><a href="https://twitter.com/ProjectsPi">Follow Me On Twitter</a></p>
<p><strong>Equipment I Use:</strong><br><a href="https://geni.us/JkNt">Screen Capture Device</a><br><a href="https://geni.us/BQ5nyKn">Tool Kit</a><br><a href="https://geni.us/wOtA">Soldering Station</a><br><a href="https://geni.us/vxAxn">Camera</a><br><a href="https://geni.us/Utll">Tripod</a><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/xqMj">Flirc Case</a></p>
<p>DISCLAIMER: This video and description contains affiliate links, which means that if you click on one of the product links, I’ll receive a small commission at no extra cost to you!</p>
<p>This video and Channel and Video are for viewers 14 years older and up. This video is not made for viewers under the age of 14. If you are under 14 years of age, you do not have permission to view this video.</p>
<p>THIS VIDEO IS FOR EDUCATIONAL PURPOSES ONLY!</p>
<p>#RaspberryPi #Pi4 #TwisterOS</p>


<figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/TX7tArVdf80?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/x4dX7mc9zI4?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/La67o7aodJY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<!-- AI CONTENT END 1 -->
					</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667310</guid>
            <pubDate>Sun, 28 Jun 2020 07:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Half of Canadians would support 30-hour work week: poll]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23667134">thread link</a>) | @chewdatgenie
<br/>
June 27, 2020 | https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/ | <a href="https://web.archive.org/web/*/https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Workers get set to pour cement from a truck at the GO train station in Oakville, Ont., Tuesday, Jan.28, 2020. A new report by the Angus Reid Institute suggests the majority of Canadians support the idea of a shorter work week. (Richard Buchan/THE CANADIAN PRESS)</p><div>
                    <p>Support for the idea of a shorter work week is growing in popularity in Canada as the COVID-19 pandemic continues to upend the working lives of Canadians, according to a <a href="http://angusreid.org/four-day-work-week/" target="_blank" rel="noopener noreferrer">new study by the Angus Reid Institute</a>.</p>
<p>More than half of Canadians (53 per cent) surveyed by the non-profit research centre said it would be a good idea to make a new 30-hour work week standard in Canada, the study found.</p>
<p>That’s a six-point increase compared to 2018 and more than twice the number of people who feel the present 40-hour workweek is just fine, the survey said.</p>
<p>Researchers at the institute speculate that the increase in support for a shorter workweek is perhaps driven in part by the COVID-19 pandemic and difficulties it has presented for many out of work Canadians.</p>
<p>The proportion of supporters of a 30-hour workweek rises to 58 per cent among those who have applied for the Canada Emergency Response Benefit. This is eight-points higher than those who have not applied for the program, the study found.</p>
<p>Support for a shorter workweek is highest at the lowest levels of household income (64 per cent) and lowest among those with incomes over $150,000 per year (47 per cent).</p>
<p>Past Conservative voters are the most fervent in their opposition to the idea of a shorter workweek.</p>
<p>This group is most likely to say that shortening the work week is an ill-conceived idea, 40 per cent feel this way, while two-thirds of past Liberal and New Democratic Party voters voice support for the measure.</p>
<h5>‘An interesting notion’</h5>
<p>Ricardo Tranjan, senior researcher at the Canadian Centre for Policy Alternatives, said “30 for 40”, thirty hours work for forty hours pay, is an interesting notion, and one that should be widely discussed, even beyond the COVID-19 context.</p>
<p>Shorter working weeks would allow workers to participate more actively in their children’s education, spend more time caring for their own parents and engage in leisure and physical activities that would have a positive impact on their health, Tranjan said.</p>
<p>Ten additional hours at home could go a long way in alleviating “double shifts,” which burden women disproportionately more than men, he said.</p>
<p>“But I have two critical concerns,” Tranjan said. “First, this can’t happen unless wages are adequate. We would absolutely need to maintain the same wage levels for shorter weeks, but for some workers, that wouldn’t be enough.”</p>
<p>People who work 40 hours a week at the minimum wage are very likely to have household incomes close to the poverty line, he said.</p>
<p>“If we reduce hours for these workers, they’re likely to pick up extra shifts, hoping that will allow them to afford things like new winter jackets for the kids or more and healthier food for the family,” Tranjan said.</p>
<p>“Meantime, higher-wage workers will be enjoying all the benefits of shorter weeks, so we’ll be just exacerbating social inequalities.”</p>
<p>Tranjan said his second concern has to do with eligibility for income supports, which is often tied to working hours.</p>
<p>“For example, will employment insurance eligibility be reduced if weeks are reduced? Or will we end up with even fewer people qualifying for EI benefits?” Tranjan said. “We need to tackle these questions heads on, but we should continue to have this conversation.”</p>
<h5>Business owners not buying it</h5>
<p>Dan Kelly, president of the Canadian Federation of Independent Business (CFIB), which has more than 100,000 members, said it should surprise no one that the majority of Canadians like the idea of a four-day work week.</p>
<p>“The only people who would say no to such an idea are those that immediately recognize that this would likely require a 20 per cent reduction in their weekly pay or the massive unemployment that would occur if businesses were required to pay the same for fewer working hours,” Kelly said. “I would like six months of vacation and double my salary – that doesn’t mean it would be a reasonable request.”</p>
<p>Half of small Canadian businesses remain fully or partially closed due to the pandemic and most of those open now will be losing money every week they are open for months and months ahead, Kelly said.</p>
<p>Businesses have been hit with multiple months of lost productivity, rising debt and the costs of the personal protective equipment they now have to procure, Kelly said.</p>
<p>“Shorter work weeks at the same rate of pay for their staff would be an impossibility for nearly every business at this time,” Kelly said.</p>
<p>Twelve per cent of independent businesses report they are considering winding down or going bankrupt, he added.</p>
<p>“There could be 100,000 fewer small businesses before this is over,” Kelly said. “Let’s not push that number even higher.”</p>
                    
                                        
                                    </div></div>]]>
            </description>
            <link>https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667134</guid>
            <pubDate>Sun, 28 Jun 2020 06:44:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Up Animation as a Hobby]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23667083">thread link</a>) | @luu
<br/>
June 27, 2020 | http://yosefk.com/blog/a-better-future-animated-post.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/a-better-future-animated-post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em>Whatever else happens, you made a movie… Nobody can take that away. A hundred years from now, when we're all dead and gone, people will be watching this fucking thing.</em></p>
<p><em>– <a href="http://en.wikipedia.org/wiki/Tony_Soprano">Tony Soprano</a> to his nephew (whom he murders over this movie in a few episodes)</em></p>
<p>So I made a 90-second animated, um, I guess it's a blog post. I don't know about a hundred years from now, but I proudly invite you to watch the fucking thing right now:</p>
<p><iframe src="//www.youtube.com/embed/xTOHyWphzFc" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>I hear that it's considered classy for animators, filmmakers and such to let their work stand on its own, either refraining from commentary or making it vague. However, anxious to secure my spot in eternity, I decided to rush my immortal masterpiece out the door, so I cut everything I could.</p>
<p>I then realized that I left out a delicate point which, despite my embarrassment, I must mention. Luckily, typing is much easier than animating, so the following afterthought was quick to put down [1]. Here goes.</p>
<p>The short isn't exactly a documentary, but real-life me did switch to a part-time job to free some time for animating, drawing, etc. I figured this mundane little step was a good topic for a starting filmmaker because it turned out to be surprisingly controversial. Here are some of the reactions I received:</p>
<ul>
<li>"So you finally got fed up with the job?"</li>
<li>"Part-time? But everyone here <em>needs</em> you!"</li>
<li>"Wow, I'm jealous! I want to work less, too. They pay you the same, right?" No, they pay less, I said. "Oh. Ha-ha. Work less, get less. Interesting!"</li>
<li>"You should really work more, not less, while you're young. Futurists predict a huge global pension crisis, so save for your retirement!"</li>
<li>"I doubt this will fly with the big deadline coming. Who's gonna do all the work? Not me!" (This guy works part-time himself – very productively.)</li>
<li>"Doesn't your wife object?" (Actually, my light table is Rachel's gift. I don't know when/if I'd ever get one on my own.)</li>
</ul>
<p>These comments suggest that many people want to work less, but something is keeping them from doing it. I can certainly relate to that. It took me 10 years to decide to work part-time – and then <em>5 more years to actually do it</em>.</p>
<p>Why is it so hard?</p>
<p>My own reasons mostly revolve around money. Where I live, money is much easier to make programming than animating (good luck even finding a half-stable job working on animated features.)</p>
<p>Hence "I went into programming for the money", as I said in the short – as I always say. And initially I figured I'd work all I can and retire early – the opposite of working part-time and animating in my spare time ("settling for a fraction of the dream"). And you've just seen how I changed my mind.</p>
<p>But there's another thing, which I usually<em> don't </em>say and which I must reluctantly admit. You see, I came for the money, and then I started liking the <em>getting paid</em> part.</p>
<p>What's the difference between money and getting paid? There's a world of difference!</p>
<p>Winning a lottery is a way to obtain money without getting paid for a service. And spending your wage on designer clothes is a way to get paid without having any money left. The difference is this:</p>
<ul>
<li><strong>Money</strong> lets you buy things – food, living space, spare time, etc. It's about <strong>options</strong>.</li>
<li><strong>Getting paid</strong> tells you the value of your service to whoever paid you. It's about <strong>achievement</strong>.</li>
</ul>
<p>I like getting paid, I must admit despite the embarrassment.</p>
<p>Note that I'm not ashamed in the slightest to like money (options) and to have chosen a profession with the sole purpose of maximizing income.</p>
<p>Some people believe that you can't be happy doing something you don't love – and that you can't be any good at it, hence you won't make that much money, either. I disagree.</p>
<p>I'll tell you who my role model is, as a computer programmer. It's neither Bill Gates nor <a href="http://en.wikipedia.org/wiki/Richard_stallman">Richard Stallman</a>. My role model is <a href="http://en.wikipedia.org/wiki/Alec_Guinness">Alec Guinness</a>, whom you probably remember as Obi-Wan Kenobi from Star Wars. Wikipedia says:</p>
<blockquote><p>In letters to his friends, Guinness described the film as "fairy tale rubbish" &lt;…&gt;</p>
<p>He was one of the few cast members who believed that the film would be a box office hit;&nbsp; he negotiated a deal for 2% of the gross royalties &lt;…&gt;</p>
<p>Lucas and fellow cast members … have spoken highly of his courtesy and professionalism, both on and off the set. Lucas &lt;said&gt; that Guinness contributed significantly to achieving completion of the filming.</p></blockquote>
<p>Here's a man working on something he disliked because it paid – and delighting his target audience and colleagues alike. To me it shows that "extrinsic motivation" – money – is a perfectly good primary motivation, contrary to <a href="http://lemire.me/blog/archives/2014/07/09/extrinsic-motivations-are-harmful/">some researchers' conclusions</a>.</p>
<p>I'm in it for the money – hence, I'll never get bored and lose interest, as long as there's money to be made. I'll dutifully work on the unpleasant parts necessary to get things actually done (and get paid). Not liking programming that much, I try to keep my programs short and easy to maintain and extend – so I can program less.</p>
<p>These are all desirable traits – and not everyone genuinely loving programming has them. Think about it. Who's the better henchman – the psychopath murdering for the thrill, or the coldblooded killer who's in it for an early retirement? Same thing here.</p>
<p>I'm your perfect henchman. Pay me, give me some time alone with your computers, and when you come back, you'll find them doing your bidding. Of this I am not ashamed.</p>
<p>Recently, however, I noticed that I'm no longer the coldblooded henchman I used to be, that I started to enjoy the thrill of the kill for its own sake. And this I cannot admit without blushing.</p>
<p>That's what getting paid does to the weak-minded. It warped my value system. The phases of my transition – or should I say my moral decay – went something like this:</p>
<ol>
<li>I program because they pay me.</li>
<li>Programming is good because they pay me.</li>
<li>Programming is good.</li>
<li>Programming is good! I think I'll go program right now. Or read about it. Or write something about it. All in my spare time.</li>
</ol>
<p>And there you have it. <strong>"Achievement" has been redefined to mean "that thing you get paid for".</strong></p>
<p>This is how I ended up with a website dedicated largely to programming. Then a programming blog on the site and&nbsp;<a href="http://www.embeddedrelated.com/blogs-1/nf/Yossi_Kreinin.php">a similar blog elsewhere</a>. Then came the ultimate downfall: <a href="https://github.com/yosefk">open-source programs on GitHub</a>, written during evenings and weekends.</p>
<p>And I don't regret the writing. Keeping readers' attention on my very dry programming-related subjects is a worthy challenge for any starting storyteller.</p>
<p>But <em>programming for free? Me?</em> <a href="http://www.imdb.com/title/tt0468569/quotes">If you're good at something, never do it for free!</a> Oh, how the weak-minded have fallen.</p>
<p>Sometimes you need to hit rock bottom to begin rising. So it was with me. Realizing that I've just programmed for free for several weekends in a row made me think. Hard.</p>
<p>"I can't believe you," I said to myself. "All this money-chasing at least made some sense. But programming for free? Why not <em>draw</em> in your spare time instead? What's <em>wrong </em>with you?"</p>
<p>"Not so fast," said self. "For free or not, at least here you are doing something you're good at. You know you're good – you get paid for it! Would they pay you for drawing? Not so soon. Maybe never. Even if you're any good. <strong>In fact you'll never know if you're any good. </strong>Not if you're never paid. Nor if you're paid badly, which happens all the time in those arty parts of the world, even to the best. Why not stick to things you're <em>good</em> at – that you <em>know </em>you're good at?"</p>
<p>Could you believe this guy? Well, I wouldn't have any of that.</p>
<p>"You shameless, hypocritical, baiting-and-switching COWARD," I screamed at self at the top of my lungs. "You always said programming was for the money – to buy time, to buy that bloody creative freedom you kept chattering about! And now you say I should keep programming because I got good at it? But of course I got good – I've been doing it all this time! I could have gotten just as good at drawing – <strong>I still can</strong> – if I have the time!"</p>
<p>"And you say that now when I can afford some spare time," I went on, "I should regardless stick to what I'm good at, which by now is programming? Are you hinting that I won't ever draw very well? Is <em>that </em>why you suggested a career in programming in the first place – because you didn't believe I could draw? Was that chanting about needing money one big lie all along? Tell me, you lying bastard! I'm gonna -"</p>
<p>"OK, OK, chill, man, CHILL!" Self looked scared and unsettled. He clearly didn't see it coming. Now he was looking for some way to appease me. "You know," said self, "maybe you're right. Remember how you're always proud of taking a long-term view? Of how you care today about things 5, even 10 years ahead?"</p>
<p>I smiled smugly. Indeed I was proud of my long-term-centered, strategic thinking. <a href="http://en.wikipedia.org/wiki/Bob_Colwell">Bob Colwell</a> – the legendary computer architect – once said that it's the architect's duty to think about the long term, because nobody else will. I <em>so</em> identified with that. (Colwell and I are both computer architects, you see – just, um, of different calibers.)</p>
<p>"Well," said self, "you <em>should</em> be proud. Too many lose sight of the future because of today's small but pressing worries!"</p>
<p>"Yeah, yeah, yeah." I was losing my patience. "Thanks but no thanks for your brown-nosing. Listen, are you playing bait and switch on me again? What does this have to do with drawing?"</p>
<p>"But that's the point – it's the same thing," self exclaimed, "it's about long-term thinking! Sure, in the short term, maybe you're better at programming than drawing. But keep practicing and yes, of course you'll get good at drawing! Use your favorite superpower – your ability to imagine the future vividly, to practically live there – to overcome the temptation to stick to your comfort zone! Secure a better future today! Be the shrewd guy investing in a little unknown startup – yourself the would-be animator – to reap great benefits down the road! Be -"</p>
<p>"I get it. That's what I said though, isn't it? Let's practice – let's draw in the spare time."</p>
<p>"Sure. Sure! You're right," said self submissively. "I'm actually helping you, see? I'm telling you how to use your strengths to take the plunge!"</p>
<p>"Thaaaanks. You know what? We'll …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yosefk.com/blog/a-better-future-animated-post.html">http://yosefk.com/blog/a-better-future-animated-post.html</a></em></p>]]>
            </description>
            <link>http://yosefk.com/blog/a-better-future-animated-post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667083</guid>
            <pubDate>Sun, 28 Jun 2020 06:26:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we got our AWS bill to around 2% of revenue]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 224 (<a href="https://news.ycombinator.com/item?id=23666999">thread link</a>) | @grwthckrmstr
<br/>
June 27, 2020 | https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Server cost is usually not a concern for most funded startups, but for a boot strapped SaaS product like ours,&nbsp; it was important to have an AWS bill that is easy on the pocket and a little more proportional to the MRR.</p><p>‍</p><p>To that end when we started<a href="http://superlemon.xyz/" target="_blank"> superlemon.xyz</a> one of the first things I did was to find ways to consume the least amount of resources on the cloud. We currently serve a traffic of ~ 250 requests per second with our AWS setup.</p><p>‍<br></p><p>Most applications require certain common cloud resources and these include</p><p>‍<br></p><ul role="list"><li>Compute instances</li><li>Database instances</li><li>Caching instances</li><li>CDN&nbsp;</li><li>A web server that acts as a reverse proxy and load balancer</li></ul><p>‍<br></p><div><p>I will now go through each of these resources and talk about both the expensive way and the cheap way to implement them</p></div><p><strong>Compute instances</strong></p><p><strong>‍</strong><br></p><p>When it comes to compute instances, most people go with AWS EC2 instances. EC2 instances are the safest choice to make for running server applications as they are highly configurable, scalable and you can change the configuration on demand according to your needs. However, sometimes you do not really need this level of control on your compute instances and that brings us to <a href="https://aws.amazon.com/free/compute/lightsail/" target="_blank">AWS Lightsail</a>.</p><p>‍<br></p><p>Lightsail as the name suggests is a lightweight version of EC2. Under the hood Lightsail instances are actually EC2 instances, but this is not apparent to the user and unlike the highly configurable EC2, Lightsail comes with a fixed configuration that once you provision cannot be changed. The billing is also a fixed amount per month as opposed to EC2 which is billed by the hour.&nbsp;</p><p>‍<br></p><p>To give you a sense of how much less complicated Lightsail is, please take a look at these screenshots of the EC2 dashboard and Lightsail dashboard.</p><figure id="w-node-7afe1c2bdee3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef82a451ea3cd05dfd4c146_x93boOZlEeQGL9kcVSXPZyGOX3SNQJfDNyRC0qG3jNDCYeySdZpIgBzYgkVDZqq3DhR92f_Eqdp8sG-vIgkwltIW9ExWhshfDSsb-gd2qCah6E5VjydVhGxO4QFRA5qCR2KXqhP5.png" alt=""></p></figure><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-2074947a61a8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef737f4a33047deb1c0a4a6_ZMr0t2QqxGgPZ-Grg-TIHjpok_ujhoYzyHLQnsGzlSfLJj0wRrKWFMKNnVDwCoOorYJHs6j4aqKz_NgztOFGNSNc9Fw4nKGrwSRVK7E4hQtDkzE7OXIVaQp0lDjXxwjiKkHN1e3c.png" alt=""></p><figcaption>EC2 dashboard</figcaption></figure><p>‍</p><p>‍</p><p>But we are not here to debate the complexity of EC2 vs Lightsail, so let’s let us talk about the cost.</p><p>An EC2 instance with 2 virtual cores, 4GB RAM and a storage of 80GB costs roughly 37$ a month and a Lightsail instance with the exact same configuration costs 20$ a month which is almost half the cost!</p><p>‍<br></p><p>The only drawback here as previously mentioned is that the instance is fixed and neither the storage nor the compute power can be tweaked later according to spikes in traffic and usage.&nbsp;</p><p>‍<br></p><p>In our case we do not have a need for too much storage on the compute instance, and as for the computing power it was easy for us to simply provision another Lightsail instance when there is an increase in traffic and set it up behind a load balancer. This way our system is still scalable.</p><p><strong>Database instances</strong></p><p><strong>‍</strong><br></p><p>Choosing a database provider for your application can be a tricky decision, but on a high level there is just one thing that is absolutely required for any database provider - the ability to take regular backups of the DB automatically and the ability to restore the database from one of the backups.</p><p>‍<br></p><p>All of this functionality is provided by AWS RDS along with an array of other capabilities like autoscaling of storage, multiple availability zones, etc. However we did not not really need this level of control over the DB for our simple SaaS product, not to mention the fact that RDS would cost us a minimum of 200$ a month with the lowest acceptable configuration.&nbsp;</p><p>‍<br></p><p>Once again our saviour was Lightsail which provides managed Databases with a fixed storage at very cheap prices. Only MySQL and PostgreSQL are available though which was fine with us since I am quite comfortable with MySQL. We have currently provisioned one MySQL DB with 2 vCPUS, 4GB RAM and 120GB SSD and it costs us 60$ a month.</p><p>‍<br></p><p>And as mentioned before Lightsail provides the basic capabilities of backups and restoration.</p><figure id="w-node-e1f43dee380f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef731c812136072299e133c_Q2n6wprxbcqgh5vI97YqjWYkOYV52HGzRtHXIQFfpgxwlHkGaO8YDv3aO3V-PwM2SI4qxPty6ZMlK0siv1-lAizSl9hf_6RASDqzNrSfEmIeMdu8UeSTsRhu4Sk1Ofg6Uw8CPPuK.png" alt=""></p><figcaption>Database restoration from recent backup</figcaption></figure><p>‍</p><div><p>The drawback here is that the DB will not scale automatically so your will have to make sure that your application does not use storage beyond what is available in the instance you select. We do this by regularly purging our Database of data that is older than X days and data that belongs to users who churned from our app more than X days ago and haven’t come back since.&nbsp;</p></div><p><strong>Caching instances</strong></p><p><strong>‍</strong><br></p><p>For our application we needed a Caching layer as well as the ability to queue up jobs that can be executed asynchronously. The seasoned folks here might have realised that the best tool to use for this is Redis and AWS has a service called ElastiCache which is Redis under the hood.&nbsp;</p><p>‍<br></p><p>Once again this would be a very safe choice to make because it is completely managed and scalable. Our need was a Redis instance with at least 6GB of memory and 2vCPUs and if we went with ElastiCache our cost would roughly come out to be 112$ a month, not to mention the additional cost of running our async workers somewhere else.</p><p>‍<br></p><p>I might sound like a broken record at this point but what we ended up doing was to provision a Lightsail instance with 2vCPUs and 8GB of memory for the cost of 40$ a month and installed an open source version of Redis on this instance. We also use the same instance to run our asynchronous workers which read from the Redis queue and execute jobs.&nbsp;</p><p>‍<br></p><p>So what is the drawback? Well since it is not a managed service, you would have to monitor the Redis server yourself. There are many tools out there that help you do this and the one I would recommend is<a href="http://prometheus.io/" target="_blank"> prometheus.io</a>.</p><p>‍<br></p><p>This means that you have to do a little bit of extra work to setup metrics collection from your Redis instance and use a grafana dashboard where you can view these metrics, but this extra work saves a lot of money in the long run and you get to look at a super cool dashboard like this one</p><figure id="w-node-ed9ef23d383f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b6832df460f9189c1ef_8fAYGJqB0CXvglSTkg-wXPXqpKi2e3fusNyMcOaiepfnZ-dC1kjn2Do44sILw5lbKOSISB1CMTEdCzyqBcyggDwK4tJcDEA17xkWXb2J1tUjLHBJgtMa_t3ekfIUfOiImx5IaZd6.png" alt=""></p><figcaption>Grafana dashboard for monitoring redis instance</figcaption></figure><p><strong>CDN</strong></p><p><strong>‍</strong><br></p><p>Our application requires a javascript file to be loaded into the websites of our customers. This JS file gets a ton of traffic because this traffic scales according to how many visitors our customers get. Now this can be scary because it means we really had no idea how many requests the JS file might actually end up receiving so we hesitated to go with CloudFront which is the goto solution for a CDN on AWS.&nbsp;</p><p>‍<br></p><p>So we ended up taking an entirely different approach for this. Our application is a Shopify app and during the process of building the application we created a Shopify store. Every Shopify store gets its own personal CDN where you can manually upload anything and it will be served over the Shopify CDN. So we minified and uploaded our JS file to the CDN of our Shopify store and now we serve 20000 Shopify stores using this method at zero cost.</p><figure id="w-node-78b80f124ebd-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b68374cfd3932d127f5_z2vfALB6_5FJXMp4al-65PIczwKOE-wUb0TubqBXAFMiu0rnqPEKGAOl12Saf0Xn-Ay1DjWL7wIj7Vby1sNPfLHkpuXzHf17ytoJ5gQvql13DZl1BsIV2rJPeHgfnCnIdezWiddG.png" alt=""></p><figcaption>Shopify CDN&nbsp;that is free of cost</figcaption></figure><p>There is a glaring drawback to this approach. The Shopify store CDN does not provide an API that you can use to programmatically upload files and it has to be done manually. Also unlike CloudFront, there is no option of invalidating a file once it is uploaded. So If you have to make updates to your file you would have to upload a new file and migrate all of your existing users to this new file.&nbsp;<br></p><p>‍</p><p>This might sound like a big drawback, but it actually took me an hour to whip up a script that updates the JS file for all our existing 20000 stores to the updated JS file that I provide. So whenever I make a new release to this JS file, I simply upload a new file manually to the CDN, then take that file as the input and run this script and we re live! This approach works for us because we do not make too many releases to the JS&nbsp;file to begin with.</p><p><strong>Web server + load balancer</strong></p><p><strong>‍</strong><br></p><p>Every application requires the ability to route requests coming to their domain or subdomain to various applications running under the hood. The best way to do this is to use AWS ELB which can be used to automatically distribute incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions.&nbsp;</p><p>‍<br></p><p>This sounds quite fancy, but all we needed for our product was 4 things</p><p>‍</p><ul role="list"><li>Serving static files for our application dashboard</li><li>Distribute traffic among different Lightsail instances based on the path of the incoming URL</li><li>Load balance traffic that comes from our Merchants Shopify stores amongst N identical Lightsail instances.</li><li>Rate limiting of requests to prevent DDOS attacks.</li></ul><p>‍<br></p><p>All of this can be done using NGINX which is a great piece of software and is quite robust even with the default settings that it comes with.&nbsp;<br></p><p>So we simply installed a stable version of NGINX on one of our existing Lightsail instances which was already being used to host one of our server applications. We also use<a href="http://amplify.nginx.com/" target="_blank"> amplify.nginx.com</a> for monitoring it. This setup is pretty much equivalent to using a managed service at zero cost.</p><p>‍</p><figure id="w-node-26b2c44e15ee-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef730c34b26677e785fa7ea_w67-tKkFsy_LekSEhO_PXqnHGxDiREqENBgMBaEAOqotyjEDJoKXRk6Wpd5K86OOv2z_S-ejGOnL37l6lj6MWqE_x2ZvrIZ4FCQraAC1uDWMne7yi0Fme4Jap2sp2uH2zrKdvpTz.png" alt=""></p><figcaption>Amplify dashboard for monitoring health of the NGINX server</figcaption></figure><p>‍</p><p><strong>Summary</strong></p><p>‍</p><ul role="list"><li>Use lightsail instances (20$ per instance) instead of EC2 instances (37$ per instance)</li><li>Use a lightsail database (60$ per DB) instead of RDS (200$ per DB)</li><li>Use a self hosted redis server on a compute instance (40$) instead of ElastiCache (112$)&nbsp;</li><li>If feasible, use a free CDN (cost savings depends on traffic size)</li><li>Use a self hosted NGINX server (20$ fixed cost) instead of ELB (cost depends on traffic and usage)</li></ul><p><strong>Closing notes</strong></p><p><strong>‍</strong><br></p><p>I would like to put emphasis on the fact that we are a micro-SaaS product that solves a small and specific use case and therefore this kind of AWS setup worked for us. This may not work for big organisations or products where the traffic is erratic.&nbsp;</p><p>This setup will also not work for folks who have a ton of stuff to do already and would prefer to use managed services and not take the additional headache of monitoring, maintaining and provisioning hardware resources on a regular basis because this has a time cost to it.</p><p>We are a team of 2 people with a product that is not computation heavy and has cloud requirements that are quite straightforward. We have been running this product for a little over 1 year with this AWS setup and so far we have not encountered any problems.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666999</guid>
            <pubDate>Sun, 28 Jun 2020 05:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I learn UIKit or SwiftUI?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23666923">thread link</a>) | @sarunw
<br/>
June 27, 2020 | https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/ | <a href="https://web.archive.org/web/*/https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>            
      
<section>
<div>
    <div>        

      

      <hr>

      
        

      <p>SwiftUI feels very young when it first announced last year in WWDC19. It shows a promising future, but it has a rough edge here and there, and it quite hard to predict what it will be like in a year. The year has passed, and here is my thought on Apple's new declarative UI framework SwiftUI.</p>
<h2 id="the-gap-is-getting-closer">The gap is getting closer <a href="#the-gap-is-getting-closer">#</a></h2>
<p>My arguments around SwiftUI are always like, "You can't do x (UIKit features) in SwiftUI". This year, Apple show an incredible pace of SwiftUI development. The missing UI elements from last year already have a SwiftUI counterpart, e.g., <code>UIColelctionView</code> and <code>UITextField</code> already have a SwiftUI counterpart of <code>LazyH/VGrid</code> and <code>TextEditor</code>.</p>
<h2 id="first-class-citizen">First-class citizen <a href="#first-class-citizen">#</a></h2>
<p>It looks like SwiftUI doesn't want to be just a view for UIKit anymore. Now, you can write an entire app using pure SwiftUI.</p>
<p>The following is a working SwiftUI app code.</p>
<pre><code><span><span>import</span> <span>SwiftUI</span></span><br><span></span><br><span>@main</span><br><span><span>struct</span> <span>SwiftUIApp</span><span>:</span> <span>App</span> <span>{</span></span><br><span>    <span>var</span> body<span>:</span> some <span>Scene</span> <span>{</span></span><br><span>        <span>WindowGroup</span> <span>{</span></span><br><span>            <span>Text</span><span>(</span><span>"Hello! SwiftUI"</span><span>)</span></span><br><span>        <span>}</span></span><br><span>    <span>}</span></span><br><span><span>}</span></span></code></pre>
<p>And the code above not just works on iOS, but the same code can make an iPad and Mac app. You can write a multiplatform app entirely with SwiftUI. Seem like the concepts of SwiftUI are far more powerful than I first thought.</p>
<h2 id="exclusive-deal">Exclusive Deal <a href="#exclusive-deal">#</a></h2>
<p><a href="https://developer.apple.com/documentation/widgetkit" target="_blank" rel="nofollow noopener">WidgetKit</a>, a new framework in iOS 14 for writing a Widget can only write using SwiftUI. This means you can't run away from it, even you love UIKit, it seems like you have no choice, but to also learn SwiftUI.</p>
<figure>
  <img src="https://d33wubrfki0l68.cloudfront.net/29ba6373e9bf92bbbc301e0f6fb491f3cf51920a/819cd/images/swiftui-2-widget.png" alt="Widget">
  <figcaption>Widget</figcaption>
</figure>
<h2 id="is-uikit-going-to-die%3F">Is UIKit going to die? <a href="#is-uikit-going-to-die%3F">#</a></h2>
<p>Nope, it is far from over. I don't think Apple has a plan to drop UIKit in the foreseeable future. As working on UIKit for years, SwiftUI feels like magic to me. It can replicate UIKit function with a single line of code (or no line of code since it builds right into SwiftUI). The bad thing about magic is that when things are not going as you want, it is hard to figure out what's wrong, and it might not be possible to fix it. That's when you need to go back to UIKit. UIKit is a foundation of iOS, and Apple still keeps adding new features to it (UICollectionView and UISplitViewController got a lot of cool features this year, you should check it out).</p>
<p>I see UIKit as a secret sauce behind all SwiftUI magic. Both UIKit and SwiftUI have their strength, and Apple picks the right tool for the right job (they use SwiftUI for WidgetKit because it suits the constraint that Widget has right now). I think these two will coexist for a very long time.</p>
<p>Apple put years of experience in their UIKit and tools into SwiftUI. It is enjoyable to work with, and the outcome is phenomenal. Apple can do this because they set up a way to bridge SwiftUI to UIKit, so they know that even when SwiftUI fails to do some tasks, there will always have UIKit there.</p>
<h2 id="conclusion">Conclusion <a href="#conclusion">#</a></h2>
<p>Here comes the important question. Should you learn UIKit or SwiftUI?</p>
<p>My short answer would be <strong>SwiftUI</strong>.</p>
<p>And here is my long answer. From all the facts I point out in this article, SwiftUI is ready now. I think in the end you would end up learning both of them.</p>
<p>If you know UIKit, you are forced to learn SwiftUI since it is exclusive to a new framework like WidgetKit. Even not for that reason, I think you probably the one who appreciates SwiftUI the most. SwiftUI can do many great things right out of the box, things that we always want to do in UIKit, but don't have the opportunity and time to do it.</p>
<p>If you know SwiftUI, there would be a time that you want extra customization or hit some roadblock. When the time comes, UIKit will always there for you.</p>



      <hr>
      
      <p>Feel free to follow me on <a rel="nofollow noopener" href="https://twitter.com/sarunw" target="_blank">Twitter</a> and ask your questions related to this post. Thanks for reading and see you next time.</p>
      
      

      

      

      

      



      <p><a href="https://sarunw.com/">← Home</a></p>


      
  </div>
</div>
</section>            
    </div></div>]]>
            </description>
            <link>https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666923</guid>
            <pubDate>Sun, 28 Jun 2020 05:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventures in booting Linux on Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23666564">thread link</a>) | @todsacerdoti
<br/>
June 27, 2020 | https://blog.mostlypointless.dev/posts/net-boot-rpi/ | <a href="https://web.archive.org/web/*/https://blog.mostlypointless.dev/posts/net-boot-rpi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
        
        
            <span> Jun 26, 2020</span>
            
                <a href="https://blog.mostlypointless.dev/tags/linux">linux</a>
            
                <a href="https://blog.mostlypointless.dev/tags/raspberry-pi">raspberry pi</a>
            
        
        <p>Almost two months ago, I started building a four node Raspberry Pi 4 cluster for a project I’m working on. Figuring out the best way to get Linux on each node lead me down a rabbit hole and I spent the next four weeks <a href="http://www.catb.org/~esr/jargon/html/Y/yak-shaving.html">yak shaving</a>.</p>
<p>The most common way to boot a Pi is from an SD card. But they are slow and unreliable - I don’t like them. Certain models of Pi 2 and Pi 3 support <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/msd.md">booting from USB storage</a>, but Pi 4 cannot do that yet. So, I’m stuck with using an SD card for each Pi. Or so I thought.</p>
<h3 id="enter-pxe-boot">Enter PXE boot</h3>
<p>Turns out, Raspberry Pi 2 and 3 also <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net.md">support network booting</a>. A beta firmware was released late last year that enables <a href="https://en.wikipedia.org/wiki/Preboot_Execution_Environment">PXE</a> for Pi 4. I found <a href="https://linuxhit.com/raspberry-pi-pxe-boot-netbooting-a-pi-4-without-an-sd-card">an article on LinuxHit</a> detailing the process of installing the firmware and setting up network boot.</p>
<p>Just to test this out, I updated the firmware and configured PXE server on one of the Pis. I tried booting another Pi over the network and…it worked!
Here is the gist of PXE server setup process:</p>
<ol>
<li>Copy the contents of <code>/boot</code> and the rest of <code>/</code> into separate folders on your local filesystem. I copied mine to <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code> respectively.</li>
<li>Install and configure <code>dnsmasq</code> to enable TFTP and use <code>/tftp</code> as <code>tftp-root</code></li>
<li>Install and configure NFS server to share <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code></li>
<li>Edit the contents of <code>/nfs/raspbian-root/fstab</code> to mount the boot partition.</li>
<li>Edit <code>/nfs/raspbian-boot/cmdline.txt</code> to</li>
</ol>
<div><pre><code data-lang="bash">console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/raspbian-root,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><h3 id="pxe-booting-3-nodes-using-overlayfs">PXE booting 3 nodes using OverlayFS</h3>
<p>I cannot just boot all three nodes from the same boot and root filesystems since they are not read-only. And I don’t want to maintain a copy of these for each node. But this is a solved problem - Docker already lets you spin up multiple containers from a single base image. So I’ll just do <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works">what Docker does</a> - create <a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">OverlayFS</a> for each node using raspbian-root and raspbian-boot as my lower directories. I’ll share them over NFS like before.</p>
<p>Configuration for one of the nodes is below. Other two nodes follow the same pattern. Note that I moved raspbian-root and raspbian-boot to a USB hard drive (mounted at <code>/mnt</code>) to get better r/w performance. dc-a6-32-XX-XX-XX is the MAC address of the node. I’m using <code>tftp-unique-root=mac</code> option in <code>dnsmasq</code> to maintain a separate boot environment for each node based on its MAC address.</p>
<div><pre><code data-lang="bash">$ mount -t overlay nog-boot -o lowerdir<span>=</span>/mnt/raspbian-boot,upperdir<span>=</span>/mnt/upper/nog-boot,workdir<span>=</span>/mnt/work/nog-boot -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /tftpboot/dc-a6-32-XX-XX-XX

$ mount -t overlay nog-root -o lowerdir<span>=</span>/mnt/raspbian-root,upperdir<span>=</span>/mnt/work/nog-root,workdir<span>=</span>/mnt/work/nog-root -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /nfs/nog

$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>(In case you are wondering what <code>nog</code> is: I name my servers after planets from the Star Wars universe. Following this tradition, I’ve named the Pis Mandalore (PXE server), Nog, Ordo and Werda)</p>
<p>You are probably thinking that this worked. It did not.</p>
<p>NFS and OverlayFS did not play nice with each other. After a weekend trying to work around some weird issues, I gave up.</p>
<p>But OverlayFS is not the only copy-on-write filesystem in existence, is it? ZFS and BTRFS offer <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">subvolumes and snapshots</a> that I can use instead. But not before I <del>procrastinate</del> spend 2 weeks deciding which one to use.</p>
<h3 id="moving-to-btrfs">Moving to BTRFS</h3>
<p>The plan is simple: I’ll create a subvolume each for raspbian-root and raspbian-boot. I’ll then create three snapshots of each subvolume - one for every node. I created a <a href="https://en.wikipedia.org/wiki/RAS_syndrome">btrfs file system</a> on my external drive and ran the following commands</p>
<div><pre><code data-lang="bash">$ btrfs subvolume create raspbian-root
$ btrfs subvolume create raspbian-boot

<span># Repeat the following for each node changing folder names as necessary</span>
$ btrfs subvolume snapshot raspbian-boot nog-boot
$ btrfs subvolume snapshot raspbian-root nog-root
$ mount --bind /mnt/nog-boot /tftpboot/dc-a6-32-XX-XX-XX
$ mount --bind /mnt/nog-root /nfs/nog

<span># Don’t forget to edit cmdline.txt for each node</span>
$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>Well, this worked! I have a Pi running without an SD card!! Now all I have to do is create systemd unit files to start all required services and mount snapshots. I can finally start working on my project.</p>
<p>Wait a minute. Take a closer look at the output of <code>cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.
If you are like me, you will realize for the first time that <code>root=</code> in this file defines where the root filesystem will be mounted from. Right now, we are telling it to mount from <code>/dev/nfs</code>. What if I attach an external drive and set <code>root=</code> to point to the external drive?</p>
<h3 id="network-booting-into-a-usb-hard-drive">Network booting into a USB hard drive</h3>
<p>RPi 4 cannot directly boot from a USB drive. As in - it cannot find <code>/boot</code> on a USB drive when powering on. But what if we provide <code>/boot</code> with network boot and mount <code>/</code> from a USB drive using <code>cmdline.txt</code>? Time to test.</p>
<p>I copied raspbian-root to a USB drive, edited <code>fstab</code> to mount <code>/</code> using the partition’s PARTUUID and connected it to Nog. I then updated the contents of <code>/tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.</p>
<div><pre><code data-lang="bash">$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
 console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>PARTUUID<span>=</span>c1f95d14-01 rootfstype<span>=</span>ext4 elevator<span>=</span>deadline fsck.repair<span>=</span>yes rootwait
</code></pre></div><p>After a couple of reboots, it worked! I now have a RPi 4 running off a USB hard drive!</p>
<h3 id="what-did-i-gain">What did I gain?</h3>
<p>Let’s start with what I was looking for. All I wanted was to not deal with SD cards because they are slow and unreliable. Reliability is relative - everything fails at some point. But a decent quality USB hard drive will likely outlive an SD card. So let’s just look at some read/write performance numbers and see how they compare.</p>
<div><pre><code data-lang="bash">$ sync; dd <span>if</span><span>=</span>/dev/zero of<span>=</span>twogeefile bs<span>=</span>1M count<span>=</span>2048; sync  <span># Write performance</span>
$ sudo sh -c <span>"sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches"</span>
$ dd <span>if</span><span>=</span>twogeefile of<span>=</span>/dev/null bs<span>=</span>1M count<span>=</span><span>2048</span>              <span># Read performance</span>
</code></pre></div><table>
<thead>
<tr>
<th>Storage</th>
<th>Read (MB/s)</th>
<th>Write (MB/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sandisk Ultra MicroSDXC Class 10</td>
<td>45.7</td>
<td>20.2</td>
</tr>
<tr>
<td>Network Boot with BTRFS</td>
<td>63.3</td>
<td>18.8</td>
</tr>
<tr>
<td>/ mounted from USB hard drive</td>
<td>113.0</td>
<td>92.7</td>
</tr>
</tbody>
</table>
<p>With network boot, I was able to get read and write speeds similar to a class 10 SD card. Note that the boot images are hosted on a USB hard drive connected to Mandalore (PXE server). NFS seems to be the bottleneck here - raw r/w speeds of the hard drive are much better than this. All Pis are connected to Netgear’s 8 port gigabit ethernet switch.</p>
<p>To no one’s surprise, things improve considerably when Pis are running off a USB hard disk. Note that the external drives I used are 5400RPM hard disks repurposed from very old MacBooks. I bought them on eBay for $10 a pop. YMMV.</p>
<h3 id="current-setup">Current setup</h3>
<p>Right now, I have Mandalore booting from an SD card and <code>/</code> mounted from a USB hard disk. Nog, Ordo and Werda fetch <code>/boot</code> from Mandalore over the network and <code>/</code> mounted from a USB hard disk.</p>
<p><img src="https://blog.mostlypointless.dev/img/pi-cluster.jpg" alt="from top to bottom - Mandalore, Nog, Ordo, Werda"></p>
<p>I can finally start working on my proj… wait, what?</p>
<p><a href="https://www.tomshardware.com/how-to/boot-raspberry-pi-4-usb">A new beta firmware is out for RPi 4 that lets you boot from USB drives directly.</a></p>
<p>Oh well…</p>
<p>¯\_(ツ)_/¯</p>
<p><em><strong>Update:</strong> This post was discussed on <a href="https://news.ycombinator.com/item?id=23666564">Hacker News</a>. As jordybg <a href="https://news.ycombinator.com/item?id=23667247">points out</a>, USB boot is no longer “beta” and is available in the latest (2020-06-15) “stable” firmware release.</em></p>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.mostlypointless.dev/posts/net-boot-rpi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666564</guid>
            <pubDate>Sun, 28 Jun 2020 03:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebTransport API]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23666364">thread link</a>) | @Jarred
<br/>
June 27, 2020 | https://wicg.github.io/web-transport/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/web-transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="introduction"><span>1. </span><span>Introduction</span><a href="#introduction"></a></h2>
   <p><em>This section is non-normative.</em></p>
   <p>This specification uses pluggable protocols, with QUIC <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a> as
one such protocol, to send data to and receive data from servers. It can be
used like WebSockets but with support for multiple streams, unidirectional
streams, out-of-order delivery, and reliable as well as unreliable transport.</p>
   <p role="note"><span>Note:</span> The API presented in this specification represents a preliminary proposal
based on work-in-progress within the IETF QUIC WG. Since the QUIC transport
specification is a work-in-progress, both the protocol and API are likely to
change significantly going forward.</p>
   <h2 data-level="2" id="conformance"><span>2. </span><span>Conformance</span><a href="#conformance"></a></h2>
   <p>As well as sections marked as non-normative, all authoring guidelines,
diagrams, examples, and notes in this specification are non-normative.
Everything else in this specification is normative.</p>
   <p>The key words <em>MUST</em> and <em>SHOULD</em> are to be interpreted as described in <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a>.</p>
   <p>This specification defines conformance criteria that apply to a single product:
the user agent that implements the interfaces that it contains.</p>
   <p>Conformance requirements phrased as algorithms or specific steps may be
implemented in any manner, so long as the end result is equivalent. (In
particular, the algorithms defined in this specification are intended to be
easy to follow, and not intended to be performant.)</p>
   <p>Implementations that use ECMAScript to implement the APIs defined in this
specification MUST implement them in a manner consistent with the ECMAScript
Bindings defined in the Web IDL specification <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>, as this
specification uses that specification and terminology.</p>
   <h2 data-level="3" id="terminology"><span>3. </span><span>Terminology</span><a href="#terminology"></a></h2>
   <p>The <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler">EventHandler</a></code> interface, representing a callback used for event
handlers, and the <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#errorevent" id="ref-for-errorevent">ErrorEvent</a></code> interface are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The concepts <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-task" id="ref-for-queue-a-task">queue a task</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#networking-task-source" id="ref-for-networking-task-source">networking task source</a> are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event" id="ref-for-concept-event">event</a>, <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handlers" id="ref-for-event-handlers">event handlers</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handler-event-type" id="ref-for-event-handler-event-type">event handler event types</a> are
defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>When referring to exceptions, the terms <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-throw" id="ref-for-dfn-throw">throw</a> and <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-create-exception" id="ref-for-dfn-create-exception">create</a> are defined in <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects">fulfilled</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①">rejected</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects②">resolved</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects③">pending</a> and <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects④">settled</a> used in the context of Promises are defined in <a data-link-type="biblio" href="#biblio-ecmascript-60">[ECMASCRIPT-6.0]</a>.</p>
   <p>The terms <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream">ReadableStream</a></code> and <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream">WritableStream</a></code> are defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.  Note that despite sharing the name "stream", these are
distinct from the IncomingStream, OutgoingStream, and BidirectionalStream
defined here. The IncomingStream, OutgoingStream, and BidirectionalStream
defined here correspend to a higher level of abstraction that contain and
depend on the lower-level concepts of "streams" defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.</p>
   <h2 data-level="4" id="unidirectional-streams-transport"><span>4. </span><span><code>UnidirectionalStreamsTransport</code> Mixin</span><a href="#unidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="unidirectionalstreamstransport"><code>UnidirectionalStreamsTransport</code></dfn> can send and receive
unidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order.  Data is generally sent
reliably, but retransmissions may be disabled or the stream may aborted to
produce a form of unreliability.  All stream data is encrypted and
congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#unidirectionalstreamstransport" id="ref-for-unidirectionalstreamstransport"><c- g="">UnidirectionalStreamsTransport</c-></a> {
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#sendstream" id="ref-for-sendstream"><c- n="">SendStream</c-></a>&gt; <a data-link-type="method" href="#dom-unidirectionalstreamstransport-createsendstream" id="ref-for-dom-unidirectionalstreamstransport-createsendstream"><c- g="">createSendStream</c-></a>(<c- b="">optional</c-> <a data-link-type="idl-name" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters"><c- n="">SendStreamParameters</c-></a> <dfn data-dfn-for="UnidirectionalStreamsTransport/createSendStream(parameters), UnidirectionalStreamsTransport/createSendStream()" data-dfn-type="argument" data-export="" id="dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"><code><c- g="">parameters</c-></code><a href="#dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"></a></dfn> = {});
  <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream①"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-unidirectionalstreamstransport-receivestreams" id="ref-for-dom-unidirectionalstreamstransport-receivestreams"><c- g="">receiveStreams</c-></a>();
};
</pre>
   <h3 data-level="4.1" id="#unidirectional-streams-transport-methods"><span>4.1. </span><span>Methods</span><a href="#%23unidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" data-lt="createSendStream(parameters)|createSendStream()" id="dom-unidirectionalstreamstransport-createsendstream"><code>createSendStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream①">SendStream</a></code> object.</p>
     <p>When <code>createSendStream()</code> method is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>createSendStream</code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑤">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑥">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream②">SendStream</a></code> object and <a data-link-type="dfn" href="#add-the-sendstream" id="ref-for-add-the-sendstream">add the
  SendStream</a> to <var>transport</var> when all of the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state①">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint.  For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑦">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑧">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror①">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑨">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-unidirectionalstreamstransport-receivestreams"><code>receiveStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream②">ReadableStream</a></code> of <code><a data-link-type="idl" href="#receivestream" id="ref-for-receivestream">ReceiveStream</a></code>s that have been received
 from the remote host.</p>
     <p>When <code>receiveStreams</code> is called, the user agent MUST run the following
 steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>receiveStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot">[[ReceivedStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each unidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#incomingstream" id="ref-for-incomingstream">IncomingStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot①">[[ReceivedStreams]]</a></code>. As data
  is received over the unidirectional stream, insert that data into the
  corresponding <code>IncomingStream</code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code>IncomingStream</code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="4.2" id="#unidirectional-streams-transport-procedures"><span>4.2. </span><span>Procedures</span><a href="#%23unidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="4.2.1" id="add-sendstream"><span>4.2.1. </span><span>Add SendStream to UnidirectionalStreamsTransport</span><a href="#add-sendstream"></a></h4>
   
   <h3 data-level="4.3" id="send-stream-parameters"><span>4.3. </span><span>SendStreamParameters Dictionary</span><a href="#send-stream-parameters"></a></h3>
   <p>The <dfn data-dfn-type="dictionary" data-export="" id="dictdef-sendstreamparameters"><code>SendStreamParameters</code></dfn> dictionary includes information
relating to stream configuration.</p>
<pre><c- b="">dictionary</c-> <a data-link-type="dictionary" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters①"><c- g="">SendStreamParameters</c-></a> {
};
</pre>
   <h2 data-level="5" id="bidirectional-streams-transport"><span>5. </span><span><code>BidirectionalStreamsTransport</code> Mixin</span><a href="#bidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="bidirectionalstreamstransport"><code>BidirectionalStreamsTransport</code></dfn> can send and receive
bidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order. Data is generally sent reliably,
but retransmissions may be disabled or the stream may aborted to produce a form
of unreliability.  All stream data is encrypted and congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport"><c- g="">BidirectionalStreamsTransport</c-></a> {
    <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#bidirectionalstream" id="ref-for-bidirectionalstream"><c- n="">BidirectionalStream</c-></a>&gt; <a data-link-type="method" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream"><c- g="">createBidirectionalStream</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream③"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-bidirectionalstreamstransport-receivebidirectionalstreams" id="ref-for-dom-bidirectionalstreamstransport-receivebidirectionalstreams"><c- g="">receiveBidirectionalStreams</c-></a>();
};
</pre>
   <h3 data-level="5.1" id="#bidirectional-streams-transport-methods"><span>5.1. </span><span>Methods</span><a href="#%23bidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-createbidirectionalstream"><code>createBidirectionalStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream①">BidirectionalStream</a></code> object.</p>
     <p>When <code>createBidirectionalStream</code> is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport①">BidirectionalStreamsTransport</a></code> on which <code><a data-link-type="idl" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream①">createBidirectionalStream</a></code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state②">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⓪">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror②">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state③">state</a></code> is <code>"connected"</code>, immediately
  return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①①">fulfilled</a> promise with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream②">BidirectionalStream</a></code> object, <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream">add the BidirectionalStream</a> to the
  transport and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①②">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream③">BidirectionalStream</a></code> object and <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream①">add the BidirectionalStream</a> to <var>transport</var> when all of the following
  conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state④">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint. For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①③">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①④">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror③">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⑤">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-receivebidirectionalstreams"><code>receiveBidirectionalStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream④">ReadableStream</a></code> of <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream④">BidirectionalStream</a></code>s that have been
 received from the remote host.</p>
     <p>When <code>receiveBidirectionalStreams</code> method is called, the user agent MUST run
 the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>BidirectionalStreamsTransport</code> on which <code>receiveBidirectionalStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot">[[ReceivedBidirectionalStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each bidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑤">BidirectionalStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot①">[[ReceivedBidirectionalStreams]]</a></code>.
  As data is received over the bidirectional stream, insert that data into the
  corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑥">BidirectionalStream</a></code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑦">BidirectionalStream</a></code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="5.2" id="#bidirectional-streams-transport-procedures"><span>5.2. </span><span>Procedures</span><a href="#%23bidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="5.2.1" id="add-bidirectionalstream"><span>5.2.1. </span><span>Add BidirectionalStream to BidirectionalStreamsTransport</span><a href="#add-bidirectionalstream"></a></h4>
   
   <h2 data-level="6" id="datagram-transport"><span>6. </span><span><code>DatagramTransport</code> Mixin</span><a href="#datagram-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="datagramtransport"><code>DatagramTransport</code></dfn> can send and receive datagrams.
Datagrams are sent out of order, unreliably, and have a limited maximum size.
Datagrams are encrypted and congestion controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#datagramtransport" id="ref-for-datagramtransport"><c- g="">DatagramTransport</c-></a> {
    <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short"><c- b="">unsigned</c-> <c- b="">short</c-></a> <a data-link-type="attribute" data-readonly="" data-type="unsigned short" href="#dom-datagramtransport-maxdatagramsize" id="ref-for-dom-datagramtransport-maxdatagramsize"><c- g="">maxDatagramSize</c-></a>;
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream①"><c- n="">WritableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams"><c- g="">sendDatagrams</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream⑤"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-receivedatagrams" id="ref-for-dom-datagramtransport-receivedatagrams"><c- g="">receiveDatagrams</c-></a>();
};
</pre>
   <h3 data-level="6.1" id="datagram-transport-attributes"><span>6.1. </span><span>Attributes</span><a href="#datagram-transport-attributes"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="attribute" data-export="" id="dom-datagramtransport-maxdatagramsize"><code>maxDatagramSize</code></dfn>, <span> of type <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short①">unsigned short</a>, readonly</span>
    </dt><dd data-md="">
     <p>The maximum size data that may be passed to <code><a data-link-type="idl" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams①">sendDatagrams</a></code>.</p>
   </dd></dl>
   <h3 data-level="6.2" id="datagram-transport-methods"><span>6.2. </span><span>Methods</span><a href="#datagram-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-senddatagrams"><code>sendDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Sends datagrams that are written to the returned <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream②">WritableStream</a></code>.</p>
     <p>When <code>sendDatagrams</code> is called, the user agent MUST run the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#datagramtransport" id="ref-for-datagramtransport①">DatagramTransport</a></code> on which <code>sendDatagram</code> is
  invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-sentdatagrams-slot" id="ref-for-dom-quictransport-sentdatagrams-slot">[[SentDatagrams]]</a></code> internal slot.</p>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-receivedatagrams"><code>receiveDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot">[[ReceivedDatagrams]]</a></code> internal slot.</p>
     <p>For each datagram received, insert it into <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot①">[[ReceivedDatagrams]]</a></code>. If too
 many datagrams are queued because the stream is not being read quickly
 enough, drop datagrams to avoid queueing. Implementations should drop older
 datagrams in favor of newer datagrams. The number of datagrams to queue
 should be kept small enough to avoid adding significant latency to packet
 delivery when the stream is being read slowly (due to the reader being slow)
 but large enough to avoid dropping packets when for the stream is not read
 for short periods of time (due to the reader being paused).</p>
   </dd></dl>
   <h2 data-level="7" id="web-transport"><span>7…</span></h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wicg.github.io/web-transport/">https://wicg.github.io/web-transport/</a></em></p>]]>
            </description>
            <link>https://wicg.github.io/web-transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666364</guid>
            <pubDate>Sun, 28 Jun 2020 02:26:47 GMT</pubDate>
        </item>
    </channel>
</rss>
