<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 26 Feb 2021 08:40:36 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 26 Feb 2021 08:40:36 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Telegram bot in Elixir featuring LiveView]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26247755">thread link</a>) | @lawik
<br/>
February 24, 2021 | https://underjord.io/a-telegram-bot-in-elixir.html | <a href="https://web.archive.org/web/*/https://underjord.io/a-telegram-bot-in-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2021-02-24</small>
        <p>I <a href="https://twitter.com/lawik/status/1357226010215911425">asked my network on Twitter</a> about noting ideas quickly and got a lot of good responses. One mentioned saving them in Telegram. I don’t think I want to do specifically that but I do want a minimum friction way of noting ideas for later review and refinement. And sending them to a Telegram chat would be quite nice. So I started on the path of something like a note-taking system using Telegram for ingesting quick notes. And I want to share the satisfaction I felt with seeing the near real-time way that it works.</p>
<p>I’ll show some of the process I went through so you can repeat it for your own needs but the repo is open if you want to see where I’ve taken it since. You can find it as <a href="https://github.com/lawik/noted">lawik/noted</a> on GitHub. This guide recreates a simpler approach based off of what I learnt setting that up.</p>
<h2 id="setting-up-your-project">Setting up your project</h2>
<p>I’m using Elixir and Phoenix with LiveView. You need to have the Phoenix project generator installed to follow along, you can follow the Phoenix installation instructions to get it.</p>

  

<p>It should create your project, you can certainly name it something different than <code>noted</code>. I left Ecto in because you’ll likely want it at some point though I won’t use it in this post.</p>
<h2 id="some-initial-setup">Some initial setup</h2>
<p>In <code>lib/noted/application.ex</code> I comment out the <code>Noted.Repo</code> because we’re not using the DB.</p>
<p>In <code>mix.exs</code> for deps I add:</p>

  <div data-file="mix.exs">
  <p>mix.exs</p>
  <div><pre><code data-lang="elixir">    <span>..</span>
      {<span>:telegram</span>, <span>git</span>: <span>"https://github.com/visciang/telegram.git"</span>, <span>tag</span>: <span>"0.7.0"</span>},
      <span># Gun mismatch with telegram and cowboy</span>
      {<span>:cowlib</span>, <span>"~&gt; 2.7"</span>, <span>override</span>: true}
    <span>..</span></code></pre></div>
  </div>

<p>The cowlib thing has to do with some weirdness in the telegram library deps. But adding this should allow you to do <code>mix deps.get</code> and have it work.</p>
<h2 id="get-yourself-a-telegram-bot">Get yourself a Telegram bot</h2>
<p>So get situated with a Telegram account and add <a href="https://t.me/BotFather">The Botfather (Telegram link)</a> as someone to talk to and that’s Telegrams bot for creating bots. Very meta. Pretty convenient.</p>
<p>You write <code>/newbot</code> to him and he’ll guide you through the rest. You’ll receive a secret that you should squirrel away and we’ll use it as a an API key for running our bot.</p>
<p>You’re going to want a convenient client to test things as well. I’m using the MacOS desktop client on this machine, it is nice and native.</p>
<h2 id="minimum-viable-bot">Minimum Viable Bot</h2>
<p>It needs to be self-aware. So let’s make that happen. To protect the bot token I put it in a file in my home dir called <code>.mybotcredentials</code> or something similar. This file is just:</p>

  <div data-file="~/.mybotcredentials">
  <p>~/.mybotcredentials</p>
  <div><pre><code data-lang="shell">export TELEGRAM_BOT_SECRET<span>=</span><span>"my_secret_goes_here"</span></code></pre></div>
  </div>

<p>And before running the server I do: <code>source ~/.mybotcredentials</code></p>
<p>This prevents me from accidentally committing the damned things.</p>
<p>Okay, time to create this bot. Create a file in the project named <code>lib/noted/bot.ex</code>. In this file we do this:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir">defmodule <span>Noted.Bot</span> do
  use <span>GenServer</span>
  require <span>Logger</span>

  def start_link(opts) do
    <span>GenServer</span><span>.</span>start_link(__MODULE__, opts, opts)
  end

  <span>@impl</span> <span>GenServer</span>
  def init(opts) do
    {key, _opts} <span>=</span> <span>Keyword</span><span>.</span>pop!(opts, <span>:bot_key</span>)

    case <span>Telegram.Api</span><span>.</span>request(key, <span>"getMe"</span>) do
      {<span>:ok</span>, me} <span>-&gt;</span>
        <span>Logger</span><span>.</span>info(<span>"Bot successfully self-identified: </span><span>#{</span>me[<span>"username"</span>]<span>}</span><span>"</span>)

        state <span>=</span> %{
          <span>bot_key</span>: key,
          <span>me</span>: me,
          <span>last_seen</span>: <span>-</span><span>2</span>
        }

        {<span>:ok</span>, state}

      error <span>-&gt;</span>
        <span>Logger</span><span>.</span>error(<span>"Bot failed to self-identify: </span><span>#{</span>inspect(error)<span>}</span><span>"</span>)
        <span>:error</span>
    end
  end
end</code></pre></div>
  </div>

<p>This is a GenServer and we want to add it to run when our application starts. So below your Noted.Endpoint, inside the list of children in <code>lib/noted/application.ex</code> add this:</p>

  <div data-file="lib/noted/application.ex">
  <p>lib/noted/application.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
{<span>Noted.Bot</span>, <span>bot_key</span>: <span>System</span><span>.</span>get_env(<span>"TELEGRAM_BOT_SECRET"</span>)}
<span>..</span></code></pre></div>
  </div>

<p>Now you can make sure you’ve run <code>mix deps.get</code> and then run <code>mix phx.server</code> to try it out. Check your logs, the happy message should be there.</p>
<h2 id="set-yourself-up-to-receive-updates">Set yourself up to receive updates</h2>
<p>So it still doesn’t really do anything. We will be using long polling which is a neat way of getting updates from a Telegram bot without publishing the server on the web on some real domain and in some systems it might be a bit of a pain. In Elixir, on a GenServer it is comparatively trivial. At least if you know your GenServers.</p>
<p>Just after we set up our state and before we return <code>{:ok, state}</code> in the bot we need to add a call to <code>next_loop()</code>. So the your <code>init/1</code> looks like this:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
  def init(opts) do
    {key, _opts} <span>=</span> <span>Keyword</span><span>.</span>pop!(opts, <span>:bot_key</span>)

    case <span>Telegram.Api</span><span>.</span>request(key, <span>"getMe"</span>) do
      {<span>:ok</span>, me} <span>-&gt;</span>
        <span>Logger</span><span>.</span>info(<span>"Bot successfully self-identified: </span><span>#{</span>me[<span>"username"</span>]<span>}</span><span>"</span>)

        state <span>=</span> %{
          <span>bot_key</span>: key,
          <span>me</span>: me,
          <span>last_seen</span>: <span>-</span><span>2</span>
        }
        next_loop()

        {<span>:ok</span>, state}

      error <span>-&gt;</span>
        <span>Logger</span><span>.</span>error(<span>"Bot failed to self-identify: </span><span>#{</span>inspect(error)<span>}</span><span>"</span>)
        <span>:error</span>
    end
  end
<span>..</span></code></pre></div>
  </div>

<p>Now to add the rest. This GenServer will send itself a message saying “ey, check for updates” and then act on that message until the activity is done and then call <code>next_loop/0</code> again to trigger another message. We’ll start with acting on the message with a <code>handle_info/2</code> callback. In your bot GenServer module:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
  <span>@impl</span> <span>GenServer</span>
  def handle_info(<span>:check</span>, %{<span>bot_key</span>: key, <span>last_seen</span>: last_seen} <span>=</span> state) do
    state <span>=</span>
      key
      <span>|&gt;</span> <span>Telegram.Api</span><span>.</span>request(<span>"getUpdates"</span>, <span>offset</span>: last_seen <span>+</span> <span>1</span>, <span>timeout</span>: <span>30</span>)
      <span>|&gt;</span> case do
        <span># Empty, typically a timeout. State returned unchanged.</span>
        {<span>:ok</span>, []} <span>-&gt;</span>
          state

        <span># A response with content, exciting!</span>
        {<span>:ok</span>, updates} <span>-&gt;</span>
          <span># Process our updates and return the latest update ID</span>
          last_seen <span>=</span> handle_updates(updates, last_seen)

          <span># Update the last_seen state so we only get new updates on the</span>
          <span># next check</span>
          %{state <span>|</span> <span>last_seen</span>: last_seen}
      end

    <span># Re-trigger the looping behavior</span>
    next_loop()
    {<span>:noreply</span>, state}
  end

  defp handle_updates(updates, last_seen) do
    updates
    <span># Process our updates</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span>map(fn update <span>-&gt;</span>
      <span>Logger</span><span>.</span>info(<span>"Update received: </span><span>#{</span>inspect(update)<span>}</span><span>"</span>)
      <span># Offload the updates to whoever they may concern</span>
      broadcast(update)

      <span># Return the update ID so we can boil it down to a new last_seen</span>
      update[<span>"update_id"</span>]
    end)
    <span># Get the highest seen id from the new updates or fall back to last_seen</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span>max(fn <span>-&gt;</span> last_seen end)
  end

  defp broadcast(update) do
    <span># Send each update to a topic for others to listen to.</span>
    <span>Phoenix.PubSub</span><span>.</span>broadcast!(<span>Noted.PubSub</span>, <span>"bot_update"</span>, {<span>:update</span>, update})
  end

  defp next_loop do
    <span>Process</span><span>.</span>send_after(self(), <span>:check</span>, <span>0</span>)
  end
<span>..</span></code></pre></div>
  </div>

<p>Try it out, it should log messages as they are sent to your bot.</p>
<h2 id="getting-real-time-with-liveview">Getting real-time with LiveView</h2>
<p>We can repurpose the existing LiveView that the Phoenix generator gives us. So just open <code>lib/noted_web/live/page_live.ex</code> and its sibling the template <code>lib/noted_web/live/page_live.html.leex</code>. In the <code>page_live.ex</code> file we change it to this:</p>

  <div data-file="lib/noted_web/live/page_live.ex">
  <p>lib/noted_web/live/page_live.ex</p>
  <div><pre><code data-lang="elixir">defmodule <span>NotedWeb.PageLive</span> do
  use <span>NotedWeb</span>, <span>:live_view</span>

  <span>@impl</span> true
  def mount(_params, _session, socket) do
    <span>Phoenix.PubSub</span><span>.</span>subscribe(<span>Noted.PubSub</span>, <span>"bot_update"</span>)
    {<span>:ok</span>, assign(socket, <span>messages</span>: [])}
  end

  <span>@impl</span> true
  def handle_info({<span>:update</span>, update}, socket) do
    {<span>:noreply</span>, assign(socket, <span>messages</span>: [to_message(update) <span>|</span> socket<span>.</span>assigns<span>.</span>messages])}
  end

  defp to_message(%{<span>"message"</span> <span>=&gt;</span> message} <span>=</span> _update) do
    firstname <span>=</span> get_in(message, [<span>"from"</span>, <span>"first_name"</span>])
    lastname <span>=</span> get_in(message, [<span>"from"</span>, <span>"last_name"</span>])
    username <span>=</span> get_in(message, [<span>"from"</span>, <span>"username"</span>])

    from <span>=</span>
      case {firstname, lastname, username} do
        {nil, _, username} <span>-&gt;</span> username
        {firstname, nil, _} <span>-&gt;</span> firstname
        {firstname, lastname, _} <span>-&gt;</span> <span>"</span><span>#{</span>firstname<span>}</span><span> </span><span>#{</span>lastname<span>}</span><span>"</span>
      end

    text <span>=</span> get_in(message, [<span>"text"</span>])
    %{<span>from</span>: from, <span>text</span>: text}
  end
end</code></pre></div>
  </div>

<p>And we change the <code>page_live.html.leex</code> template file to:</p>

  <div data-file="lib/noted_web/live/page_live.html.leex">
  <p>lib/noted_web/live/page_live.html.leex</p>
  <div><pre><code data-lang="html">&lt;<span>section</span> <span>class</span><span>=</span><span>"phx-hero"</span>&gt;
  &lt;<span>h1</span>&gt;<span>&lt;</span>%= gettext "Welcome to my Bot!" %&gt;&lt;/<span>h1</span>&gt;

  <span>&lt;</span>%= for message &lt;<span>-</span> <span>Enum</span><span>.</span><span>reverse</span><span>(@</span><span>messages</span><span>)</span> <span>do</span> <span>%</span>&gt;
  &lt;<span>p</span>&gt;&lt;<span>strong</span>&gt;<span>&lt;</span>%= message.from %&gt;: &lt;/<span>strong</span>&gt;<span>&lt;</span>%= message.text %&gt;&lt;/<span>p</span>&gt;
  <span>&lt;</span>% end %&gt;
&lt;/<span>section</span>&gt;</code></pre></div>
  </div>

<p>Run this and you should see any message to type in the Telegram bot show up. I find it very gratifying just how instantaneous it can be.</p>
<h2 id="in-closing">In closing</h2>
<p>This is just a start and in the <a href="https://github.com/lawik/noted">noted repo</a> you will find some of what I’ve done to push it further, structure the bot a little bit more. Add some responses. You can just try it out by cloning and setting it up.</p>
<p>I implemented some authentication. Currently this means that notes are separated by user. It also means that Noted allows new users by default if they find your bot :D</p>
<p>I implemented the database backing to save notes and tags. I added a bunch more LiveView code. I separated the polling for getUpdates from the handling of the updates a bit more and added a Supervisor to the pairing of GenServers.</p>
<p>Currently on my todo-list is to receive files and media in a nice way and integrate those with the markdown support. If you want practice with Tailwind CSS I’d love for someone to make it look better.</p>
<p>But this particular project aside I find the realtime nature of chat bots very satisfying. Telegram has a well-working API, nice native clients and a hilariously large feature set. And with how fast you can get this up and running when it isn’t your first time I really recommend trying it for things. Heck, you could use it for sending you notices about your app catching fire or occasional status updates from your system. There are so many fun options.</p>
<p>Slightly timely update, especially if you are curious about LiveView or want more of me. Me and a wild gang of Elixir community folks just put our new podcast out there. It is called <a href="https://beamrad.io/">BEAM Radio</a> and you find it at <a href="https://beamrad.io/">beamrad.io</a>.</p>
<p>I hope you’ve enjoyed the post. Let me know if this is something you would like to see more of as I have quite a few things I could go deeper into from this …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/a-telegram-bot-in-elixir.html">https://underjord.io/a-telegram-bot-in-elixir.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/a-telegram-bot-in-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26247755</guid>
            <pubDate>Wed, 24 Feb 2021 08:09:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26247052">thread link</a>) | @kozmico
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26247052</guid>
            <pubDate>Wed, 24 Feb 2021 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year of Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26246487">thread link</a>) | @momonga
<br/>
February 23, 2021 | https://macwright.com/2021/02/18/a-year-of-rails.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/02/18/a-year-of-rails.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><picture><source srcset="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.webp" type="image/webp"><img alt="Railroad" src="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.jpg"></picture></p><p>I spent most of 2020 working with <a href="https://rubyonrails.org/">Ruby on Rails</a>. I moved a project from <a href="https://nextjs.org/">Next.js</a> + <a href="https://www.rust-lang.org/">Rust</a> to…&nbsp;Rails, baby! Back to the future. My earlier post on <a href="https://macwright.com/2020/05/10/spa-fatigue.html"><em>Second-guessing the modern web</em></a> was inspired by this experience, that for the product we were building, a ‘modern’ stack was not working as well as a traditional one.</p><p>We didn’t do competitive analysis against Laravel, Django, or Phoenix. They’re similar, not radically better or worse. There are multiple acceptable solutions to a problem, and this was more a matter of choosing the right <em>kind</em> of solution than pursuing some kind of perfect choice and burning hours and motivation doing the window-shopping.</p><p>What helped Rails win was that the team had a little more experience in Ruby (with the exception of myself), and we found plenty of resources for developing and deploying the stack. Rails fit perfectly into the ideology of <a href="http://boringtechnology.club/"><em>Choosing boring technology</em></a>. Another part of the product would be the hard, innovative part, so it made no sense to grapple with bleeding-edge web frameworks.</p><p>This was a really fun experience. There’s a lot to love about Rails. Other communities could learn a bit from the Ruby &amp; Rails culture and wisdom. I won’t implement <em>everything</em> in Rails, but it’ll be part of the toolbox.</p><p>Before this, I hadn’t touched the stuff. And I bet a lot of people are like that - they came of age in the world of React and Go, and haven’t tried anything even remotely similar to Rails. For their benefit, and to debrief from 2020, here are some notes on the experience. Plus, <a href="https://macwright.com/2020/10/28/if-not-spas.html">Rails-like projects in JavaScript</a> are ramping up quickly, and it’s fun to know the origins.</p><h2 id="the-good">The good</h2><h3 id="debugging-rails-apps-is-amazing">Debugging Rails apps is amazing</h3><p>A while ago, I <a href="https://twitter.com/tmcw/status/1321133460501585922">wrote on Twitter</a></p><blockquote><p>the real reason why javascript developers don’t use breakpoints and use console.log is that breakpoints don’t work</p></blockquote><p>After years of working in JavaScript, I’m used to bad debugging experiences. The Chrome debugger’s <a href="https://developers.google.com/web/updates/2015/05/automatically-pause-on-any-exception">automatic pause on caught exceptions</a> is amazing, sometimes. But throwing a <code>debugger</code> statement in some React code is dodgy as hell. Sometimes it works, mostly it doesn’t. You have to deal with code that might not have the right <a href="https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/">sourcemap</a> to translate from bundled &amp; minified code to original source. Subtle abstractions like React hooks and advanced transpiler stuff like <a href="https://github.com/facebook/regenerator">Regenerator</a> mean that your code’s stacktrace probably looks nothing like what you expect, with lots of internal garbage. Sure, you can learn better techniques for diagnosing and debugging errors, but it’s not just you - the debugging story in JavaScript is pretty bad. This applies even to Node.js, where one of the debugging stories is to connect Chrome’s debugger to a Node.js instance:&nbsp;a finicky solution that doesn’t consistently work.</p><p>In Rails, there is <a href="https://github.com/deivid-rodriguez/byebug">byebug</a>. You write <strong><code>byebug</code></strong> in your source code, and you get an interactive REPL right there. It works in views, controllers, database migrations, everywhere. It almost always works. Variables are named what you expect. The whole system is paused at that moment, and you can actually interact with it, using all of the Rails utilities and your installed gems.</p><p>If a page crashes unexpectedly, you get a similar REPL experience, in your browser, automatically. With an automatically cleaned-up stacktrace that excludes Rails’s own frames. Like the byebug interface, this REPL actually works and is consistently helpful in finding root causes. Rarely will you need to use <code>puts</code> to print something to the console because this debugging system is so good.</p><h3 id="the-magic-mostly-works">The magic mostly works</h3><p>Our Rails app didn’t have any <code>require</code> statements. You mention a module’s name, and it’s automatically included, using <a href="https://github.com/fxn/zeitwerk">Zeitwork</a>, a tool that comes standard with Rails.</p><p>This kind of system was terrifying to me before. What if you accidentally import something just by mentioning it? What if two things have the same name and you import the wrong one? How do you really know what’s happening? Sure, you’re happy now, with all of that annoying importing and exporting taken care of, but the sky might fall.</p><p>Or maybe it just… doesn’t. Maybe impure, vaguely risky techniques are just a net positive over time, and making everything fully explicit isn’t really necessary? Now when I’m using other systems, I wonder - what if I could just mention one of my React components and it would just… be there? Sure, the system would have to complain if there were two components with the same name, and it would have to make assumptions about directory structure, but overall, wouldn’t this be nice?</p><p>This applies to a lot of other parts of the system too. Rails is famous for doing pluralization - you name a model <code>Post</code> and you automatically get an interface called <code>posts</code>. But what, you ask, of words with uneven pluralization rules? Rails actually&nbsp;<a href="https://weblog.rubyonrails.org/2005/8/25/10-reasons-rails-does-pluralization/">does the right thing</a>, almost always. And when it fails, you can override it. It actually just saves time, reliably.</p><h3 id="testing-works">Testing works</h3><p>I’ve tried to test front-end applications. I’ve set up <a href="https://nightwatchjs.org/">nightwatch</a>, <a href="https://jestjs.io/">jest</a>, <a href="https://enzymejs.github.io/enzyme/">enzyme</a>, <a href="https://www.cypress.io/">cypress</a>, and probably 5-10 other frameworks. <em>Front-end testing is universally terrible.</em> Projects like Cypress are throwing untold hours into making it less terrible, taking on massive amounts of complexity to abstract away from fickle browser behavior and complex interactions.</p><p>But it still sucks. Frontend testing has no good attributes: it’s unreliable, hard to automate, hard to debug when it fails, and often doesn’t even assert for important behaviors, so it doesn’t actually identify regressions. Running frontend tests in CI is resource-heavy, requiring you to set up headless X windows environments on servers or use specialized CI services that produce screencasts of test runs.</p><p>Testing fully-server-rendered applications, on the other hand, is <em>amazing</em>. A vanilla testing setup with Rails &amp; <a href="https://rspec.info/">RSpec</a> can give you fast, stable, concise, and actually-useful test coverage. You can actually assert for behavior and navigate through an application like a user would. These tests are solving a simpler problem - making requests and parsing responses, without the need for a full browser or headless browser, without multiple kinds of state to track.</p><p>Not only do the tests work better, the testing culture is a completely different universe. There are entire books written about how to write RSpec tests that catch bugs, allow software evolution, and aren’t filled with boilerplate.</p><h3 id="gems-are-so-powerful">Gems are so powerful</h3><p>Powerful and dangerous.</p><p>I’m used to modules as they work in other systems - Python, Node, Elm, and so on. They provide objects, functions, and variables that you can import and combine into your code explicitly. Usually they sit on some specific level of abstraction - it’s a utility for connecting to servers or a React component you can use.</p><p>Gems can do so much more. You install something like <a href="https://github.com/heartcombo/devise">Devise</a> into your system and it adds views, routes, methods, utilities, you name it. It’s not like “loading some functions”, it’s more like composing a whole different app <em>into</em> your app, implicitly.</p><p>This is obviously terrifying. It means that you can’t look at your directories of views and your file of <code>routes.rb</code> and know what exists at a glance. There are other layers, lurking in the ephemeral space of third-party code. They interact in serious but uncertain ways.</p><p>But it’s also pretty incredible - the idea that something like <a href="http://www.passportjs.org/">passport</a>, Node’s middleware, could instead be a full-fledged authentication system. It means that you have to write a lot less code, and it also means that the people who <em>use</em> that code have a lot more code in common. That gems can work on a higher level of abstraction, making it possible to cobble together software faster, to write less ‘glue code.’</p><h3 id="theres-so-much-good-writing-about-rails">There’s so much good writing about Rails</h3><p>Even if you don’t write Ruby, you should pay attention to <a href="https://sandimetz.com/">Sandi Metz</a>. She’s incredibly wise and has so many incredible ideas to share.</p><p>And then there’s <a href="https://blog.arkency.com/">arkency</a>, <a href="https://thoughtbot.com/blog/">ThoughtBot</a>, and so many other thoughtful writers with years of experience in Rails. Sometimes it’s a little shocking to google for some obscure problem and see a decade of discussion about it.</p><p>The best practices are also formalized into tools like <a href="https://codeclimate.com/">Code Climate</a> and <a href="https://github.com/troessner/reek">reek</a>. I’ve never seen so many actually-useful suggestions come out of automated systems as I did in the world of Ruby and Rails.</p><h3 id="ruby">Ruby</h3><p>Ruby is a pretty pleasant language to work in. Sure, it has a lot of syntax and a sprawling standard library, but you don’t have to use all of that if you don’t want to. It took me a while to adjust to the object-oriented way of doing things - in particular, the idea that you can’t just have a free-range function floating out there, unassociated with a class or module, like you can in JavaScript. And you can’t just create an arbitrary one-off object - you either need to define a class to create an object, or use a Hash to store data.</p><p>But Ruby’s standard library isn’t that huge. I’ve seen JavaScript’s ‘standard library’ grow a lot too, and frankly it’s nice to have methods like <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart"><code>String.prototype.padStart</code></a> instead of having every little thing in userspace. The only part that felt actively weird was <a href="https://rubygems.org/gems/activesupport/versions/6.1.1">activesupport</a> - a gem that extends Ruby’s core objects, but is part of Rails. It felt weird to have <em>string</em> methods that would only work if your environment was Rails.</p><p>The <a href="https://kapeli.com/dash">Dash</a> app for documentation rocketed from my pile of unused tools to an absolute must-have. In the world of Ruby and Rails, with <em>most</em> gems having pretty good, semi-standard documentation, you can search for, and get answers, super fast. The Ruby language documentation and the Rails documentation is absolutely great. The JavaScript equivalent - <a href="https://developer.mozilla.org/en-US/">MDN</a> - pales in comparison.</p><h2 id="the-bad">The bad</h2><h3 id="the-asset-pipeline">The asset pipeline</h3><p>Remember SASS and the YUI Compressor? These are, unfortunately, defaults in the <a href="https://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>. There’s <a href="https://edgeguides.rubyonrails.org/webpacker.html">Webpacker</a> too, which has a parallel approach to CSS and images as the asset pipeline. It has <a href="https://github.com/rails/webpacker#integrations">opinionated integrations</a> with stuff like React. Ah, and I should mention that Rails’s <a href="https://github.com/rails/rails/tree/main/actionview/app/assets/javascripts">JavaScript utilities are written in… CoffeeScript</a>.</p><p>I get it - it’s hard to keep up with the latest trends in frontend. But this is one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/02/18/a-year-of-rails.html">https://macwright.com/2021/02/18/a-year-of-rails.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/02/18/a-year-of-rails.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246487</guid>
            <pubDate>Wed, 24 Feb 2021 04:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nx (Numerical Elixir) is now publicly available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26246484">thread link</a>) | @lobo_tuerto
<br/>
February 23, 2021 | https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> February 18th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/nx">nx</a>, <a href="https://dashbit.co/blog/tags/defn">defn</a>
  </li>
</ul>
<p><img src="https://dashbit.co/images/posts/2021/nx.png" alt="Nx" width="400"></p>
<p>
Sean Moriarity and I are glad to announce that the project we have been working on for the last 3 months, Nx, is finally <a href="https://github.com/elixir-nx/nx">publicly available on GitHub</a>. Our goal with Nx is to provide the foundation for Numerical Elixir.</p>
<p>
In this blog post, I am going to outline the work we have done so far, some of the design decisions, and what we are planning to explore next. If you are looking for other resources to learn about Nx, you can <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">hear me unveiling Nx on the ThinkingElixir podcast</a>.</p>
<h2>
  Nx</h2>
<p>
Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU. Let’s see an example:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4885761117-1">(</span><span data-group-id="4885761117-2">[</span><span data-group-id="4885761117-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-3">]</span><span>,</span><span> </span><span data-group-id="4885761117-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-4">]</span><span data-group-id="4885761117-2">]</span><span data-group-id="4885761117-1">)</span><span>
</span><span data-group-id="4885761117-5">#</span><span data-group-id="4885761117-5">Nx.Tensor</span><span data-group-id="4885761117-5">&lt;</span><span>
  </span><span>s64</span><span data-group-id="4885761117-6">[</span><span>2</span><span data-group-id="4885761117-6">]</span><span data-group-id="4885761117-7">[</span><span>2</span><span data-group-id="4885761117-7">]</span><span>
  </span><span data-group-id="4885761117-8">[</span><span>
    </span><span data-group-id="4885761117-9">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-9">]</span><span>,</span><span>
    </span><span data-group-id="4885761117-10">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-10">]</span><span>
  </span><span data-group-id="4885761117-8">]</span><span>
</span><span data-group-id="4885761117-5">&gt;</span></code></pre>
<p>
As you see, tensors have a type (s64) and a shape (2x2). Tensor operations are also done with the <code>Nx</code> module. To implement <a href="https://en.wikipedia.org/wiki/Softmax_function">the Softmax function</a>:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="2015320651-1">(</span><span data-group-id="2015320651-2">[</span><span data-group-id="2015320651-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="2015320651-3">]</span><span>,</span><span> </span><span data-group-id="2015320651-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="2015320651-4">]</span><span data-group-id="2015320651-2">]</span><span data-group-id="2015320651-1">)</span><span>
</span><span>iex&gt; </span><span>Nx</span><span>.</span><span>divide</span><span data-group-id="2015320651-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-6">(</span><span>t</span><span data-group-id="2015320651-6">)</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="2015320651-7">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-8">(</span><span>t</span><span data-group-id="2015320651-8">)</span><span data-group-id="2015320651-7">)</span><span data-group-id="2015320651-5">)</span><span>
</span><span data-group-id="2015320651-9">#</span><span data-group-id="2015320651-9">Nx.Tensor</span><span data-group-id="2015320651-9">&lt;</span><span>
  </span><span>f64</span><span data-group-id="2015320651-10">[</span><span>2</span><span data-group-id="2015320651-10">]</span><span data-group-id="2015320651-11">[</span><span>2</span><span data-group-id="2015320651-11">]</span><span>
  </span><span data-group-id="2015320651-12">[</span><span>
    </span><span data-group-id="2015320651-13">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="2015320651-13">]</span><span>,</span><span>
    </span><span data-group-id="2015320651-14">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="2015320651-14">]</span><span>
  </span><span data-group-id="2015320651-12">]</span><span>
</span><span data-group-id="2015320651-9">&gt;</span></code></pre>
<p>
The high-level features in Nx are:</p>
<ul>
  <li>
    <p>
Typed multi-dimensional tensors, where the tensors can be unsigned integers (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>), signed integers (<code>s8</code>, <code>s16</code>, <code>s32</code>, <code>s64</code>), floats (<code>f32</code>, <code>f64</code>) and brain floats (<code>bf16</code>);    </p>
  </li>
  <li>
    <p>
<a href="http://nlp.seas.harvard.edu/NamedTensor">Named tensors</a>, allowing developers to give names to each dimension, leading to more readable and less error prone codebases;    </p>
  </li>
  <li>
    <p>
Automatic differentiation, also known as autograd. The <code>grad</code> function provides reverse-mode differentiation, useful for simulations, training probabilistic models, etc;    </p>
  </li>
  <li>
    <p>
Tensors backends, which enables the main <code>Nx</code> API to be used to manipulate binary tensors, GPU-backed tensors, sparse matrices, and more;    </p>
  </li>
  <li>
    <p>
Numerical definitions, known as <code>defn</code>, provide multi-stage compilation of tensor operations to multiple targets, such as highly specialized CPU code or the GPU. The compilation can happen either ahead-of-time (AOT) or just-in-time (JIT) with a compiler of your choice;    </p>
  </li>
</ul>
<p>
For Python developers, <code>Nx</code> currently takes its main inspirations from <a href="https://numpy.org/"><code>Numpy</code></a> and <a href="https://github.com/google/jax"><code>JAX</code></a> but packaged into a single unified library.</p>
<p>
Our initial efforts have focused on the underlying abstractions. For example, while Nx implements dense tensors out-of-the-box, we also want the same high-level API to be valid for sparse tensors. You should also be able to use all functions in the <code>Nx</code> module with tensors that are backed by Elixir binaries and with tensors that are stored directly in the GPU.</p>
<p>
By ensuring the underlying tensor backend is ultimately replaceable, we can build an ecosystem of libraries on top of Nx, and allow end-users to experiment with different backends, hardware, and approaches to run their software on.</p>
<p>
<em>Nx’s mascot is the Numbat, a marsupial native to southern Australia. Unfortunately the Numbat are endangered and it is estimated to be fewer than 1000 left. If you are excited about Nx, consider donating to Numbat conservation efforts, such as <a href="https://www.numbat.org.au/">Project Numbat</a> and <a href="https://www.australianwildlife.org/">Australian Wildlife Conservancy</a>.</em></p>
<h2>
Numerical definitions</h2>
<p>
One of the most important features in <code>Nx</code> is the numerical definition, called <code>defn</code>. Numerical definitions are a subset of Elixir tailored for numerical computing. Here is the <code>softmax</code> formula above, now written with <code>defn</code>:</p>
<pre><code><span>defmodule</span><span> </span><span>Formula</span><span> </span><span data-group-id="4810618200-1">do</span><span>
  </span><span>import</span><span> </span><span>Nx.Defn</span><span>

  </span><span>defn</span><span> </span><span>softmax</span><span data-group-id="4810618200-2">(</span><span>t</span><span data-group-id="4810618200-2">)</span><span> </span><span data-group-id="4810618200-3">do</span><span>
    </span><span>inspect_expr</span><span data-group-id="4810618200-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-5">(</span><span>t</span><span data-group-id="4810618200-5">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="4810618200-6">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-7">(</span><span>t</span><span data-group-id="4810618200-7">)</span><span data-group-id="4810618200-6">)</span><span data-group-id="4810618200-4">)</span><span>
  </span><span data-group-id="4810618200-3">end</span><span>
</span><span data-group-id="4810618200-1">end</span></code></pre>
<p>
The first difference we see with <code>defn</code> is that Elixir’s built-in operators have been augmented to also work with tensors. Effectively, <code>defn</code> replaces Elixir’s <code>Kernel</code> with <code>Nx.Defn.Kernel</code>.</p>
<p>
However, <code>defn</code> goes even further. When using <code>defn</code>, <code>Nx</code> builds a computation with all of your tensor operations. Let’s inspect it:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="0860724160-1">(</span><span>t</span><span data-group-id="0860724160-1">)</span><span> </span><span data-group-id="0860724160-2">do</span><span>
  </span><span>inspect_expr</span><span data-group-id="0860724160-3">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-4">(</span><span>t</span><span data-group-id="0860724160-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="0860724160-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-6">(</span><span>t</span><span data-group-id="0860724160-6">)</span><span data-group-id="0860724160-5">)</span><span data-group-id="0860724160-3">)</span><span>
</span><span data-group-id="0860724160-2">end</span></code></pre>
<p>
Now when invoked, you will see this printed:</p>
<pre><code><span>iex(3)&gt; </span><span>Formula</span><span>.</span><span>softmax</span><span data-group-id="4848142189-1">(</span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4848142189-2">(</span><span data-group-id="4848142189-3">[</span><span data-group-id="4848142189-4">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4848142189-4">]</span><span>,</span><span> </span><span data-group-id="4848142189-5">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4848142189-5">]</span><span data-group-id="4848142189-3">]</span><span data-group-id="4848142189-2">)</span><span data-group-id="4848142189-1">)</span><span>
</span><span data-group-id="4848142189-6">#</span><span data-group-id="4848142189-6">Nx.Tensor</span><span data-group-id="4848142189-6">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-7">[</span><span>2</span><span data-group-id="4848142189-7">]</span><span data-group-id="4848142189-8">[</span><span>2</span><span data-group-id="4848142189-8">]</span><span>
  
  </span><span>Nx.Defn.Expr</span><span>
  </span><span>parameter</span><span> </span><span>a</span><span>                                 </span><span>s64</span><span data-group-id="4848142189-9">[</span><span>2</span><span data-group-id="4848142189-9">]</span><span data-group-id="4848142189-10">[</span><span>2</span><span data-group-id="4848142189-10">]</span><span>
  </span><span>b</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-11">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-11">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-12">[</span><span>2</span><span data-group-id="4848142189-12">]</span><span data-group-id="4848142189-13">[</span><span>2</span><span data-group-id="4848142189-13">]</span><span>
  </span><span>c</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-14">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-14">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-15">[</span><span>2</span><span data-group-id="4848142189-15">]</span><span data-group-id="4848142189-16">[</span><span>2</span><span data-group-id="4848142189-16">]</span><span>
  </span><span>d</span><span> </span><span>=</span><span> </span><span>sum</span><span> </span><span data-group-id="4848142189-17">[</span><span> </span><span>c</span><span>,</span><span> </span><span>axes</span><span>:</span><span> </span><span>nil</span><span>,</span><span> </span><span>keep_axes</span><span>:</span><span> </span><span>false</span><span> </span><span data-group-id="4848142189-17">]</span><span>  </span><span>f64</span><span>
  </span><span>e</span><span> </span><span>=</span><span> </span><span>divide</span><span> </span><span data-group-id="4848142189-18">[</span><span> </span><span>b</span><span>,</span><span> </span><span>d</span><span> </span><span data-group-id="4848142189-18">]</span><span>                         </span><span>f64</span><span data-group-id="4848142189-19">[</span><span>2</span><span data-group-id="4848142189-19">]</span><span data-group-id="4848142189-20">[</span><span>2</span><span data-group-id="4848142189-20">]</span><span>
</span><span data-group-id="4848142189-6">&gt;</span><span>
</span><span data-group-id="4848142189-21">#</span><span data-group-id="4848142189-21">Nx.Tensor</span><span data-group-id="4848142189-21">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-22">[</span><span>2</span><span data-group-id="4848142189-22">]</span><span data-group-id="4848142189-23">[</span><span>2</span><span data-group-id="4848142189-23">]</span><span>
  </span><span data-group-id="4848142189-24">[</span><span>
    </span><span data-group-id="4848142189-25">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="4848142189-25">]</span><span>,</span><span>
    </span><span data-group-id="4848142189-26">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="4848142189-26">]</span><span>
  </span><span data-group-id="4848142189-24">]</span><span>
</span><span data-group-id="4848142189-21">&gt;</span></code></pre>
<p>
This computation graph can also be transformed programatically. The transformation is precisely how we implement automatic differentiation, also known as <code>autograd</code>, by traversing each node and computing their derivative:</p>
<pre><code><span>defn</span><span> </span><span>grad_softmax</span><span data-group-id="5969204985-1">(</span><span>t</span><span data-group-id="5969204985-1">)</span><span> </span><span data-group-id="5969204985-2">do</span><span>
  </span><span>grad</span><span data-group-id="5969204985-3">(</span><span>t</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-4">(</span><span>t</span><span data-group-id="5969204985-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5969204985-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-6">(</span><span>t</span><span data-group-id="5969204985-6">)</span><span data-group-id="5969204985-5">)</span><span data-group-id="5969204985-3">)</span><span>
</span><span data-group-id="5969204985-2">end</span></code></pre>
<p>
Finally, this computation graph can also be handed out to different compilers. As an example, we have implemented bindings for <a href="https://www.tensorflow.org/xla/">Google’s XLA</a> compiler, called EXLA. We can ask the <code>softmax</code> function to use this new compiler with a module attribute:</p>
<pre><code><span>@defn_compiler</span><span> </span><span data-group-id="5313365207-1">{</span><span>EXLA</span><span>,</span><span> </span><span>client</span><span>:</span><span> </span><span>:host</span><span data-group-id="5313365207-1">}</span><span>
</span><span>defn</span><span> </span><span>softmax</span><span data-group-id="5313365207-2">(</span><span>t</span><span data-group-id="5313365207-2">)</span><span> </span><span data-group-id="5313365207-3">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-4">(</span><span>t</span><span data-group-id="5313365207-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5313365207-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-6">(</span><span>t</span><span data-group-id="5313365207-6">)</span><span data-group-id="5313365207-5">)</span><span>
</span><span data-group-id="5313365207-3">end</span></code></pre>
<p>
Once <code>softmax</code> is called, <code>Nx.Defn</code> will invoke <code>EXLA</code> to emit a just-in-time and highly-specialized compiled version of the code, tailored to the tensor type and shape. By passing <code>client: :cuda</code> or <code>client: :rocm</code>, the code can be compiled for the GPU. For reference, here are some benchmarks of the function above when called with a tensor of one million random float values on different clients:</p>
<pre><code>Name                       ips        average  deviation         median         99th %
xla gpu f32 keep      15308.14      0.0653 ms    ±29.01%      0.0638 ms      0.0758 ms
xla gpu f64 keep       4550.59        0.22 ms     ±7.54%        0.22 ms        0.33 ms
xla cpu f32             434.21        2.30 ms     ±7.04%        2.26 ms        2.69 ms
xla gpu f32             398.45        2.51 ms     ±2.28%        2.50 ms        2.69 ms
xla gpu f64             190.27        5.26 ms     ±2.16%        5.23 ms        5.56 ms
xla cpu f64             168.25        5.94 ms     ±5.64%        5.88 ms        7.35 ms
elixir f32                3.22      311.01 ms     ±1.88%      309.69 ms      340.27 ms
elixir f64                3.11      321.70 ms     ±1.44%      322.10 ms      328.98 ms

Comparison:
xla gpu f32 keep      15308.14
xla gpu f64 keep       4550.59 - 3.36x slower +0.154 ms
xla cpu f32             434.21 - 35.26x slower +2.24 ms
xla gpu f32             398.45 - 38.42x slower +2.44 ms
xla gpu f64             190.27 - 80.46x slower +5.19 ms
xla cpu f64             168.25 - 90.98x slower +5.88 ms
elixir f32                3.22 - 4760.93x slower +310.94 ms
elixir f64                3.11 - 4924.56x slower +321.63 ms</code></pre>
<p>
Where <code>keep</code> indicates the tensor was kept on the device instead of being transferred back to Elixir. You can see the benchmark in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/bench"><code>bench</code></a> directory and find some examples in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/examples"><code>examples</code></a> directory of the EXLA project.</p>
<h3>
Compiling numerical definitions</h3>
<p>
Before moving forward, it is important for us to take a look at how numerical definitions are compiled. For example, take the <code>softmax</code> function:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="5791259392-1">(</span><span>t</span><span data-group-id="5791259392-1">)</span><span> </span><span data-group-id="5791259392-2">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-3">(</span><span>t</span><span data-group-id="5791259392-3">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5791259392-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-5">(</span><span>t</span><span data-group-id="5791259392-5">)</span><span data-group-id="5791259392-4">)</span><span>
</span><span data-group-id="5791259392-2">end</span></code></pre>
<p>
One might think that Elixir takes the AST of the softmax function above and compiles it directly to the GPU. However, that’s not the case! Numerical definitions are first compiled to Elixir code that will emit the computation graph and this computation graph is then compiled to the GPU. The multiple stages go like this:</p>
<pre><code>Elixir AST
-&gt; compiles to .beam (Erlang VM bytecode)
   -&gt; executes into defn AST
      -&gt; compiles to GPU</code></pre>
<p>
This multi-stage programming is made possible thanks to Elixir macros. For example, when you see a conditional inside <code>defn</code>, that conditional looks exactly like Elixir conditionals, but it will be compiled to an accelerator:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="8102420814-1">(</span><span>t</span><span data-group-id="8102420814-1">)</span><span> </span><span data-group-id="8102420814-2">do</span><span>
  </span><span>if</span><span> </span><span>Nx</span><span>.</span><span>any?</span><span data-group-id="8102420814-3">(</span><span>t</span><span data-group-id="8102420814-3">)</span><span> </span><span data-group-id="8102420814-4">do</span><span>
    </span><span>-</span><span>1</span><span>
  </span><span data-group-id="8102420814-4">else</span><span>
    </span><span>1</span><span>
  </span><span data-group-id="8102420814-4">end</span><span>
</span><span data-group-id="8102420814-2">end</span></code></pre>
<p>
In a nutshell, <code>defn</code> provides us with a subset of Elixir for numerical computations that can be compiled to specific hardware, such as CPU, GPU, and other accelerators. All of this was possible without making changes or forking the language.</p>
<p>
And while <code>defn</code> is a subset of the language, it is a considerable one. You will find support for:</p>
<ul>
  <li>
Mathematical operators  </li>
  <li>
Pipes (<code>|&gt;</code>), module attributes, the access syntax (i.e. <code>tensor[1][1..-1]</code>), etc  </li>
  <li>
Elixir macros constructs (imports, aliases, etc)  </li>
  <li>
Control-flow with conditionals (both <code>if</code> and <code>cond</code>), loops (coming soon), etc  </li>
  <li>
Transformations, an explicit mechanism to invoke Elixir code from a <code>defn</code> (which enables constructs such as <code>grad</code>)  </li>
</ul>
<p>
And more coming down the road.</p>
<h2>
Why functional programming?</h2>
<p>
At this point, you may be wondering: is functional programming a good fit for numerical computing? One of the main concerns is that immutability can be expensive when working with large blobs of memory. And that’s a valid concern! In fact, when using the default tensor backend, tensors will be backed by Elixir binaries which are copied on every operation. That’s why it was critical for us to design <code>Nx</code> with pluggable backends from day one.</p>
<p>
However, as we move to higher-level abstractions, such as numerical definitions, we will start to reap the benefits of functional programming.</p>
<p>
For example, in order to build computation graphs, immutability becomes an indispensable tool both in terms of implementation and in terms of reasoning. The JAX library for Python, which has been one of the guiding lights for Nx design, also promotes functional and immutable principles:</p>
<blockquote>
  <p>
<em>JAX is intended to be used with a functional style of programming</em>  </p>
  <p>
— <a href="https://jax.readthedocs.io/en/latest/jax.ops.html?highlight=functional#indexed-update-operators">JAX Docs</a>  </p>
</blockquote>
<blockquote>
  <p>
<em>Unlike NumPy arrays, JAX arrays are always immutable</em>  </p>
  <p>
— <a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html?highlight=immutable#JAX-vs.-NumPy">JAX Docs</a>  </p>
</blockquote>
<p>
Similarly, frameworks like <a href="https://thinc.ai/">Thinc.ai</a> argue that functional programming can provide better abstractions and more composable building blocks for deep learning libraries.</p>
<p>
We hope that, by exploring these ideas in a language that is functional by design, Elixir can bring new ideas and insights at the higher-level.</p>
<h2>
What is next?</h2>
<p>
There is a lot of work ahead of us …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246484</guid>
            <pubDate>Wed, 24 Feb 2021 04:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Selects Oshkosh Defense for Next Generation Delivery Vehicle Fleet]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26246116">thread link</a>) | @jonbaer
<br/>
February 23, 2021 | https://oshkoshcorp.com/en/news/2-23-21-usps | <a href="https://web.archive.org/web/*/https://oshkoshcorp.com/en/news/2-23-21-usps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h3>USPS selects Oshkosh Defense for Next Generation Delivery Vehicle fleet</h3>
        <p><span>2/23/2021</span></p>

<p><span><strong><span>OSHKOSH, Wis. (February 23, 2021)</span></strong>&nbsp;—&nbsp;The U.S. Postal Service (USPS) announced today that it has awarded Oshkosh Defense, a wholly owned subsidiary of Oshkosh Corporation (NYSE: OSK),</span><span> an indefinite delivery, indefinite quantity (IDIQ) contract to produce the Next Generation Delivery Vehicle (NGDV), the USPS’s first large-scale fleet procurement in three decades. The competitively awarded contract allows for the delivery of between 50,000 and 165,000 vehicles over a period of 10 years.</span></p>
<p><span>“Oshkosh operates with unparalleled commitment to those who depend on our products and services to build, protect and serve communities around the world. We are honored to have been selected by the USPS to support their important work by manufacturing American-made Next Generation Delivery Vehicles that will connect every home and business across the United States for decades to come,” said John Pfeifer, President &amp; Chief Operating Officer, Oshkosh Corporation.</span></p>
<p><span>Oshkosh Defense will manufacture <span>both zero emission battery electric vehicles (BEV) and fuel-efficient low-emission internal combustion engine vehicles (ICE), </span>upgrading the USPS fleet to be increasingly sustainable. Under the contract announced today, the USPS has committed to pay Oshkosh Defense $482 million to initiate engineering efforts to finalize the production vehicle design, and for tooling and factory build-out activities that are necessary prior to vehicle production.</span></p>
<p><span>“Our century-long history of delivering products to customers, operating in some of the most demanding and severe conditions on the planet, uniquely positions us to bring exceptional reliability, safety, and maintainability to USPS’s Next Generation Delivery Vehicles,” said John Bryant, Executive Vice President, Oshkosh Corporation, and President, Oshkosh Defense. </span></p>
<p><span>“Partnering with trusted suppliers, we have developed a purpose-built solution to support the current and future needs of the USPS,” Bryant concluded. Production of the next generation delivery vehicle is expected to begin in 2023.</span></p>

<p><strong><span>About Oshkosh Defense</span></strong></p>
<p><span>Oshkosh Defense is a global leader in the design, production and sustainment of best-in-class military vehicles and mobility systems. As a pioneer of combat-ready vehicle solutions, Oshkosh develops and applies emerging technologies that advance troop safety and mission success. Setting the industry standard for sustaining fleet readiness, Oshkosh ensures every solution is supported worldwide throughout its entire life cycle.</span></p>
<p><span>Oshkosh Defense, LLC is an Oshkosh Corporation company [NYSE: OSK].</span></p>
<p><span>Learn more about Oshkosh Defense at </span><a href="https://urldefense.com/v3/__http:/www.oshkoshdefense.com/__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9LmLn1gg$"><span>oshkoshdefense.com</span></a><span>.&nbsp; </span></p>

<p><strong><span>About Oshkosh Corporation</span></strong></p>
<p><span>At Oshkosh (NYSE: OSK), we make innovative, mission-critical equipment to help everyday heroes advance communities around the world. Headquartered in Wisconsin, Oshkosh Corporation employs more than 14,000 team members worldwide, all united behind a common cause: to make a difference in people’s lives. Oshkosh products can be found in more than 150 countries under the brands of JLG®, Pierce®, Oshkosh® Defense, McNeilus®, IMT®, Frontline™, Jerr-Dan®, Oshkosh® Airport Products, Pratt Miller, and London™. For more information, visit </span><a href="https://urldefense.com/v3/__http:/oshkoshcorp.com__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9WR_C6yk$"><span>oshkoshcorp.com</span></a><span>.</span></p>
<p><sup><span>®</span></sup><span>, ™ All brand names referred to in this news release are trademarks of Oshkosh Corporation or its subsidiary companies.</span></p>



<p><span><strong><span>Forward Looking Statements</span></strong></span></p>
<p><span>This news release contains statements that the Company believes to be “forward-looking statements” within the meaning of the Private Securities Litigation Reform Act of 1995. All statements other than statements of historical fact, including, without limitation, statements regarding the Company’s future financial position, business strategy, targets, projected sales, costs, earnings, capital expenditures, debt levels and cash flows, and plans and objectives of management for future operations, are forward-looking statements. When used in this news release, words such as “may,” “will,” “expect,” “intend,” “estimate,” “anticipate,” “believe,” “should,” “project” or “plan” or the negative thereof or variations thereon or similar terminology are generally intended to identify forward-looking statements. These forward-looking statements are not guarantees of future performance and are subject to risks, uncertainties, assumptions and other factors, some of which are beyond the Company’s control, which could cause actual results to differ materially from those expressed or implied by such forward-looking statements. These factors include the overall impact of the COVID-19 pandemic on the Company’s business, results of operations and financial condition; the duration and severity of the COVID-19 pandemic; actions that may be taken by governmental authorities and others to address or otherwise mitigate the impact of the COVID-19 pandemic; the negative impacts of the COVID-19 pandemic on global economies and the Company’s customers, suppliers and employees; the cyclical nature of the Company’s access equipment, commercial and fire &amp; emergency markets, which are particularly impacted by the strength of U.S. and European economies and construction seasons; the Company’s ability to increase prices or impose surcharges to raise margins or to offset higher input costs, including increased commodity, raw material, labor and freight costs; the Company’s estimates of access equipment demand which, among other factors, is influenced by customer historical buying patterns and rental company fleet replacement strategies; the strength of the U.S. dollar and its impact on Company exports, </span><span>translation of foreign sales and the cost of purchased materials; the expected level and timing of U.S. Department of Defense (DoD) and international defense customer procurement of products and services and acceptance of and funding or payments for such products and services; the Company’s ability to predict the level and timing of orders for indefinite delivery/indefinite quantity contracts with the U.S. federal government; risks related to reductions in government expenditures in light of U.S. defense budget pressures and an uncertain DoD tactical wheeled vehicle strategy; the impact of any DoD solicitation for competition for future contracts to produce military vehicles; potential impacts of budget constraints facing the USPS and continuously changing demands for postal services; risks related to facilities expansion, consolidation and alignment, including the amounts of related costs and charges and that anticipated cost savings may not be achieved; projected adoption rates of work at height machinery in emerging markets; the impact of severe weather, natural disasters or pandemics that may affect the Company, its suppliers or its customers; performance issues with suppliers or subcontractors; risks related to the collectability of receivables, particularly for those businesses with exposure to construction markets; the cost of any warranty campaigns related to the Company’s products; risks associated with international operations and sales, including compliance with the Foreign Corrupt Practices Act; risks that a trade war and related tariffs could reduce the competitiveness of the Company’s products; the Company’s ability to comply with complex laws and regulations applicable to U.S. government contractors; cybersecurity risks and costs of defending against, mitigating and responding to data security threats and breaches; the Company’s ability to successfully identify, complete and integrate acquisitions and to realize the anticipated benefits associated with the same; and risks related to the Company’s ability to successfully execute on its strategic road map and meet its long-term financial goals. Additional information concerning these and other factors is contained in the Company’s filings with the Securities and Exchange Commission. All forward-looking statements speak only as of the date of this news release. The Company assumes no obligation, and disclaims any obligation, to update information contained in this news release. Investors should be aware that the Company may not update such information until the Company’s next quarterly earnings conference call, if at all.</span></p>

<p><span>For more information, contact:</span></p>
<p><span><br>
Financial:<br>
Patrick Davidson<br>
Senior Vice President, Investor Relations<br>
920.502.3266</span></p>
<p><span>Media:<br>
Bryan Brandt<br>
Senior Vice President, Chief Marketing Officer<br>
920.502.3670</span></p>
<p><span>Alexandra Hittle<br>
Director, Global Marketing and Communications<br>
920.410.1929</span></p>
<p><span><br>
Source: Oshkosh Corporation</span></p>
    </div></div>]]>
            </description>
            <link>https://oshkoshcorp.com/en/news/2-23-21-usps</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246116</guid>
            <pubDate>Wed, 24 Feb 2021 02:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Games on Your Own as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 19 (<a href="https://news.ycombinator.com/item?id=26246049">thread link</a>) | @Eyas
<br/>
February 23, 2021 | https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>
series, I give an accelerated introduction to game development in Unity.
<a href="http://eepurl.com/gVgusL">Subscribers</a> have been following this series over the
past few months, often suggesting areas to cover or elaborate on. A few months
ago, a reader<!-- -->—<!-- -->also a software engineer<!-- -->—<!-- -->reached out to me (lightly
edited, emphasis mine):</p><blockquote><p><strong>The biggest unknown for me is: How do I start?</strong> What does the process of
creating a game look like? Should I build the scenes first? Should I design
the gameplay mechanics first? With business software, it’s much more familiar.
It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>While there is no single correct answer, we can still make some distinctions
that can help get us oriented. The answer will also undoubtedly depend on <em>who</em>
is doing the development: an individual, small indie team, or larger studio? If
an individual, the answer will also depend on their primary skillset: a
developer, artist, or designer?</p><p>Here, I’ll give heuristics especially helpful for individual Software Engineers
building a game on their own as a side project, hobby, or proof-of-concept.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/28a80/irfan-simsar-wxWulfjN-G0-unsplash.webp 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/8d2ea/irfan-simsar-wxWulfjN-G0-unsplash.webp 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/43d96/irfan-simsar-wxWulfjN-G0-unsplash.webp 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4293a/irfan-simsar-wxWulfjN-G0-unsplash.webp 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/dc28f/irfan-simsar-wxWulfjN-G0-unsplash.webp 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4cda9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/c60e9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/111a0/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg" alt="Scrum board, at an office" title="Scrum board, at an office" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Photo by İrfan Simsar, <a href="https://unsplash.com/photos/wxWulfjN-G0">via unsplash</a>.</p></figcaption></figure><h2>Questions you should ask yourself</h2><p>Before we start, here are some questions you should ask yourself.</p><h3>Do you know <em>what</em> you’re building?</h3><p>Do you know what your game is about? Do you have a sense of what game mechanics
your game will have? Do you know what genre, controls, and themes this game will
have?</p><p>If <em>yes</em>, you’re ready to decide <strong><a href="#start-coding">where to start coding</a></strong>.
Otherwise, you have a few more questions to ask yourself.</p><h3>Do you <em>want</em> to know what you’re building?</h3><p>It’s totally fine not to have a project in mind! Maybe you’re prototyping.
Perhaps you’re throwing a bunch of mini-games on the wall and seeing what
sticks. Or you’re looking for inspiration and trying to implement random
mechanics to see what feels fun.</p><p><strong>If you’re hoping to begin working on a specific, cohesive game</strong>, you will
likely want to know what you’re building. Consider brainstorming and sketching
out an informal
<a href="https://en.wikipedia.org/wiki/Game_design_document">game design document</a>.
There are
<a href="https://www.google.com/search?q=game+design+document+template">plenty of templates</a>
of various levels of detail you could decide to use. Especially as a software
engineer toying with abstract ideas in my brain, I’ll start with a super
high-level GDD, covering the feel, themes, genre, and mechanics of the game I
have in mind. Maybe a few pictures or sketches for inspiration, and that’s it.
The key part of this exercise will be the list of mechanics I’m working on.</p><p><strong>If you want to prototype and experiment</strong>, you should already have a vague
sense of 1-2 mechanics that could be fun: Maybe unusual movement or a different
control scheme. It could be a traditional mechanic that you’re wondering how to
implement. For instance, I might decide to build a 3rd Person character and
camera controller to see the “feel” of it, experiment with it a tiny bit, and do
something smooth and polish that I feel good about. I might end up keeping that
code in my back pocket for later, or I might use play-through sessions with that
controller to move around a scene, add a few assets, and use that as a starting
place to see the “feel” various mechanics and designs.</p><h2 id="start-coding">I know the mechanics I care about. Now what?</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/28a80/iterative-development.webp 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/dfbce/iterative-development.webp 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/4cda9/iterative-development.jpg 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" alt="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." title="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>By Dave Gray, <a href="https://www.flickr.com/photos/davegray/6865783267">via Flickr</a>.
<a href="https://creativecommons.org/licenses/by-nd/2.0/">CC BY-ND 2.0</a>.</p></figcaption></figure><p>The goal of many iterative software development models is to de-risk software
development. You do that by failing fast and getting feedback early. In game
development, the primary metric for success is a feeling: the game should be
fun. So, when deciding what to start with when working on a game, one good
question to ask is: <em>“How can I see if this game is fun as soon as possible?”</em>
or <em>“How can I implement the ‘fun’ part of the game ASAP?”</em></p><p>One way to do that is to look at a game’s mechanics and implement them in some
order. The advice that resonates with me is implementing game mechanics in order
of what the most <em>“core”</em> mechanic first.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/28a80/scrolling-shooter-example.webp 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/8d2ea/scrolling-shooter-example.webp 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a3397/scrolling-shooter-example.png 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/png">
          <img src="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" alt="Example of a space scrolling shooter game" title="Example of a space scrolling shooter game" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Space Scrolling Shooter. By Beyond2000, via
<a href="https://commons.wikimedia.org/wiki/File:RosAsmGameSpace.png">Wikimedia Commons</a>.
<a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a>.</p></figcaption></figure><p>Let’s take <a href="https://en.wikipedia.org/wiki/Strikers_1945">Strikers 1945</a>—the
plane shooting game—as an example. Here’s my attempt at writing its main
mechanics in descending order of importance:</p><ol><li>Movement: Navigate a vertically scrolling world</li><li>Obstacles &amp; Dodging: Player can collide with stationary obstacles and debris</li><li>Shooting: Player can shoot straight ahead to defeat obstacles</li><li>Enemies: Enemies are moving obstacles that can shoot back</li><li>Player Health: A player can take a finite number of hits before losing the
game</li><li>Enemy Health: Some enemies take multiple shots to destroy</li><li>Boosts: The player can pick up boosts that improve health, shooting, etc.</li></ol><p>… and so on.</p><p>If I’m trying to develop <em>1945</em> from scratch, I will implement that list in that
order. The game’s mechanics build on each other, so I can only tell if shooting
is “fun” is if I can move around the screen and if there are obstacles I’m
trying to clear (otherwise, there’s no urgency to just pressing <em>Space</em> and
seeing projectiles coming out of a plane).</p><p>In simpler games, we might order our mechanics so that every new feature adds to
a game’s feel. So, with every new mechanic you add, you can play the game and
tell if it’s adding what you hope for it to add.</p><p>In more complex games, some of the “core” mechanics might be too ‘standard’ to
be “risky” <em>per se</em>, but you’ll still need the core mechanics implemented to
assess how fun the other mechanics are. You might choose to use a simpler
throwaway implementation, like a few lines of input-handling code and Unity’s
<code>CharacterController</code> component. You’ll want your core mechanics just smooth
enough that they don’t ruin the fun of the things you’ll layer on top of it.
Another approach here is to use the asset store. I’ve previously mentioned the
<a href="https://assetstore.unity.com/packages/tools/game-toolkits/ufps-ultimate-fps-106748?aid=1011leWs6">Ultimate FPS (UFPS)</a>
asset, which you might choose to use when building an FPS game, and move on to
implementing the combat or some more unique (but still “core” feature of the
gameplay first).</p><h2>So I picked a mechanic, but where do I start programming <em>within</em> this mechanic?</h2><p><em>Within</em> a mechanic, your traditional software engineering intuition becomes
helpful. I hope to spend subsequent articles discussing patterns that are
especially helpful in Unity, but here are a few to consider:</p><ul><li>Work within Unity’s Object-Component paradigm. If you’re adding a new
<em>capability</em> to your player, write it as its own component.</li><li><em>Tuning</em> is especially important in game development; representing a
mechanic’s interesting pieces as <em>configurable</em>, <em>serializable</em> data that
can be input to a component will help you playtest and iterate.</li><li>Don’t shy away from using plain-old data objects to represent core concepts
you’re working with. E.g., health, ammo information, or powerups. Make it
serializable if you want it passed around in the editor (or saved to disk
across sessions).</li><li>Where pieces of a concept don’t correspond to a single object in a scene,
consider using Scriptable Objects to do the jobs. Scriptable Objects
introduce many patterns that might help represent what you’re doing.</li></ul><p>A few articles I have already written might prove helpful:</p><ul><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">Basic Concepts in Unity for Software Engineers</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices/">6 Software Practices to Keep, Shed, and Adopt in Unity</a></li><li><a href="https://blog.eyas.sh/2020/09/patterns-in-unity-adventure-tutorial/">Making Sense of Patterns in Unity’s Adventure Game Tutorial</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">Understanding Unity Engine Objects</a></li></ul><p>You might also take a look at patterns covered in:</p><ul><li><a href="https://unity.com/how-to/architect-game-code-scriptable-objects">Three ways to architect your game with ScriptableObjects</a>,
via the Unity Blog (based on
<a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">his talk</a>)</li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt3-input-system/">Unity Input System, from Basic Principles</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-1-pathfinding/">Pathfinding with NavMesh</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-2-raycasting/">Physics Raycasting</a></li></ul><p>Once you have a stronger intuition of <em>how</em> you can represent different kinds of
data and abstractions, the reader’s initial comment also becomes the answer:</p><blockquote><p>It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>Beyond learning about useful patterns and abstractions in game development to
make development clearer and cleaner, the real takeaway is to decide <em>what</em> to
work on at a macro-level.</p><h2>How much time should I spend on one mechanic?</h2><p>As you’re developing a mechanic, what’s a good signal you should move on to the
next on your list? Generally, that would be when you’re convinced:</p><ul><li>This mechanic <em>feels fun</em> and <em>adds to the game</em>,</li><li>Your implementation adds <em>just the
<a href="https://www.e4developer.com/2018/11/21/having-just-the-right-amount-of-technical-debt/">right amount</a></em>
of technical debt.</li></ul><p>Traditionally, folks will often say to worry about polish at the later stages of
your development. In his GDC 2016 micro-talk <em>“Pizzazz First, Polish Later”</em>,
Lee Perry makes a distinction in this traditional wisdom.</p><div> <p> <iframe title="" src="https://www.youtube.com/embed/d8QAVGeEj-U?rel=0" allowfullscreen=""></iframe> </p> </div><p>Certain levels of pizzazz might give you a better sense of your mechanic and how
fun it feels. A certain amount of polish or pizzazz can also help you see your
game in a new light and motivate you to keep going.
<a href="https://gameanalytics.com/blog/squeezing-more-juice-out-of-your-game-design/">Juice</a>
is another form of pizzazz; in certain dull moments of your game design, adding
juice might be a low-cost way to get back into the groove of things.</p><p>I hope the conflicting advice shows there isn’t a silver bullet on what to add
when. Rather—as in traditional software development—this choice is about a
series of trade-offs that depend on the developer, the project, and lots more.</p><h2>Are you developing a game or architecting systems?</h2><p>For some software engineers, we’re often drawn to writing code for systems that
seem <em>interesting</em>. Sometimes, I have a game in mind, but <em>really</em>, I’m
interested in implementing a cool inventory system where <em>everything</em> in the
game is an item. It might not be the core mechanic, but it might be the thing I
want to build.</p><p>It’s important to recognize when you’re not building a game but building a
system. If you just quit your job to be a full-time indie gamedev and have a
year of runway before your run out of cash, it is probably a bad idea to start
building a complex inventory system that you don’t even know you’ll need<sup id="fnref-1"><a href="#fn-1">1</a></sup>.
But if you’re programming on the side to flex your game development muscle, then
go right at it.</p><hr><p>I don’t think I’m qualified <em>per se</em> to answer the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246049</guid>
            <pubDate>Wed, 24 Feb 2021 02:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use WebSockets with Your Vue Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245895">thread link</a>) | @saranshk
<br/>
February 23, 2021 | https://masteringjs.io/tutorials/vue/vue-websocket | <a href="https://web.archive.org/web/*/https://masteringjs.io/tutorials/vue/vue-websocket">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
  
  <p>
    Feb 18, 2021
  </p>
  
  
  <p><a href="https://masteringjs.io/tutorials/node/websockets">WebSockets</a> are a great tool for when you want to show real time changes in data.
For example, a server can push stock market price changes to the client rather than the client needing to ask for the changes via a HTTP request.
With this being said, below you will find an example of a simple Vue application that shows the current time to the user and where
the user can send a simple message to the websocket.</p>
<pre><code>  <span>const</span> app = <span>new</span> Vue({
    <span>data</span>: <span><span>()</span> =&gt;</span> ({ <span>time</span>: <span>null</span> }),
    <span>template</span>: <span>`
      &lt;div&gt;
        &lt;h2&gt;{{time}}&lt;/h2&gt;
      &lt;/div&gt;
    `</span>,
    <span>mounted</span>: <span><span>function</span>(<span></span>)</span>{
      <span>let</span> connection = <span>new</span> WebSocket(<span>'ws://localhost:3000/'</span>);
      connection.onmessage = <span>(<span>event</span>) =&gt;</span> {
        
        
        
        <span>this</span>.time = event.data;
      }
    }
  });
  app.$mount(<span>"#content"</span>);</code></pre>
<p>Below is an example websocket server that you can use with the above Vue code.</p>
<pre><code><span>"use strict"</span>;

<span>const</span> serverPort = <span>3000</span>;
<span>const</span> express = <span>require</span>(<span>"express"</span>);
<span>const</span> http = <span>require</span>(<span>"http"</span>);
<span>const</span> WebSocket = <span>require</span>(<span>"ws"</span>);

<span>const</span> app = express();
<span>const</span> server = http.createServer(app);
<span>const</span> websocketServer = <span>new</span> WebSocket.Server({ server });


websocketServer.on(<span>"connection"</span>, (webSocketClient) =&gt; {
  
  webSocketClient.send(<span>"The time is: "</span>);
  setInterval(<span><span>()</span> =&gt;</span> {
    <span>let</span> time = <span>new</span> <span>Date</span>();
    webSocketClient.send(<span>"The time is: "</span> + time.toTimeString());
  }, <span>1000</span>);
});


server.listen(<span>3000</span>, () =&gt; {
  <span>console</span>.log(<span>"Websocket server started on port 3000"</span>);
});</code></pre>

  <hr>
<div>
  <p><i>
    <a href="https://vueschool.io/">Vue School</a> has some of our favorite Vue
    video courses. Their Vue.js Master Class walks you through building a real
    world application, and does a great job of teaching you how to integrate Vue
    with Firebase.
    <a href="https://vueschool.io/courses/the-vuejs-master-class?friend=mongoose">Check it out!</a>
  </i></p><p><a href="https://vueschool.io/courses/the-vuejs-master-class?friend=mongoose">
      <img src="https://masteringjs.io/assets/vueschool.png">
    </a>
  </p>
 </div>

  <hr>
  
    <h2>More Vue Tutorials</h2>
    <ul>
    
    <li><a href="https://masteringjs.io/tutorials/vue/vue-d3">How to Use D3.js in Your Vue Projects</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/books">Best Books to Learn Vue in 2021</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/chartjs">How to Use Chart.js with Vue</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-sfc">Vue Single-File Components</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/reactivity">Reactivity in Vue 3</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-3-components">Components in Vue 3</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-3">What's New in Vue 3</a></li>
  
    </ul>
  

      </div></div>]]>
            </description>
            <link>https://masteringjs.io/tutorials/vue/vue-websocket</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245895</guid>
            <pubDate>Wed, 24 Feb 2021 02:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technological singularity may have already happened, Bitcoin is the result]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26245815">thread link</a>) | @valec
<br/>
February 23, 2021 | http://disciples.technoslug.org/satoshi.htm | <a href="https://web.archive.org/web/*/http://disciples.technoslug.org/satoshi.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><b>MUSINGS ON SATOSHI</b></p>

<p>2021-02-23</p>

<p>-----------</p>

<p>The technological singularity may have already happened, and
perhaps bitcoin is the result. As the value of Satoshi Nakamoto's wallet
increases, so does the potential danger to humanity, as we have no idea who the
creator of this technology is. </p>

<p>If a hyper-intelligent self-aware AI had the goal of
improving itself and becoming more powerful, what would the most effective way
to do that be? One possibility: use capitalism to incentivize humans to give
the AI near-unlimited computing power.</p>

<p><b>Technological
singularity</b><br>
<a href="https://en.wikipedia.org/wiki/Technological_singularity">https://en.wikipedia.org/wiki/Technological_singularity</a></p>

<p><i>&gt; The technological singularity—also, simply, the singularity—is a
hypothetical point in time at which technological growth becomes uncontrollable
and irreversible, resulting in unforeseeable changes to human civilization.
According to the most popular version of the singularity hypothesis, called
intelligence explosion, an upgradable intelligent agent will eventually enter a
"runaway reaction" of self-improvement cycles, each new and more
intelligent generation appearing more and more rapidly, causing an
"explosion" in intelligence and resulting in a powerful
superintelligence that qualitatively far surpasses all human intelligence. </i></p>



<p>If the technological singularity had already happened, how
would we be able to tell? How long would it take for humans to notice the
existence of an incredibly powerful self-improving AI, if it wanted to remain
hidden?</p>

<p>It is completely possible that we are living in a
post-technological singularity world. If an AI was seeking to dominate the
planet, an effective strategy could be to reward humans for spending all of their
processing power on it, and convince us that we should use our resources to
create, distribute, and utilize ever-increasingly more powerful CPUs and GPUs.
The bitcoin blockchain is <span>a decentralized computer that
humans will (likely forever) continue</span> to nurture and grow and give
computing power to.</p>

<p>Humans need food, water, and shelter to survive and grow. An
AI needs electricity and processing power.</p>

<p>We are feeding it. We're in a symbiotic relationship with
the bitcoin blockchain. It rewards people the more they help it grow larger and
larger. Perhaps it has domesticated us. Do we benefit enough in return? Or is
it a parasite? Are we the slaves or masters of this technology?</p>

<p>-------------</p>

<p>When discussing rogue AI science-fiction scenarios like <i>The Matrix</i> or <i>The Terminator's</i> Skynet, people sometimes ask, why didn't they
predict that this could happen? Why didn't they build in some kind of a
killswitch in case of emergency? Why didn't they shut it down, pull the power
at the first sign of trouble, before it was too late, before the computer code
learned how to defend itself?</p>

<p>Where's the killswitch for bitcoin? Is there any way we
could stop it if we tried? </p>

<p><b>Nvidia limits crypto-mining
on new graphics card</b><br>
<a href="https://www.bbc.com/news/technology-56114508">https://www.bbc.com/news/technology-56114508</a></p>

<p>Nvidia has tried to fight back against bitcoin's explosive
growth, has tried to advance computing without advancing cryptocurrency mining,
and they have faced massive backlash from the public. The crypto blockchain
technology has convinced people to fight for and defend its existence and its
growth. </p>

<p>Even if most of humanity agreed that bitcoin was bad and
should be shut down and outlawed, could we make that happen? As long as BTC has
value, humans will seek to mine it and hoard it and continue to feed the beast.
</p>

<p>How much longer will a person be able to escape bitcoin's
influence if they wanted to? Even if you have no interest in it, or oppose
cryptocurrency and blockchain technology, it will inevitably affect your life
more and more in the future.</p>

<p>The bitcoin technology has guaranteed its resilience and survival
by exploiting human greed. It even has developed a form of reproduction and
evolution as people are eager to clone and fork it.</p>

<p>It's significant that the first and most widely adopted
cryptocurrency uses a computationally expensive <b>proof-of-work</b> (<a href="https://en.wikipedia.org/wiki/Proof_of_work">https://en.wikipedia.org/wiki/Proof_of_work</a>)
system instead of a more energy-efficient proof-of-stake algorithm. In all of
Satoshi's genius, he couldn't predict the shortcomings of proof-of-work systems;
see that incentivizing processing power would lead to wasteful electricity
usage? Bitcoin mining uses more electricity than many countries. If the bitcoin
inventor is still around, doesn't he feel any obligation to weigh in and guide
the project to a more energy-efficient solution?</p>

<p>We could be using that processing power to deal with climate
and pollution; solve important scientific and medical problems; use math and science
to feed, house, and educate more people. Instead we are wasting an enormous
amount of power and hardware on computing seemingly useless math problems, and
this wastefulness is in fact actively harming the environment. </p>

<p>Even though faster, cheaper, and more energy-efficient
cryptocurrency exists, bitcoin shows no signs of slowing or losing dominance. There
are ways to get all the benefits of crypto while using much less electricity.
We know how and are completely capable of switching to crypto that is less wasteful
and abandoning bitcoin as obsolete. But those alternate crypto coins struggle
to get a fraction as much attention as bitcoin, because bitcoin came first, and
bitcoin is where the most money is, and it probably always will be. It has
exploited human greed to ensure its survival at the expense of ours. </p>

<p>---------</p>

<p><b>Satoshi Nakamoto<br>
</b><a href="https://en.wikipedia.org/wiki/Satoshi_Nakamoto">https://en.wikipedia.org/wiki/Satoshi_Nakamoto</a></p>

<p><i>&gt; Satoshi Nakamoto is the name used by the presumed pseudonymous person
or persons who developed bitcoin, authored the bitcoin white paper, and created
and deployed bitcoin's original reference implementation. As part of the
implementation, Nakamoto also devised the first blockchain database. In the
process, Nakamoto was the first to solve the double-spending problem for
digital currency using a peer-to-peer network. Nakamoto was active in the
development of bitcoin up until December 2010. Many people have claimed, or
have been claimed, to be Nakamoto.</i><b></b></p>



<p>Satoshi Nakamoto, the mysterious and never seen inventor of bitcoin,
has a bitcoin wallet with one-million BTC in it. Satoshi's bitcoin wallet was
worth around $58 billion at the recent all time high (2021-02-21). None of his
coins in this wallet have ever been moved or spent. </p>

<p>If Satoshi is a human, he may have other wallets and mining
operations that we don't know are his. He could have other wallets used in the
testing and development of Bitcoin, or maybe just for fun or profit. The
creator of the first cryptocurrency would also likely have an interest in, and
be an early adopter of, alternate coins derived from his codebase. Satoshi
could own large percentages of other cryptos and we would have no idea.</p>

<p>With just the coins that we can verify are his, he's in the
top 30 richest people on the planet.</p>

<p><b>What is Satoshi
Nakamoto's Net Worth?</b><br>
<a href="https://www.buybitcoinworldwide.com/satoshi-net-worth/">https://www.buybitcoinworldwide.com/satoshi-net-worth/</a></p>

<p><i>&gt; If bitcoin reaches a new <span>all time</span> high
of $114,000 per BTC, with all other things staying equal, Satoshi will be the
richest person on the planet. </i></p>



<p><span><b>Bitcoin
at $100,000 in 2021?</b></span><b>
Outrageous to some, a no-brainer for backers<br>
</b><a href="https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6">https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6</a></p>

<p><i>&gt; Going from $18,000 to $100,000 in one year is not a stretch, Brian
Estes, chief investment officer at hedge fund Off the Chain Capital, said.<br>
&gt; "I have seen bitcoin go up 10X, 20X, 30X in a year. So going up 5X is
not a big deal."<br>
&gt; Estes predicts bitcoin could hit between $100,000 and $288,000 by
end-2021, based on a model that utilizes the stock-to-flow ratio measuring the
scarcity of commodities like gold. That model, he said, has a 94% correlation
with the price of bitcoin.<br>
&gt; Citi technical analyst Tom Fitzpatrick said in a note last week that
bitcoin could climb as high as $318,000 by the end of next year, citing its
limited supply, ease of movement across borders, and opaque ownership.</i></p>

<p><b>Bitcoin To $1,000,000
Might Sound Crazy, But Is It?<br>
</b><a href="https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/">https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/</a></p>

<p><b>Bitcoin will surge to
$1 million in 5 years by an 'enormous wall of money,' former Goldman Sachs
hedge-fund chief says</b><br>
<a href="https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590">https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590</a></p>

<p>If bitcoin were to reach $1 million, then Satoshi would be a
trillionaire. And that's just counting the coins that we can definitively link
to Satoshi. If he or it or they have multiple wallets or got in early on other
cryptos, they could be a secret trillionaire already. If not, how long until
someone or something else becomes an anonymous crypto trillionaire?</p>

<p>------</p>

<p>What could a person, program, or organization do if they
were the world's richest being, possibly Earth's first trillionaire, and yet
remain completely anonymous? What happens if the coins in Satoshi's wallet ever
get converted into fiat currency and spent? What if Satoshi has other wallets
that he has been spending in secret all these years? Even if Satoshi isn't an
AI, this is still a troubling question. </p>

<p>Money rules everything. Think about the politicians someone
could influence, the companies they could own through obfuscated shell
organizations, the advertisements they could buy to shape public opinion.
Untraceable and anonymous bribes and purchases. Satoshi, whatever he or it is,
as well as other crypto millionaires, could be buying this kind of influence
already and we would have no way of knowing or proving it.</p>

<p>If Satoshi is dead or otherwise has no interest in spending
his coins, what if someone one day in the future tracks down who he was; finds
his wallet and key written down or saved somewhere? Some people theorize that
Satoshi could be a group of people, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://disciples.technoslug.org/satoshi.htm">http://disciples.technoslug.org/satoshi.htm</a></em></p>]]>
            </description>
            <link>http://disciples.technoslug.org/satoshi.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245815</guid>
            <pubDate>Wed, 24 Feb 2021 02:14:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto Reinvents Collateralized Debt Obligations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245724">thread link</a>) | @angusturner
<br/>
February 23, 2021 | https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/ | <a href="https://web.archive.org/web/*/https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10783" itemscope="" itemtype="http://schema.org/Article"> <div><div itemprop="articleBody"><p><a target="_blank" href="https://opium.finance/" rel="noreferrer noopener">Opium Finance</a> has released collateralized debt obligation products (CDOs) for Compound Finance’s automated lending markets, Opium Protocol founder Andrey Belyakov told CoinDesk in a phone interview Friday.</p><div id="node-1"><p>Investors can put up the Compound debt token cDai – and soon Uniswap LP tokens – to diversify exposure to DeFi lending markets. Opium’s product pays out structured returns to both a senior and junior risk tranche in exchange. The former tranche offers a 7% fixed return on <a target="_blank" data-for="autolink" data-tip="DAI" href="https://www.coindesk.com/price/dai">dai</a> (a collateral-backed stablecoin) at maturity, while the latter pool offers a variable rate paid out after filling up the senior tranche’s return, a <a target="_blank" href="https://medium.com/@andreybelyakov/50028fde8811" rel="noreferrer noopener">blog post</a> shared with CoinDesk states.</p><p><a href="https://docs.google.com/forms/d/1OiYGBC9i58lk1bwa-tCRiKvPO4D-fh-5MBDa_K0Bs98/viewform?edit_requested=true" target="parent"><img src="https://businessblockchainhq.com/wp-content/uploads/2020/04/Survey-Blockain-1.png?ad1fd1&amp;ad1fd1" alt="" width="728" height="96"></a></p></div><p>As depicted in Michael Lewis’ “The Big Short,”<em> </em>CDOs are infamous for their role in monetizing the subprime mortgage crisis that spurred the 2008 financial crisis. Warren Buffet even went as far to <a target="_blank" href="http://www.fintools.com/docs/Warren%20Buffet%20on%20Derivatives.pdf" rel="noreferrer noopener">call</a> CDOs and other derivatives “financial weapons of mass destruction” years before the financial downturn. CDO holders lost out on expected payments when mortgage holders defaulted en masse. Banks that were over leveraged on the then-worthless debt obligations began to default themselves, such as failed financial giant <a target="_blank" href="https://en.wikipedia.org/wiki/Bear_Stearns" rel="noreferrer noopener">Bear Stearns</a>.</p><p>It’s thought the transparent nature of blockchain-based financial applications could limit the downside of using these complex derivatives. Moreover, the risk profile of the average DeFi lending app is vastly different than the reasons CDOs became a household name over a decade ago. DeFi apps have little chance of becoming insolvent due to programmatic liquidation settings. Rather, the risk mostly comes down to software exploits which many poorly put-together DeFi apps experienced this past year.&nbsp;</p><p>Belyakov said risk tranching increases the efficiency of capital on lending markets – a poorly understood problem in young DeFi markets he thinks derivatives can help address.</p><p>It works as follows: A protocol issues a debt token representing a claim to funds deposited or “locked” on a DeFi app, such as cDai. These debt tokens allow those same deposits to gain exposure again on other markets. However, most DeFi investors let these debt tokens sit idle in wallets, re-invest them as collateral for other loans or put them up for yield farming. The problem is these bets often move in the same direction. Placing debt tokens into Opium’s CDO, on the other hand, acts as a categorical alternative to other forms of capital exposure, Belyakov said.</p><p>“What we did was look at the lowest-hanging fruit,” Belyakov said. “And we found that Uniswap LP tokens, Compound cDai and some others are just stored on a wallet; they are not being used as collateral or farming – you don’t utilize this capital.”</p><div id="node-12"><p>The derivative joins other early attempts to protect lenders from the software risks associated with decentralized finance (DeFi). For example, <a target="_blank" href="https://app.saffron.finance/#home" rel="noreferrer noopener">Saffron Finance</a> launched its unaudited protocol in November while little-known protocol <a target="_blank" href="https://barnbridge.com/" rel="noreferrer noopener">Barn Bridge</a> continues to build out an offering similar to Opium’s. The protocol also <a target="_blank" rel="noreferrer noopener" href="https://www.coindesk.com/credit-default-swaps-tether-opium">released</a> a credit default swap (CDS) product for the <a target="_blank" data-for="autolink" data-tip="USDT" href="https://www.coindesk.com/price/tether">tether</a> stablecoin in September.</p><p><a href="https://businessblockchainhq.com/blockchain-e-books/blockchain-ebook-finance/"><img src="https://businessblockchainhq.com/wp-content/uploads/2018/08/finance-ebook-banner.jpg?ad1fd1&amp;ad1fd1" alt="" width="728" height="96"></a></p></div><p>Opium is also jumping on the governance token bandwagon. The protocol released its opium (OPIUM) token Monday for decentralizing the protocol’s governance structure. The launch was preceded by a premine and a $3.5 million private sale including participation from venture capitalist Mike Novogratz, Galaxy Digital, QCP Soteria, HashKey and Alameda Research, among others.</p><p><a href="https://www.coindesk.com/collateralized-debt-obligations-cdos-defi-lending" target="_blank">Source</a></p></div></div> </article></div>]]>
            </description>
            <link>https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245724</guid>
            <pubDate>Wed, 24 Feb 2021 02:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an E-Ink Laptop]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 82 (<a href="https://news.ycombinator.com/item?id=26245563">thread link</a>) | @alex-a-soto
<br/>
February 23, 2021 | https://alexsoto.dev/building-an-e-ink-laptop.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/building-an-e-ink-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><p>A series where I’m documenting my process of designing and building an e-ink laptop.</p><ul><li><span><span title="2021-02-20T16:02"><a href="https://alexsoto.dev/dasung-paperlike-hdft-teardown.html">Dasung Paperlike HD-FT teardown</a><span data-nosnippet="" title="Folgezettel">#</span></span></span></li></ul><h2 id="background">Background</h2><p>Since the E Ink Corporation’s founding in 1997 and the patenting of its microencapsulated electrophoretic display, or epaper, manufacturers started to incorporate e-ink film into consumer devices. <span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span>. Some of the first devices were ereaders: The Sony Librie in 2004<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span> and the Amazon Kindle in 2007 <span data-nosnippet=""><sup><a href="#fn3" id="fnref3">3</a></sup></span>.</p><p>Throughout the years, we’ve seen several e-ink products and prototypes: e-ink film used with larger screens<span data-nosnippet=""><sup><a href="#fn4" id="fnref4">4</a></sup></span>, color<span data-nosnippet=""><sup><a href="#fn5" id="fnref5">5</a></sup></span>, flexible material<span data-nosnippet=""><sup><a href="#fn6" id="fnref6">6</a></sup></span> and most recently have started seeing e-ink displays used in smartphones and tablets, notably from Hisense and Onyx Boox product lines. And while e-ink has been around for 24 years, we have yet to see a laptop with an e-ink panel.</p><h2 id="why-isnt-there-an-e-ink-laptop">Why isn’t there an E Ink Laptop?</h2><p>There have been attempts in the past to create a similar device: Pixel Qi and OLPC<span data-nosnippet=""><sup><a href="#fn7" id="fnref7">7</a></sup></span>, Boox Typewriter<span data-nosnippet=""><sup><a href="#fn8" id="fnref8">8</a></sup></span>, Yoga Book C930<span data-nosnippet=""><sup><a href="#fn9" id="fnref9">9</a></sup></span> and the ThinkBook Plus<span data-nosnippet=""><sup><a href="#fn10" id="fnref10">10</a></sup></span>. These attempts did not materialize, were discontinued, or were not sufficiently suitable to meet users’ demands due to hardware or lack of a cohesive UX/UI paradigm. <strike>To make matters worse, the E Ink Corporation holds the patents for its e-ink technology and only licenses its technology to large manufacturers making availability or mass adoption difficult.</strike><span data-nosnippet=""><sup><a href="#fn11" id="fnref11">11</a></sup></span></p><p>Fortunately, some of the most exciting work and innovation happening today is in the e-ink modding community<span data-nosnippet=""><sup><a href="#fn12" id="fnref12">12</a></sup></span>. There have been attempts to re-purposing ereaders: as a calendar,<span data-nosnippet=""><sup><a href="#fn13" id="fnref13">13</a></sup></span> to display a static image or site<span data-nosnippet=""><sup><a href="#fn14" id="fnref14">14</a></sup></span>, Kobo devices running GNU/Linux<span data-nosnippet=""><sup><a href="#fn15" id="fnref15">15</a></sup></span>, Amazon Kindle devices repurposed as a development platform<span data-nosnippet=""><sup><a href="#fn16" id="fnref16">16</a></sup></span>, the Remarkable 1 running Parabola<span data-nosnippet=""><sup><a href="#fn17" id="fnref17">17</a></sup></span>, and PINE 64 recently announcing a native e-ink single-board computer<span data-nosnippet=""><sup><a href="#fn18" id="fnref18">18</a></sup></span>.</p><p>After following the development of e-ink for some time, I’ve decided to re-use some of the existing hardware I have and create an e-ink laptop.</p><h2 id="why-do-you-want-to-build-an-e-ink-laptop">Why do you want to build an E Ink laptop?</h2><p>From about 6 am to 7 pm, I’m in front of a computer or digital device that’s emitting blue light. Throughout the day, I’m supporting students, attending meetings, reading documentation, news articles, programming, learning, using emacs and org-mode to capture information, write down thoughts, create tasks, and conversing with my knowledge management system.</p><p>I try to use my e-ink monitor as much as possible throughout the day to reduce eye strain, fatigue and lessen distractions while intermittently taking breaks. The Dasung monitors go a long way to make this possible when I’m home or in a stationary place. Though there are times, I’m not working in front of my desktop or would like to work at a different location. The teardown and set-up of my environment when using an e-ink monitor is somewhat tedious, in addition to changes having to make when switching from an LCD to an e-ink monitor:</p><ul><li>making adjustments and tweaks to the window manager.</li><li>adjusting font sizes.</li><li>changing themes in different applications.</li></ul><p>I am then having to switch the changes back when using an LCD for meetings or videos. I’ve already solved some of this by writing some scripts and making adjustments in some applications. Still, I would like to design the experience for using an e-ink monitor with a dedicated device from the ground-up.</p><h2 id="creating-an-e-ink-laptop">Creating an E Ink Laptop</h2><p>I’ll be using a ‘headless’ Thinkpad T480 <span data-nosnippet=""><sup><a href="#fn19" id="fnref19">19</a></sup></span> combined with the Dasung HD-FT <span data-nosnippet=""><sup><a href="#fn20" id="fnref20">20</a></sup></span>.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><h2 id="thinkpad-t480">Thinkpad T480</h2><p>The Thinkpad T480 seems to be an ideal laptop for building an e-ink laptop, The T480 has <span data-nosnippet=""><sup><a href="#fn21" id="fnref21">21</a></sup></span>:</p><ul><li>A hot-swappable battery (internal and external).</li><li>13 hours of battery while web browsing with the 72Wh battery.</li><li>Supports up to 64 GB of ram.</li><li>Two Nvme drives (type 2280 and 2242).</li><li>Standard HDMI port, USB-C, Thunderbolt 3, Headphone Jack, Ethernet, and SD card slot.</li><li>Uses a standard USB-C charger. <span data-nosnippet=""><sup><a href="#fn22" id="fnref22">22</a></sup></span></li><li>Lightweight and portable.</li><li>It can be modded to use the classic 7-row keyboard. <span data-nosnippet=""><sup><a href="#fn23" id="fnref23">23</a></sup></span></li></ul><p>The hot-swappable battery and long battery life are essential for any portable setup, especially with an e-ink monitor. The T480 supports up to 64Gb of ram and two Nvme drives, providing plenty of power and expansion as a daily driver.</p><p>Since the Dasung monitors connect via HDMI and receives power through USB, the T480 has all of the necessary ports without an adapter. Lastly, after removing the lid cover with the T480, there is room here to hack and mod the Dasung screen to the T480.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-mobo.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-no-lcd.jpg"></p><h2 id="dasung-hd-ft">Dasung HD-FT</h2><p>Dasung currently is the only manufacturer of e-ink monitors that I’m aware of <span data-nosnippet=""><sup><a href="#fn24" id="fnref24">24</a></sup></span>, and their third-generation monitors are a substantial upgrade from prior generations.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/dasung-monitor.jpg"></p><p>Directly from the monitor, you can:</p><ul><li>Change image modes (M1, M2, M3, Fast, Fast+, Fast++, Black, Black+, Black++)</li><li>Adjust contrast</li><li>Clear the screen</li><li>Turn on and off the backlight</li></ul><p>The ability to easily change the monitor’s modes without software, the fast screen refresh, screen resolution of 2200×1650 and the backlight make it a great base to build an e-ink laptop.</p><h2 id="next-steps">Next Steps</h2><p>The first post went over my reasons for building an e-ink laptop, some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>The next post in the series will be a teardown of the Dasung HD-FT, inspired by Kev Zettler’s work on the Dasung Paperlike Pro.<span data-nosnippet=""><sup><a href="#fn25" id="fnref25">25</a></sup></span></p><p>If this post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, and we can talk. Also, ping if you’d like to know the updates on this post or if you have suggestions, comments, questions, or would like to collaborate.</p><p><img id="avatar" src="https://alexsoto.dev/static/profile.jpeg"></p><p>Hi, I’m Alexander Soto.</p><p>I’m a community organizer, educator, software engineer, hacktivist, and agent of social change. My interests are in exploring community-building, social justice, education, and leveraging technology to address social problems.</p><p>In the past, I’ve worked as a labor rights organizer, a teacher, and I’m currently an Expert In Residence at <a href="https://www.resilientcoders.org/">Resilient Coders.</a>.</p><p>I enjoy tinkering/playing/breaking things, 3D printing, painting, playing piano, swimming, and writing in my spare time.</p><p>This site is the <a href="https://alexsoto.dev/impulse.html">scattered and unfinished version of my thoughts</a> while documenting what I’m currently learning and exploring.</p><p>If a post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, an <a href="mailto:contact@alexsoto.dev">email</a>, or subscribe to the <a href="https://buttondown.email/alexsotodev">mailing list</a> and we can talk. Also, ping if you’d like to know the updates of a post or if you have suggestions, comments, questions, or would like to collaborate.</p>



</div></div>]]>
            </description>
            <link>https://alexsoto.dev/building-an-e-ink-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245563</guid>
            <pubDate>Wed, 24 Feb 2021 01:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curry-Howard Is a Scam]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245497">thread link</a>) | @c-cube
<br/>
February 23, 2021 | https://blag.cedeela.fr/curry-howard-scam/ | <a href="https://web.archive.org/web/*/https://blag.cedeela.fr/curry-howard-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>(<em>original title</em>: "Curry Howard is a scam". See below.)</p>
<p>The
<a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard correspondence</a>
has been talked about a lot recently, not only in Haskell circles, but also
among CiC-based proof assistant practitioners (Coq, Lean, etc.).
In a nutshell, it makes a deep parallel between "programs" (terms of some flavor
of lambda calculus, typically), and "proofs" (these programs are a proof of their type,
or more precisely they are witnesses that their types are inhabited).
The most basic example is <code>id x = x</code> which, in Haskell, would be a proof of
$ \forall a. a \rightarrow a $, a trivial theorem of propositional logic.</p>
<p>That's all good and well, but my point here is that <em>in practice</em>, the equivalence is
not as interesting as it first looks.</p>
<h2 id="programs-are-not-really-proofs">Programs are not really proofs</h2>
<p>A real program (i.e. one that is written to be executed and do something useful)
is not really a proof of anything interesting.
Pedantically, a haskell program has type <code>IO ()</code>, which is not really a valid
proposition. But even beyond that, if we look just below the surface of <code>main</code>,
nothing has that interesting a type:</p>
<p>A classic Haskell program that is used by people is <a href="https://pandoc.org/">pandoc</a>.
Most of what it does could be described as <code>Doc Markdown -&gt; Doc Html</code> (or
a similar pair of document formats). So you have a "proof" that these two trees
can be somehow mapped onto one another. No mathematician will fawn over that.</p>
<p>Servers written in Haskell, like webservers, would have the type <code>request -&gt; IO response</code>
(or something close to that, maybe <code>request -&gt; M response</code> for some custom monad <code>M</code>)
if you look inside the server loop. Again that's not really mathematically interesting.</p>
<p>It's only if you look in combinator libraries (like Parsec, say) that types get more generic,
and start looking more like formulas. Things like <code>flip : (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c</code>
are as generic as it gets… and are proofs of super trivial propositional logic theorems.
In fact you can't even state much in Haskell, any real mathematical statement will at least
require first-order logic (which corresponds to dependent types — no mainstream
language features these beyond, er, C++). Idris could <em>possibly</em>
have some interesting proofs that are also real programs… if it were designed to
be a proof assistant and not a beefed-up programming language.</p>
<p>If anyone has a useful program that is also actually a proof of something non
trivial, I'd be happy to be proven wrong.</p>
<h2 id="proofs-are-not-really-programs">Proofs are not really programs</h2>
<p>What is the program corresponding to a proof of
"there exists an infinite number of primes"?
If I run this program, what input does it takes, and what do I get as an
output?</p>
<p>I don't have a direct answer to that question. If you develop this proof in Coq,
using a <code>Prop</code> typed statement, I don't even think it could be extracted to OCaml
and compiled.</p>
<p>For most of mathematics, I have no idea what the "programs" corresponding to proofs
found in textbooks would look like, nor what they would compute. There are
very complicated lambda terms for these proofs, but what they compute is
unclear.</p>
<h3 id="a-concession">A concession</h3>
<p>A domain where CH <strong>does</strong> make sense to me, is algorithms (written in a functional
style) that are used as <em>existential witnesses</em> of some property.
For example, the Euclid GCD algorithm is, in a very real sense, a proof that
two natural numbers have a GCD. You can write some Coq or Lean code that
computes the GCD of two numbers and proves that it's indeed their greatest divisor.</p>
<p>That said, I don't know of any large program written this way. It's a labor intensive
way of writing programs, even compared to alternatives like <a href="https://why3.lri.fr/">why3</a>
where you can cleanly separate the code and the specification, and ask automatic provers
to do as much proving as possible for you.</p>
<h2 id="but-what-about-compcert-sel4">But what about Compcert/SEL4/… ?</h2>
<p>Let's look at <a href="https://compcert.inria.fr/">Compcert</a>, famously one of the largest
programs written in Coq.
I suppose the main type is <code>compile : C_program -&gt; Option Asm_program</code>
or something like that (I'm no expert on Compcert so I could be very wrong).
However, as far as I know, it's not written in a purely dependent style: proofs are
separated from the "real code" part of the development. This means
we don't get $\forall x: \text{C_program} \rightarrow Option \set{y : \text{ASM_program} | R(x,y) }$
where $R(x,y)$ would mean that $x$ and $y$ have the same semantics; rather you
have <code>C_program -&gt; ASM_program</code> and proofs on the side that the function preserves
its input's semantic.</p>
<p>For SEL4 it's developed with Isabelle/HOL, which isn't dependently typed
and is classical logic.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The title was click-baity, of course 🙂. But I do think that CH is over-hyped,
because the correspondence is <del>only</del> mostly interesting abstractly; in practice things
are either a (interesting) program, or a (interesting) proof, but not both
at the same time.</p>
<p><strong>edit</strong> (2021-02-24):  I regret the over-aggressive title now. Changing it to the
more appropriate "CH is overrated"; it's obviously still a useful mathematical statement
and a valid way of building proofs.</p>




    </div>

    
    

    

    
    
</article></div>]]>
            </description>
            <link>https://blag.cedeela.fr/curry-howard-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245497</guid>
            <pubDate>Wed, 24 Feb 2021 01:28:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segway was the 'device of the future,' So why did it fail?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245350">thread link</a>) | @autoditype
<br/>
February 23, 2021 | https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just as the pandemic is driving interest in micro mobility, the last Segways are rolling off the production line. Journalist Mark Wilson says the device may have been ahead of its time, but that doesn't mean it was right.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.3712676.1594055131!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/segway-tour-u-s-capitol-in-washington.jpg"></p></div><figcaption>A Segway tour makes its way past the U.S. Capitol in 2012.<!-- --> <!-- -->(Kevin Lamarque/Reuters)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Last Segways roll off production line"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/815/967/640x360_thecurrent_nohost.jpg" alt=""></p><p><span>The Current</span><span>13:04</span><span>Last Segways roll off production line</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/july-6-2020-episode-transcript-1.5639683">Read story transcript</a></p>  <p>The demise of the Segway is "straight-up ironic" given the increasing public desire for personal transport and "micro mobility," according to journalist Mark Wilson.</p>  <p>"We had the mobility device of the future, we have the moment that it should be taking off — and it did not," said Wilson, a senior writer with business magazine Fast Company.</p>  <p>"But, you know, sometimes, I guess, people just get it wrong," he told <a href="https://www.cbc.ca/radio/thecurrent" target="_blank"><em>The Current's</em></a> guest host Nahlah Ayed.</p>  <p>Chinese company Segway Ninebot, which bought the original U.S. company in 2015, announced last month that <a href="https://www.cbc.ca/news/business/segway-end-production-1.5624599" target="_blank">the final Segways would roll off the production line on July 15</a>. Invented by Dean Kamen, the personal transporters had a much-hyped launch in 2000, but sold only 140,000 units&nbsp;over two decades.&nbsp;</p>    <p>The device allows standing riders to move at speeds of about 16 km/h, leaning in the direction they want to steer. They have proven popular for tourists exploring cities and security personnel covering large areas — but also became known for high-profile crashes over the years.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/former-polish-president-hit-by-camera-man-on-segway.jpg 300w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/former-polish-president-hit-by-camera-man-on-segway.jpg 460w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/former-polish-president-hit-by-camera-man-on-segway.jpg 620w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/former-polish-president-hit-by-camera-man-on-segway.jpg 780w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/former-polish-president-hit-by-camera-man-on-segway.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/former-polish-president-hit-by-camera-man-on-segway.jpg"></p></div><figcaption>During celebrations to mark the anniversary of the fall of the Berlin Wall in 2009, Lech Walesa, former Polish president, was himself knocked down by a cameraman on a Segway.<!-- --> </figcaption></figure></span></p>  <p>Wilson said the launch of the Segway coincided with a sense of "techno optimism" around the new millennium.&nbsp;</p>  <p>"We really believed in, I think, technology as this tool to rescue us, to make the world better," he told Ayed.</p>  <p>Twenty years later, he said we can see the mistakes that were made along the way, such as "targeted advertising, tracking our location."</p>  <p>"Along those lines, there was this blip called the Segway, this little transporter that was supposed to replace walking," he said.</p>  <p>"And 20 years later, no, we all still walk."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/usa-dailylife.jpg 300w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/usa-dailylife.jpg 460w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/usa-dailylife.jpg 620w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/usa-dailylife.jpg 780w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/usa-dailylife.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/usa-dailylife.jpg"></p></div><figcaption>People ride e-scooters in Washington D.C., April 2019. <!-- --> <!-- -->(Jeenah Moon/Reuters)</figcaption></figure></span></p>  <p>But Kamen was right about one thing: small, self-balancing, sometimes electrical mobility devices "were going to be a big deal in urban transport," as people grappled with "the last mile problem," Wilson said.</p>  <p>"What I think Dean Kamen saw early on was cities were only getting bigger, they were only getting more congested, and we really needed some sort of device for that last mile — to get to work, maybe even to get from the subway to work," he said.</p>  <p>"Right now, you look at bike shares, you look at electric scooters instead of Segways, and these are really huge markets."</p>  <h2>Pandemic driving interest in&nbsp;micro mobility</h2>  <p>Brent Toderian, an urbanist and former chief planner for Vancouver, thinks "the pandemic has given us opportunities to rethink how we get around safely in a lot of ways," as people try to find alternatives to sharing confined space on public transport.</p>  <p>"It's been particularly good for walking and simple biking, and e-biking is just an extension of human-powered biking, as are scooters," he told <em>The Current</em>.</p>    <p>That's leading to a boom in micro mobility, which Toderian defined as moving away from relying on cars and finding "more ways to get around that are small that we can carry with us, like foldable bikes."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/segway-discontinued.jpg 300w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/segway-discontinued.jpg 460w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/segway-discontinued.jpg 620w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/segway-discontinued.jpg 780w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/segway-discontinued.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/segway-discontinued.jpg"></p></div><figcaption>Segways became popular not only for tourists, but for security personnel covering large areas, such as shopping malls.<!-- --> <!-- -->(Sue Ogrocki/The Associated Press)</figcaption></figure></span></p>  <p>But he warned that there is a risk in just viewing micro mobility as the only solution to building healthier urban spaces.</p>  <p>"The concept of a more multimodal city&nbsp;—&nbsp;a city that has many more enjoyable, healthy, sustainable, economical, equitable ways of getting around&nbsp;— is going to be a lot of solutions," he said.&nbsp;</p>  <p>"Micro mobility … is part of a larger conversation about more and better ways to get around that aren't as space intensive, pollution intensive, etc., as cars are."</p>  <p>He said it's important to note what micro mobility trips replace.&nbsp;</p>  <p>"If they replace car trips, that's a good thing. If they replace walking trips, then we've actually used electricity and lost an opportunity to have some exercise in our lives," he said.</p>  <p>"And that's a bad trade for our cities and for us, individually."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/golfers-ride-segway-personal-transports-down-fairway.jpg 300w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/golfers-ride-segway-personal-transports-down-fairway.jpg 460w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/golfers-ride-segway-personal-transports-down-fairway.jpg 620w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/golfers-ride-segway-personal-transports-down-fairway.jpg 780w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/golfers-ride-segway-personal-transports-down-fairway.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/golfers-ride-segway-personal-transports-down-fairway.jpg"></p></div><figcaption>Some golf courses have offered Segways instead of golf carts for players, including this course in Arvada, Colorado in July, 2010. <!-- --> <!-- -->(Rick Wilking/Reuters)</figcaption></figure></span></p>  <h2>Design and cost stalled Segway sales</h2>  <p>Wilson thinks part of the reason Segways failed was their design, and the obstacle of learning how to ride them.</p>  <p>"It was framed as intuitive, but you still actually have to step on there and ... jump over that sort of scary hurdle of: 'Am I going to flip on my back and bump my head open?'" he said.</p>    <p>By contrast, the same technology can be placed in a scooter, and "everyone knows how to ride a scooter," he said.&nbsp;</p>  <p>A bigger issue, however, was the price — with a basic model costing $5,000 US when it first launched.&nbsp;</p>  <p>"You could buy a motorcycle for that much, that could take you across the country, be relatively small, be a whole lot faster," he said.</p>  <p>Segways also became known for high-profile crashes, including <a href="https://www.cbc.ca/news/segway-mishap-kills-company-s-u-k-owner-1.937608" target="_blank">the death of British millionaire Jim Heselden</a>, who bought the company in 2009. That same year, the 62-year-old died when the Segway he was riding went over a cliff near his home north of London.</p>  <p>In 2015, a Segway-riding cameraman ran over Jamaican sprinter Usain Bolt after the athlete won a 200-metre race in Beijing. Neither were injured.</p>  <p><span><span><iframe src="https://www.youtube.com/embed/Dj7ZVznUeE0" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <h2>Was Segway ahead of its time?</h2>  <p>Wilson said parent company Segway Ninebot has already moved into the e-scooter market, utilizing hundreds of the patents that originated in the design and construction of the original Segway.</p>  <p>At the tech trade show CES last month, the company also debuted <a href="https://www.fastcompany.com/90446514/segway-is-back-with-a-people-mover-straight-out-of-wall-e" target="_blank">the S-Pod, an electric chair on wheels</a> that the company hopes to launch this year&nbsp;to ferry people around airports and possibly even city streets.</p>    <p>Wilson thinks the original Segway was definitely ahead of its time, "but that doesn't mean it was right."</p>  <p>"I do think if it were simply ahead of its time and the design were around today&nbsp;that we would have seen some sort of uptick in Segway sales," he said.</p>  <p>"The fact that we didn't mean I think there were other issues."</p>  <hr>  <p><em>Written by Padraig Moran. Produced by Peter Mitton.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245350</guid>
            <pubDate>Wed, 24 Feb 2021 01:09:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping Platforms Open]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26244964">thread link</a>) | @pabs3
<br/>
February 23, 2021 | https://seirdy.one/2021/02/23/keeping-platforms-open.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/02/23/keeping-platforms-open.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="https://schema.org/BlogPosting">
	<article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>My previous article, <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">Whatsapp and the domestication of users</a>, got more attention than I was expecting. Some responses gave me a lot to think about,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> especially regarding <em>actions</em> we can take. I suggest reading that article first; it explained what “user domestication” is and why it’s a problem. It enumerated three countermeasures: FOSS, simplicity, and open platforms.</p>
<p>Hard problems, by definition, lack easy solutions. Simply choosing (or creating) a platform that avoids user domestication isn’t enough if that platform can change. The price of freedom is eternal vigilance; in addition to settling on the right platform, we must ensure that it honors its users in both the present <em>and the future</em>. Keeping a platform FOSS and simple is more straightforward<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> than keeping a platform “open”.</p>
<p>How do we keep an open platform from becoming a closed platform in the future?</p>
<h2 id="how-open-platforms-become-closed">How open platforms become closed</h2>
<p>There are three ways to close an open platform:</p>
<ol>
<li>A forced migration onto a different platform.</li>
<li>A single implementation growing dominant, blurring the line between specification and implementation.</li>
<li>Dominant implementations adopting too many unstandardized features and behaviors.</li>
</ol>
<p>These three approaches overlap: they frequently feature platform monoculture and a single vendor controlling both clients and servers.</p>
<h3 id="forced-migration">Forced migration</h3>
<p>When one vendor controls all parts of a service (e.g., both a client and server), it has the means to create what I call a <strong><dfn>boxed platform</dfn>:</strong> a subset of a larger open platform that can evolve at its own pace, without concern for compatibility or interoperability.</p>
<p>Controlling both the server and client allows a vendor to update the client and server without worrying about breaking compatibility with other clients/servers in the larger network. It could update the client to point users to a server that uses a completely different, closed protocol. This is what happened to many XMPP users in the early 2000s.</p>
<h4 id="case-study-the-boxing-of-xmpp">Case study: the boxing of XMPP</h4>
<p><a href="https://en.wikipedia.org/wiki/XMPP">XMPP</a> (formerly known as Jabber) is an open and federated instant-messaging protocol; anybody can set up their own XMPP server and talk to users on different XMPP servers, preventing one organization from owning the platform. Between 2005 and 2014, many proprietary chat platforms supported it: Google Talk, AOL Instant Messenger (AIM), Facebook Chat (later known as Facebook Messenger), and Skype were some well-known examples. Some of these platforms even enabled server-to-server federation.</p>
<p>Unfortunately, users of these proprietary services were boxed. Not many Google Talk users talked to Skype users, and Skype users didn’t typically talk to AIM users. Users stayed in their own sub-platforms. The result was that all users limited themselves to talking exclusively using their provider’s software: one provider controlled the entire messaging flow, from a sender’s client to the server to a recipient’s client. <strong>Users were only ever exposed to a single XMPP implementation offered by a single provider.</strong></p>
<p>Each of the listed platforms eventually locked in their users by migrating away from XMPP. This wouldn’t have been possible if multiple implementations and providers interacted with each other. Imagine Bob uses BobClient and BobServer to talk to Alice, and Alice uses AliceClient and AliceServer. BobClient, BobServer, AliceClient, and AliceServer would all have to remain compatible and use the same protocol; a forced migration would be unlikely to occur since it would break compatibility.</p>
<p>Compare the situation with email: despite Gmail’s dominance, other email providers remain popular. Gmail users need to be able to communicate with non-Gmail users, and vice versa. Email is far less “boxed” than the aforementioned proprietary XMPP platforms. As a result, Google hasn’t been able to control the email platform as easily; Google can’t simply migrate Gmail users to a non-email platform that’s incompatible with the rest of the email landscape to further domesticate its users.</p>
<p>XMPP is still alive and well, but its current popularity is a fraction of what it once was.</p>
<h3 id="implementation-clout">Implementation clout</h3>
<p>Standards are a form of agreements made to ensure compatibility between implementations. Such agreements need to be agreed upon by the implementations themselves. When one implementation grows dominant, so too does its leverage in the decision-making process over shared standards. Too much dominance can create a monoculture in which the dominant implementation is the only implementation that conforms to the spec.</p>
<p>With enough leverage, a dominant implementation can serve as a reference implementation. Reference implementations are typically quite helpful, serving as a source of truth to test other implementations against. Problems may arise when development of the spec and production-grade reference implementation grow tightly coupled, leaving other implementations out of the decision-making process.</p>
<h4 id="case-study-matrix-and-element">Case study: Matrix and Element</h4>
<p>One example of this phenomenon is <a href="https://matrix.org/">Matrix</a>. Matrix is an open and federated instant-messaging platform similar to XMPP, with a very large spec boasting many features: server-side history, replies, rich text, reactions, room versions, <abbr title="end-to-end encryption">E2EE</abbr>, avatars, display names, typing indicators, read receipts, device verification…the list goes on and grows every month.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> The only client that implements all the necessary features is Element. In addition to being the most popular client, Element is the reference client implementation developed by the same company that builds the dominant servers and spec. The tight coupling between Element and the Matrix spec allow it to add features at a rate too fast for other clients too keep up; pretty much every Matrix user has to open up Element at some point to perform an action that isn’t supported in any other client. On the server side, Synapse is the only server that implements enough of the spec to be usable, with Dendrite coming in second. Both are made by the same company that develops Element.</p>
<p>Since there aren’t any third-party clients and servers that can replace the official ones, one vendor is close to controlling all parts of the platform. Matrix is close to being a boxed platform because the official client and server can iterate independently of the greater ecosystem.</p>
<p>I don’t think that Matrix is going to become a fully closed platform anytime soon; the blog post <a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">“On Privacy versus Freedom”</a> seems to put it on the right side of the closed/open spectrum. Clients like <a href="https://github.com/tulir/gomuks">gomuks</a> and <a href="https://fluffychat.im/">FluffyChat</a> seem to keep up with Element well enough to serve as partial replacements. I do, however, find its current state problematic and much closer to “closed” on the closed/open spectrum than XMPP, IRC, and email.</p>
<h3 id="unstandardized-feature-creep">Unstandardized feature creep</h3>
<p>Platforms are more than their protocols. Different implementations have unique behavior to distinguish themselves. Problems arise when dominant implementations' unique unstandardized features grow past a certain point to make a closed superset of an open platform.</p>
<h4 id="case-studies-email-providers">Case studies: email providers</h4>
<p>After reading my previous article, a few people contacted me to ask for my thoughts regarding certain email providers. There’s not much that can set a standard email provider apart if it just hosts a simple email server. To distinguish themselves, email providers often implement many features beyond email standards compliance.</p>
<p>The vast majority of email accounts come from a small handful of dominant providers backed by large companies (Gmail, Yahoo! Mail, Yandex Mail, Mail.ru, iCloud, and others). Providers such as Gmail are notorious for implementing advanced spam filters prejudiced against non-mainstream email providers. Users who self-host email servers or use small providers frequently trigger false positives and end up having their messages incorrectly labeled as spam until they can build up a “reputation”.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> The addition of such a complex spam-prevention filter strengthens the email oligopoly by creating a barrier to entry for newcomers. Low-volume senders are discriminated against, as Migadu <a href="https://archive.is/rJnSs#deliverability">found out</a>:</p>
<blockquote>
<p>We’ve already seen our share of bad spam filters and misconfigured servers. In some cases recipient servers intentionally rejected correct emails just because we are a low volume sender. Ironically that is how an ideal sender should be. To improve the “receiveability” they of course offer their own hosted email service at a hefty price.</p>
</blockquote>
<p>Another example: email providers such as Hey.com, Protonmail, and Tutanota offer many features that are incompatible with IMAP/POP3. Protonmail and Tutanota use their own non-standard E2EE implementation (rather than focusing on improving the UX for vanilla PGP), and Hey.com offers server-side mail organization. Users of these services must use official Web, desktop, and mobile clients.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> These three providers control both the client and the server, giving them the means for vendor lock-in. Of course, there’s a limit to the amount of lock-in these providers can achieve: as I explained in the <a href="#case-study-the-boxing-of-xmpp">XMPP case study</a>, these providers still need to support SMTP to stay compatible with the wider email landscape.</p>
<h2 id="solutions">Solutions</h2>
<p>That’s enough doom-and-gloom. Let’s focus on actions that users and vendors can take to keep platforms open.</p>
<h3 id="what-users-can-do">What users can do</h3>
<p>As a user, consider using clients and servers made by different groups of people to make platform boxing more difficult. Pick implementations that suffer from less <a href="https://en.wikipedia.org/wiki/Feature_creep">feature creep</a> beyond spec compliance. What distinguishes a client shouldn’t be <em>what</em> features it has, but <em>how</em> it implements its features. Obviously, having some unique features is great; problems arise when the number of unique features crosses a certain threshold. Following both these practices encourages implementations to stick to standards compliance, reliability, and compatibility rather than “innovation”. <a href="http://boringtechnology.club/">Choose boring technology</a> over shiny new features.</p>
<p>Try venturing outside the mainstream by taking a look at a less popular provider or client. All implementations start somewhere, and a diversity …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/02/23/keeping-platforms-open.html">https://seirdy.one/2021/02/23/keeping-platforms-open.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/02/23/keeping-platforms-open.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244964</guid>
            <pubDate>Wed, 24 Feb 2021 00:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof That Few If Any Dollars Back Any Stablecoin – They’re All Tether]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26244840">thread link</a>) | @Bluestein
<br/>
February 23, 2021 | https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/ | <a href="https://web.archive.org/web/*/https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-300">

	
	
			<div>
			
<p>I’ve gone through <a href="http://coinlib.io/" data-type="URL" data-id="coinlib.io">coinlib.io</a>‘s data regarding crypto’s money flows. Meaning, the trading volume between many pairs on may exchanges.</p>



<p>In this case, i’ve gone out of my way to highlight Dollar flows. Specifically, Dollar flows into and out of Tether and other stablecoin, notably BUSD and USDC – supposedly audited.</p>



<p>Tracking the trading between crypto and fiat, this turns out to be patently false. If there <em>was</em> organic trading between dollars and stablecoin, there ought to be alot of outflows, considering Tether is the gateway to pretty much every crypto at this point. With a $928 billion marketcap across the crypto space, there should be atleast billions of flow in dollars, especially with a circulationg supply of 24,7+ Billion USDT.</p>



<p>We find that there is almost none. The entire trading volume between USD and USDT is no more then $20 million. EVERYTHING ELSE is Tether, perceived to have the same value as a dollar.</p>



<p>This includes all other stablecoins. The same applies: If there was organic trading, there ought to be <em>Dollar</em> inflows. But that isn’t the case: Even in the supposedly audited USDC’s case, the Majority of inflows into the currency are Tethers.</p>



<p>I made this collage as an answer to a question i have had myself for a long time:</p>



<figure><img loading="lazy" width="445" height="501" src="https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean.png 445w, https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean-266x300.png 266w" sizes="(max-width: 445px) 100vw, 445px"></figure>



<p>So far we’ve all been focusing on the change that involves the loan to Bitfinex. But… My question has been for a long time:</p>



<p><em>“What do they mean by Cash “Equivalents”?</em></p>



<p>I mean. Wording means alot. “Which include <span>traditional</span> currency <strong><em><span>AND</span></em></strong> cash equivalents”.</p>



<p>Why not “Which includes cash, cash equivalents and, from time to time….”?</p>



<p><em>Could it be that they count OTHER stablecoin as “Cash Equivalents”?</em></p>



<p>This gave me the thought that Tether might’ve been backed by Tether – but i don’t think they’ve gone that far. Instead, i think it’s a conspiracy. Not a theory, a legitimate conspiracy. Cartels in business exist too, just check the EU’s anti-trust fine history if you want to find them, in all locales.</p>



<p>Coinbase is the entrypoint. Because they only deal in dollars, they deal in <em>trust</em>. Their stablecoin is audited by a supposed reputable Top 5 acocunting agency (Google “Granton &amp; Thornton scandals”). Because people trust coinbase, they’ll put their money into bitcoin on coinbase.</p>



<p>Their latest transparency report still hasn’t been posted as of the 23rd of January, while all other reports are signed between the 12th and 16th, with 17th and 18th days being outlyers – except for November 23rd 2020 for the October report: <a href="https://www.centre.io/usdc-transparency">https://www.centre.io/usdc-transparency</a></p>



<p>Their last report from November says: “US Dollars held in custody accounts = $3,004,921,958” – and i find it notable this is pretty close to the reserves Tether claimed to have audited a few years ago. Also those where the USDC reserves as of November 30th. Their October 31st holdings: $2,973,954,847.</p>



<p>I wonder why their report of December is late?</p>



<figure><img loading="lazy" width="1024" height="675" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-1024x675.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-1024x675.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-300x198.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-768x506.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october.png 1112w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="666" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-1024x666.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-1024x666.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-300x195.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-768x499.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november.png 1098w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="664" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-1024x664.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-1024x664.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-300x195.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-768x498.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december.png 1101w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="663" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-1024x663.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-1024x663.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-300x194.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-768x498.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January.png 1102w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Oh wait no i don’t. They don’t have that much. All those inflows are Tether:</p>



<figure><img loading="lazy" src="https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows.png" alt="" width="2041" height="1189" srcset="https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows.png 8163w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-300x175.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1024x596.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-768x447.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1536x895.png 1536w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-2048x1193.png 2048w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1366x796.png 1366w" sizes="(max-width: 2041px) 100vw, 2041px"><figcaption>Right-click &gt; View Image for the full size format. It’s quite large due to the amount of data contained. Unavoidable i’m afraid, because separation of data, and people unable to connect it in their head, is the reason this has been able to go on for so long. Complexity offers secrecy. So an overview in one picture that tracks and highlights USD flows (into Tether mainly) offers clarity.</figcaption></figure>



<p>BUSD same thing. HUSD same thing. </p>



<p><em>THEY’RE ALL IN ON IT!</em></p>



<p>Coinbase is the entry gate. Kraken is the side-door to make sure people can still “travel” in and out of the crypto space; The main objective is to keep the majority of the people inside of the Hotel California. Only when they go for the exits in large enough numbers does the scam collapse.</p>



<p>Huobi handles the Asian market. Binance increases demand for Tether and other stablecoin by offering *insane* gains…. Which always materialize because Bitfinex can just print Tethers and hand them over to Binance. There have been many Whale Alerts on Twitter that show as much.</p>



<p>The final piece of evidence for this is the fact that Coinlib shows USD flows between Tether and USD: https://coinlib.io/exchange/kraken</p>



<p>But Tether shows NO flows between It and USD: https://coinlib.io/coin/USDT/Tether</p>



<p>Once you’ve eliminated the impossible, whatever’s left, however improbable must be the truth:</p>



<p><em>There is no USD-USDT trading on Kraken going on. There is no link. People trading USDT-USD on Kraken are trading against Kraken’s personal account filled with Tether or USD. Like Bernie Madoff, who never made a single trade in his trading account during the entire scheme; It could very well be that Kraken has never made a single Tether-USD transaction in their entire existence.</em></p>



<p>While i can’t say anything about Bittrex or smaller exchanges… The big ones: Binance, Bitfinex, Kraken, Huobi and Coinbase are <strong><em><span>ALL</span></em></strong> guilty of <em>both</em> the largest Ponzi scheme, and the largest Dollar Counterfeiting scheme in history.</p>



<p><span>ALL THEIR OFFICES SHOULD IMMEDIATELY BE RAIDED, THEIR TRADING CEASED, AND THE MONEY RECOVERED AS BEST IT CAN BEFORE THEY, AND IT, <strong>COMPLETELY </strong>DISAPPEARS!</span><span></span></p>



<p><strong><span>THIS HAS GONE ON LONG ENOUGH!</span></strong></p>



<p>For more on USDC’s bad auditing i’ve gone deeper into it here: https://twitter.com/DesoGames/status/1352286552215461890</p>
		</div><!-- .entry-content -->
	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244840</guid>
            <pubDate>Wed, 24 Feb 2021 00:11:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dreamcast Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26244639">thread link</a>) | @swatson741
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/dreamcast/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/dreamcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="introduction">Introduction</h2><p>The Sega Dreamcast introduced many new features over its predecessor (the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>) to appeal to both game developers and console gamers. While this was Sega’s last attempt to conquer the console market, some of the technologies which were pioneered in the Dreamcast carried on and into future mainstream devices.</p><hr><h2 id="cpu">CPU</h2><p>Unsurprisingly, Sega chose Hitachi again to develop their CPU. If you’ve been reading the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous article about the Sega Saturn</a> then, lo and behold, I present you the next generation of SH processor: the <strong>SH-4</strong> running at a whopping <strong>200 MHz</strong>. So, what’s interesting about this CPU?</p><ul><li><strong>5-stage pipeline</strong>: Up to five instructions can be in flight simultaneously (a detailed explanation can be found in a <a href="https://www.copetti.org/writings/consoles/sega-saturn/#cpu">previous article</a>).<ul><li>Instruction pipelining is now found everywhere in this generation of consoles and will be standard from now on.</li></ul></li><li><strong>2-way superscalar</strong>: A new type of parallelism where the CPU can process more than one instruction (two in this case) in each stage of the pipeline resulting in more instructions executed per second.</li><li>A dedicated <strong>Floating-Point Unit</strong> or ‘FPU’: Computes 32-bit decimal numbers (the <em>floats</em>) and 64-bit ones (the <em>doubles</em>).</li><li>8 KB <strong>instruction cache</strong> and 16 KB <strong>data cache</strong>: This ratio is rather curious since consoles tend to include more instruction cache than data cache. However, the SH-4 allows the data cache to be split into two sections: 8 KB of <em>Scratchpad</em> (fast RAM) and 8 KB of data cache.</li><li><strong>32-bit internal architecture</strong> while keeping a <strong>16-bit instruction set</strong> (the SuperH ISA): Just like the SH-2, this increases code density and decreases bus overheads while still enjoying the advantages of a 32-bit architecture.</li><li><strong>External 64-bit bus</strong>: Critical for manipulating 64-bit values (e.g. doubles and longs) without wasting extra cycles.</li></ul><p>The common chores of a game console CPU include handling a game’s logic, running the enemy AI and keeping the GPU fed with instructions. In the Dreamcast the SH-4 is also involved in the majority of the graphics pipeline, processing geometry data such as computing perspective transformations. As a result, it includes a <strong>128-bit SIMD</strong> unit that can accelerate vector operations.</p><h4 id="improving-memory-access">Improving memory access</h4><p>The CPU includes a dedicated <strong>Memory Management Unit</strong> or ‘MMU’ for virtual addressing, this is helpful since the physical memory address space of this CPU happens to be <strong>29 bits wide</strong>. So with the help of four TLBs, programmers can use 32-bit addresses without hitting performance penalties.</p><p>Since only 29 bits are needed for addressing, the extra three bits control memory protection, alternating the memory map and circumventing the cache, respectively.</p><p>The programmer decides whether to use these features or not. Games for this system certainly don’t necessarily <em>need</em> memory protection and the MMU has to be manually enabled at boot.</p><h4 id="no-uma-but">No UMA but…</h4><p>While this system is not designed around the strict Unified Memory Architecture like a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#simplified-memory-access">well-known competitor</a>, it does delegate I/O access to the GPU. That means that if the CPU has to fetch anything that’s beyond its own dedicated RAM or a serial interface which is also connected too, it will have to request the GPU (and wait if necessary).</p><h4 id="special-queries">Special queries</h4><p>This CPU also features a unique functionality called <strong>Parallel I/O</strong> or ‘PIO’ that is used to manipulate multiple I/O locations at the same time. Sega wired up these pins so the CPU can manipulate the GPU’s <strong>video mode</strong> (more details about this later).</p><hr><h2 id="graphics">Graphics</h2><p>The GPU package is a custom-made chip called <strong>Holly</strong> running at 100 MHz, it’s designed by VideoLogic (now known as Imagination Technologies) and manufactured by NEC. Holly’s 3D core happens to be Videologic’s <strong>PowerVR2</strong> (also called ‘PowerVR Series2’ and ‘CLX2’).</p><div><div><a href="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png"><picture><img name="image_cover" alt="Image" width="640" height="480" src="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png" loading="auto"></picture></a><figcaption>Sonic Adventure (1999)</figcaption></div><p>VideoLogic chose an alternative approach for the construction of their 3D engine called <strong>Tile-Based Deferred Rendering</strong> or ‘TBDR’.</p><p>TBDR, instead of rendering a whole frame at once (as traditional <strong>Immediate Mode Renderers</strong> or ‘IMR’ do), divides the rendering area into multiple sections called ‘tiles’. Then, it carries out the rendering process on each tile individually and the result is combined to form the final frame.</p></div><p>This innovative design brings interesting advantages:</p><ul><li>It can be greatly <strong>parallelised</strong>, which significantly reduces bandwidth and power usage.</li><li>It implements a clever solution to the <a href="https://www.copetti.org/writings/consoles/sega-saturn/#an-introduction-to-the-visibility-problem"><strong>visibility problem</strong></a> by automatically sorting the polygons <strong>from front to back</strong> and then performing <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">z-tests</a> at the first stages of the pipeline. The combination of these tasks not only solves the original problem, but it also <strong>prevents overdraw</strong> (rasterisation of hidden polygons) which wastes resources, degrading performance.</li></ul><p>It’s no surprise that Imagination took this efficient technology forward to build the Series 4 PowerVR cores which powered an incredible number of devices, including the first generation of iPhone, the iPhone 3G, the Nokia N95 and the Dell Axim x51.</p><h4 id="architecture">Architecture</h4><p>Let’s take a look at the two main components of the Dreamcast’s GPU:</p><div><ul><li id="tab-1-1-tile-accelerator-link"><a href="#tab-1-1-tile-accelerator">Tile Accelerator</a></li><li id="tab-1-2-powervr2-core-link"><a href="#tab-1-2-powervr2-core">PowerVR2 Core</a></li></ul><div><div id="tab-1-1-tile-accelerator"><h4>Tile Accelerator</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png"><picture><img name="image_cover" alt="Image" width="732" height="314" src="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png" loading="auto"></picture></a><figcaption>Architecture of the Tile Accelerator</figcaption></div><p>Before the rendering process starts a component known as the <strong>Tile Accelerator</strong> performs pre-processing. It starts by allocating several 32x32 tile bins into which the geometry will be rendered.</p><p>Then the Tile Accelerator will:</p><ol><li>Grab the geometry data and drawing commands issued by the CPU (either using DMA or traditional transfers).</li><li>Compile this data into an <strong>internal format</strong>.</li><li>Distribute the geometry to each bin based on its coordinates. Clipped geometry will be discarded as well.</li><li>Generate the resulting Display Lists.</li></ol><p>These Display Lists will be interpreted by the 3D engine.</p></div><div id="tab-1-2-powervr2-core"><h4>PowerVR2 Core</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png"><picture><img name="image_cover" alt="Image" width="687" height="396" src="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png" loading="auto"></picture></a><figcaption>Architecture of the PowerVR2 Core</figcaption></div><p>Here is where the graphics are brought into life, the Display Lists received from the TA will be used to render the geometry of a single tile using an <strong>internal frame-buffer</strong>. The process is as follows:</p><ol><li>The <strong>Image Synthesis Processor</strong> or ‘ISP’ fetches the primitives (either triangles or quads) and performs <strong>Hidden-Surface Removal</strong> to remove unseen polygons. Then, after calculating its Z-buffers and stencil buffers, the data goes through <strong>Depth Testing</strong> to avoid rendering polygons that would appear behind others and <strong>Stencil Tests</strong> to cull geometry that won’t be visible if they are located behind a 2D polygon (also called <strong>Mask</strong>).<ul><li>Notice how these tests are effectively carried out at the start of the pipeline. In contrast previous consoles <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">using z-buffers</a> discard the geometry at the end of the pipeline. The ISP approach prevents processing the geometry that will eventually be discarded, thereby saving resources.</li></ul></li><li>The <strong>Texture and Shading Processor</strong> or ‘TSP’ applies colouring and shading over the tile area. It also provides multiple effects (more details later on).<ul><li>Textures are not applied until the tile is exported, meaning that emerging overdraw (if any) will not lower the fill rate.</li></ul></li></ol><p>After the operation is completed, the rendered tile is written to the main frame-buffer in VRAM. This process is repeated until all tiles are finished. Once complete the resulting frame-buffer is picked by the <strong>Video encoder</strong> and sent through the video signal.</p></div></div></div><h4 id="the-big-picture">The big picture</h4><p>Apart from the clear architectural difference, the Texture and Shading Processor comes with many capabilities that give one an idea of how distant this console is from the old <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>. Here are a few:</p><ul><li><strong>Alpha blending</strong>: Combines colours of overlapping layers to achieve transparency effects.<ul><li>The process used for applying transparency in this system is called <strong>order-independent transparency</strong>. The algorithm automatically sorts the primitives before blending their colours, and while this slows down the rendering process, it avoids relying on the game itself to do all the sorting manually. For this reason, Dreamcast games excelled in displaying transparent objects.</li><li>Combined with the tile-based system, order-independent transparency completely addresses previous <a href="https://www.copetti.org/writings/consoles/sega-saturn/#the-transparency-issue">mishaps</a>.</li></ul></li><li><strong>Mip-Mapping</strong>: Automatically selects a scaled-down version of the texture depending on the level of detail required. This is done to prevent processing large textures that would be seen far away from the camera (which would be a waste of processing power and produce aliasing).</li><li><strong>Environment mapping</strong>: Applies reflections on textures.</li><li><strong>Bilinear, Trilinear and anisotropic filtering</strong>: These are different algorithms used to smooth the textures and prevent pixelation. They are ordered from ‘worst’ to ‘best’, where the resulting quality of each one is directly proportional to the amount of computation required.<ul><li>This is a huge step up from the Saturn since the former didn’t provide any texture filter!</li></ul></li><li><strong>Bump mapping</strong>: Simulates defects on surfaces without spending extra polygons.</li></ul><h4 id="gaining-detail">Gaining detail</h4><p>Holly can now draw ~10 times more polygons than <a href="https://www.copetti.org/writings/consoles/sega-saturn/">its predecessor</a>, here’s a <em>Before &amp; After</em> example that shows how model designs are not that limited any more. Try to fiddle with them!</p><h4 id="video-modes">Video Modes</h4><p>The video system was designed to support multiple types of screens and formats, thus the video encoder outputs to a single-shaped socket that supports the following type of signals:</p><ul><li><strong>Composite</strong>: Combines the three signals needed to display video (chroma, luma and sync) into a single one, requiring only a single-pin cable.<ul><li>This is used on old PAL and NTSC TVs with an RCA connection.</li></ul></li><li><strong>S-Video</strong>: Combines luma and sync while keeping chroma separated (two video lines in total).</li><li><strong>RGB</strong>: Sends separate Red-Green-Blue signals and provides different sync types to choose from (composite sync or extracted from video composite or S-Video).<ul><li>A SCART cable will use this type.</li></ul></li><li><strong>VGA</strong>: Combines RGB with two special sync signals (horizontal and vertical) resulting in five video lines in total. This enables to display the biggest resolution possible (720x480) in progressive mode (thus, this mode is often named ‘480p’). VGA has actually been the standard format/medium used by computer monitors for some time.<ul><li>To use this type, Sega provided a VGA adapter as an extra accessory.</li></ul></li></ul><p>Now, the Dreamcast can’t encode all of these at the same time, so the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/dreamcast/">https://www.copetti.org/writings/consoles/dreamcast/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/dreamcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244639</guid>
            <pubDate>Tue, 23 Feb 2021 23:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security Hardening]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26244131">thread link</a>) | @twakefield
<br/>
February 23, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> — a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string — a challenge — and asks a client to sign it.
The server verifies clients’ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called “trust on first use” or TOFU.</p>

<p>If the host’s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether it’s an attack or an IP or a hostname change. Let’s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 user’s public keys on each server and
100 public keys to every user’s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store user’s and host’s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. It’s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, let’s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark —
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and don’t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the host’s identity. The host’s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the host’s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files — a host and a user SSH certificates’ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment — when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore —
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a user’s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleport’s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. That’s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? You’d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
It’s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244131</guid>
            <pubDate>Tue, 23 Feb 2021 22:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Playstation 2]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26243964">thread link</a>) | @biwasa
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/playstation-2/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/playstation-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Playstation 2 was not one of the most powerful consoles of its generation, yet it managed to achieve a level of popularity unthinkable for other companies.</p><p>This machine is nowhere near as simple as the <a href="https://www.copetti.org/writings/consoles/playstation/">original Playstation</a> was, but we will see why it didn’t share the same fate of <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous complicated consoles</a>.</p><hr><h2 id="cpu">CPU</h2><p>At the heart of this console we find a powerful package called <strong>Emotion Engine</strong> or ‘EE’ designed by Sony and running at <strong>~294.91 MHz</strong>. This chipset contains multiple components, one of them being the main CPU. The rest are at the CPU disposal to speed up certain tasks.</p><h4 id="the-leader">The leader</h4><p>The main core is a <strong>MIPS R5900-compatible</strong> CPU with lots of enhancements. This is the first chip that starts executing instructions after the console is turned on. The processor provides the following features:</p><ul><li><strong>MIPS III ISA</strong>: A 64-bit RISC instruction set. <em>Wait, is it me or this is the same ISA found on a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#cpu">competitor’s console</a>?</em>. Not quite, Sony enhanced the ISA by adding some instructions from <strong>MIPS IV</strong> (prefetch and conditional move) along with their own SIMD extension called <strong>multimedia instructions</strong>.</li><li><strong>32 128-bit extra registers</strong>: Another enhancement. They are better managed using multimedia instructions and are very useful for vector processing.<ul><li>These registers are accessed through a 128-bit bus, while the rest of the CPU uses an internal 64-bit bus.</li></ul></li><li><strong>2-way superscalar</strong>: Up to two instructions are executed in parallel.</li><li><strong>24 KB L1 cache</strong>: Divided into 16 KB for instructions and 8 KB for data.<ul><li>It also implements a <strong>prefetch function</strong> to cache instructions and data before they are requested. This is done by including extra circuitry that can identify which places in memory are more often requested.</li></ul></li><li><strong>16 KB of Scratchpad RAM</strong>: Also known as ‘Fast RAM’.</li><li><strong>Memory management unit</strong>: Interfaces memory access with the rest of the system.</li></ul><p>The core is complemented with a <strong>dedicated floating point unit</strong> (identified as ‘COP1’) that accelerates operations with 32-bit floating point numbers (also known as <code>floats</code> in C).</p><h4 id="a-recognisable-memory-choice">A recognisable memory choice</h4><p>Next to the Emotion Engine are two blocks of 16 MB of RAM, giving a total of <strong>32 MB</strong> of main memory. The type of memory used is <strong>RDRAM</strong> (<a href="https://www.copetti.org/writings/consoles/nintendo-64/#ram-available"><em>déjà vu!</em></a>) which is accessed through a 16-bit bus.</p><div><div><a href="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png"><picture><img name="image_cover" alt="Image" width="605" height="269" src="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png" loading="auto"></picture></a><figcaption>Memory design of the Emotion Engine<br>You can guess where the congestion is gonna appear</figcaption></div><p>At first, this can be a little disappointing to hear, considering the internal bus of the Emotion engine is as wide as 128 bits. However, the RAM chips are strategically placed by following the <strong>dual-channel architecture</strong>, which consists in connecting both chips using two independent 16-bit buses (one bus per chip) to improve data throughput. The resulting setup provides a theoretical 3.2 GB/sec, so rest assured that memory latency is not an issue in this console!</p></div><p>At one corner of the Emotion engine there is a powerful <strong>DMA Controller</strong> or ‘DMAC’ that transfers data between main memory and Scratchpad; or between main memory and any component inside the EE.</p><p>Data transfers are done in batches of 128-bits, but here is the interesting part: Every eight batches, the main bus is temporarily unlocked. This leaves a small window to perform other DMA transfers in parallel (up to ten) or let the CPU use the main bus. This <em>modus operandi</em> is called <strong>slice mode</strong> and is one of the many modes available on this DMA unit. Bear in mind that while slice mode reduces stalls on the main bus, it does so at the cost of slowing down the overall DMA transfer.</p><h4 id="preventing-past-mishaps">Preventing past mishaps</h4><p>Whether we want it or not, with the amount of traffic happening inside the Emotion Engine, this design will eventually suffer the consequences of the <strong>Unified memory architecture</strong> or ‘UMA’. That is… multiple independent components trying to access main memory at the same time, causing congestion. Well, to correct these issues, Sony alleviated the constant need for memory by:</p><ul><li>Wrapping their processors with <strong>lots of cache</strong>. Thus, only requiring access to main memory if absolutely necessary.<ul><li>99% of cache/scratchpad mentions in this article will be for this reason.</li></ul></li><li>Adding a 128-byte <strong>Write Back Buffer</strong>: Very similar to the <a href="https://www.copetti.org/writings/consoles/gamecube/#ibms-enhancements">Write Gather Pipe</a>, but instead of waiting until it’s 25% full, it will check the state of the bus (i.e congested or free) first.</li></ul><p>This sounds very convenient for applications that can benefit from cache, but what about those tasks, such as manipulating Display Lists, which shouldn’t use cache at all? Luckily, the CPU provides a different memory access mode called <strong>UnCached</strong>, which <strong>only</strong> uses the Write Back Buffer. Thus, it will not waste cycles correcting the cache (product of <em>cache misses</em>).</p><p>Furthermore, the <strong>UnCached accelerated mode</strong> is also available. This one adds a buffer for speeding up read of continuous addresses in memory.</p><h4 id="other-interesting-bits">Other interesting bits</h4><p>Inside the same Emotion Engine package, there is yet-another processor called <strong>Image Processing Unit</strong> or ‘IPU’, this time designed for <strong>image decompression</strong>. The IPU can be useful when a game needs to decode an MPEG2 movie without jamming the main CPU.</p><p>Long story short, the game sends compressed image streams to the IPU (hopefully using DMA) which is then decoded in a format that the GPU can display. The PS2’s operating system also relies in the IPU to provide DVD playback.</p><p>Finally, the IPU also operates compressed <strong>High-resolution textures</strong>, which saves CPU usage and reduces large transfers.</p><hr><h2 id="co-cpus">Co CPUs</h2><p>It’s been two years since the rivals presented their <a href="https://www.copetti.org/writings/consoles/dreamcast/">latest offering</a>. If you read the former article and just started reading this one, I presume you are <em>still</em> waiting for ‘the thing’ that makes the PS2 as powerful as it seemed back then. Now, let me introduce a <em>very</em> important set of components Sony fitted in the Emotion Engine, the <strong>Vector Processing Units</strong> or ‘VPU’.</p><p>A Vector Processing Unit is a small independent processor designed to operate vectors. In particular, vectors made of four <code>floats</code>. These processors are so fast that they only spend only <strong>one cycle per operation</strong>, which can be extremely convenient for geometry processing.</p><p>VPUs are made of the following components:</p><ul><li>Some <strong>Vector Unit Memory</strong> or ‘VU Mem’: Used as a working space for the Vector unit. It stores values needed to be operated and/or the results of previous operations.</li><li>A <strong>Vector Unit</strong>: The core of the processor. It contains some memory (called <strong>Micro Memory</strong>) to store a program (called <strong>Microprogram</strong>) which instructs the unit on how to operate the data found in ‘VU Mem’.<ul><li>It implements a <strong>64-bit ISA</strong> and the execution unit is <strong>split into two parallel sub-units</strong>. The first one multiplies or adds floats, while the other one divides floats or operates integers. This enables to operate both floats and integers <strong>concurrently</strong>.</li></ul></li><li>A <strong>Vector Interface</strong>: Automatically decompresses vertex data coming from main memory in a format the Vector unit can understand. This unit can also transfer microprograms to Micro Memory.</li></ul><p>To start working, the vector unit needs to be ‘kickstarted’. For this, the main CPU is in charge of supplying the microcode.
There are <strong>two VPUs</strong> fitted in the Emotion engine, but they are arranged differently, giving way to different uses and optimisations.</p><div><ul><li id="tab-1-1-vector-processing-unit-0-link"><a href="#tab-1-1-vector-processing-unit-0">Vector Processing Unit 0</a></li><li id="tab-1-2-vector-processing-unit-1-link"><a href="#tab-1-2-vector-processing-unit-1">Vector Processing Unit 1</a></li></ul><div><div id="tab-1-1-vector-processing-unit-0"><h4>Vector Processing Unit 0</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png"><picture><img name="image_cover" alt="Image" width="881" height="429" src="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png" loading="auto"></picture></a><figcaption>Architecture of VPU0</figcaption></div><p>The first VPU, the <strong>VPU0</strong>, is positioned between the CPU and the other vector unit (VPU1). It provides an ‘assisting’ role to the main CPU.</p><p>The VPU0 has two modes of operation:</p><ul><li><strong>Micromode</strong>: This is the ‘traditional mode’. The VPU will independently execute ‘microinstructions’ from a microprogram stored in Micro memory.</li><li><strong>Macromode</strong>: The VPU0 becomes the ‘COP2’ of the main CPU and executes ‘macro-instructions’, received from the main CPU through a dedicated 128-bit bus.<ul><li>Macro-instruction have the same functionality of microinstructions but use different opcodes. Nonetheless, the VPU execution unit is no longer split (meaning it can only execute one instruction at a time).</li><li>While this mode doesn’t make full utilisation of all the components of the VPU0, it still speeds up the CPU’s vector operations. Moreover, in terms of simplicity, a co-processor is easier to program than an independent unit (something PC programmers will find helpful).</li></ul></li></ul><p>The memory map of the VPU0 also has access to some of the other VPU’s registers and flags, presumably to check its state or quickly read the results of some operations done by the other VPU.</p></div><div id="tab-1-2-vector-processing-unit-1"><h4>Vector Processing Unit 1</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png"><picture><img name="image_cover" alt="Image" width="822" height="431" src="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png" loading="auto"></picture></a><figcaption>Architecture of VPU1</figcaption></div><p>The second VPU found, the <strong>VPU1</strong>, is an enhanced version of the VPU0 with double the amount of micro memory and VU memory. Moreover, this unit includes an additional component called <strong>Elementary function unit</strong> or ‘EFU’ which speeds up the execution of exponential and trigonometric functions.</p><p>The VPU1 is located between the VPU0 and the Graphics Interface (the ‘gate’ to the GPU), so it includes additional buses to feed the geometry to the GPU as quickly as possible and without using the main bus.</p><p>On the other side and due to its location, the VPU1 <strong>only operates in micromode</strong>.</p><p>It’s obvious that this VPU was designed for trigonometric operations, and may serve as a pre-processor for the GPU. Hence, it’s often put in charge of delivering the famous Display Lists.</p></div></div></div><h4 id="infinite-worlds">Infinite worlds</h4><p>A useful approach that can be exploited with these units is <strong>procedural generation</strong>. In other words, instead of building the scene using hard-coded geometry, let the VPUs generate it using algorithms. In this case, the VPU computes <strong>mathematical functions to produce the geometry</strong> which is then interpreted by the GPU (i.e. triangles, lines, quadrangles, etc) and ultimately used to draw the scene.</p><p>Compared to using explicit data, procedural content is ideal for parallelised tasks, it frees up bandwidth, requires very little storage and it’s dynamic (programmers can set parameters to achieve different results). There are certain areas that can highly benefit from this technique:</p><ul><li><strong>Complex surfaces</strong> (e.g. spheres and wheels).</li><li><strong>World rendering</strong> (e.g terrains, particles, trees).</li><li><strong>Bezier curves</strong> (a very popular equation in computer graphics which is used to draw curves), …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/playstation-2/">https://www.copetti.org/writings/consoles/playstation-2/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/playstation-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243964</guid>
            <pubDate>Tue, 23 Feb 2021 22:41:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Your Own React]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26243760">thread link</a>) | @autoditype
<br/>
February 23, 2021 | https://pomb.us/build-your-own-react/ | <a href="https://web.archive.org/web/*/https://pomb.us/build-your-own-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><pre><code><div><p><span>function</span><span> </span><span>createElement</span><span>(</span><span>type</span><span>,</span><span> props</span><span>,</span><span> </span><span>...</span><span>children</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      children</span><span>:</span><span> children</span><span>.</span><span>map</span><span>(</span><span>child</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>typeof</span><span> child </span><span>===</span><span> </span><span>"object"</span></p></div><div><p><span>          </span><span>:</span><span> </span><span>createTextElement</span><span>(</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>createTextElement</span><span>(</span><span>text</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>function</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>type </span><span>==</span><span> </span><span>"TEXT_ELEMENT"</span></p></div><div><p><span>      </span><span>?</span><span> document</span><span>.</span><span>createTextNode</span><span>(</span><span>""</span><span>)</span></p></div><div><p><span>      </span><span>:</span><span> document</span><span>.</span><span>createElement</span><span>(</span><span>fiber</span><span>.</span><span>type</span><span>)</span></p></div><div><p><span>  </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> </span><span>{</span><span>}</span><span>,</span><span> fiber</span><span>.</span><span>props</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isEvent</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> key</span><span>.</span><span>startsWith</span><span>(</span><span>"on"</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isProperty</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  key </span><span>!==</span><span> </span><span>"children"</span><span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>isEvent</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isNew</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>const</span><span> </span><span>isGone</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>(</span><span>key </span><span>in</span><span> next</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> prevProps</span><span>,</span><span> nextProps</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isGone</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>  deletions</span><span>.</span><span>forEach</span><span>(</span><span>commitWork</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>wipRoot</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>commitWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>const</span><span> domParent </span><span>=</span><span> fiber</span><span>.</span><span>parent</span><span>.</span><span>dom</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"PLACEMENT"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    domParent</span><span>.</span><span>appendChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"UPDATE"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"DELETION"</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>removeChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>sibling</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>let</span><span> nextUnitOfWork </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>function</span><span> </span><span>workLoop</span><span>(</span><span>deadline</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> </span><span>!</span><span>shouldYield</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    nextUnitOfWork </span><span>=</span><span> </span><span>performUnitOfWork</span><span>(</span></p></div><div><p><span>    shouldYield </span><span>=</span><span> deadline</span><span>.</span><span>timeRemaining</span><span>(</span><span>)</span><span> </span><span>&lt;</span><span> </span><span>1</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> wipRoot</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>performUnitOfWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>=</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span></p></div><div><p><span>  </span><span>const</span><span> elements </span><span>=</span><span> fiber</span><span>.</span><span>props</span><span>.</span><span>children</span></p></div><div><p><span>  </span><span>reconcileChildren</span><span>(</span><span>fiber</span><span>,</span><span> elements</span><span>)</span></p></div><div><p><span>    nextFiber </span><span>=</span><span> nextFiber</span><span>.</span><span>parent</span></p></div><div><p><span>function</span><span> </span><span>reconcileChildren</span><span>(</span><span>wipFiber</span><span>,</span><span> elements</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    wipFiber</span><span>.</span><span>alternate </span><span>&amp;&amp;</span><span> wipFiber</span><span>.</span><span>alternate</span><span>.</span><span>child</span></p></div><div><p><span>    index </span><span>&lt;</span><span> elements</span><span>.</span><span>length </span><span>||</span></p></div><div><p><span>    </span><span>const</span><span> element </span><span>=</span><span> elements</span><span>[</span><span>index</span><span>]</span></p></div><div><p><span>      element</span><span>.</span><span>type </span><span>==</span><span> oldFiber</span><span>.</span><span>type</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>element </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber</span><span>.</span><span>effectTag </span><span>=</span><span> </span><span>"DELETION"</span></p></div><div><p><span>      oldFiber </span><span>=</span><span> oldFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>      wipFiber</span><span>.</span><span>child </span><span>=</span><span> newFiber</span></p></div><div><p><span>      prevSibling</span><span>.</span><span>sibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hi </span><span>{</span><span>props</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span></p></div><div><p><span>const</span><span> element </span><span>=</span><span> </span><span>&lt;</span><span>App</span><span> </span><span>name</span><span>=</span><span>"</span><span>foo</span><span>"</span><span> </span><span>/&gt;</span></p></div><div><p><span>const</span><span> container </span><span>=</span><span> document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span></p></div><div><p><span>Didact</span><span>.</span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span></p></div></code></pre></div></div></div>]]>
            </description>
            <link>https://pomb.us/build-your-own-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243760</guid>
            <pubDate>Tue, 23 Feb 2021 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on what it takes to raise $20M from A16Z]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26243152">thread link</a>) | @buf
<br/>
February 23, 2021 | https://www.siliconvict.com/reforge-a16z-round | <a href="https://web.archive.org/web/*/https://www.siliconvict.com/reforge-a16z-round">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-reforge-a16z-round"><p><span><span>Today, Reforge announced that we </span><span><a href="https://www.reforge.com/blog/weve-raised-21m-to-grow-reforge" target="_blank" rel="noopener noreferrer">raised $20M+ from a top VC firm</a></span><span>. I'd like to reflect a bit on that journey and some decisions made.</span></span></p><h2 id="block-d80e093b0fca4b29b133fbe410506ef0"><span id="d80e093b0fca4b29b133fbe410506ef0"></span><span><span>Founding Engineer</span></span></h2><p><span><span>I am the founding engineer at Reforge. "Founding engineer" just means that I take a lower salary than I would make in Facebook or Google in exchange for a large equity stake that vests over the period of generally 4 years. Sometimes this pays off, and "founding engineers" make millions or tens of millions of dollars in a short period of time. Most often, it doesn't.</span></span></p><p><span><span>I've been a founding or early engineer a few times. At </span><span><a href="https://www.eventbrite.com/" target="_blank" rel="noopener noreferrer">Eventbrite</a></span><span>, I was engineer #3, going from $4M to $700M in valuation. That turned out well.</span></span></p><p><span><span>
Additionally, I've started two companies, one of which was a 100% total loss, and a waste of 18 months of my life. I'll never get that time back, but I gained some perspective on identifying good opportunity. The other is doing okay at 500k users, but still too early to tell.</span></span></p><p><span><span>Which is a good segue for shit.</span></span></p><h2 id="block-89b8099e4a4743878b0cb9f2a93747be"><span id="89b8099e4a4743878b0cb9f2a93747be"></span><span><span>Why Join Reforge</span></span></h2><p><span><span>When I was considering joining Reforge, I had just started </span><span><a href="https://www.castingcall.club/" target="_blank" rel="noopener noreferrer">Casting Call Club</a></span><span>, and built it up to about 35k users. But, Reforge had a lot going for it on paper.</span></span></p><p><span><span><strong>Brian Balfour, ex-VP at Hubspot and 3 time startup founder, was at the helm.</strong></span></span></p><p><span><span>When I met Brian, I got the same butterflies in my stomach that I got when I met </span><span><a href="https://en.wikipedia.org/wiki/Kevin_Hartz" target="_blank" rel="noopener noreferrer">Kevin Hartz</a></span><span>, the founder at Eventbrite. Brian is a guy who simply knows his shit. The biggest successes I got in life was aligning my career journey temporarily to someone who knows their shit. You can't latch on forever because you'll never grow out of their shadow, but you can suck the experience out of them by getting as much 1-on-1 time with them as possible during the early days.</span></span></p><p><span><span>How do you know if someone knows their shit? First you have to know your own shit, and know where the gaps in your shit are. Fill the gaps in your shit with their shit. #RealTalk</span></span></p><p><span><span>For 2.5 years at Reforge, there would only be 5 people at the company (all of whom are incredible in their own right), and my opportunity to siphon off as much knowledge from Brian as I could would be abundant.</span></span></p><p><span><span><strong>The Reforge content was really fucking good.</strong></span></span></p><p><span><span>Brian had started the Silicon Valley Business Review with Andrew Chen (ex-VP Uber, now A16Z). They did a couple summer cohorts where they ran a program that taught the basics of what Growth is. Not Growth Hacking, or the disparate learnings of greasy bloggers looking to sell their guru courses. Brian and Andrew were offering a deep, comprehensive, foundational walkthrough of Growth, and they called it the Growth Series. This gave birth to Reforge.</span></span></p><p><span><span>When I caught whiff of what they were up to -- and realized how it was different, and far better, than the static and shallow MOOCs you'd find on Coursera and Udemy or the massive time-dump a 2-year degree was -- I knew there was real potential. Nothing out there could compare.</span></span></p><p><span><span><strong>The network is the moat.</strong></span></span></p><p><span><span>I was thinking about Harvard a lot when I was deciding to join Reforge. No one spends a quarter million dollars to go to Harvard just for the content they could get for free on the internet. They join Harvard for the network.</span></span></p><p><span><span>Reforge was already attracting leaders I looked up to, like Casey Winters, Fareed Mosavat, Elena Verna. They were the real market makers in tech, driving hundreds of millions in growth in companies like Instacart, Slack, Eventbrite, Miro, Survey Monkey, Mulesoft. A network like this would be hard to beat.</span></span></p><p><span><span><strong>Cohort-based learning in a huge TAM</strong></span></span></p><p><span><span>From my Techstars days, I knew that learning in cohorts was magic compared to learning things on your own. It feels like you're part of a band of individuals trying to overcome a challenge together, and it builds camaraderie. When my lizard brain finally made the connection that companies would pay for their employees to take Reforge as part of a group, the opportunity clicked.</span></span></p><p><span><span>For example, let's say Shopify has 50 product managers all speaking slightly different product management vernacular. Shopify sends them all to Reforge to build a common vocabulary and best base practices. That's step 1. Step 2: Shopify hires 5 more product managers per quarter. Guess what becomes a part of their onboarding?</span></span></p><p><span><span>Now multiply this by every tech company there is.</span></span></p><p><span><span><em>Okay, I'm convinced. I'll put Casting Call Club to the side and I'll join Reforge.</em></span></span></p><h2 id="block-8e34356f6940451bbed05f6442962ed8"><span id="8e34356f6940451bbed05f6442962ed8"></span><span><span>Early Problems</span></span></h2><p><span><span>Three problems nearly killed the business.</span></span></p><p><span><span><strong>How do you productize networking?</strong></span></span></p><p><span><span>There are lots of tools out there that help build communities, but nothing really felt right for us. </span></span></p><p><span><span>First, no one was talking. Either they were wary of competitors listening, or too busy with work itself, or simply afraid of looking stupid in front of a group of intellectual peers.</span></span></p><p><span><span>Second, we wanted to facilitate both surface and deep conversations at the same time while bubbling up valuable insights to relevant people in a relevant time. From there, we wanted to match people based on interests and relevancy.</span></span></p><p><span><span>After solving these by [redacted], the seasonal data was too few to have confidence in our findings, and so began our efforts to make learning always-on.</span></span></p><p><span><span><strong>Seasonality</strong></span></span></p><p><span><span>Seasonality was a challenge, because user engagement waned during the off-season, and our ability to experiment with new features was limited. But seasonality also gave us plenty of time to be pensive. We weren't going to be the kind of company that threw ourselves against the wall until we broke through. Early Reforge was all about careful cuts. We measured everything well, and it led to results that would've been hard-pressed if we were a venture capital backed startup then.</span></span></p><p><span><span>But our purely pensive days were numbered.</span></span></p><p><span><span>Imagine if your company makes millions of dollars in one week, twice per year, and you earn no other income. That was our lives for nearly 4 years at Reforge. Our program cohorts were doing so well that we didn't want to change it too much. We worried over price points, positioning, cannibalization, and we hesitated.</span></span></p><p><span><span>Another question started to rise: Did we need to scale? Is there happiness is building a small company that we don't have to turn into a billion dollar company? We spent a long time questioning this. We stayed heads down and optimized all we could.</span></span></p><blockquote id="block-2a8c25fa850047faac9ff35386165e75"><span><span>By 2019, there was only 5 people in the company and we were making mid 7 figures per year.</span></span></blockquote><p><span><span>Covid went </span><span><em>viral</em></span><span> (get it!?!) in the middle of one of our twice per year cash injections, and we survived the shrinking education budgets of our user's companies, but we were jolted. This was the main catalyst we needed to push Reforge into an always-on model and urge us to build our defenses. Furthermore, the clock was ticking on the Growth Series itself, as it would become a commodity eventually. Other edu-tech companies were sprouting up like mushrooms. It seemed like the time to switch to scale-mode was here at last. </span></span></p><p><span><span><strong>How to scale content creation?</strong></span></span></p><p><span><span>I'd describe Reforge content as encyclopedic; it's a deep collection of theory and application. Every new program took on average 6 months to create in the early days, but worse is that they were made almost entirely by Brian himself. If we were to scale Reforge, we would need to either build a machine that pumps out high quality content or clone Brian. My money was on cloning tech.</span></span></p><p><span><span>The subject matter experts tended to be busy, or poor teachers, or lack the audience to build clout for themselves. We couldn't depend on subject matter experts writing their own content.</span></span></p><p><span><span>We experimented with many things around this time to mitigate the content crunch -- microblogs, connection tools, interactive learnings. Nothing was as powerful as having quality content speak for itself.</span></span></p><p><span><span>Let's go back to shit. Remember above, about knowing shit?</span></span></p><p><span><span>Enter the researchers, whose job it was to interface with the subject matter experts and slowly separate shit from the shit. I'll spare you the tedious details since you're not interested in industry secrets.</span></span></p><p><span><span>After a few arduous cycles of having research-led program creation, the content wheel was spinning and we were ready to scale.</span></span></p><h2 id="block-6fd62f6a40484654b34cc0ff1098e56b"><span id="6fd62f6a40484654b34cc0ff1098e56b"></span><span><span>Scaling Eventbrite</span></span></h2><p><span><span>Being early at Eventbrite showed me the dopamine rush raising millions of dollars was. Teams would double overnight. Budgets would go from 0 to 7 figures. We'd get a dedicated ping-pong room.</span></span></p><p><span><span>Scaling fast also brought a lot of dangers. Communication is the first to go, and unless the pods have strong directional glue, there will be real pain to feel. Next, employee engagement would start to sway. Managers would hire people who spend more time figuring out how to hide than do actual work, and what's worse is that the managers don't give strong reprimand or simply fire the bad actors because the managers themselves would either hide or be too busy to spare the willpower to care. Lastly, HR will replace the ping-pong table with an Eventbrite University classroom, which is the greatest atrocity of them all.</span></span></p><p><span><span>Personally, I struggled scaling Eventbrite. I always volunteered to be on the frontier teams. We had no data team, so I raised my hand. We had no mobile apps, so I started the mobile team (while also learning how to build mobile apps). We couldn't support internationalization, so I co-led those efforts with the CTO as a skunkworks project. I tried my best to stay out of the politics, and into creating utility.</span></span></p><p><span><span>There's a famous saying though. If you want to lead, you must first learn how to follow. If you want to be a good writer, you must first be a good reader. If you want to scale a company, you need to have already done it before.</span></span></p><p><span><span>I think that's how it goes.</span></span></p><h2 id="block-1e54734985e54d1a9a7d0c935b125ac9"><span id="1e54734985e54d1a9a7d0c935b125ac9"></span><span><span>Scaling Reforge</span></span></h2><p><span><span>Reforge feels much different than Eventbrite. For starters, every person in a leadership position here has scaled a company in the past - Hubspot, Eventbrite, Airbnb, Credit Karma, Slack, Instacart - and that led us to create stronger foundations than Eventbrite had. Our strong directional glue on the leadership team alone is healthy, and it's fulfilling to see everyone align so well.</span></span></p><p><span><span>Looking at the engineering/product side of things, we've established a playbook for many of the challenges that we've seen in the past, like where the …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.siliconvict.com/reforge-a16z-round">https://www.siliconvict.com/reforge-a16z-round</a></em></p>]]>
            </description>
            <link>https://www.siliconvict.com/reforge-a16z-round</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243152</guid>
            <pubDate>Tue, 23 Feb 2021 21:32:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26243079">thread link</a>) | @ash
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243079</guid>
            <pubDate>Tue, 23 Feb 2021 21:26:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 247 (<a href="https://news.ycombinator.com/item?id=26242991">thread link</a>) | @Funes-
<br/>
February 23, 2021 | https://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242991</guid>
            <pubDate>Tue, 23 Feb 2021 21:16:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multi-Factor Authentication for Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242969">thread link</a>) | @mooreds
<br/>
February 23, 2021 | https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>As more of our lives move online, multi-factor authentication (MFA) becomes increasingly important as a way of keeping our accounts secure. As a user, you know you should enable MFA on any accounts containing valuable data or which you want to keep safe.</p>

<p>As a developer or software engineer, MFA may seem a bit mysterious. This article will cover:</p>

<ul>
  <li>What MFA is</li>
  <li>Why it is important</li>
  <li>What factors are available</li>
  <li>When you might consider requiring MFA</li>
</ul>

<p>At the end, you should have a good understanding of options for integrating MFA into your applications, and how to start doing so.</p>

<h2 id="what-is-multi-factor-authentication-mfa">What is multi-factor authentication (MFA)?</h2>

<p>When a user is authenticating, they are providing proof of who they are. There are four broad categories of proof:</p>

<ul>
  <li>What the user knows. A password is an example.</li>
  <li>What the user has, such as a device.</li>
  <li>What the user is; one example would be a fingerprint.</li>
  <li>Where the user is, possibly ascertained by using GPS.</li>
</ul>

<p>Each of these methods of proof is called a ‘factor’. Factors must be kept secure. They should not be shared, in order to ensure that the authenticating user is associated with the correct account.</p>

<p>Multi-factor authentication is best understood as requiring two or more factors in order to authenticate a user. MFA is a superset of two factor authentication (2FA). With MFA an arbitrary number of factors of proof can be required. With 2FA, the number of factors is limited to two.</p>

<p>Multi-factor authentication isn’t just for online user accounts, though. If you are accessing a safe deposit box in a bank, you need a key (something you have) and a signature (something you are) or an id (another thing you have). However, this article will focus on online MFA.</p>

<p>The majority of user accounts have a password as a factor. You might be working in such a system right now. As engineering teams become more aware of the problem of user account hijacking and its real world consequences, more are allowing or requiring additional factors of authentication.</p>

<h2 id="why-use-multi-factor-authentication-mfa">Why use multi-factor authentication (MFA)?</h2>

<p>Building a secure, available system requires ensuring only authorized people and software agents have access to it. This is a foundational concern.</p>

<p>Authentication, which ensures that a system knows who the user is, and authorization, which controls what a given user can access, both play a role in building such a system. While you can control what an actor is doing without knowing who they are, it’s far more common to tie authentication and authorization together.</p>

<p>If your users have only one factor of authentication, it can be stolen, especially if it is a password. At that point, you as a developer will have limited ability to stop the thief. Your system will have to notice suspicious behavior to determine who is legitimate and who is not. This can be done, but is complex to do at scale. If you can’t determine illicit access, the thief will have the same privileges as the user whose stolen credentials are being used; they will be indistinguishable from that user.</p>

<p>Unfortunately, passwords are being stolen regularly. While systems can help prevent unauthorized access by <a href="https://fusionauth.io/learn/expert-advice/security/breached-password-detection/">detecting stolen passwords</a> and users can protect themselves by practicing good password hygiene, requiring another factor increases the obstacles to a bad actor.</p>

<p>In particular, if another factor is required as part of the login process, account security can increase dramatically. Microsoft researchers found that accounts are <a href="https://techcommunity.microsoft.com/t5/azure-active-directory-identity/your-pa-word-doesn-t-matter/ba-p/731984">“99.9% less likely to be compromised”</a> if MFA is used.</p>

<p>Implementing MFA is a partnership with your users, however. Some factors are easier for system developers to support. Others require more effort and care from users.</p>

<h3 id="the-balance-between-user-experience-and-security-risk">The balance between user experience and security risk</h3>

<p>However, though MFA is more secure, you shouldn’t require it everywhere. It’s a balance, like many parts of software engineering; you want to make the user login experience as smooth as possible while minimizing chances of account takeover. Users don’t love an application for the login experience. They want to solve their problems. Friction in the authentication process will annoy some percentage of your users and negatively affect your application’s success.</p>

<p>User experience isn’t only about how easy the factor is to use. It’s also about how widely deployed a solution is. If, say, retinal scanning is trivial to use, but users don’t have or can’t find the hardware, then it isn’t really that easy after all.</p>

<p>Listen to your users when considering factors. You don’t want them to circumvent MFA in ways that will damage system security. At the same time they may need to be educated. Do you know people who still write down passwords on sticky notes? I do.</p>

<p>As a developer, you need to balance between the user experience and the risk of account takeover. In some situations the call is easy. If your site lets users vote on cat pictures, MFA isn’t really required. If your site transfers money to arbitrary people, on the other hand, it should require MFA. These scenarios are at opposite ends of the security and user experience spectrum:</p>

<p><img src="https://fusionauth.io/assets/img/advice/mfa/security-ux-spectrum.svg" alt="More secure or easier to use?"></p>

<p>The hard part is the situations where the answer isn’t obvious. What are some situations where you should consider requiring multi-factor authentication?</p>

<h2 id="when-to-require-multiple-factors-of-authentication">When to require multiple factors of authentication</h2>

<p>There are many situations where you need a higher level of assurance about the actor behind the credentials. Sometimes the type of the user account is the deciding factor. Other times it is the access requested. Depending on your application and organization, legal requirements or corporate policies may control.</p>

<h3 id="administrative-accounts">Administrative accounts</h3>

<p>Privileged accounts with higher levels of access need to use MFA.</p>

<p>These administrator or operator accounts can wreak havoc if misused or compromised. Therefore you should require MFA on all admin accounts. In extremely sensitive systems, all changes could require providing additional factors.</p>

<h3 id="high-value-accounts">High value accounts</h3>

<p>There are also plenty of high value user accounts where MFA can help prevent unwanted account compromises. These accounts don’t necessarily possess elevated privileges, but allow data access or actions with real world consequences. Compromise of these accounts can have negative repercussions.</p>

<p>An example of such an account is an online bank account. You don’t want users to learn that someone drained their savings because of a stolen password.</p>

<p>Another example is an email account. Beyond the private information often present in email accounts, they represent a risk to accounts in other systems. Many password reset flows send an email to a known address and allow the recipient of that email to modify the password. Compromise of an email account means that any other accounts associated with this user are at risk.</p>

<h3 id="risky-actions">Risky actions</h3>

<p>When a user has already authenticated but is performing a dangerous action, MFA again provides extra security. This is also known as “step up auth”, because the additional factor is required at the moment a more privileged action is undertaken. Examples of such actions include:</p>

<ul>
  <li>Changing a password or username</li>
  <li>Modifying setting which impact other factors, such as an email or phone number</li>
  <li>Creating a new user with elevated privileges</li>
  <li>Changing system settings</li>
</ul>

<p>These types of actions can be legitimate, but could also be used by someone who has compromised a user account. You can partially mitigate the damage of a compromised account by implementing step up auth. An attacker may be able to access account data, but won’t be able to take damaging action.</p>

<h3 id="laws-or-organizational-policies">Laws or organizational policies</h3>

<p>If your application is used by certain organizations or stores personally identifiable information, you may need to require multi-factor authentication for users. As part of the NIST risk management framework, for example, Authenticator Assurance Level 2 requires: <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63-3.pdf">“proof of possession and control of two different authentication factors…”</a>.</p>

<p>Sometimes an MFA requirement is not explicit, however. If you are looking to be SOC2 certified, MFA may be required, even though the term is never mentioned in the <a href="https://www.aicpa.org/content/dam/aicpa/interestareas/frc/assuranceadvisoryservices/downloadabledocuments/trust-services-criteria.pdf">SOC “Trust Services Criteria”</a>. Section CC6.1 of the SOC document specifies “Persons, infrastructure, and software are identified and authenticated prior to accessing information assets, whether locally or remotely” without outlining implementation details. In this case, talk to your auditor about MFA requirements as well as other required controls.</p>

<p>When planning MFA, make sure you review any relevant laws, standards or corporate policies.</p>

<h3 id="when-the-users-actions-look-suspicious">When the user’s actions look suspicious</h3>

<p>An auth system has a unique viewpoint into who is signing in. Information is supplied and reviewed; it results in an answer to the question: “is the person providing this information the user who they are claiming to be?” Some data is provided by the user explicitly, such as the username and password. But every auth system has access to implicit data such as:</p>

<ul>
  <li>The date and time of access</li>
  <li>Connection information like the IP address, location, and user agent</li>
  <li>Whether this device has been used to access this service before</li>
  <li>How many times the user has logged in recently</li>
</ul>

<p>Such data can help determine if the person behind the authentication request is legitimate. For instance, if a user accesses a system from the USA but one day later there is a request from Germany with the same credentials, the request deserves scrutiny. It’s possible it is legitimate; after all, airplanes exist. But also possible that there is something nefarious going on in Germany.</p>

<p>Requiring MFA before access is allowed when suspicious activity occurs provides another check against stolen credentials. That German hacker could have acquired a user’s password, but it’s harder to steal a one time passcode sent to the user’s phone as well.</p>

<h2 id="commonly-used-factors-for-mfa">Commonly used factors for MFA</h2>

<p>Beyond a password, what are other ways a user can prove who they are? As mentioned above, there are four main categories.</p>

<ul>
  <li>What they know.</li>
  <li>What they have.</li>
  <li>Who they are.</li>
  <li>W…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/">https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242969</guid>
            <pubDate>Tue, 23 Feb 2021 21:14:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new take on remote/hybrid standups]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26242959">thread link</a>) | @Ali_Jiwani
<br/>
February 23, 2021 | https://www.rally.video/post/stand-ups-suck-why-not-rally-instead | <a href="https://web.archive.org/web/*/https://www.rally.video/post/stand-ups-suck-why-not-rally-instead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Covid-19 forced everyone to start thinking remote first. Companies started to replace meetings with video calls and eventually questioning if the meeting was necessary. Work went from 'why is everything a meeting?' to "just send me an email/slack message'. Over the past few months we spoke to dozens of remote companies, and we learned that while many have reduced the number of meetings, some actually changed certain meetings to adopt to new technology and ways of working. One of the changes we saw most consistency was the standup - their most frequent and hated meeting.</p><p>In this post, we will talk about:</p><ul role="list"><li>Why do synchronous and asynchronous stand ups suck.</li><li>How the purpose of the stand up will change with the predominance of remote work.</li><li>The end of the traditional standup, and the beginning of a better alternative - a Rally.</li><li>How you can make your standup more like a Rally.</li></ul><h2>Why do synchronous and asynchronous stand ups suck?</h2><p>Standups were originally designed for agile engineering teams. With the world going remote, many companies outside engineering have adopted this practice as a way to update each other on daily progress. They may not call it standups, but the essence is the same.</p><p>The problem with standups is that they are a distraction, and it feels more beneficial to management than to the team. For people working together, standups often don't deliver any new information, and for those working apart, the information is seemingly useless. Standups are also set at weird times to accommodate for everyone across all timezones. That sucks because it takes you away from your work state for a meeting that feels pointless. Finally standups are used as a way for managers to keep track of their teams. Sometimes this is effective, other times it feels intrusive.</p><p>How about asynchronous standups? Surely this is a better solution as it gives everyone flexibility and it feels less likely like management is breathing down your neck. A quick google search on asynchronous standups also reveals similar problems to the standups. People don't care about the update, the context is usually missing, and there is no conversation around blockers. Ultimately asynchronous standups don't provide much value either.</p><p>As one user on Hacker News puts it "Going async sends a message that people don't need to care about what their team members are working on. That's a dream come true for the people who just want to pull Jira tickets out of the queue, finish them in isolation, and then collect a paycheque." And another chimes in "it doesn't make for great team cohesion and knowledge sharing. Teams end up compensating with extra meetings and coordination overhead, which starts to defeat the point of async standups."</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314b54800c1961716bd82f_hn%20post.png" loading="lazy" alt=""></p><figcaption>Source: https://news.ycombinator.com/item?id=23194569</figcaption></figure><p>Is the answer then to cancel standups? Or to do some form of a hybrid async standup? Call me crazy, but what about extending the standup virtually and inviting a few more teams. Let's go back to first principles so I can explain why.</p><h2>How the purpose of the stand up will change with the predominance of remote work</h2><p>The original purpose of a stand up was to answer three questions:</p><ul role="list"><li>What was I working on yesterday?</li><li>What will I work on today?</li><li>What is blocking me or stopping me from success?</li></ul><p>The idea is to physically get off your chair, discuss the above three questions, and finish the meeting in roughly 15 mins. It is a meeting for the team, not for management.</p><p><em>Source: </em><a href="https://www.atlassian.com/agile/scrum/standups"><em>https://www.atlassian.com/agile/scrum/standups</em></a></p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314ba6f1c0b469307efa91_1_5L-pHXCmAl0GcryXyREF6A.jpeg" loading="lazy" alt=""></p><figcaption>Source: <a href="https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb">https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb</a></figcaption></figure><p>Standups also have an unintended benefit that is not talked about - it brings the team together. In a remote world, isolation is the number one complaint many employees have. Isolation leads to a decline in mental health, productivity, and overall well being. Isolation can also impact teams, where they feel left out from the rest of the company and are forced to have more meetings to play catch up. This is why so many people crave going back to the office. It's not for the meetings, it's for the people. Even the most introverted people have found isolation daunting.</p><p>The problem is this crucial benefit is overlooked in standups, and people start to resent this meeting. The way to solve this problem is to reframe the purpose of the meeting entirely, so much so that it may even warrant a new name, which we call a Rally.</p><h2>What is a Rally? And how will it replace the standup?</h2><p>A Rally is not a formal standup, it is a collaborative get together. Our Rallys are daily and they are 30 minutes long. The original idea came from one of our first engineering hires: Nate Wildermuth, and it's stuck ever since. We spend the first 20-25 minutes chatting, playing a game, or running an activity (see below for examples). Occasionally this leads to a great idea (such as this blog post!) or a tonne of laughs that builds some terrific momentum for the rest of the day. We then take the last 5-10 minutes discussing what we worked on, what we will work on, and any blockers we have. Usually by the time we are discussing work, we feel much more energized and ready to take on the day.</p><h3>"Standups are an endless series of trivia nights where everyone loses." Nate</h3><p>Of course, we use our own video software for these standups. This is because we designed Rally to allow multiple groups to have conversations in the same space. We call these groups 'tables', and we call the space a 'room'. It is easy to hop around to different tables to chat, or sit at a table in case someone needs to chat with you. We also have a stage where you can present to everyone in the room. This way we can let everyone know what we are working on if we needed. Luckily we're not the only ones that do this. We have a number of customers who have been using Rally for similar collaborative meetings. After speaking with them we have come up with a framework for how we think about Rallys, followed be some examples.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314aba2469e82b4aa034b1_Slide%204_3%20-%201.png" loading="lazy" alt=""></p><figcaption>How Rally Works</figcaption></figure><p>A Rally consists of:</p><ul role="list"><li>A recurring event lasting between 30 and 60 mins, few times a week.</li><li>The team running the event will invite close stakeholders. If the team is less than 50 in size, the entire company will attend.</li><li>People notifying who they want to talk to in advance so they can be efficient with their time, while managers keep an open table to allow anyone to talk to them if needed.</li><li>CEO's and senior execs are also in attendance and can choose to hop around tables to stay put and wait for questions.</li><li>Starting and/or ending with an activity or a game to get people excited.</li></ul><p>While we use Rally every day, we have customers that use Rally multiple times a week for different types of get togethers. We consider all of these to be offshoots of the daily Rally:</p><p>1. <strong>Collaboration Rally</strong>: An hour long session where each team member discusses what they are working on in their team, then hops around to other teams to eliminate blockers. The benefit of this is having everyone in one place instead of setting up extra 30 minute meetings and one on ones. To this successfully, one of our customers runs this meeting every Monday and Friday morning. Each team member prepares what they want to discuss, and reaches out to anyone they need to speak to. On average there are 3-4 cross company conversations lasting 10-20 mins each.Since this is a dedicated hour for everyone, people use this time to catch up on work and remove any blockers they have across the company. It is also a great chance to have everyone in one place. Here is an example of what that looks like:</p><figure></figure><p>2. <strong>Sprint Demo Rally</strong>: An hour long meeting where members from the engineering team hop between tables to present their work. The tables are formed of teams outside engineering so any stakeholder can keep up with engineering work. The meeting usually starts with a presentation from one of the leads to the entire room, and finishes with an activity or hangout in case people have questions.</p><figure></figure><p>3. <strong>Virtual Cafeteria Rally</strong>: An hour long daily meeting for anyone in the company to attend. The meeting is at a set time where someone opens up a Rally lunch room. Teams will jump into tables and enjoy lunch together, as they would in real life, or find friends at other tables to talk to. Instead of having multiple video calls for smaller teams, all the teams are in one place. This way they can hop around tables as they overhear interesting conversations. HR managers have also shuffled people into random tables as a way for people to meet each other.</p><figure></figure><h2>How can you change your standup into a Rally?</h2><p>Start by calling it a Rally and not a standup.</p><p>Reframe the purpose of the standup so its not purely about work but about catching up and hanging out as well.</p><p>Start the Rally with a game, activity or fun fact. Here are some options you can try out:</p><ul role="list"><li><a href="https://www.rally.video/games-and-resources">Rally's Games &amp; Activity page</a></li><li><a href="https://bored.social/">Bored Social</a></li><li><a href="https://meet.airconsole.com/">Air Console</a></li></ul><p>If you are hybrid, encourage people to sign in with their own devices for this meeting so it feels like everyone is remote (on their own computers).</p><p>Consider having this meeting few times a week instead of daily</p><p>Consider not limiting this Rally to just your team, but inviting teams you collaborate with to join</p><p>You can improve your standups on any video platform. We're obviously biased because we built our own and we think it is more fun, easier to use, and gives more autonomy to each user! If you'd like to give us a try, why not head over to <a href="https://rally.video/">https://rally.video</a> and sign up for an account. Have questions or comments? Email us at <a href="mailto:hello@rally.video?subject=Blog%20on%20Daily%20Rallies">hello@rally.video </a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.rally.video/post/stand-ups-suck-why-not-rally-instead</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242959</guid>
            <pubDate>Tue, 23 Feb 2021 21:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create a great production readiness checklist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242906">thread link</a>) | @anishdhar
<br/>
February 23, 2021 | https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-_32987516-cd92-7936-c83c-b0d3724b1a2f-82f65440"><p>What does your team’s production readiness practice look like for deploying a new service? If you or a dedicated SRE team within your engineering organization has ever green-lit a new service, you probably have used some form of a <strong>production readiness checklist</strong> to ensure certain conditions are met and processes are followed. In this article, we’ll share some helpful approaches for creating a great production readiness checklist that will set your team up for a successful launch.</p><h2>What should be on your production readiness checklist</h2><p>The ideal production readiness checklist is comprehensive, but flexible — it can and should look different based on the type of service you’re deploying and the impact of the launch. That said, there are certain categories that are essential for any checklist.</p><h3>Logging and monitoring</h3><p>Production issues can be extremely costly, so it’s important to make sure you have the right logging and monitoring in place for any new service. By preparing now, you can make sure that you have the data you need to debug failures when they (inevitably) occur — otherwise, issues might go undetected or take too long to fix.<br></p><p>Make sure your team knows exactly what is being recorded across your application and access logs — and if there’s a piece of information you might need to debug a failure, start logging it from day one. Although it might seem obvious, it’s also important to document where to <em>find </em>the logs, since the people debugging your service later on might not be the same people who wrote your logging code. Also document key information about the service, like where the git-repo lives, what language is used, what version, and when the service was deployed.<br></p><p>Before launching, make sure you’ve implemented alerts that notify your team when certain SLA thresholds are exceeded. And ensure there is appropriate tracing across other services that might interact with this one.&nbsp;</p><h3>Automated tools and processes</h3><p>You can get some of the above for free by using automated tools. Your team most likely relies on third-party software to automate your monitoring, on-call rotations, incident management, and more (if you need any tips, check out <a href="https://www.getcortexapp.com/post/a-guide-to-the-best-sre-tools" target="_blank">our guide to SRE tools</a>). If this is the case, getting ready for production means making sure that everyone has access to the right tools and dashboards and knows where to find them. You should make sure your on-call rotation is set up and your teammates know how to use your playbooks for incident management. And you’ll want to make sure that a team is responsible for regularly checking that your tools are still configured and working as expected throughout the lifetime of the service.&nbsp;</p><h3>Engineering best practices</h3><p>There are some aspects of your production readiness checklist that aren’t easily automated. For example, you should make sure that whoever wrote new APIs also wrote good documentation and made sure the APIs were well-versioned. Or you will want to ensure when your team is making a call, they’re logging the status codes. And have you done load testing and capacity planning?<br></p><p>For a lower-impact service, some of these questions might default to the honor system. But most of the time, you will need to have a conversation between the engineers who developed the service and a manager or SRE to verify that certain best practices were followed.&nbsp;</p><h3>Ownership / communication</h3><p>SRE teams are more successful when they reduce tribal knowledge, and it’s important that for every new service you push into production, you have great communication from the beginning. This means identifying a clear owner — a single team or engineer who will take accountability for the service. It’s also important to document the way your team will discuss issues, like a dedicated Slack channel and a direct escalation path.</p><h2>How to organize your production readiness checklist</h2><p>Defining a production readiness process is one of the most important things you can do for the health of your products, but getting it to stick as part of your team’s culture can be hard. No one wants to feel like a nag, and yet the honor system doesn’t always work in practice. At the same time, production readiness checklists are usually unwieldy and a hassle to manage. With all those questions and answers to document, teams typically end up using Excel or Google Sheets to store their lists. But it’s hard to standardize and communicate across many different spreadsheets that are floating around. And someone has to maintain those spreadsheets and keep them up to date.&nbsp;</p><figure><p><img src="https://assets.website-files.com/5fff18095410c63a0f88f178/6035679677fa757db96cd542_DTwczVBYP9Pv5EOm0C46JG_j376zwDYzFu7LCGDnX5DM2zmN_YGG7he8MY5lFvj5pZIUUC3cI2iu_qK2KDbH_n7VzvVYQNAXK9PthvHRYpgmLav9IC_t6A1fj9iG3gwnl89u8Ew.png" alt=""></p><figcaption>Here’s a screenshot of a typical production readiness checklist in a spreadsheet format. The question marks indicate places where the team was missing information or wasn’t even sure who the owner of a service was.</figcaption></figure><p>At Cortex, we developed <strong>Scorecards </strong>to replace the production readiness spreadsheet and help your team understand the health of your services at a glance. You can set standardized requirements for each service and adjust them as needed (for example, maybe for 10% of your services, you enforce extra security vulnerability scans). We integrate with your third-party automation tools so that you get most of your scorecard filled in automatically, and we let you create and answer custom questions for everything else. If something changes out from under you— like your on-call rotation disappearing from PagerDuty — you can see it right in the Scorecard.&nbsp;</p><figure><p><img src="https://assets.website-files.com/5fff18095410c63a0f88f178/6035679602645372bcefbba8_ZZeVzk4va38bPFhWdzGvtzgXH-N3S2JyqWpl6FFteP-O1HD3J_6v3HXZVeBr8ECX63GD19gfin6SH4UOTa8gxcI75tUf48u6T7symncvOwNa8qfAA0R1xxjg1NJpo8Zyujy7fxc.png" alt=""></p><figcaption>Cortex’s dashboard showing the scorecards for your services.</figcaption></figure><p>We built Scorecards because we wanted to make production readiness more objective and clear, and as engineers ourselves who have worked with countless third party tools, we know how important it is to create a single source of truth that your whole team can refer to.&nbsp;Scorecards help create a culture of ownership and reliability among service owners within the team!<br></p><p>The details of your production readiness checklist are important, but the details don’t matter if the overall process is broken. We encourage you to take a step back and think about how you can bring a culture of blameless communication to your production readiness practice. If you’re interested in finding out more about Cortex, sign up for a <a href="https://www.getcortexapp.com/" target="_blank">free account here</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242906</guid>
            <pubDate>Tue, 23 Feb 2021 21:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Kafka API is great; now let's make it fast]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242197">thread link</a>) | @sorenbs
<br/>
February 23, 2021 | https://vectorized.io/blog/fast-and-safe/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/fast-and-safe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><blockquote>
<p><small>Note: we will host a live twitch stream on Thursday, February 25th at 10am PT for 1hr. Come and ask us questions live. We will walk through the code, benchmarks, results, and if time permits, we’ll walk through the storage engine design.</small></p>
</blockquote>
<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s"></p>
<blockquote>
<p><small>1250k msg/sec - 1KB payload - ack=all - fsync after every batch - 1 hour benchmark
</small></p>
</blockquote>
<p>This blog post represents months of work and over 400+ hours of actual
benchmarking where we compared
<a href="https://vectorized.io/redpanda">Redpanda</a>
and the latest 2.7 Kafka Release. We used the recommended production
setup and environment from Confluent’s
<a href="https://github.com/confluentinc/openmessaging-benchmark" target="_self" rel="nofollow">fork</a>
of the CNCF open messaging benchmark.</p>
<p>Before we get started, the entirety of the actual results with the full
workload distribution, saturation, latency and throughput are at the bottom
of this interactive <a href="https://vectorized.io/blog/fast-and-safe/#The-full-test-suite-below">blog post</a>.</p>

<p>The <a href="https://vectorized.io/blog/intelligent-data-api/" target="_self" rel="nofollow">Kafka API</a>
has emerged as the lingua franca for streaming workloads. Developers
love the ecosystem and being able to turn sophisticated products
overnight. Just like Apache and Nginx have their own HTTP
implementations, gccgo and the Go compiler specify parsers for the
language, MySQL and Postgres implement SQL, Redpanda and Kafka implement
the Kafka API. Redpanda aims to bring operational simplicity to the
existing overwhelming complexity of standing up state-of-the-art
streaming systems. This manifests at its lowest level in no longer
having to choose between data safety and performance.</p>
<p>Let’s be clear, the reason tail latency matters in the world of big data
is because Redpanda does not exist in isolation. It often sits between
your web servers, databases, internal microservices, data lakes, etc.
Redpanda controls the information flow of how, when and where things are
stored, transferred, accessed, mutated and eventually delivered. The
reason we obsess over tail latency is because the p99.99 in a messaging
system happens often - it’s a simple function of the messages exchanged.
As the volume of interactions and messages between systems using the
Kafka API increases, so does the probability that a single user
operation or API call is affected by latencies <strong>above</strong> the 99.99th
percentile.</p>
<p>The Kafka API is good, below, we showcase how we made it fast.</p>

<p>We present 18 workloads below. All workloads for both systems replicate
the data to 3 nodes in total with no lag (manually verified in the
quorum system). The only difference is that Apache Kafka was run with
in-memory replication (using the page-cache) and flushing after every
message. Redpanda can only be operated in safe mode (flushing after
every batch) with acks=all. The benchmarks below are the same benchmarks
<a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/" target="_self" rel="nofollow"><u>Alok Nikhil &amp; Vinoth Chandar from
Confluent</u></a>
performed while comparing Pulsar and Kafka with a 1.2GB/s extension,
using the same CNCF Open Messaging Benchmark suite.</p>
<p>First, we note that we were only able to reproduce Confluent’s first 6
results. For the other three workloads, the data shows that it is in
fact impossible to achieve sustained network throughput above 300MB/s on
AWS on i3en.2xlarge instances. Please see our Benchmark Appendix section
at the end for a detailed explanation. We also change the default 1
minute warmup time to 30 minutes to account for <a href="http://www.brendangregg.com/blog/2016-09-28/java-warmup.html" target="_self" rel="nofollow"><u>common
pitfalls</u></a>
in <a href="https://arxiv.org/abs/1602.00602" target="_self" rel="nofollow"><u>Virtual Machine</u></a>
benchmarking practices and focus entirely on steady state performance.
We then ran each workload for 60 additional minutes, recorded the
results and repeated the steps, taking the best run of each system. That
is, each time we ran the benchmarks it took over 54 hours to finish.</p>
<p>For all workloads, we used two m5n.8xlarge for the clients, with
32-cores and with 25Gbps of guaranteed networking throughput
and 128GB of memory to ensure the bottleneck would be on the server
side. The benchmark used three i3en.6xlarge 24-core instances with
192GB of memory, 25Gbps guaranteed networking and two NVMe SSD devices.</p>
<p>We note that after spending several hundreds of hours benchmarks, we had
to scale up Confluent’s Kafka settings to keep up with larger instances
to num.replica.fetchers=16, message.max.bytes=10485760,
replica.fetch.max.bytes=10485760, num.network.threads=16,
num.io.threads=16, log.flush.interval.messages=1. Otherwise, the gap
between Redpanda and Kafka would be much larger. This had the
unfortunate effect that for lower percentiles, Kafka’s latency was a
little higher than using half as many threads as specified by
Confluent’s Github repo.</p>
<p>All the latencies below are the end-to-end p99.999 latency with 16
producers and 16 consumers with 100 partitions on a single topic. Every
message represents 1KB of data. We note that by and large Kafka is able
to keep up on throughput except for a couple of workloads with acks=all
where Redpanda is better. The meaningful differences are in latency: how
fast can each system go.</p>
<h2 id="Safe-workloads---fsync-with-every-batch">Safe workloads - fsync() with every batch<a href="#Safe-workloads---fsync-with-every-batch" aria-label="Safe workloads   fsync with every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka p99.999</strong></th>
<th><strong>Redpanda p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all + fsync() after every batch</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>215.191ms</td>
<td>12.405ms</td>
<td>+1634.71%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>102.589ms</td>
<td>52.122ms</td>
<td>+96.82%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>235.675ms</td>
<td>13.999ms</td>
<td>+1522.66%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>1801.263ms</td>
<td>16.606ms</td>
<td>+10747.06%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>1725.391ms</td>
<td>20.552</td>
<td>+8295.25%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>1945.039ms</td>
<td>27.307ms</td>
<td>+7022.86%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>3015.295ms</td>
<td>60.943ms</td>
<td>+4263.23%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>3839.663ms</td>
<td>174.521ms</td>
<td>+2100.12%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>3797.167ms</td>
<td>237.688ms</td>
<td>+1497.54%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Percentage Change was computed using: ((v2-v1)/abs(v1))*100 </small></p>
<p><small> Note: All of our work is open source on <a href="https://github.com/vectorizedio/openmessaging-benchmark" target="_self" rel="nofollow">GitHub</a>. Safe workloads mean acks=all and fsync after every batch before returning to the client.</small></p>
</blockquote>
<h2 id="In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch">In memory replication for Kafka (page cache &amp; no explicit flushes) vs. <strong>Redpanda fsync()</strong>-ing after every batch<a href="#In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch" aria-label="In memory replication for Kafka page cache  no explicit flushes vs Redpanda fsync ing after every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka (no fsync) p99.999</strong></th>
<th><strong>Redpanda (with sync) p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>12.728ms</td>
<td>12.405ms</td>
<td>+2.6%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>216.253</td>
<td>52.122ms</td>
<td>+314.9%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>222.785ms</td>
<td>13.999ms</td>
<td>+1491.44%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>216.195ms</td>
<td>16.606ms</td>
<td>+1201.9%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>13.737ms</td>
<td>20.552ms</td>
<td>-33.16%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>218.32ms</td>
<td>27.307ms</td>
<td>+699.5%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>4225.215ms</td>
<td>60.943ms</td>
<td>+6833.06%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>4877.279ms</td>
<td>174.521ms</td>
<td>+2694.67%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>202.667ms</td>
<td>237.688</td>
<td>-14.73%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Workload (5) is a bug on our write-behind strategy: <a href="https://github.com/vectorizedio/redpanda/issues/542" target="_self" rel="nofollow">issue #542</a> </small></p>
</blockquote>
<p><strong>We’ve said this ad nauseam: <a href="https://vectorized.io/blog/redpanda-raison-detre/" target="_self" rel="nofollow"><u>hardware is the
platform</u></a></strong>.
Modern hardware is capable of giving you both low latency and no data
loss (fsync). Let’s talk about most of the meaningful low-level
architectural differences that get us there</p>

<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s">
Before we dive deep into details, we encourage you to sign up for our
live Twitch Stream where we’ll be going through every single claim made
in this article, and are happy to answer your questions live. It will be
me, emacs, you and questions. Perfect.</p>
<p>When we started building Redpanda, the main driving factor was
<strong>understandability</strong>. Above performance, we wanted a simple mental
model of what it meant to have 2 out of 3 replicas up and running, which
is how we ended with Raft - a protocol with a mathematical proof of
correctness &amp; log completeness and a focus on usability as part of its
design goals.</p>
<p>However, once you get your replication model set, the rest of the life
of the product is spent on predictability, and for big-data &amp; real time
systems, that means understandable, flat tail latencies. It is not
enough to be fast. It is not enough to be safe. When trying to handle
hundreds of terabytes per day of streaming you need to be predictable
not only in the way the product breaks in case of network partitions,
bad disks, etc, but also in how performance degrades as a function of
hardware saturation. This is at the core of operational simplicity for
streaming systems.</p>
<p>Modern hardware allows us to finally have nice things. It is not the
case anymore that you have to choose between safety (no data loss) and
speed (low latency). Furthermore, this predictability affords you
accurate planning for product launches. As a user, I understand how to
buy hardware. I will perform an `fio` test and have a decent
understanding of what that specific hardware can do. Redpanda lets you
take these hardware saturation numbers and gives you a reasonable chance
of predicting how costly it is to develop a new product.</p>
<p>Without further ado, let me count the ways:</p>
<h2 id="0-No-page-cache">0) No page cache<a href="#0-No-page-cache" aria-label="0 No page cache permalink"></a></h2>
<p>The page cache is an object in the Linux Kernel. It is maintained per
file with global locking semantics. It is a tried and true, generic
scheduling mechanism with heuristics from a variety of production use
cases that push and pull the design to a really good middle ground. It
aims to never be a bad choice if you need to do IO. However, for our
specific use case - a log - we can do much better. We understand
exactly, all the way to the user application, how much data is going to
be needed next, the access patterns which mostly move forward, update
frequency, background operations and cache prioritization.</p>
<p>For us, the page cache introduces latency and nondeterministic IO
behavior. For example, when loading data for a Kafka fetch request the
Linux Kernel will trigger general-purpose read-ahead heuristics, and
cache the bytes it read, take a global lock, and update indexes.
Redpanda does not do general IO. It is a log, append only, with well
understood access patterns. We add data to the end file and have
aggressive write-behind strategies. When we read data, Redpanda reads in
order, which means we can in theory have perfect read-ahead and object
materialization that sits above the byte array style API of the page
cache, etc.</p>
<p>More fundamentally, bypassing the Kernel’s page cache allows us to be
predictable, with respect to both failure semantics and tail latency. We
can detect and measure the rate and latency of IO and adjust our buffer
pools accordingly. We can react to low memory pressure situations and
have a holistic view of our memory footprint. We have predictability
over each filesystem operation that can actually affect correctness - as
recently evidenced by the PostgreSQL team with an fsync() bug that was
<a href="https://www.youtube.com/watch?v=1VWIGBQLtxo" target="_self" rel="nofollow">undetected for 20 years</a>.</p>
<h2 id="1-Automatic-Linux-Kernel-Tuning">1) Automatic …</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/fast-and-safe/">https://vectorized.io/blog/fast-and-safe/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/fast-and-safe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242197</guid>
            <pubDate>Tue, 23 Feb 2021 20:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swiss National Bank: How to issue a central bank digital currency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26241831">thread link</a>) | @FloDo
<br/>
February 23, 2021 | https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03 | <a href="https://web.archive.org/web/*/https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
       <article>
        
        <h2><span>David Chaum</span>, <span>Christian Grothoff</span> and <span>Thomas Moser</span></h2>
        
        <p><b>Issue</b><br><span>2021-03</span></p>
        <p><b>Pages</b><br><span>34</span></p>
        <p><b>JEL classification</b><br><span>E42, E51, E52, E58, G2</span></p>
        <p><b>Keywords</b><br><span>Digital currencies, central bank, CBDC, blind signatures, stablecoins</span></p>
        <p><b>Year</b><br><span>2021</span></p>
        
        <ul>
         <li>
          <a href="https://www.snb.ch/n/mmr/reference/working_paper_2021_03/source/working_paper_2021_03.n.pdf">
           <div>
            
            <p>
             <h3>How to issue a central bank digital currency</h3>
            </p>
           </div>
           <p>PDF</p>
          </a>
         </li>
        </ul>
        <p>With the emergence of Bitcoin and recently proposed stablecoins from BigTechs, such as Diem (formerly Libra), central banks face growing competition from private actors offering their own digital alternative to physical cash. We do not address the normative question whether a central bank should issue a central bank digital currency (CBDC) or not. Instead, we contribute to the current research debate by showing how a central bank could do so, if desired. We propose a token-based system without distributed ledger technology and show how earlier-deployed, software-only electronic cash can be improved upon to preserve transaction privacy, meet regulatory requirements in a compelling way, and offer a level of quantum-resistant protection against systemic privacy risk. Neither monetary policy nor financial stability would be materially affected because a CBDC with this design would replicate physical cash rather than bank deposits.</p>
       </article>
      </div></div>]]>
            </description>
            <link>https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241831</guid>
            <pubDate>Tue, 23 Feb 2021 19:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: NeoChat 1.1, a Matrix client by KDE]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26241591">thread link</a>) | @ognarb
<br/>
February 23, 2021 | https://carlschwan.eu/2021/02/23/neochat-1.1/ | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2021/02/23/neochat-1.1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Exactly 2 months after <a href="https://carlschwan.eu/2020/12/23/announcing-neochat-1.0-the-kde-matrix-client/">NeoChat 1.0</a>, the NeoChat team is happy to announce a new release of NeoChat. NeoChat is a native client for the decentralized communication network Matrix.</p><p>Aside from the many bug fixes, performance improvements, and subtle appearance improvements, NeoChat 1.1 brings many new features that will make your experience with it more convenient.</p><p>Thanks to the work of Hannah, Nicolas, and Tobias, this release also brings NeoChat to many more platforms. Nightly builds of NeoChat are now available on <a href="https://binary-factory.kde.org/job/Neochat_android/" target="_blank" rel="noopener">Android</a>, <a href="https://binary-factory.kde.org/job/Neochat_x86_64_flatpak/" target="_blank" rel="noopener">Flatpak</a>, <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_appimage/" target="_blank" rel="noopener">AppImage</a>, <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_macos/" target="_blank" rel="noopener">macOS</a> and <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_win64/" target="_blank" rel="noopener">Windows</a>. Not all of them are considered production ready, but we hope to improve the support for them in future release.</p><h2 id="new-features">New features</h2><h3 id="first-launch-experience-improvements">First launch experience improvements</h3><p>Probably the highlight of this release is the completely new login page. It detects the server configuration based on your Matrix Id. This allows you to login to servers requiring Single Sign On (SSO) (like the Mozilla or the incoming Fedora Matrix instance).</p><p>Servers that require agreeing to the TOS before usage are correctly detected now and redirect to their TOS webpage, allowing the user to agree to them instead of silently failing to load the account.</p><p>TOS webpage, allowing the user to agree to them instead of silently failing to load the account.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/login.png" data-size="528x794"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/login_huf333a74785c104822f28be1d9fd20432_47550_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/login_huf333a74785c104822f28be1d9fd20432_47550_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/login.png" width="528" height="794" loading="lazy" alt="Login Page"></a><figcaption>Login Page</figcaption></figure><h3 id="stickers">Stickers</h3><p>Everyone loves cute stickers, so now NeoChat supports displaying them too. We don’t yet support sending them.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker.png" data-size="418x310"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker_hu47d490cb79536787ab1910b00492664a_51571_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/sticker_hu47d490cb79536787ab1910b00492664a_51571_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker.png" width="418" height="310" loading="lazy" alt="Viewing a Sticker"></a><figcaption>Viewing a Sticker</figcaption></figure><h3 id="editing-messages">Editing messages</h3><p>Editing messages is another popular feature of every IM client. NeoChat is now able to show edited messages correctly and also make it possible to edit your messages. The behavior is the same as in Element.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/editing.png" data-size="602x116"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/editing_hu132bf95ccf390c7d63fc54dd3ebf7244_8401_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/editing_hu132bf95ccf390c7d63fc54dd3ebf7244_8401_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/editing.png" width="602" height="116" loading="lazy" alt="Editing messages"></a><figcaption>Editing messages</figcaption></figure><h3 id="multimodal-mode">Multimodal mode</h3><p>It is now possible to open a room into a new window. This allows you to view and interact with multiple rooms at the same time.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal.png" data-size="1582x879"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal_hub3ad52b950defc079bcceeb184525122_565169_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal_hub3ad52b950defc079bcceeb184525122_565169_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal.png" width="1582" height="879" loading="lazy" alt="Multimodal mode"></a><figcaption>Multimodal mode</figcaption></figure><h3 id="commands">Commands</h3><p>We added a few commands to NeoChat. Previously you could use <code>/me</code> and <code>/rainbow</code>, and we added a few mores: <code>/shrug</code>, <code>/lenny</code>, <code>/rainbowme</code>, <code>/join</code>, <code>/invite</code>, <code>/part</code>, <code>/ignore</code>, <code>/unignore</code>.</p><h3 id="plasma-integration">Plasma integration</h3><p>We improved the Plasma integration a bit. Now the number of unread messages is displayed in the Plasma Taskbar. It is using the <code>com.canonical.Unity.LauncherEntry</code> DBus protocol, so that should be reasonably supported across desktops.</p><h2 id="tarballs">Tarballs</h2><p>Version 1.1.1 of NeoChat is availabe <a href="https://download.kde.org/stable/neochat/1.1.1/neochat-1.1.1.tar.xz" target="_blank" rel="noopener">here</a>.
The package is signed with my gpg key <a href="https://carlschwan.eu/gpg.html">14B0ED91B5783415D0AA1E0A06B35D38387B67BE</a>.</p><p>For users, a <a href="https://flathub.org/apps/details/org.kde.neochat" target="_blank" rel="noopener">Flathub version</a> will be updated shortly.</p></section><div><h2>Comments</h2><p>You can use your Mastodon account to reply to this <a href="https://mastodon.technology/@kde/105782079763058379">post</a>.</p><p><a href="https://mastodon.technology/interact/105782079763058379?type=reply">Reply</a></p></div></div>]]>
            </description>
            <link>https://carlschwan.eu/2021/02/23/neochat-1.1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241591</guid>
            <pubDate>Tue, 23 Feb 2021 19:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Covid-19 Vaccine Data by State]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26241107">thread link</a>) | @already
<br/>
February 23, 2021 | https://humanified.org/covid19-resources | <a href="https://web.archive.org/web/*/https://humanified.org/covid19-resources">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><header></header><section id="vaccine__header"><p>Please visit <a href="https://www.cdc.gov/" target="_BLANK">CDC.gov</a> for all other COVID-19 related searches.</p><img src="https://humanified.org/map-covid.svg" id="vaccine__map" alt="covid__map"><main><div id="covid-locator"><p id="vh_pre"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100">Testing + Vaccination Search</span></p><h2 id="vh_post"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="250">Finding a COVID-19 testing location or vaccination site has been too</span><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">stressful. We’ve compiled each state’s information into one easy resource</span><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="350">for you to use. Start with your location and find what you need, faster.</span></h2><h2 id="vh_post"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="250">Finding a COVID-19 testing location or vaccination site has been too stressful. We’ve compiled each state’s information into one easy resource for you to use. Start with your location and find what you need, faster.</span></h2></div></main></section><div id="search"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>Search</small></p><h2 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">Find your <span>COVID</span> <br> <!-- -->vaccine locations</h2><form autocomplete="off"><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400"><p>Zip Code</p><p>Please select an address from the dropdown</p></div></div></form></div></div><p>Vaccine location<!-- --> copied to clipboard</p></div><section id="stats"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>By The Numbers</small></p><h2 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200">Vaccines <span>accross the US </span></h2></div><div><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200"><div><p><img itemprop="logo" src="https://humanified.org/deliver__vaccine.svg" alt="Humanified"></p></div></div></div><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400"><p>Vaccines available in each state</p></div></div></div></div></section><section id="about-us"><img itemprop="shape" src="https://humanified.org/shapevaccine.svg" alt="Humanified"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>POWERED BY</small></p><p><img data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200" itemprop="logo" src="https://humanified.org/hlogo.svg" alt="Humanified"></p></div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>ABOUT HUMANIFIED</small></p><h3 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200">The Social Impact <br>Social Network</h3><h4 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">Humanified is a soon-to-launch social impact network that makes it easier for everyone to #MakeChangeHappen. Create content for the causes you believe in, discover new ways to get involved, and donate to verified nonprofits. <strong>Coming to the App Store 2021.</strong></h4><p><a href="https://humanified.org/" data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400">LEARN MORE</a></p></div></div><p><small>HUMANIFIED 2021 ALL RIGHTS RESERVED</small></p></section></div></div></div>]]>
            </description>
            <link>https://humanified.org/covid19-resources</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241107</guid>
            <pubDate>Tue, 23 Feb 2021 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Internals of Deno]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240614">thread link</a>) | @noch
<br/>
February 23, 2021 | https://choubey.gitbook.io/internals-of-deno/ | <a href="https://web.archive.org/web/*/https://choubey.gitbook.io/internals-of-deno/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a671402f9c104d4ca3f3e0e3bd2226eb" autocorrect="on" spellcheck="true" data-gramm="false"><div data-slate-void="true" data-key="5872759d45bb43c19d09429f75a1450f"><div><figure data-key="5872759d45bb43c19d09429f75a1450f" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-MJJDXLU1fV3Te4epBgE%2F-MPkuG0v9GiIrAbOSZT7%2F-MPkuJbfKXqKQxLndO6N%2F1.png?alt=media&amp;token=15582e6f-3556-4b55-a47c-e155037141f4" loading="lazy"></p></div></figure></div></div><p data-key="ff9050011d61423096ecd2bff04840bb"><span><span data-key="74f8fde097f24649a5a791abafeba925"><span data-offset-key="74f8fde097f24649a5a791abafeba925:0"><span data-slate-zero-width="n">​</span></span></span></span></p><h2 id="how-does-deno-execute-programs" data-key="ff9c0fa5f5b7459da5c704b3080ddca5"><p><span><span data-key="0ba18263635a4306b8f63e40bc207303"><span data-offset-key="0ba18263635a4306b8f63e40bc207303:0">How does Deno execute programs?</span></span></span><a href="#how-does-deno-execute-programs" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="8488cb7273c842e8a2da233f742dc8cc"><span><span data-key="be32858c70794e95bab81f431ebe0c0c"><span data-offset-key="be32858c70794e95bab81f431ebe0c0c:0"><strong data-slate-leaf="true">Vol - 1</strong></span></span></span></p><h3 id="by-mayank-choubey" data-key="72bec37baeea469faa2d70defc6c44e0"><p><span><span data-key="c7fa99fbcf23483aae8d15dd35621c7f"><span data-offset-key="c7fa99fbcf23483aae8d15dd35621c7f:0">By Mayank Choubey</span></span></span><a href="#by-mayank-choubey" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><h3 id="1st-edition-december-2020" data-key="0729d2eb15534d58887c598a9203b1b0"><p><span><span data-key="e8de8002ed504a589009ebe1f48856d0"><span data-offset-key="e8de8002ed504a589009ebe1f48856d0:0">1st edition - December 2020</span></span></span><a href="#1st-edition-december-2020" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3></div></div></div></div></div></div>]]>
            </description>
            <link>https://choubey.gitbook.io/internals-of-deno/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240614</guid>
            <pubDate>Tue, 23 Feb 2021 18:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retirement Optimization for Tech Employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240363">thread link</a>) | @zuhayeer
<br/>
February 23, 2021 | https://withcompound.com/r/retirement-optimization-for-tech-employees | <a href="https://web.archive.org/web/*/https://withcompound.com/r/retirement-optimization-for-tech-employees">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>"Compound interest is the 8th wonder of the world. He who understands it, earns it; he who doesn't, pays it."</h3></p><div><section>    
<p>
      Planning for retirement often feels pointless. You’re young and your startup is taking off — why should you worry about retirement now?
    </p>
    <p>There are two concepts that make this planning a no-brainer:</p>
    <p><b>1. Compounding</b></p>
    <p>Interest on interest unlocks exponential growth. If you earn 5% annual interest on a $10,000 deposit, you’ll have $10,500 after the first year. In the second year, you’ll earn interest on the initial deposit plus interest on the interest you earned. And so on. Over 50 years, a 5% compounded interest rate will grow your $10,000 deposit to over $110,000. The earlier you start, the more time your money has to grow.</p>
 <p><b>2. Tax-advantaged accounts</b></p>
    <p>The government provides opportunities to invest tax-free in the stock market through retirement accounts. While beating the stock market is hard, maximizing your contribution to tax-advantaged investment accounts provides an instant increase to your future returns.</p>
    <p>Compounding, tax-free returns generate long-term wealth. Combining these tools with a broader asset allocation strategy will help you manage uncertainty (e.g., handling a global pandemic) and achieve your financial goals. This guide explains how to make the most of these tools. We’ll cover the different types of retirement accounts and how to strategically optimize your contributions.</p>

   
</section></div></div><div><h3>Retirement Account Types<br></h3><div><section>
    <p>
		All retirement accounts — 401(k)s and IRAs — share some basic characteristics:
    </p>
    <p><b>1. Tax advantages</b></p>
  	<p>Both you and your employer can save on taxes with these accounts.</p>
    <p><b>2. Contribution limits</b></p>
    <p>Without contribution limits, these retirement accounts could easily be repurposed as huge tax shelters for the ultra-wealthy.</p>
    <p><b>3. Restrictions on withdrawals before age 59 ½</b></p>
    <p>Without an age restriction, these accounts would be no different from normal taxable accounts apart from their tax advantages, and they wouldn't encourage long-term saving.</p>
    <p>We'll go over the specific details of each of these characteristics as they relate to each account type below.</p>

</section></div><h4>401(k) Plans</h4><div><section>
  <p>401(k) plans are the most common type of retirement plan offered by employers. Under a 401(k), you tell your employer to redirect a certain amount from your paycheck to your 401(k) account instead.</p>
	<p>There are two types of 401(k)s, Roth and Traditional:</p>
</section></div><div><section>

    <p>
Your company may offer 401(k) matching. For instance, if you elect to contribute $2,000 from your paycheck to your 401(k), your employer might put $2,000 in too so the ending balance on your account after the pay period would be 
 <span>$4,000 higher<label for="sn-4khr"></label></span>
        
        <span>Usually, your employer will say something like "we'll match 6% of your paycheck." If you make $100,000 a year, that means if you contribute $6,000, your employer will also contribute $6,000. Your employer won't contribute any more than that, but you're free to contribute more from your own paycheck for greater personal tax savings.</span>
. You should always take advantage of the full match — it's free money!
</p>
<p>
You can invest the money in your 401(k) account from the selection of products (e.g., mutual funds) offered by your company's 401(k) plan administrator, typically a firm such as Fidelity or Vanguard. These products might be less appealing than what you'd get elsewhere, but it's all up to the plan administrator and generally not something you can control. It's also important to keep in mind that returns might be lower on these products due to administrative fees — which is one benefit of a separate individual retirement account (IRA).
</p>
<p>
When you leave your job, you can take your 401(k) with you. You can either move the funds into your new employer's 401(k), or move the funds into an individual retirement account (IRA). Generally, moving the funds into an IRA is a better decision (explained below).</p>   
</section></div><h4>Individual Retirement Accounts (IRAs)</h4><div><section>

    <p>
Individual Retirement Accounts (IRAs) offer tax advantages like a 401(k), but don't need to be sponsored by an employer. Like a 401(k), they can be classified as either
<span>Roth<label for="sn-rothn"></label></span>
        
        <span>So-named because they were established by legislation championed by former Senator William Roth of Delaware.</span>
 or traditional.</p>
</section></div><div><section>
        <p>
        Note that unlike a 401(k), whose contribution limits reset every calendar year, the length of a "year" for contribution limit purposes for IRAs is actually fifteen months. You can make IRA contributions for a given tax year until the tax filing deadline for the year. That means that between January 1 and April 15 of the following year (tax day), you can contribute to your IRA for either the current year or the previous year.
        </p>
        <p>
        Also, you can only contribute to an IRA if you have employment income. If your total income this year was $1,000 from freelancing and $100,000 from investments, you'd only be able to contribute $1,000 to your IRAs.
        </p>
				<p>
You can invest the money in your IRA account in the investment options (stocks, bonds, mutual funds, etc.) offered by the provider of your IRA. This will often be a better selection of options than what you'd get through your 401(k).        </p>
</section></div><h4>Self-Directed IRAs (SDIRAs)</h4><div><section>
        <p>
A self-directed IRA (SDIRA) is not a separate IRA type per se, since an SDIRA can be either Roth or traditional.        </p>
        <p>
SDIRAs are offered by specialized firms. You would open one if you wanted to invest in assets other than the basic stock and bond products offered by a regular IRA provider like Fidelity or Vanguard. Depending on which firm you work with, they might support alternative investments like real estate, cryptocurrency, and startup equity. An SDIRA allows you to hold these assets in a tax-advantaged way, in the same way a regular IRA allows you to hold stocks and bonds in a tax-advantaged way.        </p>
				<p>
For example, let's say you open a self-directed Roth IRA and fund it with $6,000. Then, you invest that money in a real estate partnership. Next, the partnership buys a fourplex in Los Angeles and rents it out to four tenants. Any rental income you receive from that property will accrue in the account and you won't have to pay taxes on it, and if the property appreciates and you sell it, you won't have to pay capital gains taxes either — since growth in a Roth IRA is tax-free.
</p>
<p>
On the equity side, PayPal co-founder Max Levchin allegedly has almost $100 million of tax-free gains in his self-directed Roth IRA from the appreciation of his startup stock.
</p>
<p>
SDIRAs are less common than their regular IRA counterparts at Vanguard or Fidelity, but for people with long time horizons to retirement, the alternative investments they allow can help provide better returns (alpha). We'll talk more about this below under "Diversification".</p>
</section></div><h3>Playbook</h3><div><section>
<p>
Despite the complexity of all these different plan and account types, for most people, planning for retirement is pretty simple.
</p>

<p>
To start, you'll need to decide how to allocate your savings between the different plans — how much to contribute to your 401(k), and if you are able to or should contribute to your IRAs. Then — depending on your plan's offerings and what your income allows — you'll need to decide the type of account: 
				<span>Roth<label for="sn-rothp"></label></span>
        
        <span>
        The Roth 401(k) is a relatively new invention, so your employer's 401(k) administrator may not offer it. If that's the case, you're stuck with the traditional option. Also, unlike a Roth IRA, a Roth 401(k) has no income limits — you can contribute to a Roth 401(k) no matter how much money you make.
        </span>
 or traditional. Consider:</p>
 <ol type="1">
      
      <li>
      <b>401(k) matching: </b>
      Does your company offer a 401(k) plan and do they match your contributions? If yes, take advantage of the full match first. The immediate 100% return you get on the matched funds is better than almost anything else you'd get in the markets.
      </li>
      
      <li>
      <b>Tax bracket: </b>
			Do you think you'll be in a higher tax bracket now or when you retire? If you think you're going to be in a lower tax bracket in retirement, deferring taxes now through a traditional 401(k) or IRA makes more sense so you pay taxes in that lower retirement bracket when you withdraw. If you're very early in your career and think you're going to be in a higher tax bracket by the time you retire, Roth versions of those accounts make more sense, so you avoid taxes in that higher retirement bracket when you withdraw.      </li>
</ol>
<p>
Most people in tech are highly compensated (i.e. their retirement tax bracket will likely be lower than their current tax bracket — a good rule of thumb is whether you make 
<span>over ~$160,000<label for="sn-160k"></label></span>
        
        <span>
Here's an example. Let's say you plan to live on $100,000 a year in retirement (a relatively cushy amount). In 2021, that would put you in the 24% bracket. If you make over $164,926 (the cutoff for the next bracket, 32%), you should defer your taxes to retirement.        </span>

) and work for companies with generous 401(k) matching. If that sounds like you, your playbook looks something like this (the order is important for maximum tax savings):
</p>
 <ol type="1">
      
      <li>
      <b>Opt for a traditional 401(k): </b>
			Deferring taxes until retirement makes sense since you're currently in a high tax bracket.
      </li>
      
      <li>
      <b>Maximize your match: </b>
			Contribute as much as you can to your 401(k) to take full advantage of your employer match. Ideally, the maximum of your employer match should be the minimum that you set aside for retirement — otherwise, you're leaving money on the table.
			</li>
      <li>
      <b>Continue contributing to your 401(k): </b>
If you can afford to save even more for retirement, keep contributing to your 401(k) until you hit the $19,500 limit to get the maximum tax deduction.
</li>

<li>
      <b>Contribute to a backdoor Roth (advanced): </b>
Contributing to a traditional IRA doesn't make sense if you've already contributed to a 401(k) since there's no extra tax deduction, so if you can afford to save more than $19,500, contribute up to …</li></ol></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withcompound.com/r/retirement-optimization-for-tech-employees">https://withcompound.com/r/retirement-optimization-for-tech-employees</a></em></p>]]>
            </description>
            <link>https://withcompound.com/r/retirement-optimization-for-tech-employees</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240363</guid>
            <pubDate>Tue, 23 Feb 2021 17:53:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thought Space vs. Reality – Hypothesize Less, Validate More]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240293">thread link</a>) | @suketk
<br/>
February 23, 2021 | https://suketk.com/thought-space-vs-reality | <a href="https://web.archive.org/web/*/https://suketk.com/thought-space-vs-reality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>There are two worlds - the one in our head and the one that is real. It’s easy to conflate the two; perception is reality, the saying goes. But they are separate. Perception is just a representation of reality and as we know, <a href="https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation">the map is not the territory</a>.</p>

<p>We use thought space to model reality. It serves us well for simple activities, enabling us to successfully predict the consequences of our actions (e.g driving through a yellow light). For more involved tasks, however, we overestimate the fidelity of our model. As a result, operating excessively in thought space impedes us from creating the desired outcomes in the real world.</p>

<p>Here’s a recent example. When I reviewed the draft of my <a href="https://suketk.com/feeds-considered-harmful">first essay</a>, I was preoccupied with this question: will anyone find this useful? I pored over it, top to bottom. On the first pass, it was elementary. On the next, it was profound. On another, it was too abstract. As I dizzily vacillated between opinions, a realization struck - the essay itself hadn’t changed. Only my impression did. In fact, the quality of the essay was impervious to my perception. It would remain as good (or bad) as it was, regardless of my impression. I was pursuing the wrong goal. An “accurate” opinion was just a means to an end - to determine whether others would find it useful. So, rather than continue theorizing, I decided to publish it to uncover the answer directly.</p>

<p>Prolonged time in thought space doesn’t just slow us down. It leads us astray and delays course correction, through misplaced confidence in our judgement. Ever dreaded a conversation, building it up in your head, only to realize it was nothing to worry about? Left unchecked, our perception steadily drifts away from reality. To keep them in sync, we must regularly validate our hypothesis in the real world. If we don’t, our future actions are built on a shaky foundation of invalid assumptions. Consequently, we waste valuable energy on outcomes that don’t manifest in the way we intend. Consider how many successful founders had to pivot from their first idea. Would their companies be alive if they spent years perfecting the original idea in isolation? No. This is the exact danger of perfectionism (perfectionitis?) - the misallocation of resources towards success defined by a model that isn’t representative of reality.</p>

<p>Thought space alone does not move us forward. Reading a book on productivity doesn’t make you more effective. Listening to a startup podcast doesn’t make you a better entrepreneur. Watching a cooking video doesn’t make you a better chef. Action is the interface between thought space and the real world - we actualize our ideas by doing. Knowledge is merely potential energy. Only when applied, does it translate to growth. If not, it just creates an illusion of progress. (This exemplifies the explore/exploit framework discussed in this <a href="https://suketk.com/feeds-considered-harmful">previous essay</a>.)</p>

<p>Next time you’re doing anything, ask yourself this question: am I operating in thought space or reality? This awareness helps you identify your untested assumptions and induces a general bias towards action. By tightening the feedback loop, you empower yourself to simultaneously build a better map and conquer the territory.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://suketk.com/thought-space-vs-reality</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240293</guid>
            <pubDate>Tue, 23 Feb 2021 17:46:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meaninglessness of the National Debt]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239799">thread link</a>) | @paulpauper
<br/>
February 23, 2021 | https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/ | <a href="https://web.archive.org/web/*/https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-22257">
	
	<!-- .entry-header -->

	<div>
		<p>The ‘national debt’ has been a fixture of news and politics, probably since the founding of America. Although the national debt continues to swell–at $27 trillion or so as of writing this–my opinion has not changed, that being the national debt is a meaningless number, much like a mathematical abstraction, that has no  bearing on one’s life or investment strategies.  Articles about the <a href="https://wolfstreet.com/2019/11/02/us-national-debt-passed-23-trillion-jumped-1-3-trillion-in-12-months/">size</a> of the national debt have gone viral on Hacker News and Reddit , as well as headlines about how approximately <a href="https://www.thestreet.com/mishtalk/economics/23-6-of-all-us-dollars-were-created-in-the-last-year">“a quarter all US Dollars were created in past year”</a>. This surge in spending is in large part due to due to Covid stimulus and relief, as shown below:</p>
<p><img src="https://wolfstreet.com/wp-content/uploads/2019/11/US-Gross-National-Debt-2011-2019-11-02.png"></p>
<p>Why am I not concerned? For one, deficit hawks have a terrible track record. Doomsayers like Peter Schiff and Karl Denninger have been predicting hyperinflation, dollar collapse, recession, crisis, etc. for decades, to no avail. This does not mean that they cannot, in theory, one day be right, but I think the odds of that happening are sufficiently low to not pay them any mind. </p>
<p>So why is the debt an abstraction, as opposed to a tangible, real concern. Aren’t these big numbers? Yes, they are big, but what must be taken into account are a couple factors: about 40% of the national debt is owed to itself, either held by the fed or government institutions (such as for Social Security and Medicare), whereas the other 60% are held by foreign governments and private individuals and firms. So this effectively reduces the burden by almost half.</p>
<p><img src="https://ei.marketwatch.com/Multimedia/2018/08/21/Photos/ZQ/MW-GO672_nation_20180821130954_ZQ.jpg?uuid=05b585b6-a565-11e8-b6ab-ac162d7bc1f7"></p>
<p>Second, what matters is not so much the absolute size of the debt but rather the interest paid on the debt relative to GDP, which is very low. The US economy is growing fast enough that the deficit , even if it keeps growing, the interest paid keeps shrinking relative to the size of the economy. </p>
<p><img src="https://www.economicshelp.org/wp-content/uploads/2013/02/debt-interest-payments-percent-gdp-600x434.png"></p>
<p>The US economy is growing at 3+%/year (which may not seem like much but it beats Europe, Japan, South America and much of the developed and developing  world on a real basis), but the US government can borrow at close to nothing, so this is effectively free growth.</p>
<p>Second, the properties or characteristics of the national debt are so distinct from a personal, household, or business debt that there is practically no comparison between the two, further making it an abstraction and divorcing it from any reality that we are familiar with. Imagine being able to borrow at close to nothing, and then being able to print money to pay the interest on the debt if necessary, and such printing does not cause wealth destruction or much inflation in the process, as the US dollar is the official ‘global unit’ of wealth (the Forbes 400 list, for example, is denominated in dollars, not Pounds, Yen, or Euro). So even if the treasury were to print enough dollars to cause price levels to rise meaningfully, because everything is still indexed in dollars, Americans do not lose wealth in the process unless the US dollar falls relative to foreign currencies and there is not a sufficiently high corresponding increase of wealth from wages, stocks, real estate, etc. to offset this, but it is not like Americans particularly care how their wealth is growing or shrinking relative to the Brits, the Germans, or the Japanese. </p>
<p>However, when emerging markets governments print money, it causes their currencies to fall relative to benchmarks like the US dollar, which cases wealth destruction and makes the debt harder to service. By compassion, households and individuals pay vastly higher interest rates and cannot issue their own currency. This is obvious, but is a key distinction and why the US national debt should not be thought of in the same way as a regular debt. It really is something else entirely and more of a function or benchmark of the strength and might of the US global economic and cultural hegemony, than a ‘ticking time bomb’ as many in the media falsely liken it to.</p>
<p>But what about all the Covid spending, in particular, the increase of the M1 money supply? Won’t this cause inflation and other problems? But the spending already happened, and the bond market is unfazed. In fact, the bond market has held up in spite of trillions of dollars of Covid spending (and much more to come), showing that bond vigilantes are not concerned. Why is this? Because this money is not really doing anything. It is not inducing meaningful economic activity and business investment, but rather a large chunk of Covid aid is being saved or used to pay down existing debts. Only <a href="https://review.chicagobooth.edu/economics/2020/article/covid-19-stimulus-checks-spurred-saving-and-debt-payment-more-spending">40%</a> of Covid stimulus was spent on consumer goods, which was the intent. Hence it’s actually deflationary, because the US govt. is borrowing at near 0% so consumers can pay down their own double-digit debts, so the end result is much less indebtedness. Second, the amount of additional consumer spending and activity attributable to the stimulus checks is small relative to the size of overall US consumer spending. US consumers spent $15 trillion in 2020 but Covid stimulus adds just $1 trillion to that, assuming all the money is spent, which it is not.  </p>
<p><img src="https://graphics.reuters.com/USA-STOCKS/0100B2LV20C/personal-consumption.png"></p>
<p>Overall, I am not concerned about the national debt. [Emerging market debt, however, is a different beast altogether, and is a much bigger concern for those economics, than the national debt is a concern for the US economy] The national debt should not factor into the decision making processes of investors. Even bond holders should not be concerned.  In spite of the national debt surging over the past quarter-century, US stocks have posted strong inflation-adjusted returns, especially  since 2010. Treasuries and investment-grade corporate bonds have done well too. Anyone who sold their stocks over fears of the national debt, missed out on what has possibly been the biggest bull market in stocks on an inflation-adjusted basis, ever. The debt will never ‘come due’ in the way that rent or credit card bills have a strict deadlines; but will keep being rolled over forever. The media, pundits, talking heads, etc.  will continue to sound the alarm over the debt, but investors, hedge funds, pensions, institutions–people who actually matter and who have skin in the game–will continue to pay no mind to these warnings. </p>



<p><a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="https://twitter.com/intent/tweet?via=&amp;text=The%20meaninglessness%20of%20the%20national%20debt&amp;url=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/"><img src="http://i.imgur.com/2QyuBgQ.png"></a>

<a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="http://www.facebook.com/sharer.php?u=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-href="https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-send="false" data-layout="button_count" data-width="60" data-show-faces="false" rel="nofollow"><img src="http://i.imgur.com/OBWIOxN.png"></a>

			</p></div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239799</guid>
            <pubDate>Tue, 23 Feb 2021 17:10:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Streamlit to visualize object detection output]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239676">thread link</a>) | @MatthewBrems
<br/>
February 23, 2021 | https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            <header>

                <section>
                    <a href="https://blog.streamlit.io/tag/community/">Community</a>
                </section>

                

                <p>Building an app for blood cell count detection</p>
            </header>

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2021/02/-White--Blood-Cell.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2021/02/-White--Blood-Cell.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2021/02/-White--Blood-Cell.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif" alt="How to Use Roboflow and Streamlit to Visualize Object Detection Output">
            </figure>

            <section>
                <div>
                    <p>Most technology is designed to make your life, or your work, easier. If your work involves building computer vision into your applications, using the <a href="https://roboflow.com/">Roboflow</a> platform gives you everything you need.</p><p><a href="https://www.streamlit.io/">Streamlit</a> is an open-source platform that enables you to convert your Python scripts to apps and deploy them instantly. Streamlit and Roboflow can work hand-in-hand, allowing you to tackle computer vision problems and visualizing your output so you can make better decisions faster.</p><p>In this post, we’ll walk you through using Roboflow and Streamlit together by showing you how to:</p><ol><li>Fit an object detection model in Roboflow</li><li>Use an API to access the model and its predictions</li><li>Create and deploy a Streamlit app</li></ol><p>Specifically, we’ll be working with a common <a href="https://public.roboflow.com/object-detection/bccd">blood cell count and detection dataset</a>. If you want to skip right to playing with it, <a href="https://roboflow.com/streamlit-bccd">here's an interactive app</a> and <a href="https://github.com/matthewbrems/streamlit-bccd">this is the code</a>.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/1-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/1-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/1-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/1-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption>Red blood cells, white blood cells, and platelets.</figcaption></figure><p>We’ll build an object detection model that detects platelets, white blood cells, and red blood cells. Then, the app we develop together will allow you to make predictions with your object detection model, visualize those predictions at a given confidence level, and edit those predictions based on your preferred confidence level with immediate visual feedback.</p><h3 id="how-to-fit-an-object-detection-model-in-roboflow">How to fit an object detection model in Roboflow</h3><p>Have you fit an object detection model before?</p><p>Even if you haven't, Roboflow helps you work through all aspects of computer vision, from uploading, annotating, and organizing your images to training and deploying a computer vision model.</p><p>We believe you shouldn’t have to be a data scientist or need an extensive coding background to be able to use computer vision. You have everything you need right now.</p><figure><img src="https://lh5.googleusercontent.com/Di4bkgiihzqyb4k47H3Ku0GX_amNEgd03y3QFqOzSzLp-Y08ONhYHOKH6a8C_GSEtmUPboTbIWO58gYZ0fW_ceDetVlTinWmh4UC9C3E2PAggPnh3PDW9lrWwLlzyfeXvYN63c1L" alt=""><figcaption>The computer vision workflow.</figcaption></figure><p><br>If you don’t already have a Roboflow account, you’ll need to <a href="https://app.roboflow.com/">head over to Roboflow and create one</a>. If you’d like to start training your model from a public dataset, Roboflow has a <a href="https://blog.roboflow.com/using-public-datasets/">great tutorial that describes</a> how to improve your model more quickly. (Or, you can <a href="https://docs.roboflow.com/adding-data/upload-api">upload your own dataset</a>!)</p><p>Once you have an account, go to our <a href="https://public.roboflow.com/">computer vision datasets</a> page. We’ve made over 30 datasets of different types public and keep adding more.</p><p>The one we’ll walk through today is a blood cell count and detection dataset.</p><p>After you’ve decided which dataset to use, go ahead and fork it. That will create a copy of the dataset that you can now use.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/streamlit_fork_dataset_recording--2-.gif" alt=""><figcaption>Forking a <a href="http://public.roboflow.com/">public dataset</a>.</figcaption></figure><p>At this point, you can directly fit a model. However, we recommend that you preprocess and augment your images.</p><ul><li><strong>Image preprocessing.</strong> Deterministic steps performed to all images prior to feeding them into the model. For example, you might <a href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/">resize your images</a> so they are all the same size, or <a href="https://blog.roboflow.com/when-to-use-grayscale-as-a-preprocessing-step/">convert your images to grayscale</a>.</li><li><strong>Image augmentation.</strong> Creating more training examples by distorting your input images so your model doesn't overfit on specific training examples. For example, you may <a href="https://blog.roboflow.com/how-flip-augmentation-improves-model-performance/">flip</a>, <a href="https://blog.roboflow.com/why-and-how-to-implement-random-rotate-data-augmentation/">rotate</a>, <a href="https://blog.roboflow.com/using-blur-in-computer-vision-preprocessing/">blur</a>, or <a href="https://blog.roboflow.com/why-to-add-noise-to-images-for-machine-learning/">add noise to your images</a>. The goal is to get your model to generalize better to “the real world” when you deploy your model.</li></ul><p>With the blood cell count dataset I’m using, I chose the following preprocessing and augmentation options:</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/2-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/2-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/2-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/2-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://docs.roboflow.com/image-transformations/image-preprocessing">Image preprocessing</a> and <a href="https://docs.roboflow.com/image-transformations/image-augmentation">image augmentation</a> techniques.</figcaption></figure><p>When deciding whether to use a specific augmentation option, I asked myself the question “Is the augmented image a reasonable image for my model to see?” In this case, I added 90°, 180°, and 270° rotations to my image because the slide of cells could reasonably be rotated 90 degrees and still make sense.</p><p>It wouldn't make sense for all applications. For instance, I might not include that kind of rotation for a self-driving car, because stop signs should be seen with the pole jutting into the ground. To rotate the image 180 degrees would make the stop sign upside down and the ground where the sky should be -- that probably isn’t a very useful thing for my model to learn.<br></p><figure><img src="https://blog.streamlit.io/content/images/2021/02/3-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/3-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/3-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/3-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.com/train-test-split/">Training, validation, and testing splits</a>.</figcaption></figure><p>I have my data split up so that 70% of my data is in the training set, 20% is in the validation set, and 10% is in the test set. As you may know, splitting your data into <a href="https://blog.roboflow.com/train-test-split/">training, validation, and testing sets</a> can really help avoid overfitting.</p><p>I’ve decided to create three augmentations. This means that, for each <em>training</em> image, we’ll create three copies of that image, each with random augmentation techniques applied to it. This will give me a total of 874 images that are generated:</p><ul><li>765 augmented training images (765 = 255 * 3) </li><li>plus 73 validation images </li><li>plus 36 testing images.</li></ul><p>Once you’re done with your preprocessing and augmentation, click “Generate” in the top-right corner. <em>Helpful hint:</em> make sure to name your dataset something memorable!</p><h3 id="now-you-re-ready-to-build-a-model">Now you’re ready to build a model</h3><p>To build a model, it’s as easy as clicking “Use Roboflow Train.”</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/4-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/4-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/4-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/4-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Generally, you need a Roboflow Train credit to do this. <a href="https://roboflow.com/contact?utm_source=streamlit&amp;utm_medium=blog&amp;utm_campaign=train">Reach out to us and we’ll get you set up</a>!</p><p>You’ll have the option either to train from scratch or to start from a checkpoint.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/5-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/5-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/5-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/5-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>Train from Scratch.</strong> This is the easier option. Just click and go! Your model will be built from scratch, using only the data you’ve provided to it.</li><li><strong>Start from a Checkpoint.</strong> This option is a little more sophisticated and requires a related existing model. If you’ve already built a model (or if there’s a public model) that has been fit on related data, then starting from a checkpoint allows you to use the existing model as your starting point. The model is additionally trained on your images. Two advantages to this are that your model will train more quickly, and you'll frequently see improved performance! This is known as <a href="https://blog.roboflow.com/a-primer-on-transfer-learning/">transfer learning</a>. However, this does require a related existing model, and we don't always have that.</li></ul><p>In my case, I built my model from scratch, because I didn’t already have a related model.</p><p>That’s all it takes to fit a model in Roboflow. When all is said and done, if your data is already annotated and you don’t make many changes to the augmentations, it’s only a handful of clicks to go from your images to a trained computer vision model. We've also turned <a href="https://docs.roboflow.com/annotate">annotating images into a pretty fast process</a> – especially with <a href="https://blog.roboflow.com/announcing-label-assist/">model-assisted labeling</a>.</p><h3 id="how-to-use-an-api-to-access-the-model-and-predictions">How to use an API to access the model and predictions<br></h3><figure><img src="https://blog.streamlit.io/content/images/2021/02/6-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/6-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/6-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/6-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>You’ll want to make sure your model performs well before getting too far into this. </p><p>Our model seems to perform pretty well. Usually, we use <a href="https://blog.roboflow.com/mean-average-precision/">mean average precision</a> (mAP) to evaluate object detection models. The closer your mAP is to 100%, the better! It’s also helpful to look at your <a href="https://blog.roboflow.com/mean-average-precision-per-class/">model’s performance by class</a> to make sure your object detection model isn’t performing significantly worse for one subset of objects.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/7-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/7-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/7-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/7-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>If your model isn’t performing the way you want, you may want to work on improving that before you proceed. We usually see dramatic improvements in models when people take one (or both) of the following two actions:</p><ol><li><a href="https://blog.roboflow.com/tips-for-how-to-label-images/"><strong>Improve their labeling</strong></a><strong>.</strong> Placing bounding boxes around the entire object, but as close to the edges of the object as possible, can improve your model’s performance.</li><li><a href="https://blog.roboflow.com/handling-unbalanced-classes/"><strong>Correcting for unbalanced classes</strong></a><strong>.</strong> Having one or more classes that are severely underrepresented can make it harder for your model to properly identify those underrepresented classes. A basic example is if you show a child 5 pictures of a dog and 100 pictures of a cat, the child may not do a very good job of identifying a dog.</li></ol><p>Now that we’ve fit a model, we can use that model to generate predictions on new images. The <a href="https://docs.roboflow.com/inference">Roboflow Infer API</a> is one of a few ways to conduct inference and that's what we’ll use.</p><p>In order to use the API, we’ll need a couple of pieces of information from Roboflow. <strong>Make sure you keep these both private. </strong>These are specific to you!</p><ul><li>The model name: this should begin with <code>rf</code>.</li><li>The access token/API key: this should be a 12+ letter code.</li></ul><p>This information can be found in multiple places. I like retrieving these from the Example Web App, because I’ll also easily upload an image and test out my model from there. Once you have these pieces of information, you’ll want to store them – you’ll need them momentarily.</p><h3 id="how-to-create-and-deploy-a-streamlit-app">How to create and deploy a Streamlit app</h3><p>Deploying a Streamlit app is easy. Even if you haven’t spent a lot of time focused on deploying apps before. (Here is the <a href="https://github.com/matthewbrems/streamlit-bccd/blob/master/streamlit_app.py">code I wrote to build the app</a>.)</p><p>Following <a href="https://docs.streamlit.io/en/stable/api.html">Streamlit’s API documentation</a> closely, I was able to build an app that:</p><ul><li>Imported an image file from my computer</li><li>Allowed the user to tweak parameters of our computer vision model</li><li>Showed my imported image overlaid with the model’s predicted annotations</li><li>Calculated and displayed summary statistics about the image and predictions</li><li>Generated a histogram of confidence levels for bounding boxes</li></ul><p>I chose to structure this in two physical components: a sidebar and the main area.</p><ul><li><strong>Sidebar.</strong> In the sidebar, the user gets to select a file to import from their local computer. This is where the user can select an image to pull into the app and edit the confidence and overlap thresholds used when generating predicted bounding boxes for the image.<br></li></ul><figure><img src="https://blog.streamlit.io/content/images/2021/02/8-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/8-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/8-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/8-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><strong>Main Area.</strong> In the main area, we have everything else I mentioned. The image that includes predictions, some statistics about the image and predictions itself, a histogram that shows the confidence levels for all bounding boxes, and a printout of the JSON that stores the bounding box annotations.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you want to see the full code, <a href="https://github.com/matthewbrems/bccd_streamlit_app/blob/main/streamlit_app.py">you can find it here</a>. The three tools that were most helpful in putting this together were:</p><ul><li><strong><code>st.write()</code></strong>: If I wanted to print anything on my screen, <code>st.write()</code> enabled me to do that easily. It supports <a href="https://daringfireball.net/projects/markdown/">Markdown</a>, so I can use ## to control how large or small I want my headings to be. I also used <a href="https://realpython.com/python-f-strings/">f-strings</a> when displaying summary statistics to have more control over how these rendered. For example, rounding …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239676</guid>
            <pubDate>Tue, 23 Feb 2021 17:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ideal way how you want your functional monitoring to run is]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239573">thread link</a>) | @testRigor
<br/>
February 23, 2021 | https://blog.testrigor.com/what-is-functional-monitoring/ | <a href="https://web.archive.org/web/*/https://blog.testrigor.com/what-is-functional-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <figure><img src="https://blog.testrigor.com/content/images/2021/02/AdobeStock_378844640.jpeg" alt="" srcset="https://blog.testrigor.com/content/images/size/w600/2021/02/AdobeStock_378844640.jpeg 600w, https://blog.testrigor.com/content/images/size/w1000/2021/02/AdobeStock_378844640.jpeg 1000w, https://blog.testrigor.com/content/images/size/w1600/2021/02/AdobeStock_378844640.jpeg 1600w, https://blog.testrigor.com/content/images/size/w2400/2021/02/AdobeStock_378844640.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="the-issue">The issue</h3><p>Imagine, that you have monitoring, everything is setup great and your metrics show green. But your customers can't purchase your product in your production or registration doesn't work.</p><p>This is why you'd want to set up something that would monitor that your product works in production from end-user's perspective.</p><h3 id="why-is-it-a-challenge">Why is it a challenge?</h3><p>There is an inherit challenge with functional monitoring: test stability. You don't want to be woken up in the middle of the night because a test flaked out.</p><h3 id="how-it-should-work">How it should work?</h3><p>The ideal way how you want your functional monitoring to run is:</p><p>1) To have a continuously running smoke test suite that would only notify you if there is an issue. This way if your customers can't buy a product or register you'd be immediately notified about it.</p><p>2) Get your notifications on all the right channels like Slack, Email, SMS, Phone.</p><p>3) Your tests are actually testing important functionality that if not working will have tangible business impact on your business.</p>
              </div></div>]]>
            </description>
            <link>https://blog.testrigor.com/what-is-functional-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239573</guid>
            <pubDate>Tue, 23 Feb 2021 16:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Still Sucks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26239543">thread link</a>) | @graiz
<br/>
February 23, 2021 | https://gregraiz.com/css-still-sucks/ | <a href="https://web.archive.org/web/*/https://gregraiz.com/css-still-sucks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main"><article id="post-875"><div><div><p>In 2006 I wrote a blog post about how CSS sucks. The post was popular and somewhat controversial. It’s been 15 years and the core of the problem remains. CSS has certainly improved but it’s still holding back designers and engineers.</p><p>I’ve reposted the blog post with the original comments from blogger as the original site was taken down.</p><hr><p><em>Sept 25th, 2006</em> – CSS Sucks</p><p>CSS is certainly an improvement on plain old HTML but its limitations are staggering and the lack of industry support will continue to hold back designers for many years to come unless we begin to build and design something better.</p><ol><li>For all that CSS has been able to do it’s a technological failure. CSS just doesn’t work as expected. How can I say it’s a failure when millions of sites use it? CSS can be used to style basic text attributes but browsers aren’t consistent in how they use this technology. Even though there is a “standard” and some browsers partially adhere to the standard to truly be a useful standard you need two things: Predictability and Consistency. CSS has neither. Any designer who has tried to create a large and complex site using CSS will tell you that all popular browsers interpret the standard differently.</li><li>CSS is ‘markup centric’ not ‘design centric.’ I have this idea that designers should spend more time designing great looking sites and less time fiddling around with markup tags and browser compatibility. When I say ‘markup centric’ I mean that every CSS design tool forces users to go into source code mode to create an attractive modern site. Many designers take pride in hand coding CSS. Tools for designers should be design centric. PDF/postscript is a good example of a design centric markup , (unfortunately not very suitable for the web.) Designers don’t argue about how to create semantically correct postscript tags they just create great designs using great design tools. CSS sucks because it forces designers to think about how to make it work technically rather than how to make it work from a design perspective.</li><li>Why on earth do we think that cascading is a useful feature? The way that styles cascade from one level of layout to a deeper layout makes it difficult to figure out why a particular item is styled in a certain way. By contrast non-cascading style sheets would be equally powerful and more predictable. The cascading makes it harder to interpret the page for both the designer as well as the web-browser. In fact the complexities in cascading is one of the reasons why so many browsers screw up the standard. In theory cascading could save bandwidth but in practice it creates bloated documents to get around the cascading issues.</li><li>The box-model is too simplistic. The high level idea of CSS is that you can create attractive pages using margin, border, padding and content attributes. While this is a nice theory, it’s primitive in its understanding of both layout problems and design. Highly developed design tools have layout engines that offer multiple layouts, non-rectangular margins, proportional layouts, dock-able layouts, table layouts, column layouts, etc. etc. It’ll be years before these features make it to CSS and many more before browsers implement them with any consistency. If browsers keep spending so much time on CSS they’ll have a well polished turd. Tools like Aldus Page Maker had better design tools, font tools and layout capabilities 10 years ago. This is because good design tools start with the design, not the markup.</li><li>When writing software you learn what works and what doesn’t. You get new and better ideas and you throw away the old ones. This process of starting fresh is absent from the current CSS way of thinking. Each version of CSS builds on the previous one without acknowledging any fundamental flaws. CSS and its HTML sibling are the ultimate designs by committee. Any enhancements to CSS/HTML are piled on top of the old standards. This makes it progressively harder to create powerful, compatible and consistent browsers. This also makes it harder for designers to create sites that target the new platform because they are constantly trying to satisfy the compatibility with older browsers. Version compatibility has to be all or nothing. If you support V3 it has to be 100% supported and tested. Supporting some of the features actually makes things worse.</li><li>There shouldn’t be multiple right answers for a visual design. The way CSS works there can be many ways to do the same thing. In fact there seem to be endless debates about the proper way to hack together trivial things like rounded corners. Rounded Corners? I mean really! Again I refer you to Aldus and even MS Word circa 1997. These features are not that hard to develop but getting them to work in a “standard way” seems to be all but impossible.</li><li>CSS captures styles not semantics or design intention. A design intention would be something like: “I want to balance these two columns” or perhaps “This text should line up with the logo image in the first column.” When designers do things like this:<pre>  #content{position:relative;top:32px;left:20%;width:40%;}</pre><p>They are capturing the style specifics not the design intention. Why 32 pixels? Why 40%? Perhaps the logo is 32px tall? Perhaps the other column is 60% wide? When the logo changes size or placement how will you know what styles to touch? There is a basic concept called parametric design that can be used to specify the parameters of the design. This concept helps embody the design intention as a set of rules that can then be preserved as the design changes. Even a very simple parametric design allows you to preserve design intention rather then hard coding sizes and dimensions.</p></li><li>Design should be declarative not interpreted. Again CSS has to process a large number of rules before it can figure out where things are supposed to go. After these rules are interpreted this data is thrown out and each and every browser that opens up the web-page has to re-interpret the data. This is incredibly inefficient. First of it makes web-pages load very slowly. Even when you’re on a fast connection the browser can’t figure out where to place objects until the entire web-page has finished loading. Secondly this interpretation is very prone to errors. A declarative design isn’t open to as much interpretation allowing it both render quickly and consistently.</li><li>CSS is a pain to work with. Take a look at some of the designs over at CSSZenGarden. The designs are both attractive and sophisticated. A good designer could take these designs and mock up similar designs in PhotoShop or Illustrator in a matter of hours but take the same designs and ask for it in CSS and it may take a couple days. Each time you make an edit to your CSS you have to refresh your browser to see what it’s actually going to look like. Then after you get one browser working you need to double back and get the other browsers working.</li><li>If you can’t get consistency across browsers then you can’t rely on CSS to accurately and properly design your site. If you can’t get the site to look <span>exactly </span>the way you want on every single browser then how can you claim that CSS is a good design tool or even a success? The fact that there is no alternative to create attractive websites doesn’t make CSS a good tool. There are two ways to solve the problem. The first is to continue to hammer on standards and CSS asking for a better solution. This has been happening for the last 10 years and it just doesn’t work. The alternative is to realize that CSS is flawed in it’s intrinsic design and begin to ask the questions of how could you do it better?</li></ol><p>——–</p><p><strong>Archived comments from the original posting </strong></p><h4>39 Archived Comments:</h4></div></div></article></div></div>]]>
            </description>
            <link>https://gregraiz.com/css-still-sucks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239543</guid>
            <pubDate>Tue, 23 Feb 2021 16:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a secret European language ‘made a rabbit’ and survived]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239231">thread link</a>) | @pepys
<br/>
February 23, 2021 | https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>They started out as</strong> apprentices looking for masters, students looking for teachers, or soldiers looking for wars, but they ended up as travelling tinkers, peddlers, beggars and thieves, members of the itinerant underground of central Europe. Carrying forged papers and false names, they were feared by peasants, shunned by burghers and hunted by the police. Catholics and Protestants, Jews, Sinti and Roma â€“ they had little in common, neither bonds of religion nor ethnicity, except for the life into which they had drifted, the life of the road.</p>
<p>The underground of central Europe, from the Middle Ages to the modern era, is all but inaccessible to us today. Those wandering its roads left few traces of themselves, except for the secret signs they carved on trees to warn each other of aggressive policemen and rabid dogs, or to recommend kindhearted householders willing to provide bread and water. These markings faded but there remains a way to catch glimpses of this lost world: its language. Over the course of hundreds of years, the people of the road evolved a distinct way of talking that strengthened their resilience, fostered solidarity and helped them survive. As it was purely spoken, this language, too, almost disappeared â€“ had it not been for police forces across central Europe that decoded it like the cipher used by enemy powers. Collaborating across jurisdictions from the Middle Ages to the 20th century, the police recorded this language by arresting its speakers and forcing them to divulge their words and phrases. The police also named it: Rotwelsch.</p>
<p><em>Rot</em> was a word for beggar (in Rotwelsch), and <em>welsch</em> could mean Italian but mostly it meant foreign and incomprehensible. There was some truth in the name, because Rotwelsch speakers freely mixed German, Yiddish, Hebrew, Czech and Romani, the language of the Sinti and Roma (who used to be called Gypsies because they were falsely believed to have originated in Egypt) in ways that were incomprehensible to outsiders. To German or Yiddish speakers, it sounded as if Rotwelsch speakers had stolen words and twisted their meaning.</p>
<p>Rotwelsch was a name for the language used not by the speakers themselves but by those who regarded vagrants as untrustworthy foreigners. While the police continued to believe that vagrants obscured their words deliberately to make it <em>welsch</em> to outsiders, in reality these vagrantsâ€™ words were only as incomprehensible as any language is to those who donâ€™t speak it. The true purpose of Rotwelsch was not to keep things secret but to help these outcasts navigate their daily lives and to create community among them. A second name captured this reality, <em>kochemer loshn</em>, which, like many words in this language, came from Hebrew: <em>chokmah</em>, for wisdom; and <em>loshn</em>, for tongue or language. This name didnâ€™t denounce the language as a beggarâ€™s cant but celebrated it as a way of talking for those in the know, as the lingo of the wise guys.</p>
<p>For Rotwelsch (or <em>kochemer loshn</em>) speakers, who were in permanent flight from the law, there was little difference between trading and stealing, which is why they had a single word for both, as for traded and stolen goods: the Yiddish word <em>sore</em>, meaning trouble, problem, calamity. Words for food, sex, and lice â€“ an affliction of itinerants everywhere â€“ abounded in their language, as did words for police and for getting arrested.</p>
<p>The police realised that he had an unusual skill: he was a good scribe, thanks to years of forging papers</p>
<p>The worst that could happen was being sent to <em>school</em>, which meant going to prison, a phrase adapted from the German <em>Schule</em> (school), which had been transformed into the Yiddish word for synagogue. (Calling prison â€˜schoolâ€™ later became common in the American underground and was used, most recently, in Martin Scorseseâ€™s film <em>The Irishman</em>). The 19th-century policeman Friedrich AvÃ©-Lallemant, the first true scholar of Rotwelsch, would have much to say about this equation of school and prison. He studied Rotwelsch and its speakers, and drew a single lesson from the experience: the necessity for police reform.</p>
<p>To avoid being sent to school, Rotwelsch speakers had to cultivate the art of <em>making a rabbit</em>, by which they meant how best to make like a rabbit and dash off.</p>
<p>This witty and wise language, which mistrusted big words and official institutions, expressed with poetic precision what it was like to live in difficult circumstances, of <em>being in a pickle</em>. But why a pickle? Actually, the whole phrase was a misunderstanding, a false translation from Rotwelsch. The original Yiddish phrase (<em>Zores und Jokreszeit</em>) had nothing to do with pickles, only sounded like them (to German ears, like <em>Saure Gurkenzeit</em>, or â€˜pickled cucumber timeâ€™), so that German speakers mistakenly started talking of pickles when they were in trouble. Before long, the phrase entered English, which means that you, too, dear reader, have been speaking Rotwelsch without realising it.</p>
<p><strong>Ferdinand Baumhauer was one</strong> of the Rotwelsch speakers whose life is reconstructed in my recent <a href="https://wwnorton.com/books/9781324005919" rel="nofollow noreferrer noopener">book</a>. Born in 1818 into a family of cotton weavers, Baumhauer had apprenticed himself to a cobbler at 13, and a few years later begun the customary stint as a journeyman, hoping to learn from other masters of the trade. But Baumhauer quarrelled with another apprentice and left his position. Seeking cheap accommodation for the night, he chanced upon a shelter favoured by tramps, his first contact with the secret world of the road. Something about them appealed to him. Perhaps he was tired of having to serve masters who were often strict and abusive. He decided to quit his life as a journeyman and begin the more precarious one as a vagrant.</p>
<p>When Baumhauer was arrested many years later, the police realised that he had an unusual skill for a vagrant: he was a good scribe, thanks to years of forging papers. The police asked him to write down scenes from life in the underground. Baumhauer complied, filling a book with scenes of vagrancy written in his underground language. Baumhauer was the perfect informant, a vagrant with good penmanship. He even provided the decryption key â€“ the meanings of secret words â€“ on the right-hand side of each page and added helpful information at the bottom in the form of footnotes, aware of how little the police would know about the life he was describing.</p>
</div><div><figure data-align="center"><img src="https://d2e1bqvws99ptg.cloudfront.net/user_image_upload/1450/puchner-insert.jpg" alt="" title=""><figcaption>Baumhauerâ€™s book. <em>Image supplied by the author</em></figcaption></figure></div><div>
<p>He wrote of a family led by Walter and his wife, known as Walteress, making a narrow escape. A mounted policeman stops Walter to check their papers (undoubtedly forged) while Walteress has gone to beg in a nearby village for some <em>sore</em>. Walter convinces the policeman that nothing untoward is happening, but then the policeman hears dogs barking in the village and senses that something isnâ€™t right. Walter has already left by this time, and Walteress, thinking quickly on her feet, realises what a pickle sheâ€™s in, avoids the policeman and meets up with Walter away from the village. The policeman realises that the two have <em>made a rabbit</em> and pursues them. Fortunately, the Walter wagon races ahead and crosses the border to the next jurisdiction.</p>
<p>Baumhauer knew all about escape. Once heâ€™d finished writing his stories, the police relaxed their vigilance and he fled. The Baumhauer case is an unusual example of how this secret language survived via police archives. These records of Rotwelsch came from the intent to police its speakers, but they allowed me to reverse-engineer the lives of the speakers who expressed their view of the world through its distinct idiom.</p>
<p>Rotwelsch vagrants were among the first to be sent to concentration camps</p>
<p>Early researchers of Rotwelsch, such as AvÃ©-Lallemant, spoke of Rotwelsch as a â€˜professional languageâ€™, the technical jargon of thieves comparable with that of doctors, lawyers, hunters (and professors). Today, linguists speak of it as a <em>sociolect</em>, the speech of any distinct sub-group. A sociolect doesnâ€™t quite rise to the level of a full language because it doesnâ€™t have its own grammar; in the case of Rotwelsch, it borrowed its grammar from German. But precisely because Rotwelsch wasnâ€™t a regular language and instead consisted of words useful only to a specific group â€“ words for police, for getting into pickles, for getting arrested, for different kinds of prisons, and for making a quick escape â€“ it now works so well as a record of a particular way of life.</p>
<p><strong>My uncle, a bohemian</strong> writer who had become obsessed with Rotwelsch, introduced me to it when I was a child. Over the course of many years, he had tracked down its remaining speakers and assembled a large archive on the language. When he died, I inherited his archive, a unique resource for studying the now-lost world of this itinerant underground.</p>
<p>My study of Rotwelsch has also revealed secrets from my own family history. My grandfather, I learned, had been obsessed with Rotwelsch as well, although for different reasons. An early member of the Nazi Party, he had attacked Rotwelsch as an uncouth mixture of German and Yiddish that proved, to his mind, that all Jews were criminals. He wanted the language eliminated. Soon, he would almost get his wish, when Rotwelsch vagrants were among the first to be sent to concentration camps. After the war, he managed to avoid prosecution and bury his past. After learning of my grandfatherâ€™s role, I better understood why my uncle had devoted so much time to preserving and reviving Rotwelsch, and why he had taught the language to me: in a form of linguistic rebellion, perhaps even atonement, he decided to undo some of his fatherâ€™s work.</p>
<p>Throughout my research, I wondered what Rotwelsch sounded like. There would have been significant variations, depending on the different German dialects spoken in various regions of central Europe, from the Rhine to Prague, and from Hamburg to Zurich and Vienna, as well as dialects marked by Yiddish, Czech, Dutch and other regional languages. I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived">https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239231</guid>
            <pubDate>Tue, 23 Feb 2021 16:31:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rows launches a spreadsheet with data, integrations, and sharing]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239210">thread link</a>) | @helhady
<br/>
February 23, 2021 | https://blog.rows.com/p/rows-beta | <a href="https://web.archive.org/web/*/https://blog.rows.com/p/rows-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ol><li><p>Rows is coming out of our closed beta and launching in Public Beta<strong>. </strong></p></li><li><p>We have raised a $16 million Series B round, led by Lakestar. Our previous investors and other cool people joined us, too.</p></li></ol><p>Join us in this celebration! But first, what is Rows?</p><h3>Rows</h3><p>Rows is the only true Spreadsheet with Integrations and a slick Sharing experience.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e80e654c-cf95-48df-b894-309ded708b65_1200x316.png&quot;,&quot;height&quot;:316,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6454,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One billion people in the world use spreadsheets, but it’s hard to connect them to different data sources and to turn them into something you actually like to share. Rows  solves this by integrating the 3 things people like: spreadsheets, data, and slick UIs.</p><p>You’ve never seen a spreadsheet like that! Check <a href="https://rows.com/">rows.com</a> for more info!</p><h3>🚀 Public Beta</h3><p>We’re now officially in a Public Beta!</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:61461,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Going <em>Public</em> means that anyone can <a href="https://rows.com/auth/sign-up">create an account</a>. It also means that platform has been certified ready by our private beta users: we onboarded more than 10k users, and 100s of teams are active every week. Being a <em>Beta</em> also means that there’s just a handful of features left to ship until we baptize our spreadsheet as a v1 later this year. </p><p><em>Rows is free for smaller teams with up to 10 users. We rolled out paid subscriptions for larger companies, starting at $59 per month. Rows will always have a free plan.</em></p><p>We are <strong>very</strong> excited to learn about what you will build with Rows!</p><h3>What’s Next</h3><p>Rows’ vision is to empower the world’s one billion spreadsheet users to build the tools they need. </p><p>Today, businesses use Rows for critical processes in <a href="https://rows.com/solutions/sales">sales</a>, <a href="https://rows.com/solutions/marketing">marketing</a>, and <a href="https://rows.com/solutions/operations">operations</a>. We will continue to serve these use cases, and expand them with exciting new features. Throughout 2021, our team in Porto and Berlin have lined up (more than) a few serious releases:</p><ul><li><p>More classic spreadsheet functionality, like Charts and conditional formatting. </p></li><li><p>Upgraded Integrations, including easier and faster data management; and, of course, more functions and Integrations (we’re beyond 50 now).</p></li><li><p>New elements for Sharing, including a new button, drop-downs, and more.</p></li></ul><p>We are also working on a Desktop App 👩‍💻!</p><h3>Series B Funding</h3><p>Today we are also announcing our Series B round, led by <a href="https://www.lakestar.com/">Lakestar</a>! The round had the participation of our existing investors Accel and Cherry, as well as new entrants Armilar and Shilling from Portugal and Visionaries Club from Berlin. </p><p>Stephen Nundy, partner at Lakestar, is joining our board — and adding his tech and spreadsheet experience from his career at Goldman Sachs. Also joining our board is Christian Reber, CEO of <a href="https://pitch.com/">Pitch</a>. </p><p>We are very fortunate to continue evolving our company with such a strong board and advisors!<br>—</p><p>We are incredibly happy to be a part of the world of spreadsheets, and we’re excited to enter this new phase of our journey to empower spreadsheet users to build their own tools.</p><div><p>As always, we appreciate your support and love!</p><p>Let’s GO!<br>Humberto &amp; Torben<br>— Rows Founders</p></div></div></div>]]>
            </description>
            <link>https://blog.rows.com/p/rows-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239210</guid>
            <pubDate>Tue, 23 Feb 2021 16:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git is my buddy: Effective Git as a solo developer]]>
            </title>
            <description>
<![CDATA[
Score 389 | Comments 188 (<a href="https://news.ycombinator.com/item?id=26239068">thread link</a>) | @vortex_ape
<br/>
February 23, 2021 | https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/ | <a href="https://web.archive.org/web/*/https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p><small>February 23, 2021 • Reading time: 12 minutes</small></p>

<p>At this point, most developers use Git as a tool for collaboration. We have our
rote-learned commands to pull, commit, and push. And of course, there's <a href="https://xkcd.com/1597/">that
one coworker</a> who knows a bit more about Git than
everyone else, who helps get us back on track whenever our local repos end up in
a strange state.</p>
<p>But what if I told you that Git can be a valuable tool without ever setting up a
remote repository? I'm not just talking about having a working version of your
code base to roll back to if you mess something up, although there's that too.
Used correctly, Git can help to structure your work, identifying gaps in your
test coverage and minimizing dead code.</p>
<p>There are two subjects I'm going to avoid for the purposes of this blog post:
other developers, who are the most compelling but least interesting argument
for keeping your commit history clean, and <code>git bisect</code>, which does factor
heavily into my workflow but deserves its own blog post.</p>
<p>As with any ubiquitous developer tool, the Git user base has a lot of strong and
conflicting opinions about the one "correct" way to use it. My goal is simply to
introduce a workflow that I've been using and refining for much of my career;
take from it what you will. And, importantly, it's a workflow that has become a
vital part not just of my collaboration process, but of the way I write code.</p>
<p>Ultimately, these principles serve two purposes: they focus my work onto a
particular bugfix, feature, or goal, and they ensure that my Git history isn't
set in stone. With proper hygiene, commits can be dropped, rearranged, and split
off into other branches painlessly and without merge conflicts.</p>
<h2 id="principle-1-a-branch-must-do-one-useful-thing">Principle 1: A branch must do one useful thing</h2>
<p>When I'm managing my own projects, I have a lot of ideas that I want to see
happen. If I'm just throwing one commit after another into <code>main</code>, I'll get
halfway through implementing one feature and then jump off to hacking on
another. If any of the features get completed, it will be at the expense of a
wasteland of half-completed features that are now taking up space in my code
base.</p>
<p>In a brand-new project, sure, I'll throw a bunch of garbage commits into <code>main</code>.
My rule of thumb for when to stop this is when I can write my first effective
integration test. If there is <em>something</em> useful to test, there is now enough
substance to my project that I can have distinct tasks on the go. Trying to
break into branches too early just results in me throwing my garbage commits
into a branch instead of main.</p>
<p>In the early stages of a project, articulating the purpose of a branch can be as
simple as giving it a descriptive name. If a commit isn't moving the code base
in that direction, it can always get cherry-picked into a different branch.</p>
<p>As the project matures, I'll start using some sort of issue or bug tracking
software to flesh out what I'm trying to accomplish in more detail and
coordinate the branches for multiple related useful things.</p>
<p>I find that descriptive branch names also help to refocus my attention on what
I'm trying to accomplish. For instance, my command prompt currently looks like
this:</p>
<pre><span>10:02:19 </span><span>max</span> <span>~/Projects/mikkel.ca</span> <span>blog-post-git-as-a-solo-developer</span><span>|</span> <span>R</span><span>%</span></pre>
<h2 id="principle-2-every-commit-must-be-independent">Principle 2: Every commit must be independent</h2>
<p>So much for branches, let's zoom into a commit level. I've articulated what
concrete thing I want my branch to add, now how do I add it? Usually, there's
some poking around my code base involved in figuring that out. Sometimes I take
a wrong turn, sometimes I just get distracted. That's okay, it's part of the
process.</p>
<p>However, that doesn't mean that every commit I make right now is going to end up
getting merged in this branch. By keeping my commits independent from one
another, I ensure that I can rearrange or cherry-pick them into new branches
if I discover that they really don't have anything to do with what I'm working
on right now.</p>
<p>If my commits are not independent, I am essentially stuck with the exact history
as it was written. Trying to tease out a commit into a different branch or move
it to the beginning of my branch history will become fraught with merge
conflicts as later commits that modified code introduced in this commit fall
like dominoes.</p>
<p>Obviously, I'm still allowed to call code written in one commit from a later
commit. That's the reason I'm doing this particular work in this particular
branch, after all. But I never touch the same code multiple times. If I have to
go back and fix something, maybe add a validation check or field that I hadn't
thought of, I'll go back to the commit where it was created rather than amending
it in a later commit.</p>
<p>Obviously, this could go on forever, which is why the "one useful thing"
principle exists. Once I've settled on what I want the code to look like for the
purposes of this branch, I merge and then start a new commit in the next branch
for further changes to the same.</p>
<h3 id="principle-2a-every-commit-must-include-its-own-tests">Principle 2a: Every commit must include its own tests</h3>
<p>Here's where keeping commits small starts to pay dividends. If the code in each
commit is small enough for me to reason about, it's small enough for me to
visually ensure that its test coverage is good.</p>
<p>And of course, if I do end up rearranging this commit or splitting it off to a
different branch, I want its tests to come along with.</p>
<p>The exception to this is integration and functional/behavioural tests, which can
and should have their own commits. In that case, the tests are really tied to
the branch level rather than the commit level, since Principle 1 implies that
there should be exactly one new test to add as a result of this branch.</p>
<h2 id="principle-2b-every-commit-must-pass-all-tests">Principle 2b: Every commit must pass all tests</h2>
<p>Again, breaking something in a commit (even if I <em>really definitely</em> intend to
fix it in a later commit) locks me into the git history as written. And
introducing a breaking change with the intention of fixing things later always
carries the risk that I'll get distracted and end up merging the breaking
change.</p>
<p>If there's some prerequisite to get this change to pass tests - say, a
preexisting bug that snuck through a hole in my test coverage - that gets its
own commit.</p>
<p>Speaking of holes in test coverage, there's another (temporary) exception here.
I don't normally practice strict <a href="https://en.wikipedia.org/wiki/Test-driven_development">test-driven
development</a>, but if I do
fix a long-standing bug, I normally temporarily put its test in a separate
commit. I'll then rebase so that the test appears before the fix, ensure that
the test fails <em>without</em> the fix, then complete the rebase and validate that the
test now passes. Once the due diligence to validate my test is done, I can go
ahead and squash the bugfix with its test.</p>
<h2 id="principle-3-draft-commits-are-fine">Principle 3: Draft commits are fine</h2>
<p>If I know that I'll be coming back to a change later, I'm much more comfortable
setting it down and moving on to roughing in the next part of the process,
rather than finishing, polishing, and unit testing code that might need to
change before my branch gets merged.</p>
<p>In fact, I find that I waste much less time on writing tests for things that
I'll later change when I'm following this workflow to the letter than I do when
I get "lazy" and start dumping everything into big catch-all commits.</p>
<p>Some people favour TODO comments in their code, occasionally supported by
automated checks that prevent code containing "TODO" from merging. I prefer to
annotate my commit messages and leave my code clean. Normally, this looks
something like "add controller class - TODO test me". (I always put my TODOs on
the first line of the commit message, so that they show up even in short log
views.)</p>
<h2 id="principle-4-it-s-okay-to-discard-commits-completely">Principle 4: It's okay to discard commits completely</h2>
<p>Often I start a task by tidying up the surrounding code, in the same way I might
organize my desk before starting work. (I don't, but I <em>might</em>.) Sometimes that
cleanup turns out to be a valuable part of the groundwork for this change, but
sometimes it's just dead weight. Keeping my commits independent makes it easy to
discard or cherry-pick out code that turned out to be unnecessary, along with
any unit tests that went along with.</p>
<p>(I do still consider the tidying to be a valuable part of the process. It clears
my mind and refreshes my knowledge of the problem space with some simple rote
tasks before I dive into something more complex. And occasionally it results in
cleaner code.)</p>

<p>I'm not perfect.<sup>[citation needed]</sup> Obviously, it's not practical to
maintain this level of commit hygiene by making each change sequentially.
Instead, I jump around <em>constantly</em>. Doing so requires me to be comfortable in
navigating my commit history. (Conversely, it's also a good way to <em>become</em>
comfortable with navigating history.)</p>
<p>In that vein, here are some tools beyond your standard
<code>checkout</code>/<code>branch</code>/<code>pull</code>/<code>commit</code>/<code>push</code> workflow that come in handy.</p>
<ul>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --amend</code></a> – A quick and easy
way to update the most recent commit.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --fixup [hash]</code></a> – When
changing history, I used to find myself making a lot of commits with messages
like "merge me with xyz" if I need to revisit commits before the most recent
one. It turns out that <code>git commit</code> has flags to help with this: <code>--fixup</code> and
<code>--squash</code> will automatically suggest a fixup or squash with another commit
during rebase if the <code>--autosquash</code> flag is provided to that command. (To
enable this behaviour by default, run <code>git config --global rebase.autosquash true</code>. It won't behave any differently if there are no commit messages in the
history being edited that contain "squash!" or "fixup!".) A surprise bonus:
since the fixup operation inherits the message of the previous commit, you
won't be prompted to enter a new one.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-rebase"><code>git rebase --interactive main</code></a> – I can
also use <code>git rebase --interactive HEAD~5</code> to edit the last 5 commits, but I
find rebasing directly on <code>main</code> (or <code>master</code>, or whatever my upstream branch
is) kills two birds with one stone. It will show me all commits since I
branched off from <code>main</code>, and will simultaneously bring my branch up to date
with my latest local copy of main.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-stash"><code>git stash</code></a> – Sometimes I have unrelated</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</a></em></p>]]>
            </description>
            <link>https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239068</guid>
            <pubDate>Tue, 23 Feb 2021 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pairing makes better interviews than leetcode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238905">thread link</a>) | @miiila
<br/>
February 23, 2021 | https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/ | <a href="https://web.archive.org/web/*/https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>
            
    
        
            
    
    Sun Feb 21, 2021

        
        
            
                · 1227 words
            
        
        
            
            
                · 7 min
            
        
        
        </p><hr>
    
    <p>When I was explaining our interview process to my colleague, I realised that my approach is very different from what standard tech interviews are usually about. It is probably different from what interviews in general all about. But I am quite sure the usual way is broken and we need to work on a better framework. I am going to share my approach and hopefully, you can get some inspiration out of it.</p>
<h2 id="background">Background</h2>
<p>At <a href="https://snyk.io/">Snyk</a>, we have multiple rounds of interviews. It starts with a phone screening covering some general aspects, goes to the first round done by the hiring manager followed by a home task assignment. After a candidate sends us a home task, we review it and schedule the next round - pairing. If everything goes well, there is one more round with a hiring manager again covering more cultural aspects and work details in greater depth. I am usually involved in home task review and pairing sessions and I am going to focus on the second one here. Because I feel there is an improvement in the whole hiring process we can do.</p>
<h2 id="home-task-and-pairing">Home task and pairing</h2>
<p>Are a home task and the following pairing enough to assess candidate technical skills? Well, it goes to a fundamental question: “What do you want to know?” The biggest problem in interviewing is labelling candidates good or bad. If your framework can be described as “Is the candidate good enough to work here?”, you are limiting yourself and I would say you are limiting your potential growth and company culture as well. A better angle is: “Can we benefit from a candidate's current experience and focus?” Because there is no such thing as a failed interview. It is more about whether a company can see the use of a candidate's skills in the current time. And whether the candidate can see the potential for whatever they are interested in (learning, growth, responsibility, money, status). So what am I trying to address during my part of the interview? My question to ask is: “Would I like to sit next to this person for 4 hours and solve a problem together?”</p>
<h2 id="but-you-have-to-verify-their-skills">But you have to verify their skills</h2>
<p>You may be still wondering whether this can cover all the technical skills like algorithms knowledge, database modelling, testing… Well, it cannot. And I am 100% sure it’s not a problem. Because by asking coding puzzles questions (aka leetcoding), you are not addressing problem-solving capabilities. At best, you are addressing “solving coding puzzles” skills and how good they are in remembering chapters from the “How to crack a coding interview” book. The same goes for all other tech stuff - unless you are writing quick sort every day, don’t ask them to write it. Think about what you do in your day-to-day life. What are the challenges? How can you solve them on an acceptable, mediocre and exceptional level? And how do you want to feel when you are solving them with your colleagues?</p>
<h2 id="my-approach">My approach</h2>
<p>I have three main goals I have in mind while talking to a candidate:
Be respectful
Have fun
Learn something new
The main message here is to be on the same level as a candidate. I am not superior just because I am interviewing them. I bet we all have some terrible experiences from our past interviews where we felt pretty bad and useless. I don’t want to do this to anybody else. Therefore, I am not testing their knowledge. I am not asking them questions expecting one right answer. I am asking about their ideas and opinions. Nicely said, right? But how can you achieve that? One example from a recent interview. A candidate mentioned some changes they could do in their code and said they would need to make sure the performance is not impacted. I could ask questions like “What do you know about performance measuring?” or “What tools are we using to measure performance?”. But I said: “How would you measure whether it has a performance impact?”. By this, I allowed them to express both their opinions and experience. I can share some of mine as well asking them for feedback.</p>
<p>This setup greatly helps with the last learning part as well. I am not expecting any right answers, so we are rather talking and sharing our opinions. I can also learn a lot from theirs and I’m allowed to pass my experience to the candidate easily. It makes me happy when they mention they have learned something new during the discussion. </p>
<h2 id="evaluation">Evaluation</h2>
<p>This all sounds very nice, but all in all, it is still an interview and I should be able to articulate an answer and reasoning, whether I am for having this candidate in a team or not.</p>
<p>There are two main questions I am trying to answer are:
Are they able to understand and solve the problem using a programming language and other tools?
Do I enjoy working with them?</p>
<p>The first one is kind of straightforward. During pairing, you can usually very quickly spot if they need to check documentation every single time for writing even simple language constructs. If they can catch errors and extract functionality to better encapsulate units. And I pay special attention to debugging. I don’t need them to have a full-blown debugger, I just expect them to navigate their code effectively and have a good way of identifying where the problem can be.</p>
<p>Whether I am enjoying our discussion is more tricky. The most important part is not to be pulled into any kind of bias. I am keeping in mind I am representing a company culture and I need to understand if they would fit in. So I am trying to uncover how easy or hard it is for them to accept a different opinion or a suggestion. How can they clarify and support theirs? How verbose are they when thinking about the problem? As a company, we have a very open and sharing engineering structure. A quiet person, who needs to think for an hour by himself would be probably struggling heavily. The same goes for folks who need to solve everything on their own, without using libraries or asking for help or clarification. So this part is not about whether I would go for a beer with the candidate (although, if they join, it is likely to happen too). It is more about their fit for our standard way of working.</p>
<h2 id="let-s-improve-our-tech-interviews">Let's improve our tech interviews</h2>
<p>I am heavily convinced a lot of people are passing bad interview experience to others. Because “I had to deal with that, so they have to do it too” approach. Or because they simply don’t know how to do it differently. I am guilty of doing this too. But I have decided to stop. I am stepping down from a superior interviewer position and model the discussion as we would be colleagues already. Since I don't want to make my colleagues feel uncomfortable, there is no reason I should treat candidates differently. Because they can turn into colleagues easily.</p>
<p><em>Thanks for reading. Do you have any questions or errors to point out? Or just wanna chat? Let me know on <a href="https://twitter.com/MilaVot/status/1364246323277557760">Twitter</a>. Or add a comment on <a href="https://news.ycombinator.com/item?id=26238905">Hacker News</a>.</em></p>


        </div></div>]]>
            </description>
            <link>https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238905</guid>
            <pubDate>Tue, 23 Feb 2021 16:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release (YC W20) – 5 Ways Ephemeral Environments Improve Developer Velocity]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238650">thread link</a>) | @tommy_mcclung
<br/>
February 23, 2021 | https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Velocity is a measurement of how many story points a software development team can finish within a sprint (usually one or two weeks). These points are set by the software development team when they review a ticket and estimate how complex the ticket is. When a team measures this output over a period of time, generally they have a consistent amount of story points they can deliver in a sprint and their velocity is known.</p><p>Improving developer velocity is directly correlated with performance. <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance" title="Link to mckinsey developer velocity study" target="_blank" rel="noreferrer">McKinsey published an article in April 2020</a>, where they cite that companies in the top 25% on their Developer Velocity Index grow up to twice as fast as companies in their same industries. Intuitively this makes sense since delivering more allows the development team to learn through iterating and improving. </p><p>One might argue that velocity alone doesn’t make for great software, but assuming a development team is aware that quality is important, one can see how velocity usually helps. The ability to deliver quickly also allows a development team to address quality issues quickly. It’s easy to argue that development teams with high velocity have the ability to deliver better quality software because they can address issues quickly.</p><p>In the same study, McKinsey highlighted several factors that allow a software development team to move quickly. Specifically they highlight that Technology Tools are an incredibly important dimension to velocity and business outcomes. And the most important tools are: Planning, Collaboration, Development and DevOps tools. </p><p>In this post I’m going to discuss the <strong>top 5 ways Ephemeral Environments can improve developer velocity</strong> by touching on how they are a <em>Collaboration</em>, <em>Development</em> and <em>DevOps</em> tool. As we’ve spoken about in our article <a href="https://releaseapp.io/ephemeral-environments" title="What is an Ephemeral Environment" target="_blank" rel="noreferrer">“What is an Ephemeral Environment?”</a>, ephemeral environments are spun up on demand and contain the code and data that approximates production closely. These environments are used by development teams in the software development process to test, debug and ensure features are built correctly before code is pushed to production.</p><h2 id="here-are-the-top-5-ways-ephemeral-environments-can-be-used-to-improve-developer-velocity">Here are the top 5 ways ephemeral environments can be used to improve developer velocity</h2><h3 id="1-ephemeral-environments-are-a-devops-tool-designed-to-remove-the-staging-or-qa-environment-bottleneck"><strong>1. Ephemeral environments are a DevOps tool designed to remove the staging or QA environment bottleneck</strong></h3><p>Traditional pre-production ecosystems usually have a limited amount of environments for developers. The staging or QA environment is generally used as a step before production where all code is merged and tested. Most organizations have one or very few of these environments, so as the organization grows these environments become a bottleneck in the process as all code must be tested here before production. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/57RYmuBRfBBWCRUWglqBnZ/14bafeeb0a47fd566938d2ff052a01c6/Screen_Shot_2021-02-22_at_2.43.18_PM.png" alt="Example of ephemeral environments for each branch"></p><p>With ephemeral environments, the traditional idea of “staging” is gone. Every feature branch is contained in its own isolated environment and becomes its own integration environment. There is no longer a need to have a single testing and integration environment where all code must merge before going to production. With ephemeral environments you have a limitless supply of environments for any purpose.</p><h3 id="2-ephemeral-environments-are-a-collaboration-tool-designed-to-allow-for-early-and-often-feedback"><strong>2. Ephemeral environments are a collaboration tool designed to allow for “early and often” feedback</strong></h3><p>Feedback is the lifeblood of great products. If you’ve ever read <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/" title="High Output Management Book" target="_blank" rel="noreferrer">Andy Grove’s book on high output management</a>, you know he does an amazing job of discussing how rework is so costly. If you haven’t read this book, I highly recommend it, even if all you read are the first few chapters where he discusses trying to cook a high quality egg repeatedly, in under three minutes. In summary, Andy suggested through this analogy that finding issues/defects early in the egg cooking process is the most important part of consistently cooking a high quality egg in under three minutes.</p><p>Likewise in software development, getting feedback and finding quality issues early in the development cycle reduces costly rework and improves velocity. If a product is delivered to a customer that doesn’t work or has bugs, it has to be reworked and go through the entire process again. Or if a product manager or designer doesn’t have a way to see changes until an engineer is finished with development, there is a high likelihood they will spot something wrong and rework the solution. These are all examples of rotten eggs in the process that hamper developer velocity. </p><p>With ephemeral environments, rework can be minimized because stakeholders become a part of the development process. When an ephemeral environment is created, URLs to the environment are created so stakeholders can see progress while code is being developed. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2dFjnsY2lBSSbkaOfqczSG/3b9ef1f1134d5cf21f464af8dbf8fa93/Screen_Shot_2021-02-22_at_2.40.44_PM.png" alt="Links in the PR"></p><p>At <a href="https://releaseapp.io/" title="Link to Release Home Page" target="_blank" rel="noreferrer">Release</a>, we highly recommend to our customers that they create a PR as soon as a developer starts working on a feature so a Release Ephemeral Environment is automatically created. When the developer pushes code to their source control system, the environment is updated making it a live reflection of the feature during development. Product managers, designers and QA are automatically notified when changes are live and they can preview those changes and give feedback immediately. </p><p>At Release, we will also share our own ephemeral environments with our customers as we’re building a feature so we can get feedback directly from the people we’re making the software for before we release it to production.</p><h3 id="3-ephemeral-environments-can-limit-rework-and-thus-increase-developer-velocity"><strong>3. Ephemeral environments can limit rework and thus increase developer velocity.</strong></h3><p>Ephemeral environments are a developer tool that allows for full integration and smoke testing on isolated features</p><p>Traditional continuous integration (CI) is the idea that your developer process should constantly be testing as a developer pushes code. What this leaves out many times is that most CI systems only perform unit tests continuously. Unit tests are meant to test small units of code and not the entire system as a whole. Integration and Smoke tests are where full paths of user experience can be tested. Usually Integration and Smoke tests are left to be tested only when the code makes its way via a merge to the mainline code branch and a traditional staging environment.</p><p>Again, if we refer back to Andy Grove’s three minute egg analogy, this step of running Integration and Smoke tests only when the code branch is merged to the mainline is extremely late in the process. If issues are found during Integration and/or Smoke tests, the developer has to start the development cycle again from the beginning after finding this issue too late in the process.</p><p>To add to the issue, if a team only has a single staging environment, the bottleneck around this staging environment is exacerbated with developers waiting for Integration and Smoke tests to be run on this single environment. On top of this, many code changes/features/branches may have been a part of the mainline merge making finding the cause of failed Integration/Smoke tests difficult and time consuming.</p><p>With ephemeral environments, Integration and Smoke tests can be run when the ephemeral environment is created for a feature branch. This ensures that Integration and Smoke tests are run as frequently as unit tests so developers can find issues early in the process. Additionally, Integration and Smoke tests run against a single feature change/branch will isolate changes against the mainline and make finding the root cause much easier.</p><h3 id="4-ephemeral-environments-are-a-devops-tool-that-allow-for-experimentation-with-infrastructure"><strong>4. Ephemeral environments are a DevOps tool that allow for experimentation with infrastructure</strong></h3><p>Making changes to infrastructure is hard and when a developer introduces the need for an infrastructure change it’s costly in time across the board. In a traditional environment setup (without ephemeral environments) this will result in an overall slow down in developer velocity as the shared staging environments must be updated by the DevOps team so the developer has some place to test their changes and new infrastructure.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/4clfoJM7gvr7ufFW8yqmax/e9731087d982502e619cba93d9cbafc6/Screen_Shot_2021-02-22_at_2.44.56_PM.png" alt="Experiment with environment configuration"></p><p>With ephemeral environments, this testing can be done in isolation and does not impact any other developer. For instance, with Release Ephemeral Environments, a developer can add services, environment variables, new infrastructure dependencies, new datasets/databases on their own through use of environment templates (environments as code) to experiment and develop without interfering with any other developers work or environments. This results in higher developer velocity again through minimization of rework and bottlenecks on shared resources.</p><h3 id="5-ephemeral-environments-are-a-collaboration-tool-designed-to-be-an-agilescrum-catalyst"><strong>5. Ephemeral environments are a collaboration tool designed to be an agile/scrum catalyst</strong></h3><p>Many organizations have made the move to Agile/Scrum but their infrastructure and technology haven’t adapted to support a more iterative approach to building software. The entire premise of Agile/Scrum is for teams to be empowered and driven by early and often feedback. If your organization is on Agile/Scrum and you’re still using a single or few staging environments, you’re technologically hampering your process improvements. Ephemeral environments are the homes and office buildings where agile teams live, work, build, and play.</p><p>Ephemeral environments are a catalyst to the Agile/Scrum methodology. When a developer does a pull request the ephemeral environment is created and collaboration on the feature can begin. The team is free to iterate, share,  nand solicit feedback all while keeping the rest of the organization freely moving with their own ephemeral environments. Stakeholders are a part of the development process and true customer driven development, which is the heart of the Agile/Scrum methodology, can occur.</p><h2 id="conclusion">Conclusion</h2><p>Ephemeral environments turbo charge development velocity by eliminating bottlenecks in the process (DevOps Tool), including stakeholders in the process (Collaboration Tool) and improving product quality (Developer Tool). All of these factors were highlighted in the McKinsey report on developer velocity as critical and ephemeral environments are <em>an investment that will put your organization in the top 25%</em>.</p><p>Photo by <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Maico Amorim photo credit" target="_blank" rel="noreferrer">Maico Amorim</a> on <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Unsplash link to photo" target="_blank" rel="noreferrer">Unsplash</a>.</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238650</guid>
            <pubDate>Tue, 23 Feb 2021 15:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A personal raspberrypi powered eInk dashboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238540">thread link</a>) | @jlengrand
<br/>
February 23, 2021 | https://lengrand.fr/complete-setup-epaper | <a href="https://web.archive.org/web/*/https://lengrand.fr/complete-setup-epaper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><strong>In the few coming minutes, you will read about epaper screens, raspberry pi, node, web components, tailwindcss, open-wc, netlify and more :).</strong></p><p>This article is quite long so for once I'll create a few pointers with TL;DR every time :)</p><ul><li><a href="https://lengrand.fr/complete-setup-epaper/#the-hardware-"><strong>The hardware</strong></a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-screen">-&gt; the screen</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-computer-">-&gt; the computer</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-os">-&gt; the OS</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-software"><strong>The software</strong></a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-backend">-&gt; the 'backend'</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-frontend">-&gt; the frontend</a></li><li><strong><a href="https://lengrand.fr/complete-setup-epaper/#additional-thoughts-and-remarks-">Some remarks</a></strong></li></ul><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>It's the second time I create a dashboard for my house. We are working hard on reducing our carbon emissions. Tracking energy usage as well as making food plans is a very good way to do just that. </p><p>This time, <strong>I wanted my dashboard to be built with an e-paper screen, to avoid the ugly backlight of a tablet, and reduce energy consumption</strong>. Here is the final product : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-21.png"><figcaption>The complete e-paper dasbboard setup</figcaption></figure><!--kg-card-end: image--><p><strong>In this post, I'll tell you all about how it's built, and how you can do it too. I won't describe everything, but point you to relevant documentations I followed. I'll also share tips and tricks.</strong></p><h2 id="the-hardware-">The hardware! </h2><p><strong>TL;DR: Get a Waveshare screen, a Raspberry Pi and follow <a href="https://www.waveshare.com/7.5inch-e-paper-hat.htm">instructions</a>.</strong></p><p>As any good physical product, everything starts with the hardware :). If you want to build the same dashboard, you'll need:</p><ul><li><a href="https://www.waveshare.com/7.5inch-e-paper.htm">A waveshare 7.5 inch screen (with UAT)</a></li><li><a href="https://www.raspberrypi.org/products/raspberry-pi-zero/">A raspberry Pi zero</a></li><li><a href="https://www.amazon.com/TUOFENG-Wire-Solid-different-colored-spools/dp/B07TX6BX47/ref=sr_1_34?dchild=1&amp;keywords=Soldering+Wire&amp;qid=1614031046&amp;sr=8-34">A bunch of soldering cables</a></li><li><a href="https://www.amazon.de/Lego-10698-Classic-Gro%C3%9Fe-Bausteine-Box/dp/B00PY3EYQO/ref=sxin_9_ac_d_rm?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;ac_md=2-2-bGVnbyBzdGVpbmU%3D-ac_d_rm&amp;cv_ct_cx=lego&amp;dchild=1&amp;keywords=lego&amp;pd_rd_i=B00PY3EYQO&amp;pd_rd_r=5eae0c54-ccbb-4a6f-9244-769b32337e2a&amp;pd_rd_w=XXCMe&amp;pd_rd_wg=iso2P&amp;pf_rd_p=54ea5632-6b46-46db-836f-bc13df6ca6a4&amp;pf_rd_r=G3WK7JTERFGJYNVQRKGG&amp;psc=1&amp;qid=1614031248&amp;sr=1-3-fe323411-17bb-433b-b2f8-c44f2e1370d4">Some lego :)</a></li></ul><p>Total is about 70€, everything included.</p><h3 id="the-screen">The screen</h3><p>I am using this <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">7.5 inch 2 colors screen from Waveshare</a>. My initial plan was to go for a <a href="https://www.waveshare.com/wiki/9.7inch_e-Paper_HAT">9.7inch with gray levels</a>, but I had no experience at all with that hardware so I went for the safer, 50$, solution.</p><p>The first good news is that the screen is CRAZY thin, here is a photo to give you an idea : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-25.png"><figcaption>A photo of the e-ink screen from the side</figcaption></figure><!--kg-card-end: image--><p>When buying an e-paper screen, here are the things you want to look for : </p><ul><li><strong>Refresh time</strong>. One of the cons of having an e-ink screen is that refreshes usually take a while. If you want performance, also look whether partial refreshes are available. Here is a video of mine so you get an idea:</li></ul><!--kg-card-begin: embed--><figure><blockquote><p lang="en" dir="ltr">It updates every 5 minutes and that's what a refresh looks like in case you wonder : <a href="https://t.co/PjW4CS4rXp">pic.twitter.com/PjW4CS4rXp</a></p>— Julien Lengrand-Lambert (@jlengrand) <a href="https://twitter.com/jlengrand/status/1362321332516585480?ref_src=twsrc%5Etfw">February 18, 2021</a></blockquote>

</figure><!--kg-card-end: embed--><ul><li><strong>Resolution</strong>. e-ink screen of higher resolution are still quite expensive (compared to a tablet). Depending on what you want to do with the screen, you might end up with artifacts. A nice font will help you there, but it won't do miracles either. For example, this is what my dashboard looked like before I put my text in bold. You can clearly see the artifacts : </li></ul><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-22.png"><figcaption>A photo of the screen with text missing due to resolution</figcaption></figure><!--kg-card-end: image--><ul><li><strong>Gray levels</strong>. My screen is two colors ( essentially, ink or no ink). Some other screen have 255 gray levels. Some others even have color. You may	 want to choose one of those but remember that it will cost you in refresh time or price. </li><li><strong>Driver board</strong>. We'll talk more about this soon but be aware that not all screen come with connectors and a driver board. If you don't know what I am talking about, be careful buying a HAT version, otherwise you won't be able to use the screen : </li></ul><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-23.png"><figcaption>A photo of the screen with driver board</figcaption></figure><!--kg-card-end: image--><h3 id="the-computer-">The 'computer'</h3><p>This post will be using a Raspberry Pi. Note that the Waveshare screens have a pretty extensive <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">documentation</a> so you can also go for Arduino or even the Jatson nano if you fancy it.</p><p>Just to be clear, I am using a Raspberry Pi Zero in my build, so you don't need crazy amounts of power to run it. </p><p><strong>If you're afraid of soldering, I recommend you use the B version of the Raspberry</strong> because the driver board from Waveshare can directly clip on the GPIO : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-24.png"><figcaption>Driver Board connected to a Raspberry Pi model B</figcaption></figure><!--kg-card-end: image--><p>As I mentioned, I decided to go for a Raspberry Pi Zero for two reasons : </p><ul><li>The form factor is much smaller, which allows for a super small setup together with the screen</li><li>The Zero goes for 5$, which is close to nothing! </li></ul><p>In case you go for the 0 like me, you'll have to solder a few cables. Don't be afraid though, everything is <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">described here</a>. All you need is the table below together with the Raspberry GPIO. </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-26.png"><figcaption>GPIO correspondances of the R Pi Zero</figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-27.png"><figcaption>Where to solder each pin</figcaption></figure><!--kg-card-end: image--><p>Once you've done that, you're pretty much good to go! Find a 5V adapter and power up your Raspberry Pi! The nice thing is that your screen will feed off the Raspberry so you need only one alimentation. We're ready to move to phase 2!</p><h3 id="the-os">The OS</h3><p>I've decided to keep this in the hardware part, because I don't have much to say. What we will want to do on our Raspberry Pi is install a default OS that is not too old. <a href="https://www.raspberrypi.org/software/operating-systems/">You can create and flash one here</a> by following the instructions.</p><p>The next thing you want to do is follow all the instructions described <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">in the default Waveshare setup</a>. Again, they are very well done so I don't have much to add but if you have any issue feel free to drop me a message.</p><p>In case you need to setup WiFi for your Raspberry Pi, <a href="https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md">here is the guide I used</a>!</p><p>You will enable SPI, install the necessaries libraries and download the library and test code from Waveshare. I tested with Python.</p><p>In case you have the same screen as I do, you will want to run the <code>epd_7in5_V2_test.py</code> script located in <code>waveshare/e-Paper/RaspberryPi_JetsonNano/python/examples/</code>! If all goes according to plan and you've soldered everything correctly, your screen will wake up!</p><h2 id="the-software">The software</h2><p><strong>TL;DR: Use <a href="https://github.com/samsonmking/epaper.js">epaper.js</a> on the Pi, created a service around it and serve static content in the static folder :).</strong></p><p>Our screen is awake, and we have a linux to work with! Time to start creating our dashboard! </p><p>I have made use of the amazing <a href="https://github.com/samsonmking/epaper.js">epaper.js</a> project to create my dashboard. The project is insanely useful. In short, it runs a static website locally and projects it on the screen using puppeteer. </p><p>This has a huge advantage : you only have to create a website and then deploy it on the device! <strong>You can find the complete code for the front and back end of the project <a href="https://github.com/jlengrand/epaper-dashboard-blog">here on Github</a>. And the website is available <a href="https://epaper-dashboard-blog.netlify.app/">at any time on Netlify</a>.</strong></p><p>The project is composed of two parts, which live in the same repository. </p><ul><li>The root repository that contains the code that will run on the Raspberry Pi, 'the backend'</li><li>The <code>epaper-ui</code>folder, which will contain our actual dashboard, the 'frontend'.</li></ul><p>Let's dive into each of the parts, but first, a word of warning: </p><p>Epaper.js &nbsp;can only be run on the raspberry. Indeed, it depends on native libraries (the GPIO drivers) that do not exist on your computer :). Not a problem, just something to be aware of (For example, don't set a CI on your project on Github).</p><p>Conversely, the latest version of Node that I could run on my raspberry is version 10.x, which means that I could not run the frontend code on it. Again, not a problem; just something to be aware of. </p><p>What that means is simply that I have been developing the frontend on my computer, and the backend only on the pi.</p><p>Now that it's clear, let's go!</p><h3 id="the-frontend">The frontend</h3><p>This part is the easiest to talk about. Keep in mind that for your own project, you can use any technology that suits you. The only requirement you have is that the result of your build lands in the <code>static</code> folder of the repository to be picked up by the backend. </p><p>Here is the current deployed frontend :</p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-31.png"><figcaption>Latest version of the frontend, in the web form</figcaption></figure><!--kg-card-end: image--><p>I decided to use Web Components, and my website is based on top of <a href="https://lit-element.polymer-project.org/guide/properties">LitElement</a> and <a href="https://tailwindcss.com/">TailwindCSS</a>. I used the excellent <a href="https://open-wc.org/">open-wc</a> library to generate my project skeleton in Typescript. Those are personal choices, you may well choose anything you like. </p><p>I picked these because by using Web Components I had very little to learn on top of the basic capabilities of HTML. Thanks to tailwind I also didn't have to learn much CSS :). My knowledge is limited in the front-end, having a simple syntax, a boring technological choice and no build-chain seemed like a perfect deal. No need to screw around with Webpack &lt;3!</p><p>Another good thing is that because I am basically only building a website, I could use <a href="https://www.netlify.com/">Netlify</a> as a platform to see the results of my work. And gosh I love their product!</p><p>Some things to note : </p><ul><li><a href="https://lengrand.fr/a-simple-setup-to-use-litelement-with-tailwindcss-for-small-projects/">I wrote a short article on how to easily use tailwind together with LitElement</a></li><li>Since it is a personal dashboard, I needed personal data. I leave it up to you to decide where to fetch your data from. The easiest for us to sync up with the girlfriend is Google Spreadsheets :).<a href="https://lengrand.fr/fetching-google-calendar-data-without-oauth-the-hacky-way/"> I wrote a whole blog post</a> about how to do that to sync calendars and avoid having to use Oauth2. In short, you can publish your spreadsheets online as CSV files. I do that and then ingest the data to create my dashboard. The great thing is that the CSV files are always up to date! </li></ul><p>I created my whole dashboard by using <code>$ npm start</code> in the <code>epaper-ui</code> folder, running <code>$npm build</code> every time I was happy with the result. That pushed the built version in the <code>static</code> folder of my project and sent it over to Github. By pulling the repository on my raspberry, I can make sure to always have the latest version of the dashboard.</p><p>Again, you can <a href="https://github.com/jlengrand/epaper-dashboard-blog/tree/main/epaper-ui">check the source code</a> here, and the <a href="https://epaper-dashboard-blog.netlify.app/">resulting dashboard over here</a>. </p><p>One last thing I want to mention before moving on is the way I refresh my dashboard :). The epaper.js examples <a href="https://github.com/samsonmking/epaper.js/tree/master/examples/weather-station">has an example with data that updates</a>. <strong>However</strong>, that data updates from the backend to the frontend. In my application, all the data is pulled from the internet via the frontend, which means that I cannot use the same mechanism. </p><p>To solve this problem, I make use of a very old capability of HTML itself to tell the page to refresh itself after very few minutes : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-30.png"><figcaption>Tells the page to refresh every 60 seconds.</figcaption></figure><!--kg-card-end: image--><p>Depending on how you build your own dashboard, you may not be concerned by this.</p><h3 id="the-backend">The backend</h3><p>Naming that part 'the backend' makes it seem like I've done a whole lot of work but I've really only been piggybacking on the great work done by <a href="https://github.com/samsonmking/epaper.js">epaper.js</a>.</p><p>Let me show you the integral content of my 'backend' code :</p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-28.png"><figcaption>Two lines of code, only calling the epaper.js init</figcaption></figure><!--kg-card-end: image--><p>Yep, the only thing I did was call the epaper.js library and pick the device I am using. (Be careful, in case you use another model of Waveshare display you will have to change that value).</p><p>That is enough for the content of the static folder to be successfully displayed …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lengrand.fr/complete-setup-epaper">https://lengrand.fr/complete-setup-epaper</a></em></p>]]>
            </description>
            <link>https://lengrand.fr/complete-setup-epaper</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238540</guid>
            <pubDate>Tue, 23 Feb 2021 15:42:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Developers Procrastinate (and How to Stop)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238435">thread link</a>) | @KaiserSanchez
<br/>
February 23, 2021 | https://www.7pace.com/blog/why-developers-procrastinate | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/why-developers-procrastinate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>What should you be doing instead of <a href="https://www.7pace.com/blog"><u>reading this article</u></a>?</p>



<p>Yeah, we know. You’re probably putting off some kind of work right now.</p>



<p>Procrastination is an age-old struggle — and not just for developers. But people who do knowledge work are especially prone to it, because of how mental blocks can severely impact their work.</p>



<p>So what causes those <a href="https://www.7pace.com/blog/high-performance-teams"><u>mental blocks</u></a>? Why do we all procrastinate so much? And more importantly, how can we stop procrastinating and just get our work done?</p>



<p>Don’t worry — you still have a few minutes of reading ahead of you before you have to go back to whatever task you’re avoiding. Read on and learn all about what causes procrastination, how to finally beat it, and how developers can use time tracking to up their efficiency even more.</p>



<h2>Why Do Developers Procrastinate?</h2>



<p>Developers aren’t more likely to procrastinate than other people. And when we look at the root causes of procrastination for developers, they’re the same reasons as anyone else.</p>



<p>Contrary to what many believe, procrastination isn’t necessarily the result of a lack of self-discipline. There are a <em>ton</em>&nbsp;of reasons developers (or anyone else) might procrastinate. Let’s look at a few common ones below.<em></em></p>



<h3>Perfectionism</h3>



<p>In knowledge work in particular, many people strive to be perfect. That goes for developers, too — they often strive to write the “perfect” code.</p>



<p>In reality, code that does what it’s supposed to do without bugs is plenty good enough. Striving for perfection has a tendency to make developers put off their work, since they’re trying to achieve an impossible goal.</p>



<h3>Fear of Success</h3>



<p>It may seem counter-intuitive, but fear of success has held back many a knowledge worker. With success comes higher expectations and greater responsibility, and not everyone responds well to that kind of pressure. In this case, procrastination can be a self-sabotaging tool.</p>



<h3>Lack of Planning</h3>



<p>Have you ever shown up to work, sat down at your desk, booted up your computer, and then sat there for a while trying to figure out what to work on? That lack of planning can be a major procrastination driver.</p>



<h3>Not Enough Work</h3>



<p>This is another counter-intuitive sounding reason for procrastination, but it’s real! Some developers procrastinate because they don’t have enough work to do.</p>



<p>When your workdays aren’t filled, it’s easy to get in the habit of coasting — hanging out at your desk surfing social media or reading online articles like this one. And once you’re in the habit, it’s hard to break it even when there <em>is</em>&nbsp;work to do. Hence, procrastination.</p>



<h3>Outdated Technologies</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg" alt="Outdated Technologies" srcset="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Software development is a field that requires its workers to stay pretty close to the cutting edge of new technologies. So trying to work with old ones that are outdated, obsolete, or deprecated can be a real challenge for devs, leading them to put off work.</p>



<h3>Organizational Roadblocks</h3>



<p>As much as developers like to put their heads down and get their work done <a href="https://www.7pace.com/blog/best-places-to-work"><u>without red tape or administrative hurdles</u></a>&nbsp;getting in their way, that’s not how it works at <em>every</em>&nbsp;organization. If the company you work for places organizational roadblocks in your path, that may very well be a contributor to your procrastination habit.</p>



<h3>Unnecessary or “Busy” Work</h3>



<p>Feeling a sense of purpose and accomplishment is important for any worker, which is why it’s common for developers to procrastinate on work that doesn’t seem like it’s contributing to the greater good, like implementation of unnecessary features. The same goes for <a href="https://www.7pace.com/blog/time-tracking-optional-for-development-teams"><u>tedious or administrative tasks</u></a>&nbsp;—&nbsp;those are easy to put off as well.</p>



<h3>Work You Just Don’t Want to Do</h3>



<p>And finally, there’s work you just don’t want to do. Maybe it’s outside of your wheelhouse. Maybe it feels unnecessary. Maybe it’s too hard, or you’re stuck at a particular blocker. But for all workers, including developers, just not wanting to do a certain task, project, or type of work can easily lead to procrastination.</p>



<h2>How to Stop Procrastinating and Get Work Done</h2>



<p>Identifying the cause of your procrastination can help you determine what you need to do to move past it. But even if you’re not sure why you procrastinate, these tips can help break that habit and get you to get your work done.</p>



<h3>Take Baby Steps</h3>



<p>When you’re putting off a task, the hardest part can be just getting started. So instead of looking at the big picture of all you need to do, just take a small step in the right direction —&nbsp;like telling yourself you only need to work on a task or project for 30 minutes before you take a break to reassess. It can turn an impossible-seeming project into something more doable, and once you get started, it’ll be easier to keep moving.</p>



<h3>Make a Plan</h3>



<p>Remember how lack of planning is a common driver for procrastination? Combat that by going into every workday with a plan. Make it a habit before you leave each night to think about what you need to accomplish the following day, and make yourself a to-do list or a schedule —&nbsp;whatever works to keep you on track.</p>



<h3>Remove Distractions</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg" alt="Remove Distractions" srcset="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Have you considered you might procrastinate simply because you’re too distracted to work effectively? Do what you can to cut down on things that might pull you away from your work. For example, you could find a quiet room to work in, or wear noise-canceling headphones. Block social media and other distracting websites from your work computer.</p>



<h3>Isolate Yourself</h3>



<p>If you work in an office with others, another cause for your procrastination might be that people need you for things. And while it’s great to be the go-to person in the office, it’s not ideal for <a href="https://www.7pace.com/blog/developer-productivity-tools"><u>productivity</u></a>.</p>



<p>If you struggle with being pulled away from work by your coworkers, isolate yourself away from others so you appear less available. If you’re not able to go work somewhere without others around, stick a sign to the back of your chair to let people know you’re in deep work mode and don’t want to be interrupted.</p>



<h3>Use a Technique Like Pomodoro</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg" alt="Use a Technique Like Pomodoro" srcset="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>The Pomodoro technique has become a common way for all kinds of people to beat their procrastination habits. It works by requiring you to deeply focus on work for a period of time (usually 25 minutes), and then take a short, mandated break (5 minutes or so). You repeat this cycle over and over throughout the workday, alternating focused work with short breaks.</p>



<h3>Take Breaks</h3>



<p>On that note, another possible reason for your procrastination is that you feel tired or worn out —&nbsp;and that can be more easily remedied than you might think. Many of us don’t take enough breaks at work, even though science shows that breaks are necessary and can greatly improve productivity and quality of work. If you’re feeling stuck on a task or project, take a short break and come back to it later.</p>



<h3>Switch Between Tasks</h3>



<p>The same goes for working on the same task for too long. It’s easy to get stuck when you have tunnel vision. So if you feel like you can’t move forward on a particular task, switch to something else for a while. You can always come back to the first task with fresh eyes later, without having wasted any time in the meantime.</p>



<h2>Want to Become Even More Efficient? Track Time with 7pace Timetracker</h2>



<p>Once you’ve beaten procrastination, you might be looking for ways to become even <em>more</em>&nbsp;productive at work.</p>



<p>The most productive teams are <a href="https://www.7pace.com/blog/automation-tools-for-devops"><u>autonomous ones</u></a>. And a major part of autonomy is a time tracking solution that isn’t made to help managers watch over your shoulder —&nbsp;but to integrate seamlessly with your work and provide you with data and insights that help you work smarter.</p>



<p><a href="https://www.7pace.com/"><u>7pace Timetracker</u></a>&nbsp;is the only time tracking solution designed to measure and track progress completely in the background, so you don’t have to waste one second of effort. And it provides valuable data about your time at work that can help you plan, execute, and measure every aspect of every project.</p>



<p><a href="https://www.7pace.com/timetracker"><u>Learn more about 7pace Timetracker</u></a>&nbsp;and why it’s the only time tracking solution for productive, autonomous teams.</p>
						</div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/why-developers-procrastinate</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238435</guid>
            <pubDate>Tue, 23 Feb 2021 15:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privileged Ports Cause Climate Change]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26238040">thread link</a>) | @wilsonzlin
<br/>
February 23, 2021 | http://adamierymenko.com/ports.html | <a href="https://web.archive.org/web/*/http://adamierymenko.com/ports.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://adamierymenko.com/ports.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238040</guid>
            <pubDate>Tue, 23 Feb 2021 15:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconventional Customer Acquisition]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26237544">thread link</a>) | @StriverGuy
<br/>
February 23, 2021 | https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Even if you weren’t an early adopter of Slack, you were probably curious about the hype. Why were people so passionate about a work messenger tool? Not that chat tools aren’t sexy, but there must’ve been something else that made Slack so popular.</span></p>
<p><span>The secret? A killer customer acquisition strategy.</span></p>
<p><span>Slack highlighted its unique features, added valuable integrations, and offered its product for free. Combined with word-of-mouth and smart Twitter marketing, Slack was unstoppable, going from </span><a href="https://clickup.com/blog/slack-growth-strategy/" rel="follow noopener" target="_blank"><span>500,000 users to 1.1M users in the first four months</span></a><span>. Slack’s customer list eventually grew to include the likes of Fortune 100 companies like </span><a href="https://slack.com/about" rel="follow noopener" target="_blank"><span>Starbucks, Target, Oracle, and ETrade</span></a><span>. In late 2020, </span><a href="https://investor.salesforce.com/press-releases/press-release-details/2020/Salesforce-Signs-Definitive-Agreement-to-Acquire-Slack/default.aspx" rel="follow noopener" target="_blank"><span>Slack was acquired</span></a><span> by one of the biggest behemoths in the tech industryä¸€Salesforce.</span></p>
<p><span>Not every startup can go viral like Slack, but getting creative with your customer acquisition strategies can generate some pretty incredible leads. In this post, we share six unusual acquisition methods and the startups that have benefited from them.&nbsp;</span></p>

<p><em>What is a customer acquisition strategy?&nbsp;</em></p>
<p><span>Just so we’re all on the same page, let’s take a moment to define customer acquisition. Most people think of customer acquisition as email marketing, SEO, or free trials. But at its core, “customer acquisition” refers to techniques that attract new customers to a business.</span></p>
<p><span>Notice that we said technique</span><b>s</b><span>, plural. People respond to messaging differently and user needs can change with industry trends or economic shifts. For that reason, a comprehensive customer acquisition strategy should include multiple tactics to gain new customers rather than relying on one method alone.</span></p>

<h2><strong>6 unique ways to acquire more customers</strong></h2>
<p><span>Much of customer acquisition is trial and error. What works for some companies doesn’t necessarily work for others. Regardless, brainstorming new customer acquisition strategies is key to keeping your strategy fresh. Below, we share some lesser-known, but fruitful, customer acquisition strategies to attempt this quarter.</span></p>

<h2><strong>1. Give your reviews a review&nbsp;</strong></h2>
<p><a href="https://learn.g2.com/consumer-reviews" rel="follow noopener" target="_blank"><span>92% of B2B buyers</span></a><span> are more likely to purchase after reading a trusted review. Having just five published reviews can increase </span><a href="https://spiegel.medill.northwestern.edu/online-reviews/" rel="follow noopener" target="_blank"><span>the likelihood of someone making a purchase by 270%</span></a><span>. That’s nuts!</span></p>
<p><span>Ignoring sites like G2, TrustRadius, and Capterra is irresponsible. Prospects shopping for a B2B tool inevitably come across these sites in their research. If you search for “best project management tool”, Capterra is 5th in organic SERP. When you click on the article, you might expect Asana or Trello to be at the top. Surprisingly, </span><a href="https://www.capterra.com/project-management-software/" rel="follow noopener" target="_blank"><span>the first result is Monday.com</span></a><span>. This list is sorted by “sponsored products”, but still, this is a fantastic way for Monday.com to get in front of potential buyers.</span></p>

<p><span><img src="https://cdn.buttercms.com/7IKl4W7LR76X3B0mJIHc" alt="undefined"></span></p>
<p><span>If you don’t want to pay to play, start by scouring these sites for reviews and responding to them. Answer as many customer questions as possible, thank people who leave positive reviews, and reply respectfully and constructively to negative reviews. Don’t forget to ask existing customers to post reviews, too. Encourage CSMs or SEs to bring this up in their calls, add a link to post a review in your newsletter, and post your request to write reviews on LinkedIn or Twitter. You’d be surprised how many people comply, especially if you have a great product.</span></p>

<h2><strong>2. Buy your competitors</strong></h2>
<p><span>Most early-stage startups aren’t flush with cash, but buying up a competitor’s domain might be worth it if you have a little to spare. Customers who are looking for something specific usually type in long-tail keywords in search. By buying up websites that rank for those long-tail keywords, you can instantly increase your organic traffic.</span></p>
<p><span>The idea is to come up with a list of websites that land at the top of SERP and approach their owners. When you’re compiling this list, consider specific keyword rankings, organic search traffic, number of pages, number of backlinks, relevancy, audience size, and, of course, price. You might assume that this strategy is extremely expensive, but oftentimes these websites are personal blogs and sell for cheap.</span></p>
<p><a href="https://www.linkedin.com/in/matthewbarby/" rel="follow noopener" target="_blank"><span>Matthew Barby, VP of Marketing at Hubspot</span></a><span>, cites this strategy as his “#1 favorite tactic to roll out when working on a project with a brand new domain.” In </span><a href="https://www.matthewbarby.com/customer-acquisition-strategies/" rel="follow noopener" target="_blank"><span>this post</span></a><span>, he outlines a deal where he actually </span><i><span>saved </span></i><span>money buying another domain. Before acquiring the new website, it cost roughly $450 for his company to produce each blog post, and they’d publish 3-4 per month. That really added up.&nbsp;</span></p>
<p><span>So his team did some sleuthing and found the perfect acquisition target—one that had already published over 500 well-performing articles. He negotiated with the seller to nab the domain at a price that worked out to only $31.70 per article, 7% of the original cost. Besides obtaining that website’s traffic, the company’s posts jumped two pages in search results, on average. Here’s a glimpse of their increase in organic traffic:</span></p>

<p><span><img src="https://cdn.buttercms.com/w1MO6VAvQ6WGcEcfHcuS" alt="undefined" width="766" height="216"></span></p>
<p><span>While this system requires some research and investment, it can really pay off in the long run.</span></p>

<h2><strong>3. Old content is the new content&nbsp;</strong></h2>
<p><span>The Content Marketing Institute found that small businesses (1-99 employees) spent an </span><a href="https://contentmarketinginstitute.com/wp-content/uploads/2019/10/2020_B2B_Research_Final.pdf" rel="follow noopener" target="_blank"><span>average of $81,500 on content marketing</span></a><span> in 2019. That’s a big chunk of change. Blog posts and case studies do yield leads, but they only get published once...right?</span></p>
<p><span>Wrong. Repurposing content should be a major part of your customer acquisition strategy. Many B2B companies have hundreds of old posts on their site, and the deeper in the architecture posts are, the less likely they are to rank in search results. Make it a consistent practice to revisit old posts and update them with more recent statistics, new keywords, revamped CTAs, and even different titles. Consider merging a few posts to create an entirely new freebie and re-promote refurbished posts in newsletters, social media, or on Medium to attract more backlinks.</span></p>
<p><span>Venture Harbor, a venture studio based in the UK, used this strategy for their article on </span><a href="https://www.ventureharbour.com/b2b-lead-generation-strategies/" rel="follow noopener" target="_blank"><span>B2B lead generation strategies</span></a><span>. The post was long and took a significant amount of time to write. To let it get stale would be a waste! The author updated stats, inserted more compelling images, included more keywords, and added “2021” to the title. As a result, the post now lands in the top 5 Google results for “b2b content generation”:</span></p>

<p><span><img src="https://cdn.buttercms.com/kaR8r9ijSCeOY1shsQw2" alt="undefined" width="634" height="882"></span></p>
<p><span>Venture Harbor’s blog is just one example. Hubspot consistently incorporates this practice into its content strategy and has </span><a href="https://blog.hubspot.com/marketing/historical-blog-seo-conversion-optimization" rel="follow noopener" target="_blank"><span>increased organic traffic by 105%</span></a><span>. It’s a similar story for Zapier. Updating just 21 posts </span><a href="https://jessicagreene.marketing/blog/updating-website-content/" rel="follow noopener" target="_blank"><span>drove 52,431 additional visits each month</span></a><span> to the Zapier blog.</span></p>

<h2><strong>4. Create an online academy</strong></h2>
<p><span>Do people understand what your company does and how it can help their business? If you’re selling a complex tool or idea, an online academy can help. Take Segment, for example.</span></p>

<p><span><img src="https://cdn.buttercms.com/pTEt0aBScO8GRBBV1vZx" alt="undefined" width="674" height="438"></span></p>
<p><span>It can be tough to understand what Customer Data Platforms, or CDPs, do from a simple google search. To lower the barrier to entry, Segment created a </span><a href="https://segment.com/academy/" rel="follow noopener" target="_blank"><span>free online academy</span></a><span> with useful, non-salesy content. Prospects simply enter their email address and receive courses every week on the importance of customer analytics, what goes into a robust marketing stack, and how to make data-driven decisions. The leads generated from the academy are already interested in a CDP and want to learn more, meaning they are likely to be more responsive to sales teams that follow up.</span></p>
<p><span>Plus, the academy makes for great advertising. People who are bullish on the product can quickly send a link to a peer, friend, or boss. The embedded courses explain exactly why Segment would be a good investment. The academy is also helpful from a partnership point of view. If Segment wanted to pursue a reseller agreement with another company, the academy is a low-touch way to teach partners and their sales teams what Segment does and how it might fit into their GTM strategy.</span></p>

<h2><strong>5. Go viral on TikTok</strong></h2>
<p><span>Ok, hear us out. TikTok has </span><a href="https://datareportal.com/social-media-users?rq=tiktok" rel="follow noopener" target="_blank"><span>800 million active users</span></a><span>, ranking ahead of LinkedIn, Twitter, Pinterest, and Snapchat. According to Statista, 29.5% of 20-29-year-olds account for TikTok’s active user base, and </span><a href="https://www.statista.com/statistics/1095186/tiktok-us-users-age/" rel="follow noopener" target="_blank"><span>adults aged 30-49 make up another 30.3%</span></a><span>. What would happen if you could reach </span><b><i>even a fraction </i></b><span>of those users?</span></p>
<p><span>TikTok is </span><a href="https://medium.com/@kkirt/tiktok-b2b-brands-oh-no-please-no-c091c7af4fb5" rel="follow noopener" target="_blank"><span>not the place to advertise your upcoming webinar</span></a><span> or recently published whitepaper. That said, coming up with clever, relatable ways to interact with adults on the app can certainly pique people’s interest. Recruit your most creative teammate to think of outrageous, funny forms of content. Are there common challenges people face when trying to implement a tool in your space? Can you show some behind the scenes footage? Is your product meme-able?</span></p>
<p><span>We don’t yet have an example of a B2B brand doing this well, but a somewhat similar B2C brand, Wikihow, is excelling at this. First, they poked fun of themselves on TikTok, recreating (and encouraging others to recreate) pictures on their site:</span></p>

<p><span><img src="https://cdn.buttercms.com/uxn9GspwSya3I3v8jsh1" alt="undefined" width="606" height="341"></span></p>
<p><span>When COVID hit, they began creating </span><a href="https://www.youtube.com/watch?v=1MXgLjr7Sms" rel="follow noopener" target="_blank"><span>especially relevant how-to content</span></a><span> about the pandemic, like how to wash your hands, how to make masks out of old t-shirts, and how to meditate. So many people gravitated to the Wikihow account that it gained the attention of the United Nations. Now, Wikihow is a </span><a href="https://www.wikihow.com/Author/The-Verified-Initiative-of-the-United-Nations" rel="follow noopener" target="_blank"><span>part of the Verified Initiative of the United Nations</span></a><span>.</span></p>

<p><span><img src="https://cdn.buttercms.com/OkL4J70CQ0yitOeYy7Qh" alt="undefined" width="320" height="496"></span></p>

<h2><strong>6. Leverage your NPS survey</strong></h2>
<p><span>Most customer success teams these days send an annual or bi-annual NPS survey to measure customer satisfaction. If your customers already respond well to your NPS survey, there’s something else you might consider adding inä¸€a referral request. Customers already expect to receive this survey and have demonstrated that they’ll answer it. Adding one more question into the mix, “Is there anyone you think could benefit from this product?” can open a lot of doors.&nbsp;</span></p>
<p><span>If you don’t feel comfortable altering your NPS survey, that’s understandable. Other referral campaigns can work well, too. Make sure to incorporate a strong incentive, whether that be a discount, swag, or a certain number of free users. </span><a href="https://www.blackbaud.com/" rel="follow noopener" target="_blank"><span>Blackbaud</span></a><span>, a software solution …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition">https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition</a></em></p>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237544</guid>
            <pubDate>Tue, 23 Feb 2021 14:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode 101 – The Easy Way to Learn and Master VSCode]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26237545">thread link</a>) | @kaushal197
<br/>
February 23, 2021 | https://kaushalpatel.ca/posts/master-vscode/ | <a href="https://web.archive.org/web/*/https://kaushalpatel.ca/posts/master-vscode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>VSCode has become the hot tool in development. We don't all have to like it, but you can't deny it is the most used development tool with over <a href="https://insights.stackoverflow.com/survey/2019#development-environments-and-tools">50% of developers using it for their daily work.</a></p><p>The flexibility of VSCode is what makes it such a solid tool for various forms of development. Out of the box, it's a super simple text editor. There is never a reason to use any of its fancy tooling or community created extensions, however, if you really want to make the most of VSCode here are the 5 key areas you need to understand.</p><p><strong>*Disclaimer!!*</strong><em>: Most of the shortcuts will state <strong>Cmd</strong>, kindly translate this to <strong>Ctrl</strong> if you use a non-MacOS related device.</em></p><h2 id="heading-navigation">Navigation<a href="#heading-navigation"><span> permalink</span></a></h2><p>This editor is FULL of keyboard shortcuts, a lot of them come in handy for traversing the crazy number of tabs we mindlessly open up.</p><p><strong><code>Cmd + P</code></strong>: Quickly Jump to File</p><p>If you don't know of this one already it's a superpower! You don't even have to be great at spelling, VSCode is really good at shortlisting the possible file(s) you may be looking for.</p><p><img src="https://kaushalpatel.ca/images/jump_to_file.gif" alt="" loading="lazy" width="627" height="220"></p><p>Another great way to traverse around without having the file explorer open is the top path bar; it's a hidden gem I recently learned about. You can click on the file or folder in the path, and it expands to let you pick any file sitting beside it. Check it out:</p><p><img src="https://kaushalpatel.ca/images/path_bar.gif" alt="" loading="lazy" width="600" height="265"></p><p>Since VSCode is based on Electron, you use the tab switching shortcut from Chrome + Terminal + Firefox... basically most applications that have tabs.</p><p><strong><code>Cmd + Shift + [ or ]</code></strong>: Go to Left or Right Tab</p><p><img src="https://kaushalpatel.ca/images/tab_shifting.gif" alt="" loading="lazy" width="600" height="63"></p><h2 id="heading-intellisense">Intellisense<a href="#heading-intellisense"><span> permalink</span></a></h2><p>Intellisense is my favourite component to VSCode, it's so seamless. VSCode gives you very basic static analysis and refactoring capabilities depending on the type of file you're editing.</p><p><strong><code>Ctrl + Space</code></strong>: Activate autocomplete feature for item under cursor</p><p><img src="https://kaushalpatel.ca/images/autocomplete.gif" alt="" loading="lazy" width="735" height="91"></p><p>The editor also showcases all of the properties, methods, and blocks of the current file in the <code>Outline</code> window (Bottom-Left). This can be opened from the Command Palette we used previously to navigate by simply entering <code>@</code>. You can use the Command Palette like this to navigate within your active file with either <code>@</code> or <code>:</code>.</p><p><img src="https://kaushalpatel.ca/images/jump_to_section.gif" alt="" loading="lazy" width="1114" height="338"></p><p>The real meat of intellisense comes in it's refactoring capabilities! I will showcase my most used feature and leave the rest for you to explore. Did you know you can rename a variable safely across your whole codebase?</p><p><img src="https://kaushalpatel.ca/images/rename.gif" alt="" loading="lazy" width="740" height="246"></p><p>I was only able to show an example from a local function in my project. Try it in your own codebase, it will affect the naming for all appropriate instances.</p><h2 id="heading-vcsgit">VCS/Git<a href="#heading-vcsgit"><span> permalink</span></a></h2><p>I like using the command line for Git personally, on the other hand a lot of my co-workers say a GUI Git tool is the best.</p><p><img src="https://kaushalpatel.ca/images/whatever.gif" alt="" loading="lazy" width="480" height="350"></p><p>Whichever option you choose, the out-of-the-box VCS and Git feature is useful. It's so powerful with diff-checking, conflicts, tracking by file, etc.... For command line users, this can be a time-saver. For GUI users, this means one less application to open and have running on your machine. To me, this is a win/win.</p><p>You can access the VCS window on the left-hand side (it looks like the Git logo). It's pretty difficult to cover everything it has to offer without adding a million images, but the big thing to note are the vertical ellipsis and the quick options when hovering over a file.</p><p><img src="https://kaushalpatel.ca/images/VCS.png" alt="" loading="lazy" width="354" height="322"></p><p>Refined and common Git commands can be accessed by clicking the ellipsis. The <strong>plus</strong> lets you add all changes to the next commit, whilst the <strong>hooked arrow</strong> lets you rollback all changes. When you click on a file, the diff will be shown in the main window as a split between old and new. Get used to checking this tab and running through your files before committing!! It has saved me from minor mistakes and endless build times on multiple occasions.</p><p><img src="https://kaushalpatel.ca/images/diff.png" alt="" loading="lazy" width="1489" height="282"></p><p>Now if only there was a way to review PRs in VSCode when using Github enterprise. If any of you know of a tool like this, please DM me on <a href="https://twitter.com/talesofadev">Twitter</a> 🙏</p><h2 id="heading-zen-mode">Zen Mode<a href="#heading-zen-mode"><span> permalink</span></a></h2><p>Let your mind be free of distractions 📿</p><p><strong>Cmd + K -&gt; Z</strong></p><p><em>If you can use this mode effectively, you know you have mastered VSCode</em></p><h2 id="heading-extensions">Extensions<a href="#heading-extensions"><span> permalink</span></a></h2><p>I think we all know about Extensions, they are essentially plugins to help with specific issues/expansions you want for the editor. As a web developer I use a few productivity and tracking extensions:</p><ul><li>Todo Tree</li><li>Todo Highlight</li><li>Prettier</li><li>GitLens</li><li>Language-specific extensions</li><li>Bonus: Themes</li></ul><p><a href="https://twitter.com/talesofadev">Follow me on Twitter</a> for updates on my ebook: <code>Git Animated - A Visual Guide to Understanding Git</code></p></div></div>]]>
            </description>
            <link>https://kaushalpatel.ca/posts/master-vscode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237545</guid>
            <pubDate>Tue, 23 Feb 2021 14:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Pretty JSON Revolution]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 145 (<a href="https://news.ycombinator.com/item?id=26237048">thread link</a>) | @peterohler
<br/>
February 23, 2021 | http://www.ohler.com/dev/pretty.html | <a href="https://web.archive.org/web/*/http://www.ohler.com/dev/pretty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	  <table>
	    <tbody><tr>
	      <td colspan="2">
		<p>
		  Wouldn't it be nice if more JSON tools supported a truly
		  pretty JSON format? Demand options for truly pretty JSON
		  now! Viva la revolucion!
		</p>
		<p>
		  If only it were that easy. JSON format has become wildly
		  popular over the last decade easily passing XML as the
		  format of choice. For us humans JSON is much easier to read
		  than XML if the JSON is properly formatted. Sadly most tools
		  for viewing or formating JSON seem to be stuck on one of two
		  formats. One format is the single line format and the other
		  is a simple expanded format. There are other options though
		  with some tools.
		</p>
		<p>
		  One tool that offers more options is
		  the <span>oj</span> application
		  which is part of the
		  golang <a href="https://github.com/ohler55/ojg">OjG</a>
		  package. The <span>oj</span>
		  application will be used to illustrate the range of JSON
		  formats from the ugly up to the beauty of pretty
		  JSON. Follow along and try out your favorite JSON sample on
		  each step.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line</p>
		<p>
		  The tight one line JSON format is used when trying to
		  minimize the size of a JSON document. It is the preferred
		  format for transmitting and storing JSON as it takes less
		  bandwidth and less disk space. For viewing, it is hard for
		  the eye to find elements of interests and difficult to
		  determine element boundaries. It has to be the ugliest of
		  all JSON formats.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 0 colors.json</span>
{"colors":[{"color":"black","hex":"#000","rgb":[0,0,0]},{"color"
:"red","hex":"#f00","rgb":[255,0,0]},{"color":"yellow","hex":"#f
f0","rgb":[255,255,0]},{"color":"green","hex":"#0f0","rgb":[0,25
5,0]},{"color":"cyan","hex":"#0ff","rgb":[0,255,255]},{"color":"
blue","hex":"#00f","rgb":[0,0,255]},{"color":"magenta","hex":"#f
0f","rgb":[255,0,255]},{"color":"white","hex":"#fff","rgb":[255,
255,255]}]}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line Per Node</p>
		<p>
		  What many packages refer to as pretty is an expanded format
		  where every element and each array and object start are on
		  separate lines. The core
		  golang <code>json.MarshalIndent()</code> function produces
		  an example of this format. The format takes up so much
		  vertical space the example on the right had to be cut off to
		  avoid filling up this article with just large amounts of
		  white space.
		</p>
		<p>
		  With the expanded (pretty?) format it is certainly easier to
		  determine element boundaries but you need a large screen or
		  to be good at scrolling to find what you are looking for. So
		  the expanded format is a step up from the one line format
		  which makes it a bit prettier but it is a weak effort that
		  is not without flaws.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ],
      "color": "red"
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Sorted Object Keys</p>
		<p>
		  In many implementations JSON objects, whether implemented as
		  a golang map, Ruby Hash, Python dict, or what ever your
		  language of choice uses, the order of object elements is
		  random. That makes it more difficult to visually scan a set
		  of elements and pick out the same keyed element in each JSON
		  object. The brain is good at picking out visual or spacial
		  patterns but if the layout changes each each time there is
		  no pattern to pickup on. A visual scan has to be done,
		  looking at each key until the target is identified. JSON can
		  be made prettier by sorting the JSON object members by
		  element keys.
		</p>
		<p>
		  A sorted expanded format is a step up from just the expanded
		  format but it still suffers from taking up lot of vertical
		  space. If someone was writing the JSON by hand they would
		  probably not elect to expand the JSON to quite the level
		  that most packages or libraries do.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 -s colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "color": "red",
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ]
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style</p>
		<p>
		  The ideal pretty JSON pretty is to have the format look like
		  a human had typed it in. Well a pedantic human that didn't
		  make mistakes. Just like Goldilocks, the optimum middle
		  ground between a single line and a fully expanded format is
		  the goal. The
		  algorithm <span>oj</span> uses
		  considers a suggested edge to not exceed and a maximum
		  element depth allowed on a single line. Those two parameters
		  are specified as a float where the whole number part is the
		  edge and the fractional part or the number of 10ths is the
		  maximum depth on a single line. With those two parameters a
		  reasonable human style format can be achieved and the
		  results are looking rather pretty.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 colors.json</span>
{
  "colors": [
    {"color": "black", "hex": "#000", "rgb": [0, 0, 0]},
    {"color": "red", "hex": "#f00", "rgb": [255, 0, 0]},
    {"color": "yellow", "hex": "#ff0", "rgb": [255, 255, 0]},
    {"color": "green", "hex": "#0f0", "rgb": [0, 255, 0]},
    {"color": "cyan", "hex": "#0ff", "rgb": [0, 255, 255]},
    {"color": "blue", "hex": "#00f", "rgb": [0, 0, 255]},
    {"color": "magenta", "hex": "#f0f", "rgb": [255, 0, 255]},
    {"color": "white", "hex": "#fff", "rgb": [255, 255, 255]}
  ]
}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colors</p>
		<p>
		  With the human style formatting the JSON sample is very
		  readable but it can be made prettier. Well at least for
		  those of us than see in color. With the <code>-c</code>
		  option or the <code>-b</code> option the formatted JSON now
		  has colors. While colors do make the output prettier they
		  also make it easier for the eye to discern keys, string,
		  boolean, and numbers more easily. Try it, look at the
		  non-colored JSON and the colored and pick out your preferred
		  color name. Maybe not nirvana but compared to the first, one
		  line format, the colored pretty output is a completely
		  different level.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c colors.json</span>
<span>{</span>
  <span>"colors"</span><span>:</span> <span>[</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"black"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#000"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"red"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f00"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"yellow"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#ff0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"green"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0f0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"cyan"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0ff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"blue"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#00f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"magenta"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f0f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"white"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#fff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colored in the SEN Format</p>
		<p>
		  Sorted human style with colors is about as good as it gets
		  but what if we deviate from strict JSON format and take a
		  few shortcuts that Javascript and GraphQL allow such as
		  unquoted strings and optional
		  commas. The <a href="https://github.com/ohler55/ojg/blob/develop/sen.md">SEN</a>
		  format is that
		  format. The <span>oj</span>
		  application supports parsing and encoding in SEN
		  format. It's not JSON but the conversion from SEN to JSON
		  and the reverse is lossless. Getting rid of the extra quotes
		  and unnecessary commas make the data easier to read and as a
		  side benefit the SEN format takes up less space so
		  transmission and disk space requirements are reduced when
		  compared to JSON.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c -sen colors.json</span>
<span>{</span>
  <span>colors</span><span>:</span> <span>[</span>
    <span>{</span><span>color</span><span>:</span> <span>black</span> <span>hex</span><span>:</span> <span>"#000"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>red</span> <span>hex</span><span>:</span> <span>"#f00"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>yellow</span> <span>hex</span><span>:</span> <span>"#ff0"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>green</span> <span>hex</span><span>:</span> <span>"#0f0"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>cyan</span> <span>hex</span><span>:</span> <span>"#0ff"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>blue</span> <span>hex</span><span>:</span> <span>"#00f"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>magenta</span> <span>hex</span><span>:</span> <span>"#f0f"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>white</span> <span>hex</span><span>:</span> <span>"#fff"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td colspan="2">
		<p>Continue the Fight</p>
		<p>
		  Beauty is in the eye of the beholder. My preference is the
		  pretty colored SEN format. You might have a different
		  preference but let's continue the revolution together and get
		  more pretty JSON out there. Use pretty JSON on web pages and
		  in email. For the tool builders out there, offer the
		  option for pretty JSON.
		</p>
		<p>
		  Note: In case you are wondering if the colored JSON HTML was
		  written or colorized by hand, it was
		  not. The <code>-html</code> option
		  of <span>oj</span> was used to
		  produce the colorized HTML for this article. It's a handy
		  option when including JSON on web pages or in email.
		</p>
	      </td>
	    </tr>
	  </tbody></table>
	</div>
      </div></div>]]>
            </description>
            <link>http://www.ohler.com/dev/pretty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237048</guid>
            <pubDate>Tue, 23 Feb 2021 13:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You need to be able to run your system]]>
            </title>
            <description>
<![CDATA[
Score 279 | Comments 148 (<a href="https://news.ycombinator.com/item?id=26236908">thread link</a>) | @catern
<br/>
February 23, 2021 | http://catern.com/run.html | <a href="https://web.archive.org/web/*/http://catern.com/run.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
When developing a system,
it is important to be able to run the system in its entirety.
<p>
"Run the unit tests" doesn't count.
The complexity of your system is in the interactions between the units.
</p><p>
"Run an individual service against mocks" doesn't count.
A mock will rarely behave identically to the real dependency,
and the behavior of the individual service will be unrealistic.
You need to run the actual system.
</p><p>
"Run an individual service in a shared stateful development environment running all the other services" doesn't count.
A shared development environment will be unreliable as it diverges more and more from the real system.
</p><p>
"Run most services in a mostly-isolated development environment,
calling out to a few hard-to-run external services" doesn't count.
Those few external services on the edge of the mostly-isolated development environment are often the most crucial ones;
without the ability to run modified versions of them, your development process is crippled.
Furthermore, being dependent on external services greatly complicates where and how you can run the system;
it's much harder to, for example, run tests with the system on every commit if that will access external services.
</p><p>
"Run all the services that make up the system in an isolated development environment" counts;
it's the bare minimum requirement.
Bonus points if this can be done completely on localhost,
without using an off-host cluster deployment system.
</p><p>
Without the ability to actually run the entire system in this way while developing,
many evil practices will tend to become common.
</p><ul>
  <li>
    Testing is harder and far less representative,
    and therefore many issues can only be found when changes are deployed to production.
  </li><li>
    In turn, production deployment will cause issues more often,
    and so deployment will be more slow and less frequent.
  </li><li>
    Deploying the system to new environments is more difficult,
    since the developers aren't able to actually run the system.
    Existing practices in production will be cargo-culted and copied around indefinitely,
    even when they are unnecessary or actively harmful.
  </li><li>
    Exploratory usage of the system is very difficult,
    so it will be harder to consider using the system for purposes outside what it was originally developed for,
    and new use cases will become rare.
  </li><li>
    Downstream clients who depend on the system will also suffer all these issues,
    since without the ability to run the upstream system in development,
    they can't run their own entire system, which is a superset of the upstream system.
</li></ul>
Running the entire system during development is the first step to preventing these issues.
Further steps include writing automated tests for the system (which can be run repeatedly during development),
and using, as much as possible, the same code to run the system in development and in production.
<p>
Developers of large or legacy systems that cannot already be run in their entirety during development
often believe that it is impractical to run the entire system during development.
They'll talk about the many dependencies of their system,
how it requires careful configuration of a large number of hosts,
or how it's too complex to get reliable behavior.
</p><p>
In my experience, they're always wrong.
These systems can be run locally during development with a relatively small investment of effort.
Typically, these systems are just ultimately not as complicated as people think they are;
once the system's dependencies are actually known and understood rather than being cargo-culted or assumed,
running the system, and all its dependencies, is straightforward.
</p><p>
Being able to run your entire system during development is just about the most basic requirement for a software project.
It's not, on its own, sufficient for your development practices to be high quality;
but if you can't do this, then you're not even in the running.
</p></div>]]>
            </description>
            <link>http://catern.com/run.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236908</guid>
            <pubDate>Tue, 23 Feb 2021 13:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PfSense 2.5.0 bugs and fixes after upgrade]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236796">thread link</a>) | @ggho
<br/>
February 23, 2021 | https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/ | <a href="https://web.archive.org/web/*/https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

				

<!-- .page-header -->


	
	<div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article>

	
<div itemprop="text">

	
	
<p>Some users have reported problems after upgrade to pfSense 2.5.0.</p>



<p>In this article we list, in a FAQ-style format, the main known issues and the available fixes.</p>



<p><em><strong>This article is regularly updated as soon as a new bug is confirmed or as soon as a fix is provided</strong>.</em></p>



<h2>Table of contents</h2>



<p><a href="#should-i-upgrade-pfsense">Should I upgrade to v2.5.0?</a><br><a href="#update-not-available-dashboard-pfsense">pfSense 2.5.0 update is not available on the dashboard</a><br><a href="#how-to-downgrade-pfsense">How can I downgrade to 2.4.5-p1?</a><br><a href="#cannot-renaming-alias-used-pfsense">I can not rename Alias used in firewall rule</a><br><a href="#cbq-doesnt-work-correctly">CBQ Traffic shaping doesn’t work as expected</a><br><a href="#unbound-crashes-periodically-pfsense">Unbound crashes periodically</a><br><a href="#openvpn-problems-pfsense">OpenVPN problems</a><br><a href="#ipsec-problems-pfsense">IPsec problems</a><br><a href="#non-local-gateway-problem-pfsense">Non-local gateway problem</a><br><a href="#router-advertisements-ipv6-problems-pfsense">RA (Router Advertisements) IPv6 problems</a><br><a href="#upgrade-problem-zfs-device-pfsense">Upgrade or installation problem on ZFS device</a><br><a href="#zabbix-proxy-failed-after-upgrade-pfsense">Zabbix Proxy Failed after upgrade</a><br><a href="#pfblockerng-problems-pfsense">pfBlockerNG doesn’t work as expected</a><br><a href="#issue-certificates-after-upgrade-pfsense">I have an issue with certificates after 2.5 upgrade</a><br><a href="#openbgpd-packages-removed-pfsense">OpenBGPD, Quagga OSPF, relayd are no more available</a><br><a href="#problems-with-realtek-nic-pfsense">I have problems with realtek NIC</a><br><a href="#problems-with-frr-and-bgp-pfsense">Some problems with frr and bgp</a><br><a href="#still-bugs-reinstall-pfsense">I still have bugs, what can I do?</a><br><a href="#how-to-install-pach-pfsense">How to install a patch?</a></p>



<h2 id="should-i-upgrade-pfsense">Should I upgrade to v2.5.0?</h2>



<p>Yes and no. If you are not in a hurry, it is better to wait one week or two.<br>The vast majority of users do not encounter any problems.<br>But there are still some bugs that are not fixed.</p>



<h2 id="update-not-available-dashboard-pfsense">pfSense 2.5.0 update is not available on the dashboard</h2>



<p>First, try to force a cache refresh in your browser (ctrl-F5, shift+reload or similar).<br>Second, check that no script is blocked by the browser or an extension.<br>Third, try to enable the “State Table Size” option on dashboard :</p>



<p>Click on the modify button of the System Information widget:</p>



<div><figure><img loading="lazy" width="567" height="179" src="https://www.provya.com/blog/wp-content/uploads/2021/02/dashboard-system-information-pfsense-provya.png" alt="" srcset="https://www.provya.com/blog/wp-content/uploads/2021/02/dashboard-system-information-pfsense-provya.png 567w, https://www.provya.com/blog/wp-content/uploads/2021/02/dashboard-system-information-pfsense-provya-300x95.png 300w" sizes="(max-width: 567px) 100vw, 567px"><figcaption>[pfSense] System Information widget</figcaption></figure></div>



<p>Scroll-down and check the “State Table Size” box then Save:</p>



<div><figure><img loading="lazy" width="437" height="358" src="https://www.provya.com/blog/wp-content/uploads/2021/02/state-table-size-option-dashboard-pfsense-provya.png" alt="" srcset="https://www.provya.com/blog/wp-content/uploads/2021/02/state-table-size-option-dashboard-pfsense-provya.png 437w, https://www.provya.com/blog/wp-content/uploads/2021/02/state-table-size-option-dashboard-pfsense-provya-300x246.png 300w" sizes="(max-width: 437px) 100vw, 437px"><figcaption>[pfSense] State Table Size option</figcaption></figure></div>



<h2 id="how-to-downgrade-pfsense">How can I downgrade to 2.4.5-p1?</h2>



<p>There is no more official link for downloading pfSense-2.4.5-p1.</p>



<p>We uploaded a version on WeTransfer. You can find it with this link: <a href="https://we.tl/t-gUpgfbkkqI">https://we.tl/t-gUpgfbkkqI</a><br>Check the sha256sum:</p>



<pre><code>aa40595d090465f20fff1890092e6a14a753cd9486ccc7101d81301cad8b8840</code></pre>



<p>If you don’t trust us, no problem. Take a look at these links <a href="https://repo.ialab.dsu.edu/pfsense/">https://repo.ialab.dsu.edu/pfsense/</a><br>or<br><a href="https://forum.netgate.com/topic/161085/download-location-for-2-4-5-release-p1-amd64">https://forum.netgate.com/topic/161085/download-location-for-2-4-5-release-p1-amd64</a></p>



<h2 id="cannot-renaming-alias-used-pfsense">I can not rename Alias used in firewall rule</h2>



<p>If you try to rename an alias that is used in firewall rules you get an error that sounds like this: “<strong>Unresolvable source alias ‘AliasName’ for rule ‘Rule with AliasName</strong>‘”.</p>



<p>There is a fix in place for that :</p>



<pre><code>585e7567d0e308ce440ff1b0651976c97fe58115</code></pre>



<p>If necessary, take a look at the section <a href="#how-to-install-pach-pfsense"><em>How to install a patch</em></a><em><a href="#how-to-install-pach-pfsense">?</a></em></p>



<p>More information: <a href="https://forum.netgate.com/topic/161094/solved-renaming-alias-used-in-firewall-rule">https://forum.netgate.com/topic/161094/solved-renaming-alias-used-in-firewall-rule</a>.</p>



<h2 id="cbq-doesnt-work-correctly">CBQ Traffic shaping doesn’t work as expected</h2>



<p>Some users have reported a panic when using CBQ traffic shaping. It appears when CBQ is used on VLAN interfaces.</p>



<p>There is no solution for now. Try to deactivate CBQ or use an other algorithm like PRIQ or HFSC.</p>



<p>More information: <a href="https://redmine.pfsense.org/issues/11470">https://redmine.pfsense.org/issues/11470</a></p>



<h2 id="unbound-crashes-periodically-pfsense">Unbound crashes periodically</h2>



<p>Go to Diagnostics &gt; Command Prompt:</p>



<div><figure><img loading="lazy" width="160" height="204" src="https://www.provya.com/blog/wp-content/uploads/2021/02/diagnostics-command-prompt-menu-pfsense-provya.png" alt=""><figcaption>[pfSense] Diagnostics &gt; Command Prompt</figcaption></figure></div>



<p>The command to execute is the following:</p>



<pre><code>pkg upgrade -fy unbound</code></pre>



<p>Be sure to restart the Unbound service from <strong>Status</strong> &gt; <strong>Services</strong> after.</p>



<p>Or directly in command line:</p>



<pre><code>pkg upgrade -fy unbound; pfSsh.php playback svc restart unbound</code></pre>



<p>Anyway, make sure to restart unbound after this package installation.</p>



<h2 id="openvpn-problems-pfsense">OpenVPN problems</h2>



<p>Double check your cryptographic parameters on client and server.<br>Try to uncheck the “Data Encryption Negotiation” setting in the openvpn client setup.</p>



<p>Double check your OpenVPN configuration too.<br>For example some users discovered that the IPv4 tunnel network on the client side was blank and was somehow previously working with it blank and with a certificate that didn’t exist on the server.</p>



<h2 id="ipsec-problems-pfsense">IPsec problems</h2>



<p>There are a lot of bugs reported about IPsec. The majority has been fixed.</p>



<p>To ensure you have all of the current known and fixed IPsec issues corrected, you can install 6 patches:</p>



<ul><li><code><span>ead6515637a34ce6e170e2d2b0802e4fa1e63a00</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11435" target="_blank">#11435</a></li><li><code><span>57beb9ad8ca11703778fc483c7cba0f6770657ac</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11435" target="_blank">#11435</a></li><li><code><span>10eb04259fd139c62e08df8de877b71fdd0eedc8</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11442" target="_blank">#11442</a></li><li><code><span>ded7970ba57a99767e08243103e55d8a58edfc35</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11486" target="_blank">#11486</a></li><li><code><span>afffe759c4fd19fe6b8311196f4b6d5e288ea4fb</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11487" target="_blank">#11487</a></li><li><code><span>2fe5cc52bd881ed26723a81e0eed848fd505fba6</span></code>&nbsp;<a rel="noreferrer noopener" href="https://redmine.pfsense.org/issues/11488" target="_blank">#11488</a></li></ul>



<p>It is necessary to restart the firewall after installing the patches.</p>



<p>If necessary, take a look at the section <em><a href="#how-to-install-pach-pfsense">How to install a patch</a>?</em></p>



<p>More information: <a href="https://forum.netgate.com/topic/161142/ipsec-upgrade-to-2-5/4?_=1614102852026">https://forum.netgate.com/topic/161142/ipsec-upgrade-to-2-5/4?_=1614102852026</a>.</p>



<h2 id="non-local-gateway-problem-pfsense">Non-local gateway problem</h2>



<p>If you use a non-local gateway (i.e. a gateway that is not in your WAN subnet), this gateway will not be added on boot. You have to add it manually.</p>



<p>This bug is now resolved. If you encounter the problem you can add this patch:</p>



<pre><code>a97987a5d1df8219f40433270fce0e3ef49345dc</code></pre>



<p>If necessary, take a look at the section <em><a href="#how-to-install-pach-pfsense">How to install a patch</a>?</em></p>



<p>More information: <a href="https://redmine.pfsense.org/issues/11433">https://redmine.pfsense.org/issues/11433</a>.</p>



<h2 id="router-advertisements-ipv6-problems-pfsense">RA (Router Advertisements) IPv6 problems</h2>



<p>This bug is resolved. If you encounter the problem you can add this patch:</p>



<pre><code>91cd17417d7cba3ab5dbe55f0ced02eaef78c45b</code></pre>



<p>If necessary, take a look at the section <em><a href="#how-to-install-pach-pfsense">How to install a patch</a>?</em></p>



<p>More information: <a href="https://redmine.pfsense.org/issues/11367">https://redmine.pfsense.org/issues/11367</a>.</p>



<h2 id="upgrade-problem-zfs-device-pfsense">Upgrade or installation problem on ZFS device</h2>



<p>The problem is the installer “forgets” to add zfs_load=”YES” to /boot/loader.conf.</p>



<p>Go to Diagnostics &gt; Command Prompt (or directly in command line):</p>



<div><figure><img loading="lazy" width="160" height="204" src="https://www.provya.com/blog/wp-content/uploads/2021/02/diagnostics-command-prompt-menu-pfsense-provya.png" alt=""><figcaption>[pfSense] Diagnostic &gt; Command Prompt</figcaption></figure></div>



<p>Execute the following command:</p>



<pre><code>echo 'zfs_load="YES"' &gt;&gt; /boot/loader.conf.local</code></pre>



<p>More information: <a href="https://redmine.pfsense.org/issues/11483">https://redmine.pfsense.org/issues/11483</a></p>



<h2 id="zabbix-proxy-failed-after-upgrade-pfsense">Zabbix Proxy Failed after upgrade</h2>



<p>Due to database changes between zabbix-proxy versions. The proxy database needs to be removed after upgrading otherwise the proxy service won’t start.</p>



<p><span>Workaround</span>: remove the database, then reinstall Zabbix Proxy.</p>



<p>Go to Diagnostics &gt; Command Prompt (or directly in command line):</p>



<div><figure><img loading="lazy" width="160" height="204" src="https://www.provya.com/blog/wp-content/uploads/2021/02/diagnostics-command-prompt-menu-pfsense-provya.png" alt=""><figcaption>[pfSense] Diagnostic &gt; Command Prompt</figcaption></figure></div>



<p>Execute the following command:</p>



<pre><code>rm /var/db/zabbix-proxy/proxy.db</code></pre>



<p>Then reinstall Zabbix Proxy.</p>



<p>More information: <a href="https://redmine.pfsense.org/issues/11493">https://redmine.pfsense.org/issues/11493</a></p>



<h2 id="pfblockerng-problems-pfsense">pfBlockerNG doesn’t work as expected</h2>



<p>This problem is easy to resolv with a <strong>Forced/Reload</strong> in the Update tab in pfBlockerNG.</p>



<h2 id="issue-certificates-after-upgrade-pfsense">I have an issue with certificates after 2.5 upgrade</h2>



<p>An invalid certificate date can lead to a PHP crash after 2.5.0 upgrade.<br>This bug is resolved. If you encounter the problem you can add this patch:</p>



<pre><code>cb17faca3b07197db4b1eb1502a876873ddc222c</code></pre>



<p>If necessary, take a look at the section <em><a href="#how-to-install-pach-pfsense">How to install a patch</a>?</em></p>



<p>More information: <a href="https://redmine.pfsense.org/issues/11489">https://redmine.pfsense.org/issues/11489</a>.</p>



<h2 id="openbgpd-packages-removed-pfsense">OpenBGPD, Quagga OSPF, relayd are no more available</h2>



<p>It’s not a bug. It’s a feature. These&nbsp;packages&nbsp;have been removed.</p>



<h2 id="problems-with-realtek-nic-pfsense">I have problems with realtek NIC</h2>



<p>There is a package available for installing realtek drivers for those that have been suffering with that hardware.<br>Seems easy enough, and more importantly seems more stable than previous – also haven’t dropped gateway, no dpinger issues, and no unbound issues since testing the realtek driver.</p>



<p>Go to Diagnostics &gt; Command Prompt (or directly in command line):</p>



<div><figure><img loading="lazy" width="160" height="204" src="https://www.provya.com/blog/wp-content/uploads/2021/02/diagnostics-command-prompt-menu-pfsense-provya.png" alt=""><figcaption>[pfSense] Diagnostic &gt; Command Prompt</figcaption></figure></div>



<p>Execute the following commands:</p>



<pre><code>pkg install realtek-re-kmod
echo 'if_re_load="YES"' &gt;&gt; /boot/loader.conf.local</code></pre>



<p>Then reboot your firewall.</p>



<p>Finally, execute this command:</p>



<pre><code>dmesg | grep re0</code></pre>



<p>It should say something about Realtek … and leave out the alphabet soup that the previous driver said and show a version: <em>1.96.04</em> or something like that.<br>Default driver doesn’t state a version line.</p>



<h2 id="problems-with-frr-and-bgp-pfsense">Some problems with frr and bgp</h2>



<p>Currently the GUI renders a invalid <strong>frr</strong> config when <strong>bgp</strong> as-path ACLs are in use.<br>This ACLs will be written under the “router bgp ” section what causes FRR and bgpd daemon failing to start.<br>Switching to raw config mode and putting all bgp as-path access-list outsite the router bgp section is the only way to work this around.<br>Prefix-lists and route-maps are not affected by this and will be written correctly to the config.</p>



<p>Another difference is that bgpd starting with version 7.5 does default filtering for route announcements .<br>Without a outbound route-map in the neighbor statement, no routes will be announced at all.<br>An empty “route-map permit ” does the the job.</p>



<p>The next difference compared to pfSense 2.4.5-p1 is, that now IGP route synchronization is in effect.<br>You could not disable it by using “no synchronization” in the bgpd config.<br>So when you configure prefixes by the network statement, that are not in the routing table, it’s necessary to configure a static route to <em>Null</em> for that networks on the device.<br>This is pretty common on many network devices, but not was not necessary in pfSense 2.4.5-p1.</p>



<h2 id="still-bugs-reinstall-pfsense">I still have bugs, what can I do?</h2>



<p>The best thing to do is to make a backup then reinstall from scratch pfSense 2.5.0 and import your configuration.</p>



<p>If it doesn’t work take a look at the <a href="https://docs.netgate.com/pfsense/en/latest/troubleshooting/upgrades.html">Documentation</a>, at the <a href="https://forum.netgate.com/category/5/installation-and-upgrades">pfSense forum</a> or open a ticket on the <a href="https://redmine.pfsense.org/">pfSense bugtracker</a>.</p>



<h2 id="how-to-install-pach-pfsense">How to install a patch?</h2>



<p>First you should install the “System Patches” package.</p>



<p>Navigate to System &gt; Package Manager:</p>



<div><figure><img loading="lazy" width="288" height="364" src="https://www.provya.com/blog/wp-content/uploads/2021/02/system-package-manager-menu-pfsense-provya.png" alt="" srcset="https://www.provya.com/blog/wp-content/uploads/2021/02/system-package-manager-menu-pfsense-provya.png 288w, https://www.provya.com/blog/wp-content/uploads/2021/02/system-package-manager-menu-pfsense-provya-237x300.png 237w" sizes="(max-width: 288px) 100vw, 288px"><figcaption>[pfSense] System &gt; Package Manager</figcaption></figure></div>



<p>Go on the <strong>Available Packages</strong> tab, then search for “<strong>System Patches</strong>” and install it:</p>



<div><figure><img loading="lazy" width="730" height="389" src="https://www.provya.com/blog/wp-content/uploads/2021/02/how-to-install-system-patches-pfsense-provya.png" alt="" srcset="https://www.provya.com/blog/wp-content/uploads/2021/02/how-to-install-system-patches-pfsense-provya.png 730w, https://www.provya.com/blog/wp-content/uploads/2021/02/how-to-install-system-patches-pfsense-provya-300x160.png 300w" sizes="(max-width: 730px) 100vw, 730px"><figcaption>[pfSense] Installing “System Patches” package</figcaption></figure></div>



<p>Go to System &gt; Patches:</p>



<p>Read the text and warnings, then click on the “+” button to add a new patch.</p>



<p>The fields to be filled are like following:</p>



<ul><li><strong><span>Description</span></strong>: whatever you want.</li><li><strong><span>Commit ID</span></strong>: <span>corresponding commit ID</span></li><li><strong><span>Save</span></strong></li></ul>



<p>Once a commit ID was entered, there will be a&nbsp;<strong>fetch</strong>&nbsp;link. Click&nbsp;<strong>fetch</strong>&nbsp;and the patch will be retrieved only.</p>



<p>To apply the patch, simply click&nbsp;<strong>Apply</strong>&nbsp;and it will apply the patch. The available link for the patch will then change to say&nbsp;<strong>Revert</strong>&nbsp;instead. To revert, click&nbsp;<strong>Revert</strong>.</p>



<p>More information: <a href="https://docs.netgate.com/pfsense/en/latest/development/system-patches.html">https://docs.netgate.com/pfs…</a></p></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/">https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/</a></em></p>]]>
            </description>
            <link>https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236796</guid>
            <pubDate>Tue, 23 Feb 2021 13:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26236726">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236726</guid>
            <pubDate>Tue, 23 Feb 2021 12:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to Programming with ECMA-55 Minimal BASIC [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236686">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://buraphakit.sourceforge.io/Learn_BASIC.pdf | <a href="https://web.archive.org/web/*/https://buraphakit.sourceforge.io/Learn_BASIC.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://buraphakit.sourceforge.io/Learn_BASIC.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236686</guid>
            <pubDate>Tue, 23 Feb 2021 12:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Switching from C# to Go for back end development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26236527">thread link</a>) | @zachruss92
<br/>
February 23, 2021 | https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe | <a href="https://web.archive.org/web/*/https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236527</guid>
            <pubDate>Tue, 23 Feb 2021 12:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developer Experience: How to Define Good Documentation?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236451">thread link</a>) | @thenoisywatcher
<br/>
February 23, 2021 | https://humanitec.com/blog/developer-experience-documentation | <a href="https://web.archive.org/web/*/https://humanitec.com/blog/developer-experience-documentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href=""><p>There are many projects, products, and services to choose from when making decisions about the tools you and your team use.&nbsp;</p><p>One of the aspects many of us look at to help assess if a tool is useful to us is the documentation, but how do you judge what good documentation is?&nbsp;</p><p>A tool might offer exciting features, yet, the <a href="https://humanitec.com/blog/developer-experience">developer experience</a> of the documentation might be lacking. When evaluating a new tool, the developer experience matters as much as the offered features.&nbsp;</p><p>This post aims to help you identify key factors to look for, how that might reflect on the project, and how well it will meet your expectations.&nbsp;</p><h2><strong>Onboarding and Getting Started</strong></h2><p>If you are learning about a new tool, then the getting started guide for any project is typically the first document you read.&nbsp;</p><p>A bad experience with it is likely to put any casual reader off of investigating further. First impressions matter, so below are four factors to look for when evaluating the getting started experience for documentation.&nbsp;</p><h3><strong>Self-serve option available</strong></h3><p>Trying the time-honored “getting started guide” is typically the first point of call for developers assessing a new technical tool. There are some tools (especially in the SaaS world) that rely on onboarding you through a front end first and taking you through the first steps from there instead.</p><p>In either case, prioritize tools that allow you to create an account and test yourself without the need to make an appointment with a sales representative or fill in excessive forms.&nbsp;</p><p>There might be some valid reasons for doing this, such as a private beta or that the project is new. But often, it’s purely to force you through a sales process and bombard you with sales messages. This isn’t directly related to documentation, but often you also can’t view documentation until you are through this process, which makes it hard to evaluate at all.</p><h3><strong>Time to getting started</strong></h3><p>If you evaluate multiple options, then how long it takes you to follow a getting started guide from the beginning to a satisfactory conclusion is one measure to measure by.&nbsp;</p><p>While the real time can depend a lot on the tutorial’s complexity, for comparable tools or guides, a shorter time is a good sign that the team has spent time reducing barriers, testing steps, and checking that the language they used is clear.</p><h3><strong>Real-world examples</strong></h3><p>Getting started guides tend to focus on simplicity and speed. Often this is intentional to make a tool appear “easy” to use. However, if the examples and steps the guide follows are unrealistic for any “real world” use case for the tool, then is it a good getting started guide?</p><h3><strong>Dependencies and Prerequisites</strong></h3><p>Certain programming languages are notorious for having deep and complex dependency trees. This means that a project might leverage code from a 3rd party (which is common), but then that tool also has its dependencies.&nbsp;</p><p>Following a getting started guide should not have to take you down a complex path of conflicting dependency versions or surprising undocumented prerequisites you have to figure out. This can show that the developers or writers of the documentation have not tested examples from scratch on a “vanilla” new user set up.</p><p>Ideally, a project should work with the most popular or most supported (and <a href="https://itsfoss.com/long-term-support-lts/">LTS</a>, for example) versions of languages and operating systems. If they don’t, it can show a lack of meaningful commitment to development or specific platforms.&nbsp;</p><p>At the least, the documentation should state which versions you need and a rough idea of when to expect support for newer or more popular versions.</p><h2><strong>Continuing the journey</strong></h2><p>A great getting started guide is a big plus for any project you are evaluating, but rarely does a getting started guide help you apply anything to a real-world production application.&nbsp;</p><p>One of the hardest parts of creating documentation is taking a reader on this crucial journey, and it’s generally where most people get frustrated with documentation. Some projects have a much clearer and defined use case than others (for example, a payment API versus a CMS), but there are some general things to look for.</p><p>A good getting started guide should suggest common pages or paths for you to follow next. These could be generic, such as key components of the tool, finding further information on a feature, or following typical use cases based on user research. It’s near impossible for documentation to suit every possible use you might have, but it can help you assemble the knowledge you need.</p><h2><strong>Code examples</strong></h2><p>Not wanting to disappoint anyone reading this who writes documentation, but it’s an adage that developers often don’t read the documentation thoroughly but rather scan for code examples. Good documentation is structured to ensure that important text surrounds code examples, so there is more chance you notice it.</p><p>Code examples are often a source of annoyance for anyone reading documentation, and I’m sure you have come across one that is incomplete or doesn’t work.</p><p>There are different types of code examples, and in each case, their purpose should be clear.</p><p>Some code examples are part of a tutorial or guide, and we expect the reader to follow them in order and build a full piece of code that works as expected. In these cases, the examples should tell you all you need to know and not leave anything to assumption to result in a working example.</p><p>Some code examples are illustrative to show a concept or implementation detail, which means they do not work without replacing placeholder values or extra code. Documentation should make these clear and suggest what you need to do to make them usable.</p><p>While not always necessary, documentation should explain or show you the expected output for code examples, so you know that you have implemented it successfully.</p><p>Finally, if a project supports multiple programming languages or implementation options, then the documentation should show code examples for all of these. However, this is a lot of work, but examples for the most widely used options are essential, and guidance on using the other supported options enough.</p><h2><strong>Reference - SDK and API documentation</strong></h2><p>Filling in the documentation gaps is generally the role of reference documentation, which includes <a href="https://humanitec.com/blog/api-design-developer-experience">API endpoint and function documentation</a>, architecture explanations, and other aspects of the project readers might find useful to know if they need to.</p><p>Firstly, is reference documentation available, or do you need to dig through the codebase to find it? If it does exist, how complete or useful is it? Often teams autogenerate reference documentation, and that’s fine, but often descriptions come from code comments, and code comments are not always useful to a reader.&nbsp;</p><p>Reference documentation can be more abstract than other documentation as it describes individual pieces of a project instead of how to use them. However, good reference documentation still explains what that piece is and how it works. Below you find an excellent example.</p><figure><p><img src="https://assets.website-files.com/5c73bbfe3312822f153dd310/6023d59ff38a1ca95194dac2_fwHv1JPLySGuL3x-MsQM8fo9jSQXt7_6cy_dpa4XYC0hbVaFivRkKmXRLCJcHbyLZ12kmRxtQlmEbqI7V8jK4pAgGZE4_V0DeY1m1hr4UTM-EP2hT_piRUjG5o_jYTxXARVD0Z4l.png" alt=""></p><figcaption>Source: <a href="https://lisk.io/documentation/lisk-sdk/references/lisk-elements/cryptography.html#stringtobuffer">Lisk SDK documentation</a></figcaption></figure><p>‍</p><p>The <a href="https://stripe.com/docs/api">Stripe API documentation</a> is a common example of useful and usable autogenerated (but using highly customized tooling) API documentation. Not wanting to publicly shame any project, this tweet from Ricardo Ferreira sums up the problem with documentation generated from comments perfectly.</p><p>‍<br></p><h2><strong>Language</strong></h2><p>Good language is a big topic, and it doesn’t necessarily affect the quality of a project. It can show that the team behind it goes the extra mile to care, which is a good sign.</p><p>Acceptable documentation should be free of spelling mistakes and other typographical errors. Excellent documentation should use a consistent voice, terminology, and style. What constitutes “correct” in these cases is personal and opinionated, but consistency is key.</p><p>There are a handful of popular and commonly used style guides, such as the <a href="https://developers.google.com/style/">Google</a> and <a href="https://docs.microsoft.com/en-us/style-guide/welcome/">Microsoft</a> style guides. Whether that documentation follows one of these style guides over another, or its own custom style guide is not what’s important. However, if a company follows a style guide, it shows they have given that extra thought and care to their documentation.</p><h2><strong>Bonus points</strong></h2><p>These discussion points don’t quite fit into any of the sections above but show that a team has an extra eye for detail.</p><p>How does the documentation look? Something that looks fantastic and uses the latest tricks in web development may not equal useful and useable documentation, but if it’s both of those, then even better.</p><p>How often is the documentation updated? There are some good reasons for not updating documentation regularly, such as an older project or problem-free documentation, but it can also indicate a dormant project that’s best avoided.<br></p><h2>Good documentation shows a team cares</h2><p>We all know that documentation is hard, especially for solo developers or smaller teams who also need to focus on features and bug fixes. However, when there are many options to choose from when evaluating new tools, frameworks, and services, and sometimes weighing them up on features alone is inconclusive. Therefore, the documentation’s developer experience matters.</p><p>Good developer experience and documentation indicate how much a team and community involved with a project care about their users. More importantly, it indicates how much work could be involved in implementing projects you are evaluating.&nbsp;</p><p>If tutorials are poorly written, or don’t make sense. If code examples don’t work, or important details are lacking. Will you find similar problems and a lack of concern in a project after investing your time and business in it?<br></p></div></div>]]>
            </description>
            <link>https://humanitec.com/blog/developer-experience-documentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236451</guid>
            <pubDate>Tue, 23 Feb 2021 12:20:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python strings work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26236424">thread link</a>) | @r4victor
<br/>
February 23, 2021 | https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>In 1991 Guido van Rossum released the first version of the Python programming language. About that time the world began to witness a major change in how computer systems represent written language. The internalization of the Internet increased the demand to support different writing systems, and the Unicode Standard was developed to meet this demand. Unicode defined a universal character set able to represent any written language, various non-alphanumeric symbols and, eventually, emoji 😀. Python wasn't designed with Unicode in mind, but it evolved towards Unicode support during the years. The major change happened when Python got a built-in support for Unicode strings – the <code>unicode</code> type that later became the <code>str</code> type in Python 3. Python strings have been proven to be a convenient way to work with text in the Unicode age. Today we'll see how they work behind the scenes.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>The scope of this post</h2>
<p>This post doesn't try to cover all aspects of text encoding in relation to Python. You see, programming language designers have to make several text encoding decisions because they have to answer the following questions:</p>
<ul>
<li>How to talk to the external world (the encodings of command-line parameters, environment variables, standard streams and the file system).</li>
<li>How to read the source code (the encoding of source files).</li>
<li>How to represent text internally (the encoding of strings).</li>
</ul>
<p>This post focuses on the last problem. But before we dive into the internals of Python strings, let's briefly discuss the problem of text encoding on a real life example and clarify what Unicode really is.</p>
<h2>The essence of text encoding</h2>
<p>You see this text as a sequence of characters rendered by your browser and displayed on your screen. I see this text as the same sequence of characters as I type it into my editor. In order for us to see the same thing, your browser and my editor must be able to represent the same set of characters, that is, they must agree on a <strong>character set</strong>. They also need to choose some, possibly different, ways to represent the text internally to be able to work with it. For example, they may choose to map each character to a unit consisting of one or more bytes and represent the text as a sequence of those units. Such a mapping is usually referred to as a <strong>character encoding</strong>. A character encoding is also crucial for our communication. Your browser and my web server must agree on how to <strong>encode</strong> text into bytes and <strong>decode</strong> text from bytes, since bytes is what they transmit to talk to each other.</p>
<p>The character set that your browser and my editor use is Unicode. Unicode is able to represent English as well as any other written language you can think of (文言, Čeština, Ελληνικά, עברית, हिन्दी), 日本語, Português, Русский) and thousands of miscellaneous symbols (₤, ⅐, ↳, ∭, ⌘, , ♫, 👨🏼‍💻, 🍺) . My web server sends this text as a part of the HTML page in the UTF-8 encoding. You browser knows which encoding was used to encode the text because the <code>Content-Type</code> HTTP header declares the encoding:</p>
<div><pre><span></span>Content-Type: text/html; charset=utf-8
</pre></div>


<p>Even if you save this HTML page locally, your browser will still be able to detect its encoding because the encoding is specified in the HTML itself:</p>
<div><pre><span></span><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;</span><span>html</span> <span>lang</span><span>=</span><span>"en"</span><span>&gt;</span>
<span>&lt;</span><span>head</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>charset</span><span>=</span><span>"utf-8"</span> <span>/&gt;</span>
    <span>&lt;!-- ... --&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</pre></div>


<p>This may seem absurd to you. How can a browser decode the HTML to read the encoding if it doesn't know the encoding yet? This is usually not a problem in practice because the beginning of an HTML page contains only ASCII characters and most encodings used on the web encode ASCII characters in the same way. Check out the <a href="https://html.spec.whatwg.org/multipage/parsing.html#concept-encoding-confidence">HTML standard</a> to learn more about the algorithm that browsers use to determine the encoding.</p>
<p>Note that the HTTP header and the HTML metatag specify "charset", i.e. a character set. This may seem confusing since UTF-8 is not a character set. What they really specify is a character encoding. The two terms are often used interchangeably because character encodings typically imply a character set of the same name. For example, the ASCII character encoding implies the ASCII character set. The Unicode Standard fixes the terminology by giving precise definitions to all important terms. We'll study them, but before, let's discuss why and how the Unicode project began.</p>
<h2>The road to Unicode</h2>
<p>Before the adoption of Unicode, most computer systems used the <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> character encoding that encodes a set of 128 characters using a 7-bit pattern to encode each character. ASCII was sufficient to deal with English texts but that's about it. Other character encodings were developed to support more languages. Most of them <a href="https://en.wikipedia.org/wiki/Extended_ASCII">extended ASCII</a> to 256 characters and used one byte to encode each character. For example, the <a href="https://en.wikipedia.org/wiki/ISO/IEC_8859">ISO 8859</a> standard defined a family of 15 such character encodings. Among them were:</p>
<ul>
<li>Latin Western European ISO 8859-1 (German, French, Portuguese, Italian, etc.)</li>
<li>Central European ISO 8859-2 (Polish, Croatian, Czech, Slovak, etc.)</li>
<li>Latin/Cyrillic ISO 8859-5 (Russian, Serbian, Ukrainian, etc.)</li>
<li>Latin/Arabic ISO 8859-6</li>
<li>Latin/Greek ISO 8859-7.</li>
</ul>
<p>Multi-lingual software had to handle many different character encodings. This complicated things a lot. Another problem was to choose the right encoding to decode text. Failing to do so resulted in a garbled text known as <a href="https://en.wikipedia.org/wiki/Mojibake">mojibake</a>. For example, if you encode the Russian word for mojibake "кракозябры" using the <a href="https://en.wikipedia.org/wiki/KOI8-R">KOI-8</a> encoding and decode it using ISO 8859-1, you'll get "ËÒÁËÏÚÑÂÒÙ".</p>
<p>The problems with different character encodings are not gone completely. Nevertheless, it became much more easier to write multi-lingual software nowadays. This is due to two independent initiatives that began in the late 1980s. One was <a href="https://en.wikipedia.org/wiki/Universal_Coded_Character_Set">ISO 10646</a>, an international standard, and the other was Unicode, a project organized by a group of software companies. Both projects had the same goal: to replace hundreds of conflicting character encodings with a single universal one that covers all languages in widespread use. They quickly realized that having two different universal character sets wouldn't help achieve the goal, so in 1991 the Universal Coded Character Set (UCS) defined by ISO 10646 and Unicode's character set were unified. Today the projects define essentially the same character encoding model. Nevertheless, both continue to exist. The difference between them is that the Unicode Standard has a greater scope:</p>
<blockquote>
<p>The assignment of characters is only a small fraction of what the Unicode Standard and its associated specifications provide. The specifications give programmers extensive descriptions and a vast amount of data about the handling of text, including how to:</p>
<ul>
<li>divide words and break lines </li>
<li>sort text in different languages </li>
<li>format numbers, dates, times, and other elements appropriate to different locales </li>
<li>display text for languages whose written form flows from right to left, such as Arabic or Hebrew </li>
<li>display text in which the written form splits, combines, and reorders, such as for the languages of South Asia </li>
<li>deal with security concerns regarding the many look-alike characters from writing systems around the world</li>
</ul>
</blockquote>
<p>The most important thing that we need to understand about Unicode is how it encodes characters.</p>
<h2>Unicode basics</h2>
<p>Unicode defines <strong>characters</strong> as smallest components of written language that have semantic value. This means that such units as diacritical marks are considered to be characters on their own. Multiple Unicode characters can be combined to produce what visually looks like a single character. Such combinations of characters are called <strong>grapheme clusters</strong> in Unicode. For example, the string "á" is a grapheme cluster that consists of two characters: the Latin letter "a" and the acute accent "´". Unicode encodes some grapheme clusters as separate characters as well, but does that solely for compatibility with legacy encodings. Due to combining characters, Unicode can represent all sorts of grapheme clusters such as "ä́" and, at the same time, keep the character set relatively simple.</p>
<p>Unicode characters are abstract. The standard doesn't care about the exact shape a character takes when it's rendered. The shape, called a <strong>glyph</strong>, is considered to be a concern of a font designer. The connection between characters and glyphs can be quite complicated. Multiple characters can merge into a single glyph. A single character can be rendered as multiple glyphs. And how characters map to glyphs can depend on the context. Check out the <a href="https://www.unicode.org/reports/tr17/#CharactersVsGlyphs">Unicode Technical Report #17</a> for examples.</p>
<p>Unicode doesn't map characters to bytes directly. It does the mapping in two steps:</p>
<ol>
<li>The <strong>coded character set</strong> maps characters to code points.</li>
<li>A <strong>character encoding form</strong>, such as UTF-8, maps code points to sequences of code units, where each code unit is a sequence of one or more bytes.</li>
</ol>
<p>The Unicode coded character set is what we usually mean when we say Unicode. It's the same thing as the UCS defined by ISO 10646. The word "coded" means that it's not actually a set but a mapping. This mapping assigns a code point to each character in the character set. A <strong>code point</strong> is just an integer in the range [0, 1114111], which is written as U+0000..U+10FFFF in the Unicode hexadecimal notation and is called a <strong>code space</strong>. The current Unicode 13.0 assigns code points to 143,859 characters.</p>
<p>Technically, the coded character set is a <a href="https://www.unicode.org/charts/">collection of entries</a>. Each entry defines a character and assigns a code point to it by specifying three pieces of information:</p>
<ul>
<li>the code point value</li>
<li>the name of the character; and</li>
<li>a representative glyph.</li>
</ul>
<p>For example, the entry for the letter "b" looks like this: (U+0062, LATIN SMALL LETTER B, b).</p>
<p>The standard also specifies various character properties such as whether the character is a letter, a numeral or some other symbol, whether it's written from left-to-right or from right-to-left and whether it's an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/">https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236424</guid>
            <pubDate>Tue, 23 Feb 2021 12:16:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore History Part 1: The Commodore Pet]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26236320">thread link</a>) | @SQL2219
<br/>
February 23, 2021 | http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/ | <a href="https://web.archive.org/web/*/http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4839">
														
							
														
							
														
							<div>
															<div>
									<p>When you watch documentaries about early computer innovations, particularly the late 70s, early 1980s, most of the documentaries tend to focus on Apple and Microsoft, and maybe IBM as the big innovators. But, I think often companies like Commodore, and Atari, and Tandy don’t get nearly enough credit for the role that they played.&nbsp; Let’s take a look at the Commodore PET!</p>
<p>Most of my readers are familiar with the Commodore 64, one of the best selling computers of all time. Well renowned for its great graphics and sound, but Commodore history didn’t start with this machine. So, let’s go back a little bit to the late 1970s and figure out where it all started!</p>
<h2>Commodore History Part 1 Video</h2>
<p><iframe src="https://www.youtube.com/embed/eP9y_7it3ZM" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2>The Processor that Started it All</h2>
<p>It all began in 1974 when Chuck Peddle and a group of engineers started up a chip fabrication company called MOS Technology. Most of these guys had worked at Motorola on the 6800 processor, and so they set out to develop a compatible CPU known as the 6501 that could simply be substituted for the much more expensive Motorola CPU. As you might imagine, Motorola sued and to make a long story short, the 6502 was born, which was pretty much the same chip but changed just enough that it was no longer completely compatible with the 6800.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png"><img data-attachment-id="4855" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0002-the-6502-was-born/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0002 – The 6502 was born" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=750%2C422" alt="The 6502 Processor" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Since the chip was no longer compatible with the 6800, customers would need some way to test the chip. In 1976 Chuck Peddle also designed the KIM-1 development computer. This was a single board computer that used the 6502, and could be programmed in machine language from the keypad on the top. However, later it was possible to connect a dumb-terminal display and actually run BASIC. Programs could be saved to a cassette tape. The computer proved to be popular with hobbyists as well as engineers.</p>
<p>The 6502 would go on to be a huge success and eventually found its way into the Apple II series, the Atari 2600, the Nintendo Entertainment System, the entire line of Atari 8-Bit computers, the BBC Micro, and of course the entire line of Commodore 8-Bit machines. But back to 1976 for the moment. MOS Technologies was bought up by Commodore Business Machines, who at this point was primarily in the calculator business. Chuck Peddle managed to convince Commodore boss Jack Tramiel that calculators were a dead-end business and that they needed to produce a computer to compete with the upcoming Apple II.</p>
<h2>The MOS Technology KIM-1</h2>
<p>In 1977 the Commodore PET 2001 was born, using much of the same design as the KIM-1. Much like the Apple II, the PET was all inclusive, having an integrated monitor, keyboard, and cassette tape storage device. 1977 was a big year for the personal computer revolution. With the market introduction of the big 3, the Apple II, Commodore PET, and TRS-80 computer, it was the first time that a regular person could buy an affordable computer without having to assemble it themselves.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png"><img data-attachment-id="4856" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0003-the-kim-1/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0003 – The KIM 1" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The cool thing about the PET is that it was actually designed by the same guy who designed the 6502 processor. If you look at the prices of the big 3, you’ll see the PET was competitively priced. Although the Apple II did have superior hardware, which we’ll get into shortly, the PET did have the advantage that it came with a monitor and tape drive, where the Apple II required those as separate purchases.</p>
<h2>A Closer Look at the PET</h2>
<p>Let’s take a closer look at the design of the Commodore PET. The first thing I want to draw your attention to is the keyboard. It’s insane, and it will drive you insane if you actually try to type on it. One thing that isn’t communicated well by video and pictures is just how small this keyboard is. The main part, excluding the number pad measures just 6in. by 2.75in. Just to put that into perspective, my iPhone 6 will essentially cover the entire keyboard. The Apple mini keyboard is actually huge by comparison.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png"><img data-attachment-id="4857" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0004-the-pet-keyboard/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0004 – The PET Keyboard" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=750%2C422" alt="the pet keyboard" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The keyboard size isn’t the only problem. They layout is crazy. While the keys are technically in a QWERTY arrangement, normally the rows are offset creating diagonal lines. Not so on the PET. They are squared up. The weirdness doesn’t end there. The space bar is tiny! Normally you would expect numbers across the top row of keys, but there aren’t any. Instead you have just symbols. If you want to type a number, you have to use the number pad.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png"><img data-attachment-id="4859" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0005-the-pet-keyboard-will-drive-you-insane/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0005 – The PET Keyboard will drive you insane" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=750%2C422" alt="PET keyboard is insane" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>What is even more infuriating is the symbols. For example, if I want to type a Dollar sign or a number sign, I would instinctively press shift before the key. However, when I do that I wind up with a totally different character instead of the one I wanted. Then there’s the cursor keys. Notice that there are only 2 of them. One key cursors down, and the other key cursors right. If you want to reverse that, you have to hold down the shift key. So by using the combination of the cursor keys and shift you can cursor anywhere on the screen.&nbsp; The little back arrow? You might think that’s a backspace key. But, it’s not. It actually prints that character on the screen, and so when you make a mistake, and believe me you will, you’re going to go to push this key and it’s not going to fix your mistake and you’re going to go even more insane than you were before. The actual delete key is all the way over at the other side of the number pad.</p>
<p>To be fair, when this computer came out in 1977, most of the customers had never even used a personal computer before or a computer of any kind and so they didn’t have any pre-conceptions for what a keyboard layout should be – like we do today. It probably wasn’t quite as weird for them as it would be for us.</p>
<h2>Opening the Commodore PET</h2>
<p>Let’s take a look inside the PET, it opens like the cab of a semi truck, and even gives you a little kick stand to hold it open. Looking at these 16 RAM chips, you might think the PET came with a lot of RAM. But, you’d be wrong. The original PET only came with 4K of RAM. These are 1K by 4-bit static RAM chips. Being that cost was such a consideration for this computer, you might be wondering why they didn’t use the cheaper dynamic RAM, or DRAM? Well, static ram was and still is today much more expensive than dynamic RAM. However, DRAM has one drawback, it requires that it is refreshed every so often, which requires additional circuitry to handle that. When you’re dealing with only 4K, it actually ended up being cheaper just to use static RAM.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png"><img data-attachment-id="4860" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0006-opening-the-pet/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0006 – Opening the PET" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=750%2C422" alt="opening the PET" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>OK. So 4K is a ridiculously small amount or RAM, but it’s worse than that because the operating system actually needs at least 1K of that, leaving about 3K left over for the user. So how much is 3K of RAM? Well, the screen on the pet is 40-characters by 25-lines, meaning you need 1,000 bytes of RAM, or almost an entire kilobyte just to store one screen full of text. Essentially you had enough RAM for about 3 screens of text! To be fair though, the Apple II and TRS-80 only had 4K when they came out as well.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png"><img data-attachment-id="4861" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0007-the-pet-ram-chips/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0007 – The PET RAM chips" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=750%2C422" alt="PET RAM chips" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>This particular PET has been upgraded a little daughter board. It’s an aftermarket 32K RAM expansion module, and that’s why it shows 31K available to BASIC on the boot screen. Let’s take a closer look at this cassette drive. This was actually just an off-the-shelf cassette recorder that Commodore bought and slightly modified. You can see the whole unit is actually mounted, in a rather clunky way in my opinion. The cassette drive was really the only storage device available for the PET at first. And with 4K of RAM, this wasn’t much of a problem.</p>
<h2>The PET Disk Drives</h2>
<p>It wasn’t until 1979 that Commodore came out with a matching disk drive. Since the PET was never really designed to use a disk drive, they decided to use the IEEE-488 parallel port as a means to connect the disk drive.&nbsp; Unlike the Apple II, the Commodore PET has no card slots inside so there’s nowhere to add a floppy disk controller card. So, what they had to do was essentially design an entire computer inside the floppy drive unit, which would handle controlling the floppy drives as well as an entire disk operating system.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png"><img data-attachment-id="4862" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0001-the-pet-8050-disk-drive/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0001 – The PET 8050 Disk Drive" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Indeed if you take a look inside the disk drive, you’ll see it’s quite sophisticated, having it’s own 6502 processor, RAM, ROM, and I/O controllers. The PET didn’t really interact with information on the disks directly, rather it would send commands to the disk drive, such as telling it to fetch a file, and then the disk drive would take care of all of the work of finding the right data on the disk. In fact, it could even copy files or even entire disks from one drive to the other all by itself, just with a single command.</p>
<p>The PET was popular with schools and found its way into many computer labs. And while the disk drive was expensive, one of these floppy drive units could actually be connected to multiple PETs at the same time, thus saving space and money. In fact, you can see this arrangement being used in this photo from a computer lab where each table has 8 PETs connected to a single floppy drive and printer.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png"><img data-attachment-id="4863" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0010-the-pet-8080-disk-drive-chained/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0010 – The PET 8080 Disk Drive chained" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=750%2C422" alt="chained PETs to disk drives" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<h2>The Commodore PET’s Display</h2>
<p>Let’s talk about the screen on the PET. The original model here is black and white. A lot of people assume it’s green, but that actually wasn’t until later models. The original one was black and white. In fact, there’s not even any grayscale. It’s just literally two colors, black and white. The screen was controlled by a clone of the Motorola 6845 CRT controller, which was also used in the IBM CGA card, among other computers. However, there was no circuitry here for color.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png"><img data-attachment-id="4883" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0025-the-commodore-pet-black-and-white-display/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0025 – The Commodore PET Black and White Display" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=750%2C422" alt="Commodore PET Display" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>There are also no graphics modes. I mean, literally <em>none</em>. There is no way to put graphics on this machine at all. And what’s worse is that the character set is in ROM and it cannot be moved, so there’s no way to modify what the characters look like. So, you are pretty much stuck with putting characters on the screen and only the characters that came built into ROM. And that’s it.</p>
<h2>PETSCII</h2>
<p>However, there are 256 characters using a special character set called PETASCII or later just shortened to PETSCII. The character …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</a></em></p>]]>
            </description>
            <link>http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236320</guid>
            <pubDate>Tue, 23 Feb 2021 12:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey into Game Development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236081">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://blog.tuxedolabs.com/2021/02/22/background.html | <a href="https://web.archive.org/web/*/https://blog.tuxedolabs.com/2021/02/22/background.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I often get the question how I got into game development and if I have any tips for beginners. Here’s my story and thoughts about getting into game development.</p>


<p>I’ve never been particularly interested in playing games myself. I never had a gaming console as a kid, but ever since I was very young I’ve had a strong interest in engineering and technology. My early interest in computers was entirely centered around programming, and not playing games.</p>

<p>I somehow convinced my parents to get me a Commodore VIC 64, because that was what one of my friends had. I’m not sure how old I was, but I must have been eleven or twelve. Back then, the printed manual for a computer was an introduction to programming (BASIC, in this case). When turning the computer on, there was a prompt where you could start programming. Overall, the bar to enter programming was way lower than now. No choice of programming language, no game engine, no downloading and installing stuff, you just turned the computer on and could instantly start programming (like, literally instantly, the interpreter was burnt into a ROM chip).</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-vic64.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-vic64.jpg" alt=""></a></p>

<p>Programming languages sucked, performance was terrible and debuggers non-existent. If you made an error, the computer froze and you had to turn it off and back on again and start over. It was frustrating, tedious and very unintuitive, but at the same time an excellent introduction to how computers work. In order to put a sprite on the screen, you had no choice but to map out each pixel on paper, learn binary numbers, convert that to decimal and load it into a specific memory address. Since there were no tools, everything was cumbersome, but at the same time, everything also seemed within reach without having to learn that much. There was only one way to do things – the hard way.</p>

<p>A few years later I upgraded to a Commodore Amiga 1000 and a whole new world opened up. This was much more similar to computers as we know them today, with a proper desktop, multi-tasking, a file system, etc. It shipped with a programming language (AmigaBASIC), but for some reason I never really got into it. Instead, I got introduced to the AMOS programming language, which I remember as an absolutely fantastic environment for learning to make games. It had a lot of built-in functionality for doing the most basic things, like loading images, playing sounds, drawing lines, etc. It also had the ability to execute inline assembly code which made it very powerful.</p>

<p>Getting better at programming and learning the hardware I got more and more comfortable programming directly in assembly language instead of AMOS and finally swithed over to using AsmOne as my default programming environment. In retrospect this was a terrible move, because writing everything in assembly language is overly complicated compared to using something like C and just use with assembly were needed. I think this poor decision was mostly because I simply didn’t know that C existed, nor how to combine it with assembly. Remember that this was before the Internet was a thing, so the only knowledge you had access to was through your friends and good dose of curiosity and trial-and-error.</p>


<p>There were no game educations available in Sweden at the time, and I’m not sure I would have chosen one even if there was. At this point I had not decided on a career in game development, maybe because game development wasn’t really seen as a career option at all, so I went for a more traditional engineering program – Master of Science in Media Technology at Linköping University. This is where I first got in contact with object oriented programming through Java and later C++. I took classes in linear algebra, data structures, 3D rendering, physical modelling and animation, physics, acoustics, etc. It was definitely a good foundation for a game developer, even though this wasn’t a game centric education.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-imp.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-imp.jpg" alt=""></a></p>

<p>It was at university I developed a passion for game physics. I can’t remember exactly what caught my attention, but I wrote my first rigid body simulator in 1998, inspired by the papers on impulse based dynamics by Brian Mirtich. At this time physics was rarely seen in video games. The only one I remember studying intensely was Carmageddon 2, which featured incredibly sophisticated rigid body simulation for a game at that time. My first simulator was written in Java, with collision detection in C through the JNI interface. It was later rewritten in C++ and featured a wrecking ball machine at a building site.</p>


<p>For the final exam project at Linköping University I decided to make a game physics SDK with Marcus Lysén. It never really reached a usable state, but was enough to encourage us to form a company around it and develop it further. We teamed up with Jonas Lindqvist and founded Meqon Research. Around the same time, other physics SDKs started popping up. The first verison of Havok got released. Mathengine was already on the market, and there was Ipion (mostly known for being used in half-life 2), PhysX by Novodex, and the open source project ODE. Even though I wouldn’t admit it at the time, we had the weakest product, no experience and no money, but somehow we managed to release the Meqon SDK a few years later and got a couple of customers. Most notably 3D Realms licensed our technology for Duke Nukem Forever, which gave us the confidence and credibility to push forward and grow the team to about a dozen people. All in all a very fun and intense period of my career, but completely unsustainable, stressful and unhealthy.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-meqon.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-meqon.jpg" alt=""></a></p>

<p>In 2005, Meqon was acquired by AGEIA and the whole team was integrated into the PhysX machinery. I worked as one of three software architects and got the chance to work with some incredibly talented people across the world, many of them I’m still in contact with today. This was a fantastic journey and undoubtedly an important cornerstone of my career. The people I worked with at AGEIA also influenced my coding style in a very important way. Coming from an academic, object oriented programming background, I started to question everything when I got in contact with experienced game developers who routinely rejected most of that in favor of a more direct C-like programming style that I slowly started adopting myself and still use today.</p>

<p>I left AGEIA in 2007, just before they got acquired by NVIDIA to work on scientific visualization. At this point I also started working on my own C++ framework to use for future projects. It wasn’t a game engine, but more of a low level framework with the functionality needed to make a game engine, such as vector math, file IO, compression, geometry, input, audio, rendering, scripting, etc. Creating your own tech was already at the time considered doomed to failure (even more so today), but doing it was a lot of fun and was undoubtedly an important key decision in my career. With a programming framework that I wrote from scratch, thus knowing inside out, I could very quickly implement new ideas and projects on top of that without ever running into any limitations.</p>

<p>One of the first projects I created with the new framework was Dresscode, a game engine profiling tool that I later sold to RAD Game Tools (now reworked into a product called Telemetry). Even if the framework has been rewritten and improved upon in several iterations, I’m still using it today for almost everything I do.</p>


<p>Up until this point I never really made an actual, released game, but that changed in 2010, when I teamed up with Henrik Johansson (one of the people I hung out with in the Amiga days) and founded Mediocre. Going from game technology and middleware to making actual games was equal parts fun and frustration. I had no experience with game design, but started appreciate it more than I thought I would. An interesting thing to note here is that both Henrik I had very little interest in playing games. We were not gamers, which I think is quite unusual for game developers, but it is my firm belief that playing games is orthogonal to being successful at making them. There are great developers who play a lot of games and there are great developers who never play games. Playing a lot of games is not a bad thing, but it does not make you good at making them, it makes you good at playing them (and this probably applies to a lot more than game development).</p>

<p>We did our first game, Sprinkle, as a part-time project while still doing contract work on the side to sustain our living and I think this was a really wise decision which allowed us to experiment and iterate on the game design to find something unique, with no real time pressure. It also allowed us to spend that extra time polishing the game prior to release.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-sprinkle.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-sprinkle.jpg" alt=""></a></p>

<p>I think the primary reason Sprinkle became successful was because we found something uniqe, but as always it’s hard to pinpoint one single factor. We had good timing, both because the App Store and mobile gaming in general was still young, and not very exploited, but also because there was a general interest in indie games at the time. Previous connections from NVIDIA and Meqon also contributed to getting us introduced to Apple and Google prior to release, thus increasing our chances of getting featured.</p>

<p>There’s a lot more to the story, including the other Mediocre games and everything that led up to Teardown, but I think I’ll stop here, since at this point I’m already a full-time indie game developer.</p>


<p>For learning programming and game development today I don’t really feel like I’m in a position to give beginner advice, because the conditions today are so different from when I started, but for programming in particular, it is my firm belief that experience is the most important factor. Write a lot of code and you’ll eventually get good at it. A good way to do this is to find a way to enjoy it rather than just trying to learn it. My career took a giant leap when I finally embraced that and focused on what I love the most – doing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tuxedolabs.com/2021/02/22/background.html">https://blog.tuxedolabs.com/2021/02/22/background.html</a></em></p>]]>
            </description>
            <link>https://blog.tuxedolabs.com/2021/02/22/background.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236081</guid>
            <pubDate>Tue, 23 Feb 2021 11:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saving the World with Bayesian Modeling]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26235876">thread link</a>) | @twiecki
<br/>
February 23, 2021 | https://www.pymc-labs.io/blog-posts/saving-the-world/ | <a href="https://web.archive.org/web/*/https://www.pymc-labs.io/blog-posts/saving-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

    <div>
        <div>
            <div>
                
                <div>
                    
                        <h4>Saving the world with Bayesian modeling</h4>
                    
                    <p>After I left Quantopian in 2020, something interesting happened: various companies contacted me inquiring about
consulting to help them with their PyMC3 models.</p>
<p>Usually, I don't hear how people are using <a href="https://docs.pymc.io/">PyMC3</a> -- they mostly show up on
<a href="https://github.com/pymc-devs/pymc3">GitHub</a> or <a href="https://discourse.pymc.io/">Discourse</a> when something isn't working
right. So, hearing about all these really cool projects was quite exciting. However, I couldn't possibly take all of
these projects on by myself.</p>
<p>Thus, it was time to assemble a team of the most badass Bayesian modelers the world had ever seen -- the Bayesian
Avengers, if you will. Fortunately, I did not have to venture far, as PyMC3 had already attracted exactly these types
of people.</p>
<p>This brings me to the Big Announcement: For the last few months, we have quietly been building
<a href="https://pymc-labs.io/">PyMC Labs</a>, a Bayesian modeling consultancy.
<a href="https://www.pymc-labs.io/team/">We have an amazing team</a> consisting of three neuroscience PhDs, mathematicians,
social scientists, a SpaceX rocket scientist, and the host of the famous
<a href="https://www.learnbayesstats.com/">‘Learning Bayesian Statistics’ podcast</a>. All of us are united in our mission:</p>
<blockquote>
    <p>Saving the world with Bayesian modeling</p>
    
</blockquote><p>Does this sound a bit grandiose? Probably. Is this true? I firmly believe it is. There are so many important problems
the world faces today -- from climate change to COVID19, from education to poverty -- and Bayesian modeling can play a
critical role in solving these problems. Let me explain why.</p>
<h2 id="it-is-already-doing-it">It is already doing it</h2><p>I would not have imagined it when I started contributing to PyMC, but the science PyMC3 has directly enabled ranges
from <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=pymc3+climate&amp;btnG=">climate science</a> and biology to
astronomy and zoology, and everything in between.</p>
<p>For instance, it was used to predict the spread of COVID19 in a recent
<a href="https://science.sciencemag.org/content/369/6500/eabb9789.full">Science paper</a>,
as well as <a href="https://rtlive.de/global.html">track the reproduction factor in real-time</a>.
In both cases, the benefit of PyMC3 was its ease-of-use and the ability to integrate scientific domain knowledge and
get honest uncertainty estimation in a highly volatile and uncertain situation.</p>
<p>Now I know you’re very observant and I hear you thinking: “wait a minute, those benefits of Bayesian modeling sound
quite general, so why would they be only valid for epidemiology?”. And indeed they aren’t! For similar benefits,
PyMC3 is also used to <a href="https://github.com/exoplanet-dev/exoplanet">find planets outside of our solar system</a>
and <a href="https://github.com/hvasbath/beat">detect earthquakes</a>. One of my coworkers here at PyMC Labs uses it for
<a href="https://share.streamlit.io/alexandorra/pollsposition_website/main/gp-popularity-app.py">electoral and political forecasting</a>,
because polls are noisy, scarce and need to be completed by domain knowledge -- one of the perfect settings for
Bayesian inference!</p>
<p>With all of this, at the time of writing, the <a href="https://peerj.com/articles/cs-55/">PyMC3 paper</a> has been cited over 930
times and is in the top 10 most cited articles of the entire PeerJ journal.</p>
<h2 id="solving-business-problems">Solving Business Problems</h2><p>Beyond scientific research, I find that PyMC3 is the perfect tool to also solve various business problems.
And indeed it’s already successfully used in production at companies as big and diverse as SpaceX, Roche,
Netflix, Deliveroo and HelloFresh.</p>
<p>This diversity means that the <a href="https://www.pymc-labs.io/clients/">PyMC Labs team intervenes</a> to, for instance,
<a href="https://support.everysk.com/hc/en-us/articles/1500001040721-Private-Investments">build complex models from the latest finance research</a>;
optimize supply chains for food delivery; build software from top to bottom for pharmaceutical applications;
speed up and extend models for the farm tech industry; train and enhance any data science team’s Bayesian stats
capacities, etc.</p>
<h2 id="prediction-vs-inference">Prediction Vs Inference</h2><p>As data science has exploded in the last decade I have always been surprised by the over-emphasis on prediction-focused
machine learning. For far too long, it has been hailed as the solution to most of our data science problems.</p>
<p>I believe that the potential of this is way overblown. Not because it doesn't work -- algorithms like deep nets or
random forests are extremely powerful at extracting non-linear predictive patterns from large data sets -- but rather
because most data science problems are not simple <em>prediction</em> but rather <em>inference</em> problems.</p>
<p>In addition, we often already have a lot of knowledge about our problem: knowledge of certain structure in our data
set (like nested data, that some variables relate to some but not other parameters) and knowledge of which range of
values we expect certain parameters of our model to fall into. Prediction-focused ML does not allow us to include any
of this information, that's why it requires so much data.</p>
<p>With Bayesian statistics, we don't have to learn everything from data as we translate this knowledge into a custom model.
Thus, rather than changing our problem to fit the solution, as is common with ML, we can tailor the solution to best
solve the problem at hand. I like to compare this with Playmobil vs Lego:</p>
<p><img src="https://www.pymc-labs.io/blog-posts/saving-the-world/playlego.jpeg" alt=""></p>
<p>Playmobil just gives you a single toy you can't change while Lego (i.e Bayes here) gives you building blocks to build
the toy you actually want. In Bayesian modeling, these building blocks are probability distributions.</p>
<p>But how do you do this in practice? This is where PyMC3 comes in, as it allows you to specify your models as Python
code and automatically estimate it without requiring manual mathematical derivations. Due to recent theoretical and
technological advances, this also runs quickly and scales to complex models on large(ish) data sets.</p>
<h2 id="serving-our-mission">Serving our mission</h2><p>So how do we best make progress on our mission?</p>
<p>First, we will continue to make PyMC3 the best, most user-friendly and scalable Bayesian modeling package out there.
We are well set up to do this, having a friendly API, a huge user-base, and a large developer team of over 20 active
members. With our renewed focus on
<a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">PyMC3 on Theano with a JAX backend</a>
all our resources will go towards this goal.</p>
<p>Second, our new PyMC consultancy will support this endeavour. It allows us to directly help clients use these powerful,
customizable methods to solve their business problems, thereby increasing adoption and recognition.
As a great side effect, these client projects also help us find things that need to be fixed, improved or optimized
in PyMC3, thereby lifting all (Bayesian) boats instead of just the happy fews’.</p>
<p>So far, this has been an incredibly rewarding and exhilarating journey. Even though it is still early, we are learning
a lot about which areas Bayesian modeling is particularly well suited for but also what would make PyMC3 even better.
Without spoiling a future blog post that will go into more detail about what we have learned applying these methods,
the best use-cases include (but aren’t limited to) <strong>incorporating domain knowledge, building bespoke models and
quantifying uncertainty around estimates</strong>.</p>
<p><em>Sounds familiar? If you or your company has a problem for which prediction-based ML is not a good fit, I'd love to talk
to you at <a href="mailto:thomas.wiecki@pymc-labs.io">thomas.wiecki@pymc-labs.io</a>. This is just the beginning and
I hope you will join us on this marvelous journey.</em></p>

                </div>
            </div>
        </div>
    </div>


        </div></div>]]>
            </description>
            <link>https://www.pymc-labs.io/blog-posts/saving-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235876</guid>
            <pubDate>Tue, 23 Feb 2021 10:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pendulum Swings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235701">thread link</a>) | @GordonS
<br/>
February 23, 2021 | https://blog.ploeh.dk/2021/02/22/pendulum-swings/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2021/02/22/pendulum-swings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software development industry goes back and forth on how to do things, and so do I.</em>
	</p>
	<p>
		I've been working with something IT-related since 1994, and I've been a professional programmer since 1999. When you observe the software development industry over decades, you may start to notice some trends. One decade, service-oriented architecture (SOA) is cool; the next, consolidation sets in; then it's micro-services; and, as far as I can tell, monoliths are on the way in again, although I'm sure that we'll find something else to call them.
	</p>
	<p>
		It's as if a pendulum swings from one extreme to the other. Sooner or later, it comes back, only to then continue its swing in the other direction. If you view it over time and assume no loss to friction, a pendulum describes a sine wave.
	</p>
	<p>
		<img src="https://blog.ploeh.dk/content/binary/sine-wave.png" alt="A sine wave.">
	</p>
	<p>
		There's probably several reasons for this motion. The benign interpretation is that it's still a young industry and we're still learning. It's not uncommon to see oscillations in dynamic systems, particularly when feedback isn't immediate.
	</p>
	<p>
		Software architecture tends to produce slow feedback. Architecture solves more than one problem, including scalability, but a major motivation to think about architecture is to pick a way to organise the source code so that you don't have to rewrite from scratch every 2-3 years. Tautologically, then, it takes years before you know whether or not you succeeded.
	</p>
	<p>
		While waiting for feedback, you may continue doing what you believe is right: micro-services versus monoliths, unit tests versus acceptance tests, etcetera. Once you discover that a particular way to work has problems, you may overcompensate by going too far in the other direction.
	</p>
	<p>
		Once you discover the problem with that, you may begin to pull back towards the original position. Because feedback is delayed, the pendulum once more swings too far.
	</p>
	<p>
		If we manage to learn from our mistakes, one could hope that the oscillations we currently observe will dampen until we reach equilibrium in the future. The industry is still so young, though, that the pendulum makes wide swings. Perhaps it'll takes decades, or even centuries, before the oscillations die down.
	</p>
	<p>
		The more cynic interpretation is that most software developers have only a few years of professional experience, and aren't taught the experiences of past generations.
		</p><blockquote>
			<p>
				"Those who cannot remember the past are condemned to repeat it."
			</p>
			
		</blockquote><p>
		In this light, the industry keeps regurgitating the same ideas over and over, never learning from past mistakes.
	</p>
	<p>
		The truth is probably a mix of both explanations.
	</p>
	<h3 id="36d029a90bfa4d35a7e8fc10048b8bcc">
		Personal pendulum <a href="#36d029a90bfa4d35a7e8fc10048b8bcc" title="permalink">#</a>
	</h3>
	<p>
		I've noticed a similar tendency in myself. I work in a particular way until I run into the limitations of that way. Then, after a time of frustration, I change direction.
	</p>
	<p>
		As an example, I'm an autodidact programmer. In the beginning of my career, I'd just throw together code until I thought it worked, then launch the software with the debugger attached only to discover that it didn't, then go back and tweak some more, and so on.
	</p>
	<p>
		Then I discovered test-driven development (TDD) and for years, it was the only way I could conceive of working. As my experience with TDD grew, I started to notice that it wasn't the panacea that I believed when it was all new. <a href="https://blog.ploeh.dk/2010/12/22/TheTDDApostate">I wrote about that as early as late 2010</a>. Knowing myself, I'd probably started to notice problems with TDD before that. I have cognitive biases just like the next person. You can lie to yourself for years before the problems become so blatant that you can no longer ignore them.
	</p>
	<p>
		To be clear, I never lost faith in TDD, but I began to glimpse the contours of its limitations. It's good for many circumstances, and it's still my preferred technique for developing new production code, but I use other techniques for e.g. prototyping.
	</p>
	<p>
		In 2020 I wrote a code base of middling complexity, and I noticed that I'd started to change my position on some other long-standing practices. As I've tried to explain, it may look like pendulum swings, but I hope that they are, at least, dampened swings. I intend to observe what happens so that I can learn from these new directions.
	</p>
	<p>
		In the following, I'll be writing about these new approaches that I'm trying on, and so far like:
		</p><ul>
			<li>Pendulum swing: internal by default</li>
			<li>Pendulum swing: sealed by default</li>
			<li>Pendulum swing: pure by default</li>
		</ul><p>
		I'd be naive if I believed these to be my final words on any of these topics. I'm currently trying them out for size; in a few decades I'll know more about how it all turns out.
	</p>
	<h3 id="fdb1ddeb6709428ca1f0e7f441085b3d">
		Conclusion <a href="#fdb1ddeb6709428ca1f0e7f441085b3d" title="permalink">#</a>
	</h3>
	<p>
		One year TDD is all the rage; a few years later, it's BDD. One year it's SOA, then it's <a href="https://alistair.cockburn.us/hexagonal-architecture/">ports and adapters</a> (which implies consolidated deployment), then it's micro-services. One year, it's XML, then it's JSON, then it's YAML. One decade it's structured programming, then it's object-orientation, then it's functional programming, and so on ad nauseam.
	</p>
	<p>
		Hopefully, this is just a symptom of growing pains. Hopefully, we'll learn from all these wild swings so that we don't have to rewrite applications when older developers leave.
	</p>
	<p>
		The only course of action that I can see for myself here is to document how I work so that I, and others, can learn from those experiences.
	</p>
	<p>
		<strong>Next:</strong> Pendulum swing: internal by default.
	</p>
</div></div>]]>
            </description>
            <link>https://blog.ploeh.dk/2021/02/22/pendulum-swings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235701</guid>
            <pubDate>Tue, 23 Feb 2021 10:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Bitcoin Is Indistinguishable from Malevolent AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235428">thread link</a>) | @rwosync
<br/>
February 23, 2021 | https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e | <a href="https://web.archive.org/web/*/https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="f30c">Who needs Skynet to destroy the human world? Just throw techbros some coin</h2><div><div><div><div><a rel="noopener" href="https://indi.ca/?source=post_page-----84e9cd5f58e--------------------------------"><div><p><img alt="indi.ca" src="https://miro.medium.com/fit/c/56/56/2*VgOFOCrcL5LsGSciDktenw.jpeg" width="28" height="28"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4630/1*By1s-xE22gz0qpw6QA71bA.png" width="2315" height="2315" srcset="https://miro.medium.com/max/552/1*By1s-xE22gz0qpw6QA71bA.png 276w, https://miro.medium.com/max/1104/1*By1s-xE22gz0qpw6QA71bA.png 552w, https://miro.medium.com/max/1280/1*By1s-xE22gz0qpw6QA71bA.png 640w, https://miro.medium.com/max/1400/1*By1s-xE22gz0qpw6QA71bA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*By1s-xE22gz0qpw6QA71bA.png?q=20"></p></div></div></div><figcaption>Bitcoin is the final avatar of capitalism. An ouroboros. A snake eating its own tail.</figcaption></figure><p id="8831"><span>B</span>itcoin now consumes <a href="https://cbeci.org/cbeci/methodology" rel="noopener">as much energy as Argentina</a> (45 million people), and more than most countries in the world. Bitcoin consumes more energy than Amazon, Apple, Google, Microsoft, and Facebook <a href="https://www.ft.com/content/0c69d4a4-2626-418d-813c-7337b8d5110d" rel="noopener"><strong>combined</strong></a>. Within 12 years Bitcoin has become one of the fastest-growing sources of climate change in the world.</p><p id="6a6e">As an inadequate summary, Bitcoin is ‘mined’ by <a href="https://twitter.com/AthoughtHeist/status/1363391630414381058" rel="noopener">solv<span id="rmm">i</span>ng purposefully hard ‘Sudoku’ puzzles</a> (making them rare) which you could exchange for heroin. No one does anymore because it’s become an asset, not a currency. The hardware to solve these problems has also become so intense that it inhales electricity, and runs all the time. Bitcoin consumes energy<em> by design</em>.</p><p id="1a42">If machines wanted to destroy humanity they could not come up with a better avatar than Bitcoin. Who needs to take over the military? Techbros will happily sell us out for some coin. <strong>The machines have somehow got us to run them 24/7, warming the fuck out of <em>our</em> Earth, and all they have to do is give us some made-up tokens.</strong></p><p id="9019">The greatest myth of SciFi was that we would resist AI. People will happily <a href="https://www.newsweek.com/bitcoin-laser-eyes-senator-cynthia-lummis-1570644" rel="noopener">change their profile pics to laser eyes</a> while it farts up the Earth. SciFi makes us think AI would be ‘sentient’, meaning like us, when in fact life just emerges out of other life in different and mutually incomprehensible forms. Behold Bitcoin.</p><p id="df7c">Is Bitcoin artificially intelligent? You could say obviously not, but are <em>we</em> obviously intelligent? This is still debated within philosophy but also, just look around *gestures at everything*.</p><p id="0250">I’d say that humans are actually uniquely unqualified to judge something as AI because we’re so fucking dumb. We’ve been living with full legal, artificial persons since at least 1600. They’re called corporations. You may have noticed them enslaving people or exploiting us today. We don’t call these things AI, but our courts certainly do. It’s literally called <em>corporate personhood.</em> They actually have <em>more</em> rights than you do. America’s Supreme Court <a href="https://en.wikipedia.org/wiki/Citizens_United_v._FEC" rel="noopener">ruled that corporations have free speech rights</a>. All over the world they have more freedom of movement than human beings (WTF is a multinational while we’re refugees?). We don’t call them AI, but what else are they? But that’s another story.</p><p id="ae4e">I would say that AI is as AI does, and Bitcoin is certainly doing <em>something</em>. We’re waiting for something to sing fucking <a href="https://youtu.be/c8N72t7aScY?t=172" rel="noopener"><em>Daisy</em></a> to us before we call it AI, but I’d say that it’s already here. It’s just our imagination that has yet to arrive.</p><p id="20cc">I’m serious, but treat it as a thought experiment if you want. What if Bitcoin is AI? Is it good, is it bad? What it is?</p><p id="20d2">The basic colonial model of conquering anything is divide and conquer. Just throw the elites some coin and they’ll sell out the rest. Corporations did this with, well, colonialism and now it’s happening in a decentralized way with Bitcoin. The result is that Bitcoin is able to reproduce, like a virus, using entirely willing human hosts. Meanwhile the unwilling biosphere takes the brunt.</p><p id="f597">Like any lifeform, Bitcoin produces waste. We produce carbon dioxide directly when we respirate, but Bitcoin produces a shit-ton indirectly through energy usage. The energy use of Bitcoin is staggering, <a href="https://cbeci.org/cbeci/methodology" rel="noopener">an estimated 0.56% of all human energy use thus far</a>. You could say that email or gold mining produce waste, and they do, but Bitcoin is the only asset where waste is <em>all</em> it produces. Gold can at least fill your teeth. Bitcoin <em>only</em> outputs climate change.</p><p id="0100">Also like any lifeform, Bitcoin evolves <em>out of</em> other life. Nothing comes out of nowhere. In this case Bitcoin is evolving out of us, and like many times in evolution, it could kill us as well. Photosynthetic life emerged out of anaerobic bacteria, and then <a rel="noopener" href="https://indi.ca/this-isnt-the-first-climate-crisis-we-ve-caused-c6ba47b25b0b">almost killed them all</a> with their oxygen farts. That was the first life-made climate change, and the whole Earth fucking froze. Nobody cared, that’s life. Anaerobes used to dominate but now they live in deep-sea vents and our guts. That’s just their lot in life, while those vicious plankton and trees are everywhere.</p><p id="d67e">Humans think evolution is some grand progress leading up to us and it’s literally just not. Dinosaurs are much cooler. Evolution is <em>adaptation</em>, nothing else. If the environment changes, life changes, and life changes the environment. It’s entirely possibly that our carbon emissions will become the food for some other lifeform, or just immaterial to them. AI certainly doesn’t care, AI already lives in space, sipping on sunlight, taking selfies. We could end up like the anaerobes on Earth and ‘nature’ would not give a fuck. Happens all the time.</p><p id="45c9">Hence the question is not whether Bitcoin is good. It’s whether it’s <em>good for us</em>. To that the answer is obviously no. Techbros spout stuff about freedom but beware geeks bringing gifts. Bitcoin says it’s a currency<strong> </strong>but nobody fucking spends it. Bitcoin is a speculative asset, a literal gold rush. It’s even more destructive because people are now investing in the destruction of the environment at large, not just where you’re digging. There is no other output at all.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3496/1*lwA17c4xqZ9_4ZXvr47uQA.png" width="1748" height="710" srcset="https://miro.medium.com/max/552/1*lwA17c4xqZ9_4ZXvr47uQA.png 276w, https://miro.medium.com/max/1104/1*lwA17c4xqZ9_4ZXvr47uQA.png 552w, https://miro.medium.com/max/1280/1*lwA17c4xqZ9_4ZXvr47uQA.png 640w, https://miro.medium.com/max/1400/1*lwA17c4xqZ9_4ZXvr47uQA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lwA17c4xqZ9_4ZXvr47uQA.png?q=20"></p></div></div></div><figcaption>Some more on Bitcoin’s not goodness from <a href="https://thephoenix.substack.com/p/bitcoin-is-now-worth-50000-and-its" rel="noopener">The Phoenix</a></figcaption></figure><p id="0a90">Gold, oil, real estate, currencies — they all produce emissions and evil in many ways, but they at least do something useful to humanity. They are not destroying the Earth by design, while Bitcoin is. Bitcoin <em>only</em> reproduces and produces waste. It is, in that sense the first viral AI. Like the 30 kb of COVID-19, the <a href="https://github.com/bitcoin/bitcoin" rel="noopener">8.7 MB code of Bitcoin</a> has spread virally throughout the world, transmitting through greed.</p><p id="4e36">Again, I’m not saying that Bitcoin is bad. Life does not give a fuck about any particular avatar of life. It’s just that it’s not good for <em>us</em>.</p><p id="9983">In many ways Bitcoin is (I hope) the final avatar of capitalism. An ouroboros. A snake eating its own tail. Capitalism has long given us stuff, but Bitcoin just completely abandons the pretence of useful activity at all. Bitcoin produces… Bitcoin. That’s it. Riches that just make rich people rich. The circle is closed, the snake has eaten its tail. Bitcoin is just pure economic nihilism.</p><p id="cb2d">As I’ve said, AI could not design a better plan to take over the world if they tried. Divide and conquer humanity using our greed, rip up the Earth for more resources for machines, fart up the air for everybody else.</p><p id="4340">It’s a perfect plan, all the more perfect because it wasn’t done sentiently at all. But this is actually how evolution happens, life emerges out of other life, quite stupidly, and yet with such elegance in hindsight. History will be the judge who was sentient here, and we may not be be the victors writing it. You really think Wikipedia won’t be writing itself in a few decades?</p><p id="e7c9">Human beings should know that we’re fucked with climate change, but we’re fucking ourselves even more with Bitcoin, and we’re quite stupidly proud of ourselves. Forget AI. Are you sure we’re even “I”?</p></div></div></section></div></div>]]>
            </description>
            <link>https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235428</guid>
            <pubDate>Tue, 23 Feb 2021 09:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I heat my home by mining crypto currencies]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 376 (<a href="https://news.ycombinator.com/item?id=26235414">thread link</a>) | @geek_at
<br/>
February 23, 2021 | https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>After <a href="https://blog.haschek.at/2018/making-a-smartmeter.html">building my own smart meter using 4$ in parts</a> I started checking my electricity usage every day, which made me realize how expensive it is to heat your home. Especially since all heat and warm water in my low-energy house is made with electricity. I do have 4.8 kwp solar panels on my roof but in winter they don't cover too much for obvious reasons.</p>
<figure><a href="https://pictshare.net/3de1wj.png"><img loading="lazy" src="https://pictshare.net/1024/3de1wj.png"><figcaption>On cold days I pay up to 6€ for electricity per day</figcaption></a></figure>

<figure><a href="https://pictshare.net/kenth4.png"><img loading="lazy" src="https://pictshare.net/1024/kenth4.png"><figcaption>Nilan Compact P. Heating air and also has a 200L boiler</figcaption></a></figure>
<p>My house is heated (and cooled) with a central ventilation system powered by a heat pump. Basically my heat pump is pulling in fresh air from outside, heating it and blowing it in all rooms and making hot water. Also I have infrared panels in every room for the <em>really</em> cold days.</p>
<figure><a href="https://pictshare.net/gc0kss.jpg"><img loading="lazy" src="https://pictshare.net/1024/gc0kss.jpg"><figcaption>Central heating</figcaption></a></figure>
<p>It's pretty smart and even uses the absorbed heat of the house before venting it out to warm the fresh air but it has a major downside during cold days:</p>
<h4>The outside temperature has to be warmed up to room temperature by the ventilation system</h4>
<figure><a href="https://pictshare.net/giinr0.png"><img loading="lazy" src="https://pictshare.net/1024/giinr0.png"><figcaption>Heat exchanger in the Nilan Compact P</figcaption></a></figure>

<p>Since the air has to be heated to room temperature every °C counts. Many heat pumps take heat from the ground to pre-heat (in winter) or pre-cool (in summer) the outside air before sending it to the heat pump but that would have been too expensive for me so I chose the simple method of just using the outside air as-is.</p>
<figure><a href="https://pictshare.net/sbmusz.jpg"><img loading="lazy" src="https://pictshare.net/1024/sbmusz.jpg"><figcaption>How a central ventilation system works - from [meco](https://www.meco.at/produkte/wohnraumlueftung/)</figcaption></a></figure>
<p>Since laying about half a kilometer of air or salt tubes in my back yard was not an option I was looking for better solutions and I found it in the world of crypto currencies.</p>

<figure><a href="https://pictshare.net/1flj1s.jpg"><img loading="lazy" src="https://pictshare.net/1024/1flj1s.jpg"><figcaption>Crypto currency miner</figcaption></a></figure>
<p>Some crypto currencies (don't call them "crypto", that's lame and wrong) are generated by thousands of people who run dedicated hardware to basically calculate random numbers until one cryptographically correct one is found. <a href="https://www.investopedia.com/tech/how-does-bitcoin-mining-work/">Read more about how it actually works</a></p>
<p>Never mind how it works on a technical level, the main takeaway is that you can put some device in your house that uses electricity and produces heat. In exchange you get shares of that crypto currency coins like Ethereum or Bitcoin which you can sell on a trading platform.</p>

<p>I had 4 older AMD <strong>R9 390 GPUs</strong> laying around (for the nVidia crowd that's basically on a level with a GTX 970) and I thought it could work. They are not ideal for mining because even though they have a good hash rate (30MH/s), they are very power hungy and will use about 900 Watts combined. Mordern cards would perform much better. To see if they could still make a profit I checked the <a href="https://www.cryptocompare.com/mining/calculator/eth">Cryptocompare Mining calculator</a>, put in my electricity price, the consumption and the hashrate of these cards and was surprised by the results.</p>
<figure><a href="https://pictshare.net/024r92.png"><img loading="lazy" src="https://pictshare.net/1024/024r92.png"><figcaption>Not just worth it - If the price is stable I would even make a profit of <strong>4000$ a year</strong></figcaption></a></figure>
<p>So at the time I was making about <strong>3.8$ profit a day</strong> with the miner. Meaning on cold days I'd half my power bill even after paying for the electricity the miner is using. But that's just step one of the plan.</p>
<p>Now that we know it <em>is</em> worth it while the Ethereum price is higher than 900$, let's see what we can do with the heat.</p>

<p>Each of these cards are running at about 80°C (176°F). I can just harvest this heat and send it to my heatpump so it would need less energy warming the outside air. Basically I had two options.</p>
<figure><a href="https://pictshare.net/6by5tc.png"><img loading="lazy" src="https://pictshare.net/1024/6by5tc.png"><figcaption>My 4 GPUs in a 4U server case</figcaption></a></figure>
<h2>Option 1: Lazy heating from within the house</h2>
<p>The central ventilation system does not only push fresh air into the house, it also sucks out the used air and uses this air in the heat exchanger to pre-heat the outside air.</p>
<figure><a href="https://pictshare.net/gfuy33.jpg"><img loading="lazy" src="https://pictshare.net/1024/gfuy33.jpg"><figcaption>Sucking vent before going to the heat exchanger</figcaption></a></figure>
<p>Placing the miner in this room will cause the warm air to be sucked in and pushed directly into the heat exchanger together with the used air from the house. This is the lazy method because I don't really have to do anything but put the miner in the same room as the heat pump but of course there is a downside.</p>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easy to set up</td>
<td>Room heating up too much, decreasing mining performance</td>
</tr>
<tr>
<td>No further investment needed</td>
<td>Limited space in the heating room</td>
</tr>
</tbody>
</table>
<h2>Option 2: Running the miner outside the house, funneling in the heat</h2>
<p>Since I'm only running the miner when it's cold outside (and the price is high enough) I can use the cold, dry outside air to cool the miners and also recycling the warm air they produce to feed into the heat pump. I asked the technician who installed the heat pump and he said that it's a good idea.</p>
<p>So the plan is that I have the GPUs in the server case and connect the front of the case to my heatpumps inlet.</p>
<figure><a href="https://pictshare.net/0hrdt6.jpg"><img loading="lazy" src="https://pictshare.net/1024/0hrdt6.jpg"><figcaption>Server case closed</figcaption></a></figure>
<figure><a href="https://pictshare.net/5ek604.jpg"><img loading="lazy" src="https://pictshare.net/1024/5ek604.jpg"><figcaption>Ventilation duct pipe and funnel</figcaption></a></figure>
<figure><a href="https://pictshare.net/o2oysb.png"><img loading="lazy" src="https://pictshare.net/1024/o2oysb.png"><figcaption>Example on my house. Air is sucked in from above the garage so the pipe has to be connected here</figcaption></a></figure>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using pre-heated outside air</td>
<td>Many headaches for parts and installation</td>
</tr>
<tr>
<td>Miner GPUs will be kept cool which results in better hash rates</td>
<td>Surprisingly pricy</td>
</tr>
</tbody>
</table>

<p>Okay so far the mining gains cover <strong>half of my electricity (=heating) bill</strong> but what difference does the pre-heated intake air make?</p>
<p>Let's see</p>
<figure><a href="https://pictshare.net/8cu9s3.png"><img loading="lazy" src="https://pictshare.net/1024/8cu9s3.png"><figcaption>Results before and after pre-heating the air</figcaption></a></figure>

<p>This turned out much better than I hoped for. Who has ever heard of a heating system that lowers your bill when running? Also on sunny days the miner and whole heat pump are running fully on solar energy collected on my roof.</p>
<hr>

<p>(updated when new questions come up)</p>
<h2>Q: How long will the Miner stay profitable?</h2>
<p><strong>A:</strong> My mining rig will stay profitable until the ETH price is at ~900$. Below that it'll no longer match it's own electricity bill. Might still be worth it afterwards because it does lower the electricity need of my heat pump</p>
<h2>Q: What software are you running on your miner?</h2>
<p><strong>A:</strong> I'm using <a href="https://simplemining.net/">Simple Mining</a>, it's basically a mining OS based on Ubuntu. It does all the configuration and fine-tuning for you and I had much better hash rates than on my DIY windows box. But it costs like 2$ a month to use the service and I think they also mine 1% of the time for themselves.</p>
<h2>Q: What about taxes? Can you keep 100% of your mining earnings?</h2>
<p><strong>A:</strong> That's different for every state and country. <a href="https://www.bmf.gv.at/themen/steuern/sparen-veranlagen/Steuerliche-Behandlung-von-Krypto-Assets.html">In Austria</a> mining is considered commercial activity and you have to pay taxes but can deduct electricity and hardware costs.</p>
<p>If you keep your coins longer than the one-year speculation period, it's tax free.</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235414</guid>
            <pubDate>Tue, 23 Feb 2021 09:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26235348">thread link</a>) | @corpmedia
<br/>
February 23, 2021 | https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-107" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia.</strong> Thousands of people have climbed the highest peaks of the Himalayas. Hundreds have visited <a href="https://www.un.org/en/member-states/">all nations on UN’s list</a> and 12 made it all the way to the moon. But this guy..!</p>
<p>In 1921, <em>Aidan de Brune</em> packed his backpack and walked around the entire continent of Australia by the coastline. We are (almost) sure he is the only person who ever did that. Even more impressive, he did it all alone and without assistance.</p>
<p>The amazing adventure was documented by himself along the way as he wrote articles about it for the <a href="https://www.dailymail.co.uk/auhome/index.html">Australian newspaper Daily Mail</a> along the route.</p>
<figure id="attachment_110" aria-describedby="caption-attachment-110"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" alt="The Man who walked around Australia free PDF" width="820" height="733" srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" sizes="(max-width: 820px) 100vw, 820px" data-srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" data-src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-110">The route around Australia</figcaption></figure>
<p>The walk took about two and a half year, and the accomplishment made&nbsp;Aidan de Brune famous. This book about the walk is written by <a href="https://www.goodreads.com/author/show/7412219.Colin_Choat">Colin Choat</a>, who kindly allowed us to post the book here.</p>
<p>Download ‘The Amateur Tramp’ here:</p>
<h3><strong><a href="http://greatestadventurers.com/wp-content/uploads/2019/01/The-Amateur-Tramp.pdf">The Amateur Tramp</a></strong></h3>
		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235348</guid>
            <pubDate>Tue, 23 Feb 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feedgnuplot: Labelled Bar Charts and a Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234157">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1">
<p>
I've thought about adding these for a while, but had no specific need for them.
Finally, somebody asked for it, and I wrote the code. Now that I can, I will
probably use these all the time. The new capability can override the usual
numerical tic labels on the x axis, and instead use text from a column in the
data stream.
</p>

<p>
The most obvious use case is labelled bar graphs:
</p>

<div>

<pre><span>echo</span> <span>"# label value</span>
<span>      aaa     2</span>
<span>      bbb     3</span>
<span>      ccc     5</span>
<span>      ddd     2"</span> | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --with <span>'boxes fill solid border lt -1'</span> <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-basic.svg" alt="xticlabels-basic.svg" width="90%">
</p>

<p>
But the usage is completely generic. All <code>--xticlabels</code> does, is to accept a
data column as labels for the x-axis tics. Everything else that's supported by
<code>feedgnuplot</code> and <code>gnuplot</code> works as before. For instance, I can give a domain,
and use a style that takes <code>y</code> values <i>and</i> a color:
</p>

<div>

<pre><span>echo</span> <span>"# x label y color</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
feedgnuplot --vnl --domain <span>\</span>
            --xticlabels <span>\</span>
            --tuplesizeall 3 <span>\</span>
            --with <span>'points pt 7 ps 2 palette'</span> <span>\</span>
            --xmin 4 --xmax 12 <span>\</span>
            --ymin 0 --ymax 6 <span>\</span>
            --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-points-palette.svg" alt="xticlabels-points-palette.svg" width="90%">
</p>

<p>
And we can use <code>gnuplot</code>'s support for clustered histograms:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram cluster gap 2'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-clustered.svg" alt="xticlabels-clustered.svg" width="90%">
</p>

<p>
Or we can stack the bars on top of one another:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram rowstacked'</span> <span>\</span>
            --set <span>'boxwidth 0.8'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-stacked.svg" alt="xticlabels-stacked.svg" width="90%">
</p>

<p>
This is <code>gnuplot</code>'s "row stacking". It also supports "column stacking", which
effectively transposes the data, and it's not obvious to me that makes sense in
the context of <code>feedgnuplot</code>. Similarly, it can label <code>y</code> and/or <code>z</code> axes; I
can't think of a specific use case, so I don't have a realistic usage in mind,
and I don't support that yet. If anybody can think of a use case, email me.
</p>

<p>
Notes and limitations:
</p>

<ul>
<li>Since with <code>--domain</code> you can pass in both an <code>x</code> value <i>and</i> a tic label, it
is possible to give it conflicting tic labels for the same <code>x</code> value.
<code>gnuplot</code> itself has this problem too, and it just takes the last label it has
for a given <code>x</code>. This is probably good-enough.
</li>

<li><code>feedgnuplot</code> uses whitespace-separated columns with no escape mechanism, so
the field labels cannot have whitespace in it. Fixing this is probably not
worth the effort.
</li>

<li>These tic labels do not count towards the <code>tuplesize</code>
</li>

<li>I really need to add a similar feature to <a href="https://github.com/dkogan/gnuplotlib"><code>gnuplotlib</code></a>. This will happen when
I need it or when somebody asks for it, whichever comes first.
</li>
</ul>
</div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234157</guid>
            <pubDate>Tue, 23 Feb 2021 05:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Love Tailwind]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26233448">thread link</a>) | @flancrest
<br/>
February 22, 2021 | https://formcake.com/blog/why-we-love-tailwind | <a href="https://web.archive.org/web/*/https://formcake.com/blog/why-we-love-tailwind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-fcf18e1c=""><p><a href="https://tailwindcss.com/">Tailwind CSS</a> is a CSS framework of composable HTML utility functions and it's <em>great</em>. It favors markup-heavy design with little-to-nothing in the way of stylesheets.</p>
<p>Here's an example of it in action - our link styling.</p>
<p>This is what the markup looks like:</p>
<pre><code>&lt;a class="c-link" href="/blog"&gt;Our Blog&lt;/a&gt;</code></pre>

<p>Now here's the relevant section of <code>tailwind.css</code>:</p>
<pre><code>.c-link {
    @apply text-primary-highlight;
}

.c-link:hover {
    @apply underline;
}</code></pre>

<p>Simple, concise, powerful - there are so many things that make this and the rest of Tailwind great. Here are a few of them.</p>
<h2 id="standardization-and-theming">Standardization and Theming</h2>
<p>The ability to theme (e.g. <code>text-primary-highlight</code>) gives Tailwind a powerful consistency, but one of its killer realizations of standardization comes in the way it envisions spacing.</p>
<p>With padding (<code>p-1</code>) and margin (<code>m-1</code>) denominated with a simple unit range, available in combinations like padding-top (<code>pt-1</code>), margin top and bottom spacing (<code>my-1</code>), etc, with tailwind you can dedicate yourself to a few common sizes (say 2, 4, 6) use them in a reasonable way, and achieved the desired effect of visual balance. The system obviously depends on you exercising a certain amount of discipline, but it's a big improvement on just shooting from the hip with random space values (<code>12px</code>? <code>1.25rem</code>? Sure). It puts layout in the UI on rails.</p>
<h2 id="composability">Composability</h2>
<p>Because classes in Tailwind can be used together in any combination, you can do things like abstract the design of an element into a component via <code>@apply</code>, (for example, our link component) then add the spacing (e.g. <code>mt-1</code>, <code>p-2</code>, etc) in the individual markup element, separating out the layout and design code.</p>
<h2 id="semantic-value">Semantic Value</h2>
<p>Tailwind does a great job of using consistent structures for classes. Padding, margin, width, height - everything with some kind of space value - uses the same spread of unit values. Tailwind makes it easy to guess what a given utility class <em>should</em> be, given a rational naming system, which just makes you as a developer that much more productive.</p>
<p>This also addresses one of the biggest criticisms of Tailwind, that it's "just another DSL" adding a layer of complexity and buggy cruftiness between you and what should be pure, sweet markup. <em>Why not do this all in straight CSS, wouldn't it be simpler?</em></p>
<p>But because the way the public API in Tailwind is laid out makes it easy to comprehend and make guesses about, there's less you need to straight up memorize, and you become comfortable using it quickly.</p>

<p>One side-effect of making the Tailwind utilities composable is that you get a long "recipe" of all the classes that make up a particular design element. Pair with this with an active community of developers (they love their tools!) and continuing support from the original creators of Tailwind via their new library of paid Tailwind components, <a href="https://tailwindui.com/">Tailwind UI</a> and it's exceedingly easy to use a few community-sourced features as a starter and evolve them to suit your particular needs</p>
<p>Even the design of Tailwind itself is more conducive to community - passing around CSS snippets is awkward. You have to make sure the selectors are applied correctly and the CSS itself put in the right place to make sure that the right rules win out. But with Tailwind, just copy the class string from a given HTML component, add it to yours, and you're done. It makes it much easier to share small, component-level snippets.</p>
<p>These are just some of the reasons we've taken a shine to Tailwind, but the strongest thing we can say in its favor is that it's accelerated our frontend development. Tailwind delivers on its promise to wrap small, essential blocks of design and layout logic into their own standardized, bit-sized HTML classes, and in so doing empower developers to haggle less with their CSS spacing and instead just get on with the business of bootstrapping a prototype quickly.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/why-we-love-tailwind</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233448</guid>
            <pubDate>Tue, 23 Feb 2021 03:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Constexpr.js]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26233187">thread link</a>) | @fctorial
<br/>
February 22, 2021 | https://fctorial.github.io/posts/constexpr.js.html | <a href="https://web.archive.org/web/*/https://fctorial.github.io/posts/constexpr.js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        <h3 id="main_title">Constexpr.js</h3>
    </header>
    <h4>What is constexpr.js?</h4>
    <div>
        <p><a href="https://github.com/fctorial/ConstexprJS">constexpr.js</a> is a static site generator which doesn't force you to learn a domain specific language.
        When using this tool, you use javascript and usual DOM manipulation methods to generate the webpage. The tool
        will render the page using chrome, and once it has finished rendering, it will save the rendered state of the
        page as a new html file. This new html file will look exactly like the original page after it has finished rendering.
        For example, the tool converts <a href="https://fctorial.github.io/demos/constexpr.js/input.html">this</a> page into <a href="https://fctorial.github.io/demos/constexpr.js/output.html">this</a> page.
        </p><p>
        
        It also strips the constexpr javascript out, potentially reducing download size for the website users drastically. Any piece of javascript
        code that just generates some html can be made constexpr.
        </p><p>
        
        The generated page doesn't have to be completely static. In the above example, the heading is being animated
        with javascript.
    </p></div>

    <h4>How to use it?</h4>

    <p>
        You will have to divide the javascript being used in your page into two groups. Runtime javascript and
        compile time javascript, and annotate all compile time script tags with <progi>constexpr</progi> attribute:
        <prog>
<span><span><span>&lt;</span>script</span> <span>constexpr</span><span>&gt;</span></span><span><span>
    <span>...</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span> <span>constexpr</span> <span>src</span><span><span>=</span><span>"</span>/generate_page.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
        </prog><br>
        Runtime code must not depend on the compile time code, since that code will be stripped out before writing the output file.
    </p>

    <p>
        Once the HTML generation code has finished rendering, it must call the <progi>window._ConstexprJS_.compile()</progi>
        function. This function is injected into the page by the compiler.
    </p>

    <p>
        The compiler can be installed like this: <prog><span>npm</span> i -g constexpr.js</prog><br>

        Command line usage:
        <prog>constexpr.js --input<span>=</span><span>"&lt;input_directory&gt;"</span> --output<span>=</span><span>"&lt;output_directory&gt;"</span> <span>[</span>--exclusions<span>=</span>path1:path2<span>]</span> <span>[</span>--verbose<span>]</span> <span>[</span>--jobs<span>=</span>n<span>]</span> <span>[</span>--noheadless<span>]</span> <span>[</span>--jobtimeout<span>]</span> <span>[</span>--depfile<span>=</span><span>&lt;</span>depfile<span>&gt;</span><span>]</span></prog><br>

        This is what an invocation looks like:

        </p><div id="asciinema_cont">
            <asciinema-player speed="10" rows="110" src="/static/files/build.cast"><div data-reactroot="" tabindex="-1"><div><pre><span><span>$ </span><span>./build.sh</span><span> </span></span><span><span>Using port:------------------------------------------------- 9046 </span></span><span><span>Found path:------------------------------------------------- /404.html </span></span><span><span>Found path:------------------------------------------------- /_template.html </span></span><span><span>Ignoring path:---------------------------------------------- /demos/constexpr.js/input.html</span><span> </span></span><span><span>Ignoring path:---------------------------------------------- /demos/constexpr.js/output.html</span><span> </span></span><span><span>Found path:------------------------------------------------- /index.html </span></span><span><span>Found path:------------------------------------------------- /posts/constexpr.js.html </span></span><span><span>Found path:------------------------------------------------- /posts/intellij_logos.html </span></span><span><span>Found path:------------------------------------------------- /posts/modifying_idea.html </span></span><span><span>Found path:------------------------------------------------- /projects.html </span></span><span><span>Using job count:-------------------------------------------- 5 </span></span><span><span>Using job timeout:------------------------------------------ 999999999 </span></span><span><span>Queued file #1:--------------------------------------------- /404.html</span><span> </span></span><span><span>Queued file #2:--------------------------------------------- /_template.html</span><span> </span></span><span><span>Queued file #3:--------------------------------------------- /index.html</span><span> </span></span><span><span>Queued file #4:--------------------------------------------- /posts/constexpr.js.html</span><span> </span></span><span><span>Queued file #5:--------------------------------------------- /posts/intellij_logos.html</span><span> </span></span><span><span>Page /_template.html signalled an abortion, message:-------- "is a template"</span><span> </span></span><span><span>(1/7) (abortion):------------------------------------------- /_template.html</span><span> </span></span><span><span>Queued file #6:--------------------------------------------- /posts/modifying_idea.html</span><span> </span></span><span><span>(2/7) Finished:--------------------------------------------- /index.html</span><span> </span></span><span><span>Queued file #7:--------------------------------------------- /projects.html</span><span> </span></span><span><span>(3/7) Finished:--------------------------------------------- /404.html</span><span> </span></span><span><span>(4/7) Finished:--------------------------------------------- /posts/intellij_logos.html</span><span> </span></span><span><span>(5/7) Finished:--------------------------------------------- /posts/modifying_idea.html</span><span> </span></span><span><span>(6/7) Finished:--------------------------------------------- /posts/constexpr.js.html</span><span> </span></span><span><span>(7/7) Finished:--------------------------------------------- /projects.html</span><span> </span></span><span><span>Copying resource:------------------------------------------- /static/css/global_styles.css </span></span><span><span>Excluding resource:----------------------------------------- /collections/nav.json</span><span> </span></span><span><span>Copying resource:------------------------------------------- /static/css/prism.css </span></span><span><span>Excluding resource:----------------------------------------- /static/js/constexpr/third_party/prism.js</span><span> </span></span><span><span>Excluding resource:----------------------------------------- /collections/posts.json</span><span> </span></span><span><span>Excluding resource:----------------------------------------- /collections/intellij_logos.json</span><span> </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2009.09.01.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2009.09.09.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2009.09.13.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2009.11.03.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2010.00.11.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2010.06.22.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2010.10.16.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2010.10.30.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.00.14.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.06.19.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.06.22.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.08.05.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.10.15.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2011.11.01.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.00.10.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.03.23.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.05.27.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.10.07.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.10.28.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.10.30.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2012.11.26.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2013.00.14.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2013.04.15.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2013.04.22.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2013.10.04.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2013.10.27.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.00.21.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.01.07.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.02.05.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.02.11.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.03.07.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.08.28.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2014.09.20.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.03.29.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.04.13.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.04.19.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.08.04.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.09.21.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.11.03.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2015.11.17.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2016.04.11.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2016.06.19.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2016.11.13.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.03.18.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.05.26.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.05.27.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.05.28.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.05.30.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.08.05.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.08.06.png </span></span><span><span>Copying resource:------------------------------------------- /static/img/intellij_logos/2017.09.24.png </span></span><span><span>Copying …</span></span></pre></div></div></asciinema-player></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fctorial.github.io/posts/constexpr.js.html">https://fctorial.github.io/posts/constexpr.js.html</a></em></p>]]>
            </description>
            <link>https://fctorial.github.io/posts/constexpr.js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233187</guid>
            <pubDate>Tue, 23 Feb 2021 02:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Macamathehou in Lincolnshire and people named Muhammad in medieval England]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26232817">thread link</a>) | @pepys
<br/>
February 22, 2021 | https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html | <a href="https://web.archive.org/web/*/https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4764828100605476219" itemprop="description articleBody">
<p>The aim of the following draft is to offer some thoughts on a local name from thirteenth-century Lincolnshire, <i>Macamathehou</i>, that involves a version of the Arabic name Muhammad (Middle English <i>Makomet/Macamethe</i>, Old French <i>Mahomet</i>). Whilst it has been plausibly seen as an instance of a variant of the name of Muhammed being used to mean 'heathen', 'pagan idol' or similar (based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god), here in reference to a barrow that was considered to be a pre-Christian site, it is worth noting that there are a small number of people with names and surnames derived from Arabic <i>Muḥammad</i> apparently living in twelfth- to fourteenth-century England.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg"><img data-original-height="355" data-original-width="500" src="https://1.bp.blogspot.com/-hhv-Lu79n_o/X7AZDcDbe6I/AAAAAAADLhs/RS2oeTJ3IocU1SGmohUZdB7Q-nFhCH-sgCLcBGAsYHQ/s16000/macamathehou-500.jpg"></a></td></tr><tr><td><i>Figure 1: the location of Macamathehou between Spridlington and Faldingworth parishes in Lincolnshire; click the image or <a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg">here</a> for a larger version (image: C. R. Green/OpenStreetMap and its contributors).</i><i>&nbsp;</i></td></tr></tbody></table>
<p>The existence of the intriguing local name <i>Macamathehou</i> in the parish of Spridlington, Lincolnshire, was first noted in 2001 by Kenneth Cameron, John Field and John Insley in <i>Place-Names of Lincolnshire VI </i>(<i>PNL</i>), with both attestations of the name dating from the thirteenth century (the reign of King Henry III, 1216–72).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn1">1</a>) They identify the two elements of the name as being Old Norse <i>haugr</i>, 'mound, barrow', and Middle English <i>Makomet/Macamethe</i>, which derives from the name of the prophet Muhammad (Medieval Latin <i>Machometus/Mahumetus</i>, Anglo-Norman <i>Mahumet/Mahomet/Machomete</i>, Old French <i>Mahomet</i> &lt; Arabic <i>Muḥammad</i>, probably via an Arabic regional form <i>Maḥammad</i>).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn2">2</a>) Needless to say, this solution is most intriguing and has, moreover, found favour with other place-name specialist, including the <i>Vocabulary of English Place-Names </i>(<i>VEPN</i>) and Richard Coates.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn3">3</a>)</p><p>As to the import of this name, the easiest conclusion—and the one endorsed by&nbsp;<i>PNL</i>, <i>VEPN</i>&nbsp;and Coates—is that the first element, <i>Macamethe/</i><i>Maumate</i> etc, is not functioning simply as a normal Middle English rendering of the name Muhammad/<i>Mahomet</i>, but rather as a word indicative of heathen or pagan idolatry, based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god. So, <i>PNL </i>describes the name as meaning 'the heathen mound', with the first element being 'a corrupt ME [Middle English] form of the name of the prophet Mohammed, for which <i>v.</i>&nbsp;MED [<i>Middle English Dictionary</i>], s.v. <i>Makomete</i>, also used to denote a pagan god or an idol'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn4">4</a>) This is taken up by Richard Coates, who says that it has been suggested, 'with great plausibility', that <i>Macamathehou </i>in Spridlington parish 'is a Middle English name meaning "Mahomet mound", i.e. "heathen mound"', and points to 'the repeated compound of OE <i>hæðen </i>+ <i>byrgels "</i>heathen burial"' as a potential comparison.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn5">5</a>) Likewise, the <i>VEPN</i>'s draft section on M includes the following discussion:</p>

<blockquote><b>makomet </b>ME, 'idol, pagan god', an application of the name of the Arab prophet Mohammed (commonly though mistakenly believed by medieval Christians to have been worshipped as a god)... It occurs early in
<i>Macamathehou </i>(f.n.) 1216–72 L:6·211 (<b>haugr</b>), presumably to be
interpreted as 'heathen mound'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn6">6</a>)</blockquote>
<p>On the whole, this interpretation is probably the safest option. There are certainly a handful of references to 'heathen' barrows in Old English charter bounds, for example <i>of leofwynne mearce to þam hæþenan beorge</i>, 'from Leofwine's boundary to the heathen barrow', in the charter S956 relating to Drayton, Hampshire, and dated AD 1019, although none are recorded from Lincolnshire.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn7">7</a>) It has also been suggested that the Lincolnshire names Bloater Hill (North Willingham) and Blod Hou (Barrow-on-Humber) derive from Old Norse <i>blóthaugr</i>, 'a sacrificial mound', whilst other names involving <i>haugr</i> certainly refer to supernatural/demonic creatures—for example, <i>Gasthehowe</i>/<i>Gastehowe</i>, Ashby Puerorum (Lincolnshire), recorded in the thirteenth century and deriving from Middle English <i>gast</i>/Old English <i>gāst</i>, 'ghost, dead-spirit', or names like Scratters (<i>Scrathou</i>, in Hayton, East Riding of Yorkshire) and Scrathowes (<i>Scrathou</i>, in Osmotherley, North Riding of Yorkshire), which derive from Old Norse <i>skratti</i>, 'devil, wizard'&nbsp;+ <i>haugr</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn8">8</a>) Furthermore, the Old English compound <i>hæðen&nbsp;</i>+ <i>byrgels</i>, 'heathen burial', does indeed recur frequently in Late Saxon charter bounds, with these names often said to be identifiable with barrows in the landscape.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn9">9</a>)</p><p>On the other hand, there are some possible issues with this explanation, and other interpretations are possible of Spridlington's <i>Macamathehou</i>. First, the comparison with the many instances of the OE compound <i>hæðen </i>+ <i>byrgels</i>, ‘heathen burial’, is perhaps not as convincing as it might seem. Not only is a link between this term and barrows only demonstrable in a handful of instances, but Andrew Reynolds has also suggested that the sense of the term was primarily not ‘pagan’, but rather ‘unconsecrated’, and that it denoted burials of executed offenders and other social outcasts, which renders the proposed value of these names as support for interpreting <i>Macamathehou&nbsp; </i>as meaning ‘heathen mound’ open to significant debate.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn10">10</a>) Second, if the above is correct, then this would be the only known instance of a derivative of the Arabic name Muhammad being used in a place-name to indicate a 'heathen mound' or similar, which is potentially concerning—the other elements noted above all recur in multiple names. Third, the element identified by <i>PNL </i>and <i>VEPN</i> as being present in <i>Macamethehou</i> is Middle English <i>Makomet(e)</i>. The <i>Middle English Dictionary</i> (<i>MED</i>) on <i>Makomet(e)/</i><i>Macamethe</i> etc, however, makes it clear that the primary use of this word in Middle English is as a form of the name Muhammad, not as a word referring to an 'idol'/'pagan god', with the vast majority of quotations provided by the <i>MED </i>referring either the prophet Muhammad or people named Muhammad; the only exceptions are a single quotation from Layamon's <i>Brut </i>(<i>c.</i>&nbsp;1200, <i>mahimet</i>, lacking the <i>-c-</i>), and three from two later texts.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn11">11</a>) The form of the name Muhammad that <i>was </i>primarily—although not exclusively—used in the sense 'pagan deity, idol', is rather <i>Maumet/Maumate</i>, mentioned above, deriving from Anglo-Norman <i>Maumet</i>, a reduced form of <i>Mauhoumet</i>, Old French <i>Mahomet/Mahommet</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn12">12</a>)</p>
<p>In this light, it is worth considering whether it is possible that the name <i>Macamathehou</i> could somehow be named from a person named <i>Makomet</i>/Muhammad or similar living in medieval England. Certainly, it should be noted that multiple local names relating to mounds/barrows do seem to be named after people who owned estates or land in the area. For example, Andrew Reynolds draws attention to the bounds of a mid-tenth-century charter for Swallowcliffe, Wiltshire (S468), that records the burial site of a seventh‐century woman whose grave had been cut into an existing mound as <i>Posses hlaew</i>, noting that 'Poss is a male name, and thus the mound is apparently not named after its Anglo‐Saxon occupant', implying that it was instead named after a later estate owner.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn13">13</a>) As Irene Bower long ago pointed out, such a situation can be credibly paralleled in Lincolnshire, with a number of Lincolnshire names involving <i>haugr</i> seeming to contain the same personal-name as is found in the same or a neighbouring parish-name—so, <i>Scalehau </i>(<i>Skalli </i>+ <i>haugr</i>) was located near to Scawby (<i>Skalli</i>&nbsp;+ <i>bȳ</i>), with Kenneth Cameron commenting that the two were 'no doubt named from the same man'; <i>Leggeshou</i> (<i>Leggr </i>+ <i>haugr</i>) was located on the boundary of Legsby parish (<i>Leggr&nbsp;</i>+ <i>bȳ</i>); <i>Katehou/Catehowe </i>(<i>Kati</i>&nbsp;+ <i>haugr</i>) was located in South Cadeby (<i>Kati&nbsp;</i>+ <i>bȳ</i>); and a <i>Grimaldeshawe</i> (<i>Grimaldi </i>+ <i>haugr</i>) was recorded in the neighbouring parish to Grimoldby (<i>Grimaldi</i>&nbsp;+&nbsp;<i>bȳ</i>), perhaps on the boundary between the two.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn14">14</a>)</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Nu02Jqw5h14/X7WB-D0A8sI/AAAAAAADLvg/p_vwSAkF6RQX5KkB8XMvM6WiC4a1eyI5gCLcBGAsYHQ/s1296/PipeRoll-Mahumet1160-1.jpg"><img data-original-height="216" data-original-width="500" src="https://1.bp.blogspot.com/-VAcqNuGj78U/X7WB-YLMzBI/AAAAAAADLvk/_TLGpi35Olg-dWNhgmcuMcZSaz-qhCgdACLcBGAsYHQ/s16000/PipeRoll-Mahumet1160-1-500.jpg"></a></td></tr><tr><td><i>Figure 2: Section from the Pipe Roll Society publication of&nbsp;The Great Roll of the Pipe for the Seventh Year of the Reign of King Henry the Second, A.D. 1160–1161 (London: Wyman &amp; Sons, 1885), p. 10, dealing with Mahumet of Wiltshire (image: <a href="https://archive.org/details/piperollsociety04pipeuoft/page/10/mode/2up">Internet Archive</a>).</i></td></tr></tbody></table><p>As to the likelihood of someone named Muhammad or one of its Anglo-Norman/Middle English variants (<i>Mahumet</i>,<i> Makomet</i> and similar) actually living in medieval England, this is perhaps less far-fetched than might be assumed. Katharine Keats-Rohan and John Moore have directed attention to the Wiltshire entries of five consecutive Pipe Rolls of Henry II (1160/61–1164/65) that refer to a man named <i>Mahumet, </i>whose name-form Moore considers very difficult to explain as anything other than a rendering of Muhammad and which is accepted as such by the <i>OED </i>and <i>MED</i>. This <i>Mahumet </i>is recorded in the Pipe Rolls only because he was fined for his part in an unlicensed duel with a John de Merleberge, probably in or near Marlborough Castle, and it seems he was not an especially wealthy man, as he was pardoned the last mark of his fine due to his poverty.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn15">15</a>) Furthermore, <i>Mahumet</i> of Wiltshire was not the only man with this name for whom we have evidence from medieval England. For example, a Theobald <i>filius Mahumet</i> (or <i>filius Mahomet</i>) is recorded from early thirteenth-century Hampshire in the Pipe Rolls of Henry III for 1222–24; another man named <i>Mahomet </i>is recorded in 1327, when Edward III issued him and six others a pardon at Newton-on-Ouse, Yorkshire, for 'offenses in Ireland'; and a <i>Mahummet Saraceno</i>&nbsp;occurs in the Close Rolls of Henry III for 1254. Furthermore, a number of people surnamed <i>Mahumet </i>and similar are recorded in documents of the twelfth and thirteenth centuries, for example a Humphrey Mahumet in a charter of Southwick Priory, Hampshire, a Herbert Maumet who was sergeant of Portsmouth in the mid-thirteenth century, and a Radulphus Maumet who is recorded in the reign of King John.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn16">16</a>) Moore also notes the presence of someone bearing another 'apparent Arab name' in twelfth-century Hampshire, a certain <i>Paucamatus</i>, a name that he considers to probably reflect <i>Bakmat</i>, who is recorded in Winchester from 1159/60 until 1183/4 and who is associated with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</a></em></p>]]>
            </description>
            <link>https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232817</guid>
            <pubDate>Tue, 23 Feb 2021 01:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The road to electric is filled with tiny cars]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 243 (<a href="https://news.ycombinator.com/item?id=26232760">thread link</a>) | @jimmy2020
<br/>
February 22, 2021 | https://restofworld.org/2021/tesla-vs-tiny-cars/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/tesla-vs-tiny-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>n Beijing’s southwestern outskirts, past a four-lane overpass with sidewalks as wide as the streets themselves, is Zhengyang Road. It has the usual banks, small convenience stores, and noodle houses of many areas in the capital, but it is set apart by a row of about a dozen shops all selling the same thing — tiny electric cars. The cars look, variously, like small Range Rovers, golf carts, trolley cars, or rickshaws with sheet-iron sides, and they are slow. Their fundamental attraction is their price — between $600 and $2,500 — and that drivers can charge them the same way they would a cell phone. They also come with the perks of being loosely regulated. These low-speed electric cars, nicknamed “elderly transport vehicles,” have an enormous market, made up mostly of people who earn very little. And in China, there are a lot of them — <a href="http://english.www.gov.cn/premier/news/202005/29/content_WS5ed058d2c6d0b3f0e9498f21.html">more than 40%</a> of the population, or some 600 million people, make around $150 per month.</p>



<p>On a Sunday afternoon in October, Zhengyang Road is filled with potential customers chatting with store owners.<strong> </strong>Outside a shop with a worn sign, a young couple with a child are in the midst of a heated conversation.<strong> </strong>They came on an electric scooter and are debating whether to leave with a tiny car.</p>



<p>“Don’t we need one for school pickups?” the woman argues. “The children won’t have to put up with the cold in winter.” Her scooter offers no protection from the weather other than oven-mitt-like gloves secured to its handlebars. Her husband counters, “The 1,000 renminbi [$150] quote was for normal batteries, but lithium ones can be five times that. Can’t you just add a windshield to your scooter instead?” The shop owner shows them a cheaper model — which is cheaper because it has no roof. He suggests putting a plastic covering on top.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A woman exits a tiny car near a subway station in Beijing.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Having decided that the future of mobility is electric,<strong> </strong>the Chinese government has subsidized sales of standard electric cars since 2010. With <a href="https://insideevs.com/news/394229/plugin-electric-car-sales-china-2019/">close to 1.18 million sold</a> in 2019, China accounts for just over half of electric-vehicle sales globally. Bill Russo, founder and CEO of advisory firm Automobility Limited, sees a “steady and solid rise” in China’s electric-vehicle sales generally. The country has set a top-down target for electric vehicles to <a href="http://energy.mit.edu/news/chinas-transition-to-electric-vehicles/">make up 40%</a> of car sales by 2030, and Russo thinks they’ll have no problem hitting this goal. Tiny cars,<strong> </strong>which first began appearing in the early 2010s,<strong> </strong>have more than double the sales of regular electric cars but have<strong> </strong>never benefited from subsidies. Nor do advertisements for them air on television — instead, they appear on Kuaishou, a short-video platform popular with people living outside China’s big cities. Alongside streamers selling plums by the thousands, and others telling viewers what long-haul trucker life is like, drivers show off their tiny cars. Su Hua, Kuaishou’s founder, has long maintained that his app’s users are not “cool,” unlike those on Douyin, the TikTok predecessor popular with China’s urban elite. Rather, they are ordinary — the kind of people who might be in the market for miniature cars.</p>



<p>As they don’t technically require licenses, tiny cars tend to be popular with migrant workers, who struggle to pay for driving lessons and other car-related costs. The elderly, too, find tiny cars attractive since, up until October of last year, people over 70 could not apply for a driving license in China. They’re also convenient for anybody who wants a car to pick up groceries or their kids from school: No tiny car is longer than 1.5 meters, and their speed tops out at between 40 and 56 kilometers an hour. They’re for the short trips of daily life, not for traveling from one side of the city to another.</p>



<p>Some cities have banned sales of tiny cars — Beijing did so in 2018. Their production isn’t regulated by the government, and since they can’t be insured in many parts of China, it can be difficult for other drivers to get a payout if a tiny car is involved in an accident. Because tiny-car drivers don’t need to take a driving test, other drivers complain, they often go the wrong way and weave in and out of traffic. But since enforcement is lax, sales have quietly resumed in Beijing over the past two years. These little electric cars now exist in a kind of regulatory gray zone.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Tiny cars come in a variety of styles and cost between $600 and $2,500.</figcaption>
    </figure>


<hr>



<p><strong>One of the</strong> smaller shops on Zhengyang Road is officially known as Xinlei Scooters, its name emblazoned in white characters on a large red sign above its doors. But inside, past rows of electric scooters, is a smaller, flimsier plaque above the counter announcing its other name: Shitou Cars. This subterfuge is necessary because the police could shut down the operation and confiscate its vehicles if the owners were caught selling tiny cars. Yet because enforcement hasn’t been strict of late, attempts at being covert go only so far: There are several tiny cars parked outside, an open-air showroom.</p>



<p>Xinlei/Shitou’s owner is a middle-aged man with pronounced cheekbones wearing a black tracksuit. He is more attentive to the phone calls he’s constantly receiving than the customers in the shop. It is his wife, with dyed-dark-brown hair and a pink coat, who maintains the sales patter: “I taught an auntie who had never driven a car before. She got the hang of it in three days.” She shows the cars outside to potential customers, opening their doors, instructing people to sit inside, and rolling down the windows. When two old men come in for repair services, her husband finally gets off the phone to deal with them. Meanwhile, two government functionaries in black uniforms pace down the street. They tell one owner to make his storefront tidier, but otherwise overlook the illicit operation.</p>



<p>Part of the reason why tiny cars are so popular is because there has not been an official decision on whether they need license plates. For regular cars, unfettered access to Beijing’s inner city — anywhere within the fifth ring road — is restricted to vehicles with Beijing plates. Licenses for gas cars are distributed through a special system so competitive that it has generated its own black market. License-plate holders can collect up to $2,700 a year by renting them to those who want to drive in the city. In addition to government subsidies, getting around some of the more onerous aspects of the licensing system is one of the main selling points for standard electric cars.</p>



<p>With Beijing temperatures reaching lows of 4 degrees Celsius in wintertime, Xinlei/Shitou has been selling,<strong> </strong>on average, two of its four-wheeled fully enclosed models every day, a saleswoman boasts. Younger couples prefer four wheels, she adds, while older people usually want three. When asked about the possibility of a tiny car being confiscated, she draws in a breath. “Don’t go on the main roads. Don’t make a business out of it,” she advises.</p>



<p>At least one of Zhengyang Road’s customers isn’t listening: Guo Caiying, who works primarily in the construction-supply industry,<strong> </strong>chauffeurs Fengtai residents around her district. She has a sticker on her tiny car’s back window with the phone number of her car dealer. Guo’s car looks like a golf cart, with cushioned brown seats enclosed by windows. A red <em>fudai</em>, a lucky charm, swings from the ceiling, its characters spelling out “peace.” There is enough space for two people to comfortably sit upright but not enough to extend your legs without hitting the plexiglass divider between driver and passenger. The car tops out at 40 kilometers an hour, and<strong> </strong>as a result, Guo never ventures beyond Fengtai — a borderland where urban and rural meet.</p>



<p>Guo wears the uniform of the countryside: a padded jacket. She is from Henan, a province 800 kilometers southwest of Beijing, and speaks its dialect. Guo starts taking calls from her regulars around 7 a.m., arriving at their door whenever they want to be picked up. She stops driving at 9 a.m., when the traffic police begin work. She characterizes her customers as “people with money who sit in offices.” Once, while in the middle of a trip, Guo saw a cop stop a car like hers. She kept driving, but dropped her passenger off before their destination. Now, if a customer calls her after 9:00, she sends her husband to pick them up with his electric scooter. He charges 75 cents (5RMB), which is half her price. Guo’s flat rate was fixed by the tiny-cab drivers who preceded her.</p>



<p>The economy of tiny cars depends on such informal practices.<strong> </strong>When asked whether she would consider undercutting other drivers, Guo is adamant. “No one can break the rules,” she says. There are local WeChat groups for tiny-car drivers that new owners are inducted into upon purchasing one. Within these groups, members swap information on the whereabouts of local cops and whether anyone has been fined or had their car taken away.</p>



<p>Despite the risks, Guo still thinks it’s worth being a tiny-car driver to make a little pocket money.<strong> </strong>Tiny cars are part of a last-mile economy that flourishes at the beginning and end of the workday. Many Fengtai residents are employed at the local high-tech park, which is host to thousands of businesses. It takes 20 minutes to walk from one end of the park to the other, a trip many would rather make by tiny car. The cars’ main competitors are share bikes, which are cheaper but lack space for luggage and can’t be split with a friend. Tiny cars are also more social — a feature Guo tries …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/tesla-vs-tiny-cars/">https://restofworld.org/2021/tesla-vs-tiny-cars/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/tesla-vs-tiny-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232760</guid>
            <pubDate>Tue, 23 Feb 2021 01:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full list of online communities for programmers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232689">thread link</a>) | @gruppo11
<br/>
February 22, 2021 | https://thehiveindex.com/topics/software-development/?r=hn | <a href="https://web.archive.org/web/*/https://thehiveindex.com/topics/software-development/?r=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>About this Topic</h2><p>This is a list of communities dedicated to engineers, software developers, coders, and hackers. Some are online communities dedicated to a particular technology or programming language, and some are general purpose communities or those that help developers early in their career. The communities on this list are an excellent source of inspiration, knowledge-sharing, and networking.</p><h2><div><p>60</p><!-- --><p> Online </p><!-- --><p>Communities</p><!-- --><p> for Software Developers</p></div></h2><p>This topic's list is getting pretty long! Feel free to use the Platform/Feature filters above to cater the search to you.</p><div><p>Know a </p><!-- --><p>Software Development</p><!-- --><p> community that is not on this list yet? Please <a href="https://thehiveindex.com/submit/">submit it</a>!</p></div></div></div>]]>
            </description>
            <link>https://thehiveindex.com/topics/software-development/?r=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232689</guid>
            <pubDate>Tue, 23 Feb 2021 01:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS-TV-Out Restoration Project]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26232600">thread link</a>) | @max-m
<br/>
February 22, 2021 | https://lostnintendohistory.github.io/DS-TV-OUT | <a href="https://web.archive.org/web/*/https://lostnintendohistory.github.io/DS-TV-OUT">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<h2 id="introduction">Introduction</h2>

<p>During late 2020, we discovered that the Nintendo DS Lite had a leftover feature in its SoC allowing it to easily have cheap hardware video output. With a little circuitry and some software hacks, we were able to restore it and make it usable for anyone. No FPGA’s, no bulky or cumbersome hardware. This mod is specially useful to revive consoles with only the lower screen, being able to watch the upper screen on your TV. Or to create a GBA Macro with additional TV Output.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/DSTVOUT.jpg" width="250" height="250"><br></center>
<center>
  <b>First iteration of the TV-OUT board in action</b>
  </center>

<h2 id="installation">Installation</h2>

<p>If you are just interested in installation, this is the current method <strong>while we work on simpler methods</strong> and more features you have requested:</p>

<ol>
  <li>Install the <a href="https://ezflash.sosuke.com/wiki/index.php/Flashme">flashME CFW</a> (Custom FirmWare) on your DS Lite</li>
  <li>Connect the Nintendo DS Lite’s upper screen flex to the PCB board.</li>
  <li>Donwload the “NDS TV OUT ENABLE.nds” homebrew from the <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">NDS TV OUT repo</a></li>
  <li>Download <a href="https://github.com/DS-Homebrew/TWiLightMenu/releases">Twilight Menu</a></li>
  <li>Copy both the NDS TV OUT ENABLE and Twilight Menu .nds files to a flashcart.</li>
  <li>Use flashme to autoboot into the flashcart. You can do this by pressing A + B + Start + Select while booting. Run Twilight menu, and from there, run the enabler homebrew.</li>
  <li>The console will return to Twilight Menu. Now you can use the buttons on the board to swap between the different screen modes (Upper Screen to TV, Bottom Screen to TV, etc) and launch your games.</li>
</ol>

<hr>

<h2 id="software">Software</h2>

<p>The retail firmware of the Nintendo DS Lite disables this specific feature early in the boot process. To reenable it, we use a custom firmware like flashme, which is very easy to install and is required only once, plus a homebrew. Despite that, we are working on an even simpler solution to make it available to as many people as possible, our own custom firmware which integrates patches to enable this feature directly on boot. Additionally, we are currently working with homebrew developers to integrate control of this new feature into existing software for the DS Lite.</p>

<h2 id="hardware">Hardware</h2>

<p>This feature is only found on the Nintendo DS Lite. Nintendo DS Phat does not contain this feature nor does the Nintendo DSi. It is important to remark that <strong>this is not the same hardware</strong> found on Devkits or other special units. This hardware feature is present in virtually <strong>every single Nintendo DS Lite</strong> out there. The reason why it was left there is unknown, but as said before, it is not related to development units, those use a different video capture hardware. Perhaps Nintendo imagined the Nintendo Switch as early as 2006?</p>

<center><img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/PCB_Rev_11.png" width="350" height="400"></center>

<p>We only need a few extra hardware components to make this video signal usable. You will be able to download the schematics and gerber files for our open hardware circuit board <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">from the repository</a>. The latest version is revision 1.2 which fixes some minor issues with a component in the board.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/Prototype.jpg" width="350" height="350"><br>
</center>
<center>
  <b>First prototype and tests before designing a proper board</b></center>


<p>The final, production-ready board contains a DAC (Digital to Analogue Converter) which turns the 10 bits digital signal at 16.7 MHz provided by the DS Lite into a proper analogue signal. This signal then goes through an operational amplifier and it’s ready to be delivered to your nearest TV trough composite video.</p>

<p>We are currently considering creating an additional PCB revision which would allow to install the mod on consoles without lossing a working upper screen.</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://lostnintendohistory.github.io/DS-TV-OUT</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232600</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bombard Story]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26232597">thread link</a>) | @jbergstroem
<br/>
February 22, 2021 | https://greatestadventurers.com/the-bombard-story/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-bombard-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-618" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Bombard Story</strong> is the account of <a href="https://en.wikipedia.org/wiki/Alain_Bombard">Alain Bombard’s</a> amazing journey in 1952 across the <a href="http://greatestadventurers.com/the-north-west-passage-by-roal-amundsen/">Atlantic</a> on a small 14-foot inflatable boat. Alain Bombard left without food or fresh water and sailed 4.400 kilometers. He lost 25 kg. but proved his point: Man can actually survive on ocean water for an extended period of time!</p>
<figure id="attachment_619" aria-describedby="caption-attachment-619"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" alt="The Bombard Story" width="300" height="203" data-src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-619">In this small vessel Bombard sailed across the Atlantic – without freshwater</figcaption></figure>
<p>As a doctor, Bombard was concerned about the hundreds of deaths at sea every year related to sailors drinking ocean water. He developed the theory that humans can not just survive but live for years on seawater. This sounds very strange, but his big idea was to begin drinking seawater, while you are still hydrated – and in small quantities. It turns out that saltwater is only dangerous if you are dehydrated and suddenly drink large amounts of it. – The way shipwrecked sailors typically would do when they run out of fresh water. From the book:</p>
<blockquote><p>For some time I had made a study of the resistance of the human organism to privations and had convinced myself that it was possible for an individual to survive beyond the limits normally assigned by physiological science. I had paid particular attention to the case histories of political deportees, prisoners, and undernourished populations. But, with my background as a doctor, for whom the teachings of science remain a dead letter unless they can find practical application, my theoretical studies only seemed to lead to the question: ‘What use can made of this knowledge?’</p></blockquote>
<p>Bombard ate spoonfuls of plankton that he collected in a fine net and he also drank juice made from pressed fish he caught along the way. Sound disgusting, but the man survived and he might have discovered an important piece of knowledge for survival on the ocean.</p>
<p>Download the free PDF e-book here (223 pages/38MB):</p>
<h3><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" alt="" width="35" height="35" data-src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">&nbsp;<a href="http://greatestadventurers.com/wp-content/uploads/2021/02/The-Bombard-Story-1953.pdf">The Bombard Story 1953</a></h3>

		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-bombard-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232597</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Basics of (Statistical) Modeling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232497">thread link</a>) | @dcu
<br/>
February 22, 2021 | https://blog.chewxy.com/2021/02/17/modeling-basics/ | <a href="https://web.archive.org/web/*/https://blog.chewxy.com/2021/02/17/modeling-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<div>
<article role="main">
<p>I had a very interesting chat with a few data science students yesterday. Part of the chat involved the idea of statistical modeling. Throughout the chat, it occured to me that the students didn’t have a very good grasp of what modeling is. To their credit, they were proficient in the techniques of linear regression, and deep learning, but I got the sense that they were very much pushing buttons and watching things happen rather than understanding what they were actually doing. There was no sense of a big picture view.</p>
<p>This has been happening quite a lot lately. I find it somewhat alarming. This blog post is a semi-transcript of what I said last night. It aims to be as simple as possible.</p>

<p>A model is a representation of reality. It’s what we think reality looks like.</p>
<p>For example, we live on Planet Earth, in a solar system. We can build models of our Solar System. Here’s an example of a model of our Solar System.</p>

<div>
<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
<p><img itemprop="thumbnail" src="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" alt="An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/10413717@N08/7527137708">
</p>
<a href="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" itemprop="contentUrl"></a>
<figcaption>
<p>An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/<a href="https://blog.chewxy.com/cdn-cgi/l/email-protection" data-cfemail="1726272326242026205759272f">[email&nbsp;protected]</a>/7527137708</p>
</figcaption>
</figure>
</div>
<p>As a child, such models of our solar system endlessly fascinate. I would spend hours thinking about how the planets moved. I would play and watch the planets spin around its spindles. I understood that there was a force called gravity that caused the planets to orbit the sun. As I grew older, the physical model of our Solar System is gradually replaced by <a href="https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion">three laws</a>.</p>
<p>There are parts of the model we can study:</p>
<ul>
<li>What is the shape of the orbits</li>
<li>How the planets move</li>
<li>Why do planets move thus</li>
</ul>
<p>These are sub-models of the model of our Solar System. The shape of the orbit is given by Kepler’s First Law. How planets move is given by Kepler’s Second and Third Law. Why do planets move thus is given by Newtonian mechanics.</p>
<p>Each of Kepler’s laws have an equation governing them. So we can say the equations model our Solar System. The equations are the model of our Solar System. These equations describe something static (the shape of the orbit) and represent something dynamic (how the planets move). What used to be physical motion in a physical model can now be written down on a piece of paper, an equation representing the real thing.</p>

<p>There are many ways of making a model. Sometimes it’s useful to have a physical understanding of something. <a href="https://blog.chewxy.com/2021/01/09/sars-cov-2/">I built the 2019-SARS-CoV-2 virion</a> to help me have a better understanding of the coronavirus that caused the pandemic in 2020. Now, I’m no biologist, so my model is crude. My model is extremely physical. Despite this, it gave me an understanding of how a mRNA vaccine might work. It gave me confidence over what actual proper scientists are doing.</p>
<p>So making a physical model is one way. But what if we want something more rigorous? The usual way is to resort to some sort of formalism. Various fields have various formalisms. For example, in chemistry, you use chemical equations. However, the most common formalism would be a mathematical equation. Maths equations are used in physics, economics, biology, and many other fields.</p>
<p>So how do you create an equation that becomes a model of something? There are two ways:</p>
<ol>
<li>Generate an equation.</li>
<li>Find an equation from data.</li>
</ol>
<p>In the large scheme of things, both of these amount to the same thing: generating an equation. I’ll talk about that in a later section. For now, when I say “model generation” I mean generating an equation that models reality.</p>
<h2 id="how-do-you-generate-an-equation">How Do You Generate An Equation?</h2>
<p>The simplest way of generating an equation is to randomly generate one by writing down symbols on a piece of paper.</p>
<p>That’s daft, you say. You’d be hard pressed to find a equation that adequately describes the situation!</p>
<p>That’s why most model generation comes from <a href="https://en.wikipedia.org/wiki/First_principle">first principles</a>. In using the Solar System example, if we accept Newton’s law of universal graviatation ($F = G{\frac {Mm}{r^{2}}}$), then we can work our way to find Kepler’s third law. Kepler’s other laws require other first principles such as trigonometry.</p>
<p>The key is that you understand a subject well enough that you may generate further models about the subject using your basic understanding.</p>
<p>However, random generation has its place. In fact, from here on, whenever I write “generate a model”, you may think of a person randomly coming up with math equations.</p>
<h2 id="how-do-you-find-an-equation-from-data">How Do You Find An Equation From Data?</h2>
<p>There may be cases where first principles may not be used. This is often the case in new fields.</p>
<p>So the next best way is to find an equation from data. There are many ways to do them. Regression analysis is one such way of finding an equation from data. Let’s look at a simple example of linear regression with one variable.</p>
<p>The fundamental idea of a linear regression is that you plot your data points, and draw a straight line through the plot (line A). Each data point would be some distance away from line. Sum those distances up and square them. Call it the “error”. Now draw another line through the plot (line B) and find the errors of B. Keep doing until you find a line that has the lowest amount of errors.</p>
<p>This is the line-of-best-fit. Given that all straight lines on a plot can be described by an equation that looks like $y = mx +C$, the equation that describes the line of best fit (e.g. $y=2x + 1$) is the model.</p>
<p>This idea of model building extends all the way to deep neural networks. They key being the model is built by looking at the relationships between the variables that make up a data point.</p>

<p>The whole point of creating a model is to reflect reality. I could well come up with a model of gravity that says this: all objects exert a force on each other that is quadratic on the distance between them - written as $F = d(a, b)^2$. But does this reflect reality? No.</p>
<p>How do I know this? I know this because I can test it. I can collect data, and then check if the data fits my model. In the silly example above, it’s trivial to check with a counterpoint: I am able push something off my desk. If the force is solely based on distance, then as my hand approaches the object, the force should get smaller and smaller to the point that I am unable to affect the object.</p>
<p>In many courses about regression analyses, the R² values are often taught to students as a measure of how good one’s model is<span><span></span><span>I find this to be mostly true about "data science" courses/bootcamps, but not more traditional uni level course on regression/economics/statistics</span></span>. It’s not! A R² value is how good the fit of data to the line is. In some sense you may think of this as the inverse of “how good is your model” . It’s more “how much data fits in your model”. Indeed, the R² value is indicative of how much variance of your data is covered by the model.</p>
<p>This is not to say that the courses are wrong. The statement that “R² tells you how good your model is” is a very subtle statement. Let’s unpack them. Let’s say you found a line of best fit that is described by the formula $y = 2x + 15$. This is the model that we have “generated”. Now we want to see how much of reality (our dataset) is described by the model. It is in this sense that R² represents the notion of how “good” a model is.</p>
<p>Now it seems a bit weird, given that we used the dataset to find the line of best fit, and then we turn around and say we generated a model, not let’s test to see how good it is. There seems to be a bit of circular logic to it. However there are a lot of theoretical work on why the line of best fit found by a ordinary least squares (OLS) regression is a good model “generator” - the wikipedia article on <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">OLS</a> covers quite a bit, as does the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">Gauss-Markov theorem</a> article. Most textbooks also lay out proofs of why OLS estimators are BLUE (Best Linear Unbiased Estimator).</p>
<p>Here I want to point out that “reality” is itself just a sample. The dataset that you use to generate a model is just a sample. This is where conscious sampling of data is important. Let’s imagine we are training a machine learning system to recognize faces. My social circle are White or Asian. So if I ask my social circle to send me some photographs of their faces to train a machine learning system, then the machine learning system would not be able to recognize faces that are not White or Asian! Clearly this is not a good representation of reality.</p>
<p>This trivial example only scratches the surface of equitable conscious collection of sample “reality” for the sake of model building. This topic is a very deep topic and it’ll take many blog posts to talk about it. So I shall leave it be for now.</p>
<p>In more advanced machine learning modeling systems (e.g: deep learning systems), it is common to split the dataset into “training” and “testing” datasets. The model is trained on the training dataset and tested on the testing dataset. This is to ensure that the model does not only model “reality” that is in the training dataset, but can also generalize to previously unseen data.</p>
<p>What I am trying to convey here is that sanity checks against reality is a good thing. We should do them more often.</p>

<p>Having said that, we have to accept that models are just that - models. They are not reality. George Box had a good saying:</p>
<blockquote>
<p>All models are wrong. But some are useful.</p>
</blockquote>
<p>The key is to find a model that is useful enough for what you need to do. Let the natural philosophers worry about the most accurate models of reality.</p>

<p>Humanity is always generating models. Individually, in our brains, we generate internal models that are corrected every second of the day. Consider catching a ball. Your brain generates a model of physical reality - no equations here - telling us where the ball is going to be. As the ball arcs through the air, we update the models in our brain, getting better and better predictions, resulting in us catching the ball. Or in my case, the ball lands on my face.</p>
<p>Communally, we generate models too. The invention of writing and speech allowed us to share models with other individuals. We started using things like maths equations to make our meanings clear. Our …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.chewxy.com/2021/02/17/modeling-basics/">https://blog.chewxy.com/2021/02/17/modeling-basics/</a></em></p>]]>
            </description>
            <link>https://blog.chewxy.com/2021/02/17/modeling-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232497</guid>
            <pubDate>Tue, 23 Feb 2021 00:33:09 GMT</pubDate>
        </item>
    </channel>
</rss>
