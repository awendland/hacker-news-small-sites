<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 12 Feb 2021 12:39:51 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 12 Feb 2021 12:39:51 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[We almost got acquired by Facebook and failed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26087271">thread link</a>) | @joaodmj
<br/>
February 10, 2021 | https://johndamaia.com/how-we-almost-got-acquired-by-facebook-and-failed | <a href="https://web.archive.org/web/*/https://johndamaia.com/how-we-almost-got-acquired-by-facebook-and-failed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://johndamaia.com/how-we-almost-got-acquired-by-facebook-and-failed</link>
            <guid isPermaLink="false">hacker-news-small-sites-26087271</guid>
            <pubDate>Wed, 10 Feb 2021 09:47:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My go-to tool for reading long JSON snippets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26086229">thread link</a>) | @bengtan
<br/>
February 9, 2021 | https://bengtan.com/blog/reading-long-json-snippets/ | <a href="https://web.archive.org/web/*/https://bengtan.com/blog/reading-long-json-snippets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    

    
    <p><a href="https://www.json.org/json-en.html">JSON</a> is ubiquitous and I often run into it whilst developing or debugging.</p>
<p>When it’s in raw form like this …</p>
<p><img src="https://bengtan.com/blog/reading-long-json-snippets/plaintext.jpg" alt="json as raw text"></p>
<p>it’s hard for a human to interpret.</p>
<p>For small snippets, I could copy-and-paste it into a text file and hand-prettify it. For long snippets, that’s obviously not scalable.</p>
<p>I stumbled upon a very useful tool for interpreting and analysing (extremely) long JSON snippets. The surprising thing is that it’s been around for a long time and I just never noticed. However, once I knew about it, I kept using it, and it’s now my go-to tool for analysing long JSON snippets.</p>
<p>The tool?</p>
<p><strong>Mozilla Firefox.</strong></p>
<p>Yes, the web browser. (It also helps that Firefox is my main browser.)</p>
<p>Here is a link to a random JSON file from the internet:</p>
<p><a href="https://raw.githubusercontent.com/bengtan/bengtan.github.io/main/content/css-named-colours-picker/dist/main.js.map">https://raw.githubusercontent.com/bengtan/bengtan.github.io/main/content/css-named-colours-picker/dist/main.js.map</a></p>
<p>If you click on the link with Firefox you get something human-unfriendly:</p>
<p><img src="https://bengtan.com/blog/reading-long-json-snippets/plaintext.jpg" alt="json as raw text"></p>
<p>However, if you open a file with a <code>.json</code> extension on your local computer , you get …</p>
<p><img src="https://bengtan.com/blog/reading-long-json-snippets/json.png" alt="json in firefox json browser"></p>
<p>… which is a nice and useful and human-friendly json browser with collapsible sections, pretty printing and <strong>filtering</strong>.</p>
<p>(I think Firefox shows the json browser when the mimetype is set to json, and opening a local file with a <code>.json</code> extension is an easy way to set the mimetype.)</p>
<p>I stumbled upon this by chance. But since then, everytime I have a long JSON snippet to debug, I save it to a text file, give it a <code>.json</code> extension and open it with Firefox.</p>
<p>* * *</p>
<p>Okay, so installing Firefox just to browse JSON is probably overkill, but this is great for me since I already use it.</p>
<p>I’m glad Firefox is my main browser.</p>

    
      



    
  </article>


  
</div>
    </div></div>]]>
            </description>
            <link>https://bengtan.com/blog/reading-long-json-snippets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26086229</guid>
            <pubDate>Wed, 10 Feb 2021 06:32:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“The New Internet” Browser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26085975">thread link</a>) | @democracywatch
<br/>
February 9, 2021 | https://www.thenewinternet.com/downloads | <a href="https://web.archive.org/web/*/https://www.thenewinternet.com/downloads">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.thenewinternet.com/downloads</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085975</guid>
            <pubDate>Wed, 10 Feb 2021 05:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let’s compare the cloud shells offered by AWS, Microsoft Azure, and GCP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26085615">thread link</a>) | @dtrailin
<br/>
February 9, 2021 | https://seroter.com/2021/02/03/lets-compare-the-cloud-shells-offered-by-aws-microsoft-azure-and-google-cloud-platform/ | <a href="https://web.archive.org/web/*/https://seroter.com/2021/02/03/lets-compare-the-cloud-shells-offered-by-aws-microsoft-azure-and-google-cloud-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8596" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">

	<!-- .entry-header-wrapper -->

	<div itemprop="text">
		
<p>I keep getting more and more powerful laptops, and then offloading more and more processing to the cloud. SOMETHING’S GOTTA GIVE! My local machine doesn’t just run web browsers and chat apps. No, my laptop is still loaded up with dev tools, while all my virtual machines and container clusters now live in the cloud. That helps. But we’re seeing  more and more of the dev tools sneak into the cloud, too.</p>



<p>One of those dev tools is the shell experience. If you’re like me—actually, you’re probably much more advanced than me—you invest in a loaded terminal on your machine. On my Mac, I directly install a few tools (e.g. git, gcloud CLI) but use Homebrew to keep most of my favorite tools close by. </p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png"><img data-attachment-id="8600" data-permalink="https://seroter.com/2021-02-03-shell-01/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png" data-orig-size="1200,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-01" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-01.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>It’s no small effort to maintain a local terminal environment that’s up to date, and authenticated to various endpoints. To make all this easier, each of three hyperscalers now has a “cloud shell” experience that offers developers a hosted, pre-loaded terminal for working with that cloud.</p>



<p><strong>In this blog post, I’m going to look at the cloud shells from AWS, Microsoft Azure, and Google Cloud, and see what they really have to offer.</strong> Specifically, I’m going to assess:</p>



<ul><li><strong>Shell access.</strong> How exactly do you reach and use the shell?</li><li><strong>Shells offered</strong>. Bash? Powershell?</li><li><strong>Amount of storage provided</strong>. How much can you stash in your environment?</li><li><strong>Durability period</strong>. How long does each cloud hold onto your compute environment? Storage?</li><li><strong>Platform integrations</strong>. What ways does the shell integrate with the cloud experience?</li><li><strong>Embedded tools</strong>. What comes pre-loaded in the shell?</li><li><strong>Code editing options</strong>. Is there a way to edit files or build apps?</li><li><strong>Compute environment configuration/extensibility</strong>. Can you change the shell environment temporarily or permanently?</li><li><strong>UX and usability controls</strong>. What can you do to tweak the appearance or behavior?</li></ul>



<p>Let’s take a look.</p>



<p><em>Disclaimer: I work for Google Cloud, so obviously I’ll have some biases. That said, I’ve used AWS for over a decade, was an Azure MVP for years, and can be mostly fair when comparing products and services. Please call out any mistakes I make!</em></p>







<p>GCP offers a Cloud Shell that <a href="https://cloud.google.com/shell/docs/how-cloud-shell-works">runs within a Docker container on a dedicated Google Compute Engine virtual machine</a>. Not that you see any of that. You just see a blinking cursor.</p>



<p>How do you reach that cursor? From within the GCP Console, there’s an ever-present button in the top navigation. Of note, you can also access it via a dedicated link at <a href="https://shell.cloud.google.com/">shell.cloud.google.com</a>.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png"><img data-attachment-id="8604" data-permalink="https://seroter.com/2021-02-03-shell-02/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png" data-orig-size="1200,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-02" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-02.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Once you launch the Cloud Shell—and if it’s the first time, you’ll see a brief message about provisioning your infrastructure—you see a new frame on your screen. Note that this is a globally distributed service, and <a href="https://cloud.google.com/shell/docs/how-cloud-shell-works#zone_selection">you’re automatically assigned to the closest geographic region</a>. </p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png"><img data-attachment-id="8606" data-permalink="https://seroter.com/2021-02-03-shell-03/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png" data-orig-size="1200,626" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-03" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-03.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Each user gets <strong>5GB of persistent storage</strong> that’s mounted into this underlying virtual machine. This <strong>VM terminates after 20 minutes</strong> of inactivity. If you don’t use Cloud Shell at all for 120 days, the home disk goes away too. </p>



<p>You have <strong>two default shell interpreters</strong> (Bash and sh) at your disposal here. Google Cloud Shell lets you create unique sessions via tabs, and see below that I’m using one tab to list all the shells. I was able to switch between shells, including PowerShell too!</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png"><img data-attachment-id="8611" data-permalink="https://seroter.com/2021-02-03-shell-05/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png" data-orig-size="1200,870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-05" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-05.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Cloud Shell comes with lots of <a href="https://cloud.google.com/shell/docs/how-cloud-shell-works#tools"><strong>pre-loaded tools</strong></a> including gcloud, vim, emacs, gradle, helm, maven, npm, pip, git, docker, MySQL client, TensorFlow, and Terraform. It also has built-in <a href="https://cloud.google.com/shell/docs/how-cloud-shell-works#language_support">language support</a> for Java, Go, Python, Node.js, Ruby, PHP, and .NET Core.</p>



<p>If you want tools that aren’t pre-loaded by Google Cloud, you’ve got a few options. You can manually install tools during your session, or, <a href="https://cloud.google.com/shell/docs/configuring-cloud-shell#environment_customization">create a customer_environment script</a> that runs whenever your instance boots up.</p>



<p>What about <strong>platform integrations</strong>? If you call a Google Cloud API that requires credentials, there’s a <a href="https://cloud.google.com/shell/docs/auth">prompt for authorization</a>. There’s also an “<a href="https://cloud.google.com/shell/docs/open-in-cloud-shell">Open in Cloud Shell</a>” feature that makes it simple to create links that trigger opinionated Cloud Shell instances. If you’re writing tutorials or want people to try the code in your git repo, you can generate a link. There’s also a baked-in <a href="https://cloud.google.com/shell/docs/using-cloudshell-command">cloudshell CLI</a> to launch tutorials, download files, and more. You can also use the gcloud CLI on your local workstation to tunnel into the Cloud Shell, thanks to the <a href="https://cloud.google.com/sdk/gcloud/reference/beta/cloud-shell">gcloud beta cloud-shell</a> operation.</p>



<p>The Google Cloud Shell also has a full-fledged <strong>code editor built in</strong>. This editor—also available directly via <a href="https://ide.cloud.google.com/">ide.cloud.google.com</a>—gets launched right from the Cloud Shell, either through the button on the Cloud Shell navigation or by invoking the <code>cloudshell edit .</code> command.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png"><img data-attachment-id="8616" data-permalink="https://seroter.com/2021-02-03-shell-06/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png" data-orig-size="1200,860" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-06" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-06.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>This editor is based on Eclipse Theia and has the Cloud Code extensions built in. This means I can create apps, use source control, link to GCP services, run tests, and more. Because Cloud Shell <a href="https://cloud.google.com/shell/docs/using-web-preview">supports Web Preview</a>, you can also start up web applications and hit a local endpoint.</p>



<p>Let’s look at the overall <strong>user experience</strong>. In the Cloud Shell navigation menu, I have options to send key combinations (e.g. Ctrl+V), change the look and feel (e.g. color, font), upload or download files, run in safe mode, restart the Cloud Shell instance, minimize the frame itself, break it out into its own window, or close the terminal entirely.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png"><img data-attachment-id="8618" data-permalink="https://seroter.com/2021-02-03-shell-07/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png" data-orig-size="2080,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-07" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=2048 2048w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-07.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>With this mix of free storage, a wide set of tools, a fully functional code editor, and easily extendible environments, the Google Cloud Shell feels like a very complete experience.</p>







<p>Azure provides a <a href="https://azure.microsoft.com/en-us/features/cloud-shell/">Cloud Shell</a> that runs on a temporary virtual machine. Like with GCP, all the infrastructure details are invisible, and users just get a virtual terminal.</p>



<p>You have a few ways to reach Azure’s Cloud Shell. There’s an always-there button in the Portal and a direct link available at <a href="https://shell.azure.com/">shell.azure.com</a>.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png"><img data-attachment-id="8621" data-permalink="https://seroter.com/2021-02-03-shell-08/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png" data-orig-size="1200,556" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-08" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-08.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Once you trigger the Cloud Shell, you quickly get a new resizable frame holding your terminal instance.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png"><img data-attachment-id="8623" data-permalink="https://seroter.com/2021-02-03-shell-09/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png" data-orig-size="1200,928" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-09" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-09.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>The compute instance is available at no charge. These instances use a <strong>5GB persistent storage</strong> image in your file share, and it appears that you pay for that. Like the Google Cloud Shell, the Azure one uses non-durable compute nodes that time out after <strong>20 minutes of inactivity</strong>.</p>



<p>You have <strong>two shell experiences</strong>: bash or PowerShell. Storage is shared between each.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png"><img data-attachment-id="8625" data-permalink="https://seroter.com/2021-02-03-shell-10/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png" data-orig-size="814,1194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-10" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=205" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=698" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=698" alt="" width="400" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=698 698w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=102 102w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=205 205w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-10.png 814w" sizes="(max-width: 698px) 100vw, 698px"></a></figure>



<p>The Azure Cloud Shell comes <a href="https://docs.microsoft.com/en-us/azure/cloud-shell/features#tools">absolutely loaded with <strong>tools</strong></a>. You have all the standard Azure tools (Azure CLI, azcopy, etc) along with things like vim, emacs, git, maven, npm, Docker, kubectl, Helm, MySQL client, PostgreSQL client, Cloud Foundry CLI, Terraform, Ansible, Packer, and more. There’s also built-in language support for Go, Ruby. .NET Core, Java, Node.js, PowerShell, and Python. I didn’t see any obvious way to customize the experience that lasts beyond a given session.</p>



<p>As far as <strong>integrations</strong>, it appears there is SSO with Azure Active Directory. There’s also a special PowerShell commandlet for managing Exchange Online. Try to control yourselves. Similar to GCP, the Azure Cloud Shell supports a URL format that lets tutorial creators launch the Cloud Shell from anywhere. Visual Studio Code users can also <a href="https://microsoft.github.io/AzureTipsAndTricks/blog/tip49.html">integrate the Azure Cloud Shell into their local dev experience</a>.</p>



<p>Azure also provides a handy <strong>code editor</strong> within their Cloud Shell experience. Based on the open source Monaco editor, has a basic file explorer, command palette, and language highlighting.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png"><img data-attachment-id="8627" data-permalink="https://seroter.com/2021-02-03-shell-11/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png" data-orig-size="1200,934" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-11" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-11.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Let’s look at the <strong>user experience</strong>. In the Cloud Shell navigation bar, you have buttons to restart the shell, configure font style and size, download files, upload files, open the code editor, trigger a local web server, minimize the frame, or shut it down. </p>



<p>All in all, it’s a solid experience. Not as rich as what GCP has, but entirely functional with nice touches like the code editor, and easy switching between bash and PowerShell.</p>







<p>AWS is the newest entrant to the cloud-based terminal with their <a href="https://aws.amazon.com/cloudshell/">AWS CloudShell</a>. AWS seems careful to call the host a “<a href="https://docs.aws.amazon.com/cloudshell/latest/userguide/vm-specs.html#vm-configuration">computing environment</a>” versus ever saying “virtual machine.” It’s possible that you get a container in a shared environment.</p>



<p>It looks like you have one way to reach the CloudShell. There’s a button in the AWS Console navigation bar. </p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png"><img data-attachment-id="8630" data-permalink="https://seroter.com/2021-02-03-shell-13/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png" data-orig-size="1200,576" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-13" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-13.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Clicking that button pops up a new browser instance holding your terminal. </p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png"><img data-attachment-id="8632" data-permalink="https://seroter.com/2021-02-03-shell-14/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png" data-orig-size="1200,452" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-14" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-14.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>There’s no cost for AWS CloudShell and you get <strong>1GB of persistent storage</strong> (also for free). The service is available in a handful of AWS regions (3 in the US, 1 in Ireland, 1 in Tokyo). Sessions expire after 20-30 minutes, and <strong>data is held for 120 days</strong>.</p>



<p>AWS CloudShell has <a href="https://docs.aws.amazon.com/cloudshell/latest/userguide/working-with-cloudshell.html#using-shells"><strong>three shell experiences</strong></a> including bash, PowerShell, and z shell. </p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png"><img data-attachment-id="8634" data-permalink="https://seroter.com/2021-02-03-shell-15/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png" data-orig-size="1000,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-15" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=1000" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png 1000w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-15.png?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></figure>



<p>The AWS CloudShell comes with a handful of useful <strong>pre-loaded tools</strong>. You get the AWS tools (e.g. AWS CLI, AWS SAM), as well as git, make, ssh, and vim. You can modify the default environment by creating a .bashrc script that runs whenever the bash shell fires up. There’s native language support for Node.js and Python. </p>



<p>There’s one <strong>platform integration</strong> I noticed, which helps you <a href="https://docs.aws.amazon.com/cloudshell/latest/userguide/tutorial-code-commit.html">push and pull code</a> from AWS CodeCommit. </p>



<p>There are some nice touches in the AWS CloudShell <strong>user experience</strong>. I like that you can stack tabs (session) or put them side by side. You can also download and upload files. AWS also offers settings to change the font size or switch from dark mode to light mode.</p>



<figure><a href="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png"><img data-attachment-id="8636" data-permalink="https://seroter.com/2021-02-03-shell-16/" data-orig-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png" data-orig-size="1200,518" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021.02.03-shell-16" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=300" data-large-file="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=730" src="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=1024" alt="" srcset="https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=1024 1024w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=150 150w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=300 300w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png?w=768 768w, https://seroter.files.wordpress.com/2021/02/2021.02.03-shell-16.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>AWS offers a functional experience that’s basic, but useful for those living in an AWS world.</p>



<p>It’s great to see all the major clouds offering this functionality. GCP objectively has the most feature-rich experience, but each one is useful. Try them out, and see if they can make your dev environment simpler.</p>
			
			
						</div><!-- .entry-content -->

	<!-- .entry-meta -->

</article></div>]]>
            </description>
            <link>https://seroter.com/2021/02/03/lets-compare-the-cloud-shells-offered-by-aws-microsoft-azure-and-google-cloud-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085615</guid>
            <pubDate>Wed, 10 Feb 2021 04:03:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Great Semiconductor Shortage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26085598">thread link</a>) | @totaldude87
<br/>
February 9, 2021 | https://finshots.in/archive/the-great-semiconductor-shortage/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/the-great-semiconductor-shortage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2021/02/chip4.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2021/02/chip4.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2021/02/chip4.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2021/02/chip4.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2021/02/chip4.jpg" alt="The Great Semiconductor Shortage">
            </figure>

            <section>
                <div>
                    <p><em>Car companies are halting production because their vendors can't supply electronic components. Laptops are struggling to meet demand because they don’t have computer chips. Mobile phone companies are having to pay through the roof to source critical parts. And it’s all happening because the world is witnessing an unprecedented semiconductor shortage. So in today’s Finshots, we talk about this and more.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Companies dabbling with semiconductors are in a highly specialized business. They are few and far between and they spend billions of dollars planning for the future.</p><p>As we wrote in one of our articles <a href="https://finshots.in/archive/nvidia-arm-40-billion-deal/">earlier </a>—</p><blockquote>Intel spent close to <a href="https://www.bloomberg.com/news/articles/2016-06-09/how-intel-makes-a-chip" rel="noopener">$8.5 billion</a> in building a fabricator that could produce its flagship E5 chips. These were sophisticated enterprise-level chips and they weren’t easy to produce. The research and development cost $11.5 billion. Mistakes cost extra. And this doesn’t include time commitments. Companies have to plan years in advance to build this kind of capacity and scaling production can be quite a challenging task.</blockquote><p>So you can’t wake up one day and suddenly ramp up supply. It’s almost next to impossible to achieve this kind of scale. And the likes of Taiwan Semiconductor Manufacturing Company (TSMC) — the largest semiconductor company in the world haven’t been investing aggressively over the past few years. As one article <a href="https://www.counterpointresearch.com/mega-wave-capex-cycle-logic-semiconductor-industry/">notes</a> — <em>“From 2015 to 2019, the capital investment cycle remained conservative across the industry.”</em> It further goes on to add —<em> “Taking a closer look at the semiconductor capital investment trends during the past few years, it becomes clear that under-investment is the root cause of demand-supply imbalance, particularly in logic (non-memory) semiconductor industry.”</em></p><p>And that’s the crux of the problem. We didn’t think we’d need this many semiconductors. Especially the kind we use for computing stuff. The kind that goes on cars, gaming consoles, mobile phones and laptops. And it’s now pushing us to the brink. However, semiconductor companies should have jumped into action last year when it became evident that the supply lines were being stretched thin. They knew it was inevitable. And truth be told, they would have done it if it weren’t for Covid.</p><p>Expanding capacity in the middle of a pandemic isn’t exactly easy. So they were forced to defer plans. And if reports are to be believed, companies are gearing for a massive capacity building exercise this year after having struggled to expand last year. TSMC, for instance, said it would raise nearly $9 billion in a bid to expand in 2021. You’ll likely see other companies follow suit as well. So if all goes well, the problem should be alleviated by the end of 2021.</p><p>However, the current predicament isn’t a result of the supply crunch alone. Companies like Huawei, for instance, have been building semiconductor reserves over the past few years. And the pandemic forced people to spend on sophisticated consumer appliances that further dented supply lines. As an article in Bloomberg <a href="https://www.bloomberg.com/news/articles/2021-02-05/chip-shortage-spirals-beyond-cars-to-phones-and-game-consoles">notes </a>—<em> “Industry executives also blame excessive stockpiling, which began over the summer when <a href="https://www.bloomberg.com/quote/40978Z:CH" rel="noopener">Huawei Technologies Co.</a> — a major smartphone and networking gear maker — began hoarding components to ensure its survival from crippling U.S. sanctions. Led by Huawei, Chinese imports of chips of all kinds climbed to almost $380 billion in 2020…Rivals including Apple, worried about their own caches, responded in kind. At the same time, the stay-at-home era spurred sales of home appliances from the costliest TVs to the lowliest air purifiers, all of which now come with smart, customized chips.”</em></p><p>Also, the impact of this shortage isn’t uniform across the board. The likes of Apple can negotiate better than small time vendors. Meaning, if you are in an industry that sources a lot of semiconductors then you have better bargaining power, plain and simple. Auto manufacturers unfortunately rely on third party vendors who don't source a lot of semiconductors. At least not on a relative scale. So they've been affected real bad. </p><p>Bottom Line — The semiconductor shortage is pulling multiple industries to its knees and now you know why.</p><p>Until then...</p><p>Share this Finshots on <a href="https://api.whatsapp.com/send?text=An%20explainer%20on%20semiconductor%20shortage.%20https://bit.ly/3jFyoi7">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/3p2dCKB&amp;via=finshots&amp;text=An%20explainer%20on%20semiconductor%20shortage.">Twitter</a>, or <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/the-great-semiconductor-shortage">LinkedIn</a>.</p>
                </div>
            </section>


            

            
            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/the-great-semiconductor-shortage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085598</guid>
            <pubDate>Wed, 10 Feb 2021 03:59:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Apple Banning Free Analytics SDKs?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26085129">thread link</a>) | @gdeglin
<br/>
February 9, 2021 | https://steamclock.com/blog/2021/02/apple-tracking-analytics-sdks/ | <a href="https://web.archive.org/web/*/https://steamclock.com/blog/2021/02/apple-tracking-analytics-sdks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Page body">

        



<section id="archive">

    
    
    <div>

        <p><span><span></span></span> Allen Pike • February 8, 2021</p>

        

        <article>
            <p>Apple <a href="https://www.theverge.com/interface/2020/8/27/21402744/apple-idfa-facebook-fight-ads-advertising">announced last summer</a> that they will soon require users to opt in before apps can get the infamous “IDFA” tracking identifier for that user. While this was controversial in the ad tech sphere, most mobile apps can get by without this identifier.</p>

<p>However, most mobile app teams do collect analytics to help make product decisions. What features inspire free users to convert to paid users? Why do we think our trial is converting poorly? Do we still need to support iOS 12? A lot of apps use free SDKs to collect and analyze this kind of data.</p>

<p>The most popular analytics SDKs are free because they’re owned by companies that sell ads, or share data with those companies: Google Analytics, Flurry, and Google’s Firebase. Paid competitors like Mixpanel and Amplitude can be really powerful, but often cost thousands of dollars a year or more.</p>

<p>Now, I can’t find this said explicitly anywhere. But it <em>seems</em> like, along with the incoming restrictions on IDFA and ad attribution, Apple is also enacting a de-facto ban on these free analytics SDKs. The setup looks like this:</p>

<ol>
  <li>Since December, App Store Connect’s <a href="https://developer.apple.com/app-store/app-privacy-details/#user-tracking">App Privacy submission process</a> has required developers to indicate if they have “3rd Party Tracking”. Developers are told to do this if they’re including an SDK from a company that hosts ads or shares data with advertisers across apps.</li>
  <li>In the coming weeks, iOS 14.5 will <a href="https://developer.apple.com/app-store/user-privacy-and-data-use/">require apps that engage in “3rd Party Tracking” to ask explicit permission</a>, which most users will opt out of.</li>
  <li>App Review will soon start rejecting apps that are not following the opt in provisions. They’ll likely do this by comparing the app’s App Privacy metadata to the use of the new opt-in APIs, as well as scanning apps for the presence of certain SDKs.</li>
  <li>Therefore, it seems, <strong>iOS apps currently using the Google Analytics, Flurry, and Firebase SDKs may need to migrate off of them promptly</strong> and instead use an analytics tool not owned by a company that displays ads. Popular choices include Mixpanel, Amplitude, or a self-managed analytics tool.</li>
</ol>

<p>These new rules could be a big hurdle for some developers, especially if they currently rely on other SDKs that do 3rd party tracking or attribution, such as Facebook’s.</p>

<h2 id="do-we-really-have-to">Do we really have to?</h2>

<p>The challenging thing for developers evaluating all this is that many of the points above have not been said so explicitly by Apple. Apple has instead outlined a series of rules, each rule being worded somewhat differently between the App Privacy documentation and the App Tracking Transparency documentation. A generous reading makes it seem like you maybe <em>could</em> comply with the rules and still use some of these SDKs. Maybe.</p>

<p>Apple did not – and from a legal perspective likely can’t – explicitly ban the Google Analytics, Flurry, Facebook, and Firebase SDKs. Their wording leaves some wiggle room. It seems like it <em>could</em> be possible to use them. It seems even more possible that Facebook and Google could make them usable. However, this puts developers in the situation of evaluating the changing documentation, complex privacy policies, and large settings panels that these tools offer, trying to judge whether a given setup of a given SDK would now pass muster from Apple’s perspective.</p>

<p>For example, in App Store Connect – where developers indicate if they have Third Party Tracking – Apple asks if your app is:</p>

<blockquote>
  <p>Sharing data with entities who display third-party ads.</p>
</blockquote>

<p>It seems maybe impossible for a Google-owned analytics SDK to not trigger this provision. In contrast, the AppTrackingTransparency documentation asks whether you are:</p>

<blockquote>
  <p>Placing a third-party SDK in your app that combines user data from your app with user data from other developers’ apps to target advertising or measure advertising efficiency.</p>
</blockquote>

<p>Does it matter if the SDK combines user data <em>in general</em>, or is it sufficient if you’ve been assured that your app’s user data <em>in particular</em> won’t be combined by the SDK? The logical complexities and differences in wording raise questions that, unfortunately, developers need to make assumptions about until we hear something from Apple, or we hear through the grapevine how App Review actually enforces these rules. In particular we need to make three guesses:</p>

<ol>
  <li>Will you be allowed to indicate your app has 3rd Party Tracking, not implement the opt-in dialog, but still get App Review to approve you as long as you believe you’re not required to do opt-in based on your evaluation of the SDK, its settings, and the exact wording in the AppTrackingTransparency documentation? <strong>Our guess is no. It seems likely that Apple will expect that all 3rd Party Tracking requires the opt-in dialog.</strong></li>
  <li>Will you be allowed to include an SDK that App Review considers a “3rd Party Tracking SDK”, but not indicate 3rd Party Tracking in your App Privacy data as long as you believe you’re not required to based on your evaluation of the SDK, its settings, and the exact wording of the App Privacy documentation? <strong>Our guess is no. It seems like Apple will probably consider any use of the Facebook and Google SDKs to be 3rd Party Tracking.</strong></li>
  <li>Is it safe to continue using – or migrate to – 3rd party product analytics tools like MixPanel and Amplitude that are not owned by advertising companies? <strong>Our guess is yes. These rules seem squarely aimed at companies involved in advertising.</strong></li>
</ol>

<p>If one of the above assumptions is wrong – for example, maybe these SDKs <em>can</em> be configured to behave sufficiently privately, and App Review can be convinced that this has been done for your app – then that would be really  useful to know. If anybody has more information on what Apple will or won’t be allowing, or even conflicting hunches, <a href="https://twitter.com/apike">let me know</a>.</p>

<h2 id="does-our-sdk-require-app-tracking-transparency-uh-well">Does our SDK require App Tracking Transparency? Uh… well…</h2>

<p><a href="https://firebase.google.com/docs/ios/app-store-data-collection#firebase_user_agent">Firebase</a>, <a href="https://support.google.com/analytics/answer/10285841">Google Analytics</a>, and <a href="https://developers.facebook.com/blog/post/2021/01/19/facebook-login-updates-new-limited-data-mode/">Facebook</a> have been releasing updates and documentation to help developers navigate Apple’s questions, but conspiciously they don’t directly answer them. Instead they answer different, related questions that are maybe helpful but are certainly not decisive.</p>

<p>Contrast that to paid analytics tools that don’t share data with ad companies. MixPanel, for example, <a href="https://community.mixpanel.com/announcements-6/idfa-changes-on-ios-14-4442">posted clearly 6 months ago</a> that they believe they’re compliant with Apple’s rules:</p>

<blockquote>
  <p>You need to specify what data is used to track someone across external apps and websites, which in our case is none. We only allow customers to track data they own; data sent to Mixpanel is not used by any other external companies.</p>
</blockquote>

<p>Interestingly, Flurry – whose business model apparently <em>is</em> to share data with advertisers – <a href="https://developer.yahoo.com/flurry/docs/analytics/gettingstarted/ios14/att/">has also claimed its SDK doesn’t trigger the App Tracking Transparency rules</a>. This seems dubious, but is interesting if so.</p>

<p>However, if the above rules and assumptions are correct, any apps that don’t both purge these SDKs and set their App Privacy to say they no longer have 3rd Party Tracking – or only use the SDKs for the small percentage of users who opt in – will soon face rejection. Meanwhile, even besides these restrictions, there are some substantial benefits to using premium analytics services like Mixpanel.</p>

<p>Our advice for now, then, is that <strong>all iOS apps should be prepared to migrate off of the Google Analytics, Firebase, Facebook, and Flurry SDKs, potentially on very short notice</strong>. If you were already on the fence, now is probably a good time to make the move. A <em>lot</em> of apps might be making changes in the coming weeks.</p>

<p>Hold on to your butts.</p>

<hr>

<p><em>Updates, February 11:</em></p>

<p>A number of developers have gotten in touch to share their guesses about how App Review will handle this in the coming weeks – thanks folks! Some common themes:</p>

<ol>
  <li>Many developers assume Apple will only be using App Review to enforce opt-in for the IDFA identifier, and will not start rejecting apps for using SDKs that go against their <a href="https://developer.apple.com/app-store/user-privacy-and-data-use/">new rules prohibiting things like combining data and using fingerprinting</a>, as long as developers assert their SDKs are following the rules. This is plausible. If Apple goes this route though, developers are left with the ongoing risk of a surprise rejection, when App Review later cracks down on a specific SDK that’s played loose with the rules.</li>
  <li>Flurry <a href="https://www.flurry.com/blog/preparing-for-ios-14/">posted back in July 2020 that it intends to comply with Apple’s requirements</a> so as not to require opt-in. In particular, they’ve explicitly said “Flurry will respect Apple’s policy requirement to not combine data across apps and websites owned by other companies.” It’s not clear how Apple would verify this is true, and this is surprising given Flurry’s business model, but it seems like a clear statement that Flurry intends to comply.</li>
  <li>A couple folks has asked if embedding code from YouTube – which certainly does ad targeting with its data – would violate Apple’s privacy rules. By the letter of the policy, this seems possible.</li>
</ol>

        </article>

        

        <div>

            <p><span><span><!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="218px" height="50px" viewBox="0 0 218 50" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Steamclock Software</title>
    <desc>Steamclock is a web and mobile software studio based in downtown Vancouver. We make great apps for iOS, Android, and the web.</desc>
    <defs>
        <path d="M71.213593,20.9625922 C72.4992306,20.9625922 73.3869621,20.6244828 73.3869621,19.610331 C73.3869621,18.5652975 72.1930679,18.2273646 70.6626055,17.7662581 C68.2445873,17.0593341 65.3365682,16.1681793 65.3365682,12.4800336 C65.3365682,9.37599138 67.8466812,7.47050826 71.2441741,7.47050826 C73.3869621,7.47050826 75.2847496,7.71650228 77.121199,8.82276952 L75.8968994,11.9883985 C74.5806806,11.3737664 73.2644619,11.0663621 71.6728372,11.0663621 C70.5402809,11.0663621 69.6219684,11.404295 69.6219684,12.4186233 C69.6219684,13.4327752 70.7545246,13.7708846 72.4686495,14.2626962 C74.9785868,14.9696202 77.7335246,15.8914801 77.7335246,19.3643369 C77.7335246,22.8064886 75.3766687,24.435449 71.6420803,24.435449 C68.8567371,24.435449 66.7447061,23.9438139 65,22.8987805 L66.1631374,19.7024464 C67.8466812,20.5016622 69.6219684,20.9625922 71.213593,20.9625922 Z M84.7118567,24.7427474 C81.7122699,23.0523767 81.2836068,19.7025169 81.2836068,16.6290034 L81.2836068,11.1585481 L78.9265752,11.1585481 L78.9265752,7.83921695 L81.2836068,7.83921695 L81.2836068,3.22921131 L85.7526695,2.67616592 L85.7526695,7.83921695 L89.0890002,7.83921695 L88.6912698,11.1585481 L85.7526695,11.1585481 L85.7526695,16.7212953 C85.7526695,19.1800002 86.211738,20.9933679 87.7116192,22.652857 L84.7118567,24.7427474 Z M97.9658755,24.435449 C93.0377444,24.435449 90.2216444,22.3455586 90.2216444,16.0144771 C90.2216444,9.46810679 93.0989067,7.47050826 97.5066314,7.47050826 C101.853194,7.47050826 104.454874,9.13017382 104.454874,17.0593341 L94.8436127,18.0734859 C95.1190186,20.0405558 96.037507,20.8088901 97.9045375,20.8088901 C99.5880813,20.8088901 101.087963,20.4707806 102.649006,19.5487442 L103.995806,22.6529629 C102.2511,23.851522 100.322731,24.435449 97.9658755,24.435449 Z M100.108488,14.3855167 C100.04715,11.9883985 99.159594,11.0663621 97.5066314,11.0663621 C95.639425,11.0663621 94.6599502,12.234216 94.6599502,14.7852129 L94.6599502,15.2461429 L100.108488,14.3855167 Z M117.402941,24.4047968 C117.096954,23.6364625 116.821373,22.8065415 116.63771,22.0075021 C115.749979,23.5134655 114.372598,24.435502 111.954404,24.435502 C107.883423,24.435502 106.291623,22.4686086 106.291623,19.4259766 C106.291623,16.2603476 108.18941,14.5699769 115.994804,14.109047 C115.872479,11.7731625 114.709342,11.1892356 112.933879,11.1892356 C111.403416,11.1892356 109.872954,11.5889317 108.464816,12.2956793 L107.118192,9.00722975 C109.04656,7.90078604 111.219754,7.4705612 113.637948,7.4705612 C117.892591,7.4705612 120.463866,9.99067644 120.463866,13.8630529 L120.463866,17.8584265 C120.463866,19.7332044 120.494623,21.7000978 120.892354,23.5441707 L117.402941,24.4047968 Z M115.994804,17.059387 C112.138066,17.2744995 110.760685,17.9507183 110.760685,19.2722745 C110.760685,20.4708336 111.342078,20.9626452 113.08696,20.9626452 C114.617423,20.9626452 115.382829,20.1327241 115.994804,18.811168 L115.994804,17.059387 Z M142.747279,24.0666874 L142.747279,15.1231988 C142.747279,12.357266 142.226873,11.1278253 140.543329,11.1278253 C139.012867,11.1278253 138.339555,11.7731625 137.666067,13.0333084 L137.666067,24.0666874 L133.197004,24.0666874 L133.197004,13.52512 C133.197004,12.0805668 132.462354,11.1278253 130.99323,11.1278253 C129.462592,11.1278253 128.789279,11.7731625 128.115967,13.0333084 L128.115967,24.0666874 L123.646905,24.0666874 L123.646905,14.0474602 C123.646905,12.1726822 123.616148,10.2057889 123.218417,8.36171602 L126.70783,7.50126634 C127.013817,8.26960061 127.289398,9.09934516 127.473061,9.89838457 C128.330211,8.39259762 129.677011,7.4705612 132.095205,7.4705612 C134.819386,7.4705612 136.257929,8.5461233 136.961998,10.0213816 C137.819148,8.39259762 139.22711,7.4705612 141.645129,7.4705612 C146.787503,7.4705612 147.216342,11.1892356 147.216342,14.5085667 L147.216342,24.0666874 L142.747279,24.0666874 Z M157.531339,24.4354843 C152.05222,24.4354843 149.879027,21.7307853 149.879027,15.9529257 C149.879027,10.1750661 152.05222,7.47054355 157.531339,7.47054355 C159.306802,7.47054355 160.898426,7.74706625 162.275807,8.57698726 L160.837264,11.8654368 C159.857614,11.3736252 158.725057,11.1278076 157.531339,11.1278076 C154.837739,11.1278076 154.378671,12.9102937 154.378671,15.9529257 C154.378671,18.9955577 154.837739,20.7780438 157.531339,20.7780438 C158.725057,20.7780438 159.857614,20.5322262 160.837264,20.0405911 L162.275807,23.3290406 C160.898426,24.1589616 159.306802,24.4354843 157.531339,24.4354843 Z M171.886595,15.9529433 C171.886595,10.1750837 174.059964,7.4705612 179.539082,7.4705612 C185.018025,7.4705612 187.191395,10.1750837 187.191395,15.9529433 C187.191395,21.730803 185.018025,24.435502 179.539082,24.435502 C174.059964,24.435502 171.886595,21.730803 171.886595,15.9529433 Z M182.691751,15.9529433 C182.691751,12.9103114 182.232682,11.066415 179.539082,11.066415 C176.845307,11.066415 176.386239,12.9103114 176.386239,15.9529433 C176.386239,18.9955753 176.845307,20.8396481 179.539082,20.8396481 C182.232682,20.8396481 182.691751,18.9955753 182.691751,15.9529433 Z M196.757347,24.4354843 C191.278228,24.4354843 189.104859,21.7307853 189.104859,15.9529257 C189.104859,10.1750661 191.278228,7.47054355 196.757347,7.47054355 C198.532634,7.47054355 200.124259,7.74706625 201.50164,8.57698726 L200.063097,11.8654368 C199.083446,11.3736252 197.951065,11.1278076 196.757347,11.1278076 C194.063571,11.1278076 193.604503,12.9102937 193.604503,15.9529257 C193.604503,18.9955577 194.063571,20.7780438 196.757347,20.7780438 C197.951065,20.7780438 199.083446,20.5322262 200.063097,20.0405911 L201.50164,23.3290406 C200.124259,24.1589616 198.532634,24.4354843 196.757347,24.4354843 Z M207.990656,15.8607573 L207.990656,24.0666168 L203.521769,24.0666168 L203.521769,2.55308068 L207.990656,2.00003529 L207.990656,14.9387209 L212.3678,7.83930518 L217.357269,8.33111676 L212.337219,15.2768304 L218,23.3905744 L213.163788,24.4354314 L207.990656,15.8607573 Z M70.5211238,46.3708984 C72.1677593,46.3708984 73.1605915,45.933262 73.1605915,44.4258868 C73.1605915,43.0399205 72.3131076,42.7969264 70.4000296,42.2375282 C68.2932711,41.6541307 66.3318608,40.9974995 66.3318608,38.2015675 C66.3318608,35.8430954 68.1721768,34.7975325 70.4242836,34.7975325 C71.8044766,34.7975325 73.0880052,34.9921749 74.2261856,35.6242772 L73.6207144,37.0344194 C72.7730548,36.5724306 71.7076364,36.3536124 70.569456,36.3536124 C69.140755,36.3536124 68.0753366,36.6454876 68.0753366,38.2988004 C68.0753366,39.6604144 69.3103572,40.0736985 70.8842308,40.5113349 C72.7973088,41.0462042 74.9040672,41.5810736 74.9040672,44.2312445 C74.9040672,46.9057678 73.2574317,47.9269782 70.617964,47.9269782 C68.8259803,47.9269782 67.251931,47.6352794 65.9685781,46.8328872 L66.5497953,45.3983926 C67.6877999,46.0548473 69.0681687,46.3708984 70.5211238,46.3708984 Z M77.4462201,41.3622907 C77.4462201,36.888517 78.9960154,34.7975678 82.8947577,34.7975678 C86.7935,34.7975678 88.3432953,36.888517 88.3432953,41.3622907 C88.3432953,45.8360643 86.7935,47.9270135 82.8947577,47.9270135 C78.9960154,47.9270135 77.4462201,45.8360643 77.4462201,41.3622907 Z M86.5270575,41.3622907 C86.5270575,38.2257787 85.9943483,36.3292953 82.8947577,36.3292953 C79.7951671,36.3292953 79.2624579,38.2257787 79.2624579,41.3622907 C79.2624579,44.4988027 79.7951671,46.395286 82.8947577,46.395286 C85.9943483,46.395286 86.5270575,44.4988027 86.5270575,41.3622907 Z M92.4110246,47.6351912 L92.4110246,36.8642176 L90.2801879,36.8642176 L90.2801879,35.3324901 L92.3626924,35.3324901 C92.2658521,34.7489161 92.1930901,34.1409897 92.1930901,33.581768 C92.1930901,31.4664664 93.0407498,29.8860342 95.7529795,29.8860342 C96.2612589,29.8860342 96.7698898,29.9590913 97.2300128,30.0806766 L96.9394921,31.612404 C96.6004633,31.5151711 96.2371806,31.4664664 95.9224059,31.4664664 C94.2755946,31.4664664 93.9124877,32.1716258 93.9124877,33.7033532 C93.9124877,34.1896944 93.9608199,34.8217967 94.1061682,35.3324901 L97.0120783,35.3324901 L96.8424761,36.8642176 L94.2030084,36.8642176 L94.2030084,47.6351912 L92.4110246,47.6351912 Z M100.668527,41.629743 L100.668527,36.6211 L98.5375141,36.6211 L98.5375141,35.0893725 L100.668527,35.0893725 L100.668527,31.2720535 L102.460335,31.0288829 L102.460335,35.0893725 L105.245326,35.0893725 L105.075724,36.6211 L102.460335,36.6211 L102.460335,42.1404365 C102.460335,44.2799139 102.484589,45.4955903 104.034384,46.9787895 L102.823617,48 C100.813699,46.3952155 100.668527,44.3771468 100.668527,41.629743 Z M115.415361,37.326224 L112.436865,47.6352089 L110.330107,47.6352089 L106.552459,35.2838031 L108.417204,34.9433996 L111.492541,45.8846632 L114.471037,35.2109225 L116.311353,34.9921043 L119.217264,45.8846632 L122.19576,34.9433996 L123.987568,35.2350984 L120.33119,47.6352089 L118.224256,47.6352089 L115.415361,37.326224 Z M134.472571,45.9089273 C133.722103,47.2218366 132.462829,47.9269959 130.404402,47.9269959 C127.547,47.9269959 126.166631,46.9543136 126.166631,44.2312622 C126.166631,41.7755571 128.079709,40.5842331 134.254637,40.3167102 L134.254637,40.0250114 C134.254637,37.2532552 132.85019,36.4023347 131.106714,36.4023347 C129.895947,36.4023347 128.709259,36.6696812 127.619586,37.2045505 L127.038369,35.7457036 C128.273566,35.089249 129.629505,34.7975502 131.106714,34.7975502 C133.770435,34.7975502 136.04662,36.1346353 136.04662,39.8305455 L136.04662,43.0884664 C136.04662,44.596018 136.143461,46.1033931 136.482665,47.4406548 L134.981202,47.7810583 C134.763268,47.1733083 134.593841,46.5410296 134.472571,45.9089273 Z M134.254637,41.7999095 C130.065374,41.9945518 127.934361,42.6023017 127.934361,44.2312622 C127.934361,45.7386373 128.442992,46.4437966 130.743431,46.4437966 C132.559493,46.4437966 133.455485,45.4954667 134.254637,43.8908587 L134.254637,41.7999095 Z M139.872232,47.6351912 L139.872232,39.6359738 C139.872232,38.1285987 139.775391,36.6210471 139.436538,35.2837854 L140.93765,34.9433819 C141.179838,35.5998366 141.373695,36.3535241 141.519043,37.1073882 C142.1971,35.7214219 143.335105,34.9433819 145.272437,34.7974443 L145.514625,36.7426323 C143.528961,36.7669847 142.366527,37.6179052 141.664215,39.4171556 L141.664215,47.6351912 L139.872232,47.6351912 Z M152.948458,47.9269606 C149.655187,47.9269606 147.499921,46.5653466 147.499921,41.3622377 C147.499921,35.9159583 149.994216,34.7975149 152.706445,34.7975149 C155.854368,34.7975149 157.670606,36.3050665 157.670606,41.654113 L157.670606,41.8727548 L149.340412,42.5535617 C149.412999,45.4956079 150.720605,46.3952331 152.948458,46.3952331 C154.231811,46.3952331 155.345737,46.1033578 156.483918,45.4227273 L157.137721,46.8085172 C155.878447,47.6352618 154.449745,47.9269606 152.948458,47.9269606 Z M155.902876,40.5113172 C155.854368,37.3504529 154.667856,36.3292424 152.706445,36.3292424 C150.599511,36.3292424 149.291904,37.4963905 149.291904,40.8760731 L149.291904,41.1434195 L155.902876,40.5113172 Z M168.917923,16.5496465 C168.917923,19.0083515 169.376991,20.8215427 170.876873,22.4812083 L167.877286,24.5710987 C164.974715,22.935609 164.479441,19.7461571 164.450442,16.7569944 L164.44886,16.7569944 L164.44886,2.52251672 L168.917923,2 L168.917923,16.5496465 Z M48.8146433,22.4922864 C49.8699564,22.6590279 50,23.5436841 50,24.2058402 L50,25.7941598 C50,26.4563159 49.8699564,27.3409721 48.8146433,27.5077136 C48.1621092,27.6096112 47.4315489,27.7116869 46.6885187,27.8157222 C45.79674,27.9402438 45.0868442,28.6111289 44.8894629,29.4899064 C44.7702859,30.0205933 44.6304445,30.54362 44.4706511,31.0579177 C44.2036163,31.9178121 44.4820522,32.8530608 45.191948,33.4069062 C45.7830231,33.8681175 46.3641222,34.3214904 46.8778837,34.735672 C47.7085597,35.4078041 47.3788189,36.2388394 47.047653,36.8122804 L46.253496,38.1877196 C45.9223301,38.7613388 45.367596,39.46233 44.370179,39.0789671 C43.7527389,38.8404341 43.0672486,38.563066 42.3703572,38.2808881 C41.5361183,37.9431298 40.5869778,38.1688364 39.9763071,38.8299237 C39.6093346,39.2270036 39.2268638,39.6094758 38.8297853,39.9764495 C38.1687005,40.5871224 37.9431727,41.5362663 38.2807518,42.37033 C38.5629287,43.067402 38.8402957,43.7528948 39.079006,44.3703371 C39.4623675,45.3675795 38.7612007,45.9224937 38.1877616,46.2536608 L36.8121493,47.0478206 C36.2387103,47.3789877 35.4076779,47.7087297 34.7355482,46.8780507 C34.3213681,46.3642874 33.8679968,45.7831862 33.4067872,45.192109 C32.8531219,44.4822107 31.9176984,44.2037738 31.0578071,44.4708096 C30.5436893,44.6306035 30.0206645,44.7704454 29.4898014,44.8896228 C28.6112051,45.0870049 27.9403224,45.7969032 27.8156231,46.6886851 C27.7117663,47.4317179 27.6095128,48.1622808 27.5076156,48.8148172 C27.3408747,49.870134 26.4563998,50 25.794246,50 L24.205754,50 C23.5436002,50 22.6589472,49.870134 22.4923844,48.8148172 C22.3904872,48.1622808 22.2882337,47.4317179 22.1841988,46.6886851 C22.0596776,45.7969032 21.3887949,45.0870049 20.5100205,44.8896228 C19.9793355,44.7704454 19.4563107,44.6306035 18.9420148,44.4708096 C18.0823016,44.2037738 17.1468781,44.4822107 16.5930346,45.192109 C16.1318251,45.7831862 15.6784537,46.3642874 15.2642736,46.8780507 C14.5923221,47.7087297 13.7612897,47.3789877 13.1876726,47.0478206 L11.8122384,46.2536608 C11.2387993,45.9224937 10.5376325,45.3675795 10.920994,44.3703371 C11.1595261,43.7528948 11.4368932,43.067402 11.7190701,42.3705081 C12.0568273,41.5362663 11.8311214,40.5871224 11.1702147,39.9764495 C10.772958,39.6094758 10.3904872,39.2270036 10.0235147,38.8299237 C9.41284404,38.1688364 8.46370357,37.9431298 7.62964283,38.2808881 C6.93257326,38.563066 6.24708293,38.8404341 5.62964283,39.0789671 C4.63240403,39.46233 4.07749176,38.7613388 3.74632582,38.1877196 L2.95216888,36.8122804 C2.62118108,36.2388394 2.29144028,35.4078041 3.12211633,34.735672 C3.63587779,34.3214904 4.21697693,33.8681175 4.80787388,33.4069062 C5.51776966,32.8530608 5.79620558,31.9178121 5.52917075,31.0579177 C5.36937739,30.54362 5.22953594,30.0205933 5.11035896,29.4899064 C4.91297764,28.6111289 4.20308186,27.940422 3.31130311,27.8157222 C2.56845106,27.7116869 1.8378908,27.6096112 1.18517859,27.5077136 C0.129865503,27.3409721 0,26.4563159 0,25.7941598 L0,24.2058402 C0,23.5436841 0.129865503,22.6590279 1.18517859,22.4922864 C1.8378908,22.3903888 2.56845106,22.288135 3.31130311,22.1842778 C4.20308186,22.059578 4.91297764,21.3888711 5.11035896,20.5100936 C5.22953594,19.9794067 5.36937739,19.45638 5.52917075,18.9420823 C5.79620558,18.0821879 5.51776966,17.1469392 4.80787388,16.5930938 C4.21697693,16.1318825 3.63587779,15.6785096 3.12211633,15.264328 C2.29144028,14.5921959 2.62118108,13.7611606 2.95216888,13.1877196 L3.74632582,11.8121023 C4.07749176,11.2386612 4.63240403,10.53767 5.62964283,10.9210329 C6.24708293,11.1595659 6.93257326,11.436934 7.62964283,11.7191119 C8.46370357,12.0568702 9.41284404,11.8311636 10.0235147,11.1702545 C10.3904872,10.7729964 10.772958,10.3905242 11.1702147,10.0235505 C11.8311214,9.41287757 12.0568273,8.46373373 11.7190701,7.62967001 C11.4368932,6.93259796 11.1595261,6.24710518 10.920994,5.62966288 C10.5376325,4.63242053 11.2387993,4.07750629 11.8122384,3.74633917 L13.1876726,2.9521794 C13.7612897,2.62101228 14.5923221,2.2912703 15.2642736,3.12194931 C15.6784537,3.63571261 16.1318251,4.21681381 16.5930346,4.80789101 C17.1468781,5.51778932 18.0823016,5.79622623 18.9420148,5.52919045 C19.4563107,5.36939652 19.9793355,5.22955457 20.5100205,5.11037716 C21.3887949,4.91299515 22.0596776,4.20309683 22.1841988,3.31131491 C22.2882337,2.56828206 22.3904872,1.8377192 22.4923844,1.18518281 C22.6589472,0.129865965 23.5436002,0 24.205754,0 L25.794246,0 C26.4563998,0 27.3408747,0.129865965 27.5076156,1.18518281 C27.6095128,1.8377192 27.7117663,2.56828206 27.8156231,3.31131491 C27.9403224,4.20309683 28.6112051,4.91299515 29.4898014,5.11037716 C30.0206645,5.22955457 30.5435112,5.36939652 31.0578071,5.52919045 C31.9176984,5.79622623 32.8531219,5.51778932 33.4067872,4.80789101 C33.8679968,4.21681381 34.3213681,3.63571261 34.7355482,3.12194931 C35.4076779,2.2912703 36.2387103,2.62101228 36.8121493,2.9521794 L38.1877616,3.74633917 C38.7612007,4.07750629 39.4623675,4.63242053 39.079006,5.62966288 C38.8402957,6.24710518 38.5629287,6.93259796 38.2807518,7.62967001 C37.9429946,8.46373373 38.1687005,9.41287757 38.8297853,10.0235505 C39.2268638,10.3905242 39.6093346,10.7729964 39.9763071,11.1700763 C40.5869778,11.8311636 41.5361183,12.0568702 42.3703572,11.7191119 C43.0672486,11.436934 43.7527389,11.1595659 44.370179,10.9210329 C45.367596,10.53767 45.9223301,11.2386612 46.253496,11.8121023 L47.047653,13.1877196 C47.3788189,13.7611606 47.7085597,14.5921959 46.8778837,15.264328 C46.3641222,15.6785096 45.7830231,16.1318825 45.191948,16.5930938 C44.4820522,17.1469392 44.2036163,18.0821879 44.4706511,18.9420823 C44.6304445,19.45638 44.7702859,19.9792286 44.8894629,20.5100936 C45.0868442,21.3888711 45.79674,22.059578 46.6885187,22.1842778 C47.4315489,22.288135 48.1621092,22.3903888 48.8146433,22.4922864 Z M41,25 C41,16.1633605 33.8365022,9 25.0000885,9 C16.1633209,9 9,16.1633605 9,25 C9,33.8366395 16.1633209,41 25.0000885,41 C33.8365022,41 41,33.8366395 41,25 Z M33.4929285,21.4251409 L34.1463574,22.930446 C34.2241211,23.1098356 34.1570343,23.3191532 33.9894063,23.4196256 L26.4616279,28.0326286 L26.4529084,28.0379729 L26.4449007,28.0440297 C26.2973809,28.1571503 26.1375827,28.252991 25.9683532,28.3294142 L25.9598116,28.3331552 L25.955007,28.3361836 L25.9510921,28.3376088 L25.9411269,28.3420623 C25.829019,28.3914078 25.7147758,28.4371905 25.5959058,28.4674747 C24.7120329,28.6924688 23.8326087,28.4462758 23.2188625,27.8364936 L15.5003227,18.1663781 C15.3764701,18.011394 15.3889266,17.7880032 15.5289725,17.6478049 L16.672473,16.5032386 C16.745966,16.4296657 16.84366,16.3892274 16.9475823,16.3892274 C17.0378024,16.3892274 17.1258872,16.4209367 17.1954653,16.4784768 L25.3885952,23.263929 C25.4636897,23.3262789 25.5649427,23.3469434 25.6583659,23.318975 L33.0251004,21.2072725 C33.0614021,21.1964058 33.0987714,21.1908834 33.1363186,21.1908834 C33.2911343,21.1908834 33.4311802,21.282805 33.4929285,21.4251409 Z" id="logo-post-February82021"></path>
    </defs>
    <g id="logo-logo-post-February82021" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <mask fill="white">
            <use xlink:href="#logo-post-February82021"></use>
        </mask>
        <use fill="#000000" xlink:href="#logo-post-February82021"></use>
    </g>
</svg></span></span></p><p>2.8.21.1495</p>

        </div>

        

        <!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="830px" height="117px" viewBox="0 0 830 117" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Accent</title>
    <g id="E26931-February82021" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <polygon fill="#E26931" fill-rule="nonzero" points="830 0 1.13861509e-13 117 0 1.42755282e-14"></polygon>
    </g>
</svg>
        <!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="830px" height="117px" viewBox="0 0 830 117" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Accent</title>
    <g id="E26931-flipped-February82021" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <polygon fill="#E26931" fill-rule="nonzero" points="0 0 830 0 830 117"></polygon>
    </g>
</svg>

    </div>

</section>



<section id="subscription">
    <div>
        <div>
            
            <p>Interested in future posts or announcements? <span>Subscribe to our feed.</span></p>
        </div>
        
    </div>
</section>

    </div><div>
        
        
        
            
                <section id="hello">
                    
                    <div id="">
                        <p>Contact us about your design and development needs today.</p>

                        <p><a href="https://steamclock.com/contact">Get in Touch <span></span></a>
                    </p></div>
                </section>
            
        
        

        

        <section id="links">
            
                
                
                
            
                
                
                
            
                
                
                
            
                
                
                
            
            
        </section>
        
        <p>© Steamclock Software Ltd. No developers were harmed in the making of this site.</p>
    </div></div>]]>
            </description>
            <link>https://steamclock.com/blog/2021/02/apple-tracking-analytics-sdks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085129</guid>
            <pubDate>Wed, 10 Feb 2021 02:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I Learned from My Dad]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26085124">thread link</a>) | @craigkerstiens
<br/>
February 9, 2021 | https://sogrady.org/2021/01/28/10-things-i-learned-from-my-dad/ | <a href="https://web.archive.org/web/*/https://sogrady.org/2021/01/28/10-things-i-learned-from-my-dad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><a href="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg"><img data-attachment-id="3240" data-permalink="https://sogrady.org/2021/01/14/my-2020-in-pictures/img_20200123_142539/" data-orig-file="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1579789539&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;106&quot;,&quot;shutter_speed&quot;:&quot;0.013592&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_20200123_142539" data-image-description="" data-medium-file="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=225" data-large-file="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=768" src="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=768" alt="" srcset="https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=768 768w, https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=1536 1536w, https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=113 113w, https://sogradyme.files.wordpress.com/2021/01/img_20200123_142539.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></a></figure>



<p>None of the doctors ever told me my Dad was dying. Not the surgeon at Maine Med who first went in to do the biopsy of the lung. Not the surgeon at Mass General who did the biopsy of a lymph node. Not the oncologist at Maine Cancer Care the first few chemo treatments, which were also the only ones I could attend thanks to COVID. None of them.</p>



<p>But they didn’t have to. Mesothelioma is hard to Google, because the search results are heavily polluted by law firms in search of riches from ignorant or irresponsible manufacturers, but you can get the gist. And the gist is that it’s not good.</p>



<p>Mesothelioma is a malignant tumor that is caused by inhaling asbestos fibers. How my father, who spent his career on Wall Street theoretically well removed from the material that used to be common in building materials, firefighting gear and the like ended up with these fibers in his lung is an open question. We’ll never know for sure, but the evidence strongly suggests that it’s a consequence of my father going back to work downtown shortly after the 9/11 attacks. Per <a href="https://en.wikipedia.org/wiki/Asbestos#11_September_2001_attacks">WikiPedia</a>:</p>



<blockquote><p>As New York City’s World Trade Center collapsed following the September 11 attacks, Lower Manhattan was blanketed in a mixture of building debris and combustible materials. This complex mixture gave rise to the concern that thousands of residents and workers in the area would be exposed to known hazards in the air and in the dust, such as asbestos, lead, glass fibers, and pulverized concrete. More than 1,000 tons of asbestos are thought to have been released into the air following the buildings’ destruction.</p></blockquote>



<p>As an aside, before someone mentions the 9/11 victims fund, he was aware of it. Given the limited pool of funds, however, this was a non-starter for him because he would never have been willing to take money away from the first responders or their families. </p>



<p>Anyway, my father’s commute for four decades had him walk off the Path trains into the Trade Center en route to the Exchange every day. I know this because I did it with him one summer. He was fortunate enough to be on vacation up here in Maine not just for the attempted bombing of the World Trade Center in 1993 but for 9/11 as well. It would be as tragic as it would be ironic if he survived the attack in 2001 by not being there but the air he breathed when he returned to work ended up killing him twenty years later.</p>



<p>Pragmatist that he was, however, he’d have taken that trade.</p>



<p>It’s a similar trade, in fact, to the one he took when he was first diagnosed with cancer while at Harvard Business School in the early seventies. Cancer treatments were a little less sophisticated all those years ago, and to attack the cancer that he had the doctors irradiated large swaths of his body. Today, they can apparently target areas smaller than a dime. He was told that he had an 8% chance of dying within six weeks, and a 92% chance of living out most of the rest of a normal lifespan – albeit with some side effects.</p>



<p>Side effects that he accepted without complaint. His immune system went haywire, for one, and he developed allergies, the worst of which was poison ivy. If that so much as touched him, it was in his blood stream and off to the races. My childhood memories are always a little hazy, but I remember that. The side effects changed his hair color and density, and it left him permanently immuno-compromised. It’s weird when you’re a kid and your Dad’s mustache randomly grows in bright red.</p>



<p>Not that any of that mattered much: I don’t remember him missing a single day of work, ever.</p>



<p>For fifty years, the deal that he’d accepted was a good deal. Despite a few scares along the way, the cancer never came back until he noticed being short of breath and developed a chronic cough two years ago. Never one to visit a doctor unnecessarily, and probably for good reason given his history, he nevertheless went and ended up on the track that led to the diagnosis and the year that was 2020.</p>



<figure><a href="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg"><img data-attachment-id="3340" data-permalink="https://sogrady.org/img_20191217_160116/" data-orig-file="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1576598477&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;209&quot;,&quot;shutter_speed&quot;:&quot;0.025011&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_20191217_160116" data-image-description="" data-medium-file="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=300" data-large-file="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=1024" src="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=1024" alt="" srcset="https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=1024 1024w, https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=2048 2048w, https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=150 150w, https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=300 300w, https://sogradyme.files.wordpress.com/2021/01/img_20191217_160116.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Christmas 2019 was a sad affair. My Dad had been diagnosed merely days before, and his weight loss left him gaunt and weary. When shown pictures of the dinner later, he replied with typical bleak humor, “shit, I look dead.” Still, we tried to take an optimistic tack with 2020. If there’s one thing I’ve learned about cancer today, it’s that your primary goal if they can’t cure you immediately is to buy time, because they might be able to in future.</p>



<p>So that is what my Dad set out to do. Always goal oriented, his assessment was that based on trajectory at the time, he was unlikely to make it until the Fourth of July. Thus his goal was to make it beyond that date. To that end, he promised his oncologist one thing: that as long as they would agree to treat him, he would show up. At times, this meant employing some gamesmanship, no stranger to the lifelong athlete. As he continued to bleed weight he couldn’t afford to lose, he slyly wore heavier and heavier shoes to his weigh-in’s so they wouldn’t remove him from treatment.</p>



<p>So intent was he on continuing treatment, in fact, that he literally broke himself out of the hospital to get the toxic substance injected into his body. He’d fallen and shattered his femur – in retrospect, likely due to the fact that his heart had begun to stop unpredictably due either to a bad valve, arrhythmia’s or both. </p>



<p>All in all in 2020, he dealt with the cancer, a bad valve in his heart, a congenital heart murmur gone rogue, five surgeries, and the broken leg. To add insult to injury, his access to the thing that made him most happy – his grandchildren, and to a lesser extent his children – was drawn down to a trickle thanks to the pandemic.</p>



<p>Insult, injury or otherwise, he fought to the last. Every time he seemed to take a hard won step forward, some new fresh hell would drop him back ten steps, or even twenty. But he was a fighter, and every time he got knocked down, he picked himself up off the mat and waded back in.</p>



<p>He died as a fighter, Monday morning. And despite the terminal prognosis, the cancer never won. His body may have ultimately failed him, but his spirit never did. It was his heart, or maybe his brain, it’s not clear which, that killed him. Not the cancer. </p>



<figure><a href="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg"><img data-attachment-id="3333" data-permalink="https://sogrady.org/img_20200822_144835/" data-orig-file="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598107715&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;46&quot;,&quot;shutter_speed&quot;:&quot;0.001491&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_20200822_144835" data-image-description="" data-medium-file="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=225" data-large-file="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=768" src="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=768" alt="" srcset="https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=768 768w, https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=1536 1536w, https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=113 113w, https://sogradyme.files.wordpress.com/2021/01/img_20200822_144835.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></a></figure>



<p>That terrible endurance was something I never wanted to learn from my Dad, but I did. He taught me many other things, some of which I wrote down in an admittedly <a href="http://thisistheway.us/">lengthy letter</a> to my then unborn daughter. Here are ten that I’ve thought about this week.</p>



<h2>Have Priorities</h2>



<p>My Dad grew up with very little. What wealth his family on one side had had at one point had largely petered out, and while his father always worked, you don’t become a minister for the money. Still, the family prioritized education, and so he went to Williams like his father and brother before him, and from there it was on to Harvard Business School. That provided him with access to jobs that featured, let’s just call it, high income potential. For the first time in his life, he had money. And but for his kids, that could have been his life.</p>



<p>Instead, he eventually came to a fork in the road. Down one path lay wealth and comfort; the other was precarious, stressful self-employment as an independent floor broker – the upside of which was predictable hours that allowed him to get home in time to coach my brother and I, first in soccer, later adding lacrosse in the spring.</p>



<p>Every family has different choices to make, and I can’t imagine the financial stress both of my parents bore. But I think I can speak for my brother when I say that I’m glad he chose us.</p>



<h2>You Do What You Have To</h2>



<p>When my Dad enlisted in the army, he and my mother were dirt poor and living in a trailer in Georgia. Every dollar, therefore, was precious. As a semi-related aside, if you get the chance, ask my Mom what it was like to work at a K-Mart in the deep south with a wicked Boston accent.</p>



<p>Anyway, after finding out that paratroopers got an extra pittance per month, my Dad signed up for jump school. The only problem with this transaction was that my Dad was terrified of heights. Every morning he had to jump, then, he’d get up and vomit because he was scared. But dollars were precious, so he got his wings.</p>



<p>Later, in business school, he had to go in regularly to get blasted with high doses of radiation. This had the intended effect of killing off the cancer and the unintended effect of giving him nearly full time nausea. He didn’t intend to miss class, however, so he merely requested a seat on the aisle so he could get to the bathroom quickly. All professors but one complied; the hold out required an appeal to the dean. He had no such impediments while competing in tennis tournaments during treatment, however; he’d merely vomit in between sets.</p>



<p>My Dad never really sat us down to talk about working through fear, sickness or injury. We just watched him.</p>



<h2>Be Yourself</h2>



<p>All the years my Dad worked on the various exchanges, he dressed – in general – as comfortably as the dress code permitted. He had nice suits and ties when they were needed, but his normal uniform was LL Bean chinos, a plain white shirt, his trading jacket and one of a couple of ties kept in his desk. That was who he was. My Dad paid no more attention to NYC fashion then he did to bars after work or coke in the bathrooms. His worst vice was coke, the soda.</p>



<p>It never occurred to me that this was in some way different or unique until I moved to New York City after college. Some friends had Armani suits and Gucci loafers. I was much more likely to be the one who kept us from getting into a bar because I was dressed like a 1930’s rail-riding hobo.</p>



<p>Like my Dad, for better or for worse, I knew who I was, and I never worried too much about what everyone else was up to.</p>



<h2>Let Your Kids Be Who They Are</h2>



<p>My Dad was an athlete all his life, and a very good one. Great, even. My brother and I grew up on stories of his freak athleticism, how he started on his college …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sogrady.org/2021/01/28/10-things-i-learned-from-my-dad/">https://sogrady.org/2021/01/28/10-things-i-learned-from-my-dad/</a></em></p>]]>
            </description>
            <link>https://sogrady.org/2021/01/28/10-things-i-learned-from-my-dad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085124</guid>
            <pubDate>Wed, 10 Feb 2021 02:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Startup Ideas]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26085118">thread link</a>) | @davidkolodny
<br/>
February 9, 2021 | https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Startups and technology canâ€™t solve <em>all</em> the worldâ€™s problems, but they can solve a good amount of them. Now more than ever, we need people to build the next generation of companies that will tackle some of the worldâ€™s biggest problems. There are a lot of unknowns right now, but at Wilbur Labs, we believe this is the best time to start a company â€“ ever. </p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have built and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, <a href="https://www.barkbus.com/">Barkbus</a>, and more.</p><p>We plan to launch several companies every year, which requires building a solid pipeline of ambitious ideas. Over the years, we have used three primary approaches to get startup ideas: build for the future, solve existing problems better, or solve personal problems.</p></div><h2>1. Build for the Future</h2><div><div><p>The future is not static. It is built by people who have a vision for what the future should look like, and those who have the willingness to work hard and take the risks necessary to get there. A great way to get startup ideas is to sit down and think about what the future should look like. Ask yourself the following questions: </p><p><em>How are behaviors changing? Which changes will stick? </em><br><em>What long-term problems have been created as a result of the COVID-19 pandemic? </em><br><em>What priorities and values have changed?</em><br><em>What are the biggest problems today?</em><br><em>What will be the biggest problems tomorrow?</em><br><em>What new problems can technology solve today?</em><br><em>How can new technology change the way existing problems are solved?</em></p></div><p>2020 is a year that consumer behaviors are changing and evolving at a faster rate than ever before. Emerging trends that would have taken 5 to 10 years to mature are instead maturing overnight. There is a large opportunity to think about changing trends and build companies ahead of the curve. eCommerce, Employment, Insurance, and Mobile On-Demand are just a few industries where we are boosting investments as a result of new long-term trends.</p><p>When thinking about the future, itâ€™s important to think and plan for the long-term. The best ideas can be built into big, sustainable businesses that can solve problems and create value over the long-term. Avoid short-termism, also known as ideas which may seem solid in the short-term but have a short expiration date.</p><p>Barkbus is a great example of a business that is building for the future. Back in 2017, the world was rapidly transitioning to direct-to-your-door services. Despite that, the way most people got their dogs groomed hadnâ€™t changed. Pet parents still went to the salon, which was a time consuming and stressful experience for both dogs and their parents. Barkbus launched to <a href="https://www.wilburlabs.com/announcements/why-we-acquired-barkbus">make mobile grooming the new norm</a> for pet parents and their dogs. </p></div><h2>2. Solve Existing Problems Better</h2><div><p>We believe the best companies solve real problems. These problems may be completely new problems, or they may be existing problems that have not been solved well by existing companies to date.</p><p>Do not discount existing problems when generating startup ideas. Some of the largest, most impactful companies throughout history were built by solving existing problems better than others. Google did not invent the search engine, search ads, web based email, or maps. Apple did not invent the smartphone, the tablet, or the smart watch. Facebook did not invent social networking. The list goes on and on. What these companies did is provide a better experience than the existing companies. At Wilbur Labs, we refer to this as â€œcreating a 10x experience.â€� </p><p>Next time you have an idea and someone says, â€œdoesnâ€™t X do that?â€� â€” instead of throwing away your idea, first decide if thereâ€™s an opportunity to 10x the experience. Competitors are a good sign as it means there is a real problem people care about. Challenging the status quo is a great way to solve big problems and build a large business. </p><p>When we built Joblist, we did so because despite multiple large job boards, the job search process hasnâ€™t changed in 20 years â€” when job listings first moved online. We saw an opportunity to 10x the job search experience by introducing more personalization and collaboration tools to a traditionally generic and lonely process. Job seekers have embraced this new approach, which allowed Joblist to help millions of job seekers by powering over 500,000 new applications <a href="https://www.joblist.com/news/why-we-launched-joblist">before their public launch</a>.</p></div><h2>3. Solve Personal Problems</h2><div><div><p>Many of the best startup ideas are personal problems that you have faced. What are the biggest problems that you wish were solved? How many others face the same problem? If you experience a problem, then you are uniquely positioned to solve it.</p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular job. The journey is absolutely worth it for the right person, but itâ€™s important that you care enough about what you are working on enough to dedicate 5 to 10 years of your life. This will be easier if you care deeply about the problem you are solving.</p></div>
<p>A great example of this is why we launched VacationRenter. At Wilbur Labs, we had quarterly company offsites where we book a vacation rental to work for a few days in a different city. Every time we searched for a rental, it took hours of planning and work. We found ourselves scrolling through pages of search results and jumping from site to site, trying to find the ideal place for the best price. This was a frustrating experience and we knew we could make the search for a vacation rental better for others like us â€” which is why <a href="https://www.vacationrenter.com/news/why-we-launched-vacationrenter">we launched VacationRenter</a>. If you experience a problem, it is likely that others are experiencing it too. </p>
<p>VacationRenter became the fastest growing travel startup ever, generating over $1 billion gross bookings in 2020. This milestone confirms that we werenâ€™t the only travelers who had a frustrating experience finding the perfect rental.</p></div><h2>Next Steps</h2><div><p>At Wilbur Labs, the best startup ideas check a few key boxes:</p><ul><li><strong>Solves a problem.</strong> Could your idea solve a big problem, and have a large positive impact on a significant number of people?</li><li><strong>Builds a sustainable business. </strong>Can the idea be turned into a sustainable business that creates value over the long-term?</li><li><strong>Uniquely positioned.</strong> Are you uniquely positioned to solve the problem and you want to dedicate 5 to 10 years of your life?</li></ul></div><figure><img alt="best-startup-ideas-venn-diagram" src="https://storage.googleapis.com/wl-blog/images/ideas-venn-diagram.png"></figure><div><p>No matter how good an idea is, we believe that ideas alone are worthless unless you take initiative to execute. Execution is everything. Everyone has big ideas â€” no startup ideas are truly unique. Being able to execute on those ideas is what will turn that idea into a business.</p><p>For any idea, the most important next step is thorough research where you pair your initial idea with independent and external information. To read more about how to evaluate and research a startup idea, and how to take the next step, follow our blueprint on <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">How to Turn An Idea Into A Business</a>.</p><p>Make sure to follow Wilbur Labs on <a href="https://www.linkedin.com/company/wilbur-labs/">LinkedIn</a>, <a href="https://twitter.com/wilburlabs">Twitter</a>, <a href="https://www.facebook.com/wilburlabs/">Facebook</a>, or <a href="http://instagram.com/wilburlabs">Instagram</a>, as we continue to release more blueprints in the future.</p><p>Want to work with us or have an idea? We are always looking for talented people to work with and exciting projects to partner on. Feel free to check out our <a href="https://www.wilburlabs.com/careers">available openings</a> or <a href="https://www.wilburlabs.com/contact">contact us</a>.</p></div></div><div><p>Wilbur Labs is a San Francisco-based startup studio. We turn bold ideas into market-leading companies.</p><p><a href="https://www.wilburlabs.com/about">Learn More â†’</a></p></div></div>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085118</guid>
            <pubDate>Wed, 10 Feb 2021 02:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turtle visual cortex is non-retinotopic]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26084739">thread link</a>) | @awinter-py
<br/>
February 9, 2021 | https://blog.jordan.matelsky.com/365papers/141/ | <a href="https://web.archive.org/web/*/https://blog.jordan.matelsky.com/365papers/141/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div>
                                    <p>Most of the visual cortex studies I’ve read have been about mammalian vision. But mammals are not the only organisms with cortex, or at least tissue resembling cortex. This paper explores <em>turtle</em> visual cortex, in an area known as dCx. This dorsal region plays the role of the turtle primary vision center — as close as you can find to the homolog of human V1.</p>

<p>But unlike V1, Fournier &amp; Müller et al confirm the existing knowledge that while dCx receives direct inputs from LGN, its layout is <em>not</em> retinotopic. They expand upon this understanding by recording from both individual cells (with electrophysiological recording) and populations of cells. They show that, aside from some slight preferences of caudal dCx for rostral LGN inputs (and vice versa), dCx doesn’t have any clear layout pattern.</p>

<p>This is interesting because the simple, three-layer cortex of a reptile is a much simpler substrate for understanding vision than the complex, deep cortex of mammals. What, if not “pixel-level” information, is dCx responding to?</p>

<p>While the turtles watched movies, the researchers watched the turtles. In particular, they noticed that certain cells of dCx responded to <em>scene-level</em> stimuli: When there was a cut, or the film started or stopped, there was a burst of activity. When the same stimulus was played repeatedly, these responses died away.</p>

<p>This style of scene-level parsing in mammals is reserved for “later”, down-stream brain areas. Does this mean that turtles are using dCx as both early signal processing as well as higher-level object recognition and interpretation? If so, does this mean that mammalian brains, with discrete areas for low-level and high-level vision, evolved from an earlier system where all of these tasks were colocated?</p>

                                </div>
                            </div>
                        </div></div>]]>
            </description>
            <link>https://blog.jordan.matelsky.com/365papers/141/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26084739</guid>
            <pubDate>Wed, 10 Feb 2021 01:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unattended Debian Installation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26084707">thread link</a>) | @sedlav
<br/>
February 9, 2021 | https://www.librebyte.net/en/systems-deployment/unattended-debian-installation/ | <a href="https://web.archive.org/web/*/https://www.librebyte.net/en/systems-deployment/unattended-debian-installation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
										
						<div>
<figure><img loading="lazy" width="100" height="123" src="https://www.librebyte.net/wp-content/uploads/2014/11/debiaopenlogo-100.jpg" alt="Debian GNU/Linux"></figure>
</div>
<p>Debian is a rock solid GNU/Linux distribution with more than 30,000 packages available in its official repositories. Debian is suitable for servers, workstations, mobile devices and embedded systems.</p>
<p>Debian has a simple and clean installation system which allows installing Debian with little effort as long as the number of installations to be executed is minimal, but as this number grows the installation procedure becomes cumbersome and tedious (Please note that during the installation process it is necessary to answer configuration questions and package selection), for example if we want to install Debian in a lab that has 15 workstations, we need to repeat this process 15 times, which is possible , but if we want to deploy Debian in mass, for example 100, 200, 500 or 1000 installations, it is no longer feasible, this is the reason why the Debian developers have created a system that allows automatic or unattended installations starting from a configuration file (preseed).</p>
<p>There are three methods that can be used to execute an unattended installation:</p>
<ol>
<li>Adding the preseed file to the installer’s <a href="https://es.wikipedia.org/wiki/Initrd">initrd.gz</a>, <a href="https://wiki.debian.org/DebianInstaller/Preseed#Adding_the_preseed_file_to_the_installer.27s_initrd.gz">link</a></li>
<li>Add the file boot parameter to the <a href="https://wiki.debian.org/ManipulatingISOs#remaster">ISO image</a></li>
<li>Load the preseed.cfg file from the network
<ul>
<li><a href="https://wiki.debian.org/DebianInstaller/Preseed#Autoloading_the_preseeding_file_from_a_webserver_via_DHCP">Autoloading the preseeding file from a webserver via DHCP</a></li>
<li><a href="https://wiki.debian.org/DebianInstaller/Preseed#Loading_the_preseeding_file_from_a_webserver">Loading the preseeding file from a webserver</a></li>
</ul>
</li>
</ol>
<p>In this post we’re going to use method 1 for unattended installation starting from <a href="https://wiki.debian.org/DebianInstaller/Preseed/EditIso">DebianInstaller/Preseed/EditIso</a></p>
<h2 id="dowload-debian-image">1. Dowload Debian image</h2>
<p>We will download the “net-install” image that allows a minimal installation, an internet connection is needed since the files are downloaded from Debian repositories.</p>
<pre><code>$ curl -LO# https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-10.8.0-amd64-netinst.iso
</code></pre>
<p>Recommended reading: <a href="https://www.librebyte.net/en/internet-browsers/as-download-files-using-curl/">How to download files using curl</a></p>
<h2 id="install-xorriso">2. Install xorriso</h2>
<p><strong>xorriso</strong> allows  to extract files from an ISO image and dump into the file system</p>
<pre><code>$ sudo apt -y install xorriso
</code></pre>

<p>With the following command we put the files contained in the “net-install” image into the file system under the isofiles DIR if the isofiles DIR does not exist, xorriso creates it automatically.</p>
<pre><code>$ xorriso -osirrox on -indev debian-10.1.0-amd64-netinst.iso  -extract / isofiles/
</code></pre>
<h2 id="dowload-a-base-preseed">4. Dowload a base preseed</h2>
<p>A basic template is available from Debian site which serves as a starting point for our unattended installation system.</p>
<pre><code>$ curl -#L https://www.debian.org/releases/stable/example-preseed.txt -o preseed.cfg
</code></pre>
<p>Recommended reading: <a href="https://www.librebyte.net/en/internet-browsers/as-download-files-using-curl/">How to download files using curl</a></p>
<h2 id="modify-preseed-template-according-our-needs">5. Modify preseed template according our needs</h2>
<h3 id="setting-the-locale">5.1. Setting the locale</h3>
<p>Set operating system language to English, UTF-8 encoding and locale settings (date, currencies) to English U.S.</p>
<pre><code>d-i debian-installer/language string en
d-i debian-installer/country string US
d-i debian-installer/locale string en_US.UTF-8
</code></pre>
<h3 id="setting-the-timezone">5.2. Setting the timezone</h3>
<p>Set the hardware clock to UTC and set the timezone to America/New_York (we can use any value found on <code>/usr/share/zoneinfo/</code>) and use <a href="https://es.wikipedia.org/wiki/Network_Time_Protocol">NTP</a> for time synchronization.</p>
<pre><code>d-i clock-setup/utc boolean true
d-i time/zone string America/New_York
d-i clock-setup/ntp boolean true
</code></pre>
<h3 id="configure-the-keyboard">5.3.  Configure the keyboard</h3>
<p>Set the keyboard to US.</p>
<pre><code>d-i keyboard-configuration/xkb-keymap select us
</code></pre>
<h3 id="configure-the-network">5.4. Configure the network</h3>
<p>With the following configuration the installation system will try to configure the network automatically, set the hostname to debian10, set localdomain as domain name and use the <code>http.us.debian.org</code> as  mirror it is also possible to specify a proxy which in this case is empty.</p>
<pre><code>d-i netcfg/choose_interface select auto
d-i netcfg/get_hostname string debian10
d-i netcfg/get_domain string localdomain
# Avoid to show WEP dialog
d-i netcfg/wireless_wep string
d-i mirror/country string manual
d-i mirror/http/hostname string http.us.debian.org
d-i mirror/http/directory string /debian
d-i mirror/http/proxy string
</code></pre>
<h3 id="configure-users">5.5. Configure users</h3>
<p>We disable the the root user authentication user, instead we will use <code>sudo</code> with a standard user with encrypted password.</p>
<pre><code>d-i passwd/root-login boolean false
d-i passwd/user-fullname string Ponga Aqui el nombre completo del usuario a crear
d-i passwd/username string nombre_de_usuario
d-i passwd/user-password-crypted password Ponga aqui la contraseña encryptada
</code></pre>
<p>To encrypt the password you can execute the following command:</p>
<pre><code>$ python3 <span>-</span>c <span>'import crypt; print(crypt.crypt("mipass", crypt.METHOD_SHA512))'</span>
</code></pre>
<h3 id="partitioning">5.6. Partitioning</h3>
<p>We’re going to use <a href="https://es.wikipedia.org/wiki/Logical_Volume_Manager">LVM</a> as partition method, <strong>any old partition will be removed</strong>, the selected partition scheme is <code>atomic</code> that means use the the entire hard disk for a single partition, another options are: home (living in its own partition) and multi (separate partitions for /home, /var, /tmp).</p>
<pre><code>d-i partman-auto/method string lvm
d-i partman-lvm/device_remove_lvm boolean true
d-i partman-lvm/confirm boolean true
d-i partman-lvm/confirm_nooverwrite boolean true
d-i partman-auto/choose_recipe select atomic
d-i partman-auto-lvm/guided_size string max
</code></pre>
<p>Avoid that partman asks for  confirmation to continue with the partition process.</p>
<pre><code>d-i partman-partitioning/confirm_write_new_label boolean true
d-i partman/choose_partition select finish
d-i partman/confirm boolean true
d-i partman/confirm_nooverwrite boolean true
</code></pre>
<h3 id="packages-selection">5.7. Packages selection</h3>
<p>In addition to the base system, install an <a href="https://es.wikipedia.org/wiki/Secure_Shell">SSH</a> server.</p>
<pre><code>tasksel tasksel/first multiselect
d-i pkgsel/include string openssh-server
</code></pre>
<h3 id="disable-send-stats">5.8. Disable send stats</h3>
<pre><code>popularity-contest popularity-contest/participate boolean false
</code></pre>
<h3 id="some-grub-configuration">5.9. Some <a href="https://es.wikipedia.org/wiki/GNU_GRUB">GRUB</a> configuration</h3>
<pre><code>d-i grub-installer/only_debian boolean true
d-i grub-installer/with_other_os boolean true
d-i grub-installer/bootdev  string default
</code></pre>
<h3 id="final-configurations">5.10. Final configurations</h3>
<pre><code># Don't show "Installation has been completed" message
d-i finish-install/reboot_in_progress note
# Avoid CD/DVD scan
d-i apt-setup/cdrom/set-first boolean false
d-i apt-setup/cdrom/set-next boolean false
d-i apt-setup/cdrom/set-failed boolean false
</code></pre>
<p>You can download the preseed file with the settings described above at: <a href="https://gist.github.com/yoander/22bec90625436a2bef532b3828ad4cbd">Debian preseed</a></p>
<h2 id="add-preseed-to-initrd">6. Add preseed to initrd</h2>
<p>Set write permissions to <code>install.amd</code> DIR</p>
<pre><code>$ chmod +w -R isofiles/install.amd/
</code></pre>
<p>Unzip <code>initrd</code> image</p>
<pre><code>$ gunzip isofiles/install.amd/initrd.gz
</code></pre>
<p>Add preseed.cfg to <code>initrd</code></p>
<pre><code>$ echo preseed.cfg | cpio -H newc -o -A -F isofiles/install.amd/initrd
</code></pre>
<p>Recreate the <code>initrd</code> image</p>
<pre><code>$ gzip isofiles/install.amd/initrd
</code></pre>
<p>Remove write permission to <code>install.amd</code> DIR.</p>
<pre><code>$ chmod -w -R isofiles/install.amd/
</code></pre>
<h2 id="modify-the-boot-loader">7. Modify the boot loader</h2>
<h3 id="isolinux">7.1 ISOLINUX</h3>
<p>The  <a href="https://wiki.syslinux.org/wiki/index.php?title=ISOLINUX">ISOLINUX</a> boot loader is compatible with  <a href="https://es.wikipedia.org/wiki/BIOS">BIOS</a></p>
<p>We should edit the <code>isolinux/isolinux.cfg</code> file and delete the line <code>default vesamenu.c32</code> this avoid the Debian installation menu.</p>
<h3 id="grub">7.2 GRUB</h3>
<p><a href="https://es.wikipedia.org/wiki/GNU_GRUB">GRUB</a> boot loader is compatible with <a href="https://es.wikipedia.org/wiki/Extensible_Firmware_Interface">UEFI</a></p>
<p>We should edit <code>boot/grub/grub.cfg</code> file  and the following lines that avoid the Debian installation menu.</p>
<pre><code>set timeout_style=hidden
set timeout=0
set default=1
</code></pre>
<h2 id="generate-the-md5-sum-md5sum.txt">8. Generate the MD5 sum (md5sum.txt)</h2>
<pre><code>$ cd isofiles/
$ chmod a+w md5sum.txt
$ md5sum `find -follow -type f` &gt; md5sum.txt
$ chmod a-w md5sum.txt
</code></pre>
<h2 id="create-the-iso">9. Create the ISO</h2>
<pre><code>$ cd ..
$ chmod a+w isofiles/isolinux/isolinux.bin
$ genisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o debian-10-unattended.iso isofiles
</code></pre>
		<div>
			<div>
				<div>
					    <p>The tutorials here on LibreByte are provided under a free software licence. if you like my work you should consider:</p>
    <p><strong>Buy a Hosting/VPS or Dedicated Server at <a href="https://my.mckhost.com/aff.php?aff=3">MCKHost</a></strong></p>
				</div>           
			</div>
		</div>
								</div></div>]]>
            </description>
            <link>https://www.librebyte.net/en/systems-deployment/unattended-debian-installation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26084707</guid>
            <pubDate>Wed, 10 Feb 2021 01:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sauce – Embedded GitHub Snippets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26084498">thread link</a>) | @flaque
<br/>
February 9, 2021 | https://kag0.github.io/sauce/ | <a href="https://web.archive.org/web/*/https://kag0.github.io/sauce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
<p>Embed snippets from source code on GitHub using <a href="https://highlightjs.org/">highlight.js</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components">web components</a>.
All client side, all free and open source.</p>

<h2 id="importing">Importing</h2>

<div><div><pre><code><span>&lt;script </span><span>type=</span><span>'module'</span> <span>src=</span><span>"https://kag0.github.io/sauce/sauce.js"</span><span>&gt;&lt;/script&gt;</span>
</code></pre></div></div>



<h2 id="embedding-a-file">Embedding a file</h2>

<sauce-code repo="kag0/sauce" file="example.html" lines="12:15"></sauce-code>

<h2 id="overriding-the-language-detection">Overriding the language detection</h2>

<sauce-code repo="kag0/sauce" file="example.html" lines="17:21"></sauce-code>

<h2 id="embedding-a-snippet-from-a-file">Embedding a snippet from a file</h2>

<sauce-code repo="kag0/sauce" file="example.html" lines="23:27"></sauce-code>

<h2 id="changing-the-theme">Changing the theme</h2>

<p>You can find a list of themes <a href="https://cdnjs.com/libraries/highlight.js">here</a>. 
The theme name is between the last <code>/</code> and the <code>.min.css</code>.<br>
Previews of themes are <a href="https://highlightjs.org/static/demo/">here</a>.</p>

<sauce-code lang="html" repo="kag0/sauce" file="example.html" theme="monokai-sublime" lines="29:33"></sauce-code>

<h2 id="other-goodies">Other goodies</h2>

<h3 id="the-source-file-link-after-the-snippet-links-directly-to-the-specified-lines-in-the-file">The source file link after the snippet links directly to the specified lines in the file</h3>

<p><img src="https://kag0.github.io/sauce/gh-ss.png" alt=""></p>


      
      
      
    </div></div>]]>
            </description>
            <link>https://kag0.github.io/sauce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26084498</guid>
            <pubDate>Wed, 10 Feb 2021 00:41:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iRacing Telemetry with F#]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26083841">thread link</a>) | @todsacerdoti
<br/>
February 9, 2021 | https://markjames.dev/2021-02-09-iracing-telemetry-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-02-09-iracing-telemetry-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>During the pandemic, I’ve been spending quite a bit of time playing <a href="https://iracing.com/">iRacing</a> in VR. I love the realism of iRacing (and how well it supports VR!), and managed to score a win in the Mazda MX-5 this season at the (sadly) now defunct Oran Park Raceway near Sydney.</p>

<p><img src="https://markjames.dev/img/posts/race-result-mazda.png" width="600" height="150" alt="First place at Oran Park Raceway"></p>

<p>In a <a href="https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">previous post</a>, I discussed how I was looking to create an F# library for the iRacing SDK. This proved to be a bigger challenge than I thought as the iRacing API uses a memory mapped file and I’m not yet familiar enough with F# to be tackling the problem yet.</p>

<p>As an alternative (and thanks to F#’s interoperability with C# and the .NET platform), I decided to familiarize myself with this <a href="https://github.com/NickThissen/iRacingSdkWrapper">C# iRacing SDK</a> and build a small app that gathers some basic telemetry data and writes it to a CSV file which I could then plot in a .NET Interactive Notebook using Plotly.NET. The end result of my first few tests looked like this:</p>


    
        <!-- Plotly.js -->
        <meta http-equiv="X-UA-Compatible" content="IE=11">
        
        
    
    
      
     
    


<p>The entire process was refreshingly simple, but there were a few things that had stumped me as I had still been thinking in C# (which I’m more familiar with). For example, here’s the code which listens to an event from the iRacing SDK and then calls a function which parses and then writes telemetry data to a CSV:</p>

<div><div><pre><code><span>// Get the current speed in m/s and convert to a rounded km/h.</span>
<span>let</span> <span>getSpeed</span> <span>(</span><span>evArgs</span><span>:</span> <span>SdkWrapper</span><span>.</span><span>TelemetryUpdatedEventArgs</span><span>)</span> <span>=</span>
    <span>let</span> <span>speed</span> <span>=</span> <span>float</span> <span>evArgs</span><span>.</span><span>TelemetryInfo</span><span>.</span><span>Speed</span><span>.</span><span>Value</span>
    <span>let</span> <span>speedInKMh</span> <span>=</span> <span>speed</span> <span>*</span> <span>3</span><span>.</span><span>6</span>
    <span>let</span> <span>speedRounded</span> <span>=</span> <span>System</span><span>.</span><span>Math</span><span>.</span><span>Round</span> <span>(</span><span>speedInKMh</span><span>,</span> <span>0</span><span>)</span> 
    <span>speedRounded</span>

<span>// Get the throttle input and round it.</span>
<span>let</span> <span>throttleValue</span> <span>(</span><span>evArgs</span><span>:</span> <span>SdkWrapper</span><span>.</span><span>TelemetryUpdatedEventArgs</span><span>)</span> <span>=</span>
    <span>let</span> <span>throttle</span> <span>=</span> <span>float</span> <span>evArgs</span><span>.</span><span>TelemetryInfo</span><span>.</span><span>Throttle</span><span>.</span><span>Value</span>
    <span>let</span> <span>roundedThrottle</span> <span>=</span> <span>System</span><span>.</span><span>Math</span><span>.</span><span>Round</span> <span>(</span><span>throttle</span><span>,</span> <span>2</span><span>)</span>
    <span>roundedThrottle</span>

<span>// Get the lapdistance and round it.</span>
<span>let</span> <span>getLapDistance</span> <span>(</span><span>evArgs</span><span>:</span> <span>SdkWrapper</span><span>.</span><span>TelemetryUpdatedEventArgs</span><span>)</span> <span>=</span>
    <span>let</span> <span>distance</span> <span>=</span> <span>float</span> <span>evArgs</span><span>.</span><span>TelemetryInfo</span><span>.</span><span>LapDistPct</span><span>.</span><span>Value</span>
    <span>let</span> <span>roundedDistance</span> <span>=</span> <span>System</span><span>.</span><span>Math</span><span>.</span><span>Round</span> <span>(</span><span>distance</span><span>,</span> <span>2</span><span>)</span>
    <span>roundedDistance</span>

<span>// Append the output of the current tick to a CSV file.</span>
<span>let</span> <span>writeToCsv</span> <span>(</span><span>evArgs</span><span>:</span> <span>SdkWrapper</span><span>.</span><span>TelemetryUpdatedEventArgs</span><span>)</span> <span>=</span>
    <span>let</span> <span>dataToWrite</span> <span>=</span> <span>$</span><span>"{getSpeed evArgs},{evArgs.TelemetryInfo.Gear.Value},{throttleValue evArgs},{evArgs.TelemetryInfo.Lap.Value},{getLapDistance evArgs}</span><span>\n</span><span>"</span>
    <span>File</span><span>.</span><span>AppendAllText</span> <span>(</span><span>"""C:</span><span>\</span><span>LapTimes.csv"""</span><span>,</span> <span>dataToWrite</span><span>)</span>
    <span>printfn</span> <span>"Wrote to CSV"</span>

<span>let</span> <span>start</span> <span>()</span> <span>=</span>
    <span>// Bind an instance of iRacing SdkWrapper to iRacing</span>
    <span>let</span> <span>iracing</span> <span>=</span> <span>new</span> <span>SdkWrapper</span><span>(</span><span>TelemetryUpdateFrequency</span> <span>=</span> <span>2</span><span>.</span><span>0</span><span>)</span>
    <span>iracing</span><span>.</span><span>TelemetryUpdated</span>
    <span>// Listen to the iRacing telemetry updates</span>
    <span>|&gt;</span> <span>Observable</span><span>.</span><span>subscribe</span> <span>writeToCsv</span> <span>|&gt;</span> <span>ignore</span>
    <span>iracing</span><span>.</span><span>Start</span><span>()</span>
</code></pre></div></div>
<p>The first thing to note is the structure of the code. F# code is structured from the bottom up (the same applies for files in a project), and I find that this helps with readability and reasoning about the code.</p>

<p>Another thing to consider is how to set the update frequency (in updates per second). In C#, we would update a variable to set the telemetry update frequency like so:</p>
<div><div><pre><code><span>iracing</span><span>.</span><span>TelemetryUpdateFrequency</span> <span>=</span> <span>2.0</span><span>;</span> <span>// Updates per second</span>
</code></pre></div></div>
<p>However, In F#, we bind names to expressions as opposed to assigning variables. Then how can we set an update frequency for the C# library without using a mutable? The answer is simple, pass it in as a parameter to the SdkWrapper constructor:</p>

<div><div><pre><code><span>let</span> <span>iracing</span> <span>=</span> <span>new</span> <span>SdkWrapper</span><span>(</span><span>TelemetryUpdateFrequency</span> <span>=</span> <span>2</span><span>.</span><span>0</span><span>)</span> <span>// Receive events at a rate of two updates/sec.</span>
</code></pre></div></div>

<p>Next, note the use of Observable.subscribe to listen to an event. In C#, we would likely do something like this to subscribe to the event using an event handler:</p>

<div><div><pre><code><span>class</span> <span>Program</span> 
<span>{</span>
    <span>private</span> <span>readonly</span> <span>Sdkwrapper</span> <span>iracing</span><span>;</span>

    <span>static</span> <span>void</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>    
        <span>iracing</span> <span>=</span> <span>new</span> <span>SdkWrapper</span><span>;</span>
        <span>iracing</span><span>.</span><span>TelemetryUpdated</span> <span>+=</span> <span>OnTelemetryUpdated</span><span>;</span>
        <span>iracing</span><span>.</span><span>Start</span><span>();</span>
    <span>}</span>

    <span>private</span> <span>void</span> <span>OnTelemetryUpdated</span><span>(</span><span>object</span> <span>sender</span><span>,</span> <span>SdkWrapper</span><span>.</span><span>TelemetryUpdatedEventArgs</span> <span>e</span><span>)</span>
    <span>{</span>
        <span>// Use live telemetry</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In F#, we subscribe to the event using Observable.subscribe and call our writeToCsv function each time the event is fired:</p>
<div><div><pre><code>    <span>iracing</span><span>.</span><span>TelemetryUpdated</span>
    <span>|&gt;</span> <span>Observable</span><span>.</span><span>subscribe</span> <span>writeToCsv</span> <span>|&gt;</span> <span>ignore</span>
</code></pre></div></div>

<p>The interop between C# and F# events is nice, and I find this solution to be quite elegant. In addition, you also have Observable.scan which accumulates state each time an event has fired. I haven’t had to do that in this example, but you can see <a href="https://fsharpforfunandprofit.com/posts/concurrency-reactive/">more details here</a>.</p>

<h2 id="plotting-the-telemetry-data">Plotting the Telemetry Data</h2>

<p>Now that we have a backend system logging some telemetry data from the sim, the next step is to plot the graph we saw above. In order to do so, I created a new .NET Interactive notebook in VS Code Insiders. I then imported the libraries I needed and wrote the following initial code:</p>
<div><div><pre><code><span>[&lt;</span><span>Literal</span><span>&gt;]</span>
<span>let</span> <span>FilePath</span> <span>=</span> <span>"""C:</span><span>\</span><span>LapTimes.csv"""</span>

<span>type</span> <span>rawCsv</span> <span>=</span> <span>CsvProvider</span><span>&lt;</span><span>FilePath</span><span>,</span> <span>HasHeaders</span> <span>=</span> <span>true</span><span>&gt;</span>

<span>// CSV File</span>
<span>let</span> <span>lapPerformance</span> <span>=</span> <span>rawCsv</span><span>.</span><span>GetSample</span><span>()</span>
</code></pre></div></div>
<p>The use of [&lt;Literal&gt;] here is because FilePath must be a constant so that the CsvProvider can read the data while we’re developing. As I mentioned in a previous article on <a href="https://markjames.dev/2021-01-23-plotting-csv-files-fsharp/">CSV files in F#</a>, “Type providers are a blessing and curse in F#. On one hand, they’re amazing, because you get compile-time types for your data! But, that also means the data must be available at compile time. You can usually work around this by either:</p>
<ul>
  <li>Including representative data inside your project’s git repo, so you can build the provider based on sample data and then parse any conforming input data</li>
  <li>Using a string literal in source code to define sample data and use that for the provider (which is what I’ve done here).”</li>
</ul>

<p>I also added some column headers into my CSV file (in the future, I plan to write these automatically in the backend code). We also create a new CsvProvider, and then get the data by calling GetSample() on the raw CSV file.</p>

<p>Next, let’s write the createChart function and then pass it out formatted CSV file:</p>

<div><div><pre><code><span>let</span> <span>createChart</span><span>(</span><span>lapPerformance</span><span>:</span> <span>rawCsv</span><span>)</span> <span>=</span> 

    <span>let</span> <span>speed</span> <span>=</span> <span>lapPerformance</span><span>.</span><span>Rows</span> <span>|&gt;</span> <span>Seq</span><span>.</span><span>filter</span> <span>(</span><span>fun</span> <span>row</span> <span>-&gt;</span> <span>row</span><span>.</span><span>Lap</span> <span>=</span> <span>2</span> <span>)</span>
    <span>speed</span>
    <span>// Map Lap Distance and Speed to X and Y on the line chart.</span>
    <span>|&gt;</span> <span>Seq</span><span>.</span><span>map</span> <span>(</span><span>fun</span> <span>row</span> <span>-&gt;</span> <span>row</span><span>.</span><span>LapDistance</span><span>,</span> <span>row</span><span>.</span><span>Speed</span><span>)</span> 
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>Spline</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>withTitle</span> <span>"Laguna Seca (Ferrari 488 GTE)"</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>withX_AxisStyle</span> <span>(</span><span>"Lap Distance (%)"</span><span>,</span> <span>Showgrid</span><span>=</span><span>false</span><span>,</span><span>Position</span><span>=</span><span>200</span><span>.</span><span>0</span><span>)</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>withY_AxisStyle</span> <span>(</span><span>"Speed (Km/h)"</span><span>,</span> <span>Showgrid</span><span>=</span><span>false</span><span>)</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>withMargin</span><span>(</span><span>Margin</span><span>.</span><span>init</span><span>(</span><span>120</span><span>,</span> <span>100</span><span>,</span> <span>50</span><span>,</span> <span>150</span><span>,</span> <span>0</span><span>,</span> <span>true</span><span>))</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>withSize</span> <span>(</span><span>900</span><span>.</span><span>0</span><span>,</span> <span>600</span><span>.</span><span>0</span><span>)</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>Show</span>
    
<span>createChart</span><span>(</span><span>lapPerformance</span><span>:</span> <span>rawCsv</span><span>)</span> 
</code></pre></div></div>
<p>The first thing I do is make use of a higher order function, Seq.filter in order to only include lap two for plotting. Thanks to type providers, we can reference columns (e.g. row.Lap) directly while developing! I find this super handy as I no longer need to reference the file itself to figure out which columns are which.</p>

<p>Next, we construct a pipeline using the forward piping operator (|&gt;) to map the lap distance and speed variables as X and Y values on a line chart, and then define how the chart should be styled. I really like the forward piping operator, and I find that it produces some really clean and concise code.</p>

<h2 id="exploratory-data-with-deedle">Exploratory Data with Deedle</h2>

<p>For a project at work, I’ve been exploring the use of <a href="https://bluemountaincapital.github.io/Deedle/">Deedle</a> as an alternative to Python’s Pandas, and it could be a good library to make use of here to explore telemetry data in greater detail.</p>

<p>The first thing I tried using Deedle, was seeing what my average lap speed was across laps 1-4 at the Laguna Seca Racetrack:</p>

<div><div><pre><code><span>let</span> <span>lapCsv</span> <span>=</span> <span>Frame</span><span>.</span><span>ReadCsv</span><span>(</span><span>"""C:</span><span>\</span><span>LapTimes.csv"""</span><span>,</span> <span>hasHeaders</span> <span>=</span> <span>true</span><span>)</span>

<span>let</span> <span>speed</span> <span>=</span> <span>lapCsv</span><span>.</span><span>GetColumn</span><span>&lt;</span><span>int</span><span>&gt;(</span><span>"Speed"</span><span>)</span>
<span>speed</span> 
<span>|&gt;</span> <span>Stats</span><span>.</span><span>mean</span>
<span>|&gt;</span> <span>printf</span> <span>"Average speed: %A Km/h"</span>
</code></pre></div></div>

<p>The results were:</p>
<div><div><pre><code>Average speed:
121.036 Km/h
</code></pre></div></div>
<p>In this example, we’re loading our CSV file into a Deedle Dataframe, and then binding the Speed column to speed. Next, we make use of pipeline operator to get the mean of the column and print that to the console.</p>

<h2 id="next-steps">Next Steps</h2>

<p>Although there are much better telemetry systems out there, working on my own simple version has allowed me to better see the differences between C# and F#, while at the same time seeing how I can use C# libraries in F# in order to accomplish different tasks. In addition, It would be a good idea to buffer the output as opposed to writing to the file each tick, but since its only two updates per second and doesn’t need to scale, I’m okay with leaving it as is for now.</p>

<p>Moving forward, the next step is to parse the CSV file and then plot several laps together to analyze breaking points and speed on the straights to see if I can improve on any specific areas of the track.</p>

<p>Lastly, thanks to F# great interop with C#, I’m not so sure that there’s a need to port the library to F#, and I might instead look towards some other areas of F# where there’s more of a need for a library.</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-02-09-iracing-telemetry-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26083841</guid>
            <pubDate>Tue, 09 Feb 2021 23:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 3]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26082667">thread link</a>) | @todsacerdoti
<br/>
February 9, 2021 | https://www.snoyman.com/blog/2020/12/haskell-bad-parts-3/ | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/12/haskell-bad-parts-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <section>
        <div>
          <div>
            <div>
              <p>
                <a href="https://www.beginrust.com/">New: The "Begin Rust" book</a>
              </p>

              




  






      <p>
        <i>
          See a typo? Have a suggestion?
          <a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/blog/haskell-bad-parts-3.md">Edit this page on Github</a>
        </i>
      </p>

      



      <p>If you didn't see it, please check out <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">part 1 of this series</a> to understand the purpose of this. You can also check out <a href="https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">part 2</a>. Now, for more bad parts!</p>
<p>Note that this is the last blog post in this series where I had specific ideas queued up. So it's likely that this will be the last post for a while until I get annoyed by something again. So if you really want to see a continuation, find some bit of Haskell code that will annoy me and share it with me!</p>
<h2 id="pattern-matching">Pattern matching</h2>
<p>OK, this section title is a complete troll. I don't think pattern matching is a bad part of Haskell. I think pattern matching is one of the most powerful features in all of Haskell, especially when combined with sum types/ADTs. If someone asked me for a singular reason to consider using Haskell, this is what I'd point to.</p>
<p>Which is why the bad parts of pattern matching in Haskell are so bad. My "Haskell elevator pitch" is almost immediately undermined by terrible defaults.</p>
<p>My elevator pitch goes something like this: with sum types, you get to define your data types far more explicitly than in languages with only product types. And then you can rely on the compiler to tell you when you've made a change to a data constructor, or added a new data constructor. I usually try to understand first what someone's field of experience is and then build a real-ish example of sum types from that.</p>
<p>Unfortunately, that's all a lie, at least by default. Some specific parts of pattern matching <em>do</em> in fact let the compiler tell you when you've screwed up. (And if it's not clear: my favorite part of GHC is when it tells me I've screwed up.) If I delete a data constructor, or if I add a new field to a data constructor and I was pattern matching on positionally, the compiler will error.</p>
<p>But this code compiles just fine, and I wish it didn't!</p>
<pre><code><span>data </span><span>MySum </span><span>= </span><span>Foo </span><span>| </span><span>Bar </span><span>| </span><span>Baz

</span><span>main </span><span>:: </span><span>IO</span><span>()
</span><span>main </span><span>=
    case </span><span>Baz </span><span>of
        </span><span>Foo </span><span>-&gt;</span><span> putStrLn </span><span>"</span><span>Foo</span><span>"
        </span><span>Bar </span><span>-&gt;</span><span> putStrLn </span><span>"</span><span>Bar</span><span>"

</span></code></pre>
<p>Not only does it compile just fine, but <em>there are no warnings</em>! "OK Michael," you say. "Who cares? <em>Everyone</em> knows that you should compile with <code>-Wall</code> turned on." To that, I say three things:</p>
<ol>
<li>No, not everyone knows it</li>
<li>Because of spurious warnings in <code>-Wall</code>, like unused import warnings, important warnings like this often get drowned out. (Yes, it's better to be warning-free for this reason...)</li>
<li>Yeah, but it gets worse</li>
</ol>
<p>Let's elaborate on (3). I'm a good programmer. So I turn on <code>-Wall</code>. Now I'm guaranteed a warning on incomplete pattern matches... right? Right?!? Right!!!!!!1111oneoneone</p>
<pre><code><span>{-# </span><span>OPTIONS_GHC</span><span> -Wall #-}
</span><span>data </span><span>MySum </span><span>= </span><span>Foo </span><span>| </span><span>Bar </span><span>| </span><span>Baz

</span><span>main </span><span>:: </span><span>IO</span><span>()
</span><span>main </span><span>=</span><span> (</span><span>\</span><span>Foo </span><span>-&gt;</span><span> putStrLn </span><span>"</span><span>Foo</span><span>"</span><span>) </span><span>Bar
</span></code></pre>
<p>Nope, denied! I get no warning here. Even though I have a <em>refutable pattern match</em> in my lambda, the compiler provides no warnings. "Didn't you know you needed to turn on <code>incomplete-uni-patterns</code> for that?" Actually, no, for a long time I didn't know that.</p>
<pre><code><span>{-# </span><span>OPTIONS_GHC</span><span> -Wall -Wincomplete-uni-patterns #-}
</span><span>data </span><span>MySum </span><span>= </span><span>Foo </span><span>| </span><span>Bar </span><span>| </span><span>Baz

</span><span>main </span><span>:: </span><span>IO</span><span>()
</span><span>main </span><span>=</span><span> (</span><span>\</span><span>Foo </span><span>-&gt;</span><span> putStrLn </span><span>"</span><span>Foo</span><span>"</span><span>) </span><span>Bar
</span></code></pre>
<p>Fortunately, there's some <a href="https://gitlab.haskell.org/ghc/ghc/-/issues/15656">hope on the horizon</a> for this one.</p>
<p>One more annoyance, only tangentially related. GHC: please stop generating partial functions on my behalf!</p>
<pre><code><span>data </span><span>Staff
    </span><span>= </span><span>Principal
    </span><span>| </span><span>Teacher</span><span> { subject </span><span>:: </span><span>String</span><span> }

</span><span>main </span><span>:: </span><span>IO</span><span>()
</span><span>main </span><span>=</span><span> putStrLn </span><span>$ </span><span>"</span><span>Your subject is </span><span>" </span><span>++</span><span> subject </span><span>Principal
</span></code></pre>
<p>I just discovered that this can be detected with <code>-Wpartial-fields</code>, which is nice, but not part of <code>-Wall</code>. I've been giving advice for a long time to not include any field labels in sum types, and I'll continue to give that advice.</p>
<p>Note that some Haskellers won't like: this topic came up for me recently while writing a blog post comparing pattern matching in Haskell and Rust (probably going live next week). And, yet again, Rust does this better than Haskell. Yes, Rust is strict and Haskell is lazy. But as far as I'm concerned, in this case, Rust is simply more type safe than Haskell.</p>
<h2 id="slow-compilation">Slow compilation</h2>
<p>Let's get an elephant in the room out in the open. Compiling is slow. Some of this is because of GHC. Some of this is because our libraries are trying to do overly complicated things (like stream fusion in <code>vector</code> and <code>text</code>). This is a bane for Haskell, constantly.</p>
<p>As a recent example, I needed to add a flag to <code>http-conduit</code> to disable the <code>aeson</code> dependency:</p>
<blockquote><p lang="en" dir="ltr">.<a href="https://twitter.com/snoyberg?ref_src=twsrc%5Etfw">@snoyberg</a> kindly provided "-aeson" flag to http-conduit which saves my time very much. Thanks.<br>BTW, why does building aeson take so much time?</p>— 山本和彦 (@kazu_yamamoto) <a href="https://twitter.com/kazu_yamamoto/status/1334988010434150401?ref_src=twsrc%5Etfw">December 4, 2020</a></blockquote> 
<p>I'm not going to beat up on this too much, since GHC is a complicated project and people are trying hard to both improve the existing support <em>and</em> add new features. And library authors (myself included) are caught between providing features and speeding up compilation.</p>
<p>There is a part of me that wonders if part of the problem is that our standard library (<code>base</code>) doesn't provide enough functionality out of the box, and leaves a lot of external libraries to implement and reimplement similar functionality. As more time goes on, I think Vincent Hanquez was <a href="https://github.com/haskell-foundation">completely correct about how to improve Haskell</a> and I wish I'd embraced it.</p>
<h2 id="text">Text</h2>
<p>There's so much wrong here. And I can't even blame it all on the <code>text</code> package. But I can blame a lot of it on the <code>text</code> package. Consider this section incoherent rambling instead of well reasoned arguments. (Typically a fair assumption with anything I say to be honest.)</p>
<ul>
<li>Why oh why is it UTF-16 instead of UTF-8? This is terrible! Except...</li>
<li>It's completely irrelevant what encoding <code>text</code> uses under the surface, because <em>you can't directly interact with its underlying representation</em>. And <em>that's</em> because...</li>
<li><code>text</code> uses unpinned memory to avoid heap fragmentation, which is a Good Thing, but then <code>text</code> can't be directly used in FFI calls. Which is probably a good thing, since it uses the wrong character encoding under the surface.</li>
<li><code>text</code> defines its own <code>Builder</code> type. It shouldn't. We should be using the <code>ByteString</code> <code>Builder</code> everywhere, and have a <code>newtype</code> wrapper around it to encode the invariant "must be UTF-8 encoded." <code>Builder</code> is a <em>wonderful</em> thing in Haskell, and it gets used far less than it should because it's such a PITA to deal with all of this. (I tried to address that in <code>rio</code>.) This is exactly the same as how we don't use <code>Vector</code> enough because of all the flaws with using it.</li>
<li>And, of course, <code>text</code> has stream fusion, which is shouldn't. I'll touch on this even more in the next section.</li>
</ul>
<p>Again, Vincent got this all right. We need a singular packed data type. It should underly a <code>ByteString</code> and a <code>Text</code>. A <code>Text</code> should be a simple newtype around a <code>ByteString</code>. Users should never have to make a decision around pinned vs unpinned memory, that should be an implementation detail. (And sure, why not, give users a knob somewhere to control this when they know better than the defaults.) Have a single <code>Builder</code> type that builds up <code>Vector</code>s, and have it work for <code>ByteString</code> and <code>Text</code> too.</p>
<p>Oh, and just a side note...</p>
<p><strong>MAKE TEXT UBIQUITOUS</strong></p>
<p>We are now more than 10 years since the first release of <code>text</code> to Hackage. And people are still regularly using <code>String</code>. <strong>I</strong> regularly use <code>String</code> in examples. We really should be able to move our ecosystem over to better types.</p>
<p>We've broken everyone's code for far less important things many times in the past. Just to rile you all up: Foldable/Traversable Proposal wasn't important or interesting, this should have taken precedence.</p>
<h2 id="lazy-data-structures">Lazy data structures</h2>
<p>There should be no lazy <code>ByteString</code>. There should be no lazy <code>Text</code>. There isn't a lazy <code>Vector</code>, and that's a Good Thing.</p>
<p>"But what if I want to read a 10GB file into memory lazily?" You're using the wrong abstraction.</p>
<p>"But what if I want to lazily generate a massive file?" You're using the wrong abstraction.</p>
<p>Here's the problem: we don't have the right abstraction in <code>base</code>. We ended up at a local minimum.</p>
<ul>
<li>Lazy lists get used for "generators" and for data storage, when they're only half good for the former</li>
<li>We don't get a real generator type in <code>base</code>, because we have lazy lists</li>
<li>We don't get a real data storage type in <code>base</code>, because <code>vector</code> exists and sucks</li>
</ul>
<p>Here's what we need to do:</p>
<ul>
<li>Get rid of lazy lists from the language entirely</li>
<li>Add a streaming data interface to <code>base</code> that properly handles side-effects without hacks like lazy I/O</li>
<li>Provide great tooling around that streaming data interface, like stream fusion</li>
<li>Add a <code>Vector</code>-like type to <code>base</code> that only handles storage, no fusion or generation, and have it work with the streaming data interface</li>
</ul>
<p>Again, I'll say: Vincent got it right.</p>
<h2 id="qualified-imports">Qualified imports</h2>
<p>Since everyone loves to fixate on trivial syntactic issues, let me include one of those here at the end so everyone can ignore my other points. Qualified imports suck. Actually, modules suck. Actually, modules and packages suck. Actually, it all sucks.</p>
<p>The first problem? Our names are too verbose. <code>import qualified Control.Monad.Trans.Class as Trans</code>. I've actually typed that, many times. That's too much typing. Why is it <code>Control.Monad</code>? How does it help me?</p>
<p>What package does that module live in? You can't tell from the name. It's <code>transformers</code>. I think. Oh wait, no, now it's in <code>base</code>. My bad. Anyway, packages are able to just trample all over each others' namespaces like this. It's annoying.</p>
<p>And because Haskell doesn't have object syntax, importing identifiers directly, or qualified importing modules, is an absolute must for accessing most functionality on types. OOP kinda beat us here.</p>
<p>Yay, more incoherent rambling!</p>
<h2 id="should-we-fix-this">Should we fix this?</h2>
<p>OK, serious talk here. I think the warnings issue I mentioned above should absolutely be fixed. For the last section: I don't see a reality where a holistic change to Haskell syntax, module hierarchy, etc, could ever be possible. We're stuck with what we've got, possibly with minor ergonomic …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/12/haskell-bad-parts-3/">https://www.snoyman.com/blog/2020/12/haskell-bad-parts-3/</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/12/haskell-bad-parts-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26082667</guid>
            <pubDate>Tue, 09 Feb 2021 21:37:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Covid-19 vaccine availability]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26082306">thread link</a>) | @hyolyeng
<br/>
February 9, 2021 | https://infinitus.ai/blog-posts/vaccinateca-covid19-automation | <a href="https://web.archive.org/web/*/https://infinitus.ai/blog-posts/vaccinateca-covid19-automation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How Infinitus helped VaccinateCA improve their coverage of Covid-19 vaccination sites by automating calls to 2500 pharmacies every day.</p></div><div><div><p>It all started when our CEO Ankit was tagged on a tweet:</p><figure><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428d57edde4b089996f4_I_MtQLyy7YWzCtfAiaxFhcmMkrcwEnW-98Us4QJYixOqGaFqeq3uTcxZo6pkaw78gO4bKrJR8Fffvwonapk3gpmSk-XzoQWgOP7hZUbqzZvZC2DsT2rrEqNVB17lLpnKQxCCLMz3.png" alt=""></p></figure><p>At Infinitus, we automate repetitive, routine phone calls so our customers can focus on the more creative and empathetic parts of their businesses. Over the past two years, we have built a platform that collects data on behalf of tens of thousands of healthcare providers to help their patients access and afford therapies as efficiently as possible. When we learned that VaccinateCA volunteers were calling hundreds of local pharmacies daily to check for vaccine availability, we asked ourselves: how can our platform help this volunteer effort?</p><figure id="w-node-_5486cc49-4b64-1119-94c9-d7485b84ba76-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a4a9679f268411d14b00f_Screen%20Shot%202021-02-02%20at%2010.59.30%20PM.png" loading="lazy" alt=""></p><figcaption>Timeline from first contact to production and a transcript of one of our first successful test calls</figcaption></figure><p>The VaccinateCA phone calls can be broken into two parts - first, identifying whether the vaccine is available, and second, how to get the vaccine. The majority of phone calls never make it past the first question. In fact, volunteers were only getting a 10% hit rate over the 200 calls they were able to make in a day. What if we could help the volunteers focus on the more exploratory work of figuring out who can get vaccines and how, and let us figure out where the vaccine is available?&nbsp;&nbsp;</p><p>Here’s how we built it:</p><h2>Phase 1. Adapt Infrastructure for New Use Case</h2><p>The Infinitus VoiceRPA platform is designed to automate phone calls. While our system is currently tuned for a few use cases, one of our goals for 2021 is to make a platform where we can quickly configure and automate any new call type. We planned to leverage our existing system as much as possible so we could get this project out the door fast. We created a new Covid Vaccination call type and a workspace for storing the data.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428dfb556cc89a26ef76_MH7Dyc-9NLpmZIatKQLSvAZsfA_ADFdYaIG7GImrhv2dWWbM-FfMT5Dl0S0rNx3Ua-sinCe-MpmQsHOEmkalMMcoYhIkMkEvABXU8D2CVnOu-XC98Mkg6csDcGPw-4vb3S-mhbKt.png" alt=""></p><figcaption>The Infinitus Technology Stack</figcaption></figure><p>The volunteers at VaccinateCA provided our team with a list of thousands of hospitals, clinics, and pharmacies that they were calling. We limited our scope to big pharmacy chains which have a large number of locations with standardized IVR (<a href="https://en.wikipedia.org/wiki/Interactive_voice_response">Interactive Voice Response</a>) systems. They were also the most likely places to have vaccine availability across the state.&nbsp;</p><p>Within a day, the Covid Vaccination workspace was filled with pharmacies and phone numbers, all displayed in the same internal tools currently used by our data labeling team.</p><h2>Phase 2. Refine the Conversation Model</h2><p>The volunteers at VaccinateCA follow this script for their phone calls:</p><ul role="list"><li>Is the vaccine available for those 65 years and older?</li><li>Where can appointments be made?</li><li>Are walk-ins accepted?&nbsp;</li><li>What documentation is needed?</li></ul><p>We dedicated two members of our data labeling team to prepare the data to call pharmacies. They guided our digital assistant, Eva, through calls to (a) generate training data for our NLP team to automate future calls and (b) validate if pharmacists would be willing to talk to a digital assistant. Here’s what an early call sounded like:</p><p>The results were promising - pharmacists were providing the information we were looking for, but, as expected, we encountered a few challenges:</p><h4>1. Some pharmacists were not sure what to do when a digital assistant called them.</h4><figure id="w-node-b7e45f80-7c74-e54e-32f5-8797a3059363-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428d108eb65d7911a316_XPM4l0fV9unhDxCqe-uyBPL5ZRVMBDY2a-_00VDUM1uquJjZNHCVFBhJf9Ra9SclJM7upP4EuUcJ2Rpcmid80O_s2wmZ9XbBMQrBq90ChQCzZ1d1HjTiuxhjVBv9B5CcgjvO96Iu.png" alt=""></p></figure><p>Between 25-30% of pharmacists who heard Eva’s automated voice, hung up without interacting with her.&nbsp;</p><p>To combat these outright hangups, we followed up with those pharmacies to explain who we are calling on behalf of and why, and asking if in the future they would be willing to talk to our digital assistant.&nbsp;</p><p>‍</p><p>‍</p><p>‍</p><h4>2. Difficulty detecting when to start asking questions.<br></h4><p>A person can easily differentiate between a pharmacist, an IVR system, or when they’re on hold, because humans subconsciously use signals like how ‘real’ a voice sounds and background noise. Humans also use signals such as pauses and changing intonations as cues to know when someone is ready for us to ask a question.<br></p><p>Our current Natural Language Understanding model processes incoming voice through a speech-to-text engine first, thereby eliminating some of the audio-based nuances a human can use to guide a conversation. For some pharmacy calls it is hard to tell from just the text if the pharmacist is ready for questions, or if they still need us to wait on hold.<br></p><p>‍</p><figure id="w-node-e8df9944-846d-a16f-b8f6-397c33be13c7-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428d57edde3aa69996f5_2R137_qS0jIN5Stj5eP8EdQXxvr6bHXOQmWrNXDXOHJyIi5PtJ0YuYVmvVjsEk8vvep9tcw3rE2nnWCad2lg90OKuDL7xKPKX_HEDvpcHG57GKLMtPeQw866Hx64zSLrRMzdG5FK.png" alt=""></p></figure><p>Consider the following examples of common phrases that can appear in the IVR, but are also commonly used by pharmacists:</p><p><strong>“How can I help you today?”</strong></p><p>In this case, the system expects a button press or a phrase like “speak to a pharmacist” to help direct the call. However, a pharmacist may use the exact same verbiage when picking up the phone, indicating that we should start asking our vaccine related questions.<br></p><p><strong>“Please hold for a moment.”</strong></p><p>If we interpret this as something to respond to, the IVR system can route our call in unexpected ways. However, if a pharmacist asks us to continue to hold and doesn’t hear a response right away, they often hang up.&nbsp;<br></p><p><strong>“Thank you for calling Rite Aid.”</strong></p><p>If we hear this in the IVR, we want to wait and listen to the menu options and press the appropriate number on a keypad. However, pharmacists also say this when picking up the phone. It is critical to ask questions as soon as we are connected to a pharmacist, otherwise they assume no one is on the line and will hang up.</p><p>‍</p><h4>3. Variation in responses from free-form questions</h4><figure id="w-node-_6c6157e9-3177-b5f2-8e36-9aad4be7a260-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428d59087960f81bd2d2_q_yj6nvFeOONto65FyIf6brM9LzBd2clk_84qdS71j074E-78rU1ifwmroEQmzGS1IuHoDOPoFOOrMRPaJslDBhMrUzqcTvn1yycIHzXvp0pIC9Be3-Yy5NoKSGtokqrLARF-8HJ.png" alt=""></p></figure><p>Responses to yes or no questions can be understood at a much higher confidence with a smaller set of training data than open-ended questions. For example, the answer to “Where can appointments be made?” results in harder to understand responses like “Do the County of Alameda.”, which was a mistranscription of something like “Through the County of Alameda [website]”.</p><p>We also noticed that the chances of a pharmacist hanging up on us increased with the length of the call. Combined with the insight that the majority of volunteers’ phone calls never made it past the first question in the script, we realized we could streamline volunteer efforts by automating the question, “Is the vaccine available for those 65 and older?” Eva could pre-screen a much larger pool of sites, and have the volunteers follow-up only in cases where the answer was “yes”.&nbsp;</p><p>‍</p><p>‍</p><h2>Phase 3. Full Automation</h2><p>To automatically navigate IVRs, we collected the scripts that the IVR systems follow. As long as a location belongs to a pharmacy chain (e.g. Rite Aid) whose IVR we have automated, we know what the IVR will say, except for some minor variations like the location’s address. Using fuzzy matching, we built a state machine which responds with the appropriate key press or voice response until we are put on hold to connect to a pharmacist.<br></p><figure id="w-node-_8d2d4741-0562-fd84-5c48-0d60d3f721cb-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428e4e028a520cbea1bf_-FeYyvb_mX7wjwX-Zk85DYOpRlGnj9JVe12V4GWeqbBfIjLQ3p2ygjhoyr3sirf5yM0RaFTxuCDSJEbIptL1PUw12Kr2WoMee9H02yKPi98ZQurlsjJUtflNq4phrPcLQ7R49Xj2.png" alt=""></p></figure><p>Once on hold, we get a continuous speech-to-text transcript and pass it to our trained model. If someone picks up and says something like “Hi, how can I help you today?”, the model classifies it as a greeting and Eva asks the covid vaccine availability question. We got around the confusion of phrases used in the IVR and by humans picking up by enabling the hold model only once the IVR portion of the call is complete.</p><p>Finally, for the conversation itself, we focused on one question: “Does your location have the covid-19 vaccine?” Because the volunteers use this data to determine which sites to call back, we want it to be as accurate as possible. If the system gets a response that it doesn’t understand yet (it’s still improving), it will ask a follow up question “Could you please answer yes or no. Do you have covid-19 vaccines?” If we still don’t get an understandable answer, we call back another time.<br></p><p>Each day, Eva calls pharmacies that haven’t been confirmed to have vaccines yet (since this information changes daily). These calls are now fully automated, from navigating each pharmacy’s automated IVR, detecting when a pharmacist is on the line, and finally extracting the response from the pharmacist and saying bye before hanging up.<br></p><p>We have been supplying the results of our calls to the volunteers at VaccinateCA, who then prioritize positive cases to confirm additional details (such as who’s eligible, how to make appointments, etc.).&nbsp;</p><h2>Beyond California</h2><p>Last week, we expanded our support to volunteer groups mirroring the efforts of VaccinateCA. We are now supporting groups in Colorado, Florida, Michigan, New Jersey, New York, Pennsylvania and Virginia.&nbsp;</p><h2>Our Impact</h2><figure id="w-node-_9943b8a9-7511-961f-4f76-5d17724f8253-f67b3b60"><p><img src="https://uploads-ssl.webflow.com/5edab43874bee849d9301d27/601a428e10a41b21690f668e_PbhUak00017R-LVSLvuO1md5n7GtubjnigyLepLSVf5Gbi4pIAJ7IdAqOxu2aNEGb0I0i7Hdg61Ejam2BPyhT2F4Az_EFGKC-zLOzmbSCALoQ5M93swtpog5DAJV5n_zolRoZduO.png" alt=""></p><figcaption>Comment about Eva in the VaccinateCA Discord channel</figcaption></figure><p>Over the past two weeks, we have made over 10,000 calls to pharmacies across 8 states. After the initial implementation phase, we’ve mostly been able to sit back and let the machine do its job. The data we’ve provided back to the group has proved immensely valuable, increasing the efficacy of their volunteer callers by an order of magnitude.</p><blockquote>Working with Infinitus has been game-changing for our effort at VaccinateCA! In under a week, their digital assistant automated daily phone calls to 2500 pharmacies across California. Using Eva means our callers, and the medical professionals they speak to, spend more of their time getting the vaccine to Californians and less hunting around for answers.<br>- Patrick McKenzie, CEO&nbsp;VaccinateCA<br></blockquote><p>It’s been fun working on this small side project, adapting and pushing our technology beyond what it was capable prior, while helping our community. We have many more interesting projects like this, and <a href="https://infinitus.ai/careers">we’re hiring</a>!<br></p></div></div></div>]]>
            </description>
            <link>https://infinitus.ai/blog-posts/vaccinateca-covid19-automation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26082306</guid>
            <pubDate>Tue, 09 Feb 2021 20:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn’s Alternate Universe]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26082268">thread link</a>) | @domrdy
<br/>
February 9, 2021 | https://every.to/divinations/linkedins-alternate-universe-21780381 | <a href="https://web.archive.org/web/*/https://every.to/divinations/linkedins-alternate-universe-21780381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><em>Hey! Today I have something different for you. Itâ€™s a piece about the weird world of LinkedIn â€” from celebrity </em>workfluencers<em> to the strange social features that feel out of place. This is a guest essay from <a href="https://twitter.com/fadeke_adegbuyi">Fadeke Adegbuyi</a>, senior marketing manager at Doist and a fan of all things internet culture. I think youâ€™re going to like it! ðŸ˜†</em></p><p><em>- Nathan</em></p><p><em> </em>LinkedIn is the fucking worst.</p><p>Despite our collective confusion about the platform, its enthusiastic embrace by HR departments and recruiters has ensured its success. Even though it was <a href="https://news.linkedin.com/2020/july/a-message">forced to lay off 1,000 employees</a> because of the pandemic, they still increased their&nbsp;Q<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2020-Q4/press-release-webcast">4 revenue by 10%.</a> As of Q3 of 2020, the company has over 722 million users and is truly internationalâ€“â€“just 26% of their members are based in North America. With revenue largely powered by recruiting solutions, paid job listings, and advertising, LinkedIn knows how to appeal to businesses at scale. LinkedIn doesnâ€™t need <em>you</em> to like it.</p><p>But, the companyâ€™s consumer-side remains in the midst of a long-standing identity crisis. Feature bloat and odd idiosyncrasies make the site a superbly strange social network. Many of us have profiles but donâ€™t log in for months at a time. Our â€œAboutâ€� sections point to better ways to be reached. Others, seemingly alive and well, have claimed on their pages to have died.</p><p>LinkedIn bills itself as an online destination, like a conference held at a 5-star hotel where big thinkers give big speeches, deals get made in private corners, and you can â€œbuild and engage with your professional network.â€� But many of us see it as a not-so-funhouse, with wacky mirrors, jumpout surprises, and peculiar attractions. Can I interest you in a tour?</p><h2>Copy-Cat Cemetery&nbsp;</h2><p>LinkedIn recently released Stories, a vertical video feature copied from Instagram, who better stole it from Snapchat. LinkedIn <a href="https://www.linkedin.com/help/linkedin/answer/119760/linkedin-stories-overview?lang=en#:~:text=LinkedIn%20Stories%20enable%20members%20and,of%20their%20everyday%20professional%20moments.&amp;text=LinkedIn%20shares%20Stories%20that%20you,recent%20version%20of%20the%20app.">suggests</a> users â€œshare images and short videos of their everyday professional moments.â€� Released in the midst of a global pandemic during a mass migration to remote work, itâ€™s unclear whether we should showcase cramped work setups on kitchen tables or restless kindergarteners interrupting the 143rd minute of a Zoom.&nbsp;</p><p>Available only on LinkedIn's iOS and Android apps, this begs the question...<em><strong>Who is using LinkedIn on their phone?</strong></em> The platform would like you to believe that celebrities are. A permanent Story from LinkedIn shows a reel of workfluencers â€“â€“Mark Cuban, Arianna Huffington, Deepak Chopra â€“â€“ posting professionally shot high-definition videos of their work days.</p><p><a href="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_40ac9496-fcd6-4638-9b55-64f17ba91976_1600x1067.png" target="_blank"><img src="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_40ac9496-fcd6-4638-9b55-64f17ba91976_1600x1067.png"></a></p><p>A tagline ends the montage: â€œShare your story.â€� At last glance, only a single one of my 1000+ connections is using the feature.&nbsp;</p><p>In contrast, Twitter is seeing early success with Fleets, their own copy-cat story feature that users have been receptive to, posting baby photos and dog pictures in between subtweets and shitposts. Feature imitation isnâ€™t a bad strategy. But LinkedIn Stories was dead on arrival. No one in the boardroom asked the critical question: <em>Who cares?</em></p><h2>The Audio Trolls</h2><p>Audio apps, like Clubhouse, Chalk, and Rodeo point to the power of sound-based social. Twitter released voice tweets earlier this spring and is currently working on an <a href="https://techcrunch.com/2020/11/17/twitter-rolls-out-stories-aka-fleets-to-all-users-will-also-test-a-clubhouse-rival/">audio spaces feature</a>. LinkedIn has taken their own steps into voice with a handful of audio features. Like most things on the platform, they feel out of place.&nbsp;</p><p>The sentiment behind their name pronunciation feature on personal profiles is a positive one, but hasnâ€™t seen wide adoption for its intended purpose. Since the feature was launched, Iâ€™ve heard people with the most pronounceable of names use the feature for anything from inserting a 10-second clip from The Office to playing a song snippet at 2x speed. A now common but unintended use case is delightful trolling:</p><ul><li>At one point, Jeff Hui used the feature to ironically <a href="https://twitter.com/jeffistyping/status/1304947619651817477?s=21">shout an elevator pitch at recruiters</a></li><li>On Riva-Melissa Tezâ€™s profile, <a href="https://www.linkedin.com/in/riva-melissa-tez-661a0aab/">she declares herself â€œQueen Beeâ€�</a></li><li>Ben Taylor, who includes â€œclick 4 soundâ€� in his name, <a href="https://www.linkedin.com/in/bentaylordata/">rickrolls his profile visitors</a></li></ul><p>On a site where people declare Ivy League associations, summa cum laude status, and internships at investment banks, cheeky irreverence for work culture warps the throughline of respectability that LinkedIn intends. Trolling LinkedIn, while on LinkedIn, is a break from the BusinessTM of polished headshots and corporately crafted â€œExperienceâ€� sections. Itâ€™s ironic participation on a platform where youâ€™re <em>meant</em> to be performing professionalism.&nbsp;</p><p>At times, it feels like LinkedIn is actively building features for the intended purpose of trolling. Within LinkedIn messages, users can hold down a microphone icon to record their voice. An audio snippet is an oddly intimate option for starting a professional conversation with a stranger. Perhaps thatâ€™s the point. But attempting to speed up relationships with overly familiar features is a â€œpersonal touchâ€� unwelcome in the world of networking, already so fraught with faux pas.</p><p>An innocent but outlandish 39-second audio message, sent by â€œ<a href="https://twitter.com/okcandice_/status/1285956830045380608?s=21">Jimmy from LinkedIn</a>â€� went viral as a case of networking-gone-not-quite-right:&nbsp;</p><blockquote>â€œHello Candice, how are you doing and good morning. How have you been? Hey Candice, this is me, Jimmy from LinkedIn. And the reason I was giving you this quick voice message call was to say thank you so kindly. I really appreciate that you have accepted me here on the LinkedIn platform. What we will do is learn from each-other. I appreciate your kindness. Jimmy from LinkedIn.â€�</blockquote><p>Though it doesnâ€™t feel malicious, itâ€™s just <em>off</em> to encounter this kind of weirdness in the same space you seek new job opportunities and professional updates from former colleagues and classmates. Itâ€™s the stuff that makes you pause and say, <em>Where am I?</em></p><h2>InMail Infinity</h2><p>The premise of the platform, bringing professionals together, is a challenging one from the start. People hate networking. Also, theyâ€™re bad at it.&nbsp;</p><p>For users, LinkedIn â€œnetworkingâ€� often means receiving a barrage of InMail and connection requests. You might recognize some or all of these:</p><ol><li><strong>The bad sales pitch</strong>: Sales people and business development people will slide into DMs to peddle their companyâ€™s products, whether youâ€™re the right person to buy or not. Usually not.</li><li><strong>The professional neg</strong>: Recruiters ask senior level employees if theyâ€™re interested in entry level roles or, better yet, internships.</li><li><strong>The just-in-case connection</strong>: Industry peers will suggest itâ€™s â€œmutually beneficialâ€� to connect, but donâ€™t specify these benefits up front.</li><li><strong>The endangered business school</strong>: Admissions teams are now online shilling once-coveted seats in their dwindling MBA programs. Based on your profile and experience, they think youâ€™re a â€œgreat fitâ€� and want you to apply.&nbsp;</li><li><strong>The eager seeker</strong>: Some people see LinkedIn messages as an alternative resume and cover letter submission portal. This is why that endless string of people in your messages inquire about roles outside your departmentâ€¦ or outside your company.&nbsp;</li><li><strong>The LinkedIn team</strong>: If their emails notifying you about connection requests wasnâ€™t enough, LinkedIn also maintains a direct line to your InMail. Expect prompts to try Premium, credits to advertise your company, and messages about whatever else theyâ€™re feeling.</li><li><strong>The proposition</strong>: Linkedin stands in the long-tradition of <em>every</em> site becoming a dating site. Or, er, a place to sexually harass people. If you havenâ€™t gotten one of these messages in your InMail, you know someone who has.</li></ol><p><a href="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_de8db43f-b1b6-454a-83a2-fe92f9bed869_1600x480.png" target="_blank"><img src="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_de8db43f-b1b6-454a-83a2-fe92f9bed869_1600x480.png"></a></p><p>Overfull InMail and random connection requests feels like a never-ending chore. You get enough work emails and donâ€™t need any more. LinkedInâ€™s constant drip of communication is just more work on top of the real work you have to do.&nbsp;</p><p>Linkedinâ€™s inbox infinity isnâ€™t just annoyingâ€”it detracts from the usability of the platform. Unless youâ€™re embracing a new position of processing and answering everything that comes through, if a real connection came along, how would you know?</p><h2>The Cursed Timeline</h2><p>At any given point on your LinkedIn timeline, youâ€™ll see a corporate blog post shared by someone you know, a marketing sales pitch from someone you donâ€™t, and a news story about COVID-19. Their timeline is similar in this way to other social networks, where you see posts made or liked by your connections, people and brands you follow, and promoted posts that people pay to get in front of you. This cacophony of content is bizarre, but not atypical â€“â€“ social feeds optimize for engagement, here as everywhere.&nbsp;</p><p>Whatâ€™s uniquely odd about LinkedIn is that it is not unique. â€œThe professional networkâ€� is still just a social network. Though the topics of the posts in your timeline may be on the world of work, diving into the comments, you can see polarization in action. Inspirational posts on giving parents grace while working from home during the pandemic have angry rants suggesting that kids are a personal choice and their burden shouldnâ€™t be foisted upon colleagues. Beneath articles on workplace harassment, sympathetic discussions ensue on why someone might naturally retaliate after being romantically rebuffed. A political article about the 2020 US presidential election draws comments on whether former President Barack Obama was really Black.&nbsp;</p><p><a href="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_96580804-aafd-41cc-896c-028a895490d6_1600x272.png" target="_blank"><img src="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_96580804-aafd-41cc-896c-028a895490d6_1600x272.png"></a></p><p>In a time when the collective conversation is consumed by the topic of human cancellation, people readily post things on LinkedIn that make them fireable or unhireable.&nbsp;</p><p><a href="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_758c1270-4c2a-4e06-8dbc-7dc0e356a568_1600x540.png" target="_blank"><img src="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_758c1270-4c2a-4e06-8dbc-7dc0e356a568_1600x540.png"></a></p><p>While these comments are nothing new in terms of online culture, they feel out of bounds on a professional website where people use their full names and disclose precisely where they work and the city they live in. In the alternate universe of LinkedIn, cancel culture either doesnâ€™t exist, its inhabitants are blissfully unaware, or they simply donâ€™t care.</p><p><a href="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_befe2496-abfd-4e7a-a29f-8dc8a3889521_1600x259.png" target="_blank"><img src="http://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1423/optimized_befe2496-abfd-4e7a-a29f-8dc8a3889521_1600x259.png"></a></p><h2>The Rockstar Recruiters</h2><p>The strangest of Linkedinâ€™s features isnâ€™t a feature at all; itâ€™s a specific set of power users.&nbsp;</p><p>Every platform has its royalty. On Instagram it's …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://every.to/divinations/linkedins-alternate-universe-21780381">https://every.to/divinations/linkedins-alternate-universe-21780381</a></em></p>]]>
            </description>
            <link>https://every.to/divinations/linkedins-alternate-universe-21780381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26082268</guid>
            <pubDate>Tue, 09 Feb 2021 20:55:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Why of Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26082257">thread link</a>) | @mpargo
<br/>
February 9, 2021 | https://www.murilopereira.com/the-why-of-technology/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-why-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://www.murilopereira.com/man_on_a_bicycle.jpg"></figure><blockquote><p>I think one of the things that really separates us from the high primates
is that we’re tool builders. I read a study that measured the efficiency of
locomotion for various species on the planet. The condor used the least
energy to move a kilometer. Humans came in with a rather unimpressive
showing about a third of the way down the list. It was not too proud a
showing for the crown of creation. So, that didn’t look so good.</p><p>But then, somebody at Scientific American had the insight to test the
efficiency of locomotion for a man on a bicycle. And, a man on a bicycle, a
human on a bicycle, blew the condor away, completely off the top of the
charts.</p><p>And that’s what a computer is to me. What a computer is to me is it’s the
most remarkable tool that we’ve ever come up with.</p><p>It’s the equivalent of a bicycle for our minds.</p><p>— <a href="https://www.youtube.com/watch?v=0lvMgMrNDlg&amp;feature=youtu.be&amp;t=322">Steve Jobs (1980)</a></p></blockquote><p>* * *</p><p><a href="https://www.it-hiroshima.ac.jp/institution/library/pdf/research52%5F007-013.pdf">No one knows</a> when or how we, the human species, started talking to each
other. It is likely a natural progression from gesturing, but we can only
speculate about it.</p><p>Language allowed us to break out of our brains and reveal the inner
workings of our consciousness to others.</p><figure><img src="https://www.murilopereira.com/language_speech.jpg" alt="Figure 2: Scott H. Young"><figcaption><p>Figure 2: <a href="https://www.scotthyoung.com/blog/2018/12/04/25-thinking-tools/">Scott H. Young</a></p></figcaption></figure><p>Language is the vessel that carried us from the stone age through the
agricultural revolution, the development of written language, the
scientific and industrial revolutions, and now, the digital age.</p><p>Writing allowed us to <em>offload</em> memories to the physical world—outside of
our brains. Through our collective and external memories, each generation
has a head start on the previous one. Little by little, standing on the
shoulders of taller and taller giants, we accumulate knowledge about
ourselves and everything around us.</p><p>We’ve been for long using tools to help us think: notebooks help us
calculate formulas, reason geometrically and preserve our ideas. With
computers, our <em>thinking</em> is now occurring outside of our brains.</p><p>Computers are extensions of our minds in that they allow us to store,
process, and retrieve information from them. With the advent of the
internet we now have immediate access to not only almost all of the
information ever produced by humankind but also to reproducible <em>thinking</em>
encoded into these machines: algorithms.</p><p>Our brain is still a much more impressive device than any of today's
computers. Computers learn
<a href="https://www.davidsilver.uk/wp-content/uploads/2020/03/nfsp-1.pdf">mostly</a>
by finding patterns in massive
quantities of examples given by us. Teaching a young kid about cars—how
to recognize one, what they are, what their purpose is, and how they're
related to other things—requires little supervision. Noam Chomsky talks
about it in
<a href="https://www.youtube.com/watch?v=hdUbIlwHRkY&amp;t=1462">this interview</a>.</p><p>Each of these processes—storing, processing and retrieving
information—have concrete effects on the physical world: if I’m in
Munich, saying “show route to Hamburg” to my phone will immediately show me
the distance, ETAs and paths for different types of transport to reach my
destination. Not only do I now suddenly know how to navigate across the
country to reach another city, I’m also able to follow through the exact
path via GPS—a sixth sense giving me perfect geolocation!</p><p>These <em>things</em> that we created—computers, and the internet—are literally
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6502424/">rewiring our brains</a>, right now, shaping how we think, and engage in social
relationships, changing not only our individual selves but the societies we
live in.</p><p>They started as mechanical machines that filled entire laboratories, turned
into beige boxes in our homes and places of work, and are now sleek slabs
of plastic, metal and glass in everyone’s pockets. Step by step they get
closer to our bodies, their interfaces more intuitive and natural.</p><p>The way we communicate with them is changing: before, we could only
interact with them by speaking their language. We have now taught them
ours. The torch of progress blazes on: it’s a matter of <em>time</em> until they’re
connected directly with our brains—which is equally terrifying and
awe-inspiring.</p><figure><img src="https://www.murilopereira.com/neuralink.jpg" alt="Figure 3: Neuralink"><figcaption><p>Figure 3: <a href="https://neuralink.com/">Neuralink</a></p></figcaption></figure><p>Brain-computer interfaces present a monumental scientific and engineering
challenge, and brain-to-brain, a whole other category of difficulty.</p><p>First, we have no idea how information is encoded in the brain. That needs
to be understood. Second, even assuming we’re able to take a perfect
snapshot of a piece of information in someone’s brain—for example, how a
particular movie scene makes them feel—we still need to be able to encode
it in a way that includes the full context of their subjective experiences.
Maybe the scene evokes unique memories of their childhood or is somehow
entangled with the smell of a particular cinema’s leather seats. Third, we
need to figure out how to safely write this perfect snapshot into someone
else’s brain in a way that can be perceived identically.</p><p>Which is to say, it’s a difficult problem. But a worthwhile one: imagine
having the capability to suddenly become aware of answers for questions you
just thought about. To expertly control <a href="https://youtu.be/PLk8Pm%5FXBJE?t=13">truly integrated</a> prosthetics giving
you superhuman abilities. To give movement to the paralized, sound to the
deaf, and sight to the blind.</p><p>What would be the impacts on society if we were able to communicate an
order of magnitude more effectively? What if <em>everyone</em> was equipped with
the same undisputed basic knowledge of history and science?</p><p>There are internal thoughts that we can attempt to describe with a thousand
words, but ultimately fail to capture in a way that’s precise, much less
comprehensible by someone else. Words and sentences are an incomplete
representation of our internal thoughts. In the same way that 3D objects
cast 2D shadows (<a href="https://www.youtube.com/watch?v=N0WjV6MmCyM">and 4D, 3D</a>) communicating through language doesn’t carry
all of our cultural and developmental context—transmitting all of that
along with every phrase would be impractical. Language is in this sense,
lossily compressed thought.</p><figure><img src="https://www.murilopereira.com/tesseract_shadow.jpg"></figure><p>Inert strings of words of ink and paper take a life of their own inside our
heads. It’s why the exact same information can be interpreted completely
differently by different people.</p><p>Before language, fire and cooking technology allowed us to reallocate
energy usage from the digestive system to the brain by outsourcing
digestion to outside of our bodies, making macronutrients more efficiently
absorbable. Almost all of a cooked meal is metabolized by the body, whereas
raw foods yield less than half of their nutrients.</p><p>Cooking is an extension of our digestive system, and enabled us to develop
large, calorie-hungry brains. It also gave us time to think: our primate
cousins spend half of their days chewing raw food to consume enough
calories to stay alive.</p><p>Brains can be seen as <em>survival machines</em>, locked inside dark skulls,
constantly building a model of the outside world by predicting and learning
through senses and memory. The biological human brain evolved to have the
necessary sophistication to not only expertly navigate and understand the
brute physical reality but also to construct <em>social</em> reality. Democracy,
religion, money: all made up by us, for us.</p><p>We remember the past so that we can predict the future, and by doing so, we
thrive.</p><p>We create technology, which functions as a non-biological extra layer to
our brains and bodies, augmenting, complementing, and sometimes replacing
our natural capabilities.</p><blockquote><p>The wheel… is an extension of the foot.</p><p>The book… is an extension of the eye…</p><p>Clothing, an extension of the skin…</p><p>Electric circuitry, an extension of the central nervous system.</p><p>—
<a href="https://en.wikipedia.org/wiki/Understanding_Media">Understanding Media: The Extensions of Man (1964)</a></p></blockquote><p>Relatively speaking, we are done evolving <em>biologically</em>. Further adaptations
and enhancements to our bodies and minds will come through technology.</p><figure><img src="https://www.murilopereira.com/brain_layers.jpg" alt="Figure 5: Check out &amp;ldquo;Neuralink and the Brain&amp;rsquo;s Magical Future&amp;rdquo; for a very entertaining primer on the brain."><figcaption><p>Figure 5: Check out “<a href="https://waitbutwhy.com/2017/04/neuralink.html">Neuralink and the Brain’s Magical Future</a>” for a very entertaining primer on the brain.</p></figcaption></figure><p>To be human is to have the ability to change the world around us. The shift
from hunting and gathering to farming allowed us to spend less energy to
acquire food while giving us a predictable calorie supply.</p><p>The resulting food surplus made it possible for populations to settle down
and grow quickly while supporting people not being directly involved in the
production of food—before agriculture that was everyone’s job. For one,
it allowed some to specialize and focus on developing better farming tools
and more resistant crops, starting a vicious cycle of improvement and
consumption that continues until today.</p><p>The transition from active foraging to a more sedentary lifestyle resulted
in worse health for the general population. The average farmer worked
harder than the average forager and got a worse diet in return. Our teeth,
bones and joints became more fragile, and we became afflicted by novel
diseases coming from newly domesticated animals, carriers of pathogens that
incubated in our new densely populated cities.</p><p>Owning land suddenly became really important. Agriculture and the concept
of private property reinforced each other and grew together, allowing us to
create value and secure the fruits of our labor. It also created the
circumstances for slavery to arise, and wars to be waged.</p><p>The groups of people growing the first crops could not have anticipated all
of the collateral effects of their breakthrough. They just wanted more
food.</p><p>If the past has taught us anything is that we have to be mindful of the
consequences of our progress. In an increasingly connected world, change is
often <a href="https://hbr.org/2017/05/linear-thinking-in-a-nonlinear-world">nonlinear</a> and unpredictable. Cars didn’t just replace horses—they
forever changed the entire outlook of every city. Did Tim Berners-Lee
anticipate his invention adding to forces pulling whole countries apart?</p><p>Our progress will continue to bring us previously unimaginable challenges.
Against an unknowable future, it doesn’t hurt to keep improving our
capabilities to adapt and, more difficultly, to cooperate—especially at
scale.</p><figure><img src="https://www.murilopereira.com/humanity.jpg" alt="Figure 6: &amp;ldquo;Humanity&amp;rdquo; by Pawel Kuczynski"><figcaption><p>Figure 6: “<a href="https://www.pictorem.com/24592/humanity.html">Humanity</a>” by Pawel Kuczynski</p></figcaption></figure><p>Computers are getting pretty good at driving cars—even in the most
difficult situations—and can already instantly diagnose some diseases
better than human doctors. Technology has a way to <a href="https://www.thenewatlantis.com/publications/understanding-heidegger-on-technology">reveal</a> the potential of
our environment, and ourselves. We have to be careful not to look at …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-why-of-technology/">https://www.murilopereira.com/the-why-of-technology/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-why-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26082257</guid>
            <pubDate>Tue, 09 Feb 2021 20:54:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl Supports Rustls]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26082231">thread link</a>) | @zdw
<br/>
February 9, 2021 | https://daniel.haxx.se/blog/2021/02/09/curl-supports-rustls/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/02/09/curl-supports-rustls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>curl is an internet transfer engine. A rather modular one too. Parts of curl’s functionality is provided by selectable alternative implementations that we call <em>backends</em>. You select what backends to enable at build-time and in many cases the backends are enabled and powered by different 3rd party libraries.</p>



<h2>Many backends</h2>



<p>curl has a range of such alternative backends for various features: </p>



<ol><li>International Domain Names</li><li>Name resolving</li><li>TLS</li><li>SSH</li><li>HTTP/3</li><li>HTTP content encoding</li><li>HTTP</li></ol>



<h2>Stable API and ABI</h2>



<p>Maintaining a stable API and ABI is key to libcurl. As long as those promises are kept, changing internals such as switching between backends is perfectly fine.</p>



<p>The API is the armored front door that we don’t change. The backends is the garden on the back of the house that we can dig up and replant every year if we want, without us having to change the front door.</p>



<h2>TLS backends</h2>



<p>Already back in 2005 we added support for using an alternative TLS library in curl when we added support for GnuTLS in addition to OpenSSL, and since then we’ve added many more.  We do this by having an internal API through which we do all the TLS related things and for each third party library we support we have code that does the necessary logic to connect the internal API with the corresponding TLS library.</p>



<h2>rustls</h2>



<p>Today, we merged support for yet another TLS library: <strong><a href="https://github.com/ctz/rustls">rustls</a></strong>. This is a TLS library written in rust and it has a C API provided in a separate project called <a href="https://github.com/abetterinternet/crustls/">crustls</a>. Strictly speaking, curl is built to use crustls.</p>



<p>This is still early days for the rustls backend and it is not yet feature complete. There’s more work to do and polish to apply before we can think of it as a proper competitor to the already established and well-used TLS backends, but with this merge it makes it much easier for more people to help out and test it out. Feel free and encouraged to join in!</p>



<p>We count this addition as the <strong>14th</strong> concurrently supported TLS library in curl. I’m not aware of any other project, anywhere, that supports more or even this many TLS libraries.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-09-curl-Project-status-dashboard.png"><img loading="lazy" width="2523" height="1419" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-09-curl-Project-status-dashboard.png" alt=""></a></figure>



<h2>rustls again!</h2>



<p>The TLS library named <a href="https://mesalink.io/">mesalink</a> is actually already using rustls, but under an OpenSSL API disguise and we support that since a few years back…</p>



<h2>Credits</h2>



<p>The TLS backend code for rustls was written and contributed by Jacob Hoffman-Andrews.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/02/09/curl-supports-rustls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26082231</guid>
            <pubDate>Tue, 09 Feb 2021 20:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I started a podcast about COSS companies and interviewed Heather Meeker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081959">thread link</a>) | @dabeeeenster
<br/>
February 9, 2021 | https://www.flagsmith.com/podcast/05-heather-meeker-oss-capital | <a href="https://web.archive.org/web/*/https://www.flagsmith.com/podcast/05-heather-meeker-oss-capital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="Interview with Heather Meeker: Founding Partner, OSS Capital" srcset="https://images.prismic.io/bullet-train/701718c3-c967-4582-9e7d-f326ca442943_Main+Banner_OSSC.png?auto=compress,format&amp;rect=0,0,1536,768&amp;w=1536&amp;h=768 1x, https://images.prismic.io/bullet-train/89597d47-5523-4768-b5eb-1187a2f603eb_Main+Banner_OSSC%402x.png?auto=compress,format&amp;rect=0,0,3072,1536&amp;w=3072&amp;h=1536 2x, https://images.prismic.io/bullet-train/c026f859-0bbc-4a62-9d4a-8b61db2caa8d_Main+Banner_OSSC%403x.png?auto=compress,format&amp;rect=0,0,4608,2304&amp;w=6144&amp;h=3072 4x"></p><p><span>Listen now</span><audio src="https://feeds.podetize.com/ep/dAfLeFRA2/media" controls=""></audio></p><h2>Episode Overview</h2><div><p>In this episode I spoke with Heather Meeker who is a founding partner at OSS Capital. Starting her career as a programmer and switching to law, Heather has been focused on software licensing for the last 25 years. She's worked with some of the most famous open source software companies and projects in the world and has an amazingly balanced view of the space and the role that licensing can/should and does play within the ecosystem. We were able to cover the history of open source, interpretations of different licenses and examples of projects/companies that are getting it right.</p><p>As we got deeper into the discussion, I asked Heather if there was a point where the licensing changed to enable the successful open source projects we see today. She had this to say which was an amazing point of view coming from someone with so much experience in the space:</p><p><em>The reason it was successful is that it was a great product. I don’t mean to be flippant but without that, the license wouldn’t have worked. It’s the license that serves the business and not vice versa.</em></p><p>If you are thinking about which license to use for your open source project or what makes the most sense for your business, you should definitely listen to this talk. </p><p>Enjoy!</p><p>-Ben</p></div><h2>Episode Transcript</h2><div><p><strong>Heather, thank you for your time. It's great to have you on. For the readers, do you want to give us a brief overview of who you are and why I'm talking to you?&nbsp;</strong></p><p>Thank you for having me on. I'm a lawyer and a venture capitalist, and in both of those roles I focus heavily on open source software. A bit of color about that: I've been a lawyer in Silicon Valley for about 25 years. Before that, I was once a computer programmer, and it was long ago that we called ourselves “computer programmers.” Everything I did professionally in computing is outdated now, but I've had fun learning from my clients over the years. As a lawyer, I am essentially a technology transactions lawyer, meaning that I do licensing and commercial deals. My specialty has always been software licensing, because software is interesting to me. A few years, I got involved in a venture capital fund, Open Source Software Capital, which focuses entirely on early-stage commercial open source companies. One of the reasons I did that was that my law practice had become more and more about advising people on business strategy around open source. That is inextricably bound up with licensing strategy. It was a more natural move than you might expect for a lawyer-type like me. Now those things are dovetailing nicely. I spent a lot of time talking to small companies about how to set their business and licensing strategy.&nbsp;</p><p><strong>I remember the first time I heard the phrase or came into contact with open source software was a CD on the front of a magazine in 1995. It was a copy of Slack for Linux. I remember me and my friends were spending days and days trying to get it up and running. It meant that we could stop programming because we had Sonos terminal at the time at the university. It meant that we could start coding at home instead of having to go and see the university. When did you first hear the phrase?&nbsp;</strong></p><p>It probably was around that time, 1995, 1996. At that time, I had been a lawyer for a brief amount of time and my clients were asking me about the software. They asked, “Can we use this software under this license?” They were referring to various licenses, a lot of them permissive, like MIT licenses and so forth, but also licenses like GPL and LGPL, which nobody in the legal community understood at the time. At that time, I was boots on the ground in terms of clients saying, “Can we do this? Can we use this?” It was free and they wanted to use it. The general attitude of lawyers at that time was like when your mother says, “Don't put that in your mouth, you don't know where it's been.”&nbsp;</p><p>They considered open source dangerous, but the reason they considered it dangerous was it didn't come from a commercial vendor. It could have infringement issues and so forth. Most of the lawyers at that time were saying, “No, you can't use that.” I realized quickly, because I was the one that they were asking every day, that was the wrong answer. It had to be, “Yes, but,” instead of “No.” I thought, I need to figure out what is that condition, “Yes, but if you do this, you can use it.” There was nobody in the law trying to figure that out from that perspective at that time. I looked around and there wasn't any information about it. There's a lot of philosophy about open source. There wasn't much that was for somebody who was making this decision on a practical level day to day on behalf of a private enterprise.&nbsp;</p><p>I started developing those things myself and trying to learn more and more about it. The rule of being in an organization is that if you know 10% more than the person in the next room, you're the expert. People kept asking me about this stuff and I kept trying to answer the best I could, with little to go on. More people asked me questions and I learned more, and gave more answers, and it kept snowballing. I thought, “This will go away. It will be the flavor of the month.” It never went away. After the internet bust in around 2000, 2001, it took off. That's when I decided that this was going to be my area. This is what I'm going to do with my legal career.&nbsp;</p><p><strong>You didn't have that light bulb moment when you came into contact with it in ‘95 or ‘96 that like, “This is going to change the world.” I didn’t. I thought it was great that someone was giving this operating system away for free, but I remember I discovered the web around the same time. It's within a minute of using Mosaic that you knew the world was never going to be the same.&nbsp;</strong></p><p>I don't think many people realized it. The reason was that at that time, open source was considered a hobbyist thing. People could not have foreseen how widely accepted it would become, much less becoming the entire backbone of the internet, which everybody perceived immediately was going to change the world. It was the internet bust that caused it to skyrocket, because people were casting around desperately to save money. All of these big companies that otherwise never would have considered Linux seriously, all of a sudden they started saying, “We're going to throw our hats in the ring here.” That in itself was the amazing thing to me. It got people to collaborate in a way that they had never collaborated before. That was the sea change. Businesses started saying, “We can collaborate with our worst competitors on this infrastructure stuff.” That was what changed things for me.&nbsp;</p><p><strong>I was working around that time. I was an engineer. I remember hearing how much people or my clients were paying 6, 7 digits for software that you wouldn't dream of paying anything for nowadays. What were the risks for someone who's not legally minded? What was the thing that was frightening people at that time? What's the worst case?&nbsp;</strong></p><p>First, beyond any real risk, people just didn't understand the licenses. People don't like things they don't understand. Not understanding things is risk. Let's lay that aside, because that's irrational. The real risk that they were worried about from a legal point of view was that the software would be infringing, and that can happen one of two ways. One way is that somebody took something they didn't have the right to use and put it in the software. In legal terms, that would be either copyright infringement or trade secret misappropriation, depending on how they did it and how much they copied and so forth. The other risk is quite different, and that's patent infringement. That can happen even if you don't improperly take something else.&nbsp;</p><p>For years and years, people had been buying software from commercial vendors who gave them some comfort in the form of an indemnity. If the software was infringing, that vendor would take care of that problem for them. With open source, you usually don't have that. There are some vendors now who offer indemnities, but at the time there was no such thing at all. People were concerned that if they used software and it was infringing, then they would be flapping out in the wind and there would be no vendor to help them.&nbsp;</p></div><div><blockquote>“<!-- -->They asked, “Can we use this software under this license?” They were referring to various licenses, a lot of them permissive like MIT licenses and so forth, but also licenses GPL and LGPL which nobody in the legal community understood at the time. <!-- -->”</blockquote></div><div><p><strong>It's where the buck stops if there's a problem. Talk a bit about the history of that. Which side was driving that? Was it the commercial side of the internet driving the changing in feelings and the licensing around that, or was it the other way around?</strong></p><p>What changed it was that people decided they needed something inexpensive enough that they were willing to bear the risk. At the same time, commercial vendors, like famously Microsoft, although they had changed their tune by now, they were creating what people call FUD -- Fear, Uncertainty, and Doubt -- about these issues because they were competing with Linux. If I can make an aside, it’s interesting that at the time, Windows was so dominant that the only thing that could have competed with it was not a commercial product. All of a sudden, they had this competition and they were trying to throw shade on it. They caused people to change the way they've thought about it. Interestingly, a lot of lawyers still have these ideas in their mind that come from that time and the FUD that Microsoft created. We even see provisions in documents that came from that time. They were effective in causing people to be concerned about it because they were competing.&nbsp;</p><p><strong>That was several years ago. I remember that time well.&nbsp;</strong></p><p>Lawyers are slow to change. What they do is they go, “I know about this risk. I have to identify it. That's my job.” It's difficult to get them to stop when the risk is no longer significant anymore.&nbsp;</p><p><strong>One of the things I've noticed when I've …</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.flagsmith.com/podcast/05-heather-meeker-oss-capital">https://www.flagsmith.com/podcast/05-heather-meeker-oss-capital</a></em></p>]]>
            </description>
            <link>https://www.flagsmith.com/podcast/05-heather-meeker-oss-capital</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081959</guid>
            <pubDate>Tue, 09 Feb 2021 20:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python behind the scenes #8: how Python integers work]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26081919">thread link</a>) | @rbanffy
<br/>
February 9, 2021 | https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>In the previous parts of this series we studied the core of the CPython interpreter and saw how the most fundamental aspects of Python are implemented. We made an overview of <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">the CPython VM</a>, took a look at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">the CPython compiler</a>, stepped through <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">the CPython source code</a>, studied <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">how the VM executes the bytecode</a> and learned <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">how variables work</a>. In the two most recent posts we focused on <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">the Python object system</a>. We learned what Python objects and Python types are, how they are defined and what determines their behavior. This discussion gave us a good understanding of how Python objects work in general. What we haven't discussed is how particular objects, such as strings, integers and lists, are implemented. In this and several upcoming posts we'll cover the implementations of the most important and most interesting built-in types. The subject of today's post is <code>int</code>.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Why Python integers are interesting</h2>
<p>Integers require no introduction. They are so ubiquitous and seem so basic that you may doubt whether it's worth discussing how they are implemented at all. Yet, Python integers are interesting because they are not just 32-bit or 64-bit integers that CPUs work with natively. Python integers are <a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic">arbitrary-precision integers</a>, also known as bignums. This means that they can be as large as we want, and their sizes are only limited by the amount of available memory.</p>
<p>Bignums are handy to work with because we don't need to worry about such things as integer overflows and underflows. They are extensively used in fields like cryptography and computer algebra where large numbers arise all the time and must be represented precisely. So, <a href="https://en.wikipedia.org/wiki/List_of_arbitrary-precision_arithmetic_software">many</a> programming languages have bignums built-in. These include Python, JavaScript, Ruby, Haskell, Erlang, Julia, Racket. Others provide bignums as a part of the standard library. These include Go, Java, C#, D, PHP. Numerous third-party libraries implement bignums. The most popular one is <a href="https://en.wikipedia.org/wiki/GNU_Multiple_Precision_Arithmetic_Library">the GNU Multiple Precision Arithmetic Library</a> (GMP). It provides a C API but has bindings for all major languages.</p>
<p>There are a lot of bignum implementations. They're different in detail, but the general approach to implement bignums is the same. Today we'll see what this approach looks like and use CPython's implementation as a reference example. The two main questions we'll have to answer are:</p>
<ul>
<li>how to represent bignums; and</li>
<li>how to performs arithmetic operations, such as addition and multiplication, on bignums.</li>
</ul>
<p>We'll also discuss how CPython's implementation compares to others and what CPython does to make integers more efficient. </p>
<h2>Bignum representation</h2>
<p>Think for a moment how you would represent large integers in your program if you were to implement them yourself. Probably the most obvious way to do that is to store an integer as a sequence of digits, just like we usually write down numbers. For example, the integer <code>51090942171709440000</code> could be represented as <code>[5, 1, 0, 9, 0, 9, 4, 2, 1, 7, 1, 7, 0, 9, 4, 4, 0, 0, 0, 0]</code>. This is essentially how bignums are represented in practice. The only important difference is that instead of base 10, much larger bases are used. For example, CPython uses base 2^15 or base 2^30 depending on the platform. What's wrong with base 10? If we represent each digit in a sequence with a single byte but use only 10 out of 256 possible values, it would be very memory-inefficient. We could solve this memory-efficiency problem if we use base 256, so that each digit takes a value between 0 and 255. But still much larger bases are used in practice. The reason for that is because larger base means that numbers have less digits, and the less digits numbers have, the faster arithmetic operations are performed. The base cannot be arbitrary large. It's typically limited by the size of the integers that the CPU can work with. We'll see why this is the case when we discuss bignum arithmetic in the next section. Now let's take a look at how CPython represents bignums.</p>
<p>Everything related to the representation of Python integers can be found in <a href="https://github.com/python/cpython/blob/3.9/Include/longintrepr.h"><code>Include/longintrepr.h</code></a>. Technically, Python integers are instances of <code>PyLongObject</code>, which is defined in <a href="https://github.com/python/cpython/blob/3.9/Include/longobject.h"><code>Include/longobject.h</code></a>, but <code>PyLongObject</code> is actually a typedef for <code>struct _longobject</code> that is defined in <code>Include/longintrepr.h</code>:</p>
<div><pre><span></span><span>struct</span> <span>_longobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>digit</span> <span>ob_digit</span><span>[</span><span>1</span><span>];</span>
<span>};</span>
</pre></div>


<p>This struct extends <a href="https://docs.python.org/3/c-api/structures.html#c.PyVarObject"><code>PyVarObject</code></a>, which in turn extends <a href="https://docs.python.org/3/c-api/structures.html#c.PyObject"><code>PyObject</code></a>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>So, besides a reference count and a type that all Python objects have, an integer object has two other members: </p>
<ul>
<li><code>ob_size</code> that comes from <code>PyVarObject</code>; and </li>
<li><code>ob_digit</code> that is defined in <code>struct _longobject</code>.</li>
</ul>
<p>The <code>ob_digit</code> member is a pointer to an array of digits. On 64-bit platforms, each digit is a 30-bit integer that takes values between 0 and 2^30-1 and is stored as an unsigned 32-bit int (<code>digit</code> is a typedef for <code>uint32_t</code>). On 32-bit platforms, each digit is a 15-bit integer that takes values between 0 and 2^15-1 and is stored as an unsigned 16-bit int (<code>digit</code> is a typedef for <code>unsigned short</code>). To make things concrete, in this post we'll assume that digits are 30 bits long.</p>
<p>The <code>ob_size</code> member is a signed int, whose absolute value tells us the number of digits in the <code>ob_digit</code> array. The sign of <code>ob_size</code> indicates the sign of the integer. Negative <code>ob_size</code> means that the integer is negative. If <code>ob_size</code> is 0, then the integer is 0.</p>
<p>Digits are stored in a little-endian order. The first digit (<code>ob_digit[0]</code>) is the least significant, and the last digit (<code>ob_digit[abs(ob_size)-1]</code>) is the most significant.</p>
<p>Finally, the absolute value of an integer is calculated as follows: </p>
<p>$$val = ob\_digit[0] \times (2 ^{30})^0 + ob\_digit[1] \times (2 ^{30})^1 + \cdots + ob\_digit[|ob\_size| - 1] \times (2 ^{30})^{|ob\_size| - 1}$$</p>
<p>Let's see what all of this means with an example. Suppose we have an integer object that has <code>ob_digit = [3, 5, 1]</code> and <code>ob_size = -3</code>. To compute its value, we can do the following:</p>
<div><pre><span></span><span>$ python -q</span>
<span>&gt;&gt;&gt; </span><span>base</span> <span>=</span> <span>2</span><span>**</span><span>30</span>
<span>&gt;&gt;&gt; </span><span>-</span><span>(</span><span>3</span> <span>*</span> <span>base</span><span>**</span><span>0</span> <span>+</span> <span>5</span> <span>*</span> <span>base</span><span>**</span><span>1</span> <span>+</span> <span>1</span> <span>*</span> <span>base</span><span>**</span><span>2</span><span>)</span>
<span>-1152921509975556099</span>
</pre></div>


<p>Now let's do the reverse. Suppose we want to get the bignum representation of the number <code>51090942171709440000</code>. Here's how we can do that:</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>x</span> <span>=</span> <span>51090942171709440000</span>
<span>&gt;&gt;&gt; </span><span>x</span> <span>%</span> <span>base</span>
<span>952369152</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>337507546</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>44</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>0</span>
</pre></div>


<p>So, <code>ob_digit = [952369152, 337507546, 44]</code> and <code>ob_size = 3</code>. Actually, we don't even have to compute the digits, we can get them by inspecting the integer object using the <a href="https://docs.python.org/3/library/ctypes.html#module-ctypes"><code>ctypes</code></a> standard library:</p>
<div><pre><span></span><span>import</span> <span>ctypes</span>


<span>MAX_DIGITS</span> <span>=</span> <span>1000</span>

<span># This is a class to map a C `PyLongObject` struct to a Python object</span>
<span>class</span> <span>PyLongObject</span><span>(</span><span>ctypes</span><span>.</span><span>Structure</span><span>):</span>
    <span>_fields_</span> <span>=</span> <span>[</span>
        <span>(</span><span>"ob_refcnt"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_ssize_t</span><span>),</span>
        <span>(</span><span>"ob_type"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_void_p</span><span>),</span>
        <span>(</span><span>"ob_size"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_ssize_t</span><span>),</span>
        <span>(</span><span>"ob_digit"</span><span>,</span> <span>MAX_DIGITS</span> <span>*</span> <span>ctypes</span><span>.</span><span>c_uint32</span><span>)</span>
    <span>]</span>


<span>def</span> <span>get_digits</span><span>(</span><span>num</span><span>):</span>
    <span>obj</span> <span>=</span> <span>PyLongObject</span><span>.</span><span>from_address</span><span>(</span><span>id</span><span>(</span><span>num</span><span>))</span>
    <span>digits_len</span> <span>=</span> <span>abs</span><span>(</span><span>obj</span><span>.</span><span>ob_size</span><span>)</span>
    <span>return</span> <span>obj</span><span>.</span><span>ob_digit</span><span>[:</span><span>digits_len</span><span>]</span>
</pre></div>


<div><pre><span></span><span>&gt;&gt;&gt; </span><span>from</span> <span>num_digits</span> <span>import</span> <span>get_digits</span>
<span>&gt;&gt;&gt; </span><span>x</span> <span>=</span> <span>51090942171709440000</span>
<span>&gt;&gt;&gt; </span><span>get_digits</span><span>(</span><span>x</span><span>)</span>
<span>[952369152, 337507546, 44]</span>
</pre></div>


<p>As you might guess, the representation of bignums is an easy part. The main challenge is to implement arithmetic operations and to implement them efficiently.</p>
<h2>Bignum arithmetic</h2>
<p>We learned in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">part 6</a> that the behavior of a Python object is determined by the object's type. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. So, to understand how CPython performs arithmetic operations on integers, we need to study the slots of the <code>int</code> type that implement those operations.</p>
<p>In the C code, the <code>int</code> type is called <code>PyLong_Type</code>. It's defined in <code>Objects/longobject.c</code> as follows:</p>
<div><pre><span></span><span>PyTypeObject</span> <span>PyLong_Type</span> <span>=</span> <span>{</span>
    <span>PyVarObject_HEAD_INIT</span><span>(</span><span>&amp;</span><span>PyType_Type</span><span>,</span> <span>0</span><span>)</span>
    <span>"int"</span><span>,</span>                                      <span>/* tp_name */</span>
    <span>offsetof</span><span>(</span><span>PyLongObject</span><span>,</span> <span>ob_digit</span><span>),</span>           <span>/* tp_basicsize */</span>
    <span>sizeof</span><span>(</span><span>digit</span><span>),</span>                              <span>/* tp_itemsize */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_dealloc */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_vectorcall_offset */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_getattr */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_setattr */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_async */</span>
    <span>long_to_decimal_string</span><span>,</span>                     <span>/* tp_repr */</span>
    <span>&amp;</span><span>long_as_number</span><span>,</span>                            <span>/* tp_as_number */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_sequence */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_mapping */</span>
    <span>(</span><span>hashfunc</span><span>)</span><span>long_hash</span><span>,</span>                        <span>/* tp_hash */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_call */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_str */</span>
    <span>PyObject_GenericGetAttr</span><span>,</span>                    <span>/* tp_getattro */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_setattro */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_buffer */</span>
    <span>Py_TPFLAGS_DEFAULT</span> <span>|</span> <span>Py_TPFLAGS_BASETYPE</span> <span>|</span>
        <span>Py_TPFLAGS_LONG_SUBCLASS</span><span>,</span>               <span>/* tp_flags */</span>
    <span>long_doc</span><span>,</span>                                   <span>/* tp_doc */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_traverse */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_clear */</span>
    <span>long_richcompare</span><span>,</span>                           <span>/* tp_richcompare */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_weaklistoffset */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_iter */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_iternext */</span>
    <span>long_methods</span><span>,</span>                               <span>/* tp_methods */</span>
    <span>0</span><span>,</span>                                          <span>/* …</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/">https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081919</guid>
            <pubDate>Tue, 09 Feb 2021 20:14:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A First-Amendment Case for Freedom from the Woke Religion (James Lindsay)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081902">thread link</a>) | @Fellshard
<br/>
February 9, 2021 | https://newdiscourses.com/2020/09/first-amendment-case-freedom-from-woke-religion/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/09/first-amendment-case-freedom-from-woke-religion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p><i>[R]eligion can be defined as a comprehensive belief system that addresses the fundamental questions of human existence, such as the meaning of life and death, man’s role in the universe, and the nature of good and evil, and that gives rise to duties of conscience. –Ben Clements, Cornell Law Review, 1989</i></p>
<p><a name="TOC"></a> <b>Contents</b></p>
<ul>
<li>
<p><a href="#Introduction">Introduction</a></p>
</li>
<li>
<p><a href="#Part I">Part I – The Philosophical Argument</a></p>
<ul>
<li>
<p><a href="#Sociology">Sociology</a></p>
</li>
<li>
<p><a href="#Liturgy">Liturgical Form</a></p>
</li>
<li>
<p><a href="#MandM">Mythological Construction</a></p>
</li>
<li>
<p><a href="#Metap">Metaphysics of Hegemony</a></p>
</li>
<li>
<p><a href="#MetapD">Metaphysics of Discourse</a></p>
</li>
<li>
<p><a href="#CrossingStreams">Crossing the Metaphysical Streams</a></p>
</li>
<li>
<p><a href="#MoralLaw">Moral Law</a></p>
</li>
<li>
<p><a href="#Epistles">Holy and Administrative Epistles</a></p>
</li>
<li>
<p><a href="#Fundies">A Note on Fundamentalism</a></p>
</li>
<li>
<p><a href="#Puritan">Puritan Fragility</a></p>
</li>
<li>
<p><a href="#Churches">A Note about Churches and Religions</a></p>
</li>
<li>
<p><a href="#Summary1">Summary</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#Part II">Part II – The Legal Argument</a></p>
<ul>
<li>
<p><a href="#NeedDef">The Need for a Definition</a></p>
</li>
<li>
<p><a href="#WhatGod">What About God?</a></p>
</li>
<li>
<p><a href="#DualD">A Dual Definition?</a></p>
</li>
<li>
<p><a href="#SupremeB">A Supreme Being</a></p>
</li>
<li>
<p><a href="#Ultimate">Ultimate Concerns</a></p>
</li>
<li>
<p><a href="#Unfalsifiable">Unfalsifiable Beliefs</a></p>
</li>
<li>
<p><a href="#TransNum">The Transcendent Numinous</a></p>
</li>
<li>
<p><a href="#Ducks">If It Walks Like a Church and Talks Like a Church</a></p>
</li>
<li>
<p><a href="#Sincerity">Sincerity of Belief</a></p>
</li>
<li>
<p><a href="#FundyQuest">Fundamental Questions</a></p>
</li>
<li>
<p><a href="#Marx">The Hiccup of Marxism</a></p>
</li>
<li>
<p><a href="#Duties">Duties of Conscience</a></p>
</li>
<li>
<p><a href="#QED">A Functional Definition of Religion (QED)</a></p>
</li>
<li>
<p><a href="#But">But Can It Be Believed?</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#Conclusion">Conclusion – What Now?</a></p>
</li>
</ul>
<h3 id="introduction"><a name="Introduction"></a> Introduction</h3>
<p>The question of whether or not the worldview and practice—for <i>practice</i> it intentionally is—going variously by the names “<a href="https://newdiscourses.com/tftw-social-justice/">Social Justice</a>,” “<a href="https://newdiscourses.com/2020/02/naming-enemy-critical-social-justice/">Critical Social Justice</a>,” or, more colloquially, “<a href="https://newdiscourses.com/tftw-woke-wokeness/">Woke</a>” constitutes a religion is one of some general interest that seems to be growing. Until quite recently, we maintained the luxury of not having to treat the matter more deeply than as something of a curio of sociocultural philosophy, however important the issue may be. I have contended, for example, that Critical Social Justice constitutes a religion of sorts (a <i>postmodern one</i>, as I <a href="https://newdiscourses.com/2020/06/postmodern-religion-faith-social-justice/">laid it out</a> at considerable length; a nominally “<a href="https://newdiscourses.com/tftw-antiracism/"><i>anti-racist</i></a>” one, as Columbia University professor John McWhorter is <a href="https://www.thedailybeast.com/antiracism-our-flawed-new-religion" target="_blank" rel="noopener noreferrer">tackling</a> it currently, at book length) and must be thought of as such, at least by everyday citizens—though not by the law. Those were simpler times.</p>
<p>Now things are quite different and much more serious, so a much more serious inquiry is demanded of us. This escalation arrives not so much due to the externally obvious reasons like how profoundly parallel to religion Critical Social Justice and its practice have become—literally washing black people’s feet in the streets through tearful apologies against whiteness—but more because of its rapid and seemingly unstoppable penetration into our public institutions, including government at every level and, more importantly, our public schools.</p>
<p>It is nearly always a question of considerable importance and some urgency when an ideology, especially when it comprises a totalizing worldview, decides that it is to be the fundamental basis for how we organize society and educate our children, to say nothing of other legal concerns. This, to be certain, is happening now with astonishing rapidity. The overwhelming majority of our schools systems’ teacher training over the summer of 2020, to prepare teachers for the new mostly-online educational demands for the coming fall term, have been heavily, if not exclusively, about issues pertinent to Critical Social Justice. Our government agencies at all levels are taking on the basic principles and tenets of this belief system as matters of both policy and recommendation.</p>
<p>With astonishing speed, a shocking number of our nation’s school systems have taken up explicitly <a href="https://newdiscourses.com/tftw-critical/">critical</a>—as in <a href="https://newdiscourses.com/tftw-critical-theory/">Critical Theory</a>—<a href="https://newdiscourses.com/tftw-critical-pedagogy/">educational approaches</a> that focus on teaching <a href="https://newdiscourses.com/tftw-identity-politics/">identity politics</a>, “<a href="https://newdiscourses.com/tftw-antiracism/">anti-racism</a>,” and about the <a href="https://newdiscourses.com/tftw-power-systemic/">systems of power</a> that the Critical Social Justice worldview <a href="https://newdiscourses.com/2020/01/influence-anti-racist-scholarship-activism-evergreen-college/">assumes</a> exists in everything. States like <a href="https://www.seattletimes.com/education-lab/free-feminine-hygiene-products-in-schools-early-ethnic-studies-on-washington-state-legislative-wish-list-for-2020/" target="_blank" rel="noopener noreferrer">Washington</a>, <a href="https://edsource.org/2020/new-draft-ethnic-studies-curriculum-for-california-students-issued-after-a-year-of-study/637506" target="_blank" rel="noopener noreferrer">California</a>, and <a href="http://www.nysed.gov/bilingual-ed/culturally-responsive-sustaining-education-framework" target="_blank" rel="noopener noreferrer">New York</a> are openly adopting “Ethnic Studies” programs that revamp their entire educational systems in line with Critical Social Justice so extreme that they seek to replace math with “<a href="https://www.edweek.org/ew/articles/2019/10/11/seattle-schools-lead-controversial-push-to-rehumanize.html" target="_blank" rel="noopener noreferrer">ethnomathematics</a>” and history with critical “hxstory.” These changes come alongside other equally questionable practices with even more jargon-heavy descriptions, all dedicated to awakening a “<a href="https://newdiscourses.com/tftw-critical-consciousness/">critical consciousness</a>” of “<a href="https://newdiscourses.com/tftw-antiracism/">anti-racism</a>” through “cultural awareness” in our nation’s children. Our curricula, we’re told, have to be “<a href="https://link.springer.com/epdf/10.1007/s12129-020-09899-2?sharing_token=QkTk_96aBmLzTIpYfqE8ofe4RwlQNchNByi7wbcMAY5ccP1G-tw-JzDXMsIXpR0f0Y4rNLFgSAa0KYeeP1aaFVQ8HMjWnRTD0mHYY1gOKUcbE09-xzMpT4tlJ5mtTAbjIkhtAiPpw166JZGnapIh1paO0lxQItuZwe2Pq9L2OSk%3D" target="_blank" rel="noopener noreferrer">decolonized</a>.” New curricula are explicitly based not only in <a href="https://newdiscourses.com/tftw-critical-theory/">Critical Theories</a> of <a href="https://newdiscourses.com/tftw-identity-politics/">identity</a>, but upon the critical historiography of the infamously <a href="https://newdiscourses.com/2020/07/history-killers-academic-fraudulence-1619-project/">revisionist</a> (and Pulitzer Prize-winning) <a href="https://newdiscourses.com/tftw-1619-project/">1619 Project</a> and the <a href="https://drive.google.com/drive/mobile/folders/1LGslwJwhXvpVnDgw0uC-n794l6EGzpuH" target="_blank" rel="noopener noreferrer">explicit dictates</a> of the radical Black-power activism organization <a href="https://blacklivesmatter.com/what-we-believe/" target="_blank" rel="noopener noreferrer">Black Lives Matter</a>.</p>
<p>Meanwhile, a veritable war is going on regarding whether or not assessment (like standardized testing) is “<a href="https://newdiscourses.com/tftw-racism-systemic/">racist</a>,” and excellence programs are being scrapped for being “<a href="https://newdiscourses.com/tftw-equity/">inequitable</a>.” As parents react to this (often very negatively) by seeking to pull their kids out of our public schools in favor of homeschooling them, calls to abolish homeschooling are coming to the fore of the discussion from the priestly of this new faith, insisting that it is “racist” to teach one’s own children at home because the state has a duty to teach them subjects like “Social Justice.” These changes should facilitate the elimination of objective standards that will enable an increase in the ability to execute and hide rampant problems of applying discriminatory admissions policies at elite schools and universities, all in the name of “equity,” which people are led to believe is a hallmark of<i> group </i>fairness.</p>
<p>Simultaneously, many of our government agencies and departments are taking on the tenets of Critical Social Justice, especially Critical Race Theory and its derivative, “anti-racism,” as a matter of mandate. These entities include state and federal “departments of” as well as myriad government contractors and state funded entities, like National Public Radio (NPR). Even NASA, which is widely regarded as synonymous with scientific rigor, hosted “anti-racist” historian Ibram X. Kendi to <a href="https://disrn.com/news/nasa-asks-far-left-antiracism-professor-ibram-x-kendi-to-speak-to-employees" target="_blank" rel="noopener noreferrer">lecture</a> its employees on tenets of this Theoretical view of the world. This invitation is remarkable given that Kendi’s <a href="https://www.politico.com/interactives/2019/how-to-fix-politics-in-america/inequality/pass-an-anti-racist-constitutional-amendment/" target="_blank" rel="noopener noreferrer">explicit ambition</a> is to pass an “anti-racist” Constitutional amendment that would permanently create and empower a <i>de facto</i> fourth branch of the American government dedicated to <a href="https://newdiscourses.com/tftw-critical/">critically</a> examining and unmaking any “racist” policy, defined as anything that ends up having certain (but not other) disparate outcomes by race. This invitation is even less alarming than the fact that Kendi’s argument is being used in support of a California initiative to remove the anti-discrimination language from its state constitution in accordance with achieving equity and “anti-racism.” Equally, if not more alarming, are that the Center for Disease Control has <a href="https://www.cdc.gov/coronavirus/2019-ncov/community/health-equity/race-ethnicity.html" target="_blank" rel="noopener noreferrer">institutionalized</a> tremendous <span>quantities</span> of this Theory (during a pandemic, no less), even while states officially declare “systemic racism” a kind of “public health crisis” that obviates any reasonable measures for pandemic mitigation if done in the name of “racial justice.” Even large government contractors, like Sandia Laboratories, which handles extremely high-tech weaponry (including nuclear weaponry), have taken on this ideology deeply enough to have fallen into an internal “<a href="https://twitter.com/realchrisrufo/status/1299008750729097216" target="_blank" rel="noopener noreferrer">civil war</a>” after a brave employee blew the whistle.</p>
<p>The matter of understanding Critical Social Justice, as the ideology is formally called, is, in some sense, no longer a mere philosophical issue (if it ever truly was). It’s now an emergency, and as more and more people are noticing (or, it seems, hoping, as it would provide them with recourse that currently seems not to exist), it’s likely to be a <i>legal</i> emergency. Unfortunately, very little legal architecture currently exists to do anything about the problem of this imposition of one particular belief system upon society via its most susceptible demographic—children. Further, perhaps due to failures of people like myself in the past few years, there has been very little push to generate this legal architecture in what is likely to be one of its strongest and most fruitful directions: identifying the Critical Social Justice worldview as a <i>functionally religious</i> worldview. This is required to open it up to the full machinery of the First Amendment to the United States Constitution and its famous Establishment Clause, and would, at least, get it out of our school systems very quickly.</p>
<p>The argument, I think, needs to be opened up in earnest because we now face two incredible perils against the American ideal where it collides with the Critical Social Justice worldview, and these merit taking the issue and the risk that comes with it (legally<i> protecting</i> Critical Social Justice as a system of faith)<i> </i>very seriously. The first of these is the one I’ve already spent some time on pointing out: Critical Social Justice has already encroached deeply into our public education system and halls of government in the United States. In fact, this trend is accelerating to a pitch so extreme that complaints that schools are operating in the service of political indoctrination rather than as houses of a basic and liberal education, as they were initially conceived, are rapidly becoming plausible. The second is that a time may come in the not-distant future in which this totalizing and totalitarian worldview could be installed as the de facto state religion, even while it elides categorization as such. The state endorsement—or worse, enforcement—of any faith falls directly afoul of the protections the U.S. Constitution was written to ensure to individual citizens, and, in fact, to other systems of faith that would disagree with it. The question is, which totalizing worldviews that are not traditionally recognizable as faiths should be treated in the same way for the same reasons? While the answer to this question is not immediately clear, it must have to do with how they function in society and in the lives of those who believe them.</p>
<p>Therefore, to put it directly: It is my belief that the contents of the Critical Social Justice worldview should be protected as matters of private conscience only, and they …</p></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newdiscourses.com/2020/09/first-amendment-case-freedom-from-woke-religion/">https://newdiscourses.com/2020/09/first-amendment-case-freedom-from-woke-religion/</a></em></p>]]>
            </description>
            <link>https://newdiscourses.com/2020/09/first-amendment-case-freedom-from-woke-religion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081902</guid>
            <pubDate>Tue, 09 Feb 2021 20:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tom Hanks’ Covid-19 Diagnosis Likely Shaped Public Attitude Toward Virus]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081832">thread link</a>) | @TheWellerman
<br/>
February 9, 2021 | https://thedebrief.org/tom-hanks-covid-19-diagnosis-likely-shaped-public-attitude-toward-virus-says-research/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/tom-hanks-covid-19-diagnosis-likely-shaped-public-attitude-toward-virus-says-research/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Recently published </span><a href="https://www.tandfonline.com/doi/full/10.1080/10410236.2020.1871169"><span>research</span></a><span> found that when actor Tom Hanks announced his COVID-19 diagnosis on March 11, 2020, it likely had a significant effect on the public’s attitude toward the deadly pandemic.&nbsp;</span></p>
<p><span>A day after Hanks </span><a href="https://twitter.com/tomhanks/status/1237909897020207104?s=20"><span>announced</span></a><span> on social media that he and his wife Rita Wilson had contracted the Coronavirus, Dr. Jessica Myrick of Penn State University and Dr. Jessica Willoughby of Washington State University surveyed 682 people about their attitudes and behaviors toward COVID-19.&nbsp;</span></p>
<p><span>The pair of researchers say 83% of persons surveyed had heard of Hanks’ diagnosis, and approximately half of that group said the news had changed their attitudes and behaviors towards COVID-19. Results of the study were published in the </span><a href="https://www.tandfonline.com/doi/full/10.1080/10410236.2020.1871169"><span>journal of Health Communication</span></a><span>.&nbsp;&nbsp;</span></p>
<p><span>“There is a growing body of research about how celebrity behavior and social media posts can affect public health,” said Dr. Myrick in a </span><a href="https://news.psu.edu/story/646649/2021/02/04/research/tom-hanks-covid-19-diagnosis-likely-shaped-behaviors-thoughts"><span>statement </span></a><span>issued by Penn State. “This suggests that public health officials and advocates may want to use these types of celebrity announcements to help reach people who may be harder to reach.”</span></p>

<figure id="attachment_3143" aria-describedby="caption-attachment-3143"><img src="https://thedebrief.org/wp-content/uploads/2021/02/860x394.jpg" alt="Tom Hanks COVID-19 diagnosis " width="860" height="394" srcset="https://thedebrief.org/wp-content/uploads/2021/02/860x394.jpg 860w,https://thedebrief.org/wp-content/uploads/2021/02/860x394-300x137.jpg 300w,https://thedebrief.org/wp-content/uploads/2021/02/860x394-768x352.jpg 768w,https://thedebrief.org/wp-content/uploads/2021/02/860x394-770x353.jpg 770w" sizes="(max-width: 860px) 100vw, 860px"><figcaption id="caption-attachment-3143">Tom Hanks at the 2017 People’s Choice Awards at The Microsoft Theatre, L.A. Live, Los Angeles. (Image Source: Stock image)</figcaption></figure>
<p><span>Staring in a slew of blockbuster movies, such as <em>Forrest Gump</em>, <em>Toy Story</em>,<em> Saving Private Ryan</em>, and <em>Captain Phillips</em>, Hanks is one of the world’s most popular and well-known film stars.&nbsp;</span></p>
<p><span>News of Hanks coming down with COVID last spring was further spread when a photo showing Hanks, apparently in a hospital room, holding a volleyball identical to the ball his character befriends and names Wilson in the 2000 film <em>Cast Away</em> went viral online. A caption accompanying the image claimed hospital staff had given Hanks the volleyball to keep him company during his quarantine.&nbsp;</span></p>
<p><span>Indeed a heartwarming story, Hanks’ photo holding the volleyball was a </span><a href="https://factcheck.afp.com/doctored-image-contains-2015-photo-tom-hanks-and-ball-movie-cast-away"><span>doctored image</span></a><span>, and the story was false. The account had initially appeared on the satire news site, </span><a href="https://factcheck.afp.com/doctored-image-contains-2015-photo-tom-hanks-and-ball-movie-cast-away"><span>The Betoota Advocate</span></a><span>.&nbsp;</span></p>
            <p><span>Nevertheless, the fake viral story further spread the news of Hanks’ diagnosis, which researchers say “highlighted the reality of COVID-19” during the early days when much of the public was still learning about the virus and its severity. Because of Hanks’ announcement, many began to consider their own susceptibility to COVID-19.&nbsp;</span></p>
<p><span>“This [Hanks disclosure] just makes me a little worried now. Anyone, no matter who you are, can catch the virus and not even know it. Makes me take all the precautions that I possibly can to prevent myself and family from getting the virus,” said one of the respondents to the study.&nbsp;</span></p>
<p><span>Researchers say many survey participants reported being inspired to learn more about COVID-19 and/or take stricter precautions thanks to Hanks’ disclosure. “I am more alert and interested in the issue of coronavirus than I was before Tom Hanks disclosed that he had it,” reported a participant. Another said, “My thoughts have changed. Hearing this news about Tom Hanks makes me think that the virus is more serious.”&nbsp;</span></p>
<p><span>Many expressed a range of emotions to the news of Hanks’ illness, including surprise, fear, anger, sadness, and hope. “I just feel an increase in fear and worry. I think humans are stupid and might give me the disease, this makes me angry,” reported a participant. “I am worried about the coronavirus hitting close to home. Knowing a celebrity has gotten sick with this virus makes me more worried that myself or my family might catch it,” said another.&nbsp;</span></p>
<p><span>For the half of respondents not influenced by Hanks’ diagnosis, the majority reported thinking the illness did not pose any severe health concerns to the actor. Researchers also noted that many in the “not influenced” category said they were already aware of COVID-19 and its effects before Hanks’ announcement.&nbsp;</span></p>
<p><span>With persons reporting they had not heard about Hanks’ diagnosis, researchers showed half of these participants the Facebook post where Hanks announced he’d tested positive for COVID-19 and the other half a non-COVID post made by Hanks. Researchers say the group who read the COVID-19 post reported feeling less capable of avoiding the virus than those who had read the non-COVID post.&nbsp;&nbsp;</span></p>
<p><span>“It could be that learning of Hanks’ diagnosis, despite his wealth and resources, resulted in people thinking that if Hanks could not avoid COVID-19, then they may not be able to, either,” theorized researchers.</span></p>
<p><span>A wealth of </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2666148"><span>empirical research</span></a><span> has demonstrated the significant impact celebrity endorsement can have on consumer buying behavior. A 2017 </span><a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=40853"><span>study </span></a><span>by Harvard Business School professor Dr. Anita Elberse and Barclays Capital analyst Jeroen Verleun found that, on average, a celebrity endorsement increased a company’s sales by 4% relative to its competition and increased stock value by 0.25%. While this may not seem like a lot, 4% can translate into billions of dollars for major corporations.&nbsp;</span></p><div><div id="block-wrap-88013" data-id="88013"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/unidentified-aerial-phenomena-could-be-a-national-security-threat-we-need-more-scientists-looking-at-the-problem/">
				<img width="120" height="80" src="https://thedebrief.org/wp-content/uploads/2020/10/planetarium.jpg" alt="Unidentified Aerial Phenomena" srcset="https://thedebrief.org/wp-content/uploads/2020/10/planetarium.jpg 1500w,https://thedebrief.org/wp-content/uploads/2020/10/planetarium-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/10/planetarium-1024x683.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/10/planetarium-768x512.jpg 768w" sizes="(max-width: 120px) 100vw, 120px">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span>Researchers say their study showing the impact of Hanks’ COVID-19 diagnosis on public perception demonstrates that celebrities can be equally powerful voices during public health crises.&nbsp;</span></p>
<p><span>Statistical analysis performed by researchers showed that celebrity influence could be especially pervasive during a health crisis whenever it involves a famous personality people feel they can identify with. “Tom Hanks is the guy we feel we like and know, so hearing about him is closer to finding out that a friend or a family member has it,” said one participant.&nbsp;</span></p>
<p><span>“People who said they typically trust celebrities, friends, family, or Donald Trump for health information were more likely to say that Hanks’ announcement led to positive behavior change,” said Dr. Myrick. “This suggests that public health officials and advocates may want to use these types of celebrity announcements to help reach people who may be harder to reach. They don’t rely as much on news or on scientists for health information.”&nbsp;</span></p>
<p><span>Researchers note their findings suggest not everyone will respond uniformly to illness announcements made by celebrities, and some may feel disempowered by the news that a beloved public figure cannot protect themselves from illness.&nbsp;</span></p>
<p><span>“Public health organizations may need to focus on creating messages that boost public efficacy if a beloved celebrity is struggling with an illness. Conversely, once a celebrity like Hanks recovers, additional campaign messages may want to point to that recovery to generate hope and stronger efficacy perceptions,” note researchers.&nbsp;</span></p>
<p><span>Following his recovery, </span><a href="https://www.theguardian.com/film/2020/jul/06/tom-hanks-on-surviving-coronavirus-i-had-crippling-body-aches-fatigue-and-couldnt-concentrate"><span>Hanks has said</span></a><span> he experienced “crippling body aches,” fatigue, and the inability to “concentrate on anything for more than 12 minutes” during his bout with COVID-19. Hanks says his wife, Rita Wilson, lost her sense of taste and smell, had severe nausea, and a high-fever.&nbsp;</span></p>
<p><span>Not wanting to see anyone else go through the unpleasant, in some cases fatal, experience, Hanks encourages people to follow prevention guidelines issued by health professionals. “There’s really only three things everyone needs to do: wear a mask, social distance, wash your hands. I know societally it’s been politicized, but I don’t get it, man. I don’t understand how anyone can put their foot down and say: ‘I don’t have to do my part.'”</span></p>

            									</div>
			</div></div>]]>
            </description>
            <link>https://thedebrief.org/tom-hanks-covid-19-diagnosis-likely-shaped-public-attitude-toward-virus-says-research/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081832</guid>
            <pubDate>Tue, 09 Feb 2021 20:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creeping as a Service]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 113 (<a href="https://news.ycombinator.com/item?id=26081672">thread link</a>) | @dshipper
<br/>
February 9, 2021 | https://every.to/divinations/creeping-as-a-service-craas | <a href="https://web.archive.org/web/*/https://every.to/divinations/creeping-as-a-service-craas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><em>Hey, Nathan here! Remember a few months ago when we published a wonderful essay on&nbsp;</em><a href="https://every.to/divinations/linkedins-alternate-universe-21780381" rel="noopener noreferrer" target="_blank"><em>LinkedInâ€™s ridiculousness</em></a><em>? It was one of Divinations most popular posts ever, and it was written by </em><a href="https://twitter.com/fadeke_adegbuyi" rel="noopener noreferrer" target="_blank"><em>Fadeke Adegbuyi</em></a><em>, a brilliant observer of internet culture who also is a senior marketing manager at Doist. Today Iâ€™m thrilled to share with you Fadekeâ€™s latest workâ€”this time examining our obsession with identity through the lens of a Twitter bio tracking app called Spoonbill. Enjoy!</em></p><hr><p>Elon Musk updated his Twitter bio 23 times in 2020. He last changed it on February 4, 2021 at 6:31 AM PST. A few versions include â€œBorn 69 days after 4/20,â€� â€œSoundCloud Rockstar,â€� â€œBudgie Smuggler,â€� and â€œ#bitcoin.â€� I didnâ€™t spend months stalking Muskâ€™s page, developing an encyclopedic knowledge of his time spent in the Twitterverse. I looked it up on <a href="http://spoonbill.io/" rel="noopener noreferrer" target="_blank">Spoonbill</a>.&nbsp;</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_1.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_1.png"></a></p><p>I could use the app to give you similar information on any celebrity or public figure with a Twitter account. Or I could use it on you. If I wanted to, I could see all the changes youâ€™ve made to your profile since you first signed up: your name, your location, your website, your pinned tweets. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_2.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_2.png"></a></p><p>Spoonbillâ€™s creator, <a href="https://twitter.com/justinmduke" rel="noopener noreferrer" target="_blank">Justin M. Duke</a>, describes the app, which has nearly 93 thousand users, as a â€œtracking tool for online metadata.â€� Over 45K of those users have signed up to receive daily emails that aggregate updates across all the Twitter profiles they follow. The open rate for these daily emails hovers around 55%, <a href="https://www.campaignmonitor.com/resources/knowledge-base/what-are-the-average-click-and-read-rates-for-email-campaigns/" rel="noopener noreferrer" target="_blank">well above average</a> for email campaigns.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_3.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_3.png"></a></p><p>I asked <a href="https://twitter.com/hunterwalk" rel="noopener noreferrer" target="_blank">Hunter Walk</a>, a Partner at the seed-stage venture capital firm Homebrew and an avid Spoonbiller, why he uses the app :</p><blockquote><em>"It's fun to see people wordsmithing their bios, changing the order of the portfolio companies they list based on startup performance, subtly announcing personal life changes...Instead of letting Twitter decide what's worthy of notification, I get to see </em>every<em> change and decide for myself what's interesting, often with context that the algorithm is unaware of."</em></blockquote><p>The tracked changes that Twitterâ€™s algorithm might register as neutral additions and subtractions can indeed be revealing to onlookers. Spoonbill captures what the people we follow are changing their bios to express; an investment exit, a tongue-in-cheek joke, or the end of an internet cult affiliation.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_New.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_New.png"></a></p><p>Social apps have made creepers out of all of us. Whether itâ€™s scrolling to the start of someoneâ€™s Instagram feed or <a href="https://sarajbenincasa.medium.com/confessions-of-a-venmo-voyeur-cb0e4c23d04a" rel="noopener noreferrer" target="_blank">looking through Venmo transactions</a>, weâ€™re constantly peering into othersâ€™ online lives. Spoonbill not only satisfies our tendency for online lurking, but pushes it into voyeur territory; surfacing whatâ€™s meant to be hidden is intimate in a way that scrolling a timeline isnâ€™t. The tool provides a glimpse into the specific ways we represent ourselves to the world, the unseen effort with which we express our identities, and how the uncanny feeling of being watched informs our sense of self.</p><p>Twitter is an interesting observation ground for online identity. Snapshots at Big Sur are meant for Instagramâ€™s photogenic feed, while professional milestones belong on <a href="https://divinations.every.to/p/linkedins-alternate-universe" rel="noopener noreferrer" target="_blank">LinkedInâ€™s alternate universe</a>. But in the Twitterverse, life and work converge. People are just as likely to share career news as they are to live-tweet a Netflix binge; professional gripes commingle with criticism of political leaders; snark and sincerity live side-by-side. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_4.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_4.png"></a></p><p>Twitterâ€™s bio section, then, is a tall order: <em>compress your entire identity into a single line item</em>. Many use the space to convey their own complexityâ€“â€“smart yet funny, accomplished but approachable. Society has progressed past the need for the phrase â€œworks hard, plays hard,â€� but thatâ€™s what weâ€™re trying to convey in our own personalized way: we contain multitudes. We are real.</p><p>Spoonbill reveals the way that people play with their latest positioning of self, carving out character space for their newly important aspects of identity.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_7.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_7.png"></a></p><p>Hustle culture looms large and professional accomplishments convey worth. In turn, notable work, career highlights, and impressive affiliations take center stage in our Twitter bios, the structure and grammar of which are heavily coded. Freelance journalists add and shuffle their bylines, arranged in order of prestige â€“â€“ @nytimes is meant to come first. In my corner of Tech Twitter, where optionality is king, itâ€™s now effectively a meme to be <em>â€œstarting something new,â€�</em> marked increasingly by the addition of â€œSubstack:â€�, â€œScout:â€�, or â€œSide project:â€� to oneâ€™s bio. Users adding â€œ<em>permanent student</em>â€� or â€œ<em>forever learning</em>â€� to their bios arenâ€™t pupils at cruel and unusual institutions, theyâ€™re signalling intellectual curiosity.&nbsp;</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_8.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_8.png"></a></p><p>The ability to see Twitter bio updates across hundreds or thousands of profiles over time make Spoonbill updates insightful in aggregate. Certain patterns and conventions emerge.&nbsp;</p><p>Spoonbillâ€™s creator has observed interesting trends in his app:</p><blockquote><em>"On an individual/corporate basis, a particularly fun one is seeing angels and investors tinker with the parts of the portfolio they </em><a href="http://spoonbill.io/twitter/data/Jason/" rel="noopener noreferrer" target="_blank"><em>choose to highlight</em></a><em>. A very classic example of this was the sheer number of firms and investors who removed things mentioning WeWork during, well, the period of time that you didnâ€™t want your name associated with WeWork."</em></blockquote><p>WeWork reached a $47 billion valuation in 2019, but cancelled their plans to go public <a href="https://www.businessinsider.com/wework-ipo-timeline-delayed-ceo-adam-neumann-scandals-explained-2019-9" rel="noopener noreferrer" target="_blank">after their IPO filing drew questions and concerns</a>. In a bio block thatâ€™s meant for selling ourselves to a potential follower, a failed investment takes up valuable real estate. But while WeWork investors might wish we would all forget their involvement as quickly as they hit â€œsaveâ€� on their new bio, Spoonbill always knows.</p><p>In that same 160-character space, weâ€™re also meant to declare our commitment to cause: political, social, or economic. Often, emojis will do:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_9.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_9.png"></a></p><p>If you watch Spoonbill updates closely enough, they suggest that the labels and descriptors we choose to signal our allegiances can be fleeting, our attention spans short. As COVID-19 spread throughout the world in early 2020, many updated their bios with their own messages about the virus, encouraging their followers to take some form of action:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_10.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_10.png"></a></p><p>But almost as quickly as these bio changes were made, they were unmade, individuals returning to their regular profiles. Less charitably, people just got bored; short-term vigilance surrounding the virus eventually led to a return to normal life for many. More charitably, the longer the pandemic wore on, identities once swaddled in concern for the virus eventually needed some wiggle room.&nbsp;</p><p>Last year, as racial tensions bubbled to a boil throughout the United States and set off an international cascade, Spoonbill revealed how Twitter bios were used to show support for what was top of mindâ€“â€“or a stance on what was top of the fold:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_11.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_11.png"></a></p><p>As time went on, it was jarring but predictable to see lines through phrases like â€œBlack lives matterâ€� across swaths of profile updates in my inbox. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_12.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_12.png"></a></p><p>Politics similarly finds its way into our descriptions of self. With the 2020 U.S. presidential election, many translated their desired vote on the ballot to their bio: </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_13.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_13.png"></a></p><p>The story has already been written, and you know what comes next: dashed presidential dreams translated to crossed-out candidates. Adding presidential hopefuls or even political parties to how we identify can be an exercise in disappointment. Disappointment is inevitable (after all, there can only be one). But seeing how long people hold on to their hopefuls was interesting; some still signalling long after their candidate had dropped out.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_14.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_14.png"></a></p><p>These tracked changes of our online selves provide a glimpse into the specific ways we represent ourselves to the world, how society manages to infect our identities, and, what we valueâ€”or what we want to be seen as valuing.</p><p>Spoonbill uncovers the tacit labor involved in our quest for the perfect personal positioning. In describing the way online influencers take effortless-looking selfies that are actually quite effortful, <a href="https://twitter.com/wishcrys" rel="noopener noreferrer" target="_blank">Dr. Crystal Abidin (aka wishcrys)</a>, a researcher and â€œanthropologist of influencer culturesâ€� (according to her own Twitter bio), <a href="https://journals.sagepub.com/doi/full/10.1177/2056305116641342" rel="noopener noreferrer" target="_blank">coined the term â€œtacit laborâ€�</a> as:&nbsp;</p><blockquote><em>â€œA collective practice of work that is understated and under-visibilized from being so thoroughly rehearsed that it appears as effortless and subconscious.â€�</em></blockquote><p>You donâ€™t need to be an influencer to know the labor involved in taking and selecting a selfie. Getting the right light, angle, and expression are just some of the considerations made while snapping and choosing from the photos that fill our camera rolls. After selecting the winning shot, we leave behind a stream of rejected selfies, never to see the light of day; the tacit labor stays hidden. After a photo has been cropped, filtered, and face-tuned, a refined â€œselfâ€�-ie joins the feed, adding to our curated online imageâ€“â€“polished, carefree, or somewhere in between.</p><p>Just like we strain for the perfect selfie, we tinker to find the perfect bio, treating it as a personal sales pitch and making micro edits to what we represent and â€œwho we are.â€� Spoonbill catalogues every time-stamped keystroke and tracked changeâ€“â€“from the removal of a single stuffy period to self-consciously swapping â€œMarketerâ€� for â€œStorytellerâ€� and reverting back again.&nbsp; Like the photos in your camera roll, your current Twitter bio has leftâ€“â€“for Spoonbill users to seeâ€“â€“a wake of rejected selves. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_5.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_5.png"></a></p><p>Spoonbill reveals the surprising scale and frenzying frequency with which all kinds of people make these online edits. We add in emojis, expand and shrink our past affiliations, and flirt briefly with humor, adding clever one-liners before eventually reverting to something more serious. Itâ€™s effortfulness on display. Seeing people iterate on their identities in Spoonbill, switching too-formal uppercase for carefree lowercase characters, makes our desire to control how …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://every.to/divinations/creeping-as-a-service-craas">https://every.to/divinations/creeping-as-a-service-craas</a></em></p>]]>
            </description>
            <link>https://every.to/divinations/creeping-as-a-service-craas</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081672</guid>
            <pubDate>Tue, 09 Feb 2021 19:45:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reminder: Ask To Reduce Your Internet Bill – I Saved $40/month in 7 minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26081661">thread link</a>) | @albertk1988
<br/>
February 9, 2021 | https://www.voyxt.com/saving-money-on-your-internet-bill/ | <a href="https://web.archive.org/web/*/https://www.voyxt.com/saving-money-on-your-internet-bill/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
					<div data-elementor-type="wp-post" data-elementor-id="311" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="39835e6" data-element_type="section">
						<div>
							<div>
					<div data-id="c2cbae7" data-element_type="column">
			<div>
							<div>
						<div data-id="b5699dd" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="577" src="https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-1024x577.png" alt="" loading="lazy" srcset="https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-1024x577.png 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-300x169.png 300w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-768x433.png 768w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2.png 1328w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-1024x577.png 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-300x169.png 300w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-768x433.png 768w, https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2.png 1328w" data-src="https://www.voyxt.com/wp-content/uploads/2021/02/thumbnail2-1024x577.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">											</p>
				</div>
				</div>
				<div data-id="2e955ba" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Having good internet is really important to me, but I also want it as cheap as possible. I know that, especially where I live in New York, I can negotiate my bill. There are always promotions that can vastly bring the cost down, but as with many Americans, I often neglect trying to get a better deal once the initial set up is over. There’s some fear that I will have to switch providers, which will be a pain (I certainly don’t want to be out of internet for any amount of time). But one of the biggest reasons I never negotiate my internet bill is that I hate talking on the phone. I don’t like having to listen to the gravelly voice while holding something up to my ear and having to pay full attention the whole time. With <a href="https://www.voyxt.com/">Voyxt</a>, I was able to call my internet provider <a href="https://www.rcn.com/">RCN </a>from my computer (no literally picking up the phone) and using my keyboard to speak, and also saved ~$40/month on my bill with a simple 7 minute call (see the full call below or on <a href="https://www.youtube.com/watch?v=aBDIREk3GJ8&amp;feature=youtu.be">Youtube</a>)</p>
				</div>
				</div>
				<div data-id="3476f96" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="218" src="https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-300x218.jpg" alt="" loading="lazy" srcset="https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-300x218.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-1024x745.jpg 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-768x559.jpg 768w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-1536x1118.jpg 1536w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920.jpg 1920w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-300x218.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-1024x745.jpg 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-768x559.jpg 768w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-1536x1118.jpg 1536w, https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920.jpg 1920w" data-src="https://www.voyxt.com/wp-content/uploads/2021/02/sever-3100049_1920-300x218.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">											</p>
				</div>
				</div>
				<div data-id="027a171" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>The big broadband corporations (ex.&nbsp;<a href="https://www.verizon.com/">Verizon</a>,&nbsp;<a href="https://official.spectrum.com/">Spectrum</a>) that provide you internet and television (and, if you’re a bit old fashioned, maybe a landline) make it pretty&nbsp;<a href="https://www.nytimes.com/2013/12/08/business/so-easy-to-sign-up-and-so-hard-to-cancel.html">hard to cancel your subscription</a>. Even though many have some form of online webchat or email support, cancellation or price changes to your subscription are often only allowed through the phone or in person. Because there are only a few providers, they don’t feel the need to provide such services through online channels. They know that calling is harder and many people avoid customer service calls, so they can continue raising your prices even though their costs are much lower. I suspect they might even make the calls more difficult to navigate on purpose – making you waste your time talking to their machine while they are using automated code to put you on hold. However, calls to negotiate price are not uncommon, and it’s likely that many of the customer service representatives that answer your call are just following a script and can easily look up promotions to reduce your price. You simply have to ask.,</p>
				</div>
				</div>
				<div data-id="a3750e3" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="199" src="https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-300x199.jpg" alt="" loading="lazy" srcset="https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-300x199.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-1024x680.jpg 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-768x510.jpg 768w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-1536x1020.jpg 1536w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920.jpg 1920w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-300x199.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-1024x680.jpg 1024w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-768x510.jpg 768w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-1536x1020.jpg 1536w, https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920.jpg 1920w" data-src="https://www.voyxt.com/wp-content/uploads/2021/02/office-620822_1920-300x199.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">											</p>
				</div>
				</div>
				<div data-id="1df05f0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>I knew that I should be able to get a better price, but I still wanted to be respectful and prepare some conversation points for my chat with RCN. I spent some time researching my options – I knew that Spectrum and Verizon both had deals in the new year for cheaper internet. It was easy to access their prices from their sites and spam letters they have been sending me (another problem!). I wrote out a few sentences that I might use so that I could communicate faster using Voyxt. I expected I could probably get about $20/month discount with my call so I was ready to cancel if I could not get the price down below $90/month total on my bill. I also prepared some research on purchasing my own modem and router (although this was a huge annoyance because it is almost impossible to determine which modems work for RCN). With these resources, I felt ready to make the call.</p>
				</div>
				</div>
				<div data-id="7901f69" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="169" src="https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640-300x169.jpg" alt="" loading="lazy" srcset="https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640-300x169.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640.jpg 640w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640-300x169.jpg 300w, https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640.jpg 640w" data-src="https://www.voyxt.com/wp-content/uploads/2021/02/robot-2301646_640-300x169.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">											</p>
				</div>
				</div>
				<div data-id="2990ba8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>First, I had to navigate RCN’s own customer service machine. Luckily, I was using Voyxt, so I could navigate it easily using Voyxt’s transcriptions and text to speech, using machine against machine. There was a long section discussion the COVID 19 pandemic which I could easily put out of my mind while I waited for useful information. Funnily, they suggested that I might have to wait 40 minutes before an agent talked to me (perhaps an unintentional way to get me to hang up?) but immediately connected me to a real agent, Jasmine. After all the transfers, the phone call had gotten jittery and some of the audio was garbled. However, Voyxt’s transcriptions kept working so I was able to easily navigate the conversation. After simply asking for a reduction in price (and being a bit patient), Jasmine was able to offer me internet at a greatly reduced price, saving me just under $40 per month. I didn’t have to use anything I prepared – I just had to ask. I believe that the customer service representatives are working hard to help out respectful customers, and with Voyxt it’s impossible to come off as upset or in the wrong way. After a brief chat, the call was over. There was a slight confusion in the call on the exact change in cost, but I checked my account online afterwards and it showed my next bill was as discussed and $40 per month cheaper than my previous month’s payment.</p><p>There are a lot of people trying to make customer service better, but in the end, the corporations are not incentivized to make it easy. The employees working there even want to help you out (they likely care little for their corporate overseers), but the way the companies have designed their customer service still means you have to call them and get to an agent. That’s why Voyxt was created – to give users the power and make phone calls easier. <a href="https://www.app.voyxt.com/register">Register for Voyxt now</a>.</p><p>See the full call I had with RCN below.&nbsp;<span>Start of chat with the agent at ~3 minutes</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="281c7f8" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.voyxt.com/saving-money-on-your-internet-bill/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081661</guid>
            <pubDate>Tue, 09 Feb 2021 19:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Windowing Revolution – Simplifying KDEs Compositor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081589">thread link</a>) | @scns
<br/>
February 9, 2021 | https://subdiff.org/blog/2021/the-windowing-revolution/ | <a href="https://web.archive.org/web/*/https://subdiff.org/blog/2021/the-windowing-revolution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="app" data-v-19ec50a8=""><div><div data-v-19ec50a8=""><div data-v-19ec50a8=""><p><img alt="Image" src="https://subdiff.org/assets/static/2021-02-08-the-windowing-revolution.07cc2b7.50b8144fa4edcbac2afe1b2921e73508.jpg" data-v-19ec50a8=""></p><section data-v-19ec50a8=""><div data-v-19ec50a8=""><p><span data-v-19ec50a8="">
              8. February 2021, by
              </span>
            — 10 min read.
          </p></div></section><section data-v-19ec50a8=""><article data-v-19ec50a8=""><p>The beta for the upcoming 5.21 release of the <a href="https://gitlab.com/kwinft" target="_blank" rel="nofollow noopener noreferrer">KWinFT projects</a> is now available.
It contains a monumental rewrite of KWinFT's windowing logic.
Read on for an overview of the changes and why this rewrite was necessary.</p>
<h2 id="a-confused-heart">A Confused Heart</h2>
<p>Let's define first what <em>windowing logic</em> is.
In my definition this means all structures and algorithms in code
to decide where a window should be stacked, placed, moved
or in which other ways its geometry can be manipulated
to allow the user to interact with and organize the totality of all windows.</p>
<p>And if you agree to such windowing logic
being of central importance for a windowing manager
and what distinguishes it in the end from others,
we may call it the <em>heart</em> of KWinFT.</p>
<p>The KWinFT compositor is based on <a href="https://en.wikipedia.org/wiki/KWin" target="_blank" rel="nofollow noopener noreferrer">KWin</a>,
KDE's official compositor for the Plasma Workspace.
KWin was founded over two decades ago.
Necessarily some of its code is very old,
does not adhere to any modern development principles
and sometimes,
due to changes in other levels of the graphics stack,
it is just plain wrong.</p>
<p>It is kind of unexpected though,
that this has been in particular the case for the windowing logic,
the heart of KWinFT.
For example at the HEAD of KWin's current master branch
<a href="https://invent.kde.org/plasma/kwin/-/blame/master/layers.cpp" target="_blank" rel="nofollow noopener noreferrer">do a git-blame</a>
over the ludicrous code in <code>layers.cpp</code>
responsible for all window stacking
and count how many lines are older than a decade.</p>
<p>But old code is not necessarily bad.
The reason why this old code is bad, is two-fold:
for one under the leadership of the former maintainer
the Wayland support was shoehorned into an already complex code base
and secondly he followed a strategy
to keep the old code untouched as much as possible.
Instead of doing necessary incremental refactors to the old code,
he tried to firewall it with an abundance of tests.</p>
<p>For sure one can find reasons and excuses to pick such a strategy,
but ultimately one has to say it failed.
This can not be judged of course from the outside,
but I feel comfortable in making this assessment
as someone who knows the code in detail
and because I am not the only one who abandoned his strategy.</p>
<h2 id="who-does-the-work-is-not-always-right">Who Does the Work Is Not Always Right</h2>
<p>In fact I am not the first one to refactor the old windowing logic.
The current de facto maintainer of KWin, <a href="https://blog.vladzahorodnii.com/" target="_blank" rel="nofollow noopener noreferrer">Vlad Zahorodnii</a>,
has done so in the past.</p>
<p>The result of his work were often massive merge requests
and back then,
when I was still contributing directly to KWin,
I had a feeling this was going into the wrong direction.
But I was also working on other upstream projects
and was in no position to tell someone,
who worked exclusively on KWin,
that his work should not go in as is.</p>
<p>This is actually enforced through an unwritten rule in KDE,
which prescribes that "the one who does the work, decides".
This sounds good when heard first,
but the one who does the work is not always right
and in the case of KWin,
Vlad's refactors made the old code even more complicated,
more fragile and less coherent.</p>
<h2 id="simple-is-difficult">Simple is Difficult</h2>
<p>The problem with Vlad's work on KWin is
that he likes to create solutions through the addition of new things.
He <a href="https://invent.kde.org/plasma/kwin/-/merge_requests/656" target="_blank" rel="nofollow noopener noreferrer">still does</a>.</p>
<p>I call that the "easy way" to solve a problem in an existing code base:
You add new code, which you write against the problem you want to solve.
You ensure the new code does not break any of the old unit tests.
For compliance add another unit test for your new code.</p>
<p>The big downside of this approach is
that the complexity of the code increases every time you do it.
And KWin's windowing code has become absurdly complex over the years.
As an example
take a look at the different <a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/toplevel.h#L299-349" target="_blank" rel="nofollow noopener noreferrer">types of geometries</a>,
which describe the position and size of a window.</p>
<p>In contrast I chose the hard way: I made the code simpler.</p>
<p>This would of course be also kind of easy if I just removed features,
but I was able to keep in all features of KWinFT's windowing logic
while simplifying major internal concepts and algorithms.</p>
<p>There is one exception though: the <a href="https://specifications.freedesktop.org/wm-spec/wm-spec-latest.html#idm45623492381424" target="_blank" rel="nofollow noopener noreferrer">shading of windows</a> got removed.
Sorry to the few people who used it,
but it is one of these features not meant for a Wayland world
and whoever had implemented it at some point in the ancient history of KWin,
had done that by littering special cases and boolean traps all over the code base
in order to get it done.</p>
<h2 id="battle-plans-and-front-lines">Battle Plans and Front Lines</h2>
<p>After this prelude let me give you an overview of what this revolution actually contains.</p>
<h3 id="flattening-the-hierarchy">Flattening the Hierarchy</h3>
<p>To get the revolution started I drafted in the beginning,
like I always do with bigger projects like this,
a general plan that I published in an <a href="https://gitlab.com/kwinft/kwinft/-/issues/75" target="_blank" rel="nofollow noopener noreferrer">issue ticket</a>.</p>
<p>You can see that my primary focus was to simplify the sprawling hierarchy of different window types,
which have grown in numbers over the years mostly because of the Wayland changes.</p>
<figure><img src="https://subdiff.org/assets/static/2021-02-08-pre-simplified.77c6345.f9cac661055f6d8f3bb43051bee4cdca.png" width="1443" alt="The old windows hierarchy." data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1443 814' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-36a3f04e077e3ac9034aadc16de6a793'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-36a3f04e077e3ac9034aadc16de6a793)' width='1443' height='814' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAkCAIAAAC2bqvFAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAG/klEQVRYw9VY%2bVPTVxDP39OZznT8QYuK9Rin1opMdepBvahOW5RjALlBucohpwJy32erUKgoJAECIUBIQhJyAgECCVfuhCTk%2bga6yTfJRC4BEeh3dt6897773nc/u/t2930xawf7rNpbg8kSXU2LqGYEl0FLDyqjPS6ilHSO2xhWd7ch5rAA3M0mhdcw05q5MXWs543soHJ6divvfwPAZEZuphHOx3VdTuy5%2bLz7%2b/ieU5G4%2bAYGvLLuEsGBA7A/y1rDgxyid0rf9XTitdS%2bGy%2bIgCS5kQ7vEUCweiQBoKJDZ0miIg1yZxdVMo1hbFqC6%2bfOy5al6pUJoWRomG80mlHmowUAFQhamVwjkag0Gr3VaptRq3VC4SLKYzZb4O3CgmJlxbTzw4A5MOlBtXPzcrVG7z4JsoLQNte3OuxjsSDzCwqUbSd2wByA6PAoVVoQC4Rz%2bpKDAQBIZRqXvm0v7B2pTC2Rqlx2OxwALo2C4hVK7TpIDgAGhwXc59EuuBksdGE%2bUAA2Pdo/iQqxzbncFIBraDKZxfMync7gHgP2AQC46zaEfgZBrBBt5ArNRjeALsRKxB7wdXrjktQGwIJY0Unr6kd2sFqtS0sq8ED0uyiPO30RC4DOQPE6veGTHgzGUSmXP8kGilhcUu6PBUC143NqllDBnlFyZpWcGSV0%2bGIVd1Y5KlTAzNScQipVAdtmjmF3br3p7cBMI1EIVNUlKPnAbyDO1BKm6nun6wjTggX1BovZ%2boYVA4U7304V/0sRvaOIWsmzbWRRJ02M2e2hlKr0UHhF1TKfVtKDy0f8iqihFbZqLKSCHl7F8M0jF77no%2bbeqDC0TJha1Dx4NRxSyQgoHYmpZ0XVsfxLRmIbWMlvOL55lLahWZuarB%2btRYeVXYLHxbSwKmbiX5zwamZEzej93IG9AHiYRw4oGQmtpD8ppvqX0ILKRh7mD/9RRI2oZvpkD5ZiJ9C4vtUOYqn2dmb/jYz%2bn9P772QP%2bGSRbmWQnhRRHuYNXU4kdFBFG5ejw7oewdXknvs5pPu5JKgF72b3Q0G1awAqrcEruefE0w7PKJxnJO50JPZUJPZMFBY6QMeC3%2be387aqydDJWcnyuRjcibBOWPhteCeQR3jn8bCOkxHYrwPbW4eEW1mgDDv%2bVUD7yUjs8bBOWA7td1GduwWwOiWShpQO%2b5dQ/V4P%2bRUMBZRS/YspT4op0AaWUh7lk2u6xrYqBNBJtc5Y1T1ZhhOU4QXl%2bElogSrwkxVdk68/jPNFyo340SF5TJL1D6fw/VjBe35Bu40K23mY3fmPTE0dEWj1RhjQR4UcvnjVXhubLVaTGeLgmmbZQBria3ZcCHz%2bg9m59BAcJVK1CYRFz6JQonEWNu6cM7NSsxnZPs2BT29F26DeYx5At9RDxnFGYrSdFcthciM/5K9NT/DhWMCle/c8sj2AxaWjBMAmvd6wLgu6ATAdBQCrWxOUu8ZFicopvWMeHYpEMr29WFjvQksKKGDc%2bV27fREABe28jBZO%2bls2UOob1otmdt47fnYr90UzJ6lptIM8jfJpdMbcNm5mCxeYc9t4L9/xE%2brosbX0PvaCoz5DkHLsWEYLN7mRkdPKzWnjpTez89v5sFtaMzvtLTunlaMzmPfw3%2bETAPwKh0MqGE%2brGMHldEjU8Y1syKyhlYyEJs69XHJ1t8DhGArtozyyXxHt3kuyf%2blIZM0oZHLfvOHq7klUJqPJHFJGjahhJv7NgVdhVYyYeuBhws4o/V5AhkvwvodXjG8u6YcEgldy75UkglcSwRvtJPd6p/Sei8U3EhwAFJoVn0zipfgelM3G8GfvmShcXc%2bkPcCtIRYkqJh84Vn3zYz%2ba6lEKAqA58ckwpWk3qvJvZfiCb9kETX2Q7/PAK6nEjwisJ7ROFtpEI077Wy/i8EfC/lQhR93FLRqvVdSN3CeiXEwnI/r/iakoxw37gRg%2bS1vwCMCdzYGD2vPxXaddRL0PaPxP6UQIAfvP4CRSfkgXzY0tp7IYzISTyqW6dacv6KoAgcntBSBAkuZaerizcn1risYT6SkjMtgQ5pgPVEn5MxphQWxHk4m3jQ5KOSayQnx2mE/mI3J2Z2cqddGFmTVRaBKvcE0t6h0/hFxFL3b06HVQps%2bJpMFSqMDK9o%2bC4BuxQRRSLG8olw2ANk6WoNEqR2bXlLpTHLNCsTQowsAjm9CEwvukBHVDIju0bVMuDrGN7Li6kfj6pjPGkYDS2mV%2bPF9z1D7AACVx2i2BJZS4fobCxI3jAISgAHS%2bxXbbsPQgfvkyzYOGkyPIgCLBfn11aBHJPZ8XNfF593Qno3FQ7C/EAcBHg9DuNplt7D28Gv/oAAgSGgF7Xo60SebdCuTdDvrI7qTM%2bCd0lfcwT8sC/wHtVo5ERO92/MAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-srcset="/assets/static/2021-02-08-pre-simplified.82a2fbd.f9cac661055f6d8f3bb43051bee4cdca.png 480w, /assets/static/2021-02-08-pre-simplified.cbab2cf.f9cac661055f6d8f3bb43051bee4cdca.png 1024w, /assets/static/2021-02-08-pre-simplified.77c6345.f9cac661055f6d8f3bb43051bee4cdca.png 1443w" data-src="/assets/static/2021-02-08-pre-simplified.77c6345.f9cac661055f6d8f3bb43051bee4cdca.png" srcset="https://subdiff.org/assets/static/2021-02-08-pre-simplified.82a2fbd.f9cac661055f6d8f3bb43051bee4cdca.png 480w, https://subdiff.org/assets/static/2021-02-08-pre-simplified.cbab2cf.f9cac661055f6d8f3bb43051bee4cdca.png 1024w, https://subdiff.org/assets/static/2021-02-08-pre-simplified.77c6345.f9cac661055f6d8f3bb43051bee4cdca.png 1443w"><figcaption>The old windows hierarchy.</figcaption></figure>
<p>My first idea was to flatten the hierarchy through the use of C++ templates
and replacing <a href="https://medium.com/better-programming/prefer-composition-over-inheritance-1602d5149ea1" target="_blank" rel="nofollow noopener noreferrer">inheritance with composition</a>.
And while not yet fully finished,
the current state absolutely reaffirms my decision to follow through with this idea.</p>
<figure><img src="https://subdiff.org/assets/static/2021-02-08-current-simplified.8a17a48.a5e485817413ff1f9b71e1675c7e8a47.png" width="572" alt="The new windows hierarchy." data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 572 190' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-1258accca43844c3ff5828b85b563494'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-1258accca43844c3ff5828b85b563494)' width='572' height='190' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAVCAIAAAB5SH/NAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEzElEQVRIx82XCVNaVxSA%2bVvpdFKNxrWZpDba7CaZTKJVMhObVCsIGPe6oFFJFeKkJpPYmoZYjcADRBBEpYrGDVAhZVFgRBZFdux576nTuMAYyYxvztw597w7757vnnPuu5ewFesnFA5D%2bzsyS3w6nMeQZTeIf2xF2xsN4pt0SeVrRSgUhAHhGE1H%2bEIAje%2bmiUxlLVvVwdcykcXm9xqQ%2bh516WtlwO9HAcInG6ClZzKuiHOpZiCfIf2hegDkco3ofJngQZs0jEfghAO09U2f/oWXVio8S%2bEnUQXJVEFKqfAbElLQPrx10gFC4Fq4ia38qpCbShMk0wTAAG0KTXC6GMlnDPk8HgwgfOIAcJ/cbs/cvFbxQTe%2bYFUuWBSqlW7epOyDfnLROrFoHZvRT88s2WyOWDEQYut9KBQym23zqn9dLjdu93i8ep3BvubAu4FAUK3RGwxmUGKSSIQYeu/3BwxGy4Z7O0NCmMALrdbo9fnDWHngFeL1%2boxGy%2bZmDHKJECvvwRvwyev17/dJpzP5fP4944PBINC6XBvHZCDExHuHY91sXg0GQwd68/HjJwC7mQMjLRbbMeshBhEAJyzWtQgD9gP8Hx4AVlZWcf0zKI4FAEtuNFmd0dLgMIBdj6HiTcvWnbIOf3GA8E4hGoxmtzt6IUYA%2bORrBgtsWUdlIMB/56iCrdmGyWSFbWf/fGHMsvtAD4oY/Nvaa9/LABGAbQDK6UgMnxOB1VWH2WLbydroM%2bn1KzhqlKhiYPDlVZvjCBFQ6SwTqmWlGpVJrFWqTKBMaVaUYN95hekmMGq0y3a7K8IXff6Ac91td7rXnBsOl9u5vjk1s2S1OR3rm2tOt2Pd7XC6Nz2%2bCOmELpDZFgoGggE/CCjbEoCDLPrgRmjhXEi4XIVcqZXcog9dqxPfa5bdaZJmN0hyWmQ36iWg5LbIrtdJ8hnDd59Ib9OH0mn87kEVWr6h0CGnoK1euTbrV0nBM8XDjn9yGCN3muU5DHnu0xFi%2b9gDpuJuq/xag4zOnjpsz8H/dFqD9RFrtICluN82mssYIbaN5rSO5P82Suocp7xUgh0zjv3ElBPgntHYq2njLbL4S429ahayVMeer%2b9RFXVOMTgLYCe/mn4mWALL8wFdXvv4G6kWAzhgctz4YkCTxxwv754jsiaIzImqN3NdUj21a7ZDoH3St8Dia6v%2bmqe9Uh4GgAdBt2y/xxij92pa3mvof6tr3qrKu2c7RbrHf84%2bfD75UqQDJ2vfqW83ydAIJJCRFCo/s1qUBodHKj%2bJgqTS%2bOmlgrMlSDIFwbtghzFfF/azpYuRAf4QzccX9n5L5SaR%2btMo3HQq9xyVm0LmnKPxwHjhMS%2b%2bqI/WKY8MoDevZVYKMioGLlYKL6EXCWFGhfBq7eB35cKLlXC7EIH9fLnwajWfkFnBiytGEslIHAk5Q0ZhQECJJ23raBd7BafiU4/63w4tRAEY1Jz6mQN3gEQKP7EElYQSBGtRSaLy4ZhNe6GIDGCw2IE8vpibSOKeKeYkklElvpiTAF1MAQu8zSjjEu63iq/Xi282iLOjyS26JKtayFPodtP9wBpgD2lSKdzMKlgzwfcVArzdlcxKYSqVV90VBQC20wtl6DUIkiL1EIE1yqri/wdIQ0fkHAIWVQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/2021-02-08-current-simplified.8a17a48.a5e485817413ff1f9b71e1675c7e8a47.png 572w" data-src="/assets/static/2021-02-08-current-simplified.8a17a48.a5e485817413ff1f9b71e1675c7e8a47.png" srcset="https://subdiff.org/assets/static/2021-02-08-current-simplified.8a17a48.a5e485817413ff1f9b71e1675c7e8a47.png 572w"><figcaption>The new windows hierarchy.</figcaption></figure>
<p>The classes <code>AbstractClient</code> and <code>XwaylandClient</code>,
which represented different kinds of windows,
have been removed completely.
This simplifies the hierarchy to only two levels.</p>
<p>In the future I want to also get rid of the <code>Toplevel</code> class.
My plan for that is to template the <code>Workspace</code> class over its supported window types.
This would mean no more dynamic inheritance at all.</p>
<p>Other dependent properties that were previously stuffed into <code>AbstractClient</code>
I carefully dissected out of it.
For example everything related to Scripting
is now contained in a single independent <a href="https://gitlab.com/kwinft/kwinft/-/blob/5409a4b98a79fdef463076b1c1b847d917cf3eb7/scripting/window_wrapper.h" target="_blank" rel="nofollow noopener noreferrer">interface</a>.</p>
<h3 id="clean-code-is-comprehensible-code">Clean Code is Comprehensible Code</h3>
<p>While moving forward with my initial goals
I realized that huge parts of the code were so outdated, so ugly, so rotten,
that I could not just refactor the logic,
but also had to improve the code styling.
Often the internal logic was incomprehensible
because of the style.</p>
<p>So this project became also about replacing archaic macros with modern lambdas,
reducing code duplication, adding white space where it made sense and so on.</p>
<p>Overall I improved the readability and reduced clutter.
I ensured there is a single coherent style in all refactored files.
One of the largest single commits in that endeavor
was the <a href="https://gitlab.com/kwinft/kwinft/-/commit/71926f30eb014ed2dfd0de715f16c01b93915d28?expanded=1" target="_blank" rel="nofollow noopener noreferrer">overhaul</a> of the <code>X11Client</code> class.</p>
<p>When deciding on how to clean up code,
I follow modern C++ principals in general.
I orientate myself at the Standard Library and the <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines" target="_blank" rel="nofollow noopener noreferrer">C++ Core Guidelines</a>
instead of the outdated Qt library style.
This falls in line with my long-term plan to <a href="https://gitlab.com/kwinft/kwinft/-/issues/21" target="_blank" rel="nofollow noopener noreferrer">factor out libraries</a>
that will be pure C++ and not depend on Qt anymore.</p>
<h3 id="the-big-ones-subsurfaces-and-window-geometries">The Big Ones: Subsurfaces and Window Geometries</h3>
<p>While my focus in the beginning of the windowing refactoring
was to simplify the hierarchy of windows,
that was not the initial motivation for this project.
My motivation was to fix a certain issue with Wayland subsurfaces:
they were not correctly transformed by effects.</p>
<p>There had landed <a href="https://phabricator.kde.org/D29131" target="_blank" rel="nofollow noopener noreferrer">a patch</a> for that in KWin in the middle of last year,
but I had a feeling it was once again a half-baked attempt at a solution,
leading to more complexity instead of less and not solving the problem in a holistic way.
My further analysis of the patch confirmed my initial thoughts
and I decided to look at the problem from a completely different angle.</p>
<p>The solution I came up with I would in fact call <em>revolutionary</em>.
In the <a href="https://gitlab.com/kwinft/kwinft/-/merge_requests/64" target="_blank" rel="nofollow noopener noreferrer">Merge Request</a>
I described it as a "huge mental shift in what we understand under subsurfaces".
I reused existing concepts from X11 and Wayland,
but interpreted them in a new way,
what simplified the code
and unified the logic over all windows.</p>
<p>As there is much to say about this specific solution,
I split out the discussion of it into a follow-up article.
Stay tuned.</p>
<p>I will also write a separate article about the other big change:
a total redesign of how we store and change the geometries of windows.</p>
<p>These geometries were a pain point for me already for a long time.
Any aspiring new contributor for KWin must feel absolutely shell-shocked,
when trying to understand what all the different geometry types of windows are supposed to mean
and how they relate to each other.</p>
<p>As a reminder <a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/toplevel.h#L299-349" target="_blank" rel="nofollow noopener noreferrer">these</a> are just the getters
for the different kinds of geometries in the abstract top level interface class.
And <a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/abstract_client.h#L624" target="_blank" rel="nofollow noopener noreferrer">this</a> is one of many ways to change a single one of them.
Yes, that's a pure virtual function in a subclass,
and yes, the second argument of that setter is a masked boolean trap.</p>
<p>To finally squash any hope that new contributor might have,
show him all the different forms on how to save a geometry
<a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/x11client.h#L483" target="_blank" rel="nofollow noopener noreferrer">here</a>, <a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/xdgshellclient.h#L97" target="_blank" rel="nofollow noopener noreferrer">here</a>,
<a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/toplevel.h#L723-724" target="_blank" rel="nofollow noopener noreferrer">here</a> and <a href="https://invent.kde.org/plasma/kwin/-/blob/4890db3f16d1b9bd244f1a83c8d198ff93f6543b/abstract_client.h#L1276-1294" target="_blank" rel="nofollow noopener noreferrer">here</a>.
And until now we have looked only at header files.</p>
<p>To simplify all that,
eradicate this glaringly unnecessary complexity,
make the code actually comprehensible again,
I redesigned everything about it from the ground up.
This was for sure the most comprehensive and most difficult task.
And I had to go through several iterations before a final overarching model emerged
on how to handle <em>all</em> geometries of <em>all</em> windows,
on how to save and manipulate them via clearly defined structures and processes.</p>
<p>Some explanation for that model
can be found in the <a href="https://gitlab.com/kwinft/kwinft/-/merge_requests/68" target="_blank" rel="nofollow noopener noreferrer">primary Merge Request</a> of the geometries rework.
But as said, like with subsurfaces,
I plan to write about the reworked geometries soon
in a more detailed follow-up article.</p>
<h2 id="a-blossoming-heart">A Blossoming Heart</h2>
<p>Why did I call this project the <em>Windowing Revolution</em>?
Does it deserve this pathos?
The project was massive, that's for sure.
In sheer numbers <a href="https://gitlab.com/kwinft/kwinft/-/merge_requests/71" target="_blank" rel="nofollow noopener noreferrer">the result</a>
is over 50 000 changed lines in over 300 commits.
I sacrificed over months all my time for this project, and my health.</p>
<p>But size or sacrifices alone do not make this a revolution.
Instead it comes through changes in our way of thinking
and how this project will reshape our future:
we radically redesigned the heart of our windowing manager,
we broke with overcome beliefs and traditions,
we simplified and reworked what was left rotten for decades.</p>
<p>In …</p></article></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://subdiff.org/blog/2021/the-windowing-revolution/">https://subdiff.org/blog/2021/the-windowing-revolution/</a></em></p>]]>
            </description>
            <link>https://subdiff.org/blog/2021/the-windowing-revolution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081589</guid>
            <pubDate>Tue, 09 Feb 2021 19:36:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Favicons as Supercookies]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081180">thread link</a>) | @agmm
<br/>
February 9, 2021 | https://supercookie.me/workwise | <a href="https://web.archive.org/web/*/https://supercookie.me/workwise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
                
                <p>📚 Please have a look at this <b>elaboration</b> from University of Illinois:
                    <a href="https://www.cs.uic.edu/~polakis/papers/solomos-ndss21.pdf" target="_blank">www.cs.uic.edu</a>
                </p>

                <h3>
                    
                    Introduction
                </h3>
                
                <blockquote>
                    <p>
                        <strong>Data is the new gold!</strong><br>
                    </p>
                </blockquote>

                
                Browsers are the most widespread access medium that makes it incredibly easy for us humans to connect to the <a href="https://en.wikipedia.org/wiki/World_Wide_Web" target="_blank">Word Wide Web</a>.<br>
                Due to the constant development of the Internet, such as the continuous elaboration of new standards and features, the introduction of powerful APIs and further interfaces on the browser side, the possibilities for collecting and analyzing data have also significantly expanded over the last few decades!
                <p>
                
                First and foremost, there is nothing wrong with collecting data at all. All of us collect data, whether unconsciously in private everyday life or completely consciously in school or at work - collecting data, interpreting it and drawing conclusions is actually incredibly important!
                </p><p>
                
                With the launch of the WWW for the public and the development of the first online services, data collection also started to become interesting for the various website providers, according to the motto <i>if I own a website, I also want to know who is surfing it</i>.
                <br>
                However, in most cases we as consumers only want to disclose as little as possible and only the data necessary for the intended service - in fact, <i>my private data is no one else's business</i>.
                </p><p>
                
                The above-mentioned further development of the WWW's capabilities has allowed data to be assigned to individual profiles, enabling the recognition of unique users and the ability to trace their browsing activities even across different pages - the so called <a href="https://en.wikipedia.org/wiki/Device_fingerprint" target="_blank">device fingerprinting</a>.
                <br>
                Some known methods for assigning a unique fingerprint to browsers are <a href="https://en.wikipedia.org/wiki/Device_fingerprint#Hardware_benchmarking" target="_blank">hardware benchmarking</a>, <a href="https://en.wikipedia.org/wiki/Device_fingerprint#Canvas_and_WebGL" target="_blank">fingerprinting via Canvas and WebGL</a> or <a href="https://en.wikipedia.org/wiki/Device_fingerprint#Browser_extensions" target="_blank">analysis of active browser extensions</a>. 
                <br><b>This article is about a less known way to achieve something similar!</b></p><h3>
                    
                    Background
                </h3>


                Modern browsers offer a wide range of features to improve and simplify the user experience.<br>
                One of these features are the so-called favicons: A <a href="https://en.wikipedia.org/wiki/Favicon" target="_blank">favicon</a> is a small (usually 16×16 or 32×32 pixels) logo used by web browsers to brand a website in a recognizable way. 
                Favicons are usually shown by most browsers in the address bar and next to the page's name in a list of bookmarks.

                <p>
                To serve a favicon on their website, a developer has to include an <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/link" target="_blank">&lt;link rel&gt;</a> attribute in the webpage’s header.
                If this tag does exist, the browser requests the icon from the predefined source and if the server response contains an valid icon file that can be properly rendered this icon is displayed by the browser. In any other case, a blank favicon is shown.
                </p><div>
                    <pre><span>&lt;link </span><span>rel</span><span>=</span><span>"icon" </span><span>href</span><span>=</span><span>"/favicon.ico"</span> <span>type</span><span>=</span><span>"image/x-icon"</span><span>&gt;</span></pre>
                </div>

                The favicons must be made very easily accessible by the browser. Therefore, they are cached in a separate local database on the system, called the favicon cache (F-Cache).
                A F-Cache data entries includes the visited URL (subdomain, domain, route, URL paramter), the favicon ID and the time to live (TTL). 
                <br>While this provides web developers the ability to delineate parts of their website using a wide variety of icons for individual routes and subdomains, it also leads to a possible <b>tracking scenario</b>.
                <p>
                
                    When a user visits a website, the browser checks if a favicon is needed by looking up the source of the shortcut icon link reference of the requested webpage.<br>
                    The browser initialy checks the local F-cache for an entry containing the URL of the active website. If a favicon entry exists, the icon will be loaded from the cache and then displayed. 
                    However, if there is no entry, for example because no favicon has ever been loaded under this particular domain, or the data in the cache is out of date, the browser makes a GET request to the server to load the site's favicon.
                </p><h3>
                    
                    Threat Model
                </h3>
                In the article a possible threat model is explained that allows to assign a <b>unique identifier to each browser</b> in order to draw conclusions about the user and to be able to identify this user even in case of applied anti-fingerprint measures, such as the use of a <a href="https://en.wikipedia.org/wiki/Virtual_private_network" target="_blank">VPN</a>, deletion of <a href="https://en.wikipedia.org/wiki/HTTP_cookie" target="_blank">cookies</a>, deletion of the <a href="https://en.wikipedia.org/wiki/Web_cache" target="_blank">browser cache</a> or manipulation of the <a href="https://developer.mozilla.org/en-US/docs/Glossary/Request_header" target="_blank">client header information</a>.
                <p>
                A web server can draw conclusions about whether a browser has already loaded a favicon or not:<br>
                So when the browser requests a web page, if the favicon is not in the local F-cache, another request for the favicon is made. If the icon already exists in the F-Cache, no further request is sent.<br>
                By combining the state of delivered and not delivered favicons for specific URL paths for a browser, a unique pattern (identification number) can be assigned to the client.
                <br>When the website is reloaded, the web server can reconstruct the identification number with the network requests sent by the client for the missing favicons and thus identify the browser.
                </p><ol>
                    <li>
                        <b>Write</b> identification
                        <div><p>
                            The goal of the <b>write</b> operation is to generate a unique identifier and store it on the client side.<br>
                            First step is to create a new N-bit ID on the server and translate it to a path vector as shown below.</p><p>
                            <strong>Example:</strong></p></div><div>
                                <pre><span>const</span> N<span> = </span><span>4</span>;<br><span>const</span> ROUTES<span> = </span>[<span><span>"</span>/a<span>"</span></span>, <span><span>"</span>/b<span>"</span></span>, <span><span>"</span>/c<span>"</span></span>, <span><span>"</span>/d<span>"</span></span>];<br><span>const</span> ID<span> = </span><span>generateNewID()</span>;<span> // -&gt; 1010 • (select unassigned decimal number, here ten: 10 -&gt; 1010b in binary)</span></pre>
                            </div>
                            <div>
                                <pre><span>const</span> vector<span> = </span><span>generateVectorFromID(<span>ID</span>)</span>;<span> // -&gt; ["/a", "/c"] • (because [a, b, c, d] where [1, 0, 1, 0] is 1 -&gt; a, c)</span></pre>
                            </div>
                        
                        Second step is to store the actual data inside the browser:<br>
                        The user will be redirected along all of the website paths, starting at <i>/a</i>, navigating to <i>/b</i>, to <i>/c</i> and finally to <i>/d</i>.
                        <br>
                        <ul>
                            <li>/a</li>
                            <li>/b</li>
                            <li>/c</li>
                            <li>/d</li>
                        </ul>
                        <br>
                       
                        While the user is redirected on every load the browser requests a favicon for the respective route, going the same way like<i>/a/favicon.ico</i>, to <i>/b/favicon.ico</i>, to <i>/c/favicon.ico</i> and finally to <i>/d/favicon.ico</i>.
                        <br>
                        <ul>
                            <li>/a/favicon.ico</li>
                            <li>/b/favicon.ico</li>
                            <li>/c/favicon.ico</li>
                            <li>/d/favicon.ico</li>
                        </ul>

                        <br>

                        The webserver will now only process those favicon requests whose path is present in the previously created path vector. If the route is present the webserver answers with the favicon file and <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200" target="_blank">Status 200 OK</a>.<br>
                        If the requested route is not in the path vector, the webserver aborts the request with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404" target="_blank">Error 404 Not Found</a>, or sends no response.<br>
                        Since the browser - as described earlier - only stores the delivered favicons in the F-Cache, we have now stored our unique identification number and the writing process is complete. <p>
                        In the above example, the webserver only responds to requests for the favicons under paths <i>/a/favicon.ico</i> and <i>/c/favicon.ico</i>. The F-Cache only has favicons-entries for these two paths.<br>


                        <a href="https://supercookie.me/assets/diagram-write.png" target="_blank">
                            <img src="https://supercookie.me/assets/diagram-write.svg">
                        </a></p></li>
                    <li>
                        <b>Read</b> identification
                        <div><p>
                            Here the goal is to re-identify a returning user based on his existing F-Cache entries.</p><p>
                            In read mode the server always responds to favicon requests with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404" target="_blank">Error 404 Not Found</a> status, but responds normally to all other requests. 
                            This preserves the <b>integrity of the cached favicons</b> during the read operation, since no new F-cache entry is created by the browser.<br>
                            To reconstruct a visitor's identifier, the browser must be routed through all available routes. The server records which favions are requested by the browser (those that are not present in the browsers F-cache) and which are not.
                            </p><p>
                            
                            <strong>Example:</strong></p></div><div>
                                <pre><span>const</span> visitedRoutes<span> = </span><span>[]</span>;<br><span>Webserver.onvisit</span><span> = <span>(route)</span> =&gt; </span><span><span>visitedRoutes.<span>push(</span></span></span>route<span>)</span>; <span> // -&gt; ["/b", "/d"]</span><br><span>Webserver.ondone</span><span> = <span>()</span> =&gt; </span><span><span>{ <span>const</span> ID = <span>getIDFromVector(</span></span></span>visitedRoutes<span>)</span> };<span> // -&gt; 10 • (because "/a" and "/b" are missing -&gt; 1010b)</span></pre>
                            </div>
                            The server can thus reconstruct the identification from the missing favicon requests and the reading process is complete.
                            <br>
                        

                        <a href="https://supercookie.me/assets/diagram-read.png" target="_blank">
                            <img src="https://supercookie.me/assets/diagram-read.svg">
                        </a>
                        <br>
                    </li>
                </ol>
                
                <h3>
                    
                    Target
                </h3>

                It looks like all top browsers are vulnerable to this attack scenario. <br>Mobile browsers are also affected.<table>
                    <thead>
                      <tr>
                        <th><p>Browser</p></th>
                        <th><p>Windows</p></th>
                        <th><p>MacOS</p></th>
                        <th><p>Linux</p></th>
                        <th><p>iOS</p></th>
                        <th><p>Android</p></th>
                        <th><i>Info</i></th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                          <td>Chrom…</td></tr></tbody></table></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supercookie.me/workwise">https://supercookie.me/workwise</a></em></p>]]>
            </description>
            <link>https://supercookie.me/workwise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081180</guid>
            <pubDate>Tue, 09 Feb 2021 18:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Fixbounty – Find security issues in open source projects]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26081069">thread link</a>) | @bhargab
<br/>
February 9, 2021 | https://spatcher.io/fixbounty | <a href="https://web.archive.org/web/*/https://spatcher.io/fixbounty">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://spatcher.io/fixbounty</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081069</guid>
            <pubDate>Tue, 09 Feb 2021 18:42:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fitness Camera: Turn Your Phone's Camera into a Fitness Tracker]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26080934">thread link</a>) | @miguelrochefort
<br/>
February 9, 2021 | https://miguelrochefort.com/blog/fitness-camera/ | <a href="https://web.archive.org/web/*/https://miguelrochefort.com/blog/fitness-camera/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article">
  <header>
  

    
    <p><time datetime="2020-04-12T00:00:00Z">April 12, 2020</time> &nbsp; 
    

    
    </p>
  </header>

  <p>This weekend, I attended <a href="https://pioneer.app/hackathon">Pioneer’s first Hackathon</a>.</p>
<p>Their call to action:</p>
<blockquote>
<p>Help upload the real world to the Internet. Work on something to make the experience of working on the web more fun for the billions staying at home. Overlay heart-rate on Zoom calls. Improve video conferencing quality. Build a Tandem competitor, one for friends rather than coworkers. The stage is yours.</p>
</blockquote>
<p>My team of 1 had 48 hours to produce a working demo.</p>

<p>Earlier this year, I played with <a href="https://www.tensorflow.org/lite/models/pose_estimation/overview">TensorFlow Lite’s PoseNet</a> model. I thought it had a lot of potential and I figured that this hackathon would be a good opportunity to find a use for it.</p>
<figure>
  <img src="https://miguelrochefort.com/img/posenet.gif" alt="">
  <figcaption>Pose estimation using <a href="https://www.tensorflow.org/lite/models/pose_estimation/overview">TensorFlow Lite's PoseNet</a></figcaption>
</figure>
<p>As a <a href="https://en.wikipedia.org/wiki/Quantified_self">quantified self</a> enthusiast, I track pretty much everything I do. While I’ve been able to <a href="https://miguelrochefort.com/blog/calendar/">automate a lot of what I track</a>, I’ve never been satisfied with the way I track my workouts:</p>
<ul>
<li>
<p>I tried manual tracking using the <a href="https://www.strong.app/">Strong</a> app.</p>
</li>
<li>
<p>I tried <a href="https://miguelrochefort.com/blog/nfc-water/">NFC tracking</a> using NFC tags and the <a href="https://nomie.app/">Nomie</a> app.</p>
</li>
<li>
<p>I tried voice tracking using <a href="https://assistant.google.com/">Google Assistant</a> on my Google Home speaker.</p>
</li>
</ul>
<p>Could I use machine learning and a camera to automatically track my workouts? This hackathon would be my chance to find out.</p>
<p><em>You might wonder what workout tracking has to do with the hackathon’s theme of “mak[ing] the experience of working on the web more fun”. I think I might have stopped reading the prompt at “Help upload the real world to the Internet”, and decided that “the real world” would be my workout and that “the Internet” would be some cloud database. When I realized my mistake, I changed my pitch to “a way to encourage employees to be more active”.</em></p>

<h2 id="improving-performance">Improving performance</h2>
<p>The first thing I did was to grab the <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/android">TensorFlow Lite PoseNet Android Demo</a> from GitHub. The app uses the phone’s camera to track the location of 17 distinct keypoints (feet, ankles, knees, hips, shoulders, neck, eyes, ears, elbows, and wrists), which it overlays on top of the video preview. After building it and deploying it to my phone, I noticed that the performance was terrible. On my Nokia 6.1—not exactly flagship material—the app struggled to maintain 10 FPS. That wouldn’t be fun to use or demo, so I investigated a bit.</p>
<figure>
  <img src="https://miguelrochefort.com/img/tensorflow-lite-posenet.png" alt="">
  <figcaption>Screenshot from <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/android">TensorFlow Lite PoseNet Android Demo</a></figcaption>
</figure>
<p>After a couple hours of investigation, I had found and addressed <a href="https://github.com/miguelrochefort/fitness-camera/commit/83398fba33d09a4e306ff519ce0f65f851921ccc">3 important performance bottlenecks</a>. The app could now reach 25 FPS, improving performance by over 250%. While far from perfect, the app finally felt usable.</p>
<h2 id="assessing-accuracy">Assessing accuracy</h2>
<p>Over the next hour, I let my phone watch me perform all kinds of exercises, at different angles, distances, and lighting conditions. I paid close attention to the accuracy of the pose estimation overlay, to understand what kinds of exercises it would and wouldn’t be compatible with. For example, it’s extremely accurate at tracking all 17 keypoints when facing the camera and doing squats. Yet, it struggles to recognize anything other than my face (nose, eyes, ears) when facing the camera and doing push-ups. Likewise, it’s very good at tracking hand movements…until you hold a dumbbell and your hand suddenly disappear.</p>
<p>Initially, I planned to use pose estimation and a trained classifier to detect distinct phases of an exercise. For example, a burpee could be decomposed into these 3 phases: crouching, planking, and jumping.</p>
<figure>
  <img src="https://miguelrochefort.com/img/burpee.jpg" alt="">
  <figcaption>Phases of a burpee (Photo: <a href="https://www.mensjournal.com/health-fitness/the-best-burpee-variations-to-burn-fat-and-build-explosive-power/">Men's Journal</a>)</figcaption>
</figure>
<p>However, due to PoseNet’s inconsistent accuracy and the hackathon’s time constraints, I pivoted to something much simpler. Instead of classifying exercises, it would only count repetitions. To further simplify the scope, I would only support 4 bodyweight exercises: squats, push-ups, sit-ups, and pull-ups.</p>
<h2 id="counting-repetitions">Counting repetitions</h2>
<p>As usual, I performed exercises in front of the camera, but this time I logged all frames (snapshot of 17 keypoints) to a CSV file. I then analyzed the data using Python and Google Colab, to look for patterns and find an appropriate repetition counting algorithm. <a href="https://colab.research.google.com/drive/1OHTsNyr3Ry_bSw8dT9s77BZsXHe7i8HR#scrollTo=uIbljMew7Wje">You can view the notebook here</a>.</p>
<p>The data looked like this:</p>
<figure>
  <img src="https://miguelrochefort.com/img/fitness-camera-logs.png" alt="">
  <figcaption>Vertical position of 17 keypoints over time when performing 7 squats</figcaption>
</figure>
<p>You don’t need to be a genius to look at this chart and figure out how many squats a person performed. I’m sure that many algorithms and machine learning models would equally qualified. But this was a hackathon and I couldn’t afford this level of sophistication.</p>
<p>Instead, I implemented the most basic algorithm imaginable:</p>
<ol>
<li>Ignore all keypoints other than the nose.</li>
<li>Record the lowest and the highest position of the nose.</li>
<li>Count a repetition whenever the nose crosses the halfway point.</li>
</ol>
<p>It worked with squats, push-ups, sit-ups, and pull-ups. I was satisfied.</p>
<figure>
  <img src="https://miguelrochefort.com/img/fitness-camera.gif" alt="">
  <figcaption>A health-conscious skeleton</figcaption>
</figure>
<h2 id="polishing-the-app">Polishing the app</h2>
<p>With the core functionality working and a few hours left before the demo, I decided to polish the app. I tweaked the colors, adjusted the layout, added audio feedback (“One!”, “Two!”, “Three!"), implemented some settings, designed an app icon, and published the APK. You can find the final product below:</p>
<!-- <img src="/img/fitness-camera-logo.png" /> -->
<ul>
<li>
<p><a href="https://github.com/miguelrochefort/fitness-camera">GitHub repository</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=Jdan-ZHiL6I">YouTube demo</a></p>
</li>
<li>
<p><a href="https://github.com/miguelrochefort/fitness-camera/releases/tag/v0.1.0">Android APK</a></p>
</li>
</ul>

<p>Overall, the hackathon was a great experience. I was lucky enough to be selected as a finalist and I had the opportunity to demo my app to the judges. Next time, I’ll make sure to join a team.</p>


  

</article></div>]]>
            </description>
            <link>https://miguelrochefort.com/blog/fitness-camera/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080934</guid>
            <pubDate>Tue, 09 Feb 2021 18:30:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Key Ways We Fail as Engineering Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26080876">thread link</a>) | @ochronus
<br/>
February 9, 2021 | https://ochronus.online/engineering-manager-4-ways-of-failure/ | <a href="https://web.archive.org/web/*/https://ochronus.online/engineering-manager-4-ways-of-failure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>Management tends to get bad rap and unfortunately many times rightfully so. Having a bad manager can make one’s life miserable and hinder their growth. Managers can seem like politicians who don’t know anything about our trade yet they give us directions.</p>
<p>On the other hand having a good manager can make you feel supported, can boost your career (and sometimes personal) growth and help make your team and company a happy place.</p>
<p>For better or worse, managers have a huge impact on their teams’ and direct report’s lives. It’s extremely important to understand some usual failure scenarios so we can course correct and provide better service and support to them.</p>
<p>Let’s see four usual ways we fail as managers.</p>
<h2 id="0-1-low-self-confidence">1. Low self-confidence</h2>
<blockquote><p>It’s not the lack of ability or opportunity that holds you back; it is only a lack of confidence in yourself.</p><p>—&nbsp;Richard Monckton Milnes</p></blockquote>
<p>I’ve known much more engineering managers with low self-confidence than otherwise. Honestly, I can relate! It’s usually really hard to see our work’s positive effect, feedback loops are just too long, and cause-and-effect relations aren’t always trivial to see.</p>
<p>This is especially true for new managers, who just stepped into a completely new skill area and often try to cling to what they already know. It’s really taxing on one’s confidence to suddenly be a beginner again after previously being highly performing (engineer, many times). The end result is that we are trying to prove to ourselves (and sometimes to others, too) that we do deserve the manager role.</p>
<p>Feeling like this is entirely natural, and it can motivate us to learn and do better. Troubles start, though when this inspires the wrong kinds of behaviors in managers.</p>
<p>For one, continually demonstrating insecurity, in general, can undermine people’s confidence in us as leaders who can enforce our negative thoughts and create a vicious circle – we start noticing others don’t have much faith in us.</p>
<p>People with low self-confidence usually have a hard time saying “I don’t know”, which is essential as an engineering manager. We cling to the thought that we have to know answers to everything that comes up; otherwise, we’re just not performing well.</p>
<p>I’ve seen some insecure managers trying to do team members’ jobs. They do this not because they don’t trust their team, but they need something they’re proficient with to feel more secure and confident. This was partially the motivation for me to write one of my old posts titled&nbsp;<a href="https://ochronus.online/engineering-managers-stop-coding/">Engineering Managers, Stop Coding!</a></p>
<p>Another way for such managers to feel that they are still worth something is to be too nitpicky, for example, in code reviews or simply when giving feedback. Among many things, all this can lead to the team’s engineers feeling that their engineering manager is competing against them in a way.</p>
<p>I’ve seen another behavior of low self-confidence managers: they sometimes complain about their direct reports to other direct reports (please&nbsp;<strong>never ever</strong>&nbsp;do this!) or their manager.</p>
<p>Usually, this is only a transition period, but sometimes managers get stuck in this for years. A good support circle (the other managers in the company) and a good manager of the manager can help tremendously. Being able to discuss insecurities and fears with others can make you understand that this is normal, you’re not alone, and you can learn good coping and growth strategies from more seasoned peers.</p>
<h2 id="1-2-the-silver-bullet-aka-the-one-trick-pony">2. The silver bullet a.k.a. the one-trick pony</h2>
<blockquote><p>Yesterday I was clever, so I wanted to change the world. Today I am wise, so I am changing myself.</p><p>—&nbsp;Jelaluddin Rumi</p></blockquote>
<p>We might not be conscious about it, but we all have a natural, default style when it comes to management. This is shaped by our general personality, our experiences and things we’ve learnt along the way.<br>As managers, we unconsciously rely on this style, and without guidance, we tend to use that style with every direct report. Even when it becomes conscious, we justify this with ‘this is who I am’ and sometimes even with core values and our self-image (see my earlier post&nbsp;<a href="https://ochronus.online/stories-we-tell-ourselves/">Stories We Tell Ourselves</a>). Also, in many cases this style is actually the way&nbsp;<em>we</em>&nbsp;prefer to be managed.</p>
<p>While having strong core values is vital to being a successful leader, using a single management style just simply won’t work with all your direct reports over the years. Acting this way will harm some of your direct reports (and of course hinder your performance as an engineering manager, too).</p>
<p>One-trick managers often talk about the one true way to do things. They get overprotective about their style as they face more and more challenge. They often see the failure to be with the direct reports who don’t respond well to their style instead of adapting to theirs.</p>
<p>This usually shows in hiring, too – engineering managers who are stuck with one single style of leadership often prefer to hire people who are like them instead of diversifying the team.</p>
<blockquote><p>INTERVIEWER 1: I think you’ll be a really good culture fit, Dave.<br>INTERVIEWER 2: I have to say Dave, your answers really impressed us.<br>CANDIDATE: Thank you, Dave. You too, Dave.<br><a href="https://twitter.com/tef_ebooks/status/1355757158458138624" target="_blank" rel="noopener">@tef_ebooks on Twitter</a></p></blockquote>
<p>These managers will have a fantastic relationship with some of the team members who’ll get most of their attention, leaving the others in the limbo a bit. These engineers who are left out will get frustrated and might end up doubting their performance if they don’t realize what’s happening.</p>
<p>As managers, it’s our core job to form a good working relationship with our direct reports. When this requires us to adapt our style or adopt new styles, it’s&nbsp;<em>our</em>&nbsp;job to do so. It’s not fair to expect our direct reports to adapt to our way of management.&nbsp;<a href="https://situational.com/situational-leadership/" target="_blank" rel="noopener">Situational Leadership</a>&nbsp;is a part of this.</p>

<h2 id="2-3-too-much-business-focus-vs-too-much-people-focus">3. Too much business focus vs. too much people focus</h2>
<blockquote><p>I still believe in synergy, but I call it natural law.</p><p>—&nbsp;Barry Diller</p></blockquote>
<p>We’ve all met managers who are only into business and view their direct reports as “resources”. They seemingly don’t care too much about their folks’ wellbeing and are only driven by deadlines, impact and KPIs. If the team is successful, it’ll make them happy, right?</p>
<p>We sometimes (much more rarely) see leaders who are only into the people part of their job. They create safe havens for their direct reports, try to protect them from the ‘evils’ of the world and the company and don’t seem to care about performance and business results too much. With a happy team, everything will just work out eventually, right?</p>
<p>These are obviously polar extremes – in reality, this works much more like a balance. Some business-focused managers actually do care a lot about their direct reports but firmly believe that the only way to happiness is a successful business. People-only leaders do sometimes nurture amazingly performing teams.</p>
<p>I just said ‘balance’, but I don’t view these to focuses as opposites. It’s much more about the balance of the short term and the long term. This balance manifests in many areas – solution quality vs. time to market, investing in the people vs. investing in the business, etc. etc..</p>
<p>Too much focus on the business in a leader will sometimes result in that leader prioritizing short term wins over long term ones. Such managers will talk a lot about holding people accountable. They are quick to ‘abandon’ direct reports who don’t fall in line in terms of team commitments and performance instead of coaching them and working on alignment. The sacrifice here can be tremendous: company culture suffers, and this setup won’t work in the long term. People will get burnt out and will leave. Sure, they will hire new engineers, but there’s the cost of onboarding and slowing down, lack of tenure and an overarching understanding of the product and systems and the job market will know what kind of place their company is.</p>
<p>Only focusing on the people without considering that you as a team are responsible for making the business successful can be equally detrimental. As an extreme case, a failed business won’t be able to eventually employ (as many) engineers. Individual and team success needs to align with the business’ success. Such leaders will often position themselves as gatekeepers of core values versus the rest of the company, or senior management. They will view their team as the last stand against the tides of evil.</p>
<p>This, in the end, is not about balance, I think, but rather about synergy (look, look, a buzzword!) – not building a silo of a safe haven for your team but finding a way for the individuals to grow and be successful in tandem with the business’ goals. Naturally, you need the right kind of company for this – if the company’s core values aren’t aligned with nurturing happy teams, it’ll naturally fail as a business, too. If you feel as a leader or as an individual contributor that you cannot stand by your company’s core values, by all means, do yourself the favor of finding a better place for yourself (unless you believe you can steer the company, of course).</p>
<p><strong>I’ve personally only seen high performing AND happy teams when business results and team happiness/health were aligned.</strong>https://newsletter.ochronus.online/embed</p>
<h2 id="3-4-too-much-solving-not-enough-listening">4. Too much solving, not enough listening</h2>
<blockquote><p>I remind myself every morning: Nothing I say this day will teach me anything. So if I’m going to learn, I must do it by listening.</p><p>—&nbsp;Larry King</p></blockquote>
<p>Interestingly this can happen both when we’re not confident as leaders and when we are too confident. We tend to focus on solutions too much instead of supporting/empowering others or listening for more context.</p>
<p>Sometimes people only need someone to vent to and are not looking for solutions immediately.<br>Even when they are, we can act as coaches and guide them to the solutions, helping them grow in the process so that next time they will be able to solve on their own.<br>Even when they need an immediate solution, we might fail to get the whole context by not authentically listening to them.</p>
<p>Such leaders usually jump to solutions right after hearing about an issue, and even when they ask for more details and input, they are not …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/engineering-manager-4-ways-of-failure/">https://ochronus.online/engineering-manager-4-ways-of-failure/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/engineering-manager-4-ways-of-failure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080876</guid>
            <pubDate>Tue, 09 Feb 2021 18:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exposing sequential IDs is bad Here is how to avoid it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26080817">thread link</a>) | @pazvanti
<br/>
February 9, 2021 | https://petrepopescu.tech/2021/01/exposing-sequential-ids-is-bad-here-is-how-to-avoid-it/ | <a href="https://web.archive.org/web/*/https://petrepopescu.tech/2021/01/exposing-sequential-ids-is-bad-here-is-how-to-avoid-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When working on LOGaritmical, I initially had my primary keys defined as UUIDs. I took this approach for two reasons: security and to avoid collisions even when there are many rows. My initial reasoning was that I will probably need to store each log line in a separate entry and considering that one log can have a few thousands of lines, there was a small risk of overflowing the Integer. Was my reasoning correct? Probably not.</p><p>Furthermore, I stumbled upon an interesting article about <a href="https://tomharrisonjr.com/uuid-or-guid-as-primary-keys-be-careful-7b2aa3dcb439" target="_blank" rel="noreferrer noopener">using UUIDs as primary keys</a>. There were some really great points about performance and query optimization. To keep it short, It is best to use numerical values as the primary key. So, I started to change my implementation. But then, another problem came into my head: security.</p><h4>Why is exposing the PK bad?</h4><p>By their nature, Auto Incremented primary keys grow by one for each new entry. This is great for avoiding collision, but it means that they are easily guessable. If you somehow find out that a user with the ID 27 exists, it most probably means that there are at least 26 other users with IDs 1 to 26. An attacker can try to exploit this by sending requests with different IDs. Furthermore, since the Administrator is usually the first user registered, it can easily guess the ID and try to get access.</p><p>There were also many reports, even on high-profile sites, where a full or partial dump of the contents could be done by simply incrementing the ID. This is how Parler data was exposed, for example. Other such attacks are rather easy to find, so exposing the internal ID is bad practice. You can still use an auto-incremented primary key internal and use it for all foreign keys as well, but whenever it is sent externally, an alternative must be found.</p><h4>The Play Session Cookie</h4><p>You may think that as long as your URLs does not contain the primary key, everything is ok. However, here is another scenario: cookies. Whenever a user is logged in, a session must be saved so that the user can remain logged in and can properly navigate the restricted pages. Play Framework does this by storing a Play Session Cookie that looks something like this:</p><figure><img loading="lazy" width="874" height="96" src="https://petrepopescu.tech/wp-content/uploads/2021/01/image-3.png" alt="" srcset="https://petrepopescu.tech/wp-content/uploads/2021/01/image-3.png 874w, https://petrepopescu.tech/wp-content/uploads/2021/01/image-3-300x33.png 300w, https://petrepopescu.tech/wp-content/uploads/2021/01/image-3-768x84.png 768w" sizes="(max-width: 874px) 100vw, 874px"></figure><p>This can easily be found using the browser’s inspector. At first sight it may seem a random string of characters, however it is much more than that. It is actually a BASE64 encoded JSON string with some additional, non-human-readable data, at the end. Decoding the string is easy and, even though changing it in the cookie may not be possible, it can still provide valuable information to an attacker if the PK is stored.</p><h4>Solution: How to avoid exposing the PK</h4><p>You use an UUID! But wait, didn’t I just say that using UUIDs is bad? You still use a numerical, auto-incremented, value for the PK and FK, but attach to it, in a separate column, a UUID. Whenever you are dealing internally, in the same application/system with the data, the numerical primary key is used.</p><pre title="Example UserDO that has both the Integer PK and the UUID column"><code lang="java">@Entity
@Table(name = "users")
public class UserDO {
    @Id
    @Column(name = "id", nullable = false)
    @GeneratedValue(strategy=GenerationType.<em>IDENTITY</em>)
    private Integer id;

    @Column(name = "uuid", columnDefinition = "VARCHAR(36)")
    @Type(type = "uuid-char")
    private UUID uuid;

    @Column
    private String username;

    @Column
    private String email;

    @Column
    private String passwordHash;

    @Column
    private String passwordSalt;
}</code></pre><p>However, when the data needs to be sent externally, you provide the UUID. Now the attacker can’t guess the UUID (or at least he will have a really hard time in doing so) and the internal workings are hidden. You store the user UUID in the session and use that one when performing security checks. You provide the UUID to the article/user/what-ever in the URL and use that one when searching for the right item. Once you find it, internally, you can start referencing it by the PK, just be careful not to expose it outside.</p><p>Any additional data that is referenced using FK can still be easily retrieved by the DB and Hibernate since the numerical value is being used. In short, you get the best of both worlds by using a numerical PK internally and an UUID externally. Initial search for an item my be a bit slower, but I believe it is negligible.</p></div></div></div>]]>
            </description>
            <link>https://petrepopescu.tech/2021/01/exposing-sequential-ids-is-bad-here-is-how-to-avoid-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080817</guid>
            <pubDate>Tue, 09 Feb 2021 18:21:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating a JavaScript Library from JavaScript to WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26080798">thread link</a>) | @jasperk
<br/>
February 9, 2021 | https://engineering.q42.nl/webassembly/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://engineering.q42.nl/content/images/size/w300/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 300w,
                            https://engineering.q42.nl/content/images/size/w600/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 600w,
                            https://engineering.q42.nl/content/images/size/w1000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 1000w,
                            https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png" alt="Going from JavaScript to WebAssembly in three steps">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>Hi! I'm Marcel, web developer at <a href="https://www.q42.com/">Q42</a> and creator of the <a href="https://micr.io/">Micrio storytelling platform</a>.</p>
<p>In 2015, I started developing a JavaScript viewer for ultra high resolution 2D and 360° images with added markers, tours, audio, and more. Since then, I've been pushing to find the best balance between hardware performance, minimal CPU and bandwidth use, and compatibility for older browsers to deliver a sharp and high quality viewing experience.</p>
<p>For Micrio, it is vital that the performance on the client's browser is as good as possible. The reason for this is very simple: when you are being told a story, or watching a movie, even <em>a single frameskip</em> immediately takes you out of your experience.</p>
<p>Since Micrio is being used for an <a href="https://micr.io/showcases">ever growing list</a> of awesome projects, the most important thing is that for whoever visits a Micrio project, it must work, and <em>work well</em>: delivering fast load times, and a butter smooth interactive experience.</p>
<p><a href="https://webassembly.org/">WebAssembly</a> (Wasm) is the ability for your browser to run <em>compiled</em> code at (near-) native speeds. It is now recognised by the W3C as the <a href="https://www.w3.org/2019/12/pressrelease-wasm-rec.html.en">4th official web programming language</a>, after HTML, CSS and JavaScript.</p>
<p>With it, you can run compiled code written in a variety of programming languages (C/C++, Rust, Go, AssemblyScript, <a href="https://github.com/appcypher/awesome-wasm-langs">and many more</a>) in your browser, without any need for plugins.</p>
<p>Finding out about Wasm in late 2019 really made me want to try it out. Could I use this tech to make the Micrio client run smoother than the current version does? Would I need to rewrite everything in C++, and if so, how would that work? Would the effort be worth the gains it would give me? And not in the least.. <em>how does it work!?</em></p>
<p>This article describes my journey from upgrading the Micrio <strong>JavaScript-only client to use WebAssembly</strong>, with the hopes of improving performance, and taking my code to the next level.</p>
<h3 id="thecurrentversion">The current version</h3>
<p>To give a rough idea about the tech stack of the current latest JS-only revision of Micrio (<a href="https://b.micr.io/micrio-2.9.min.js">version 2.9</a>): This library as a single JS file works on all semi-modern browsers, including even Internet Explorer 10 for 2D, and IE 11 for 360° images.</p>
<p>It uses Canvas2D for the rendering of 2D images, and <a href="https://threejs.org/">three.js</a>/WebGL rendering for 360° images. Written in <a href="https://caniuse.com/#search=es6">ES6 JavaScript</a> (or ECMAScript 6, the latest version of JavaScript), it still <a href="https://developers.google.com/closure/compiler">compiles</a> to ES5 to support Internet Explorer 11.</p>
<p>As you can imagine, displaying a <a href="https://micr.io/i/xCSYV/">231.250 x 193.750 pixel image</a> in your browser in a matter of milliseconds, allowing the user to freely zoom in and navigate, requires a little bit of processing power.</p>
<p>Now, Micrio 2.9 <em>isn't bad</em>. It runs pretty smoothly on all devices. But with WebAssembly around the corner, allowing all calculations to be done at native CPU speeds, this could potentially make a big difference in making Micrio's performance even better, and could improve the code architecture a lot.</p>
<p>And, perhaps, this could also mark the setup for a new major version, where I will draw a clear line and drop all compatibility and polyfills for older browsers: <strong>Micrio 3.0</strong>.</p>
<h2 id="firstrewritecandemscripten">First Rewrite: C++ and emscripten</h2>
<p>As a first step into the world of WebAssembly, getting to know the ecosystem, I started to play around with <a href="https://emscripten.org/">emscripten</a>. With it, you can take almost any project made in C or C++, and compile it to a binary <code>.wasm</code> file that your browser can natively run.</p>
<p>At this point, I didn't really have a clear image of where WebAssembly starts and ends, and how autonomously it could run inside your browser. So I started a new project from scratch to see if I could make a C++-implementation of the basic Micrio logic: a virtual <em>zoomable</em> and <em>pannable</em> image consisting of a lot of separate tiles, using a virtual camera for displaying only the tiles necessary for what the user is viewing inside your screen.</p>
<p>It turns out, emscripten already had great compatibility for <a href="https://www.libsdl.org/">libsdl</a>: a low-level audio, keyboard/mouse input, and OpenGL library. Which is awesome, because I could write my code using this very well documented library, even including mouse and key inputs and WebGL rendering. Since I was also working with downloading images, I also used the <a href="https://github.com/nothings/stb">stb_image.h</a> image library.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/cpp.png" alt="Setting up SDL and OpenGL" title="C++ in the 21st century"></p>
<p>The largest struggle of this was picking up C++ again, never having used it outside of hobby scope many years ago. But after a few days of cursing and second guessing myself, I had a working first version with all of the most important features written with help of the SDL library:</p>
<ul>
<li>A virtual camera and all necessary viewing logic;</li>
<li>Image tiles downloading;</li>
<li>Rendering using WebGL(/OpenGL) using a simple shader;</li>
<li>Mouse event handling for panning and zooming the image;</li>
<li>Resize event handling to fit Micrio to the desired <code>&lt;canvas&gt;</code> HTML element</li>
</ul>
<p>You can see this version running here: <a href="https://b.micr.io/_test/wasm/index.html">https://b.micr.io/_test/wasm/index.html</a> :</p>
<p><a href="https://b.micr.io/_test/wasm/index.html"><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/emscripten.png" alt="Micrio in native C++"></a></p>
<h3 id="firstresults">First Results</h3>
<p>As incredibly awesome it was to see Micrio in C++ running smoothly in my browser, and even handing all the user's input, there were a few reservations, which left me with an unsatisfied feeling.</p>
<h4 id="1codingcfeltoldfashioned">1. Coding C++ felt old-fashioned</h4>
<p>Writing C++ felt like going back in time. Incredibly powerful and fully proven, but also archaic, especially for me as a web developer. I spent more time fiddling with making an optimized <code>Makefile</code> than I care to admit.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/makefile.png" alt="The emscripten C++ Makefile" title="( ͡° ͜ʖ ͡°)"></p>
<h4 id="2thecompiledwasmbinarywasverylarge">2. The compiled <code>.wasm</code> binary was very large</h4>
<p>As great as the help of <code>libsdl</code> and <code>stb_image.h</code> were to let me use OpenGL and JPG image functions, as much did they add to the final compiled binary file. Even with all <code>emcc</code> compiler optimizations (which can even use the awesome <code>closure</code> JS compiler), the resulting WebAssembly binary file was 760KB. Compared to the JavaScript version of Micrio being around 240KB, this was a major setback. These libraries packed a lot of functionalities that were not necessary for Micrio, but were still included in the compiled version.</p>
<h4 id="3tilagluefile">3. TIL: A <em>glue</em> file</h4>
<p>This is the part where I learnt where the limits of WebAssembly start and finish. <strong>WebAssembly is not a magical self-contained binary that lets you run full applications out of the box</strong>. It actually needs to be <em>bound</em> to the browser using JavaScript.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/glued.png" alt="glue clipart"><br>
<small><a href="http://www.clker.com/clipart-13445.html">Image source</a></small></p>
<p>Where I thought that all the SDL OpenGL code in C++ would automagically be recognised by the browser: <em>wrong</em>. What <code>emscripten</code> does, is to take all OpenGL operations from C++, and <em>convert them</em> to WebGL operations your browser can understand.</p>
<p>Same with the <code>libsdl</code> mouse and keyboard-inputs: these were <strong>glued</strong> to the browser using an extra JavaScript file that would set event listeners for the specific cases, and send them to the WebAssembly binary. This separate JavaScript file was generated by the emscripten compiler, and had to be included in the HTML alongside the compiled binary <code>.wasm</code> file.</p>
<p>Everything added together, the new total of the <em>base engine</em> of Micrio was a whopping <strong>791KB</strong>; a bit too much for my liking.</p>
<h2 id="secondrewriteassemblyscript">Second Rewrite: AssemblyScript</h2>
<p>Fast forward a few months, to just after having attended the awesome <a href="https://webassembly-summit.org/">WebAssembly Summit</a> in Mountain View in February 2020. With a bundle of fresh energy and inspiration, I decided to see if I could use WebAssembly to improve the Micrio JavaScript client a second time.</p>
<p>During the WebAssembly conference, I was very impressed by a <a href="https://www.youtube.com/watch?v=C8j_ieOm4vE">synth demo</a> written in <strong><a href="https://www.assemblyscript.org/">AssemblyScript</a></strong>, a language created specifically for WebAssembly, using the TypeScript syntax. Basically you can write (near) TypeScript, which compiles to a <code>.wasm</code>-binary. So anyone familiar with either TypeScript or JavaScript ES6 will not have a lot of difficulties using it.</p>
<p>And the great thing-- it's all installed using <code>npm</code>, so <a href="https://www.assemblyscript.org/quick-start.html">getting it up and running</a> and compiling your program is super easy!</p>
<p>There are a few basic <a href="https://www.assemblyscript.org/types.html"><code>types</code> added in AssemblyScript</a>, which are required for compile-time optimizations:</p>
<ul>
<li><code>f64</code> / <code>f32</code> : For 64 or 32-bit floats;</li>
<li><code>i8</code> / <code>i16</code> / <code>i32</code> / <code>i64</code> : For signed <code>int</code>s, ranging in precision</li>
<li><code>u8</code> .. <code>u64</code> : For unsigned <code>int</code>s</li>
<li><a href="https://www.assemblyscript.org/types.html">And a few more</a></li>
</ul>
<h3 id="goingatomic">Going atomic</h3>
<p>This time, I wanted to see if it was possible to only let a small part of Micrio run inside WebAssembly, and still use most of the JavaScript that was already inside the client. <em>How small can we get it?</em> I decided to focus on a subset of camera functions, such as translating screen coordinates to image coordinates and vice versa. So this time no rendering, event handling, or writing shaders.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/assemblyscript.png" alt="Simple camera functions in AssemblyScript" title="My First AssemblyScript"><br>
<small><em>Simple camera functions in AssemblyScript</em></small></p>
<p>The result: a 3KB binary containing some basic math functions, that take an input and return an output. AssemblyScript offers some <em>glue-tooling</em> by providing its own <a href="https://www.assemblyscript.org/loader.html">Loader</a>, which will deal with importing the binary file and being able to call these functions.</p>
<p>However, this is optional and I ended up using the JavaScript <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API">WebAssembly API</a>, <em>neat</em>. And it turns out, this is super easy: simply use the <code>fetch</code> API to load your compiled <code>.wasm</code> file, cast it as an <code>ArrayBuffer</code>, and use the <code>WebAssembly.instantiate()</code> function to get it up and running.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/instantiate.png" alt="Loading a wasm file" title="Gluing it yourself"></p>
<p>The compiled binary will then offer an <code>exports</code> object, containing the functions that you have exported in the AssemblyScript file, which you can immediately call from JavaScript as if they were normal functions.</p>
<p>Wait.. "<em>which you can immediately call from JavaScript as if they were normal functions</em>"...</p>
<p><strong>WebAssembly is running synchronously to JavaScript!</strong> 🤯</p>
<p>Having worked with WebWorkers before, I honestly thought that WebAssembly would run inside its own CPU thread, and that any function calls would be <code>async</code>. Nope, the Wasm-functions you call will return immediately!</p>
<p><a href="https://www.assemblyscript.org/exports-and-imports.html#exports"><em>This is, like, powerful stuff</em>!</a></p>
<h3 id="bundlingthecompiledwasminsidethejsfile">Bundling the compiled Wasm inside the JS file</h3>
<p>Since I now had some extra performing hands on deck for Micrio that was very easy to integrate, I decided to include this minimal WebAssembly binary in the then-stable release of Micrio (2.9).</p>
<p>However, I didn't want an extra HTTP request for the Wasm binary every time someone loaded the Micrio JS. So I included a <code>base64</code> encoded version of the Wasm-file <em>inside</em> the Micrio JS, and for browsers that support it, auto-loaded that. As a …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.q42.nl/webassembly/">https://engineering.q42.nl/webassembly/</a></em></p>]]>
            </description>
            <link>https://engineering.q42.nl/webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080798</guid>
            <pubDate>Tue, 09 Feb 2021 18:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vantage has acquired ec2instances.info]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26080571">thread link</a>) | @StratusBen
<br/>
February 9, 2021 | https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info | <a href="https://web.archive.org/web/*/https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Two things that aren’t changing are (1) customers are always going to want simpler ways to interact with their cloud infrastructure and (2) they’re always going to want tools to understand where their cloud costs are coming from to make better business decisions. Vantage is aiming to help with both of these challenges but customers also use other tools to help make informed business decisions. One of the most popular tools we found people using is Ec2instances.info and today I’m happy to announce that Ec2instances.info is joining forces with Vantage.</p><p>Ec2instances.info will now reside at instances.vantage.sh and exists in its same form. The site will continue to be completely free and we have plans to add more features and functionality to it, including additional service prices beyond virtual machine pricing. We’ve ensured that the redirects have backwards compatibility with the prior domain so everything should continue to work as expected.&nbsp;</p><p>Garret Heaton, the creator of Ec2instances.info, says:<br></p><blockquote>After running ec2instances.info as a side project for <a href="https://powdahound.com/2011/03/hosting-a-static-site-on-amazon-s3-ec2instances-info/">almost a decade</a> I'm thrilled to hand over the reins to the Vantage team. Watching the site help people year after year has been a real pleasure and I'm very grateful for all the bug reports and improvements submitted by the public. In recent years the amount of choice available in instance types has grown significantly so comparing them is especially important, but I haven't had time to improve the site at the same rate. I'm very excited to see Vantage invest in the site as well as help people control costs across their entire infrastructure.</blockquote><p>‍</p><p>Vantage is built by working backwards from customer feedback and we hope to use the same playbook for instances.vantage.sh - so please join our <a href="https://join.slack.com/t/vantagecommunity/shared_invite/zt-mc723hg0-64opi05ckDf3gE56xapntg">Slack Community</a>, follow us on <a href="https://twitter.com/joinvantage">Twitter</a> or email us at <a href="mailto:support@vantage.sh">support@vantage.sh</a> to let us know your use-cases and how we can help.</p><p><strong>Q&amp;A</strong><br></p><p><strong>What is Vantage?</strong></p><p>Vantage is an alternative AWS console with a focus on developer experience and cost transparency.&nbsp;<br></p><p>‍</p><p><strong>What is EC2Instances.info?</strong></p><p>Ec2Instances.info, now instances.vantage.sh, is a tool for comparing hundreds of EC2 Instance Types across different instance type attributes.&nbsp;</p><p>‍<br></p><p><strong>I use EC2Instances.info - how will this impact me?</strong></p><p>Only the domain is changing and all existing links will redirect in a way that preserves filters. For all intents and purposes, you shouldn’t be impacted.&nbsp;</p><p>‍<br></p><p><strong>Do I need to be a registered Vantage user to use instances.vantage.sh?</strong></p><p>No. That being said, we are offering a one-time coupon code of $25 to all EC2Instances users that you can apply to your Vantage account using the coupon code of INSTANCES. This offer will expire on March 31st, 2021.</p><p><strong>I have a feature request for ec2instances.info - how can I submit it to you?</strong></p><p>You can continue to leave feedback on the existing <a href="https://github.com/powdahound/ec2instances.info">Github repository</a>, email <a href="mailto:support@vantage.sh">support@vantage.sh</a> with the subject line “Product Feedback Request” or join the “instances-vantage-sh” channel in the Vantage <a href="https://join.slack.com/t/vantagecommunity/shared_invite/zt-mc723hg0-64opi05ckDf3gE56xapntg">Slack community</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080571</guid>
            <pubDate>Tue, 09 Feb 2021 18:00:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe hints at patent grab from Big Pharma]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26080363">thread link</a>) | @em3rgent0rdr
<br/>
February 9, 2021 | https://www.politico.eu/article/europe-patent-grab-big-pharma/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/europe-patent-grab-big-pharma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Ever so softly, European politicians are beginning to voice a once unthinkable threat by suggesting they could snatch patents from drug companies to make up for massive shortfalls in the supply of coronavirus vaccines.</p>



<p>Big Pharma businesses have for many years regarded EU countries as unquestioningly loyal allies over intellectual property rights in the international trade arena. The EU could always be relied upon to defend U.S., Japanese and European drugmakers from poor nations in Africa and South Asia that have long wanted the recipe of critical medicines to be handed over to generic manufacturers. </p>



<p>But fury over the inability of companies to deliver on contracts amid the COVID-19 pandemic means that now even European politicians, from the Italian parliament to German Economy Minister Peter Altmaier, are arguing, albeit cautiously, that patents may no longer be as sacrosanct as they once were. </p>



<p>The big question is whether they are just saber-rattling, knowing full well that any patent raid would shatter an ultimate commercial taboo and risk an exodus of leading companies from Europe over fears about the loss of IP.  </p>



<p>The European Commission's Internal Market Commissioner Thierry Breton, a doyen of French big business, is at pains to stress that there is <a href="https://www.politico.eu/?p=1598714">no question of redistributing patents.</a> On Wednesday, he insisted that he would lead efforts by Brussels to help pharmaceutical companies expand their production sites and cooperate on output. “I will make sure they get everything they need,” he said.</p>



<p>That more traditional pro-business stance from Breton will prove comforting to pharma executives, who are now facing far more hostile messaging from other quarters of the EU. </p>



<p>European Council President Charles Michel last week raised the prospect that the EU could adopt “urgent measures” by invoking an emergency provision in the EU treaties in response to supply shortfalls. Commission officials have pointed to powers in Article 122 of the Treaty on the Functioning of the European Union, which ostensibly could be used to force vaccine makers to share their patents or other licenses — known as compulsory licensing.</p>



<p>Europe's most powerful economy minister, Germany’s Altmaier, who hails from the business-friendly center-right Christian Democratic Union, also seemed open to the possibility. During a<a href="https://www.zdf.de/politik/maybrit-illner/corona-virus-ohne-grenzen-hat-europa-die-kontrolle-verloren-sendung-vom-28-januar-2021-100.html" target="_blank"> television talk show</a> last week, Altmaier said compulsory licenses wouldn’t help to increase production in the next couple of months because it would take time to set up additional production centers. But if cooperation among pharmaceutical companies to increase production should fail, he said, he “would be willing to talk about coercive measures.”</p>



<p>Adding to the chorus, Alexis Tsipras, former Greek prime minister and current leader of the main opposition Syriza party, has called for a European patents pool. In an opinion piece for <a href="https://www.politico.eu/article/coronavirus-vaccines-public-good-not-corporate-product/">POLITICO</a> last week, he warned that depending on a few pharmaceutical companies to develop vaccines for the whole of Europe is a “weak” strategy.&nbsp;</p>



<h3>Going nuclear</h3>



<p>India and South Africa are pushing for a nuclear option, above and beyond compulsory licensing. They want a temporary international waiver on the agreement on Trade-Related Aspects of Intellectual Property Rights (TRIPS) for all coronavirus-related medical products, including vaccines and treatments.</p>



<p>This is set to come up on the agenda of the informal <a rel="noreferrer noopener" href="https://www.wto.org/english/tratop_e/trips_e/trips_e.htm" target="_blank">TRIPS Council meeting</a> Thursday, but is set to meet almost universal opposition from wealthy countries at the World Trade Organization, with the EU, U.K., U.S., and Switzerland all coming out against it. </p>



<p>Intriguingly, however, even here, potential cracks are emerging in the longer term European position. In early December, the Italian parliament passed a resolution <a rel="noreferrer noopener" href="https://www.camera.it/leg18/410?idSeduta=0440&amp;tipo=documenti_seduta" target="_blank">calling on the government to support the waiver</a>.</p>



<p>Civil society’s hopes were further boosted during the C20 — a civil society meeting that runs parallel to the G20 — from January 25 to 27. According to several attendees, Italian officials suggested that the Italian G20 presidency this year could support the waiver. </p>



<p>However, other attendees have played down the importance of those comments, since they weren't issued at the ministerial level and were conciliatory in tone. Indeed, at the official level in Geneva, the Italian foreign ministry said Rome's position was still fully in line with the European Commission's. </p>



<p>Nevertheless, Brandon Locke, policy and advocacy manager at ONE Campaign anti-poverty advocacy group, believes the Italian debate “might just be the crack in the ice to sort of get things rolling.”&nbsp;</p>



<p>“The fallout from the AstraZeneca and Pfizer [vaccine] delays are really causing a massive shift in how a lot of member states are thinking about vaccine supply and the traditional frameworks through which manufacturing was supposed to be carried out,” he said.&nbsp;&nbsp;</p>



<p>Tommaso Valletti, former chief competition economist at the Commission, has also signaled support for the waiver and the issuing of compulsory licenses. "Do we really believe that this would 'jeopardize' future innovation? 2.2m people are dead," he <a rel="noreferrer noopener" href="https://twitter.com/TomValletti/status/1356609791527964677" target="_blank">tweeted</a> on Tuesday.&nbsp;</p>



<p>However, there remains the formidable hurdle that WTO decisions must pass by consensus: Even if Italy did support the waiver, it's unlikely to make any difference.</p>



<h3>Push for unilateral action </h3>



<p>While unified WTO action is unlikely, the EU, U.S., U.K., Switzerland and Japan have offered to help members that want to implement existing "flexibilities" in the WTO’s intellectual property agreement, according to one Geneva trade official.&nbsp;That brings compulsory licensing into play, and countries can implement this individually. Several countries, including <a href="https://www.taylorwessing.com/fr/insights-and-events/insights/2020/04/covid-19-and-public-compulsory-licensing-of-drugs-in-europe" target="_blank">Germany</a> and <a href="https://www.cliffordchance.com/content/dam/cliffordchance/briefings/2020/04/compulsory-licensing-and-new-provisions-affecting-ip-holders-during-the-coronavirus-crisis-in-france-and-globally.pdf" target="_blank">France</a>, have already even strengthened legislation to make these measures easier to implement. </p>



<p>Usually seen as a last resort, there are very few cases of compulsory licensing of medicines. But one could make the case in the context of the coronavirus pandemic, explains Ceyhun Pehlivan, a lawyer at Linklaters’ Madrid office: Governments could say it's an appropriate option if the license holder can't produce enough vaccines or medicines. Opponents of compulsory licenses argue they would discourage companies from producing these kinds of products in the future, Pehlivan added. </p>



<p>Historically, compulsory licensing has certainly not proved an attractive option. Only once in WTO history has a developing country lacking production capabilities forced an export license onto a patent-holding country. In 2007, Rwanda sought to import antiretroviral HIV medicines from Canada — and Ottawa granted the license over a year after the initial ask.</p>



<p>There's another problem — possibly the Achilles' heel of the push for IP waivers and compulsory licenses: While granting a compulsory license may mean that another manufacturer can produce a drug or vaccine without being sued by the license holder, it doesn't give them the all-important know-how or technology transfer to actually make the drug. These are separate from patents and are particularly important for the manufacture of complex drugs, such as mRNA vaccines, which up until now, had never been made before.&nbsp;</p>



<p>The Geneva-based diplomat pointed to the know-how issue as a significant obstacle. “That’s the $1 million question,” the diplomat said.</p>



<p>One possible avenue is the World Health Organization’s COVID-19 <a rel="noreferrer noopener" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/global-research-on-novel-coronavirus-2019-ncov/covid-19-technology-access-pool#:~:text=The%20COVID%2D19%20Technology%20Access,knowledge%2C%20intellectual%20property%20and%20data." target="_blank">Technology Access Pool</a> (C-TAP), which was meant to become a source for open-access knowledge on COVID-19 science and technology. However, as yet, not a single patent-holding drugmaker has agreed to sign up.&nbsp;</p>



<h3>‘Guerilla war’ against IP rights&nbsp;</h3>



<p>Behind the spat at the WTO, a larger question looms: Is this an attempt to permanently override aspects of intellectual property rights that some countries disagree with?&nbsp;</p>



<p>“You can essentially see it as a play by two countries, India and South Africa, who never really liked the current intellectual property rights rules of the WTO,” said Simon Evenett, an economics professor at St. Gallen University in Switzerland. “I see it in a broader 25-year-long context of this sort of guerilla war against these rules.”</p>



<p>But for now, patent-defending countries are unlikely to let their guard down on intellectual property at the WTO, even during the pandemic.&nbsp;</p>



<p>“Almost every major pharmaceutical exporter except India has objected to this,” Evenett said. “I don’t see that proposal going ahead, unless circumstances dramatically change.</p>



<p>"But that doesn’t mean that India and South Africa can’t act unilaterally," he added.</p>



<p><em>Giorgio Leali, Helen Collis, Paola Tamma and Jakob Hanke Vela contributed reporting.</em></p>



<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#68181a0728180704011c010b07460d1d" target="_blank"><span data-cfemail="a6d6d4c9e6d6c9cacfd2cfc5c988c3d3">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/europe-patent-grab-big-pharma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080363</guid>
            <pubDate>Tue, 09 Feb 2021 17:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't start a business. Work on a side project instead]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26080321">thread link</a>) | @neilxm
<br/>
February 9, 2021 | https://neilmathew.co/dont-start-a-company-start-a-side-project/ | <a href="https://web.archive.org/web/*/https://neilmathew.co/dont-start-a-company-start-a-side-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>If I could go back in time and give a younger me one piece of advice when starting my company, it would be - don't start a business, build a side project instead. Build it for fun, see where it goes, let curiosity be your carrot as opposed to the expectation of success being a stick.</p><p>Side projects are simple. In fact they're so simple that you work on them just for the fun of it. You get deep into it, with no expectations, let what you learn evolve what you do next and let the project basically pull itself out of you.</p><p>When you start a business there is an expectation of success attached to it, otherwise the business is a failure. You need to find a business model, figure out what your vision is and what the market size is. "Is it a big enough idea?" is often the question asked by friends, parents and investors. There's nothing more demotivating than talking about your business to a cynical aunt.</p><p>Secondly, you need to be able to sell your ideas to those around you, and do it without fear. The best way to shed the fear of appearing foolish is to actually do something foolish for the fun of it. Strangely, you'll find that everyone around you is a lot more encouraging in this scenario than if you set out claiming you're going to build a big business.</p><p>Big things are accomplished by the compounding effect of many foolish little things done over a long time. If you start off trying to do a big thing, you'll always feel unaccomplished because you're too focused on what you haven't achieved yet. Focus on the small things, work on little projects, make an app for your friends as a joke, file your aunt's taxes, write a blog, <a href="https://www.reddit.com/r/shittyrobots/">build a shitty robot</a>. Keep doing that and just enjoy the process of building and creating things, and keep that child-like sense of curiosity alive. </p><p>The main reason for this is that you need to do the groundwork to prepare yourself to be receptive to opportunities when they come up. You never know when they will, but unless you are knee deep in something you love already, you just won't notice it.</p><blockquote>“You want to know how to paint a perfect painting? It's easy. Make yourself perfect and then just paint naturally.” <p>― Robert M. Pirsig, <a href="https://www.goodreads.com/work/quotes/175720">Zen and the Art of Motorcycle Maintenance</a></p></blockquote><hr><p><em>I write a weekly newsletter about topics like this. If you want to get an update when I publish a the next one, add your email in here.</em></p><!--kg-card-begin: html-->            <form data-members-form="subscribe">
                
                <div>
                    <div>
                        <p><span>Sending email...</span></p><p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
                        </p>
                        <p>
                            Please enter a valid email address!
                        </p>
                    </div>
                </div>
            </form><!--kg-card-end: html-->
			</section></div>]]>
            </description>
            <link>https://neilmathew.co/dont-start-a-company-start-a-side-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080321</guid>
            <pubDate>Tue, 09 Feb 2021 17:37:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fedora on the PinePhone: Pipewire Calling]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 85 (<a href="https://news.ycombinator.com/item?id=26080207">thread link</a>) | @ashitlerferad
<br/>
February 9, 2021 | https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1 | <a href="https://web.archive.org/web/*/https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080207</guid>
            <pubDate>Tue, 09 Feb 2021 17:29:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS in Opera Touch on iOS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26080113">thread link</a>) | @fossislife
<br/>
February 9, 2021 | https://blog.ipfs.io/2021-02-08-opera-ios-and-ipfs/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2021-02-08-opera-ios-and-ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Dietrich Ayala on 2021-02-08</p>

      

      

<p>
  <img src="https://blog.ipfs.io/img/opera-ipfs-header.png" alt="IPFS in Opera Touch for iOS">
</p>

<p>In 2020 we announced a big moment for IPFS: The first official support of IPFS protocol addressing in a major browser, when <a href="https://blog.ipfs.io/2020-03-30-ipfs-in-opera-for-android/">Opera released IPFS support in their Android browser</a>. This was an important step in IPFS browser support generally, by building interest and momentum. We didn’t stop there, and we’ve got not just one… BUT TWO releases to share with you today!</p>

<p>First, Opera has now added support for IPFS addressing to Opera Touch, their iOS browser.</p>

<p>
  <img src="https://blog.ipfs.io/img/opera-ios-wikipedia-short.png" alt="A screenshot of Wikipedia on IPFS in Opera Touch">
</p>

<p>Second, support for IPFS addressing in Opera desktop browser for Windows, macOS, and Linux will be coming in their next release, currently planned for March 2021.</p>

<p>As a special surprise for EthDenver, you can download a preview build of Opera for desktop which has IPFS addressing support! Give it a spin at <a href="https://ethdenver2021.opera.com/">ethdenver2021.opera.com</a>.</p>

<p>With these releases, Opera will now support <code>ipfs://</code> and <code>ipns://</code> addressing across their browser product line on all major operating systems: Windows, macOS, Linux, iOS, and Android.</p>

<h2 id="how-do-i-use-it">How do I use it?</h2>

<p>First, install Opera Touch on your iOS device. If you’re reading this on an iOS device, <a href="https://apps.apple.com/us/app/opera-touch-web-browser/id1411869974">click to install now</a>.</p>

<p>
  <img src="https://blog.ipfs.io/img/opera-ios-app-store-short.png" alt="Opera Touch in the iOS app store">
</p>

<p>Then you can open content using IPFS protocol addresses, like the <a href="ipns://blog.ipfs.io">blog you’re reading now</a>, <a href="ipns://en.wikipedia-on-ipfs.org">Wikipedia</a>, or this <a href="ipfs://bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi">Persian room guardian</a> by <a href="https://www.anyabozartist.com/the-persian-cat">Anya Boz</a>. You can easily upload files to IPFS using the <a href="https://docs.ipfs.io/install/ipfs-desktop/">IPFS desktop application</a> or <a href="https://share.ipfs.io/">Share.ipfs.io</a>.</p>

<h2 id="how-does-it-work">How does it work?</h2>

<p>Opera Touch supports navigating to addresses for <code>ipfs://</code> and <code>ipns://</code> protocol schemes, which are handled by a remote HTTP gateway. By default the gateway used is <code>dweb.link</code>, which is operated by Protocol Labs. The ability to select a different gateway is coming in the next update of Opera Touch.</p>

<p>Native representation of IPFS addresses in browsers is important, even when the content is loaded from an HTTP gateway as IPFS URIs are resolved out of the box, without the need for any additional extensions or opt-in settings, which familiarizes users and developers with decentralized concepts of content-addressing and creates a path to readiness for when native nodes are available.</p>

<h2 id="what-s-next">What’s next?</h2>

<p>Opera desktop browser support for IPFS addressing will ship soon, and we’re discussing what additional features to add next to build on top of this foundation of universal addressing support across the Opera browser line. Have ideas for what you’d like to see in Opera next? Let us know on the <a href="https://discuss.ipfs.io/">IPFS forums</a>, or tweet your ideas to <a href="https://twitter.com/opera">@Opera</a> and <a href="https://twitter.com/ipfs">@IPFS</a> on Twitter!</p>

<p><a href="https://apps.apple.com/us/app/opera-touch-web-browser/id1411869974">Install Opera Touch on iOS now!</a></p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2021-02-08-opera-ios-and-ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080113</guid>
            <pubDate>Tue, 09 Feb 2021 17:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js 14 is over 20x faster than Python3.8 for fib(n)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 103 (<a href="https://news.ycombinator.com/item?id=26079570">thread link</a>) | @brrrrrm
<br/>
February 9, 2021 | https://jott.live/markdown/nodejs_vs_python_ | <a href="https://web.archive.org/web/*/https://jott.live/markdown/nodejs_vs_python_">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jott.live/markdown/nodejs_vs_python_</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079570</guid>
            <pubDate>Tue, 09 Feb 2021 16:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NYC 3D pointillist map with point cloud data]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26079400">thread link</a>) | @moklick
<br/>
February 9, 2021 | https://yoninachmany.github.io/maps/nyc/index.html#15.7/40.710825/-74.008724/28.4/74 | <a href="https://web.archive.org/web/*/https://yoninachmany.github.io/maps/nyc/index.html#15.7/40.710825/-74.008724/28.4/74">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://yoninachmany.github.io/maps/nyc/index.html#15.7/40.710825/-74.008724/28.4/74</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079400</guid>
            <pubDate>Tue, 09 Feb 2021 16:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Polar Signals Continuous Profiler – Systematic Performance Profiling]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26079108">thread link</a>) | @brancz
<br/>
February 9, 2021 | https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/ | <a href="https://web.archive.org/web/*/https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Today we are pleased to introduce Polar Signals <strong>Continuous Profiler</strong>, an open source based SaaS for Continuous Profiling. Profiling has long been a tool in the developer's toolbox. It allows CPU, memory, I/O usage and more to be understood down to a line of code. It is an immensely valuable tool for debugging. <em>Continuous profiling</em> is the act of taking profiles of programs in a systematic way. Polar Signals Continuous Profiler, based on the open source <a target="_blank" href="https://github.com/conprof/conprof">Conprof</a> project, collects, stores and makes <a target="_blank" href="https://github.com/google/pprof">pprof</a> profiles available to be queried over time. This is useful in post-mortem analysis, when it is too late to take measurements. In short, Continuous Profiling allows for profiling to be systematic, instead of a search for the needle in the haystack.</p><h3>Traditional Workflow</h3><p>To understand how Polar Signals Continuous Profiler works, and why we built it, let's go through the traditional workflow of what a developer goes through when profiling. A typical scenario starts out with either a production incident or the intent to optimize a piece of code. Optimization is often driven by the intention to make a system faster, or for example to reduce resource usage in order to save cost.</p><p>Incidents caused by running out of memory (OOMKill) can be a very stressful situation, the process has already been killed by the operating system, and so it is not possible to obtain profiles about the situation anymore. Obtaining profiles often requires SSHing onto production machines and capturing profiles manually. This is problematic for security and auditability, besides that, it is also easy to make mistakes when SSHing in production environments. Above all, profiling manually in this fashion is a search for the needle in the haystack. It is impossible to know whether a situation is reproducible in a way that allows capturing the right data.</p><h3>Polar Signals Continuous Profiler Workflow</h3><p>The goal of Polar Signals Continuous Profiler is to turn the search for the right data into a systematic one. With Polar Signals Continuous Profiler, profiles are captured periodically, ensuring that profiles are available for any moment in time, that way the right data is always only a search away. This way, when a process ran out of memory, a latency spike happens or when we want to start optimize code, the data is already available! This saves time obtaining the data manually, but more importantly the <em>right</em> data is already captured - no need to wait or try and reproduce a past situation.</p><img src="https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/query-over-time.png" alt="Polar Signals Continuous Profiler Query Over Time"><p>Once the data is available over time, new useful workflows are unlocked. Take the scenario of optimizing a piece of code for reducing resource usage for example. A profile of a particular moment of time is useful, but it is only representative of that exact moment in time. When the data is collected over time, it can for example be summarized into a single report, making it not only representative of that moment of time, but the entire time range. We have found this to be particularly useful to summarize performance characteristics of an entire version of code.</p><img src="https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/merge.png" alt="Polar Signals Continuous Profiler Merge Feature"><p>And last but not least, not only is the data available over time, but also across deployment-rollouts. It allows answering questions that thus far have been notoriously difficult to answer, which boils down to "What changed in my code, that caused a change in performance?" This typically originates from one of two questions. Why did our resource usage increase? And did my optimization changes work?</p><img src="https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/compare.png" alt="Polar Signals Continuous Profiler Compare Feature"><p>To sum up, using Polar Signals Continuous Profiler an organization can:</p><ol><li>Save money on their cloud bill, by optimizing resource usage.</li><li>Boost conversion rate, by improving application latency.</li><li>Save time and stress, by make systems more reliable.</li></ol><h3>How Polar Signals Continuous Profiler Works</h3><p>Polar Signals Continuous Profiler periodically scrapes <a href="https://github.com/google/pprof">pprof</a> compatible profiles from HTTP endpoints. We are launching with support for <a href="https://golang.org/">Go</a>, which supports profiling in pprof format via its standard library. Many programs written in Go already have these endpoints, so organizations that already use Go are likely to not need any changes to their code to start using Polar Signals Continuous Profiler! Rust, Python, NodeJS and JVM are already on the roadmap, but let us know what languages and runtimes you would like to see!</p><p>The collector is configured to discover targets using service discovery, this happens to be identical to <a href="https://prometheus.io/">Prometheus'</a> service discovery, so organizations already using Prometheus can re-use configuration from it! And if not, we have automated deployment and configuration strategies prepared for you, for example to get started on Kubernetes seamlessly.</p><p>The collector regularly scrapes the HTTP endpoints and sends the results to Polar Signals. Once received by Polar Signals the exploration for improvements can start!</p><h3>Next steps</h3><p>Polar Signals Continuous Profiler is in private beta starting today! We are working hard to bring it to General Availability. We are in the process of onboarding users to our private beta, and if you want to participate, request access:</p></article></div>]]>
            </description>
            <link>https://www.polarsignals.com/blog/posts/2021/02/09/announcing-polar-signals-continuous-profiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079108</guid>
            <pubDate>Tue, 09 Feb 2021 16:06:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John McWhorter: The Neoracists]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 232 (<a href="https://news.ycombinator.com/item?id=26079002">thread link</a>) | @paulpauper
<br/>
February 9, 2021 | https://www.persuasion.community/p/john-mcwhorter-the-neoracists | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/john-mcwhorter-the-neoracists">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg&quot;,&quot;height&quot;:312,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:40221,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>[</strong>Excerpt from his new book, <em>The Elect: Neoracists Posing as Antiracists and their Threat to a Progressive America</em>]</p><p><strong>One can divide antiracism into three waves</strong>. First Wave Antiracism battled slavery and segregation. Second Wave Antiracism, in the 1970s and 1980s, battled racist attitudes and taught America that being racist was a flaw. Third Wave Antiracism, becoming mainstream in the 2010s, teaches that racism is baked into the structure of society, so whites’ “complicity” in living within it constitutes racism itself, while for black people, grappling with the racism surrounding them is the totality of experience and must condition exquisite sensitivity toward them, including a suspension of standards of achievement and conduct.</p><p>Third Wave Antiracist tenets, stated clearly and placed in simple oppositions, translate into nothing whatsoever:</p><ol><li><p>When black people say you have insulted them, apologize with profound sincerity and guilt. <strong>But </strong>don’t put black people in a position where you expect them to forgive you. They have dealt with too much to be expected to.</p></li><li><p>Black people are a conglomeration of disparate individuals. “Black culture” is code for “pathological, primitive ghetto people.” <strong>But </strong>don’t expect black people to assimilate to “white” social norms because black people have a culture of their own.</p></li><li><p>Silence about racism is violence. <strong>But </strong>elevate the voices of the oppressed over your own.</p></li><li><p>You must strive eternally to understand the experiences of black people. <strong>But </strong>you can never understand what it is to be black, and if you think you do you’re a racist.</p></li><li><p>Show interest in multiculturalism.&nbsp;<strong>But </strong>do not culturally appropriate. What is not your culture is not for you, and you may not try it or do it. But—if you aren’t nevertheless <em>interested</em> in it, you are a racist.</p></li><li><p>Support black people in creating their own spaces and stay out of them. <strong>But </strong>seek to have black friends. If you don’t have any, you’re a racist. And if you claim any, they’d better be <em>good</em> friends—in their private spaces, you aren’t allowed in.</p></li><li><p>When whites move away from&nbsp;black neighborhoods, it’s white flight.&nbsp;<strong>But </strong>when whites move into black neighborhoods, it’s gentrification, even when they pay black residents generously for their houses.</p></li><li><p>If you’re white and only date white people, you’re a racist. <strong>But </strong>if you’re white and date a black person you are, if only deep down, exotifying an “other.”</p></li><li><p>Black people cannot be held accountable for everything every black person does. <strong>But </strong>all whites must acknowledge their personal complicity in the perfidy throughout history of “whiteness.”</p></li><li><p>Black students must be admitted to schools via adjusted grade and test score standards to ensure a representative number of them and foster a diversity of views in classrooms. <strong>But </strong>it is racist to assume a black student was admitted to a school via racial preferences, and racist to expect them to represent the “diverse” view in classroom discussions.</p></li></ol><p>I suspect that deep down, most know that none of this catechism makes any sense. Less obvious is that it was not even composed with logic in mind. The self-contradiction of these tenets is crucial, in revealing that Third Wave Antiracism is not a philosophy but a religion. </p><p>The revelation of racism is, itself and alone, the point, the intention, of this curriculum. As such, the fact that if you think a little, the tenets cancel one another out, is considered trivial. That they serve their true purpose of revealing people as bigots is paramount—sacrosanct, as it were. Third Wave Antiracism’s needlepoint homily <em>par excellence</em> is the following:</p><blockquote><p>Battling power relations and their discriminatory effects must be the central focus of all human endeavor, be it intellectual, moral, civic or artistic. Those who resist this focus, or even evidence insufficient adherence to it, must be sharply condemned, deprived of influence, and ostracized.</p></blockquote><p><strong>Third Wave Antiracism is losing innocent people jobs.</strong> It is coloring, detouring and sometimes strangling academic inquiry. It forces us to render a great deal of our public discussion of urgent issues in doubletalk any 10-year-old can see through. It forces us to start teaching our actual 10-year-olds, in order to hold them off from spoiling the show in that way, to believe in sophistry in the name of enlightenment. On that, Third Wave Antiracism guru Ibram X. Kendi has written a book on how to raise antiracist children called <em>Antiracist Baby</em>. You couldn’t imagine it better: Are we in a Christopher Guest movie? This and so much else is a sign that Third Wave Antiracism forces us to pretend that performance art is politics. It forces us to spend endless amounts of time listening to nonsense presented as wisdom, and pretend to like it.</p><p>I write this viscerally driven by the fact that all of this supposed wisdom is founded in an ideology under which white people calling themselves our saviors make black people look like the dumbest, weakest, most self-indulgent human beings in the history of our species, and teach black people to revel in that status and cherish it as making us special. Talking of <em>Antiracist Baby</em>, I am especially dismayed at the idea of this indoctrination infecting my daughters’ sense of self. I can’t always be with them, and this anti-humanist ideology may seep into their school curriculum. I shudder at the thought: teachers with eyes shining at the prospect of showing their antiracism by teaching my daughters that they are poster children rather than individuals. </p><p>Ta-Nehisi Coates in <em>Between the World and Me</em> wanted to teach his son that America is set against him; I want to teach my kids the reality of their lives in the 21st&nbsp;rather than early-to-mid-20th century. Lord forbid my daughters internalize a pathetic—yes, absolutely pathetic in all of the resonances of that word—sense that what makes them interesting is what other people think of them, or don’t.</p><p>Many will see me as traitorous in writing this as a black person. They will not understand that I see myself as serving my race by writing it. One of the grimmest tragedies of how this perversion of sociopolitics makes us think (or, not think) is that it will bar more than a few black readers from understanding that I am calling for them to be treated with true dignity. However, they and everyone else should also realize: I know quite well that white readers will be more likely to hear out views like this when written by a black person, and consider it nothing less than my duty as a black person to write it.</p><p>A white version of this would be blithely dismissed as racist. I will be dismissed instead as self-hating by a certain crowd. But frankly, they won’t really mean it, and anyone who gets through <a href="https://johnmcwhorter.substack.com/p/the-elect-neoracists-posing-as-antiracists">my new book</a> on this subject, which I am now publishing in serial, will see that whatever traits I harbor, hating myself or being ashamed of being black is not one of them. And we shall move on. As in, to realizing that what I am documenting matters, and matters deeply. Namely, that America’s sense of what it is to be intellectual, moral, or artistic; what it is to educate a child; what it is to foster justice; what is to express oneself properly; what it is to be a nation—all is being refounded upon a religion. </p><p>This is directly antithetical to the very foundations of the American experiment. Religion has no place in the classroom, in the halls of ivy, in our codes of ethics, or in deciding how we express ourselves, and almost all of us spontaneously understand that and see any misunderstanding of the premise as backward. Yet since about 2015, a peculiar contingent has been slowly headlocking us into making an exception, supposing that this new religion is so incontestably good, so gorgeously surpassing millennia of brilliant philosophers’ attempts to identify the ultimate morality, that we can only bow down in humble acquiescence.</p><p>But a new religion in the guise of world progress is not an advance; it is a detour. It is not altruism; it is self-help. It is not sunlight; it is fungus. It’s time it became ordinary to call it for what it is and stop cowering before it, letting it make people so much less than they—black and everything else—could be.</p><p><strong>Third Wave Antiracism exploits modern Americans’ fear</strong> of being thought racist, using this to promulgate an obsessive, self-involved, totalitarian and unnecessary kind of cultural reprogramming. One could be excused for thinking this glowering kabuki is a continuation of the Civil Rights efforts of yore, the only kind of new antiracism there could be. Its adherents preach with such contemptuous indignation, and are now situated in the most prestigious and influential institutions in the land—on their good days they can seem awfully “correct.”</p><p>However, there is nothing correct about the essence of American thought and culture being transplanted into the soil of a religious faith. Some will go as far as to own up to it being a religion, and wonder why we can’t just accept it as our new national creed. The problem is that on matters of societal procedure and priorities, the adherents of this religion—true to the very nature of religion—cannot be reasoned with. They are, in this, medievals with lattes.</p><p>We need not wonder what the basic objections will be: Third Wave Antiracism isn’t really a religion; I am oversimplifying; I shouldn’t write this without being a theologian; it is a religion but it’s a good one; and so on. I will get all of that out of the way as we go on, and then offer some genuine solutions. But first, what this is not.</p><ol><li><p><em>It is not an argument against protest.</em> I am not arguing against the basic premises of Black Lives Matter, although I have had my differences with some of its offshoot developments. I am not arguing that the Civil Rights movement of the 1950s and 1960s would have been better off sticking to quiet negotiations. I am not arguing against the left. I am arguing against a particular strain of the left that has come to exert a grievous influence over American institutions, to the point that we are beginning to …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/john-mcwhorter-the-neoracists">https://www.persuasion.community/p/john-mcwhorter-the-neoracists</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/john-mcwhorter-the-neoracists</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079002</guid>
            <pubDate>Tue, 09 Feb 2021 15:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leveraging the Go Type System]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 104 (<a href="https://news.ycombinator.com/item?id=26078865">thread link</a>) | @gopherguides
<br/>
February 9, 2021 | https://www.gopherguides.com/articles/leveraging-the-go-type-system | <a href="https://web.archive.org/web/*/https://www.gopherguides.com/articles/leveraging-the-go-type-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <div>
    <section>  </section> <string></string> <section><p>If you haven't worked in a typed language before, it may not be obvious at first the power that it brings.  This article will show you how to leverage the type system to make your code easier to use and more reusable.</p> <h4>Target Audience</h4> <p>This article is aimed at developers that are new to Go and have little to no Go experience.</p> <h2>The Problem</h2> <p>For this article, we will look at how to handle <code language="plain">categorical</code> data.  In this case, specifically how to handle the <code language="plain">genre</code> category for classifying a book.</p> <p>To start, we'll define a data structure for a <code language="plain">Book</code> , in which we'll want to categorize it via the <code language="plain">genre</code> :</p> <pre><code language="plain" snippet="book" src="./src/v1/books.go">package books

type Book struct {
	ID    int
	Name  string
	Genre string
}</code></pre>   <p>Now that we have the book defined, let's go ahead and define some constants for <code language="plain">genre</code> :</p> <pre><code language="plain" snippet="genre" src="./src/v1/books.go">const (
	Adventure     = "Adventure"
	Comic         = "Comic"
	Crime         = "Crime"
	Fiction       = "Fiction"
	Fantasy       = "Fantasy"
	Historical    = "Historical"
	Horror        = "Horror"
	Magic         = "Magic"
	Mystery       = "Mystery"
	Philosophical = "Philosophical"
	Political     = "Political"
	Romance       = "Romance"
	Science       = "Science"
	Superhero     = "Superhero"
	Thriller      = "Thriller"
	Western       = "Western"
)</code></pre>   <p>So far, this seems fine.  However, the <code language="plain">genre</code> constants are strings.  While this makes for a very "humanized" way of reading the code, it's not very efficient as it pertains to a computer program.  Strings will take up more storage space, and more memory in the program (not to mention if we stored millions of data records to a database).  As such, we really want to use a smaller data type to represent this data.</p> <p>In Go, one way we can do this is to create constants that are based on the <code language="plain">int</code> type.</p> <pre><code language="plain" snippet="genre" src="./src/v2/books.go">const (
	Adventure     = 1
	Comic         = 2
	Crime         = 3
	Fiction       = 4
	Fantasy       = 5
	Historical    = 6
	Horror        = 7
	Magic         = 8
	Mystery       = 9
	Philosophical = 10
	Political     = 11
	Romance       = 12
	Science       = 13
	Superhero     = 14
	Thriller      = 15
	Western       = 16
)</code></pre>   <p>We also need to change the <code language="plain">Book</code> structure to now represent <code language="plain">Genre</code> as an int:</p> <pre><code language="plain" snippet="book" src="./src/v2/books.go">type Book struct {
	ID    int
	Name  string
	Genre int
}</code></pre>   <p>While we now have a more effecient memory model for <code language="plain">Genre</code> , it's not as "human" friendly.  If I print out the value of a <code language="plain">Book</code> , we now just get an integer value.  To show this, we'll write a quick test showing the output:</p> <pre><code language="plain" snippet="test" src="./src/v2/books_test.go">package books

import (
	"testing"
)

func TestGenre(t *testing.T) {
	b := Book{
		ID:    1,
		Name:  "All About Go",
		Genre: Magic,
	}

	t.Logf("%+v\n", b)

	if got, exp := b.Genre, 8; got != exp {
		t.Errorf("unexpected genre.  got %d, exp %d", got, exp)
	}
}</code></pre>   <p>And here is the output.</p> <pre><code language="plain" snippet="output" src="./src/v2/books_test.go">$ go test -v ./...
=== RUN   TestGenre
    books_test.go:14: {ID:1 Name:All About Go Genre:8}
--- PASS: TestGenre (0.00s)
PASS
ok      github.com/gopherguides/corp/_blog/types/leveraging-types/src/v2     (cached)</code></pre>   <p>Notice that the <code language="plain">Genre</code> just shows a value of <code language="plain">8</code> .  Any time we debug the code, or write a report, etc, we now need to figure out what <code language="plain">8</code> actually represents for a human being.</p> <p>To do this, we can write a helper function that takes the <code language="plain">Genre</code> value, and determines what the "human" representation should be:</p> <pre><code language="plain" snippet="string" src="./src/v2/books.go">func GenreToString(i int) string {
	switch i {
	case 1:
		return "Adventure"
	case 2:
		return "Comic"
	case 3:
		return "Crime"
	case 4:
		return "Fiction"
	case 5:
		return "Fantasy"
	case 6:
		return "Historical"
	case 7:
		return "Horror"
	case 8:
		return "Magic"
	case 9:
		return "Mystery"
	case 10:
		return "Philosophical"
	case 11:
		return "Political"
	case 12:
		return "Romance"
	case 13:
		return "Science"
	case 14:
		return "Superhero"
	case 15:
		return "Thriller"
	case 16:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <h2>A Better Way</h2> <p>While all the above code works fine, it's really missing some key points.</p> <ul><li><p>If a value for a <code language="plain">Genre</code> has to change in the future, we not only have to change the constant value, but we also have to update the <code language="plain">GenreToString</code> function.  If we don't, this will create a bug in our code.</p></li> <li><p>We aren't leveraging the type system to encapsulate this behavior for <code language="plain">Genre</code> .  We'll show you what we mean by that shortly.</p></li></ul> <p>The first thing we really need to do is write a more resilient <code language="plain">GenreToString</code> function.  What we mean by resilient is that even if the value of the <code language="plain">Genre</code> constant changes in the future, the <code language="plain">GenreToString</code> function will not need to change.</p> <p>The correct way to do that is no longer use hard coded values, but use the value of the constant themselves:</p> <pre><code language="plain" snippet="string" src="./src/v3/books.go">func GenreToString(i int) string {
	switch i {
	case Adventure:
		return "Adventure"
	case Comic:
		return "Comic"
	case Crime:
		return "Crime"
	case Fiction:
		return "Fiction"
	case Fantasy:
		return "Fantasy"
	case Historical:
		return "Historical"
	case Horror:
		return "Horror"
	case Magic:
		return "Magic"
	case Mystery:
		return "Mystery"
	case Philosophical:
		return "Philosophical"
	case Political:
		return "Political"
	case Romance:
		return "Romance"
	case Science:
		return "Science"
	case Superhero:
		return "Superhero"
	case Thriller:
		return "Thriller"
	case Western:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <p>Ok, that's much cleaner (and readable), but we still haven't solved the fact that when we print it out, it shows a data value ( <code language="plain">int</code> ), and not a "human" readable value.</p> <h2>Types to the Rescue</h2> <p>Instead of using a generic <code language="plain">int</code> type for <code language="plain">Genre</code> , we can create our own type based on an existing type.  In this case, we'll create a new type called <code language="plain">Genre</code> based on the <code language="plain">int</code> type:</p> <pre><code language="plain" snippet="genre" src="./src/v4/books.go">type Genre int</code></pre>   <p>Now, we'll define our constants as <code language="plain">Genre</code> types:</p> <pre><code language="plain" snippet="constants" src="./src/v4/books.go">const (
	Adventure     Genre = 1
	Comic         Genre = 2
	Crime         Genre = 3
	Fiction       Genre = 4
	Fantasy       Genre = 5
	Historical    Genre = 6
	Horror        Genre = 7
	Magic         Genre = 8
	Mystery       Genre = 9
	Philosophical Genre = 10
	Political     Genre = 11
	Romance       Genre = 12
	Science       Genre = 13
	Superhero     Genre = 14
	Thriller      Genre = 15
	Western       Genre = 16
)</code></pre>   <p>So far, the code doesn't really feel different.  However, now that <code language="plain">Genre</code> is it's own type, we can add methods to it.  This allows us to encapsulate the "human" behavior we want to the type, and not as a generic function.</p> <p>To do this, we'll add a <code language="plain">String</code> method to the <code language="plain">Genre</code> type:</p> <pre><code language="plain" snippet="string" src="./src/v4/books.go">func (g Genre) String() string {
	switch g {
	case Adventure:
		return "Adventure"
	case Comic:
		return "Comic"
	case Crime:
		return "Crime"
	case Fiction:
		return "Fiction"
	case Fantasy:
		return "Fantasy"
	case Historical:
		return "Historical"
	case Horror:
		return "Horror"
	case Magic:
		return "Magic"
	case Mystery:
		return "Mystery"
	case Philosophical:
		return "Philosophical"
	case Political:
		return "Political"
	case Romance:
		return "Romance"
	case Science:
		return "Science"
	case Superhero:
		return "Superhero"
	case Thriller:
		return "Thriller"
	case Western:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <p>Now, we'll be able to use the <code language="plain">String</code> method when we want to see what the "human" value of a <code language="plain">Genre</code> is:</p> <pre><code language="go">b := Book{
	ID:    1,
	Name:  "All About Go",
	Genre: Magic,
}
fmt.Println(b.Genre.String())</code></pre> <p>Output:</p> <pre><code language="sh">Magic</code></pre> <h2>Magic Formatting</h2> <p>In Go, if you add a <code language="plain">String</code> method to any type, the <code language="plain">fmt</code> package will now use your <code language="plain">String</code> method to "pretty print" the representation of your type.  Because of this, we will now see that if we print out the <code language="plain">book</code> in our tests, we get a "human-readable" <code language="plain">Genre</code> as well:</p> <pre><code language="plain" snippet="test" src="./src/v4/books_test.go">func TestGenre(t *testing.T) {
	b := Book{
		ID:    1,
		Name:  "All About Go",
		Genre: Magic,
	}

	t.Logf("%+v\n", b)

	if got, exp := b.Genre.String(), "Magic"; got != exp {
		t.Errorf("unexpected genre.  got %q, exp %q", got, exp)
	}
}</code></pre>   <p>Output:</p> <pre><code language="plain" snippet="output" src="./src/v4/books_test.go">$ go test -v -run=TestGenre -count=1 .
=== RUN   TestGenre
    books_test.go:16: {ID:1 Name:All About Go Genre:Magic}
--- PASS: TestGenre (0.00s)
PASS
ok      book    0.059s</code></pre>   <p>We now see the value for <code language="plain">Genre</code> in the printed output is <code language="plain">Magic</code> , and not <code language="plain">8</code> . It's also important to note that our test actually didn't change, only the way in which we leveraged our new type for <code language="plain">Genre</code> .</p> <h2>What about Iota?</h2> <p>For those of you that are familiar with Go already, you might have looked at this problem and asked "Why didn't you just use iota?". <a href="https://github.com/golang/go/wiki/Iota" target="_blank">Iota</a> is an identifier that you can use in Go to also create incrementing number constants.  While there are several reasons I didn't use iota here, I did dedicate an entire article to the topic.  Read all about it in <a href="https://www.gopherguides.com/articles/how-to-use-iota-in-golang" target="_blank">Where and When to use Iota in Go</a> .</p> <h2>Summary</h2> <p>While this example was purposefully basic in nature, it illustrates the power of defining your own type, and leveraging the type system in Go to create more resilient, readable, and reusable code.</p> <h3>Want More?</h3> <p>Check out our previous article, <a href="https://www.gopherguides.com/articles/embracing-the-go-type-system" target="_blank">Embracing the Go Type System</a> and learn how to use the type system to avoid common mistakes in Go.</p></section>
  </div>
  
</div></div>]]>
            </description>
            <link>https://www.gopherguides.com/articles/leveraging-the-go-type-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078865</guid>
            <pubDate>Tue, 09 Feb 2021 15:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple 11.2 GHz radio telescope (Hardware) (2020)]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26078761">thread link</a>) | @_Microft
<br/>
February 9, 2021 | https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/ | <a href="https://web.archive.org/web/*/https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
					
					<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg"><img data-attachment-id="14895" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/10ghzradiotelescope1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg" data-orig-size="1044,890" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10GHzRadiotelescope1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-300x256.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg" alt="" width="550" height="469" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-300x256.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-768x655.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg 1044w" sizes="(max-width: 550px) 100vw, 550px"></a></p>
<p><em><strong>Abstract : </strong><span lang="en">In this post we describe the construction of a small amateur radio telescope operating at the frequency of 11.2 GHz. The construction of the radio telescope takes advantage of the satellite TV market which has made it easy and cheap to find parabolic reflector antennas with relative illuminator (feed horn) and LNB block (low noise amplifier-frequency converter). The performances of a similar instrument are naturally rather limited, however they still allow to make interesting observations of some of the most intense radio sources.</span></em></p>
<h3>Introduction</h3>
<p>Radio astronomy is a difficult and fascinating science. It requires the use of bulky and expensive antennas, uses sophisticated radio-electronic technologies and sophisticated algorithms for signal processing. At first glance it would seem completely beyond the reach of an “amateur”. In reality it is possible to make interesting radio astronomical observations even at an amateur level.<br>
On our site we have already described some radio astronomy projects for specific applications:</p>
<ul>
<li><a href="http://physicsopenlab.org/2020/05/03/loop-antenna-for-very-low-frequency/">Loop Antenna for Very Low Frequency</a></li>
<li><a href="http://physicsopenlab.org/2020/05/07/vlf-receiver-for-sid-monitoring/">VLF Receiver for SID Monitoring</a></li>
<li><a href="http://physicsopenlab.org/2020/07/20/horn-antenna-for-the-21cm-neutral-hydrogen-line/">Horn Antenna for the 21cm Neutral-Hydrogen Line</a></li>
<li><a href="http://physicsopenlab.org/2020/07/26/sdr-based-receiver-for-the-21-cm-neutral-hydrogen-line/">Low-Noise SDR-Based Receiver for the 21cm Neutral-Hydrogen Line</a></li>
<li><a href="http://physicsopenlab.org/2020/07/26/gnuradio-software-for-the-21-cm-neutral-hydrogen-line/">GNURadio Software for 21cm Neutral-Hydrogen Line</a></li>
</ul>
<p>Now we want to try to make an “amateur” radio telescope based on the principle of the <strong>radiometer</strong>. This is certainly not the place to give detailed information on radio astronomy and radio telescopes (there is a lot of information on the net and specific texts), so we limit ourselves to providing some hints on the main points that guided us in the construction of the radio telescope.</p>
<p>Radio astronomy studies celestial bodies by analyzing the radio waves emitted by objects in the sky: any object emits electromagnetic waves through various physical processes (thermal and non-thermal), these waves are picked up by the antenna and analyzed with appropriate instruments: in general the characteristics of the captured signal are no different from those that characterize a <strong>broad spectrum electrical noise</strong>. The purpose of the radio telescope is to pick up this radiation and measure the signal strength, such an instrument is called a radiometer. To be precise, we speak of power per unit area and per unit of bandwidth and is expressed in Jansky&nbsp;: <strong>1Jy = 10<sup>-26</sup> W/m<sup>2</sup> Hz</strong>.</p>
<p>The range of radio frequencies useful for radio astronomy observations is between <strong>20 MHz</strong> and about <strong>20 GHz</strong>: below 20 MHz there is absorption by the ionosphere, above 20 GHz there is absorption by of the gases present in the atmosphere.</p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">To choose the most suitable frequency band for an amateur radio telescope we must make a compromise between the observation possibilities and the cost and feasibility constraints. The frequency spectrum of the radio-source emissions depends on the underlying physical process: for “thermal” emissions such as the sun or the moon, the intensity follows the <strong>law of the black body</strong> with maximums at high frequencies (according to the approximation of Rayleigh-Jeans<strong> I ∝ 1/λ<sup>4</sup></strong>), while for non-thermal emissions (for example synchrotron emission) the maximums are at lower frequencies, as can be seen in the graph below which shows the intensity of some radio sources as a function of frequency.</span><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png"><img data-attachment-id="14927" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/radiosorgenti/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" data-orig-size="658,756" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="radiosorgenti" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti-261x300.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" alt="" width="450" height="515"></a></p>
<p>As we know the dimensions of the antenna are related to the wavelength of the radiation to be received, furthermore our antenna must be sufficiently directive, otherwise it would be practically useless: this means that to receive frequencies below 1 GHz the dimensions of the antenna should be significantly greater than 1m: large antennas are expensive and difficult to move.<br>
Another aspect to consider is external radio interference. The ether, especially in the city, is now saturated with transmissions and RF signals from the most heterogeneous origin: radio and TV broadcasting, cellular networks, WiFi networks, disturbances from power lines, etc …. Not having the possibility to install the radio telescope in “quiet” places we must choose a frequency band that is not too disturbed.</p>
<p>For the reasons described above, the choice is almost obligatory: the <strong>10-12 GHz frequency band</strong> is the one that seems most suitable for an amateur project like ours. At these frequencies, parabolic reflector antennas and devices designed for satellite television can be re-used. The costs of the equipment are affordable, the spatial resolution of the antenna is quite good and the interference is low (basically broadcasting satellites) and easily avoidable.<br>
Working at lower frequencies would make it possible to easily receive more radio sources but with a considerable increase in terms of costs, not to mention the problem of interference.</p>
<h3>Parabolic Dish Antenna</h3>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The antenna we found on the second-hand market is a <strong>prime focus dish</strong> with a diameter of 120 cm. For radio astronomy applications it is better that the dish is of the prime focus type: in these antennas the feed horn is placed in the focus of the dish. In offset-type dishes, the feed-horn is not placed in the center but on the side, this type has constructive advantages but is more difficult to aim to the source than the prime focus.</span></p>
<p dir="ltr" data-placeholder="Traduzione">For this antenna we can calculate the gain and the directivity intended as half power band width HPBW (half power band width) :</p>
<p><strong>G = η*(π*D/λ) = 40 dB</strong></p>
<p><strong>HPBW = 65*λ/D = 1.45°</strong></p>
<p>Where<br>
<strong>η : efficiency = 0.5</strong><br>
<strong>D : diameter = 120 cm</strong><br>
<strong>λ : wavelength = 2.68 cm (correspond to 11.2 GHz)</strong></p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The images below show the antenna and the metal structure used for manual movement.</span></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg"><img data-attachment-id="14907" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/parab1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg" data-orig-size="884,1346" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="parab1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-197x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg" alt="" width="500" height="761" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg 673w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-197x300.jpg 197w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-768x1169.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg 884w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg"><img data-attachment-id="14908" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/parab2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg" data-orig-size="844,1106" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="parab2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-229x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg" alt="" width="501" height="657" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg 781w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-229x300.jpg 229w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-768x1006.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg 844w" sizes="(max-width: 501px) 100vw, 501px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg"><img data-attachment-id="14909" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/10ghzradiotelescope2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg" data-orig-size="1062,1416" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="10GHzRadiotelescope2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-225x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg" alt="" width="500" height="667" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-225x300.jpg 225w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg 1062w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<h3>LNB</h3>
<p dir="ltr" data-placeholder="Traduzione"><span lang="en">The first component of the system is the converter-amplifier block, the so-called <strong>LNB</strong>. This is the most important component because system performance largely depends on it. Our system receives in the 10-12 GHz band, at these frequencies the use of cables is problematic, for this reason the LNB block provides for a frequency down conversion in a lower band so that normal coaxial cables can be used.<br>
</span><span lang="en">The following image shows the basic scheme of the LNB block: there is a first <strong>RF amplification stage</strong>, followed by the mixer which multiplies the RF signal with the signal generated by a <strong>local oscillator (LO)</strong>. The resulting signal contains the sum and difference frequencies, the next filter eliminates the high frequency sum components to let pass only the frequencies in the band of interest, called <strong>intermediate frequencies (IF)</strong>, which are further amplified by another amplifier stage. In practice it is a heterodyne scheme, in which the frequency of the local oscillator is fixed.</span></p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en"><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png"><img data-attachment-id="14947" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnbscheme/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" data-orig-size="377,213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LNBScheme" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme-300x169.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" alt="" width="377" height="213" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png 377w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme-300x169.png 300w" sizes="(max-width: 377px) 100vw, 377px"></a></span></p>
<p>The LNB block we use is<strong> Invacom’s SNF-031</strong> model which has<strong> low noise</strong> and <strong>good stability</strong> of the gain parameters with respect to variations in operating temperature. The actual antenna is located inside the waveguide which has a C120 flange on the outside to which the feed horn is fixed, which has the task of collecting the waves reflected by the dish and conveying them to the inside the waveguide.</p>
<p>LNB features:</p>
<ul>
<li>Operating frequency band : 10.7 – 12.75 GHz</li>
<li>Intermediate frequencies (IF) : 950 – 2150 MHz, LO = 9.75 GHz</li>
<li><strong>Noise Figure NF = 0.3 dB</strong></li>
<li><strong>Gain G = 50 – 60 dB</strong></li>
</ul>
<p>The following images show the LNB block with its feed horn fixed to the focus of the dish.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg"><img data-attachment-id="14910" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb0/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" data-orig-size="466,397" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LNB0" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0-300x256.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" alt="" width="399" height="340" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg 466w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0-300x256.jpg 300w" sizes="(max-width: 399px) 100vw, 399px"></a></p>

<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg"><img data-attachment-id="15000" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb3/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg" data-orig-size="1128,850" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LNB3" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-300x226.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg" alt="" width="550" height="415" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-300x226.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-768x579.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg 1128w" sizes="(max-width: 550px) 100vw, 550px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg"><img data-attachment-id="15001" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb4/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg" data-orig-size="1184,902" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LNB4" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-300x229.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg" alt="" width="551" height="419" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-300x229.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-768x585.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg 1184w" sizes="(max-width: 551px) 100vw, 551px"></a></p>
<h3>The Receiver</h3>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The receiver consists of the few components, shown in the following image: there is a bias-T for feeding the LNB block, a bandpass filter centered at 1420 MHZ, a wide-band amplifier and the <strong>Airspy R2 SDR receiver</strong>. The “hardware” part has the function of limiting the receiving band and giving the signal a second amplification after the LNB stage. The signal is then acquired by Airspy and subsequently processed for the determination of the total power using <strong>GNURadio</strong> software. The <strong>radiometer</strong> function is practically realized through software.</span></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png"><img data-attachment-id="14917" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/radiometer/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png" data-orig-size="1088,668" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="radiometer" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-300x184.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png" alt="" width="600" height="369" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-300x184.png 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-768x472.png 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png 1088w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><strong>Features of our receiver :</strong><br>
Frequency Band = 80 MHz<br>
G<sub>LNB</sub> = 55 dB ; NF<sub>LNB</sub> = 0.3 dB<br>
G<sub>Filter</sub> = 3.5 dB (insertion loss)<br>
G<sub>Ampli</sub> = 15 dB ; NF<sub>Ampli</sub> = 0.75 dB<br>
<strong>Gain : G<sub>LNB</sub> – G<sub>Filter</sub> + G<sub>Ampli</sub> = 55 -3.5 +15 = 66.5 dB</strong><br>
<strong>Noise Figure : F = F<sub>LNB</sub> + (F<sub>Ampli</sub> – 1)/G<sub>LNB</sub> = 0.3 dB<br>
T<sub>e</sub> = (F – 1) * T<sub>0</sub> = 20.3 °K (Receiver equivalent temperature)</strong></p>
<h4>Bias-T</h4>
<p>The Bias-T has the function of “injecting” the supply voltage to the LNB block along the coaxial cable. In practice it is a simple circuit with a coupling capacitor to filter the DC component towards the RF side and an inductance at the DC input. Obtained on eBay, it can be easily self-built but attention must be paid to the “RF” quality of the components and the shielding.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg"><img data-attachment-id="14914" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/bias-t/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" data-orig-size="709,661" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Bias-T" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T-300x280.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" alt="" width="251" height="234" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg 709w, https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T-300x280.jpg 300w" sizes="(max-width: 251px) 100vw, 251px"></a></p>
<h4>1420 MHz Band Pass Filter</h4>
<p>This filter is dedicated to amateur radioastronomers interested in the hydrogen line observations. It uses the TA2494A SAW component and measures only 50 x 10mm. It features edge pads for an easy soldering of a RF shield. Insertion loss is typically less than 3.5dB and bandwith 80MHz.</p>
<p><strong>Technical Data</strong> :<br>
Center Frequency <strong>1420MHz</strong><br>
Usable Bandpass <strong>1380-1460MHz</strong><br>
Insertion Loss, 1380 to 1460 MHz <strong>3.5dB</strong><br>
Amplitude Ripple, 1380 to 1460 MHz 1.0 dBpp<br>
VSWR, 1380 &nbsp;to 1420 MHz 1.9:1<br>
Rejection referenced to 0dB :<br>
DC to 1300 MHz 28dB<br>
1550 to 3000 MHz 30dB<br>
Impedance 50Ω<br>
Maximum Input Power Level 10 dBm</p>
<p>In the images below we show the unit and its frequency response. We have soldered two wires between the SMA female headers and we wrapped the filter with aluminum tape in order to shield the filter.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg"><img data-attachment-id="14378" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg" data-orig-size="1134,460" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="filter21cm" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-300x122.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg" alt="" width="601" height="243" srcset="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-300x122.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-768x312.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg 1134w" sizes="(max-width: 601px) 100vw, 601px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg"><img data-attachment-id="14432" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg" data-orig-size="1054,388" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="filter21cm1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-300x110.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg" alt="" width="599" height="220" srcset="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-300x110.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-768x283.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1050x388.jpg 1050w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg 1054w" sizes="(max-width: 599px) 100vw, 599px"></a></p>
<table>
<tbody>
<tr>
<td><b><i>Frequency (MHz)</i></b></td>
<td><b><i>Gain (dB)</i></b></td>
</tr>
<tr>
<td>1300</td>
<td><strong>-50</strong></td>
</tr>
<tr>
<td>1420</td>
<td><strong>-3.5</strong></td>
</tr>
<tr>
<td>1500</td>
<td><strong>-50</strong></td>
</tr>
</tbody>
</table>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png"><img data-attachment-id="14379" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" data-orig-size="873,620" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="filter21cm2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-300x213.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" alt="" width="600" height="426" srcset="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png 873w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-300x213.png 300w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-768x545.png 768w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<h4>Wideband Amplifier</h4>
<p>This unit HAB-FLTNOSAW built by UPUTRONICS is a preamp designed to go between a software defined radio receiver and an antenna. The LNA used inside is a MiniCircuits PSA4-5043. This particular model has the SAW filter removed to cover the 0.1MHz to 4GHz. There are 2 options for powering the unit : either by the USB header or via bias-tee. Devices such as the Airspy can enable bias-tee and power the device. Alternatively any mini USB cable can be used to power the device. We chose to power the unit via USB line.</p>
<p><strong>Technical Data</strong> :<br>
Gain 24db @ 100MHz -&gt; <strong>15.2db @ 1415MHz</strong><br>
<strong>NF 0.75dB</strong><br>
Supply Voltage USB or Bias tee 5V</p>
<p>In the images below we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/">https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/</a></em></p>]]>
            </description>
            <link>https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078761</guid>
            <pubDate>Tue, 09 Feb 2021 15:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need React]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26078564">thread link</a>) | @dshomoye
<br/>
February 9, 2021 | https://www.dshomoye.dev/you-may-not-need-react/ | <a href="https://web.archive.org/web/*/https://www.dshomoye.dev/you-may-not-need-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-sal="fade" data-sal-easing="ease" data-sal-duration="700"><header><h2>Interactive web pages can be created with libraries that are simpler than React: alpineJS, Svelte; or even no library at all: vanillaJS. </h2><p>February 07, 2021    |    8 min. read</p></header><section><div><p>I think React is currently the <a target="_blank" rel="noreferrer" href="https://trends.google.com/trends/explore?cat=31&amp;q=Vue.js,React,Angular"><em>de facto</em> UI library</a> for web development. And for good reason. It’s <em>relatively</em> high-performance and easy to learn, and more importantly, has a large ecosystem around it. Just about anything you want to create, there’s a good chance someone’s made it, and has it available as a package. But React is not perfect and not always the right choice. This is an exploration of libraries I’ve used and I consider to be, in certain cases, better alternatives.</p>
<h3 id="going-reactless">Going React…less?<a href="https://www.dshomoye.dev/you-may-not-need-react/#going-reactless"></a></h3>
<p>I still primarily use react, I am confidently productive writing in the hooks/functional pattern - in fact, I <em>enjoy</em> the pattern. However, I think it can be an overkill for simple use cases. Responding to events, making http calls, and substituting elements on a page, is <em>not</em> that hard at small scale. Having to transpile and bundle - fiddling with <code>webpack</code> and <code>babel</code> etc… just to get some interactivity — is a little too much. The same complaint applies to <code>Angular</code> and <code>Vue</code> (with single file components) or any other library that requires a build step and has a non-trivial runtime. For creating a new web app (site?) - its worthwhile considering something simpler than react - it will remove a lot of complication and reduce the time it takes to create a working app - and maintaining it.</p>
<p>For the most basic “sample” app: this is what a react component that has a counter looks like:</p>
<div data-language="js"><pre><code><span>import</span> <span>{</span> useState <span>}</span> <span>from</span> <span>"react"</span><span>;</span>

<span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span><span>{</span> name <span>}</span></span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span>div className<span>=</span><span>"App"</span><span>&gt;</span>
      <span>&lt;</span>p<span>&gt;</span>My name is <span>{</span>name<span>}</span><span>&lt;</span><span>/</span>p<span>&gt;</span>
      <span>&lt;</span>h1<span>&gt;</span>Button Clicked<span>:</span> <span>{</span>count<span>}</span> times<span>&lt;</span><span>/</span>h1<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>count</span> <span>=&gt;</span> count <span>+</span> <span>1</span><span>)</span><span>}</span><span>&gt;</span>Add <span>1</span><span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Most of this code is tiny compared to what the browser will <em>actually</em> run - all of the <code>JSX</code> (html-looking part) inside the <code>return</code> statement isn’t valid javascript - it’s syntactic sugar for more complex function calls to React APIs and it all gets transpiled and bundled before shipping. This is what I sometimes find unnerving about react, especially with smaller apps. It sometimes feels like too much abstraction. There are many, many alternatives to React. JavaScript isn’t exactly short on libraries (for better or worse), but I want to focus on three.</p>
<h3 id="vanillajs">VanillaJS<a href="https://www.dshomoye.dev/you-may-not-need-react/#vanillajs"></a></h3>
<p>The first option here, is, well, the “use nothing” option. Just write JavaScript, inside html (or a script file) and make use of all the native DOM (the <a target="_blank" rel="noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">document object model</a>) apis; the same ones every other library depends on anyway. The <code>"vanillaJs"</code> route. I recommend reading the tongue-in-cheek site created for <a target="_blank" rel="noreferrer" href="http://vanilla-js.com/">vanillajs</a>. It’s impressive is just how much more efficient using plain/vanilla is over adding a library - essentially a middle-man to DOM operations. This is definitely going to be the best-performing approach. Bundle size is 0Kb+ - you only have to worry about how much code <em>you</em> write. Nothing beats that. And of course, there’s no build step. Just write, save. And you’re done.</p>
<h4 id="vanilla-js-example">Vanilla JS Example<a href="https://www.dshomoye.dev/you-may-not-need-react/#vanilla-js-example"></a></h4>
<p>Here’s a working example of an incrementing button in vanilla js.</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>html</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>app<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>p</span> <span>id</span><span><span>=</span><span>"</span>label<span>"</span></span><span>&gt;</span></span>Button clicked: 0 times<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>button</span> <span>id</span><span><span>=</span><span>"</span>click<span>"</span></span><span>&gt;</span></span>Add 1<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
      <span>const</span> btn <span>=</span> document<span>.</span><span>getElementById</span><span>(</span><span>"click"</span><span>)</span><span>;</span>
      <span>const</span> label <span>=</span> document<span>.</span><span>getElementById</span><span>(</span><span>"label"</span><span>)</span><span>;</span>
      <span>let</span> clicked <span>=</span> <span>0</span><span>;</span>

      btn<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
        clicked <span>+=</span> <span>1</span><span>;</span>
        label<span>.</span>innerText <span>=</span> <span><span>`</span><span>Button clicked :</span><span><span>${</span>clicked<span>}</span></span><span> times</span><span>`</span></span><span>;</span>
      <span>}</span><span>)</span><span>;</span>
    </span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div>
<p>I consider this a clearer, more explicit code than the react example. It is <em>exactly</em> how the browser works. Creating a non-trivial web page using this vanillajs is a good learning experience; even if for no other reason than understanding how the browser APIs work.</p>
<p>**This <em>looks</em> like a stateful component in vanilla, but it’s definitely not. Based on context, it could be buggy. It’s intentionally simple, the point isn’t state management. I’m simply highlighting what’s <em>possible</em>.</p>
<h3 id="alpinejs">AlpineJS<a href="https://www.dshomoye.dev/you-may-not-need-react/#alpinejs"></a></h3>
<p>I consider alpinejs the perfect bridge between repeatedly writing code to CRUD (create, read, update, delete) DOM elements/listen for events (like above), and reaching for a full-fledged library like react. With vanilla js, these operations are as fast as they will ever get, but it also gets very redundant calling <code>document.getElementById</code>. Many <del>lazy</del> good developers will get sick of doing this, create helper functions and classes to reduce the repetition, and by the time they’re done, they would have created the ten-thousandth javascript UI library - or they might accidentally recreate alpineJS.
<a target="_blank" rel="noreferrer" href="https://github.com/alpinejs/alpine">AlpineJS</a> is a “script” in the strict meaning in html. It’s bundle comes in at 4Kb, and provides exactly 14 directives for working with the dom (plus 6 properties that I think are more for edge cases). Yes, the entire API is just 14 basic concepts to learn. It literally takes reading a readme file to learn all of alpinejs. I doubt there are a lot more frameworks that can boast such simplicity. And using alpinejs only requires adding a script tag in an html file, and…that’s it. Directives are used by adding them to the respective element, these are native dom elements, not JSX or some other syntax magic. Example:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>h1</span> <span>x-show</span><span><span>=</span><span>"</span>false<span>"</span></span><span>&gt;</span></span>I will be hidden<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span></code></pre></div>
<p><code>x-show</code> to toggle the visibility of an element, like above. <code>x-data</code> directive that creates a scope (essentially, a state) for an html element. <code>x-model</code> to 2-way bind an input element to a variable - this takes multiple lines in react, as you need to declare state, bind the value of an input (one-way) to the state, and then set up an event listener to update the state when the input changes. That gets tedious, but it needs to be done — always.
<code>x-for</code> for loops… and others in the <a target="_blank" rel="noreferrer" href="https://github.com/alpinejs/alpine#learn">docs</a>.
These directives are similar to how vue works as well. With the added benefit of not requiring any build step, and being a much smaller bundle and API.<sup><a href="https://www.dshomoye.dev/you-may-not-need-react/#notes">1</a></sup>
For adding new elements, alpine cleverly uses <a target="_blank" rel="noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template"><code>&lt;template&gt;</code></a> elements which is <em>meant</em> to be used precisely as fragments to be referenced in scripts - essentially a simpler model for what a <strong>component</strong> is in react. I really like that alpineJs embraces and properly utilizes native DOM apis this way.</p>
<p>Here’s the same counter but with alpinejs:</p>
<h4 id="alpine-js-example">Alpine JS Example<a href="https://www.dshomoye.dev/you-may-not-need-react/#alpine-js-example"></a></h4>
<p>This is a working example of a stateful component (click counter). This, just like the vanilla example, can be served as an html file, as-is - and it will work in a browser.</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>html</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>head</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>script</span> 
      <span>src</span><span><span>=</span><span>"</span>https://cdn.jsdelivr.net/gh/alpinejs/alpine@v2.x.x/dist/alpine.min.js<span>"</span></span>
      <span>defer</span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>head</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>x-data</span><span><span>=</span><span>"</span>clicks()<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>click-counter<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>p</span> <span>x-text</span><span><span>=</span><span>"</span>text<span>"</span></span><span>&gt;</span></span>Button Clicked:<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>button</span> <span>@click</span><span><span>=</span><span>"</span>increment()<span>"</span></span><span>&gt;</span></span>Add 1<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
    <span>function</span> <span>clicks</span><span>(</span><span>)</span> <span>{</span>
      <span>return</span> <span>{</span>
        clicked<span>:</span> <span>0</span><span>,</span>
        <span>get</span> <span>text</span><span>(</span><span>)</span> <span>{</span>
          <span>return</span> <span><span>`</span><span>Button Clicked </span><span><span>${</span><span>this</span><span>.</span>clicked<span>}</span></span><span> times</span><span>`</span></span><span>;</span>
        <span>}</span><span>,</span>
        <span>increment</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span>clicked <span>+=</span> <span>1</span>
      <span>}</span><span>;</span>
    <span>}</span>
  </span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div>
<h3 id="svelte">Svelte<a href="https://www.dshomoye.dev/you-may-not-need-react/#svelte"></a></h3>
<p>Another qualm I have is with react’s the virtual dom (the existence of it). It’s part of why every react app has to ship a minimum of 40kb+ of js bundle (react + react-dom) to work with react; that and its pretty extensive API. This isn’t earth-shatteringly large but it’s also not zero. And <em>not</em> using react will definitely bring that size down by a lot. Shipping very small bundle size is just great, with no downsides…? This is one of the reasons I really like <a href="https://www.dshomoye.dev/trying-rust-lang">Rust</a> - you don’t pay for what you don’t use.</p>
<p><a target="_blank" rel="noreferrer" href="https://svelte.dev/docs">Svelte</a> is akin to Rust in this sense. It <em>has no</em> runtime. All of svelte magic is done during compilation. The script that’s generated is all <em>your</em> logic with svelte helper functions added around it. Unlike vanilla and alpine however, I find svelte to be a much steeper climb when it comes to learning. I built a basic <a target="_blank" rel="noreferrer" href="https://github.com/dshomoye/image-my-contact">contact image generator</a> with svelte to learn it and that was definitely not as simple as working alpinejs (an admittedly very high bar). So yes, svelte is probably as complex as react, to learn, but actually functions much simpler than react.</p>
<p>For example, to create a stateful component in svelte looks like:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
	count <span>=</span> <span>0</span> 
	<span>export</span> name <span>=</span> <span>""</span><span>;</span> 
	<span>const</span> <span>increment</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> count <span>+=</span> <span>1</span><span>;</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>

<span><span><span>&lt;</span>div</span><span>&gt;</span></span>
	<span><span><span>&lt;</span>p</span><span>&gt;</span></span>My name is {name}<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
	<span><span><span>&lt;</span>p</span><span>&gt;</span></span>count: {count} <span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span><span>on:</span>click</span><span><span>=</span>{increment}</span><span>&gt;</span></span>Add 1<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<p>Updating state is just a reassignment of that variable. I think this is more natural than in react. Although, I still prefer the functional/no mutation approach in react, since it reduces chances of unintentional state updates and the bugs that come with that.</p>
<p>And for a component property (values passed from a parent), its just a variable export. The reason I like Svelte, is because, it’s <em>more succinct</em> than react - you write less code to achieve essentially the same functionality. And less, well, less is more (always). Of course, the fact that Svelte is compile-time instead of a run time library is just icing on top. I would still recommend even it <em>if</em> it had a run time like react <sup><a href="https://www.dshomoye.dev/you-may-not-need-react/#notes">2</a></sup>. Just because it presents this more approachable API.</p>
<p>So yes, you <em>may</em> not need React. There’s a certain level of, <em>bliss</em> I’ll call it, when using something like alpinejs - where your html and script <strong>is</strong> your application - no more, no less. It goes to show that web development can be uncomplicated. I think the ecosystem would be a little better, if us developers focus more on Keeping It Simple.</p>
<h5 id="notes">Notes:<a href="https://www.dshomoye.dev/you-may-not-need-react/#notes"></a></h5>
<ol>
<li>Vue can technically be used as a script tag - but that’s not really how it’s expected to be used, and so most of its API is designed around a project structured with a bundler.</li>
<li>It could be debatable want “counts” as a run time. But svelte has no minimum bundle size like react does - your bundle size grows linearly with your code. I think that’s a good place to draw the line.</li>
</ol></div></section><hr></article></div>]]>
            </description>
            <link>https://www.dshomoye.dev/you-may-not-need-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078564</guid>
            <pubDate>Tue, 09 Feb 2021 15:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The media still doesn't understand what it means to own Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26078263">thread link</a>) | @giuliomagnifico
<br/>
February 9, 2021 | https://blocktalk.co/2021/02/05/the-media-still-doesnt-understand-what-it-means-to-own-bitcoin/#more-372 | <a href="https://web.archive.org/web/*/https://blocktalk.co/2021/02/05/the-media-still-doesnt-understand-what-it-means-to-own-bitcoin/#more-372">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-372">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>A story has been making the rounds today about a criminal in Germany that held over $60 million in Bitcoin before being arrested. Incredibly, the media still doesn’t understand what it means to “own” Bitcoin, claiming that the government “confiscated” the funds but “can’t unlock” them…</p>



<p>It’s a fundamental misunderstanding of Bitcoin’s underlying technology. Unlike other currencies (like cash or gold), one does not own Bitcoin simply by holding something in their material possession (in this case, a computer or a wallet). Instead, one owns Bitcoin when one has access to the Bitcoin by way of a private key.</p>



<p>So no, German prosecutors have in fact <em>not</em> “confiscated more than $60 million worth of Bitcoin.” Instead, they’ve confiscated a worthless piece of hardware.</p>



<figure></figure>



<p>The misunderstanding stems from the fact that Bitcoin is “stored” on a the public blockchain (a digital ledger that keeps track of all transactions), <em>not</em> on a personal hard drive or cryptocurrency wallet. Those devices were used to access the Bitcoin by the fraudster in this case, but the “password” that the media speaks of —&nbsp;which the prosecutors can’t access —&nbsp;is really <em>the Bitcoin itself</em>. It’s the private key associated with this criminal’s coins.</p>



<p>In this case, the criminal’s Bitcoin are <em>literally </em>stored in the criminal’s mind, and they refuse to give them up. As long as this fraudster is still alive and has functioning memory, their bitcoin will remain securely in their possession. </p>



<p>Obviously this has ramifications for a governments’ ability to properly punish criminal activity, but it’s also a radical new idea in money that provides security and true ownership to legal citizens. Just like this criminal can retain ownership of his Bitcoin despite being jailed for life, a person living under an oppressive regime can retain ownership of their Bitcoin in their mind no matter how much their government wishes to unfairly confiscate it.</p>



<p>It’s critical to understand the ramifications of this, and for that reason, it’s critical that the media understands what it means to own Bitcoin. Never in human history has money been truly trustless digital information, which clearly benefits criminals that would prefer not to part with their stash, but it also benefits law-abiding citizens who wish to truly own their wealth. </p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://blocktalk.co/2021/02/05/the-media-still-doesnt-understand-what-it-means-to-own-bitcoin/#more-372</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078263</guid>
            <pubDate>Tue, 09 Feb 2021 15:03:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top cloud-to-cloud migration woes and how to solve them]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26078139">thread link</a>) | @anticristi
<br/>
February 9, 2021 | https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/ | <a href="https://web.archive.org/web/*/https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="10070" data-elementor-settings="[]"><div><div><section data-id="b19f821" data-element_type="section"><div><div><div data-id="89793d1" data-element_type="column"><div><div><div data-id="9a54334" data-element_type="widget" data-widget_type="text-editor.default"><div><p><span>All companies that use cloud services do so for a reason. But those reasons may change. Whether motivated by the need for a multi-cloud strategy, expenditure minimization, legislative or regulatory demands, or simply to get closer to end users, many organizations find themselves migrating from one cloud to another. Cloud-to-cloud migration for a non-trivial application contains a lot of unknown unknowns. This causes stress and uncertainty for a CTO. To help shed some light based on years of experience in the field, we have asked senior cloud architect Lars Larsson at Elastisys, to list some of these issues.</span></p></div></div></div></div></div></div></div></section><section data-id="f9b26b8" data-element_type="section"></section><section data-id="8342740" data-element_type="section"><div><div><div data-id="8117dc4" data-element_type="column"><div><div><div data-id="927e5d2" data-element_type="widget" data-widget_type="icon-list.default"><div><ul><li> <span> 		</span> <span>Cloud providers offer a wide range of services, each with their own associated costs. Make sure to fully understand the situation as you make your calculations.</span></li><li> <span> 		</span> <span>Providers tend to lock in customers via well-integrated services. These may make migration more difficult. </span></li><li> <span> 		</span> <span>Make clear inventory of features and functionality your application requires of a managed service. These may or may not match what other cloud providers offer.</span></li><li> <span> 		</span> <span>Also make an inventory of the tools and services supporting your organizational processes.</span></li><li> <span> 		</span> <span>Take all these inventories into account to calculate your total cost of ownership for any cloud-to-cloud migration.</span></li><li> <span> 		</span> <span>Use cloud native technologies to decouple your application and organization from the services offered by a particular cloud provider. This makes migration easier in the future.</span></li></ul></div></div></div></div></div></div></div></section><section data-id="125eda7" data-element_type="section"><div><div><div data-id="1d3e9e2" data-element_type="column"><div><div><div data-id="87019f1" data-element_type="widget" data-widget_type="heading.default"><p><h2>1. Pricing models vary wildly</h2></p></div></div></div></div></div></div></section><section data-id="f40acad" data-element_type="section"><div><div><div data-id="76c0b20" data-element_type="column"><div><div><div data-id="cf73dc9" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p dir="ltr">Most companies have been hit by that one cloud bill that surprised them. Some services or features wound up costing far more than originally anticipated.&nbsp;</p><p dir="ltr">Are you considering a cloud-to-cloud migration to reduce operational costs? If so, please take a long and hard look at the various costs in each of the clouds. Because each service has a different cost model, making it very difficult to compare accurately. You really need to get to the bottom of it.</p><p dir="ltr">Compute and storage costs are often easy enough to compare, because those are the most obvious two. But what about other services? How much are you spending on, e.g., log handling or monitoring? Good services such as AWS CloudWatch come at a cost, especially if you use it for log handling too (AWS CloudWatch Logs). Are you heavily using a managed database service? A queueing or pub/sub service?</p><p dir="ltr">Avoid feeling like that one time the surprise cloud bill hit you in the face by doing your homework this time. You are wiser from the experience, after all.</p><p dir="ltr">Network transfers in and out of the cloud can also vary by quite a large amount. The three major providers will give you incoming network traffic for free, but charge you for the outgoing traffic. Smaller, regional, cloud providers will often have higher compute and storage costs, but not charge you for network traffic. Or include a much larger amount of it in a free tier offering.</p><p dir="ltr"><span>Overwhelming? I get it. It sure looks that way at first glance! But it doesn’t have to be. My trick is to look at your past few detailed billing statements, and map those costs to your new cloud provider options.</span></p></div></div></div></div></div></div></div></div></section><section data-id="bcb76c0" data-element_type="section"><div><div><div data-id="3d68089" data-element_type="column"><div><div><div data-id="1807a73" data-element_type="widget" data-widget_type="icon-list.default"><div><ul><li> <span> 		</span> <span>Key takeaway: Deeply take all aspects of your current cloud billing into account. Find the differences between offerings, and make a more informed decision. </span></li></ul></div></div></div></div></div></div></div></section><section data-id="902230f" data-element_type="section"><div><div><div data-id="0aaa810" data-element_type="column"><div><div><div data-id="214b537" data-element_type="widget" data-widget_type="heading.default"><p><h2>2. Cloud vendor-specific integrations</h2></p></div></div></div></div></div></div></section><section data-id="caba0dc" data-element_type="section"><div><div><div data-id="acc3908" data-element_type="column"><div><div><div data-id="ff71fb3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p dir="ltr">Tell me, did you adopt Kubernetes to make yourself less dependent on cloud providers? Reduce vendor lock-in? Are you now surprised at finding out that you are still locked in, but on a different level?</p><p dir="ltr">What I’ve seen is that most organizations will make sure they have highly portable application definitions. By relying on Kubernetes, the application definitions work across cloud providers.&nbsp;</p><p dir="ltr">But what I’ve also seen is that if you are using a managed Kubernetes service, your users and permissions handling is perhaps tied not to Kubernetes role-based access control (RBAC) features, but rather, to cloud-specific offerings. Like AWS Identity and Access Management (IAM). Great service, but ties you to the AWS platform.</p><p dir="ltr">Fully-managed Kubernetes services, if offered by cloud vendors themselves, serve to offer a highly integrated experience. The cost of that integration is that migration to another cloud provider becomes just that certain amount more difficult.</p><p dir="ltr">As a community, we’ve tried to fix this. But as a community of engineers, those fixes are technical. Kubernetes dictates standards for certain components or aspects. Networking has to work according to the Container Network Interface (CNI) standard. Storage according to Container Storage Interface (CSI). And so on. Great. But the business people have put in much more clever ways of locking you to the platform. This means that other less obvious aspects are more difficult to freely migrate from one cloud to another.</p><p dir="ltr"><span>So what is the option? Do you have to manage Kubernetes yourself? No. Of course not. But it may make sense to investigate managed Kubernetes offerings that are not tied to a particular cloud provider to reduce the risk of vendor lock-in. Without having to take on the task of day-to-day operations on your own, of course.</span></p></div></div></div></div></div></div></div></div></section><section data-id="d0e3450" data-element_type="section"><div><div><div data-id="ba42612" data-element_type="column"><div><div><div data-id="6dc9c60" data-element_type="widget" data-widget_type="icon-list.default"><div><ul><li> <span> 		</span> <span>Key takeaway: Investigate the ways in which cloud providers make migration more difficult due to incompatible integrations. Choose third-party vendors that are not tied to any particular cloud provider, and can offer their services on top of other cloud providers if need be.</span></li></ul></div></div></div></div></div></div></div></section><section data-id="d20c26e" data-element_type="section"><div><div><div data-id="b0441c9" data-element_type="column"><div><div><div data-id="c379b94" data-element_type="widget" data-widget_type="shortcode.default"><div><div><div data-elementor-type="wp-post" data-elementor-id="8990" data-elementor-settings="[]"><div><div><section data-id="31e2d16" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="247a263" data-element_type="column"><div><div><div data-id="0b295df" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Want to keep up with the latest in cloud and Kubernetes?</p><p>Let us deliver it straight to your inbox!</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="a9b0a1a" data-element_type="section"><div><div><div data-id="43860cf" data-element_type="column"><div><div><div data-id="9eee64e" data-element_type="widget" data-widget_type="heading.default"><p><h2>3. The devil is in the (technical) details</h2></p></div></div></div></div></div></div></section><section data-id="8655feb" data-element_type="section"><div><div><div data-id="d06fa59" data-element_type="column"><div><div><div data-id="12330c8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Almost all organizations I’ve talked to say the same thing. They went to the cloud because they wanted to get infrastructure or platform functionality on an as-a-Service basis. That is the whole point of the cloud, is it not?</span></p><p><span>So, of course, all cloud providers will offer certain services. It used to be just infrastructure as a service (virtual machines, network, and storage) but we are starting to also take, e.g., object storage and queuing services for granted. Many such services will claim to offer an “S3 compatible API” or similar. And that is a great starting point! But beware, because what does such a compatibility claim really mean?&nbsp;</span></p><p><span>AWS S3, for example, was, until December 2020, merely eventually consistent. Since </span><a href="https://www.infoq.com/news/2020/12/aws-s3-strong-consistency/"><span>their announcement</span></a><span>, it is read-after-write consistent (strong consistency). Which level of consistency would a service that is “S3 compatible” have? The old one? Or the new one? And do you have aspects of your applications that depend on that answer being one or the other? Would you know off-hand?</span></p><p><span>If you don’t, by the way, you’re in excellent company. Most people’s eyes gloss over when consistency guarantees are discussed. But then again, you don’t want to get bitten by a bug caused by wrongful assumptions, so somebody has to stay awake to figure this stuff out. Hopefully not past midnight!</span></p><p><span>Ready for another unexciting example? Queuing services, such as AWS SQS, offer certain delivery guarantees. SQS standard queues offer “at least once” guarantees. That means that a message can be delivered to your application more than once, and must have logic in place for dealing with duplicates. An application that is not prepared for this will start showing strange behavior. Especially under heavy load, because that is when the risk for multiple deliveries is higher. This is because high load means there is less time to do housekeeping for the queuing service. (Note that while SQS offers FIFO queues that have “exactly once” </span><b>processing</b><span> guarantees, however, that </span><a href="https://www.ably.io/blog/sqs-fifo-queues-message-ordering-and-exactly-once-processing-guaranteed"><span>does not imply exactly once delivery</span></a><span>.) So confusing for an application that was coded with assumptions of RabbitMQ’s “at most once” delivery guarantees!</span></p><blockquote data-cards="hidden"><div lang="en" dir="ltr"><p>Most people's eyes gloss over when consistency guarantees are discussed</p><p>Read the whole article "CTO Headaches: Top 5 cloud-to-cloud migration woes" for more<a href="https://t.co/exLGZu5SZG">https://t.co/exLGZu5SZG</a></p></div>— elastisys (@elastisys) <a href="https://twitter.com/elastisys/status/1358795732132769794?ref_src=twsrc%5Etfw">February 8, 2021</a></blockquote>  <p><span>The point I am making here is that you must make an inventory of all the cloud services you use, and what features in these are key to your applications working the way they are intended. Because </span><b>your</b><span> use case is the one that matters.</span></p><p><span><span>Cloud providers offer services that make certain trade-offs to ensure the scalability and availability </span><i><span>of their service</span></i><span>. From the perspective of individual customers and applications, the ideal trade-off choice might have been different. If you use a software such as RabbitMQ, you can configure it perfectly for your use case and requirements. Not the ones of the cloud providers. There are companies that offer managed services in a cloud-agnostic way. Especially on top of Kubernetes, which deserve your consideration.</span></span></p></div></div></div></div></div></div></div></div></section><section data-id="e3536a4" data-element_type="section"><div><div><div data-id="5535fd4" data-element_type="column"><div><div><div data-id="5ac6b9d" data-element_type="widget" data-widget_type="icon-list.default"><div><ul><li> <span> 		</span> <span>Key takeaway: Make a clear inventory of all cloud services you use, along with the required features of each for your use case. To make a cloud-to-cloud migration easier, start depending on software not tied to any particular provider.</span></li></ul></div></div></div></div></div></div></div></section><section data-id="f9e74f3" data-element_type="section"><div><div><div data-id="29f1154" data-element_type="column"><div><div><div data-id="d920fe1" data-element_type="widget" data-widget_type="heading.default"><p><h2>4. Tools supporting your processes (may) change</h2></p></div></div></div></div></div></div></section><section data-id="0aa6eff" data-element_type="section"><div><div><div data-id="93249c8" data-element_type="column"><div><div><div data-id="bed1504" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p dir="ltr">Industry wisdom and rule of thumb says that <a href="https://www.econnectivity.se/app-maintenance-cost-can-be-three-times-higher-than-development-cost/">about 70% of software costs</a> are in maintenance. Not development. Just keeping the thing running as intended. How do you address that? My take on it is to rely on smart tools and automation as much as possible. The less your staff has to work on rote menial tasks, the better. Everything they do is a process. So let’s talk about those processes.</p><p dir="ltr">Operating your mission-critical cloud application? A bunch of processes. And most, if not all, of these are supported by tools. Continuous integration and deployment, monitoring, notifications and alerting. These are the tools your operations staff is using to analyze and optimize your application deployment.</p><p dir="ltr">Great tools like AWS CloudWatch offer insight into monitoring, logging (CloudWatch Logs), and containerized workloads (CloudWatch Container Insights). Your team probably depends on them. But they are specific to a particular cloud vendor.</p><p dir="ltr">If you did like many of the organizations I’ve talked to over the years, you may have taken the deep dive into them. And now your processes are …</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</a></em></p>]]>
            </description>
            <link>https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078139</guid>
            <pubDate>Tue, 09 Feb 2021 14:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Develop Transformative Tools for Thought]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26078115">thread link</a>) | @dhruvparamhans
<br/>
February 9, 2021 | https://numinous.productions/ttft/ | <a href="https://web.archive.org/web/*/https://numinous.productions/ttft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="EssayContents">
      
      <div id="EssayContentsInner">
	
	<div>

      <p>
	Part of the origin myth of modern computing is the story of a
	golden age in the 1960s and 1970s. In this story, visionary
	pioneers pursued a dream in which computers enabled powerful
	tools for thought, that is, tools to augment human
	intelligence<span> E.g., Douglas
	Engelbart, <a href="https://numinous.productions/ttft/assets/Engelbart1962.pdf">Augmenting Human
	Intellect: A Conceptual Framework</a> (1962).</span>. One of
	those pioneers, Alan Kay, summed up the optimism of this dream
	when he wrote of the potential of the personal computer:
	“the very use of it would actually change the thought
	patterns of an entire
	civilization”<span> Alan
	Kay, <a href="https://numinous.productions/ttft/assets/Kay1989.pdf">User Interface: A Personal
	View</a> (1989).</span>.
      </p>

      <p>
	It's an inspiring dream, which helped lead to modern
	interactive graphics, windowing interfaces, word processors,
	and much else. But retrospectively it's difficult not to be
	disappointed, to feel that computers have not yet been nearly
	as transformative as far older tools for thought, such as
	language and writing. Today, it's common in technology circles
	to pay lip service to the pioneering dreams of the past. But
	nostalgia aside there is little determined effort to pursue
	the vision of transformative new tools for thought.
      </p>

      <p>
	We believe now is a good time to work hard on this vision
	again. In this essay we sketch out a set of ideas we believe
	can be used to help develop transformative new tools for
	thought. In the first part of the essay we describe an
	experimental prototype system that we've built, a kind
	of <em>mnemonic medium</em> intended to augment human memory.
	This is a snapshot of an ongoing project, detailing both
	encouraging progress as well as many challenges and
	opportunities.  In the second part of the essay, we broaden
	the focus. We sketch several other prototype systems. And we
	address the question: why is it that the technology industry
	has made comparatively little effort developing this vision of
	transformative tools for thought?
      </p>

      <p>
	In the opening we mentioned some visionaries of the past. To
	those could be added many others – Ivan Sutherland,
	Seymour Papert, Vannevar Bush, and more. Online there is much
	well-deserved veneration for these people. But such veneration
	can veer into an unhealthy reverence for the good old days, a
	belief that giants once roamed the earth, and today's work is
	lesser. Yes, those pioneers did amazing things, and arguably
	had ways of working that modern technologists, in both
	industry and academia, are poorly equipped to carry on. But
	they also made mistakes, and were ignorant of powerful ideas
	that are available today. And so a theme through both parts of
	the essay is to identify powerful ideas that weren't formerly
	known or weren't acted upon. Out of this understanding arises
	a conviction that a remarkable set of opportunities is open
	today.
      </p>

      <p>
	A word on nomenclature: the term “tools for
	thought” rolls off neither the tongue nor the
	keyboard. What's more, the term “tool” implies a
	certain narrowness. Alan Kay has
	argued<span> Again, in Alan
	Kay, <a href="https://numinous.productions/ttft/assets/Kay1989.pdf">User Interface: A Personal
	View</a> (1989), among other places.</span> that a more
	powerful aim is to develop a new <em>medium for
	thought</em>. A medium such as, say,
	Adobe <em>Illustrator</em> is essentially different from any
	of the individual tools <em>Illustrator</em> contains. Such a
	medium creates a powerful immersive context, a context in
	which the user can have new kinds of thought, thoughts that
	were formerly impossible for them. Speaking loosely, the range
	of expressive thoughts possible in such a medium is an
	emergent property of the elementary objects and actions in
	that medium. If those are well chosen, the medium expands the
	possible range of human thought.
      </p>

      <p>
	With that said, the term “tools for thought” has
	been widely used since Iverson's 1950s and 1960s
	work<span> An account may be found in
	Iverson's Turing Award
	lecture, <a href="https://numinous.productions/ttft/assets/Iverson1979.pdf">Notation as a Tool
	of Thought</a> (1979). Incidentally, even Iverson is really
	describing a medium for thought, the APL programming language,
	not a narrow tool.</span> introducing the term. And so we
	shall use “tools for thought” as our catch all
	phrase, while giving ourselves license to explore a broader
	range, and also occasionally preferring the term
	“medium” when it is apt.
      </p>

      <p>
	Let's come back to that phrase from the opening, about
	changing “the thought patterns of an entire
	civilization”. It sounds ludicrous, a kind of tech
	soothsaying. Except, of course, such changes have happened
	multiple times during human history: the development of
	language, of writing, and our other most powerful tools for
	thought. And, for better and worse, computers really have
	affected the thought patterns of our civilization over the
	past 60 years, and those changes seem like just the
	beginning. This essay is a small contribution to understanding
	how such changes happen, and what is still possible.
      </p>

      <p>
	The musician and comedian Martin Mull has observed that
	“writing about music is like dancing about
	architecture”. In a similar way, there's an inherent
	inadequacy in writing about tools for thought. To the extent
	that such a tool succeeds, it expands your thinking beyond
	what can be achieved using existing tools, including
	writing. The more transformative the tool, the larger the gap
	that is opened.  Conversely, the larger the gap, the more
	difficult the new tool is to evoke in writing. But what
	writing can do, and the reason we wrote this essay, is act as
	a bootstrap. It's a way of identifying points of leverage that
	may help develop new tools for thought. So let's get on with
	it.
      </p>


      

      <h2 id="introducing-mnemonic-medium">Introducing the mnemonic medium</h2>
      
      <p>
	Few subjects are more widely regarded as difficult than
	quantum computing and quantum mechanics. Indeed, popular media
	accounts often regale (and intimidate) readers with quotes
	from famous physicists in the vein of: “anyone who
	thinks they’ve understood quantum mechanics has not understood
	quantum mechanics”.
      </p>
      
      <p>
	What makes these subjects difficult? In fact, individually
	many of the underlying ideas are not too complicated for
	people with a technical background. But the ideas come in an
	overwhelming number, a tsunami of unfamiliar concepts and
	notation. People must learn in rapid succession of qubits, the
	bra-ket notation, Hadamard gates, controlled-not gates, and
	many, many other abstract, unfamiliar notions. They're
	imbibing an entire new language. Even if they can follow at
	first, understanding later ideas requires fluency with all the
	earlier ideas. It's overwhelming and eventually disheartening.
      </p>

      <p>
	As an experiment, we have developed a
	website, <a href="https://quantum.country/"><em>Quantum
	Country</em></a>, which explores a new approach to explaining
	quantum computing and quantum
	mechanics. Ostensibly, <em>Quantum Country</em> appears to be
	a conventional essay introduction to these subjects. There is
	text, explanations, and equations, much as in any other
	technical essay. Here's an excerpt:
      </p>
			
      <p><img src="https://numinous.productions/ttft/assets/quantum_country_sample-2x.png" srcset="https://numinous.productions/ttft/assets/quantum_country_sample.png, https://numinous.productions/ttft/assets/quantum_country_sample-2x.png 2x" alt="Screenshot depicting prose and math in Quantum Country, typical of a technical essay."></p><p>
	But it's not a conventional essay. Rather, <em>Quantum
	Country</em> is a prototype for a new type of <em>mnemonic
	medium</em>. Aspirationally, the mnemonic medium makes it
	almost effortless for users to remember what they read. That
	may sound like an impossible aspiration. What makes it
	plausible is that cognitive scientists know a considerable
	amount about how human beings store long-term
	memories. Indeed, what they know can almost be distilled to an
	actionable recipe: follow these steps, and you can remember
	whatever you choose.
      </p>

      <p>
	Unfortunately, those steps are poorly supported by existing
	media.<span>For more on this argument, see
	Andy Matuschak, <a href="https://andymatuschak.org/books/">Why
	books don’t work</a> (2019).</span> Is it possible to
	design a new medium which much more actively supports
	memorization? That is, the medium would build in (and, ideally,
	make almost effortless) the key steps involved in memory. If we
	could do this, then instead of memory being a haphazard event,
	subject to chance, the mnemonic medium would make memory into a
	choice. Of course, on its own this wouldn't make it trivial to
	learn subjects such as quantum mechanics and quantum computing
	– learning those subjects is about much more than memory.
	But it would help in addressing one core difficulty: the
	overwhelming number of new concepts and notation.
      </p>
      
      <p>
	In fact, there are many ways of redesigning the essay medium
	to do that. Before showing you our prototype, please pause for
	a moment and consider the following questions: how could you
	build a medium to better support a person's memory of what
	they read?  What interactions could easily and enjoyably help
	people consolidate memories? And, more broadly: is it possible
	to 2x what people remember? 10x? And would that make any
	long-term difference to their effectiveness?
      </p>

      <p>
	Let's sketch the user experience of <em>Quantum
	Country</em>. At the time of this writing the site contains
	three mnemonic essays (i.e., particular instances of the
	mnemonic medium). We'll focus on the introductory essay,
	<a href="https://quantum.country/qcvc">“Quantum
	  Computing for the Very Curious”</a>. Embedded within
	  the text of the essay are 112 questions about that
	  text. Users are asked to create an account, and quizzed as
	  they read on whether they remember the answers to those
	  questions. Here's what the interaction looks like, as a user
	  answers three questions.
      </p>

			<video autoplay="" loop="" muted="" playsinline="">
				<source src="https://numinous.productions/ttft/assets/qc_interaction.mp4" type="video/mp4">
				<source src="https://numinous.productions/ttft/assets/qc_interaction.webm" type="video/webm">
				<source src="https://numinous.productions/ttft/assets/qc_interaction.ogv" type="video/ogg">
			</video>

      <p>
	Note that this interaction occurs within the text of the essay
	itself. Here's a zoomed-out view, so you can see how such
	questions are surrounded by essay text both above and below:
      </p>

	<p><img src="https://numinous.productions/ttft/assets/qc_zoom_out-2x.png" srcset="https://numinous.productions/ttft/assets/qc_zoom_out.png, https://numinous.productions/ttft/assets/qc_zoom_out-2x.png 2x" alt="Screenshot depicting the interactive quiz interleaved in a few paragraphs of prose."></p><p>
	We use the term <em>cards</em> for these interface elements
	pairing questions and answers.
      </p>

      <p>
	Of course, for long-term memory it's not enough for users to
	be tested just once on their recall. Instead, a few days after
	first reading the essay, the user receives an email asking
	them to sign into a review session. In that review session
	they're …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://numinous.productions/ttft/">https://numinous.productions/ttft/</a></em></p>]]>
            </description>
            <link>https://numinous.productions/ttft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078115</guid>
            <pubDate>Tue, 09 Feb 2021 14:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crackpot Cryptography and Security Theater]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077826">thread link</a>) | @pabs3
<br/>
February 9, 2021 | https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>A few years ago, when the IETF’s Crypto Forum Research Group was deeply entrenched in debates about elliptic curves for security (which eventually culminated in RFC 7748 and RFC 8032), an IT Consultant <a href="https://mailarchive.ietf.org/arch/msg/cfrg/VXLC6cj2KwecsWRhp0yJXLF9jEw/">showed up on the mailing list</a> with their homemade cipher, Crystalline.</p>



<p>Mike Hamburg <a href="https://mailarchive.ietf.org/arch/msg/cfrg/4c-nx0N9YGh6Qb3SBmM-B6ICaA8/">politely</a> informed the consultant that the CFRG isn’t the right forum for proposing new symmetric ciphers, or even new modes for symmetric ciphers, and invited them to email them off-list.</p>



<p>If you’re not familiar with the CFRG, let me just say, this was on the more patient and measured responses I’ve ever read.</p>



<p>Naturally, the author of Crystalline responded with this:</p>



<blockquote><p>I’m somewhat disappointed in your reply, as I presumed that someone with a stated interest in ciphers would be eager to investigate anything new to pop up that didn’t have obvious holes in it. It almost sounds like you have had your soul crushed by bureaucracy over the years and have lost all passion for this field.</p><cite>Full quote available <a href="https://mailarchive.ietf.org/arch/msg/cfrg/4c-nx0N9YGh6Qb3SBmM-B6ICaA8/">here</a>. It doesn’t get much better.</cite></blockquote>



<div><figure><img data-attachment-id="1390" data-permalink="https://soatok.blog/soatoktelegrams2020-14/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-14" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-14.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Really dude? (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>The discussion continued until Tony Arcieri dropped <a href="https://mailarchive.ietf.org/arch/msg/cfrg/e-jEGddvSbManBMppC8XAc5i8GY/">one of the most brutal takedowns</a> of a cryptographic design in CFRG history.</p>



<blockquote><p>I think the biggest problem though is all of this has already been pointed out to you repeatedly in other forums and you completely refuse to acknowledge that your cipher fails to meet the absolute most minimum criteria for a secure cipher.</p><cite>Tony Arcieri, landing a cryptographic 360 no-scope on Crystalline.</cite></blockquote>



<p>In spite of this mic drop moment, the author of Crystalline continued to double down and insist that a symmetric cipher doesn’t need to be indistinguishable from randomness to be secure (which, to severely understate the affairs, is simply not true).</p>



<p>Normally, when a cipher fails at the indistinguishable test, it’s subtle. This is what Crystalline ciphertexts look like.</p>



<div><figure><img data-attachment-id="2691" data-permalink="https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/crystallinecipher/" data-orig-file="https://soatok.files.wordpress.com/2021/02/crystallinecipher.png" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CrystallineCipher" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=300" data-large-file="https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=580" src="https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=1024" alt="" srcset="https://soatok.files.wordpress.com/2021/02/crystallinecipher.png 1024w, https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=150 150w, https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=300 300w, https://soatok.files.wordpress.com/2021/02/crystallinecipher.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Data encrypted with Crystalline, provided in the CFRG mailing list.</figcaption></figure></div>



<p>Modern ciphers produce something that will look like white noise, like an old TV without the cable plugged in. There should be no discernible pattern.</p>



<p>Crystalline’s author remained convinced that Crystalline’s “131072-bit keys” and claims of “information-theoretic security” were compelling enough to warrant consideration by the standards body that keeps the Internet running.</p>



<p>This was in 2015. In the year 2021, I can safely say that Crystalline adoption never really took off.</p>



<h2>Against Crackpot Crypto</h2>



<p>Instances of Crackpot Cryptography don’t always look like Crystalline. Sometimes the authors are more charismatic, or have more financial resources to bedazzle would-be <s>suckers</s>^<sup>investors</sup>. Other times, they’re less brazen and keep their designs far away from the watchful gaze of expert opinions–lest their mistakes be exposed for all to see.</p>



<p>Crackpot cryptography is considered dangerous–not because we want people to avoid encryption entirely, but because crackpot cryptography offers a false sense of security. This leads to users acting in ways they wouldn’t if they knew there was little-to-no security. Due to the strictly performative nature of these security measures, I also like to call them <strong>Security Theater</strong> (although that term is more broadly applicable in other contexts).</p>



<p>The Cryptology community has a few defense mechanisms in place to prevent the real-world adoption of crackpot cryptography. More specifically, we have pithy mottos that distill best practices in a way that usually gets the intent across. (Hey, it’s something!) Unfortunately, the rest of the security industry outside of cryptology often weaponizes these mottos to promote useless and harmful gatekeeping.</p>



<p>The best example of this is the, “Don’t roll your own crypto!” motto.</p>



<h3 id="roll-your-own">They See Me Rollin’ [My Own Crypto]</h3>



<p>Crackpots never adhere to this rule, so anyone who violates it immediately or often, with wild abandon, can be safely dismissed for kooky behavior.</p>



<p>But if taken to its literal, logical extreme, this rule mandates that nobody would ever write cryptographic code and we wouldn’t <em>have</em> cryptography libraries to begin with. So, clearly, it’s a rule meant to be sometimes broken.</p>



<p>This is why some cryptography engineers <a href="https://www.cryptofails.com/post/75204435608/write-crypto-code-dont-publish-it">soften the message a bit</a> and encourage tinkering for the sake of education. The world needs more software engineers qualified to write cryptography.</p>



<p>After all, you wouldn’t expect to hear “Don’t roll your own crypto” being levied against Jason Donenfeld (WireGuard) or Frank Denis (libsodium), despite the fact that both of those people did just that.</p>



<p>But what about <a href="https://dholecrypto.com/">a high-level library that defers to libsodium for its actual crypto implementations</a>?</p>







<p>In a twist that surprises no one, lazy heuristics have a high false positive rate. In this case, the lazy heuristic is both, “What qualifies as rolling one’s own crypto?” as well as, “When is it safe to break this rule?”</p>



<p>More broadly, though, is that these knee-jerk responses are a misfiring defense mechanism intended to stop quacks from taking all the air out of the room.</p>



<p>It doesn’t always work, though. There have been a few downright absurd instances of crackpot cryptography in the past few years.</p>



<h2>Modern Examples of Crypto Crackpottery</h2>



<h3 id="craig-wright">Craig Wright’s Sartre Signature Scam</h3>



<p>Satoshi Nakamoto is the alias of the anonymous cryptographer that invented Bitcoin. In the years since Satoshi has gone quiet, a few cranks have come out of the woodwork to claim to be the real Satoshi.</p>



<p>Craig Wright is one of the more famous Satoshi impersonators due to his <a href="https://dankaminsky.com/2016/05/02/validating-satoshi-or-not/">Sartre Signature Scam</a>.</p>



<p>Satoshi’s earliest Bitcoin transactions are public. If you can lift the public key and signature from the transaction and then replay them in a different context as “proof” that you’re Satoshi, you can produce a proof of identity that validates without having to possess Satoshi’s private key. Then you can just wildly claim it’s a signature that validates the text of some philosopher’s prose and a lot of people will believe you.</p>



<p>With a little bit of showmanship added on, you too can convince Gavin Anderson by employing this tactic. (Or maybe not; I imagine he’s learned his lesson by now.)</p>



<h3 id="time-ai">Time AI</h3>



<p>Crown Sterling’s sponsored talk at Black Hat USA 2019 is the most vivid example of crackpot cryptography in most people’s minds.</p>



<p>Even the name “Time AI” just screams buzzword soup, so it should come as no surprise that their talk covered a lot of nonsense: “quasi-prime numbers”, “infinite wave conjugations”, “nano-scale of time”, “speed of AI oscillations”, “unified physics cosmology”, and “multi-dimensional encryption technology”.</p>



<p>Naturally, this pissed a lot of cryptographers off, and the normally even-keeled Dan Guido of Trail of Bits actually called them out on their bullshit during their presentation’s Q&amp;A section.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I yelled at the Time AI guy. It’s ok to get angry at someone trying to harm people. I was shocked that more people haven’t done the same. <a href="https://t.co/Mwe7yrihgk">https://t.co/Mwe7yrihgk</a></p>— Dan Guido (@dguido) <a href="https://twitter.com/dguido/status/1159579063540805632?ref_src=twsrc%5Etfw">August 8, 2019</a></blockquote></div>
</div></figure>



<p>For most people, the story ended with a bunch of facepalms. But Crown Sterling doubled down and <a href="https://www.schneier.com/blog/archives/2019/09/crown_sterling_.html">published a press release claiming the ability to break 256-bit RSA keys</a>.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"></figure></div>



<p>Amusingly, their attack took 50 seconds–which is a lot slower than the standard RSA factoring attacks for small key sizes.</p>



<p>(For those who are missing context: In order to be secure, RSA requires public key sizes in excess of 2048 bits. Breaking 256-bit RSA should take less than a minute on any modern PC.)</p>



<h3 id="terra-quantum">Terra Quantum</h3>



<p>Earlier this week, Bloomberg news ran a story titled, <em><a href="https://archive.md/sZ1Q5">A Swiss Company Says It Found Weakness That Imperils Encryption</a></em>. If you only read the first few paragraphs, it’s really clear that the story basically boils down to, “Swiss Company realizes there’s an entire discipline of computer science dedicated to quantum computers and the risks they pose to cryptography.”</p>



<p>Here’s a quick primer on quantum computers and cryptography:</p>



<p>If a practical quantum computer is ever built, it can immediately break all of the <em>asymmetric</em> cryptography used on the Internet today: RSA, DSA, Diffie-Hellman, Elliptic Curve Cryptography, etc. The attack costs to break these algorithms vary, but are generally in the <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3&amp;c=20201002" alt="2^{32}" title="2^{32}"> range (for numbers of queries).</p>



<p>The jury is still out on whether or not quantum computers will ever be practical. Just in case, a lot of cryptographers are working on <strong>post-quantum cryptography</strong> (algorithms that are secure even against quantum computers).</p>



<p>Symmetric cryptography fares a lot better: The attack costs are roughly reduced by a factor of <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+N&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3&amp;c=20201002" alt="\sqrt N" title="\sqrt N">. This makes a 128-bit secure cipher have only a 64-bit security level, which is pretty terrible, but a 256-bit secure cipher remains at the 128-bit security level even with practical quantum computers.</p>



<p>So it’s a little strange that they open with:</p>



<blockquote><p>The company said that its research found vulnerabilities that affect symmetric encryption ciphers, including the Advanced Encryption Standard, or AES, which is widely used to secure data transmitted over the internet and to encrypt files. Using a method known as quantum annealing, the company said its research found that even the strongest versions of AES encryption may be decipherable by quantum computers that could be available in a few years from now.</p><cite>From the Bloomberg article.</cite></blockquote>



<p>Uh, no.</p>



<p>Let’s do some math: <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3&amp;c=20201002" alt="2^{32}" title="2^{32}"> calculations can be performed in <em>seconds</em> on modern computers. If we assume that practical quantum computers are also as fast as classical computers, it’s safe to assume this will hold true as well.</p>



<p>You can break 128-bit ciphers in <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3&amp;c=20201002" alt="2^{64}" title="2^{64}"> time, using <a href="https://crypto.stackexchange.com/questions/63068/attacking-aes-128-with-grovers-algorithm">Grover’s algorithm</a>. You can’t break 256-bit ciphers <a href="https://pthree.org/2016/06/19/the-physics-of-brute-force/">in any practical time</a>, even with the quantum computer speed-up. Most software prefers 256-bit AES over 128-bit AES for this reason.</p>



<p>What does <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3&amp;c=20201002" alt="2^{64}" title="2^{64}"> time look like?</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/vWXP3DvH8OQ?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>In 2012, we could break DES (which has 56-bit keys) in 24 hours with FPGAs dedicated to the task. Since each extra bit of security …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/">https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2021/02/09/crackpot-cryptography-and-security-theater/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077826</guid>
            <pubDate>Tue, 09 Feb 2021 14:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 2 (2020)]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 143 (<a href="https://news.ycombinator.com/item?id=26077823">thread link</a>) | @anuragsoni
<br/>
February 9, 2021 | https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <section>
        <div>
          <div>
            <div>
              <p>
                <a href="https://www.beginrust.com/">New: The "Begin Rust" book</a>
              </p>

              




  






      <p>
        <i>
          See a typo? Have a suggestion?
          <a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/blog/haskell-bad-parts-2.md">Edit this page on Github</a>
        </i>
      </p>

      



      <p>If you didn't see it, please check out <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">part 1 of this series</a> to understand the purpose of this. Now, for more bad parts!</p>
<h2 id="partial-functions-in-general">Partial functions (in general)</h2>
<p>Laziness very likely belongs in this list. My favorite part of criticizing laziness is how quickly people jump to defend it based on edge cases. So let's be a bit more nuanced before I later get far <em>less</em> nuanced. Laziness is <strong>obviously</strong> a good thing. Strictness is <strong>obviously</strong> a good thing. They also both suck. It depends on context and purpose. Each of them introduce different kinds of issues. The real question is: what's a more sensible default? We'll get to that another time.</p>
<p>I called this section partial functions. Am I having a senior moment? Maybe, but I intentionally started with laziness. In a strict language, function calls can result in exceptions being thrown, segfaulting occurring, or panicking. (And if I write a "Rust: The Bad Parts", believe me, I'll be mentioning panicking.) The fact that a function <em>acts</em> like it can successfully perform something, but in fact fails in a predictable way (like failing a <code>HashMap</code> lookup), it should be reflected at the type level. If not, ya dun goofed.</p>
<p>Also, if you have a language that doesn't let you reflect this information at the type level: ya dun goofed.</p>
<p>Partial functions are the antithesis of this concept. They allow you to say "yeah dude, I can <em>totally</em> give you the first value in an empty list." Partial functions are like politicians: you can tell they're lying because their lips are moving. ("But Michael," you say. "Functions don't have lips!" Whatever, I'm waxing poetical.)</p>
<p>Alright, so plenty of languages screw this up. Haskell tells those languages "hold my beer."</p>
<p><img src="https://www.snoyman.com/static/images/holdmybeer.jpg"></p><p>Haskell screws up partial functions way, way worse than other languages:</p>
<ol>
<li>It promotes a whole bunch of them in the standard libraries and <code>Prelude</code>.</li>
<li>Some libraries, like <code>vector</code> (I'm getting to you, don't worry) make it <em>really</em> confusing by providing an <code>index</code> and <code>unsafeIndex</code> function. Hint: <code>index</code> isn't really safe, it's just less unsafe.</li>
<li>There's no obvious way to search for usages of these partial functions.</li>
<li>And, by far, the worst...</li>
</ol>
<h3 id="values-are-partial-too">Values are partial too!</h3>
<p>Only in a lazy language does this exist. You call a function. You get a result. You continue working. In any other non-lazy language, that means you have a value. If I have a <code>u32</code> in Rust, I actually have a <code>u32</code> in Rust. Null pointers in languages like C and Java somewhat muddy this situation, but at least primitive types are really there if they say they're there.</p>
<p>No, not Haskell. <code>x :: Int</code> may in fact not exist. It's a lie. <code>let x = head [] :: [Int]</code> is a box waiting to explode. And you find out <em>much</em> later. And it's even worse than that. <code>let alice = Person { name = "Alice", age = someAge }</code> may give you a valid <code>Person</code> value. You can evaluate it. But Cthulhu help you if you evaluate <code>age alice</code>. Maybe, just maybe, <code>someAge</code> is a bottom value. Boom! You've smuggled a dirty bomb out.</p>
<p>I'm not advocating for removing laziness in Haskell. In fact I'm not really advocating for much of anything in this series. I'm just complaining, because I like complaining.</p>
<p>But <em>if</em> I was to advocate some changes:</p>
<ul>
<li>Deprecate partial functions</li>
<li>Introduce a naming scheme for partial functions to be more obvious</li>
<li>Introduce a compiler warning to note partial function use (with a pragma to turn off specific usages)</li>
<li>Warn by default on partial pattern matches</li>
<li>Advocate strict data fields by default</li>
</ul>
<h3 id="but-ackshualllly-infinite-loops">But ackshualllly, infinite loops</h3>
<p>Someone's gonna say it. So I'll say it. Yes, without major language changes, you can't prevent partial functions. You can't even detect them, unless Turing was wrong (and I have my suspicions.) But Haskell community, please, please learn this lesson:</p>
<p><strong>DON'T LET THE PERFECT BE THE ENEMY OF THE GOOD</strong></p>
<p>We can get rid of many of the most common partial functions trivially. We can detect many common cases by looking for partial pattern matches and usage of <code>throw</code> (again, horribly named function). "But we can't get everything" doesn't mean "don't try to get something."</p>
<h2 id="hubris">Hubris</h2>
<p>Given what I just said, we Haskellers have a lot of hubris. Each time you say "if it compiles it works," a thunk dies and collapses into a blackhole. We've got plenty of messes in Haskell that don't sufficiently protect us from ourselves. The compiler can only do as good a job as our coding standards and our libraries allow.</p>
<p>"But Haskell's at least better than languages like PHP." I mean, obviously I agree with this, or I'd be writing PHP. But since I'm being ridiculously hyperbolic here, let me make a ridiculous claim:</p>
<blockquote>
<p><strong>PHP is better than Haskell, since at least you don't get a false sense of security</strong></p>
<p><em>- Michael Snoyman, totally 100% what he actually believes, you should totally quote this out of context</em></p>
</blockquote>
<p>I've said this so many times. So I'll say it again. Using a great language with safety features is one tiny piece of the puzzle.</p>
<ul>
<li>Did you get the software requirements right?</li>
<li>Did you leverage the type system to prevent the bugs you're trying to prevent?</li>
<li>Do your underlying libraries have bugs?</li>
<li>Did you find a way to implement a function with correct types but incorrect semantics?</li>
<li>Did you host the thing on a dinky server sitting under your desk and forget that you have power outages on a daily basis?</li>
<li>Did you forget to write a single test case?</li>
<li>Do your test cases actually test anything meaningful?</li>
</ul>
<p>There are <em>so many ways</em> for software to fail outside the purview of the type system. We've got to stop thinking that somehow Haskell (or, for that matter, Rust, Scala, and other strongly typed languages) are some kind of panacea. Seriously: the PHP people at least know their languages won't protect them from anything. We should bring some of that humility back to Haskell.</p>
<p>Haskell provides me tools to help prevent certain classes of bugs, so I can spend more of my time catching a bunch of other bugs that I'm absolutely going to write. Because I'm dumb. And we need to remember: we're all dumb.</p>
<h2 id="more-partial-functions">More partial functions!</h2>
<p>You know what's worse than partial functions? Insidiously partial functions. We've all been screaming about <code>head</code> and <code>tail</code> for years. My hackles rise every time I see a <code>read</code> instead of <code>readMaybe</code>. I can't remember the last time I saw the <code>!!</code> operator in production code.</p>
<p>But there are plenty of other functions that are just as dangerous, if not more so. More dangerous because they aren't well known to be partial. They are commonly used. People don't understand why they're dangerous. And they fail only in edge cases that people aren't thinking about.</p>
<p>Exhibit A: I present <code>decodeUtf8</code>. (Thanks <a href="https://twitter.com/kerckhove_ts/status/1321390954172063745?s=20">Syd</a>.)</p>
<p>Go ahead, search your codebase. Be dismayed that you've found it present.</p>
<p>What's wrong with <code>decodeUtf8</code>? As we established last time, character encoding crap breaks stuff in production. UTF-8 works about 99% of the time, especially for people in Western countries. You'll probably forget to even test for it. And that function looks so benign: <code>decodeUtf8 :: ByteString -&gt; Text</code>.</p>
<p><strong>DO NOT BE FOOLED</strong></p>
<p>This function is a ticking time bomb. Use <code>decodeUtf8'</code> (yes, it's named that badly, just like <code>foldl'</code>) and explicitly handle error cases. Or use I/O functions that explicitly handle UTF-8 decoding errors and throw a runtime exception.</p>
<p>"I can't believe Michael still thinks runtime exceptions are a good idea." I'll get to that another time. I don't really believe they're a good idea. I believe they are omnipresent, better than bottom values, and our least-bad-option.</p>
<h2 id="law-abiding-type-classes">Law-abiding type classes</h2>
<p>Now I've truly lost it. What in tarnation could be wrong with law-abiding type classes? They're good, right? Yes, they are! The section heading is complete clickbait. Haha, fooled you!</p>
<p>There's a concept in the Haskell community that all type classes should be law-abiding. I've gone to the really bad extreme opposing this in the past with early versions of <code>classy-prelude</code>. In my defense: it was an experiment. But it was a bad idea. I've mostly come around to the idea of type classes being lawful. (Also, the original namespacing issues that led to <code>classy-prelude</code> really point out a much bigger bad part of Haskell, which I'll get to later. Stay tuned! Hint: Rust beat us again.)</p>
<p>Oh, right. Speaking of Rust: they do <em>not</em> believe in law-abiding type classes. There are plenty of type classes over there (though they call them <code>trait</code>s) that are completely ad-hoc. I'm looking at you, <code>FromIterator</code>. This is Very, Very Bad of course. Or so my Haskell instincts tell me. And yet, it makes code Really, Really Good. So now I'm just confused.</p>
<p>Basically: I think we need much more nuanced on this in the Haskell community. I'm leaning towards my <em>very</em> original instincts having been spot on. So:</p>
<ul>
<li>Law abiding type classes: great</li>
<li>Flippantly non-law-abiding type classes ala the original <code>classy-prelude</code>: bad</li>
<li>"You know what I meant" typeclasses like <code>ToContent</code> in Yesod: also great</li>
</ul>
<p>This isn't exactly in line with a "bad part" of Haskell. Up until now I've been giving a nuanced reflection on my journeys in Haskell. Let me try something better then. Ahem.</p>
<p><strong>DON'T LECTURE ME ON LAW ABIDING TYPE CLASSES AND FLAGRANTLY VIOLATE LAWS</strong></p>
<p>I'm staring at you, <code>Eq Double</code>. No, you cannot do equality on a <code>Double</code>. (And thanks again to Syd for this idea.) Rust, again, Got It Right. See <code>PartialEq</code> vs <code>Eq</code>. Floating point values do not allow for total equality. This makes things like <code>Map Double x</code> dangerous. Like, super dangerous. Though maybe not as dangerous as <code>HashMap Double x</code>, which deserves its own rant later.</p>
<p>So come down from your high horses. We don't have law abiding type classes. We have "if I close my eyes and pretend enough then maybe I have law abiding type classes."</p>
<h2 id="unused-import-warnings">Unused import warnings</h2>
<p>Haskell has a dumb set of default warnings enabled. ("I think you mean GHC, one implementation of Haskell, not …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077823</guid>
            <pubDate>Tue, 09 Feb 2021 14:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People fighting to keep Urdu alive online]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26077785">thread link</a>) | @gbseventeen3331
<br/>
February 9, 2021 | https://restofworld.org/2021/bringing-urdu-into-the-digital-age/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/bringing-urdu-into-the-digital-age/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>B</span>y the time Mudassir Azeemi wrote to Apple CEO Tim Cook in 2014, he’d tried everything he<em> </em>could think of to make it easier to type in his native language, Urdu. In 2010, the now 42-year-old Pakistani-American developed a keyboard app you could use on iOS devices; within two years, it had been downloaded over 165,000 times. But even with an Urdu-language keyboard, the characters appeared on the screen in an entirely different font.</p>



<p>“Dear Mr Tim Cook,” he wrote. “Urdu language’s beauty lies in the typeface.”</p>



<p>Spoken by nearly 170 million people in South Asia and the South Asian diaspora, Urdu is written in an alphabet derived from Arabic. But while Arabic is written in a script called <em>naskh</em>, simpler and more linear in its appearance, many other people — including Iranians, Afghans, Pakistanis, Urdu-speakers in India, and Uighur-speakers in parts of China — employ an ornate style of writing that originated in 14th-century Persia called <em>nastaʿlīq</em>. When Azeemi sat down to write his letter to Cook, nastaʿlīq was almost nowhere to be found online. To communicate in Urdu, you either had to type in naskh or spell words phonetically in Latin script.</p>



<p>Azeemi, a software developer now working and living in Silicon Valley, grew up in Pakistan’s sprawling seaside city, Karachi. As a teenager during the days of dial-up, he once racked up an internet bill that cost half of his father’s monthly salary; in his early 20s, he learned to code on one of those old calculator-sized computers called palmtops. He didn’t give much thought to Urdu’s digital future until he moved to California and became a father. Watching his children learn English through songs on YouTube, he’d felt a pang of loss — the anxiety that they might never speak or appreciate Urdu the way he does. One of the earliest apps Azeemi developed, even before the keyboard, was for nursery rhymes in Urdu.</p>



<p>These early attempts at yanking Urdu on to the internet hadn’t been particularly profitable — Azeemi says he lost over $50,000 in the process. He remained determined. In 2013, Apple introduced an Urdu keyboard for iOS devices, but, much to the chagrin of Urdu users, the default font was still naskh, the Arabic font. In Azeemi’s eyes, the solution was now pretty straightforward: operating systems — Apple, Google, Microsoft, and others — had to be persuaded to adopt nastaʿlīq.&nbsp;</p>



<p>His open letter, addressed to Cook and Apple’s chief design officer at the time, Jonathan Ive, described the need for a nastaʿlīq font on iOS platforms. “The only hurdle for us is to bring the typeface that truly represent[s] the language,” wrote Azeemi. “And every language, when it is written, shines when using the typeface which it truly presented in the world.”&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-1063733610-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-1063733610-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-1063733610-1-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-1063733610-1-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-1063733610-1-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-1063733610-1-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-1063733610-1-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A traditional calligrapher writes in Urdu at a market in India.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Stuart Freedman/InPictures/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>When Urdu calligraphers speak of nastaʿlīq, it is with deep reverence. In the subcontinent, it was the script that disseminated the Quran, considered the word of God. Mir Ali of Tabriz, a 14th-century Persian calligrapher known as the father of the script, is said to have developed it after a dream in which Ali, son-in-law of the Prophet Muhammad, instructed him to draw letters that looked like “the wings of flying geese.” Squint at an Urdu verse in nastaʿlīq, and it might very well begin to resemble a flock of birds taking flight, or a branch in bloom. Nastaʿlīq characters, <a href="https://archive.org/stream/fromconcepttocon00fush/fromconcepttocon00fush_djvu.txt">per one observation</a>, appear to “swing from the upper right to the lower left of each word as if suspended by an imaginary line.”</p>



<p>In some ways, this emphasis on the <em>form</em> of writing a language runs contrary to conventional wisdom. We tend to think of text as a means to an end, that the characters depicted are there only to convey meaning. If you could write the same Urdu word in the Arabic naskh script, even if it looked a little different — naskh is smaller, simpler, and sans serif — wasn’t the demand for digitized nastaʿlīq just a minor typographical quibble?&nbsp;</p>



<p>Nastaʿlīq, after all, is a nightmare to code. It moves right to left, like all Arabic scripts, but also slopes downward: the longer the word, the steeper the slope. The shape of each letter changes, depending on the letter that comes before and after; in a 39-letter alphabet, there are thousands of permutations. Its multifaceted nature is precisely why coders haven’t developed nastaʿlīq fonts as easily as, say, Cyrillic.</p>



<figure><blockquote><p>We tend to think of text as a means to an end, that the characters depicted are there only to convey meaning.</p></blockquote></figure>



<p>It didn’t have to be this way. As early as 1951, just four years after wresting off British rule, Pakistan — where Urdu is both the official language and played a key role in the movement for independence — set up a national printing press that could compose in both English and Urdu, a substantial investment for the young, cash-strapped country and an indication, perhaps, of Urdu’s importance for its nation-building project. But even though Monotype and Linotype, the predominant printing technology firms of the time, kept developing typefaces for the Urdu market, local publishers kept rejecting them because they just didn’t match up to the local nastaʿlīq aesthetic.&nbsp;</p>



<p>Part of the reason nastaʿlīq ran into trouble was because the technology at the time — specifically the typewriter — was built with English in mind. Subsequently, as historian Thomas S. Mullaney notes in his book, “The Chinese Typewriter,” all other languages are seen as permutations from that norm. Hebrew is English but backward. Arabic is English backward and in cursive. Russian: English with different letters. Siamese: English with too many letters. Perhaps the only major language to escape the thumb of Latin hegemony was Chinese, a script that is neither alphabetic nor syllabic, and thus <a href="https://www.wnycstudios.org/podcasts/radiolab/articles/wubi-effect">had to be imagined entirely outside the box of existing technology</a>. But nastaʿlīq, presumably not quite significant enough to send typographers back to the drawing board, remained stalled until the 1970s, its mechanical rendering nowhere close to the sweep and flourish of the handwritten script.</p>



<p>In modern-day Iran, where nastaʿlīq originated, the font changed to meet the limitations of the existing technology. Over the years, Farsi slowly developed a typographical identity that worked within the constraints of the block printing press but was stylistically different enough from the Arabic naskh to feel sufficiently “Persian.” If you pick up a newspaper in Tehran today, it looks significantly different from a paper in Karachi.&nbsp;</p>



<p>Why didn’t Urdu, and Pakistan, go down a similar typographical route as Farsi did in Iran? Stubborn fidelity to nastaʿlīq aside, one reason may be the ways in which Urdu differed from other nastaʿlīq-favoring languages. One letter, “the <em>baṛī ye</em> (ے), is particularly influential on the look of written Urdu,” writes typographer and historian Titus Nemeth in “Arabic Type-Making in the Machine Age” (2017), “and its typographic rendering is among the most challenging design questions in an Arabic font.”</p>



<p>The baṛī ye, which resembles a bent elbow, produces all sorts of mechanical obstacles with regard to kerning and the placement of dots and diacritics. Baṛī ye and letters like it posed a problem that seemed so insurmountable, in fact, that, in the 1960s — mimicking Mustafa Kemal Atatürk’s <a href="https://www.pri.org/stories/2013-06-25/some-turks-reconsidering-arabic-connection-turkish-language">mission to convert Turkish script into a Latin alphabet</a> — Pakistan’s military ruler Ayub Khan proposed officially writing Urdu in Latin letters. He was met with near-instant pushback: the nastaʿlīq script, protested local religious leaders, was an essential marker of Pakistan’s Islamic identity. Without meaningful progress in the printing process, Urdu publications in Pakistan, including dailies, continued to be written by hand well into the 1980s, armies of calligraphers scribbling furiously day and night.</p>



<hr>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/RoWURDU-031-40x23.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/RoWURDU-031-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/RoWURDU-031-400x225.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/RoWURDU-031-600x338.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/RoWURDU-031-1000x563.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/RoWURDU-031-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/RoWURDU-031-2800x1576.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p><strong>Ahmed Mirza Jamil,</strong> owner of a printing business in Karachi, inherited his love for nastaʿlīq from his father, who, in his later life, took up the daunting task of writing the Quran in his own hand. He’d completed only a third of the holy book before he fell ill and died, but his sons vowed to finish his cherished project. They photographed their father’s nine handwritten chapters, then cut and pasted his letter formations to piece together — like a jigsaw puzzle — the remaining two-thirds of the Quran. It was a staggeringly elaborate labor of love that took 14 years to complete. And it sowed the seeds for a long-awaited breakthrough in Urdu typesetting.</p>



<p>In 1980, Mirza Jamil wrote out every combination of Urdu letters that he could think of — roughly 20,000 by most accounts. These combinations, known as ligatures, became the basis of a new Urdu typeface: Noori Nastaliq, a font Jamil named after his father. It solved the difficulty posed by the shape-shifting nature of nastaʿlīq: instead of representing letters, it represented entire <em>combinations</em> of letters written together. The 20,000 ligatures were by no means exhaustive, but the chances of any other combination cropping up, Mirza Jamil reckoned, were negligible. He’d been inspired to address Urdu typographical troubles after encountering a Chinese keyboard, a 48-inch contraption with up to 500 characters, on a trip to Singapore.&nbsp;</p>



<p>“I thought, if the Chinese could do it,” he told a journalist in 1996, “so could we.”&nbsp;</p>



<p>With the advent of Noori Nastaliq, Mirza Jamil was hailed as Pakistan’s Gutenburg and bestowed with state honors. Urdu’s path to progress, <a href="http://elite.com.pk/epl/portfolio/noori-nastaliq/revolution/">one writer wrote</a>, “will be lit with the candle of Noori Nastaliq.” Still, adoption was tentative: for a while, according to the historian Nemeth, the country’s largest national newspaper, <em>Daily Jang,</em> carried typographically composed text alongside columns that were still handwritten, hoping to convince the nastaʿlīq purists that their beloved font could be printed too.&nbsp;</p>



<p>For decades, Noori Nastaliq remained the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/bringing-urdu-into-the-digital-age/">https://restofworld.org/2021/bringing-urdu-into-the-digital-age/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/bringing-urdu-into-the-digital-age/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077785</guid>
            <pubDate>Tue, 09 Feb 2021 14:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming Audio from Containers on the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077310">thread link</a>) | @amasad
<br/>
February 9, 2021 | https://blog.repl.it/audio | <a href="https://web.archive.org/web/*/https://blog.repl.it/audio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Audio brings games and projects to life! Web developers have it easy, they can publish their apps on the web and play audio using the browser API no problem. However, what about those of us that are command-line and graphics apps in other languages? Repl.it is a special place on the web where you can publish any app in any language, but so far it’s been missing audio capabilities because code executes in a container on the backend. This summer, for my internship I set out to solve this problem and make it possible to play audio in any repl in any language. In this post I’ll show you how to play audio in your repl and then I will chronicle the journey that got us here. </p>
<p><img src="https://repl.art/music-01.png" alt="music art"></p>
<h2 id="how-you-play-audio">How you play audio</h2>
<p>Before we get to the technical parts, let's talk about how you can use audio in your app or game.</p>
<p>As of this writing we support two libraries: Python and JavaScript. The Python library is built right in so you shouldn't need to install it. However, the JavaScript library you'll have to install and you can do that by simple importing (<code>@replit/audio</code>).</p>
<p>You can learn more on our <a href="https://docs.repl.it/repls/audio">docs for audio</a>.</p>
<p>Let’s take a look at a quick demo before I tell how it all works:</p>


<h2 id="how-it-works">How it works</h2>
<p>It started out with an idea, I wanted to add audio to Repl.it because I wanted to use it and many users were asking for it, so it seemed like a good project to take on.  To be honest, I thought it was going to be a lot easier than it turned out to be. I thought I’d just throw in a Pulseaudio stream over TCP, play it in the browser, and be done with it. I was wrong. But who would’ve thought that real-time audio streaming from an isolated Docker container using fake audio devices without the use of an always-on daemon would be difficult? I sure didn’t.</p>
<p>At first, my goal was to get something simple that worked. My first attempt was to use a combination of portaudio and loopback devices native to the host machine but isolated to each container but that didn’t end up working because the infrastructure was far too complicated to be maintainable and we’d have to install C libraries for each language so they could play audio. Moving on.</p>
<p>My second attempt was to prototype something so I could see how I could build the client. I wanted to make sure that I had at least one part of the setup correct.  For this attempt, I just searched for files named “PlayMeAudio.wav (or .aiff)” which would be decoded and sent to the client in a buffer when the client opened the repl. Although this worked, it was only a prototype and we didn’t ship it.</p>
<p>For my third attempt, I figured I’d decode the audio and relay that to the client via a pipe file. Although this worked, it was using a ridiculous amount of CPU in Python and just simply not fast enough. I had concerns it might be an issue in other languages as well.</p>
<p>For my final and fourth attempt, I made a request based system. Instead of decoding the audio files in userland and putting a strain on resources, I’d have the user language tell me which files to play, and we’d do the heavy lifting in Go, which is the language that we write the container service in, which we call PID1.  Although the code was a mess, it worked and ended up being the first version of audio we released to explorers, despite its many shortcomings.</p>
<p>Although it worked, this attempt had three issues: 
All files had to be at a sample rate of <code>44,000</code> hertz
All files had to have a bit depth of <code>32</code>
Only <code>.aiff</code> and <code>.wav</code> files were supported.</p>
<p>The reason for the first issue was that I couldn't find a good polyphase filter (for sample rate conversion) and I needed a C library to cross compile. This proved to be challenging, as we needed to static link it and it had libm as a dependency, which means we’d have to static link all of libc -- more on that later.  I ended up having to dynamically build it. Including its source wasn't an option because it had very large generated files, so I had to build it before we built PID1, more on this later on.</p>
<p>For the second issue, I really didn’t have an excuse other than not really understanding bit depth, but once I did I was able to quickly fix it.</p>
<p>For the third one, it wasn't so much that those files were the only ones supported - it was more so that we didn’t support <code>.mp3</code> files- for this, I ended up needing to use C again. I used minimp3 library and its Go bindings.</p>
<p>I also had plans to include <code>.opus</code> file support, so I was going to need another C library… Well to clarify, I needed both opus and opusfile. Opusfile requires opus, which requires OpenSSL, so I had to build OpenSSL the build opus and opusfile, without root. Well needless to say, this was starting to get a bit ridiculous to do more than once. I made a <a href="https://github.com/repl-it-discord/audio/">github repo</a> which would serve as a repo to house all the C libraries we needed along with the Go bindings, and I included a file I found from a source that would let me static link libm without all of libc. </p>
<p>After all of this, we have the dependencies resolved, and everything sounds good - except for one thing: Changes in audio take <code>~.74</code> -  <code>~1.48</code> seconds to take effect. Why? Well we were sending audio in chunks, instead of streaming. Every <code>~.74</code> seconds, we prepare audio and send exactly <code>32,768</code> samples (<code>2^15</code>, no particular reason for this magic number other than the buffer rarely runs out and the latency isn't unbearable) but this wasn't enough.  </p>
<p>The client was designed to append audio samples at the end of what it had scheduled, so what I did was send audio initially and then immediately send it again, so we’d give the client  <code>65,536</code> samples at the start, and send an additional <code>32,768</code> samples every <code>~.74</code> seconds. Where did I get <code>.74</code> seconds from? As we are playing the audio at <code>44,100</code> hertz, we play <code>44,100</code> samples per second - so <code>32,768/44,100</code>. </p>
<p>This setup was great for smooth audio, but I felt that the latency makes your repl experience feel rather shoddy. I mean, imagine you’re playing a game, you open the chest and go through a door. Once you go through the door, the sound from the chests plays because you as a user have that <code>.74</code> - <code>1.48</code> second buffer, which just makes using audio for games useless for anything other than background music.</p>
<p>So we had to rewrite this and unfortunately to solve the timing issue we had to complicate the solution. We made the server send overlapping buffers of samples and the client used a timing system along with a sample index the server sent to calculate and compensate for latency and try to make it “real-time” streaming.</p>
<p>Now I know this is hard to understand, in fact I was told it was also hard to code review, so I’ll do my best to illustrate it. </p>
<p>Normally, this is how our makeshift stream would look:</p>
<pre><code>Message 1: 1 2 3 4 5
Message 2:         5 6 7 8 9 
Message 3:                 9 10 11 12 13
...</code></pre><p>This keeps us from audio cutting out due to (network) latency (to an extent), allowing us for smaller buffer sizes without as much (audio) latency</p>
<p>That alone isn't very special, what's really the star of the show is for the server to be able to send:</p>
<pre><code>Message 1: 1 2 3 4 5  
Message 2:   2 3 4 5 6
Message 3:           6 7 8 9 10</code></pre><p>The client is where the difficult processing for this takes place, when we receive new samples we immediately stop playing and start playing those samples… well… mostly. </p>
<p>You see, there's still the one thing that we can’t control. Networking.  Maybe there's a <code>.1</code> second delay for one of the messages, well now look - we’re playing audio we already played!</p>
<p>So now the client has to calculate LATENCY too, which is even MORE difficult. At this point, we’re on multiple devices, and we need less than a <code>1/44,100</code> second difference in time in order to figure this out! That seemed too hard. Instead, what I did was give each message in the protocol the sample index of the first sample, i.e. the first message would have sample index <code>0</code>.  The client then determines how many samples the player has played in total and if that's greater than the sample index it will compensate for that by skipping samples. </p>
<p>Now too get back to the request system I mentioned earlier -- how does one use that? As I mentioned, there’s two libraries above for Python and JavaScript, however this should work for any language, and you’re free to implement your own libraries.</p>
<h2 id="how-do-libraries-work">How do libraries work?</h2>
<p>As mentioned above, users can determine what is played via requests to a named pipe which PID1 reads.  I opted for a simple approach for encoding - json. While making libraries is fun and all, I can’t update libraries for many languages every time I change the requests, so I figured I’d make the request system pretty simple.</p>
<p>The user’s script must only write json data to <code>/tmp/audio</code> (a named pipe) and the go script will then parse the data and fulfill the request.  However, this might error - for example the file isn't found or has invalid encoding. Since we’re sending requests through a named pipe, we can't get errors very easily.
This means that the library the client uses must determine when there’s an issue with a source being created - the setup I made for the libraries which I used would wait up to a set amount of time then if the source wasn’t created in time it times out - while this isn’t always perfect, it's better than nothing.</p>
<p>A typical request to play a tone might look like this:</p>
<pre><code>{
  <span>"Paused"</span>: <span>false</span>,
  <span>"Name"</span>: <span>"My tone"</span>,
  <span>"Type"</span>: <span>"tone"</span>,
  <span>"Volume"</span>: <span>1</span>,
  <span>"DoesLoop"</span>: <span>false</span>,
  <span>"LoopCount"</span>: <span>0</span>,
  <span>"Args"</span>: {
    <span>"Pitch"</span>: <span>400</span>,
    <span>"Seconds"</span>: <span>5</span>,
    <span>"Type"</span>: <span>1</span>,
    <span>"Path"</span>: <span>""</span>
  }
}</code></pre>
<p>A quick explanation of the above fields: </p>
<ul>
<li><code>Paused</code> - Whether the source is paused or not - this can only be set when updating the source.</li>
<li><code>Name</code> - the name of the source - this can be used to identify the source when it's being created - if it's not set the name will be set by pid1.</li>
<li><code>Type</code> - the type of the source, supported types when I wrote this are:<ul>
<li><code>wav</code> - A <code>.wav</code> file</li>
<li><code>aiff</code> - A <code>.aiff</code> file </li>
<li><code>mp3</code> - A <code>.mp3</code> file</li>
<li><code>tone</code> - A generated tone.</li>
</ul>
</li>
<li><code>Volume</code> - The volume of the source as a floating point number - <code>1</code> would be <code>100</code>%</li>
<li><code>DoesLoop</code> - Whether the source should loop or not …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/audio">https://blog.repl.it/audio</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/audio</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077310</guid>
            <pubDate>Tue, 09 Feb 2021 13:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub1s: Browse Any GitHub Project with In-Browser VSCode]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077231">thread link</a>) | @umvi
<br/>
February 9, 2021 | https://github1s.com/conwnet/github1s | <a href="https://web.archive.org/web/*/https://github1s.com/conwnet/github1s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://github1s.com/conwnet/github1s</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077231</guid>
            <pubDate>Tue, 09 Feb 2021 13:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I deploy my personal projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077182">thread link</a>) | @daveyarwood
<br/>
February 9, 2021 | https://blog.djy.io/how-i-deploy-my-personal-projects/ | <a href="https://web.archive.org/web/*/https://blog.djy.io/how-i-deploy-my-personal-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Just for fun, here is a quick run-down of how I deploy my personal projects. If
you’re reading this and you have projects of your own that you might like to
deploy, then hopefully some part of this will be helpful to you.</p>



<p>Whenever I register a domain, I use <a href="https://www.namecheap.com/">Namecheap</a>, not necessarily
because it’s the best option, but just because I’ve always found Namecheap to be
easy and intuitive, and it does everything that I need when it comes to
registering and managing domains.</p>

<p>Namecheap <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/9434/10/using-default-nameservers-vs-hosting-nameservers/">gives you a few options</a> about what DNS
nameserver to use. Depending on the project, I use either their free, default
DNS service, or I choose the “Custom DNS” option and use DigitalOcean’s
nameservers if the project is hosted there. (I’ll say more about DigitalOcean
below.)</p>

<p>Namecheap also makes it straightforward to define <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/579/2237/which-record-type-option-should-i-choose-for-the-information-im-about-to-enter/">all kinds of host
records</a>. I’m pretty far from understanding what all of
the different kinds of records (A, AAAA, ALIAS, CNAME, NS, SRV, …) are for,
but I’ve learned just enough to be able to do the basic stuff that you usually
need to do when you’re building small websites and web applications.</p>



<p>Just as an aside: When I was a kid, I learned how to write HTML and CSS, built a
lot of stupid-looking websites, and put them up on the Internet for the world
(well, mostly just my friends) to see. This was the late 90’s and early 00’s,
and as far as I could tell at the time, the only way you could do this was to
keep a copy of your website on your computer and copy the files over to your web
space any time you make changes, using an <a href="https://en.wikipedia.org/wiki/File_Transfer_Protocol">FTP</a> client. Git didn’t exist
yet, let alone GitHub Pages, and I couldn’t have told you what source control
was if you’d asked me. This felt alright to me at the time, but in retrospect,
it’s funny how painfully manual it was to deploy my websites back then.</p>

<p>Thankfully, it’s a lot easier these days to whip up a simple, nice-looking
website and make it publicly available on the Internet, even on a custom domain
with an SSL certificate.</p>

<p>When I first created this blog in 2014, I built it using <a href="https://jekyllrb.com/">Jekyll</a> and
deployed it via <a href="https://pages.github.com/">GitHub Pages</a>. This was the path of least
resistance, as GitHub did (and still does) an excellent job of documenting how
to set up your own GitHub Pages site with Jekyll. I still think this is a pretty
nice setup for new programmers who want to get into building their own websites.</p>

<p>Fun fact: this blog is <em>still</em> built using Jekyll. I’ve re-styled the template a
few times, and I’ve migrated the site away from GitHub Pages, but as much as I’m
not crazy about Jekyll, it still gets the job done well enough that I have no
interest in building it all again using some other static website generator.
Maybe if I were to start over, I would explore other options that are available
now, like <a href="https://gohugo.io/">Hugo</a> or something. But for now, Jekyll is working out just
fine.</p>

<p>I mentioned just now that at one point, I migrated this site away from GitHub
Pages. That was because I found <a href="https://www.netlify.com/">Netlify</a>. Netlify does a lot of
things, but the big thing they do is that they make it easy to automate
deploying your static sites for free. It’s trivial to take a site that you’re
deploying to GitHub Pages and convert it to use Netlify instead. Why would you
want to do that? Because Netlify gives you a lot more control over the way your
site is deployed. The reason I switched is that I ended up wanting to use some
Jekyll feature that will only work on newer versions of Jekyll, and I found that
with GitHub Pages, I couldn’t control the version of Jekyll that was used to
build the site. With Netlify, I can control pretty much everything about the
build, including which dependencies to bring in and what command to run to build
the site. Another awesome thing about Netlify is that they make it super easy to
set up your site to serve on a custom domain, and they’ll even generate an SSL
certificate for you automatically. After a quick and painless setup, you can
deploy your site by simply pushing commits to the default branch of your repo.</p>



<p>I first started using <a href="https://digitalocean.com/">DigitalOcean</a> as a way to explore having my
own <a href="https://en.wikipedia.org/wiki/Virtual_private_server">VPS</a> that I could use to deploy arbitrary static sites and web
applications. I ended up only using my VPS to host static sites, which I now
realize was kind of pointless, because I could have just used Netlify to host
all of them, and it would have been a lot easier and more convenient. But it
really wasn’t pointless, because learning how to set up a VPS was a valuable
exercise in itself.</p>

<p>If you’re curious about setting up a VPS, I will say that it’s easy and fun to
do it with DigitalOcean. I paid $5 per month for a Droplet (i.e. server) that
ran 24/7 and could do anything I wanted. There are all kinds of useful things
that you can do with a VPS, but I ended up only using mine to host web pages and
other files. The setup for that was kind of interesting. I set up a wildcard
CNAME (<code>*.djy.io</code>) to direct to the IP address of my Droplet. Then, I followed
one of DigitalOcean’s guides to set up <a href="https://www.nginx.com/resources/wiki/">nginx</a> to serve the content from
various folders in <code>/var/www</code> (sites that I had written and uploaded to the
VPS). With this setup in place, I was able to create a new site whenever I
wanted by syncing the HTML and assets into a folder in <code>/var/www</code> and using a
simple nginx config file to specify which sites were to serve on which
subdomains (e.g. <code>something.djy.io</code>).</p>

<p>I got rid of the $5/month VPS once I figured out that I wasn’t using it for
anything that Netlify couldn’t handle for me in a much better way, and for free.</p>

<p>Lately, though, I have been using DigitalOcean again, to host an actual web
application. I built an API to provide information about new <a href="https://alda.io/">Alda</a>
releases, as part of the ground-up rewrite (Alda v2) that I’ve been working on
over the last couple of years.</p>

<p>There are two components to the Alda Releases API: the API server and the asset
storage. For the asset storage, I found DigitalOcean’s <a href="https://www.digitalocean.com/products/spaces/">Spaces</a> to do
the job nicely. Spaces is an Amazon S3-compatible file storage service that is
affordable and has some nice features like a built-in CDN. I’ve set up a
<a href="https://circleci.com/">CircleCI</a> automated build pipeline that uploads the executables to a
DigitalOcean Space whenever I push a release tag up to the GitHub remote. The
API server has a background thread that regularly checks for updates to the
executables in the Space so that it can provide up-to-date information about
Alda releases.</p>

<p>I deploy the Alda API using the DigitalOcean <a href="https://www.digitalocean.com/products/app-platform/">App Platform</a>, a
platform-as-a-service (PaaS) offering that automates building and deploying the
app every time I push a commit to my repo’s default branch. App Platform is very
new (it was only released to the general public four months ago, in October
2020), and accordingly has some rough edges, but overall, using it to deploy the
Alda API has been a nice experience. There is the usual trade-off with using any
PaaS product, which is that you don’t have to worry about infrastructure,
however, when something goes wrong, it can be difficult to see what’s going on
under the hood. For a simple, low-maintenance (and low-cost) application like
this one, I think the trade-off makes sense, but it’s not the kind of thing I
would do in my day job.</p>



<p>I hope you found this at least somewhat interesting!</p>



<p>Reply to <a href="https://twitter.com/dave_yarwood/status/1359130014105632769">this tweet</a> with any comments, questions, etc.!</p>

</article></div>]]>
            </description>
            <link>https://blog.djy.io/how-i-deploy-my-personal-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077182</guid>
            <pubDate>Tue, 09 Feb 2021 13:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting a BIOS from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077166">thread link</a>) | @vermilingua
<br/>
February 9, 2021 | https://pete.akeo.ie/2011/06/crafting-bios-from-scratch.html | <a href="https://web.archive.org/web/*/https://pete.akeo.ie/2011/06/crafting-bios-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><b>Introduction</b></p><p>

Ideally, there would have been an entry between this one and <a href="http://pete.akeo.ie/2011/06/extracting-and-using-modified-vmware.html">the last</a>, where I'd give you some pointers on how to disassemble the VMware BIOS we extracted using <a href="http://www.hex-rays.com/idapro/">IDA Pro</a>. However, one of the points of this series is to explore ways of improving/revisiting the too often ignored x86 bootloader recovery process (a.k.a. <a href="http://thread.gmane.org/gmane.linux.bios/25740/focus=26022">'panic room'</a>), that really ought to be part of any system boot operations. As such, we might as well jump straight into the fun by <b>creating a VMware BIOS from scratch</b>.</p><p>

Your first question might be <i>"Why would anyone want to craft their own BIOS from scratch (apart for an academical exercise)?"</i>. Well, in an ideal world, chipmakers such as intel and AMD <b>would</b> follow the example of the <a href="http://www.realtek.com.tw/">few SoCs manufacturers</a> <a href="http://www.ali.com.tw/index.php">who got it right</a> and provide both an UART and a small serial boot recovery ROM, <i>ondie</i>, to relegate the prospect of a non-functional system because of bad/uninitialized flash, to the footnotes of history. Alas, with CPUs well into their 4th decade of existence, that still hasn't happened. Therefore, to compensate for this missing feature, we'll have to implement such a feature ourselves, in the flash ROM, and that means writing a BIOS bootblock from scratch. And if you know how to write a BIOS bootblock, then you know how to write a complete BIOS. As to why one would actually want to replace a fully functional BIOS on <b>actual</b> hardware, just wait till you purchase a 3TB (or larger) HDD, or create a &gt;2TB RAID array, on an not so old machine, with the intent of booting Windows from it...</p><p>

Of course, crafting a fully featured BIOS, that can actually boot an OS, is something better left to large projects such as <a href="http://www.coreboot.org/">coreboot</a> with a payload of either <a href="http://www.coreboot.org/SeaBIOS">SeaBIOS</a> or <a href="http://www.tianocore.org/">Tianocore</a> (<a href="http://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface">UEFI</a>), so we're not going to do that here. Instead, our aim will be to produce a very simple BIOS, that just does serial I/O, and that can be used as a development base for more interesting endeavours, such as 'panic room' type flash recovery, or regular BIOS instrumentation, to help with the development of an UEFI 'BIOS' for legacy platforms. Trying things out with a virtual machine, before jumping onto actual hardware, seems like the smart thing to do.</p><p>


<b>Know thy enemy, a.k.a. "Which SuperIO?"</b></p><p>

Hardware wise, the only subsystem we want to access then is the SuperIO chip, since it provides the (virtual) UART we are after. We're not going to bother about PCI, RAM, Video, or even Cache as RAM (CAR) access: just plain good old serial debug will do. And while I'm not going to go as far as saying that implementing the items listed above would be trivial, the fact is, as long as you have serial debug, at least you don't have to shoot in the dark, and that's big help.</p><p>

In the case of VMware, all you need to know is that the SuperIO is a (virtual) National Semiconductor PC97338 (<a href="http://pdf.datasheetcatalog.com/datasheet/nationalsemiconductor/PC97338.pdf">datasheet here</a>). Unfortunately neither coreboot's <a href="http://www.coreboot.org/Superiotool"><code>superiotool</code></a> or <a href="http://www.lm-sensors.org/">lm-sensors</a>'s <a href="http://www.lm-sensors.org/wiki/man/sensors-detect"><code>sensors-detect</code></a> seem to detect it at the moment, which is quite unfortunate (Didn't someone mention they were porting coreboot/LinuxBIOS to VMware <a href="http://www.coreboot.org/pipermail/coreboot/2007-March/019030.html">some time ago</a>? What happened?), as a lot of time was wasted on the SuperIO errand.</p><p>

And maybe I missed a step somewhere, but from what I can see, the VMware virtual chip is not set to run in PnP mode. Thus, what I'm going to expose in the code below with regards to accessing the serial port is very specific to the VMware PC97338 non-PnP implementation, and may not translate so well to SuperIO chips that run in PnP mode. Oh well... Also, if you disassemble the VMware BIOS, you'll see some mucking around with a SuperIO chip located at port <code>0x398</code> early in the bootblock, with <code>0x398</code> being one of the possible bases for the PC97338... Except the VMware SuperIO base is indeed at the <code>0x2e</code> location, so all that early stuff is a wild goose chase. Thanks a lot guys!</p><p>

Therefore, just to reiterate, all you need to know is that the VMware SuperIO is a PC97338, at port <code>0x2e</code> and running in non PnP mode. With that you can run along, and get going implementing early serial in your own BIOS.</p><p>


<b>Toolchain considerations and software constraints</b></p><p>

With the hardware in check, and before we start writing anything, it might help to have a look at our other requirements.</p><p>

First of all, as far as the development toolchain is concerned, and even more so as what follows is aimed at being usable by the largest number of people, we will use a GNU toolchain all the way. That means, as soon as you have a gcc setup on your platform that can produce x86 code, you should be good to go. And for the record, I have verified that the files I'm presenting below can produce a BIOS ROM on Windows, with either MinGW32, MinGW-w64 or cygwin, as well as Linux x86 or x64, with regular gcc. OSX (with a <b>proper</b> gcc toolchain) as well as cross compilers on other UNIX architectures are expected to work too. So if you don't have gcc setup on your system, go get it now!</p><p>

Then comes our choice of language. The coreboot and other projects seem to be quite adamant about developing as little as possible in assembly, but I don't see it that way for the two following reasons:</p><ol>
<li>We have no stack after reset but unless we plan on doing non 'panic room' type things, we <b>actually</b> don't have much use for one in the first place. From experience (<a href="https://github.com/pbatard/xtreamerdev/tree/master/rtdsr">with Realtek SoCs</a>) I can tell you that if your 'panic room' needs any form of memory to be initialized to be able to run, and that applies to Cache as RAM, you're not doing it right.</li>
<li>RAM space is infinite. BIOS bootcode blocks aren't. If there's one space you want to optimize it's that 4K or 8K BIOS recovery bootblock that you'll keep <b>and never re-flash</b> at the end of your BIOS. Flash manufacturers are providing features to help with flash recovery - make use of them dammit!!</li>
</ol><p>
Therefore, assembly it is.</p><p>

Now, the one caveat is that the GNU assembler seems to be the only tool still around defaulting to the AT&amp;T syntax which, while arguably more sensible than the intel one, nobody else, and especially not IDA, uses. Instead the intel syntax prevails. While this could have been an annoyance, any recent versions of GNU <code>as</code> also supports the Intel syntax, which can be be switched on in your code with <code>.intel_syntax noprefix</code>. Now that's better!</p><p>

Finally, we know we'll have to follow the following constraints:</p><ol>
<li>First instruction must be located at address <code>4GB-0x10</code> (or <code>FFFF:FFF0</code> if you prefer), and the whole BIOS must reside at the very end of the 32 bit address space. This is an x86 CPU initialization requirement</li>
<li>The processor starts in real address mode on reset. Another x86 reset constraint. Now, some people choose to switch to protected mode as soon as they can (so that they can use C), but we have optimization in mind, so we'll keep real address mode all the way.</li>
<li>The BIOS ROM size must be 512 KB. This time it's a VMware requirement.</li>
<li>We are also supposed to be careful about far jumps in our code, as another x86 boottime constraint. But that won't be an issue for a bootblock section of a few KB, which we plan to locate at the end of the BIOS anyway.</li>
</ol>
<p>

<b>Producing a BIOS ROM</b></p><p>

Now we jump into the gory details at last.</p><p>

Since the reset vector is located at the end of the BIOS, we need to have at least two sections in our sourcecode: one that contains the bulk of our code, which I'll call <code>main</code> and which I'll <b>arbitrarily</b> set to start at 4 KB before the end of the ROM, and another, starting at <code>FFFF:FFF0</code> and going to the end of the ROM, which I'll call <code>reset</code> and whose only purpose will be to jump into our entrypoint in the <code>main</code> section.</p><p>

Below is an example of how one can establish these two sections in the assembly source, as well as the associated GNU <code>ld</code> script that ensures they will be located at the right destination address in the ROM. Because our BIOS is short, I'll use a single <code>bios.S</code> source for the code, and I'll call the <code>ld</code> script <code>bios.ld</code>. Hence <b>bios.S</b>:</p><pre>.section main
init:   &lt;insert useful code here&gt;
        ...

.section reset
        jmp init
        .align 16</pre><p>
NB: the <code>.align 16</code> at the end is there to ensure that the reset section is exactly 16 bytes. This way, we're sure that our <code>reset</code> section will occupy [FFFF:FFF0 - FFFF:FFFF] and we won't have to do extra padding.</p><p>

<b>bios.ld</b>:</p><pre>MEMORY { ROM (rx) : org = 4096M - 512K, len = 512K }
SECTIONS { 
        .main 4096M - 4K    : { *(main) }
        .reset 4096M - 0x10 : { *(reset) }
        }</pre><p>
As you can see above, the ld script simply sets the ROM to be 512 KB in size, located at the end of the 4 GB (=4096M, since GNU <code>ld</code> doesn't know the G suffix yet) and, as indicated, we placed our bootcode segment (<code>main</code>) to start at the last 4 KB block of ROM. <br>
The script should sort out our addresses as we want them then, and once <code>ld</code> has churned through it and produced a new object file (which I'll call <code>bios.out</code>), we should be able to use <code>objcopy</code> with option <code>-j</code> to extract the various binary payloads of interest to us.</p><p>

Now, the problem is that <code>objcopy -j</code> will only extract the payload data. We could of course use a trick like<code>.align 4K-0x10</code> at the end of our main section, but that would mean we'd then have to edit our bootcode size in two separate files when we update it. The smarter approach is to use the <code>--gap-fill</code> option of <code>objcopy</code>, to conveniently fill any gap between sections <code>main</code> and <code>reset</code>.</p><p>

Another problem we face is that the above script only produces the binary data starting with the 4K at the end of the ROM, since the first section we extract (<code>main</code>) starts there. So at most objcopy will create 4 KB of data, far from the 512 KB we actually need. The solution: create a dummy section in our source, which I'll call <code>begin</code> and which I'll also use to put a BIOS ID string, and tell <code>ld</code> either explicitly, or better simply with a <code>&gt;ROM</code> directive (so that we don't have to fill in the ROM size a 3rd time in the script) where it should reside. </p><p>

After that, if we extract the <code>begin</code>, <code>main</code> and <code>reset</code> sections in order, with the <code>--gap-fill</code> option, we should have a 512 KB binary file with everything mapped where it should be. Neat!</p><p>


<b>Caveats</b></p><p>

Before I present the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pete.akeo.ie/2011/06/crafting-bios-from-scratch.html">https://pete.akeo.ie/2011/06/crafting-bios-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://pete.akeo.ie/2011/06/crafting-bios-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077166</guid>
            <pubDate>Tue, 09 Feb 2021 13:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to eat an elephant, one atomic concept at a time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26077087">thread link</a>) | @jger15
<br/>
February 9, 2021 | https://kwokchain.com/2021/02/05/atomic-concepts/ | <a href="https://web.archive.org/web/*/https://kwokchain.com/2021/02/05/atomic-concepts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>How Figma and Canva are taking on Adobe—and winning</strong></p>



<p>In 2010, Photoshop was ubiquitous. Whether you were editing a photo, making a poster, or designing a website, it happened in Photoshop.&nbsp;</p>



<p>Today, Adobe looks incredibly strong. They’ve had spectacular stock performance, thanks to clear-eyed management who’ve made bold bets that have paid off. Their transition to SaaS has been seamless, for which the public markets have rewarded them handsomely. And they’re historically one of the <a href="https://en.wikipedia.org/wiki/List_of_acquisitions_by_Adobe">best companies at M&amp;A</a>; their product lineup is a testament to their ability to acquire new product lines and integrate them well into their multi-product ecosystem. Perhaps most importantly and least appreciated, they have dramatically sped up the cadence of their internal product development process and feedback loop. Like Microsoft, they have successfully shifted from a legacy company operating on an annual (or longer) release schedule to a truly cloud company shipping updates at a sub-weekly pace.</p>



<p>Nevertheless, there are a few segments of design where they’re no longer the market leader. Companies like Figma, Sketch, and Canva are examples of products that have been able to become top products despite Adobe’s ubiquity in all things design. Figma showed up in Adobe’s annual report for the first time in <a href="https://www.bamsec.com/filing/79634320000013">2019</a>. They reprised in <a href="https://www.bamsec.com/filing/79634321000004">2020</a>, and I’m not uncertain they will continue to be in it going forward.</p>



<p>How should we understand these market transitions and why these young companies are able to thrive, even against a strong incumbent like Adobe?</p>



<p>These companies have distinct atomic concepts from Adobe. The primitives that their products are built around are fundamentally different from those of Adobe’s product lineup. It’s these different fundamental atomic concepts that turn Adobe’s advantage of an established product and existing userbase into a weakness that hinders their ability to counter these upstarts. The opportunity for these new atomic concepts to thrive is driven by the new use cases and types of users unearthed during market transitions.</p>



<p>Understanding the phases of market transition and what drives them is a universal process worth examining.</p>



<h2>New use cases: designing for digital</h2>



<p>For most markets, there are advantages to being an incumbent. Markets converge as companies arrive at the preference frontier of customers. This leaves little potential energy for new startups to take advantage of.</p>



<p>Market entropy is good for new entrants.</p>



<p>It’s not impossible to break into a market by brute force, but it’s hard. Very hard. Most successful companies, especially startups, have found tailwinds to harness that help pull them forward.</p>



<p>Changing customer needs are the largest source of entropy in markets. When customer needs rapidly change, there is less advantage in being an incumbent. Instead, legacy companies are left with all the overhead and a product that no longer is what customers want.</p>



<p>There are many causes of changing customer needs. Often there are new and growing segments of customers with different use cases. Existing products may work for them, but they aren’t ideal. The features they care about and how they value them are very different from the customers the legacy company is used to. Companies resist changing core parts of their product for every new use case since it’s costly in work, money, and attention. But every once in a while, what was once a small use case grows into one large enough to support its own company.</p>



<p>Other times the scale or dynamics of a market shift enough to make a product no longer work despite having been a great fit. Companies are often caught flat-footed by these situations because what they have done successfully for years suddenly starts to falter—and they aren’t sure why. Ebay is a good example of this. Their decentralized auction model was very good in a nascent internet economy when there was a scarcity of items being sold online. Once ecommerce became commonplace, price and speed became much more important factors and Ebay’s decentralized model was at a disadvantage. Amazon was much better at building economies of scale in this post-liquidity ecosystem.</p>



<p>Another source is when the customers themselves change. Often the function of a tool remains the same, but the type of user changes. These new types of customers often have different things they care about and resulting product needs.</p>



<p>The internet drove entirely new design use cases. Photoshop was built for editing photos and images. It’s a powerful tool that operates at the pixel level. However, many of these new uses weren’t about image manipulation. Images were a component—not the essence—of the job users were trying to accomplish.</p>



<p>For some users, this was designing digital products. Designers at software companies or any company with a website wanted to create the websites and software products they worked on. This is less about image manipulation and more about designing the UI and UX of these digital products. Vectors are more important than raster graphics. The complexity and process of designing these high-value designs also got increasingly more sophisticated. These designers worked with teams of other designers and non-designers. Their designs are part of a larger product development process and what mattered wasn’t just making a design, but how that the entire process could be improved to make collaboration easier and handoff of designs better. Iteratively.</p>



<p>The complexity of the designs and the components in the resulting code became more complex, too. The need for their tools to have a higher-level understanding of the components and variants became more important. It’s increasingly useful for designs to understand the same concepts and abstraction levels as the HTML and CSS in the resulting end product.</p>



<p>For some users, this was designing content for social platforms, digital ads, or even wedding invitations. These were often made in Photoshop, but again, pixels are the wrong abstraction level. Images are not the sole component; they are just past of a larger design that includes graphics, text, and more. Similarly, the customers are very different. Many of the people now doing what is, in essence, design work don’t think of themselves as designers. They just have a very specific thing they want to create, with the least friction possible.</p>



<p>The internet dramatically scales up the volume and type of new use cases for design. In many ways, this helps Adobe. With platforms like Instagram, the number of people editing photos has expanded by many orders of magnitude. While editing on platforms like Instagram may have increased significantly, Adobe has been a huge beneficiary of the internet and the shift to cloud—and their <a href="https://www.google.com/finance/quote/ADBE:NASDAQ">stock price</a> is a testament to this.</p>



<p><em>[KK Note: Platforms like Instagram strapping editors onto their social platforms and eating into Lightroom from the bottom up is well worth its own discussion. And perhaps someone will convince Mike Krieger to do the definitive piece on that.]</em></p>



<figure><img loading="lazy" width="800" height="559" src="https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=800%2C559&amp;ssl=1" alt="" srcset="https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?w=800&amp;ssl=1 800w, https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=300%2C210&amp;ssl=1 300w, https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=768%2C537&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?w=800&amp;ssl=1 800w, https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=300%2C210&amp;ssl=1 300w, https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=768%2C537&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/kwokchain.com/wp-content/uploads/2021/02/image.png?resize=800%2C559&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Software may be eating the world. But it’s also building new worlds? I’m going to need a refresher on remembering the Andreessen Horowitz talking points</figcaption></figure>



<p>This is even more true in video. There are orders of magnitude more video creators as the ability to record video has become ubiquitous and the platforms where video is the default format have grown. Even more striking, many of the dominant video platforms—like Youtube—are purely distribution focused. They don’t even have any editing capabilities. Instead, companies like Adobe end up being large beneficiaries of this need.</p>



<p><em>[KK Note: Platforms like Youtube still having not built any semblance of an editor into their platform is *also* well worth its own discussion. I’d say we’ll never know what could be, but then I look at TikTok and all is right with the world.]</em></p>



<p>But Adobe hasn’t captured it all. And in many of these new emergent use cases and customer types, Adobe has lost the lead to new startups.</p>



<h2>Tapping into the right level of abstraction</h2>



<p>The best products map to how customers think about their workflow. They match the abstraction level of their customers: not too high that it’s unusable, but not too low that it’s hard to use easily or extend in more complex ways.</p>



<p>They choose the right atomic concepts.</p>



<p>These are the core concepts around which the entire product is built. They not only align with how customers think of their workflow, but often crystallizes for customers how they ought to. Great atomic concepts are honed and then extended and built upon in more complex compounds that…well for lack of a better word…<em>compound</em>.</p>



<p>Similar companies often have slightly different atomic concepts that end up making them meaningfully distinct. Photoshop is focused on pixels and images. Its focus is on editing images and pictures. And its functions operate by transforming them on a pixel level.</p>



<p>Illustrator is similar, but it operates on vectors, not pixels. This is a higher level abstraction. Neither is better or worse, they are just more suited to different use cases. Photoshop is better for modifying images, while illustrator is built for designs where scale-free vectors are best.</p>



<p>Sketch, like Illustrator, is vector based. But is designed for building digital products which means things like operating at a project level. It is not individual designs, but crafting entire products and user interfaces—and the needs for repeatability and consistency inherent to that.</p>



<p>Figma builds on Sketch’s approach, but also includes a greater focus on not just projects but the entire collaborative process as the relevant scope. Similarly, it also treats higher level abstractions like plugins, community, and more as equally important concepts.</p>



<p>Canva is similar to Photoshop and Illustrator, but its users aren’t designers who care about low level tools. Instead Canva’s core atomic concepts are around the different …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kwokchain.com/2021/02/05/atomic-concepts/">https://kwokchain.com/2021/02/05/atomic-concepts/</a></em></p>]]>
            </description>
            <link>https://kwokchain.com/2021/02/05/atomic-concepts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077087</guid>
            <pubDate>Tue, 09 Feb 2021 13:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multidimensional Arrays and Operations with NDArray and Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26076878">thread link</a>) | @batterylow
<br/>
February 9, 2021 | https://datacrayon.com/posts/programming/rust-notebooks/multidimensional-arrays-and-operations-with-ndarray/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/programming/rust-notebooks/multidimensional-arrays-and-operations-with-ndarray/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<div>
<p>In&nbsp;[2]:</p>
<div>
    <div>
<div><pre><span></span>:<span>dep</span><span> </span><span>ndarray</span><span> </span><span>=</span><span> </span><span>{</span><span>version</span><span> </span><span>=</span><span> </span><span>"0.13.1"</span><span>}</span><span></span>
<span>extern</span><span> </span><span>crate</span><span> </span><span>ndarray</span><span>;</span><span></span></pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<p>This module contains the most used types, type aliases, traits and functions that you can import easily as a group:</p>
</div>
</div>

<div>

<div>
<p>This gives us access to the following: <code>ArrayBase</code>, <code>Array</code>, <code>RcArray</code>, <code>ArrayView</code>, <code>ArrayViewMut</code>, <code>Axis</code>, <code>Dim</code>, <code>Dim</code>, <code>Dimension</code>, <code>Array0</code>, <code>Array1</code>, <code>Array2</code>, <code>Array3</code>, <code>Array4</code>, <code>Array5</code>, <code>Array6</code>, <code>ArrayD</code>, <code>ArrayView0</code>, <code>ArrayView1</code>, <code>ArrayView2</code>, <code>ArrayView3</code>, <code>ArrayView4</code>, <code>ArrayView5</code>, <code>ArrayView6</code>, <code>ArrayViewD</code>, <code>ArrayViewMut0</code>, <code>ArrayViewMut1</code>, <code>ArrayViewMut2</code>, <code>ArrayViewMut3</code>, <code>ArrayViewMut4</code>, <code>ArrayViewMut5</code>, <code>ArrayViewMut6</code>, <code>ArrayViewMutD</code>, <code>Ix0</code>, <code>Ix0</code>, <code>Ix1</code>, <code>Ix1</code>, <code>Ix2</code>, <code>Ix2</code>, <code>Ix3</code>, <code>Ix3</code>, <code>Ix4</code>, <code>Ix4</code>, <code>Ix5</code>, <code>Ix5</code>, <code>Ix6</code>, <code>Ix6</code>, <code>IxDyn</code>, <code>IxDyn</code>, <code>arr0</code>, <code>arr1</code>, <code>arr2</code>, <code>aview0</code>, <code>aview1</code>, <code>aview2</code>, <code>aview_mut1</code>, <code>ShapeBuilder</code>, <code>NdFloat</code>, and <code>AsArray</code>.</p>
</div>
</div>
<div>

<div>
<div>
<h2 id="Introduction">Introduction<a href="#Introduction">¶</a>
</h2>
<p>The <code>ndarray</code> crate provides us with a multidimensional container that can contain general or numerical elements. If you're familiar with Python, then you can consider it to be similar to the <code>numpy</code> package. With <code>ndarray</code> we get our $n$-dimensional arrays, slicing, views, mathematical operations, and more. We'll need these in later sections to load in our datasets into containers that we can operate on and conduct our analyses.</p>

</div>
</div>
</div>


<div>

<div>
<p>Let's take a look at how we can create a two-dimensional ndarray <code>Array</code> from a <code>Vec</code> with the <code>arr2()</code> function.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[4]:</p>
<div>
    <div>
<div><pre><span></span><span>arr2</span><span>(</span><span>&amp;</span><span>[[</span><span>1.</span><span>,</span><span>2.</span><span>,</span><span>3.</span><span>],</span><span></span>
<span>       </span><span>[</span><span>4.</span><span>,</span><span>5.</span><span>,</span><span>6.</span><span>]])</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[4]:</p>




<div>
<pre>[[1.0, 2.0, 3.0],
 [4.0, 5.0, 6.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>It's as easy as that, This has given us a 2 by 3 array with our desired floating point values. We can also use the <code>array!</code> macro as a shorthand for creating an array.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[5]:</p>
<div>
    <div>
<div><pre><span></span><span>array</span><span>!</span><span>[[</span><span>1.</span><span>,</span><span>2.</span><span>,</span><span>3.</span><span>],</span><span></span>
<span>       </span><span>[</span><span>4.</span><span>,</span><span>5.</span><span>,</span><span>6.</span><span>]]</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[5]:</p>




<div>
<pre>[[1.0, 2.0, 3.0],
 [4.0, 5.0, 6.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>We can also construct an array filled with zeros, we can do this with the <code>zeros()</code> function and pass in our desired shape.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[6]:</p>
<div>
    <div>
<div><pre><span></span><span>Array2</span>::<span>&lt;</span><span>f64</span><span>&gt;</span>::<span>zeros</span><span>((</span><span>4</span><span>,</span><span>4</span><span>))</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[6]:</p>




<div>
<pre>[[0.0, 0.0, 0.0, 0.0],
 [0.0, 0.0, 0.0, 0.0],
 [0.0, 0.0, 0.0, 0.0],
 [0.0, 0.0, 0.0, 0.0]], shape=[4, 4], strides=[4, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>Similarly, we can also construct an array filled with ones, we can do this with the <code>ones()</code> function and pass in our desired shape.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[7]:</p>
<div>
    <div>
<div><pre><span></span><span>Array2</span>::<span>&lt;</span><span>f64</span><span>&gt;</span>::<span>ones</span><span>((</span><span>4</span><span>,</span><span>4</span><span>))</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[7]:</p>




<div>
<pre>[[1.0, 1.0, 1.0, 1.0],
 [1.0, 1.0, 1.0, 1.0],
 [1.0, 1.0, 1.0, 1.0],
 [1.0, 1.0, 1.0, 1.0]], shape=[4, 4], strides=[4, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>Let's create variables to store a 1D array and a 2D array for use in the following subsections.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[8]:</p>
<div>
    <div>
<div><pre><span></span><span>let</span><span> </span><span>data_1D</span>: <span>Array1</span>::<span>&lt;</span><span>f32</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>array</span><span>!</span><span>[</span><span>1.</span><span>,</span><span>2.</span><span>,</span><span>3.</span><span>];</span><span></span>

<span>let</span><span> </span><span>data_2D</span>: <span>Array2</span>::<span>&lt;</span><span>f32</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>array</span><span>!</span><span>[[</span><span>1.</span><span>,</span><span>2.</span><span>,</span><span>3.</span><span>],</span><span></span>
<span>                                    </span><span>[</span><span>4.</span><span>,</span><span>5.</span><span>,</span><span>6.</span><span>]];</span><span></span></pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<h2 id="Dimensions">Dimensions<a href="#Dimensions">¶</a>
</h2>
<p>It's often the case that we need to find out the dimensionality of our arrays. There are many ways to do this, and the following contains some of the common approaches.</p>

</div>
</div>
</div>
<div>

<div>
<div>
<h3 id="From-Length">From Length<a href="#From-Length">¶</a>
</h3>
<p>We can use <code>Array.len()</code> to return the shape along a single axis.</p>

</div>
</div>
</div>

<div>

<div>
<p>This is simple enough if we have a one-dimensional array. However, for higher dimensions, we can see that for a <code>len()</code> returns the flattened length.</p>
</div>
</div>

<div>

<div>
<p>If we want to get the length along one of the axes instead, e.g. the second one, we can use <code>Array.len_of(Axis(n))</code></p>
</div>
</div>

<div>

<div>
<div>
<h3 id="From-Shape">From Shape<a href="#From-Shape">¶</a>
</h3>
<p>Another approach is to use <code>Array.shape()</code> which returns more information.</p>

</div>
</div>
</div>

<div>

<div>
<p>We can see it has returned an array that indicates the length along all of our axes. This can be indexed to get the length along a specific axis.</p>
</div>
</div>


<div>

<div>
<p>Like most data structures, the indexing starts at $0$. To access the first element in our one-dimensional arrays we can do the following.</p>
</div>
</div>

<div>

<div>
<p>For higher dimensions, we need to use a primitive array.</p>
</div>
</div>

<div>

<div>
<p>Likewise, to access the second element in our one-dimensional arrays we need to index with $1$.</p>
</div>
</div>

<div>

<div>
<p>Again, for our higher dimensions, we use a primitive array..</p>
</div>
</div>

<div>

<div>
<p>To select the last element in our one-dimensional arrays we can index with <code>Array.len() -1</code>.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[18]:</p>
<div>
    <div>
<div><pre><span></span><span>data_1D</span><span>[</span><span>data_1D</span><span>.</span><span>len</span><span>()</span><span> </span><span>-</span><span>1</span><span>]</span><span></span></pre></div>

    </div>
</div>
</div>



</div>
<div>

<div>
<p>But for our multidimensional arrays we need to use a primitive array and use <code>Array.len_of(Axis(n))</code>.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[19]:</p>
<div>
    <div>
<div><pre><span></span><span>data_2D</span><span>[[</span><span>0</span><span>,</span><span> </span><span>data_2D</span><span>.</span><span>len_of</span><span>(</span><span>Axis</span><span>(</span><span>1</span><span>))</span><span> </span><span>-</span><span>1</span><span>]]</span><span></span></pre></div>

    </div>
</div>
</div>



</div>
<div>

<div>
<p>Alternatively, we could use <code>Array.shape()[n]</code>.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[20]:</p>
<div>
    <div>
<div><pre><span></span><span>data_2D</span><span>[[</span><span>0</span><span>,</span><span> </span><span>data_2D</span><span>.</span><span>shape</span><span>()[</span><span>1</span><span>]</span><span> </span><span>-</span><span> </span><span>1</span><span>]]</span><span></span></pre></div>

    </div>
</div>
</div>



</div>

<div>

<div>
<p>Let's look at some common mathematical operations that can operate on our arrays.</p>
</div>
</div>

<div>

<div>
<p>All elements in an array can be summed with <code>sum()</code>.</p>
</div>
</div>

<div>

<div>
<p>We may instead wish to sum all elements along a specific axis in an array, e.g. the first axis.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[22]:</p>
<div>
    <div>
<div><pre><span></span><span>data_2D</span><span>.</span><span>sum_axis</span><span>(</span><span>Axis</span><span>(</span><span>0</span><span>))</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[22]:</p>




<div>
<pre>[5.0, 7.0, 9.0], shape=[3], strides=[1], layout=CF (0x3), const ndim=1</pre>
</div>

</div>

</div>
</div>

</div>

<div>
<div>
<p>In&nbsp;[23]:</p>
<div>
    <div>
<div><pre><span></span><span>data_2D</span><span>.</span><span>sum_axis</span><span>(</span><span>Axis</span><span>(</span><span>1</span><span>))</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[23]:</p>




<div>
<pre>[6.0, 15.0], shape=[2], strides=[1], layout=CF (0x3), const ndim=1</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>It's quite common to apply mathematical operations to each element of an array. Let's have a look at some examples.</p>
</div>
</div>

<div>

<div>
<p>We can add values, e.g. $1.0$, to every element.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[24]:</p>




<div>
<pre>[[2.0, 3.0, 4.0],
 [5.0, 6.0, 7.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>We can also add the elements of one array to another.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[25]:</p>




<div>
<pre>[[2.0, 4.0, 6.0],
 [8.0, 10.0, 12.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>Finally, we can add a one-dimensional array to a two-dimensional array.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[26]:</p>




<div>
<pre>[[2.0, 4.0, 6.0],
 [5.0, 7.0, 9.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<div>
<div>
<p>Warning</p>
<p>When summing two arrays together they don't need to have the same shape, but their shapes must be compatible. This means we should be able to broadcast one array across another, i.e. they must be identical in the size of at least one dimension.</p>
</div>
</div>
</div>
</div>

<div>

<div>
<p>We can subtract values, e.g. $1.0$, from every element.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[27]:</p>




<div>
<pre>[[0.0, 1.0, 2.0],
 [3.0, 4.0, 5.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>We can also subtract elements of one array from another.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[28]:</p>




<div>
<pre>[[0.0, 0.0, 0.0],
 [0.0, 0.0, 0.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>Finally, we can subtract a one-dimensional array from a two-dimensional array array.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[29]:</p>




<div>
<pre>[[0.0, 0.0, 0.0],
 [3.0, 3.0, 3.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>We can multiply every element by a value, e.g. by $2.0$.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[30]:</p>




<div>
<pre>[[2.0, 4.0, 6.0],
 [8.0, 10.0, 12.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>We can also multiply every element of one array by another.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[31]:</p>




<div>
<pre>[[1.0, 4.0, 9.0],
 [4.0, 10.0, 18.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>We can divide every element by a value, e.g. by $2.0$.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[32]:</p>




<div>
<pre>[[0.5, 1.0, 1.5],
 [2.0, 2.5, 3.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<p>We can also divide every element of one array by another.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[33]:</p>




<div>
<pre>[[1.0, 1.0, 1.0],
 [4.0, 2.5, 2.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>We can raise the elements in an array to a power, e.g. of $3.0$.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[34]:</p>
<div>
    <div>
<div><pre><span></span><span>data_2D</span><span>.</span><span>mapv</span><span>(</span><span>|</span><span>data_2D</span><span>|</span><span> </span><span>data_2D</span><span>.</span><span>powi</span><span>(</span><span>3</span><span>))</span><span></span></pre></div>

    </div>
</div>
</div>

<div>
<div>


<div>

    <p>Out[34]:</p>




<div>
<pre>[[1.0, 8.0, 27.0],
 [64.0, 125.0, 216.0]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>

<div>

<div>
<p>We can calculate the square root of elements in an array. The specified data type must match.</p>
</div>
</div>
<div>


<div>
<div>


<div>

    <p>Out[35]:</p>




<div>
<pre>[[1.0, 1.4142135, 1.7320508],
 [2.0, 2.236068, 2.4494898]], shape=[2, 3], strides=[3, 1], layout=C (0x1), const ndim=2</pre>
</div>

</div>

</div>
</div>

</div>
<div>

<div>
<div>
<h2 id="Conclusion">Conclusion<a href="#Conclusion">¶</a>
</h2>
<p>In this section, we've introduced <code>ndarray</code> as a crate that gives us multidimensional containers and operations. We demonstrated how to create arrays, find out their dimensionality, index them, and how to invoke some basic mathematical operations.</p>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/programming/rust-notebooks/multidimensional-arrays-and-operations-with-ndarray/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076878</guid>
            <pubDate>Tue, 09 Feb 2021 12:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pseudophilosophy encourages confused, self-indulgent thinking]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 214 (<a href="https://news.ycombinator.com/item?id=26076731">thread link</a>) | @pseudolus
<br/>
February 9, 2021 | https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>There are many kinds</strong> of pseudosciences: astrology, homeopathy, flat-Earthism, anti-vaxx. These â€˜fieldsâ€™ traffic in bizarre claims with scientific pretensions. On a surface level, these claims <em>seem</em> to be scientific and usually appear to comment on the same kind of things that science does. However, upon closer inspection, pseudoscience is revealed to be <a href="https://aeon.co/ideas/why-bullshit-is-no-laughing-matter" rel="noopener">bullshit</a>: it is indifferent to the truth. Analogous to pseudoscience, can there be such a thing as pseudophilosophy, in which one makes claims with philosophical pretensions which on closer inspection turn out to be bullshit? I think there is.</p>
<p>Letâ€™s begin with the concept of pseudophilosophy. If there is something deserving of that name, then it would be deficient with respect to philosophical issues in the same way that pseudoscience is deficient with respect to scientific issues. So, in order to get a grip on pseudophilosophy, we should first <a href="https://doi.org/10.1111/theo.12271" rel="nofollow noreferrer noopener">look</a> more closely at the way in which pseudoscience is deficient, and then see whether we can find something analogous in the philosophical domain.</p>
<p>What makes pseudoscientific beliefs deficient is that theyâ€™re formed in an <em>epistemically unconscientious</em> way. Thatâ€™s to say, these beliefs are made from culpably confused and uninformed reasoning. For example, the belief that the Earth is flat can be sustained only by self-willed disregard of the massive amounts of evidence to the contrary, accumulated over several centuries by several different sciences.</p>
<p>However, such unconscientiousness doesnâ€™t presuppose insincerity or charlatanry. A charlatan is someone who has a hidden, usually profit-seeking, agenda and who is fundamentally indifferent to whether their beliefs are true. Often bullshit is produced without such insincerity, however, since one can <em>care</em> about the truth of oneâ€™s beliefs without <em>taking care</em> with respect to it.</p>
<p>A problem is that most of us are lacking in epistemic conscientiousness, at least sometimes and to some extent. In order for something to count as pseudoscience, some minimal degree of unconscientiousness is therefore required. A good rule of thumb for being conscientious is to keep an eye out for classical fallacies such as <a href="https://aeon.co/ideas/how-ad-hominem-arguments-can-demolish-appeals-to-authority" rel="noopener">ad hominem</a>, straw man, false dilemma and cherry-picking. Such fallacies occur in all kinds of contexts, but in pseudoscience they occur more systematically.</p>
<p>Whether there is a God or whether there are objective moral truths have to be answered largely via a priori reflection, if at all</p>
<p>Epistemic unconscientiousness is an essential but not exhaustive component of pseudoscience. To count as pseudoscientific, a belief must also be about some scientific issue, and this is precisely where pseudoscience and pseudophilosophy differ. Just like pseudoscience, pseudophilosophy is defined by a lack of epistemic conscientiousness, but its subject matter is philosophical rather than scientific.</p>
<p>Roughly speaking, the difference between scientific and philosophical issues is that the latter arenâ€™t in any straightforward way resolvable via empirical investigation. Whether there is a God, for example, or whether there are objective moral truths, are questions that have to be answered largely via a priori reflection, if at all. These questions are thus different from questions such as whether the Earth is flat or spherical, or whether anthrax is caused by bacteria, which do have empirically accessible answers.</p>
<p><strong>There are two kinds of</strong> pseudophilosophy, one mostly harmless and the other insidious. The first variety is usually found in popular scientific contexts. This is where writers, typically with a background in the natural sciences, walk self-confidently into philosophical territory without realising it, and without conscientious attention to relevant philosophical distinctions and arguments. Often implicit empiricist assumptions in epistemology, metaphysics and the philosophy of language are relied upon as if they were self-evident, and without awareness of the threat that those very assumptions pose to the authorâ€™s own reasoning. We can call this phenomenon scientistic pseudophilosophy.</p>
<p>An illustrative example is Sam Harrisâ€™s <a href="https://samharris.org/books/the-moral-landscape/" rel="nofollow noreferrer noopener">book</a> <em>The Moral Landscape</em> (2010), in which straw men are lined up due to Harrisâ€™s failure to grasp the content of many of the philosophical claims and arguments that he criticises, such as Humeâ€™s law (or the is/ought problem) and <span>G E Mooreâ€™s</span> open-question argument (ie, that no moral property is identical to a natural property). Similarly, in <em>A Universe from Nothing</em> (2012), Lawrence Krauss engages with philosophical arguments for theism without understanding them properly. Most saliently, he ends up criticising a caricature version of the so-called cosmological argument about the existence of God.</p>
<p>Usually, the prose is infused with arcane terminology and learned jargon, creating an aura of scholarly profundity</p>
<p>The insidious kind of pseudophilosophy, which I will focus on here, is an academic enterprise, pursued primarily within the humanities and social sciences. I donâ€™t mean to suggest that the disciplines in question are <em>inherently</em> pseudophilosophical, only that, for some reason, a whole lot of pseudophilosophy goes on within them (although this will vary greatly between different universities and departments). Often philosophical issues are raised concerning knowledge, truth, objectivity, rationality and scientific methodology, and, again, without conscientious attention to relevant philosophical distinctions and arguments. A characteristic trait is a deferential attitude toward some supposedly great continental European thinker or thinkers, such as <span>G W F Hegel,</span> Karl Marx, Sigmund Freud, Carl Jung, Martin Heidegger or Jean-Paul Sartre (who might or might not have themselves been guilty of pseudophilosophy). Usually, the prose is infused with arcane terminology and learned jargon, creating an aura of scholarly profundity. We can <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/theo.12047" rel="nofollow noreferrer noopener">call</a> this phenomenon obscurantist pseudophilosophy.</p>
<p>While pseudoscience is particularly prone to causal fallacies and cherry-picking of data, the most common fallacy in obscurantist pseudophilosophy is equivocation. This fallacy <a href="https://journals.sagepub.com/doi/abs/10.1177/0392192112444984" rel="nofollow noreferrer noopener">exploits</a> ambiguities in certain key terms, where plausible but trivial claims lend apparent credibility to interesting but controversial ones. When challenged, the obscurantist will typically retreat to the safe house provided by the trivial interpretation of his claims, only to reoccupy the controversial ground once the critic has left the scene.</p>
<p>Let me <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9973.2005.00370.x" rel="nofollow noreferrer noopener">illustrate</a> how this works, focusing on <a href="https://aeon.co/essays/why-foucaults-work-on-power-is-more-important-than-ever" rel="noopener">Michel Foucault</a>, one of the central figures of French postmodernism. A central theme in Foucaultâ€™s writings is a critique of the notion of objective truth. Although there are controversies about interpretation, at least on the face of it Foucault maintains that truth is socially constructed and subject to ideological influence, and therefore not objective. However, his arguments for this claim focus entirely on the way in which what is assumed or believed to be true is influenced by what he refers to as â€˜powerâ€™. It is, of course, a plausible claim that our assumptions or beliefs are susceptible to ideological influence, especially in emotionally charged areas such as politics, but also in supposedly rational areas such as science. But Foucault doesnâ€™t explain how this rather mundane observation is supposed to imply or support the philosophically controversial claim that what is true, or which facts obtain (concerning the shape of the Earth, for example), is susceptible to ideological influence. Instead, by using the word â€˜truthâ€™ in an impressionistic fashion, the distinction between belief and truth is smudged over, allowing Foucault to make seemingly profound statements such as:</p>
<blockquote>[T]ruth isnâ€™t outside power, or lacking in power: contrary to a myth whose history and functions would repay further study, truth isnâ€™t the reward of free spirits, the child of protracted solitude, nor the privilege of those who have succeeded in liberating themselves. Truth is a thing of this world: it is produced only by virtue of multiple forms of constraint.</blockquote>
<p>I leave it as an exercise to the reader to disambiguate this statement and see what remains.</p>
<p>This kind of fallacious critique of the notion of objective truth is a particularly pernicious aspect of obscurantist pseudophilosophy in general. Often, itâ€™s due to simple misunderstandings (such as confusing truth with belief or knowledge), but sometimes itâ€™s due rather to wilful obscurity (as in the case of Foucault).</p>
<p>Perhaps due to its aura of academic legitimacy and profundity, obscurantist pseudophilosophy is often used to give credence to dogmatic and bellicose political agendas, both on the Left and on the Right. Beyond that, it encourages confused and self-indulgent thinking in university students, and consumes vast resources that could be put to better use.</p>
<p>While pseudoscience can perhaps be counteracted by science education, the cure for pseudophilosophy is not science education but philosophical education. More specifically, it is a matter of developing the kind of basic critical thinking skills that are taught to undergraduates in philosophy. This doesnâ€™t need to be anything fancy. Students should be taught things like learning to distinguish in a disciplined way between central philosophical concepts such as belief, truth, rationality and knowledge. They should be aware of the way ambiguities can be exploited by equivocating arguments, and become adept at how to spot other fallacies such as ad hominem and straw man. With these fundamental tools in hand, there would be a good deal less pseudophilosophy going around.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076731</guid>
            <pubDate>Tue, 09 Feb 2021 12:34:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: "100 Page Python Intro" eBook]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26076721">thread link</a>) | @asicsp
<br/>
February 9, 2021 | https://learnbyexample.github.io/100_page_python_intro/introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/100_page_python_intro/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav id="sidebar" aria-label="Table of contents"></nav><div id="page-wrapper"><div class="page"><div id="content"><main><p><a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Wikipedia</a> does a great job of describing about Python in a few words. So, I'll just copy-paste relevant information here:</p><blockquote><p>Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.</p><p>Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming. Python is often described as a "batteries included" language due to its comprehensive standard library.</p><p>As of December 2020 Python ranked third in TIOBE’s index of most popular programming languages, behind <code>C</code> and <code>Java</code>.</p></blockquote><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> See also <a href="https://docs.python.org/3/faq/general.html">docs.python: General Python FAQ</a> for answers to questions like "What is Python?", "What is Python good for?", "Why is it called Python?", etc.</p></blockquote><h2><a href="#installation" id="installation">Installation</a></h2><p>On modern Linux distributions, you are likely to find Python already installed. It may be a few versions behind, but should work just fine for most of the topics covered in this book. To get the exact version used here, visit <a href="https://www.python.org/downloads/">Python downloads page</a> and install using the appropriate source for your operating system. Should you face any issues in installing, search online for a solution. Yes, that is something I expect you should be able to do as a prerequisite for this book, i.e. you should have prior experience with basic programming and computer usage.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> See <a href="https://docs.python.org/3/whatsnew/index.html">docs.python: What's New</a> to track changes across versions. As mentioned in the Preface chapter, <strong>3.9.0</strong> is the version used in this book.</p></blockquote><h2><a href="#online-tools" id="online-tools">Online tools</a></h2><p>In case you are facing installation issues, or do not want to (or cannot) install Python on your computer for some reason, there are plenty of options to execute Python programs using online tools. Some of the popular ones are listed below:</p><ul><li><a href="https://repl.it/languages/python3">Repl.it</a> — Interactive playground. Code, collaborate, compile, run, share, and deploy Python and more online from your browser</li><li><a href="http://www.pythontutor.com/visualize.html#mode=edit">Pythontutor</a> — Visualize code execution, also has example codes and ability to share sessions</li><li><a href="https://www.pythonanywhere.com/">PythonAnywhere</a> — Host, run, and code Python in the cloud</li></ul><p>The <a href="https://www.python.org/">offical Python website</a> also has a <em>Launch Interactive Shell</em> option (<a href="https://www.python.org/shell/">https://www.python.org/shell/</a>), which gives access to a REPL session.</p><h2><a href="#first-program" id="first-program">First program</a></h2><p>It is customary to start learning a new programming language by printing a simple phrase. Create a new directory, say <code>Python/programs</code> for this book. Then, create a plain text file named <code>hello.py</code> with your favorite text editor and type the following piece of code.</p><pre><code># hello.py
print('*************')
print('Hello there!')
print('*************')
</code></pre><p>If you are familiar with using command line on a Unix-like system, run the script as shown below. Other options to execute a Python program will be discussed in the next section.</p><pre><code>$ python3.9 hello.py
*************
Hello there!
*************
</code></pre><p>A few things to note here. The first line is a comment, used here to indicate the name of the Python program. <code>print()</code> is a built-in function, which can be used without having to load some library. A single string argument has been used for each of the three invocations. <code>print()</code> automatically appends a newline character by default. The program ran without a compilation step. As quoted earlier, Python is an <em>interpreted</em> language. More details will be discussed in later chapters.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> All the Python programs discussed in this book, along with related text files, can be accessed from my GitHub repo <a href="https://github.com/learnbyexample/100_page_python_intro/tree/main/programs">learnbyexample: 100_page_python_intro</a>. However, I highly recommend typing the programs manually by yourself.</p></blockquote><h2><a href="#ide-and-text-editors" id="ide-and-text-editors">IDE and text editors</a></h2><p>An <strong>integrated development environment</strong> (IDE) might suit you better if you are not comfortable with the command line. IDE provides features likes debugging, syntax highlighting, autocompletion, code refactoring and so on. They also help in setting up <strong>virtual environment</strong> to manage different versions of Python and modules (more on that later).</p><p>If you install Python on Windows, it will automatically include <strong>IDLE</strong>, an IDE built using Python's <code>tkinter</code> module. On Linux, see if you already have the program <code>idle3.9</code>. Otherwise you may have to install it separately, for example, <code>sudo apt install idle-python3.9</code> on Ubuntu.</p><p>When you open IDLE, you'll get a Python shell (discussed in the next section). For now, click the <strong>New File</strong> option under <strong>File</strong> menu to open a text editor. Type the short program <code>hello.py</code> discussed in the previous section. After saving the code, press <strong>F5</strong> to run it. You'll see the results in the shell window.</p><p>Screenshots from the text editor and the Python shell are shown below.</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/hello.png" alt="hello.py program on IDLE editor"></p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/Python_shell_run.png" alt="Python shell example with output from an executed program"></p><p>Popular alternatives to IDLE are listed below:</p><ul><li><a href="https://thonny.org/">Thonny</a> — Python IDE for beginners, lots of handy features like viewing variables, debugger, step through, highlight syntax errors, name completion, etc</li><li><a href="https://www.jetbrains.com/pycharm/">Pycharm</a> — smart code completion, code inspections, on-the-fly error highlighting and quick-fixes, automated code refactorings, rich navigation capabilities, support for frameworks, etc</li><li><a href="https://www.spyder-ide.org/">Spyder</a> — typically used for scientific computing</li><li><a href="https://jupyter.org/">Jupyter</a> — web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text</li><li><a href="https://vscodium.com/">VSCodium</a> — community-driven, freely-licensed binary distribution of VSCode</li><li><a href="https://github.com/vim/vim">Vim</a>, <a href="https://www.gnu.org/software/emacs/">Emacs</a>, <a href="https://www.geany.org/">Geany</a>, <a href="https://wiki.gnome.org/Apps/Gedit">Gedit</a> — text editors with support for syntax highlighting and more</li></ul><h2><a href="#repl" id="repl">REPL</a></h2><p>One of the best features of Python is the interactive shell. Such shells are also referred to as REPL, which is an abbreviation for <strong>R</strong>ead <strong>E</strong>valuate <strong>P</strong>rint <strong>L</strong>oop. The Python REPL makes it easy for beginners to try out code snippets for learning purposes. Beyond learning, it is also useful for developing a program in small steps, debugging a large program by trying out few lines of code at a time and so on. REPL will be used frequently in this book to show code snippets.</p><p>When you launch Python from the command line, or open IDLE, you get a shell that is ready for user input after the <code>&gt;&gt;&gt;</code> prompt.</p><pre><code>$ python3.9
Python 3.9.0 (default, Dec  2 2020, 10:42:13) 
[GCC 5.4.0 20160609] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 
</code></pre><p>Try the below instructions. The first one displays a greeting using the <code>print()</code> function. Then, a user defined variable is used to store a string value. To display the value, you can either use <code>print()</code> again or just type the variable name. Expression results are immediately displayed in the shell. Name of a variable by itself is a valid expression. This behavior is unique to the REPL and an expression by itself won't display anything when used inside a script.</p><pre><code>&gt;&gt;&gt; print('have a nice day')
have a nice day

&gt;&gt;&gt; username = 'learnbyexample'
&gt;&gt;&gt; print(username)
learnbyexample

# use # to start a single line comment
# note that string representation is shown instead of actual value
# details will be discussed later
&gt;&gt;&gt; username
'learnbyexample'

# use exit() to close the shell, can also use Ctrl+D shortcut
&gt;&gt;&gt; exit()
</code></pre><p>I'll stress again the importance of following along the code snippets by manually typing them on your computer. Programming requires hands-on experience too, reading alone isn't enough. As an analogy, can you learn to drive a car by just reading about it? Since one of the prerequisite is that you should already be familiar with programming basics, I'll extend the analogy to learning to drive a different car model. Or, perhaps a different vehicle such as a truck or a bus might be more appropriate here.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> Depending on the command line shell you are using, you might have the <code>readline</code> library that makes it easier to use the REPL. For example, <code>up</code> and <code>down</code> arrow keys to browse code history, re-execute them (after editing if necessary), search history, autocomplete based on first few characters and so on. See <a href="https://en.wikipedia.org/wiki/GNU_Readline">wikipedia: GNU readline</a> and <a href="https://wiki.archlinux.org/index.php/readline">wiki.archlinux: readline</a> for more information.</p></blockquote><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> You can use <code>python3.9 -q</code> to avoid <em>version and copyright messages</em> when you start an interactive shell. Use <code>python3.9 -h</code> or visit <a href="https://docs.python.org/3/using/cmdline.html">docs.python: Command line and environment</a> for documentation on cli options.</p></blockquote><h2><a href="#documentation-and-getting-help" id="documentation-and-getting-help">Documentation and getting help</a></h2><p>The offical Python website has an extensive documentation located at <a href="https://docs.python.org/3/">https://docs.python.org/3/</a>. This includes a tutorial, which is much more comprehensive than the contents presented in this book, several guides for specific modules like <code>re</code> and <code>argparse</code> and various other information.</p><p>Here's a couple of annotated screenshots:</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/py_docs_1.png" alt="Python documentation: part 1"></p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/py_docs_2.png" alt="Python documentation: part 2"></p><p>Python provides a <code>help()</code> function, which is quite handy to use from the REPL. If you type <code>help(print)</code> and press the Enter key, you'll get a screen as shown below. If you are using IDLE, the output would be displayed on the same screen. Otherwise, the content might be shown on a different screen depending on your <code>pager</code> settings. Typically, pressing the <code>q</code> key will quit the <code>pager</code> and get you back to the shell.</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/help_print.png" alt="help print"></p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> Quotes are necessary, for example <code>help('import')</code> and <code>help('del')</code>, if the topic you are looking for isn't an object.</p></blockquote><p>If you get stuck with a problem, there are several ways to get it resolved. For example:</p><ol><li>read/search for that particular topic from documentation/books/tutorials/etc</li><li>reduce the code as much as possible so that you are left with minimal code necessary to reproduce the issue</li><li>talk about the problem with a friend/colleague/inanimate-objects/etc (see <a href="https://rubberduckdebugging.com/">Rubber duck debugging</a>)</li><li>search about the problem online</li></ol><p>You can also ask for help on forums. Make sure to read the instructions provided by the respective forums before asking a question. See also <a href="http://catb.org/%7Eesr/faqs/smart-questions.html#before">how to ask smart-questions</a>. Here's some forums you can use:</p><ul><li><a href="https://www.reddit.com/r/learnpython">/r/learnpython</a> and <a href="https://www.reddit.com/r/learnprogramming/">/r/learnprogramming/</a> — beginner friendly</li><li><a href="https://python-forum.io/">python-forum</a> — dedicated Python forum, encourages back and forth discussions based on the topic of the thread</li><li><a href="https://www.reddit.com/r/Python/">/r/Python/</a> — general Python discussion</li><li><a href="https://stackoverflow.com/tags/python">stackoverflow: python tag</a></li></ul><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> The <a href="https://learnbyexample.github.io/100_page_python_intro/debugging.html#debugging">Debugging</a> chapter will discuss more on this topic.</p></blockquote></main><nav aria-label="Page navigation"><a rel="prev" href="https://learnbyexample.github.io/100_page_python_intro/preface.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left"> <i></i> </a><a rel="next" href="https://learnbyexample.github.io/100_page_python_intro/numeric-data-types.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div><nav aria-label="Page navigation"><a rel="prev" href="https://learnbyexample.github.io/100_page_python_intro/preface.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left"> <i></i> </a><a rel="next" href="https://learnbyexample.github.io/100_page_python_intro/numeric-data-types.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div>]]>
            </description>
            <link>https://learnbyexample.github.io/100_page_python_intro/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076721</guid>
            <pubDate>Tue, 09 Feb 2021 12:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[José Valim Reveals “Project Nx” (Numerical Elixir) [audio]]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26076680">thread link</a>) | @thibaut_barrere
<br/>
February 9, 2021 | https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
		<p>
José Valim visits and finally publicly reveals what Project Nx is! He and others have been working on it for 3 months and he’s finally ready to unveil it. José will speak more about it at the LambdaDays conference, demonstrating it with code and announcing the release and availability of the OpenSource code.</p>
<p>Nx stands for “Numerical Elixir”. The Nx project brings a unique numerical mode to Elixir along with GPU support. This important work lays the foundation for a powerful new era with data science in Elixir! Listen in as Jose discusses the details of how this works, how it came about, the goals of the project, what this means for the community, and what comes next.
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx">https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/122" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/122</a> – ElixirLS version 0.6.3 released</li>
<li><a href="https://github.com/elixir-lsp/elixir-ls/blob/master/CHANGELOG.md" target="_blank" rel="noopener noreferrer">https://github.com/elixir-lsp/elixir-ls/blob/master/CHANGELOG.md</a> – ElixirLS Changelog</li>
<li><a href="https://codesync.global/conferences/code-beam-v-america-2021/" target="_blank" rel="noopener noreferrer">https://codesync.global/conferences/code-beam-v-america-2021/</a> – CodeBEAM American conference dates March 10-12</li>
<li><a href="https://hexdocs.pm/oban/changelog.html#2-4-0-2021-01-26" target="_blank" rel="noopener noreferrer">https://hexdocs.pm/oban/changelog.html#2-4-0-2021-01-26</a> – Oban 2.4.0 released</li>
<li><a href="https://twitter.com/sorentwo/status/1354099475191652352" target="_blank" rel="noopener noreferrer">https://twitter.com/sorentwo/status/1354099475191652352</a> – Oban performance improvement charts</li>
<li><a href="https://github.com/wintermeyer/phx_tailwind_generators" target="_blank" rel="noopener noreferrer">https://github.com/wintermeyer/phx_tailwind_generators</a> – Phoenix TailwindCSS generator</li>
<li><a href="https://github.com/phoenixframework/phoenix/pull/4191" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix/pull/4191</a> – Phoenix JavaScript gets more modern with Phoenix ES modules</li>
<li><a href="https://fullstackphoenix.com/boilerplates/new" target="_blank" rel="noopener noreferrer">https://fullstackphoenix.com/boilerplates/new</a> – Feedback! We learned about the site FullStackPhoenix which helps you start new projects already setup with several options for how to configure it.</li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li>Nx stands for “Numerical Elixir”</li>
<li><a href="https://elixirforum.com/t/anyone-who-wants-to-speculate-about-this-tweet-from-jose/35772/68" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/anyone-who-wants-to-speculate-about-this-tweet-from-jose/35772/68</a> – A great text summary of the announcement found on ElixirForum.</li>
<li><a href="https://twitter.com/josevalim/status/1356880707474370560" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim/status/1356880707474370560</a> – José Valim released the new Nx logo during our recording. The cute animal is a Numbat!</li>
<li><a href="https://en.wikipedia.org/wiki/Numbat" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Numbat</a></li>
<li><a href="https://github.com/erlang/otp/pull/2890" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/pull/2890</a> – José’s pull request to add 16-bit floats in bitstrings to OTP</li>
<li><a href="https://numpy.org/" target="_blank" rel="noopener noreferrer">https://numpy.org/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Softmax_function</a></li>
<li><a href="https://pragprog.com/titles/smgaelixir/genetic-algorithms-in-elixir/" target="_blank" rel="noopener noreferrer">https://pragprog.com/titles/smgaelixir/genetic-algorithms-in-elixir/</a></li>
<li><a href="https://elixirforum.com/t/pelemay-formerly-hastega-challenge-for-gpgpu-on-elixir/22986" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/pelemay-formerly-hastega-challenge-for-gpgpu-on-elixir/22986</a></li>
<li><a href="https://erlang.org/doc/man/erl_nif.html#dirty_nifs" target="_blank" rel="noopener noreferrer">https://erlang.org/doc/man/erl_nif.html#dirty_nifs</a> – Information on Dirty NIFs</li>
<li><a href="https://twitter.com/bcardarella" target="_blank" rel="noopener noreferrer">https://twitter.com/bcardarella</a></li>
<li><a href="https://www.tensorflow.org/xla" target="_blank" rel="noopener noreferrer">https://www.tensorflow.org/xla</a></li>
<li><a href="https://tvm.apache.org/" target="_blank" rel="noopener noreferrer">https://tvm.apache.org/</a></li>
<li><a href="https://mlir.llvm.org/" target="_blank" rel="noopener noreferrer">https://mlir.llvm.org/</a></li>
<li><a href="https://github.com/google/jax" target="_blank" rel="noopener noreferrer">https://github.com/google/jax</a></li>
<li><a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">https://julialang.org/</a></li>
<li><a href="https://www.lambdadays.org/lambdadays2021/jose-valim" target="_blank" rel="noopener noreferrer">https://www.lambdadays.org/lambdadays2021/jose-valim</a> – LambdaDays speaker page</li>
<li><a href="https://www.lambdadays.org/lambdadays2021#programme" target="_blank" rel="noopener noreferrer">https://www.lambdadays.org/lambdadays2021#programme</a> – José speaks on day 2</li>
<li>Promo code for 15% off LambdaDays tickets! Just use “thinkingelixir15”</li>
<li><a href="https://twitter.com/josevalim" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim</a></li>
<li><a href="https://twitter.com/sean_moriarity" target="_blank" rel="noopener noreferrer">https://twitter.com/sean_moriarity</a></li>
<li><a href="https://twitter.com/elixirlang" target="_blank" rel="noopener noreferrer">https://twitter.com/elixirlang</a></li>
</ul>
<p><strong>Guest Information</strong></p>

<ul>
<li><a href="https://twitter.com/josevalim" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim</a> – on Twitter</li>
<li><a href="https://github.com/josevalim" target="_blank" rel="noopener noreferrer">https://github.com/josevalim</a> – on Github</li>
<li><a href="https://dashbit.co/" target="_blank" rel="noopener noreferrer">https://dashbit.co/</a> – Dashbit website and blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://twitter.com/cadebward" target="_blank" rel="noopener noreferrer">@cadebward</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#034 José Valim reveals Project Nx"><meta itemprop="uploadDate" content="2021-02-09T04:15:48-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT1H15M59S"><meta itemprop="description" content="José Valim visits and finally publicly reveals what Project Nx is! He and others have been working on it for 3 months and he's finally ready to unveil it. José will speak more about it at the LambdaDays conference, demonstrating it with code and announcing the release and availability of the OpenSource code. This is an exciting development that brings Elixir into areas it hasn't been used before. We also talk about what this means for Elixir and the community going forward. A must listen!



Show Notes online - https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3"><meta itemprop="contentSize" content="35.0"><div id="powerpress_player_189"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6278-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3" title="Download" rel="nofollow" download="034-project-nx-with-jose-valim.mp3">Download</a></p>	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076680</guid>
            <pubDate>Tue, 09 Feb 2021 12:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Objection to ORM Hatred]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 87 (<a href="https://news.ycombinator.com/item?id=26076622">thread link</a>) | @dsego
<br/>
February 9, 2021 | https://www.jakso.me/blog/objection-to-orm-hatred | <a href="https://web.archive.org/web/*/https://www.jakso.me/blog/objection-to-orm-hatred">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f2fc11fb4d616c1f00b5"><div><p>Whenever someone asks which <a href="https://github.com/sindresorhus/awesome-nodejs#database" target="_blank">Node.js ORM</a> they should use, one of the first answers is always some version of “<em>don’t use an ORM, just write SQL</em>”. This answer is then usually attacked with an opposite opinion along the lines of “<em>you need to use an ORM to hide all that nasty SQL</em>”. People always seem to ignore the third option: using <a href="https://vincit.github.io/objection.js/" target="_blank">an ORM that embraces SQL</a>!</p><p>I completely understand where the hatred comes from though. There are real problems in many ORMs, that <a href="https://medium.com/u/ac187d616e0b" target="_blank">Thomas Hunter II</a> summarizes well in his post <a href="https://blog.logrocket.com/why-you-should-avoid-orms-with-examples-in-node-js-e0baab73fa5" target="_blank">Why you should avoid ORMs</a>. The main points Thomas listed were</p><ol data-rte-list="default"><li><p>You learn the ORM, not SQL and that knowledge is usually not transferable to other tools.</p></li><li><p>Complex ORM calls are inefficient. ORMs have their own object-oriented query language which they try to convert to SQL, and it’s usually really difficult.</p></li><li><p>ORMs can’t do everything. The object oriented approach of most ORMs doesn’t map well to SQL. For many SQL operations, there is no object oriented equivalent.</p></li></ol><p>These problems arise from the fact that most ORMs are designed to abstract away SQL in favor of some object oriented interface. But not all ORMs are like that!</p><p>I created an ORM called <a href="https://vincit.github.io/objection.js/" target="_blank">objection.js</a> for exactly the reasons Thomas listed. The design goal of objection.js is to allow you to use SQL whenever possible and only provide a DSL (Domain Specific Language) or a custom concept when something cannot be easily done using SQL. I’ll get back to objection.js soon. First, I’ll introduce you to the most common argument for avoiding ORMs:</p><blockquote><p>It’s easier to write &lt;something&gt; in plain SQL than using an ORM</p></blockquote><p>This argument is usually followed by a contrived example like this:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_4953"><p>Yes, if you only need a flat list of items from one table at a time, by all means, don’t use an ORM! Of course you can use joins, subqueries and multiple queries to access related items in other tables, but that easily becomes tedious. For example, here’s a very basic query that joins a many-to-many relationship (children of a person) and a has-many relationship (pets of a person)</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_6074"><div><p>That’s already quite a bit of SQL. What if you want to join more relationships? How about nested relationships? You also need to repeat that every time you want to fetch the related objects. Not to mention the result of that query is a flat list of items and not a nested tree of objects.</p><p>The next thing any ORM hater would do is to use a library that converts that flat result list into a nicely nested object tree and then proceed to writing a bunch of helper functions for adding those joins to queries so that you don’t need to repeat yourself. You quickly realize that most of these helper functions look the same and only the table names and foreign keys are different. Then the obvious choice is to go ahead and define the relationships in a single place as objects and create a generic function that takes a relationship description object and outputs the needed joins.</p><p>Congratulations, you’ve just reinvented the ORM!</p><p>In my opinion, that’s all a good ORM is: a set of tools to make using SQL easier! It allows you to fully use all the features of SQL and the underlying database engine and only provides helpers and custom solutions to things that are difficult to achieve with just plain SQL.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_8837"><div><p>With objection.js, you always work with a<a href="https://vincit.github.io/objection.js/api/query-builder/#class-querybuilder" target="_blank"> query builder</a>. You can build any query and use as much SQL as you want but it also helps you to deal with the repetitive stuff like relations if you want it to. The <a href="https://vincit.github.io/objection.js/api/query-builder/join-methods.html#joinrelation" target="_blank">leftJoinRelation</a> method is given the names of the relations you want to join and objection.js uses the <a href="https://vincit.github.io/objection.js/guide/relations.html#examples" target="_blank">relation mappings</a> to create the joins. </p><p>Now you may be thinking, “that’s not much shorter and I still need to define the relationships somewhere”. Well yeah, but you only need to do that once. If your project is so simple that defining the relationships and models takes a significant part of your development time, it doesn’t matter whether you use an ORM or not.</p><p>The <a href="https://vincit.github.io/objection.js/api/query-builder/join-methods.html#joinrelation" target="_blank">joinRelation</a> query above is 100% equivalent to the previous SQL query and would still produce a flat list of result rows. You can easily get a tree of objects using the <a href="https://vincit.github.io/objection.js/guide/query-examples.html#eager-loading" target="_blank">joinEager</a> method:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_9918"><p>Loading nested relations is just as easy:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1554871633687_10767"><p>And in the next code block is the minimal SQL needed to carry out that query. The selects with aliases are needed to be able to build the object tree from the flat list.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1555046254723_11559"><p>For many ORMs, SQL concepts like subqueries are difficult or impossible to write. Since all objection.js operations return a <a href="https://vincit.github.io/objection.js/api/query-builder/" target="_blank">query builder</a>, writing <a href="https://vincit.github.io/objection.js/recipes/subqueries.html" target="_blank">subqueries</a> is just as easy as using plain SQL. For example, fetching all people that have at least one pet called ‘Fluffy’</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_14131"><p>But there’s also an easier way to write this in objection.js if you have defined the <code>pets</code> relationship for the <code>Person</code> model:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1554837408459_15231"><div><p>But that requires you to learn the ORM (which was one of the arguments against ORMs). You can still start by writing the SQL solution you are familiar with. Once you learn more about objection.js, you find helpers like this that improve your productivity.</p><p>Here’s another example of using the <a href="https://vincit.github.io/objection.js/api/model/static-methods.html#static-relatedquery" target="_blank">relatedQuery</a> helper</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1554876097081_10902"><div><p>If your application is simple and you rarely need to deal with nested data and relations, using plain SQL or a query builder like <a href="https://knexjs.org/" target="_blank">knex</a> can be a good option. However, in most applications you want to work with nested data and a lot of relations and an ORM can be a helpful tool. With objection.js, you don’t need to make a compromise. You get the flexibility of a query builder and the relational power of an ORM in the same package.</p><p>If you found any of this interesting, take a closer look at <a href="https://vincit.github.io/objection.js/" target="_blank">objection.js.</a></p><p>Some links to get you started</p><ul data-rte-list="default"><li><p><a href="https://vincit.github.io/objection.js/guide/installation.html" target="_blank">Getting started</a></p></li><li><p><a href="https://vincit.github.io/objection.js/guide/query-examples.html#eager-loading" target="_blank">Eager loading</a></p></li><li><p><a href="https://vincit.github.io/objection.js/guide/query-examples.html#graph-inserts" target="_blank">Graph inserts</a></p></li><li><p><a href="https://github.com/Vincit/objection.js/issues/1069" target="_blank">Who is using objection</a></p></li><li><p><a href="https://vincit.github.io/objection.js/guide/query-examples.html" target="_blank">Query examples</a></p></li><li><p><a href="https://vincit.github.io/objection.js/recipes/relation-subqueries.html" target="_blank">Relation subqueries</a></p></li></ul></div></div></div>]]>
            </description>
            <link>https://www.jakso.me/blog/objection-to-orm-hatred</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076622</guid>
            <pubDate>Tue, 09 Feb 2021 12:18:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pi from High School Maths]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26076128">thread link</a>) | @vonadz
<br/>
February 9, 2021 | https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html | <a href="https://web.archive.org/web/*/https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<p>Warning: I don’t think the stuff in this post has any direct practical application by itself (unless you’re a
nuclear war survivor and need to reconstruct maths from scratch or something). Sometimes I like to go back to basics,
though. Here’s a look at <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math> and areas of curved shapes without any calculus or transcendental functions.</p><h2 id="a-simple-algorithm-for-calculating-pi">A simple algorithm for calculating <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math></h2>
<p>This algorithm starts with simple number theoretic musing. Some whole numbers form neat Pythagorean triples
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
,
</mo>
<mi>
y
</mi>
<mo>
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(x, y, z)
</annotation>
</semantics></math> where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mi>
z
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = z^2
</annotation>
</semantics></math>. E.g., <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
3^2 + 4^2 = 5^2
</annotation>
</semantics></math>. It’s easy to find all the solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = 5^2
</annotation>
</semantics></math> through brute-force search because we know that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> can’t be bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
5
</mn>
</mrow>
<annotation encoding="application/x-tex">
5
</annotation>
</semantics></math>. Here they are:</p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<semantics>
<mrow>
<mrow>
<mtable displaystyle="true" columnalign="right left right left right left right left right left" columnspacing="0em">
<mtr>
<mtd>
<msup>
<mn>
0
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
0
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
</mtable>
</mrow>
</mrow>
<annotation encoding="application/x-tex">
\begin{aligned} 0^2 + 5^2 &amp;= 5^2 \\ 3^2 + 4^2 &amp;= 5^2 \\ 4^2 + 3^2 &amp;= 5^2 \\ 5^2 + 0^2 &amp;= 5^2 \end{aligned}
</annotation>
</semantics></math>
<p>(Plus all the negative-number combinations, but let’s stick with non-negative integers and just count 4 solutions.)
If we relax the equation, and count solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le 5^2
</annotation>
</semantics></math>, the answer turns out to be 26. Why care? Well, if <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
t
</mi>
</mrow>
<annotation encoding="application/x-tex">
t
</annotation>
</semantics></math> is the total number of solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le n^2
</annotation>
</semantics></math>, then</p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<semantics>
<mrow>
<munder>
<mi>
lim
</mi>
<mrow>
<mi>
n
</mi>
<mo>
→
</mo>
<mn>
∞
</mn>
</mrow>
</munder>
<mfrac>
<mrow>
<mn>
4
</mn>
<mi>
t
</mi>
</mrow>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<msup>
<mo stretchy="false">
)
</mo>
<mn>
2
</mn>
</msup>
</mrow>
</mfrac>
<mo>
=
</mo>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\lim_{n \to \infinity} \frac{4t}{(n+1)^2} = \pi
</annotation>
</semantics></math>
<p>Or, in code, here’s a simple program that estimates <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, getting more accurate for bigger values of the <code>n</code> variable:</p>
<figure>
<pre><code data-lang="d"><span>import</span> <span>std</span><span>;</span>

<span>ulong</span> <span>sq</span><span>(</span><span>ulong</span> <span>x</span><span>)</span> <span>pure</span>
<span>{</span>
    <span>return</span> <span>x</span> <span>*</span> <span>x</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
<span>{</span>
    <span>const</span> <span>n</span> <span>=</span> <span>args</span><span>.</span><span>length</span> <span>&gt;</span> <span>1</span> <span>?</span> <span>args</span><span>[</span><span>1</span><span>].</span><span>to</span><span>!</span><span>ulong</span> <span>:</span> <span>20</span><span>;</span>

    <span>ulong</span> <span>total</span><span>;</span>
    <span>foreach</span> <span>(</span><span>x</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
    <span>{</span>
        <span>foreach</span> <span>(</span><span>y</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
        <span>{</span>
            <span>if</span> <span>(</span><span>sq</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>sq</span><span>(</span><span>y</span><span>)</span> <span>&lt;=</span> <span>sq</span><span>(</span><span>n</span><span>))</span> <span>total</span><span>++;</span>
        <span>}</span>
    <span>}</span>

    <span>/*
    // Alternatively, for functional programming fans:
    const total =
        cartesianProduct(iota(n+1), iota(n+1))
                .count!(p =&gt; sq(p[0]) + sq(p[1]) &lt;= sq(n));
    */</span>

    <span>writef</span><span>(</span><span>"%.12f\n"</span><span>,</span> <span>4.0</span> <span>*</span> <span>total</span> <span>/</span> <span>sq</span><span>(</span><span>n</span><span>+</span><span>1</span><span>));</span>
<span>}</span></code></pre>
</figure>
<figure>
<pre><code data-lang="shell">
$ ./pi_calc 
3.038548752834
$ ./pi_calc 10000
3.141362256135
</code></pre>
</figure>
<p>Okay, that’s a little bit more accurate than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mn>
22
</mn>
<mn>
7
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{22}{7}
</annotation>
</semantics></math>. Unlike most formulae for <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, though, there’s a simple diagram that shows how it works. Imagine we lay out the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
,
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(x, y)
</annotation>
</semantics></math> integer pairs (where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> range from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>) on a 2D grid the obvious way. The figure below shows an example for <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
</mrow>
<annotation encoding="application/x-tex">
n=10
</annotation>
</semantics></math>, with the arrow <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
r
</annotation>
</semantics></math> pointing from the origin to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math>. <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
r
</annotation>
</semantics></math> and the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> components make a right-angled triangle, so <a href="https://www.cut-the-knot.org/pythagoras/">Pythagoras’s theorem</a> says that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = r^2
</annotation>
</semantics></math>. For <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
<mo>
=
</mo>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
r = 10 = n
</annotation>
</semantics></math>, so <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math> is on the boundary as a solution to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mn>
10
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le 10^2
</annotation>
</semantics></math>. That boundary (the set of real-valued points a constant distance <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
</mrow>
<annotation encoding="application/x-tex">
n=10
</annotation>
</semantics></math> from the origin) makes a quarter circle.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_calc_grid.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_calc_grid.svg" alt="Grid for calculating an estimate of pi"></a>
</figure>
<p>A circle is a simple, convex shape, and the grid points are evenly spaced, so the number of points inside the
quarter circle will be roughly proportional to the area. More specifically, the fraction of all the grid points inside
the quarter circle will be roughly the area of the quarter circle divided by the area of square around all points. The
quarter circle area is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
<mo>
÷
</mo>
<mn>
4
</mn>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2 \div 4
</annotation>
</semantics></math>, inside the square of area <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
r^2
</annotation>
</semantics></math> (remember, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
n = r
</annotation>
</semantics></math>), so <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
π
</mi>
<mn>
4
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{\pi}{4}
</annotation>
</semantics></math> of all points represent solutions. The <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> values count from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, so there are <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<msup>
<mo stretchy="false">
)
</mo>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
(n+1)^2
</annotation>
</semantics></math> grid points. Rearrange the equations and you get a formula for estimating <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math> from a solution count. The grid points keep drawing an arbitrarily more accurate circle as
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math> gets bigger (just like a higher-resolution computer monitor does) so the estimate is exact in the
limit.</p>
<h2 id="a-faster-implementation">A faster implementation</h2>
<p>The code above is simple but slow because it brute-force scans over all <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
<mo>
×
</mo>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(n+1) \times (n+1)
</annotation>
</semantics></math>possible <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> values. But we obviously don’t need to scan <em>all</em> values. If we know that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le n^2
</annotation>
</semantics></math>, then making <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> or <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> smaller will only give us another solution. We don’t need to keep testing smaller values after we
find a solution. Ultimately, we only need to find the integral points around the boundary. Here’s a faster algorithm
based on that idea.</p>
<p>Imagine we scan along the integral <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> values and find the maximum integral <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> value that still gives us a solution. This gives us a border line marked in red in the figure
below. If <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
<mo>
=
</mo>
<mn>
8
</mn>
</mrow>
<annotation encoding="application/x-tex">
y=8
</annotation>
</semantics></math> for a given <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value, we instantly know there are <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
8
</mn>
<mo>
+
</mo>
<mn>
1
</mn>
<mo>
=
</mo>
<mn>
9
</mn>
</mrow>
<annotation encoding="application/x-tex">
8 + 1 = 9
</annotation>
</semantics></math> solutions with that given <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo lspace="0.11111em" rspace="0em">
+
</mo>
<mn>
1
</mn>
</mrow>
<annotation encoding="application/x-tex">
+ 1
</annotation>
</semantics></math> to count the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
<mo>
=
</mo>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
y=0
</annotation>
</semantics></math> solution).</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_fast_calc_grid.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_fast_calc_grid.svg" alt="Estimating pi efficiently by tracing circle boundary"></a>
</figure>
<p>Note that as <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> scans from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> starts at <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math> and decreases to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math>. Importantly, it <em>only</em> decreases — it’s monotonic. So if we scan <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, we can find the next boundary <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> point by starting from the previous boundary point and searching downwards. Here’s some code:</p>
<figure>
<pre><code data-lang="d"><span>ulong</span> <span>y</span> <span>=</span> <span>n</span><span>,</span> <span>total</span><span>;</span>
<span>foreach</span> <span>(</span><span>x</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
<span>{</span>
    <span>while</span> <span>(</span><span>sq</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>sq</span><span>(</span><span>y</span><span>)</span> <span>&gt;</span> <span>sq</span><span>(</span><span>n</span><span>))</span> <span>y</span><span>--;</span>
    <span>total</span> <span>+=</span> <span>y</span> <span>+</span> <span>1</span><span>;</span>
<span>}</span></code></pre>
</figure>
<p>This version still has nested loops, so it might look like it’s still <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n^2)
</annotation>
</semantics></math>. However, the inner <code>while</code> loop executes a
varying number of times for each <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value. Often the <code>y--</code> doesn’t trigger at
all. In fact, because <code>y</code> starts from <code>n</code> and monotonically decreases to 0, we know the <code>y--</code> will be executed exactly <code>n</code> times in total. There’s no instruction in that code that executes more
than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n)
</annotation>
</semantics></math> times, total, so the whole algorithm is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n)
</annotation>
</semantics></math>.</p>
<p>With 64b <code>ulong</code> integers, the largest value of <code>n</code> that works before overflow is 4294967294:</p>
<figure>
<pre><code data-lang="shell">
$ ./pi_calc 4294967294
3.141592653058
</code></pre>
</figure>
<p>There are ways to get faster convergence using numerical integration tricks, but I like the way this algorithm only
uses integer arithmetic (up until the final division), and can be understood directly from simple diagrams.</p>
<h2 id="area-of-a-circle-without-calculus">Area of a circle without calculus</h2>
<p>Perhaps you feel a bit cheated because that algorithm assumes the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math> formula for the area of a circle. Sure, that’s arguably included in “high school maths”, but it’s
something students just get told to remember, unless they study integral calculus and derive it that way. But if we’re
going to assume <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math>, why not assume the theory of trigonometric functions as well, and just use <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<mo>
=
</mo>
<mn>
4
</mn>
<mo lspace="0em" rspace="0.16667em">
atan
</mo>
<mo stretchy="false">
(
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\pi = 4\atan(1)
</annotation>
</semantics></math>?</p>
<p>The great ancient Greek mathematician Archimedes figured out the circle area over two thousand years ago without
integral calculus (or trigonometric functions for that matter). He started with an elegant insight about regular (i.e.,
equal-sided) polygons.</p>
<p>The famous <a href="https://mathcs.clarku.edu/~djoyce/java/elements/bookI/propI37.html">“half base times height”
formula for the area of a triangle already had a well-known proof in the first book of Euclid’s Elements of
Geometry</a> (easily derived from <a href="https://mathcs.clarku.edu/~djoyce/java/elements/bookI/propI35.html">a
theorem about parallelograms</a>). Conveniently, any regular polygon can be split into equal triangles joined to the
centre. For example, a regular hexagon splits into six triangles, as in the figure below. We can take any one of the
triangles (they’re all the same) and call the “base” the side that’s also a side of the polygon. Then the “height” is
the line from the centre of the base to the centre of the polygon.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon.svg" alt="Explanation of perimeter-to-area ratio of regular polygons"></a>
</figure>
<p>Now here’s Archimedes’s neat insight: The ratio of the triangle area to the base is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math>. If you add up all the areas, you get the area of the polygon. Likewise, if you add up all the
bases, you get the perimeter of the polygon. Because the triangle area/base ratio is a constant <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math> for all triangles, the area/perimeter ratio for the whole polygon is the same <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math>. As a formula, the area of <em>any</em> regular polygon is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
P \times \frac{h}{2}
</annotation>
</semantics></math> (where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
</mrow>
<annotation encoding="application/x-tex">
P
</annotation>
</semantics></math> is the perimeter).</p>
<p>If you think of a circle as a regular polygon with infinitely many sides (so that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
</mrow>
<annotation encoding="application/x-tex">
h
</annotation>
</semantics></math> becomes the radius of the circle), and use the circle circumference (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
2\pi r
</annotation>
</semantics></math>) as your basic definition of <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, then that implies the area of a circle is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
<mo>
=
</mo>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2} = \pi r^2
</annotation>
</semantics></math>.</p>
<p>Of course, Archimedes was a respected mathematician who couldn’t get away with just assuming that anything true of a
polygon is true of a circle (counterexample: all polygons have bumpy corners, but circles don’t). He used the kind of
geometric proof by contradiction that was popular in his day. (He even took it further and analysed spheres, cylinders,
parabolas and other curved objects, almost inventing something like modern real analysis a couple of millenia early.)
Sadly, not all of his mathemetical work has survived, but <a href="https://flashman.neocities.org/ARCHCI1set.htm">the
key part of his Measurement of a Circle</a> has.</p>
<p>Here’s the high-level version. Archimedes claimed that the area of a circle is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. Suppose you think his value is too small, and the circle is really bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. That means there’s enough room inside the circle to fit a regular polygon that’s also bigger than
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. But Archimedes said that’s contradictory because for any such polygon, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
<mo>
&lt;
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
h \lt r
</annotation>
</semantics></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
<mo>
&lt;
</mo>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
P \lt 2\pi r
</annotation>
</semantics></math> (because each side of the polygon is a straight line that’s shorter than the circle arc that
connects the same points), so the area <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
A
</mi>
<mo>
=
</mo>
<mi>
P
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
<mo>
&lt;
</mo>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
A = P \times \frac{h}{2} \lt 2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. The polygon’s area can’t be both bigger and smaller than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_inner.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_inner.svg" alt="A regular polygon inside a circle"></a>
</figure>
<p>Archimedes argued that there’s a similar contradiction if you think <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math> is too big, and the circle area is smaller than that. In that case he could make a polygon that’s
also smaller than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>, yet still wraps around the circle. For this polygon, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
<mo>
=
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
h = r
</annotation>
</semantics></math>, but he said the perimeter of the polygon must be greater than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
2\pi r
</annotation>
</semantics></math><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>, so that the
polygon’s area must be bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>, even though it’s also meant to be smaller.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_outer.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_outer.svg" alt="A regular polygon around a circle"></a>
</figure>
<p>If both of those cases lead to contradiction, we’re left with the only alternative that the circle area is
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math>.</p>

</div></div>]]>
            </description>
            <link>https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076128</guid>
            <pubDate>Tue, 09 Feb 2021 11:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Insights – A Clang based tool which does C++ source to source transformation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26076096">thread link</a>) | @peter_d_sherman
<br/>
February 9, 2021 | https://cppinsights.io/about.html | <a href="https://web.archive.org/web/*/https://cppinsights.io/about.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p><a href="https://cppinsights.io/">C++ Insights</a> is a <a target="_blank" href="https://clang.llvm.org/">clang</a>-based tool which does a source to source transformation. Its goal is to make things visible, which normally and intentionally happen behind the scenes. It's about the magic the compiler does for us to make things work. Or looking through the classes of a compiler.</p> <p>Some time ago, I started looking into some new things we got with C++11, C++14, C++17 and C++20. Amazing things like lambdas, range-based for-loops, and structured bindings. I put it together in a talk. You can find the <a target="_blank" href="https://www.andreasfertig.info/talks_dl/afertig-ndcolo-2017-fast-and-small.pdf">slides</a> and a <a target="_blank" href="https://youtu.be/Bt7KzFxcbgc">video</a> online.</p> <p>However, all that research and some of my training and teaching got me to start thinking about how it would be if we could see with the eyes of the compiler. Sure, there is an AST-dump, at least for clang. With tools like <a target="_blank" href="https://godbolt.org/#">Compiler Explorer</a>, we can see what code the compiler generates from a C++ source snippet. However, what we see is assembler. Neither the AST nor the <a target="_blank" href="https://godbolt.org/#">Compiler Explorer</a> output is in the language I write code, and therefore I'm most familiar with. Plus, when teaching students C++ showing an AST and explaining that it is all there was not quite satisfying for me.</p> <p>I started to write a <a target="_blank" href="https://clang.llvm.org/">clang</a>-based tool able to transform a range-based for-loop into the compiler-internal version. Then, I did the same for structured bindings and lambdas. In the end, I ended up doing a lot more as initially planned. It shows where operators are invoked, places in which the compiler does some casting. <a href="https://cppinsights.io/">C++ Insights</a> is able to deduce the type behind <code>auto</code> or <code>decltype</code>. The goal is to produce compilable code. However, this is not possible in all places.</p> <p>Still, there is work to do.</p> <p>I do not claim to get all the things right. This is just the initial version of <a href="https://cppinsights.io/">C++ Insights</a> I consider good enough to hand it to the public. Also, keep in mind that it is solely based on clang and my understanding of C++ and the AST.</p> <p>You can see, for example, the transformation of a <a href="https://cppinsights.io/s/f7710a4b">lambda</a>, <a href="https://cppinsights.io/s/40f6a267">range-based for-loop</a>, or <a href="https://cppinsights.io/s/e1a8cf40">auto</a>. Of course, you can transform any other C++ snippet.</p> <p>For those who like videos, there is a C++ Insights series on <a href="https://www.youtube.com/watch?v=NhIubRbFfuM&amp;list=PLm0Dc2Lp2ycaFyR2OqPkusuSB8LmifY8D" target="_blank">Youtube</a>. If you have topics you like me to speak about, please reach out to me.</p> <p>The version information of the C++ Insights version running on this website can be found here: <a href="https://cppinsights.io/version">https://cppinsights.io/version</a>.</p> <p>You can find the <a href="https://github.com/andreasfertig/cppinsights-web">source</a> of the web front-end and the tool <a href="https://github.com/andreasfertig/cppinsights">C++ Insights</a> on Github.</p> <p>If you like to support the project, consider <a href="https://github.com/andreasfertig/cppinsights/blob/master/CONTRIBUTING.md">submitting</a> a patch. Another alternative is to become a <a href="https://www.patreon.com/cppinsights" target="_blank">Patreon</a> supporter.</p> <p>Contact: <a href="mailto:andy at cppinsights.io">andy at cppinsights.io</a></p>  </div></div>]]>
            </description>
            <link>https://cppinsights.io/about.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076096</guid>
            <pubDate>Tue, 09 Feb 2021 11:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiler Class]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26075930">thread link</a>) | @ingve
<br/>
February 9, 2021 | https://norswap.com/compilers/ | <a href="https://web.archive.org/web/*/https://norswap.com/compilers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>In 2021, I'm teaching a master-level compiler class at <a href="https://uclouvain.be/">Université catholique de
Louvain</a>.</p>
<p>All the course materials are made available online, for anyone interested to
peruse. I'm also happy to <a href="mailto:norswap+compiler+q@gmail.com">answer</a> your questions.</p>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLOech0kWpH8-njQpmSNGSiQBPUvl8v3IM">Youtube Playlist</a></li>
<li><a href="https://drive.google.com/drive/folders/1cMgLvEiaWsyfip8wJXXilVhvM2XDrS-6">Slides</a></li>
</ul>
<p>The course's project is to create your own programming language. A few libraries
are supplied to assist in this task:</p>
<ul>
<li><a href="https://github.com/norswap/autumn">Autumn</a> (parsing)</li>
<li><a href="https://github.com/norswap/uranium/">Uranium</a> (semantic analysis)</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://norswap.com/compilers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26075930</guid>
            <pubDate>Tue, 09 Feb 2021 10:43:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: FINT, more than just a gRPC Test Client]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26075812">thread link</a>) | @namigop
<br/>
February 9, 2021 | http://www.bytesmotion.com/fint/ | <a href="https://web.archive.org/web/*/http://www.bytesmotion.com/fint/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					

					<div>
						

						<div id="start-content">
							

							<div id="ctl00_divCenter">

								
<div>


<div>

<div>

<div>


<div id="ctl00_mainContent_ctl00_divContent">
<h3><span>Full, comprehensive testing&nbsp;of gRPC services</span></h3>

<p>Fint is the only test software built for both developers and QA Testers!</p>





<p><a href="http://www.bytesmotion.com/fint/download-fint"><img alt="" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/download2.jpg"></a> <span>and have a look at the <a href="http://bytesmotion.com/fint/getting-started-with-fint">Getting Started</a> guide</span></p>





</div>
</div>


</div>


</div>


</div>

<div>


<div>


<div>

<div>


<div id="ctl00_mainContent_ctl01_divContent">
<h4>Quickly add gRPC Services</h4>

<table>
	<tbody>
		<tr>
			<td>
			<p><img alt="" height="324" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/fint-functionaltests.png" width="600"></p>
			</td>
			<td>&nbsp;</td>
			<td>
			<p>Fully supports adding GRPC services by discovering *.proto files or via server reflection. Unary, Server streams, client streams and Bi-directional streams are fully supported</p>
			</td>
		</tr>
	</tbody>
</table>



<h4>Create performance test cases</h4>

<table>
	<tbody>
		<tr>
			<td>
			<p><img alt="" height="324" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/fint-perftests.png" width="600"></p>
			</td>
			<td>&nbsp;</td>
			<td>
			<p>See how your service performs by running performance tests against it.&nbsp; Different types of load can be simulated (Constant Load, Incremental Load, Burst Load).&nbsp; A real-time plot of various performance metrics are shown.&nbsp; The distribution of of OK and error responses is also generated</p>
			</td>
		</tr>
	</tbody>
</table>



<h4>Create functional test cases</h4>

<table>
	<tbody>
		<tr>
			<td>
			<p><img alt="" height="324" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/fint-functionaltests.png" width="600"></p>
			</td>
			<td>&nbsp;</td>
			<td>
			<p>You can create functional test cases and save your test input, create and execute validation rules, generate the test report (html) with a Pass or Fail</p>
			</td>
		</tr>
	</tbody>
</table>



<h4>Create Test Sets</h4>

<table>
	<tbody>
		<tr>
			<td>
			<p><img alt="" height="324" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/fint-testsets.png" width="600"></p>
			</td>
			<td>&nbsp;</td>
			<td>
			<p>Group individual functional tests and create test sets that can be executed in one go.&nbsp; Tests can be executed in parallel or in sequence.&nbsp; Each test can also be executed individually and test reports are created per test case</p>
			</td>
		</tr>
	</tbody>
</table>



<h4>Quickly access your tests from dashboard</h4>

<table>
	<tbody>
		<tr>
			<td>
			<p><img alt="" height="324" src="http://www.bytesmotion.com/fint/Data/Sites/1/media/images/fint-dashboard.png" width="600"></p>
			</td>
			<td>&nbsp;</td>
			<td>
			<p>Service clients, functional tests, performance tests and others can be "starred" and added to the dashboard for a quick 1-click access</p>
			</td>
		</tr>
	</tbody>
</table>





<h3>And many more features...</h3>

<p><span><em>Have a look at<a href="http://bytesmotion.com/fint/full-list-of-features"> full list of features</a></em></span></p>

<hr>
</div>
</div>


</div>


</div>


</div>

							
</div>

							
						</div>
					</div>

					
				</div></div>]]>
            </description>
            <link>http://www.bytesmotion.com/fint/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26075812</guid>
            <pubDate>Tue, 09 Feb 2021 10:22:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My first eBook – results and feedback]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26075471">thread link</a>) | @alexellisuk
<br/>
February 9, 2021 | https://blog.alexellis.io/my-first-ebook-results-feedback/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/my-first-ebook-results-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
   <article>

        

        <section>
            <div><p>I wanted to write to you all and share that I've launched my first eBook called <a href="https://gumroad.com/l/serverless-for-everyone-else">"Serverless For Everyone Else"</a> - within the first three hours of launch, nobody bought a single copy and I thought that I'd got it all wrong.</p>
<p>The "everyone else" is a reference to how complicated and difficult cloud-based and Kubernetes-based FaaS has become. The eBook sets out to help indie developers, and individuals within corporations build and deploy functions using a new version of OpenFaaS (<a href="https://github.com/openfaas/faasd">faasd</a>) which is open source and can run on a single VM or VPS without much overhead.</p>
<p>The real power of functions comes in extending existing systems through webhooks, polling, or querying and updating state. I'll share some of these use-cases below including how I used functions to extend how the Gumroad marketplace worked.</p>
<h2 id="whywriteanebookanyway">Why write an eBook anyway?</h2>
<p>Why did I decide to write an eBook? If you've ever written about tech or spoken at a conference, then Packt has probably approached you on LinkedIn about writing for them. From what I hear, that kind of arrangement means writing in a word doc, with tight deadlines and cranking out 300+ pages. It wasn't for me.</p>
<p>I'd seen <a href="https://twitter.com/dvassallo">Daniel Vassallo</a> create an eBook about AWS and Twitter. Daniel had really good results using Gumroad to sell his self-published eBooks. Then there's <a href="https://twitter.com/adamwathan">Adam Wathan</a> who built Tailwind CSS and trained himself up as a UI designer. He wrote his own eBook and in his yearly review mentioned that it did 600k USD in passive sales, without any promotion.</p>
<p>Whilst I didn't expect to get anywhere close to those numbers with a specialist topic, I did want to know if people would buy something from me.</p>
<h2 id="thetiersatlaunch">The tiers at launch</h2>
<p>I launched with three tiers, with names and clear differentiation:</p>
<ul>
<li>Minimalist - 25 USD - just the eBook</li>
<li>DevOps PRO - 50 USD - the eBook, plus a Grafana dashboard and the YAML for faasd to enable it</li>
<li>The learner - 99 USD - the eBook, plus a Grafana dashboard,  the YAML for faasd to enable it and a video workshop ready in 7 days</li>
<li>The team player - the learner, but for 5 people in your company</li>
</ul>
<p>As long as your options add some value, it seems that people enjoy the choice and are willing to pay a little more.</p>
<p>So I tweeted about the eBook and then nothing happened for three hours.</p>
<p>I interpreted this as a failure. I'd been reading <a href="https://amzn.to/38N5uZy">"The Right It: Why So Many Ideas Fail and How to Make Sure Yours Succeed"</a>, and had convinced myself that this was a sign that nobody wanted the material.</p>
<p>Then I got my first sale, and felt a little relief, maybe I was wrong?</p>
<p><img src="https://user-images.githubusercontent.com/6358735/104810538-27b57080-57ed-11eb-905b-d042d3046adf.png" alt="Sale email"></p>
<p>My sales graph had one initial spike on the Friday, and kept going into the Sunday. What had happened? My Twitter audience and GitHub Sponsors came to lend their support.</p>
<p><img src="https://pbs.twimg.com/media/ErzMnuOXMAA_REk?format=jpg&amp;name=medium" alt="Initial spike"></p>
<p>Then things died down, and over the course of the week I wondered if I'd failed to find market fit. <a href="https://gumroad.com/">Gumroad</a> was sending me almost no organic traffic, and nobody was landing on the page via SEO.</p>
<p>It was still more money than I had expected to earn from the eBook within the first week, but I felt like with so much interest in OpenFaaS, that there was a broader audience to reach.</p>
<h2 id="gettingasecondpeak">Getting a second peak</h2>
<p>After the first week, I released the video workshop to the people who'd purchased that tier (99USD), and to get some feedback, I offered a free upgrade to the workshop for the tier just below (50USD). That resulted in another large spike in interest.</p>
<p><img src="https://camo.githubusercontent.com/4e204e93dcfc33679c997c739fbf4f651fdf268d23961bae6f9b4c25ad4ec145/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f45735a3372753258634155513451673f666f726d61743d6a7067266e616d653d6d656469756d" alt="Video workshop"></p>
<p>How did I fulfil the upgrade / discount? I did it by writing a function and deploying it to my Raspberry Pi, so that Gumroad would send a webhook, my code would query the dollar amount, and then send out an email to the customer over AWS SES.</p>
<p><img src="https://pbs.twimg.com/media/EscxNxbXAAEHD8z?format=jpg&amp;name=large" alt="The function running"></p>
<p>Get the source code here: <a href="https://github.com/alexellis/gumroad-responder">alexellis/gumroad-responder</a></p>
<p>After the second peak, I saw a complete drop-off again - and started to wonder why?</p>
<p>99% of referrals came from Twitter and email, so had I exhausted my network?</p>
<p>I went ahead and added a link on openfaas.com and on my blog at the end of each post, to try and get more views on the eBook. It's too early to tell if that is going to work out, but has resulted in a few conversions already.</p>
<p>One of the bits of feedback I got on the eBook was how users enjoyed the use-cases, and practical examples. I'd recently started video streaming, so invited a friend to my YouTube channel to talk about serverless use-cases.</p>
<p><img src="https://camo.githubusercontent.com/544dffaf339a4ff44439db1c14cd953de385640b99231688f8a49db61294a02e/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f457378444745505841415968724c4f3f666f726d61743d6a7067266e616d653d6c61726765" alt="Video on use-cases"></p>
<p><a href="https://www.youtube.com/watch?v=mzuXVuccaqI&amp;feature=youtu.be">Watch the recording</a></p>
<p>The recording generated a lot of interest and engagement for existing eBook customers, but no additional sales.</p>
<p>You can get the <a href="https://gist.github.com/alexellis/c72d7a385f801cc9b8deb7fcaa531b69">show notes</a> here which have lots of links for use-cases from hobbyists, indie devs and corporate users of OpenFaaS.</p>
<h2 id="mynextmilestone">My next milestone</h2>
<p>I am pleased with the results so far, and have learned a lot along the way. I also had a few people reach out to me directly asking for help who had taken inspiration from seeing someone actually go ahead and take a calculated risk.</p>
<p>I haven't quite got to 10k USD, which is a nice round number to aim for, but I can roughly understand what each peak means here, and whether they are repeatable.</p>
<p><img src="https://pbs.twimg.com/media/EtARGclXMAg7nJ-?format=jpg&amp;name=medium" alt="Approaching 10k"></p>
<p>Once the sales do cross that threshold, I'll write-up a how to guide and share the command lines and tools I used to generate the eBook.</p>
<h2 id="whatsnext">What's next</h2>
<p>I committed to providing free updates - because the eBook was partially experimental and I wanted to validate that it was useful. Using the <a href="https://slack.openfaas.io/">OpenFaaS Slack</a> helped here - I opened a new channel for people who'd bought the book, and enjoyed the feedback and engagement from this.</p>
<p>Some people charge extra for community, but it felt too hard to enforce the access for this.</p>
<p><img src="https://user-images.githubusercontent.com/6358735/104810333-b628f280-57eb-11eb-8be9-a2f6c773346b.png" alt="Original cover"></p>
<p>I generated my own eBook cover originally and then only later, got a professional designer involved.</p>
<p><img src="https://static-2.gumroad.com/res/gumroad/2028406193591/asset_previews/741f2ad46ff0a08e16aaf48d21810ba7/retina/social4.png" alt="New design"></p>
<p>It turns out that the cover may not matter with Gumroad, as long as it's not awful. Since changing cover, I've only seen two new sales.</p>
<p>Now that I have some initial feedback and have learned that people will buy things from me, I want to let goodwill rebuild, and my audience "recover" before launching a second eBook. I've done a lot of free blog posts and writing on Kubernetes, Docker, Golang and Raspberry Pi and analytics from my blog shows me what's popular.</p>
<blockquote>
<p>In 14 days, I've received more money than OpenFaaS corporate users have paid into the project over 4 years.</p>
</blockquote>
<p>Just because something you give away for free is popular, doesn't mean that anyone will be willing to pay for it. OpenFaaS itself is testament to that, with many corporations using it in production, without contributing code or finances back.</p>
<p>The Right It has taught me not to invest too much effort up front in any one idea - as it's likely to fail. Instead I'll be testing ideas - getting feedback by investing a few hours or days, not weeks.</p>
<p>I am sure I've missed out lots of details here, so feel free to ask me questions.</p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/my-first-ebook-results-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26075471</guid>
            <pubDate>Tue, 09 Feb 2021 09:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing my personal SSH infrastructure with Yubikeys]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26075386">thread link</a>) | @ingve
<br/>
February 9, 2021 | https://www.dzombak.com/blog/2021/02/Securing-my-personal-SSH-infrastructure-with-Yubikeys.html | <a href="https://web.archive.org/web/*/https://www.dzombak.com/blog/2021/02/Securing-my-personal-SSH-infrastructure-with-Yubikeys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<header>
				
				
				<time pubdate="" datetime="2021-02-08T19:08:13-05:00">
					<span>February</span>
					<span>08</span>
					<span>2021</span>
				</time>
				
			</header>
			
			<p>One recently-completed project I mentioned in January’s <a href="https://www.dzombak.com/blog/2021/01/Now-Jan-2021.html">“Now” post</a> was locking down SSH in my personal computing infrastructure using Yubikeys. In this post, I’ll outline my goals, the strategy I took, and the problems and solutions I ran into along the way.</p>

<h2>Goals &amp; Strategy</h2>

<p>Historically, I’ve used a pretty basic SSH setup for my personal projects: my user account on every laptop/desktop/server had its own key in <code>~/.ssh</code>, and I’d try to keep the <a href="https://www.ssh.com/ssh/authorized_keys/"><code>authorized_keys</code></a> lists on all my servers more-or-less up-to-date. This presents a number of obvious security problems.</p>

<p>I wanted to ensure that, should an attacker gain access to one of my servers, they can’t use that access to move onto any other computer I control. To do this, I moved to using a few <a href="https://www.yubico.com/">Yubikeys</a> to store my SSH keys; there’s no longer key material stored on any server for a hypothetical attacker to steal. The Yubikeys require a PIN, so this is an example of two-factor authentication: something I physically have, and something I know.</p>

<p><a href="https://www.cloudsavvyit.com/25/what-is-ssh-agent-forwarding-and-how-do-you-use-it/">SSH agent forwarding</a> is used to allow me to SSH from one server to another or fetch code from GitHub on a remote server. With <a href="https://github.com/FiloSottile/yubikey-agent"><code>yubikey-agent</code></a>, my preferred agent software, every single SSH operation — yes, even those performed via agent forwarding — requires a physical touch to confirm.</p>

<p>I use a private Git repository to synchronize SSH configuration (including <code>authorized_keys</code>, the list of public keys corresponding to my Yubikeys) between machines, with a modular local configuration system allowing me to quickly enable commonly-used SSH configuration blocks which only apply to a subset of my machines.</p>

<h2>Implementation</h2>

<h3>Yubikeys</h3>

<p>I found it easiest by far to use <a href="https://github.com/FiloSottile/yubikey-agent"><code>yubikey-agent</code></a> for this project. It’s pretty straightforward to set this up; the real work was figuring out how to smooth out the various difficulties I encountered later.</p>

<p>(The commands and configuration changes under this heading apply to client machines with attached Yubikeys.)</p>

<p>Install <code>yubikey-agent</code> with <a href="https://brew.sh/">Homebrew</a>:</p>

<pre><code>brew tap filippo.io/yubikey-agent https://filippo.io/yubikey-agent
brew install yubikey-agent
brew services start yubikey-agent
</code></pre>

<p>Run <code>yubikey-agent -setup</code> to generate a new SSH key on your Yubikey.</p>

<p>Set the <code>SSH_AUTH_SOCK</code> environment variable (do this in your <code>.bashrc</code> or <code>.zshrc</code>). In <a href="https://github.com/cdzombak/dotfiles/blob/800ca4e760da36171643e8a116e038cc4c4dcf31/zsh/.zshrc#L24">my dotfiles</a>, I first check that <code>yubikey-agent</code> is installed, then proceed:</p>

<pre><code>command -v yubikey-agent &gt;/dev/null 2&gt;&amp;1 &amp;&amp; export SSH_AUTH_SOCK="/usr/local/var/run/yubikey-agent.sock"
</code></pre>

<p>Enable SSH agent forwarding for a specific, trusted host (don’t enable it for all hosts; that’s a potential security issue) by adding <code>ForwardAgent yes</code> to that host’s block in your <code>~/.ssh/config</code>. A complete example might look like:</p>

<pre><code>Host dzombak.com
    User chris
    HostName dzombak.com
    ForwardAgent yes
</code></pre>

<p>This is a bit of a spoiler for a topic later in this blog post, but we’ll also add this to our <code>~/.ssh/config</code>:</p>

<pre><code>Host *
    IdentityAgent /usr/local/var/run/yubikey-agent.sock
</code></pre>

<p>This allows apps started from outside your terminal — like the GUI Git client, <a href="https://fork.dev/">Fork.app</a> — to find and use <code>yubikey-agent</code>.</p>

<h4>A note: Secretive.app</h4>

<p>I’d like to use the new macOS app <a href="https://github.com/maxgoedjen/secretive">Secretive</a>, which stores SSH keys in the Secure Enclave on newer MacBooks and requires Touch ID to authenticate. Unfortunately, for Reasons™ I’m still using macOS Mojave, and Secretive requires Catalina or Big Sur. I plan to move to Big Sur soon enough, since I want to get an M1 MacBook Pro when the 16” models are released, so I’ll be able to try Secretive soon enough. (Worth noting, this changes the security model somewhat, as the second factor is biometric rather than a PIN, but it’s still two factors.)</p>

<h3>Server Configuration</h3>

<p>Of course, moving to Yubikeys doesn’t solve much if your servers still allow password logins. On every server, in <code>/etc/ssh/sshd_config</code>, I set the following. Make this change only after you’ve set up a Yubikey and added it to <code>authorized_keys</code> for your user account on the server!</p>

<pre><code>ChallengeResponseAuthentication no
PasswordAuthentication no
PermitRootLogin no
</code></pre>

<p>(That last line — <code>PermitRootLogin no</code> — ensures that logins as <code>root</code> via SSH are never allowed, which is a good SSH best practice unrelated to Yubikeys.)</p>

<p><a href="https://www.cyberciti.biz/faq/howto-restart-ssh/">Restart the SSH service</a>, and immediately — before logging out — open a new terminal window and test that you can still login to the server with your Yubikey.</p>

<p>macOS tends to lose changes to <code>sshd_config</code> during OS upgrades, so after installing macOS updates I make sure to check that my SSH server configuration is intact.</p>

<h3>Git repo for SSH configuration</h3>

<p>I keep my <code>~/.ssh</code> directory, with a few important exceptions (keys are never committed!), in a private Git repo. This allows me to sync configuration and <code>authorized_keys</code> changes between systems easily. I’ve created a stripped-down version at <a href="https://github.com/cdzombak/ssh-example">cdzombak/ssh-example</a> which you can use as a basis for your own setup.</p>

<p>I’ll walk through the highlights here:</p>

<ul>
<li><a href="https://github.com/cdzombak/ssh-example/blob/main/README.md"><code>README.md</code></a> covers initial installation &amp; setup.</li>
<li><a href="https://github.com/cdzombak/ssh-example/blob/main/authorized_keys"><code>authorized_keys</code></a> is where you’ll add the public keys associated with the new, private SSH keys on your Yubikeys.</li>
<li><a href="https://github.com/cdzombak/ssh-example/blob/main/config"><code>config</code></a> is where you’ll add <code>Host</code> blocks for your servers. At the top, it sets some SSH best practices that I’ve accumulated over the years.</li>
<li><a href="https://github.com/cdzombak/ssh-example/blob/main/fix-permissions.sh"><code>fix-permissions.sh</code></a> ensures that <code>~/.ssh/authorized_keys</code> and <code>~/.ssh/rc</code> have the correct permissions. I run this after pulling from the repository; if it results in any changes the files’ permissions in the repo should be corrected.</li>
<li><a href="https://github.com/cdzombak/ssh-example/blob/main/rc"><code>rc</code></a> runs after I log into a machine via SSH. In this case, it updates a symlink in <code>~/.ssh/sock</code> to point to the new SSH agent socket. See the “Long-lived <code>screen</code> sessions” section, below, for an explanation on why this is necessary.</li>
<li><a href="https://github.com/cdzombak/ssh-example/tree/main/config.templates"><code>config.templates/</code></a> contains SSH configuration blocks which <em>can</em> be included on a given machine, but shouldn’t be included everywhere. The most important of these are <a href="https://github.com/cdzombak/ssh-example/blob/main/config.templates/yubikey-agent"><code>yubikey-agent</code></a>, which when enabled sets <code>IdentityAgent</code> to the <code>yubikey-agent</code> socket as described above; and <a href="https://github.com/cdzombak/ssh-example/blob/main/config.templates/homedir-ssh-auth-sock"><code>homedir-ssh-auth-sock</code></a>, which sets <code>IdentityAgent</code> to the symlink <code>rc</code> creates after an SSH login. On any given machine, I enable one and only one of these two configurations, depending whether it’s a client machine with Yubikey attached or a server which will rely on agent forwarding for any outgoing SSH connections.</li>
<li><a href="https://github.com/cdzombak/ssh-example/tree/main/config.local"><code>config.local/</code></a> is <a href="https://github.com/cdzombak/ssh-example/blob/main/config#L2">included by</a> <code>config</code> and ignored by Git. I can add symlinks from here to <code>config.templates</code> to enable a specific SSH configuration block on the machine.</li>
</ul>


<p>Those last two — <code>config.local</code> and <code>config.templates</code> — are important, because that’s how I achieve variations in SSH configuration between different machines. <a href="https://github.com/cdzombak/ssh-example/blob/main/README.md#configuration">The README covers</a> how to enable config templates on a given computer.</p>

<h2>Challenges &amp; Solutions</h2>

<h3>Long-lived <code>screen</code> sessions</h3>

<p>I use GNU <code>screen</code> (yes, still; I haven’t bothered to learn <code>tmux</code>) as a terminal multiplexer and to provide persistence between SSH sessions. This was a problem for SSH agent forwarding: when I first SSH in and start a <code>screen</code> session, the <code>SSH_AUTH_SOCK</code> environment variable would be set. But when I logged in from somewhere else and reattached to the <code>screen</code> session, the <code>SSH_AUTH_SOCK</code> environment variable wouldn’t get updated, so SSH agent forwarding was broken until I started a new <code>screen</code> session.</p>

<p><a href="https://gist.github.com/martijnvermaat/8070533">This Gist</a> helped me fix this situation. There are a few parts to this solution. (The commands and configuration changes under this heading apply to servers you’ll SSH into.)</p>

<p>First, we have to have a location for our SSH agent socket that doesn’t change between logins. These few lines in <a href="https://github.com/cdzombak/ssh-example/blob/main/rc#L5-L7"><code>~/.ssh/rc</code></a> achieve this:</p>

<pre><code>if test "$SSH_AUTH_SOCK" ; then
    ln -sf "$SSH_AUTH_SOCK" ~/.ssh/sock/ssh_auth_sock
fi
</code></pre>

<p>Great! Then we just need clients to use this new, always-updated socket. To do this, we configure <a href="https://github.com/cdzombak/dotfiles/blob/800ca4e760da36171643e8a116e038cc4c4dcf31/screen/.screenrc#L31-L32"><code>~/.screenrc</code></a> to set the environment variable <code>SSH_AUTH_SOCK</code>:</p>

<pre><code>setenv SSH_AUTH_SOCK $HOME/.ssh/sock/ssh_auth_sock
</code></pre>

<p>Finally, we’ll also want to include <code>IdentityAgent ~/.ssh/sock/ssh_auth_sock</code> in our SSH configuration. We can do this by including the <code>homedir-ssh-auth-sock</code> configuration block within my <a href="https://github.com/cdzombak/ssh-example">modular SSH configuration</a> setup:</p>

<pre><code>cd ~/.ssh/config.local
ln -s ../config.templates/homedir-ssh-auth-sock .
</code></pre>

<h3>SSH agent forwarding when running commands under sudo</h3>

<p>When running a command with <code>sudo</code>, you’re working in a new environment; your user’s environment variables are not preserved. This will, of course, break SSH agent forwarding.</p>

<p>To solve this, we want to preserve the <code>SSH_AUTH_SOCK</code> environment variable when using <code>sudo</code>. (The commands and configuration changes under this heading apply to servers you’ll SSH into.)</p>

<p>Run <code>visudo</code> (as <code>root</code>) to edit your <code>sudoers</code> file, and add:</p>

<pre><code>Defaults&gt;root    env_keep+=SSH_AUTH_SOCK
</code></pre>

<p>This means that when using <code>sudo</code> to run a command as <code>root</code> (not as any other user), your <code>SSH_AUTH_SOCK</code> variable remains intact, and agent forwarding works as expected.</p>

<h3>SSH agent forwarding via <code>SSH_AUTH_SOCK</code> doesn’t work with GUI macOS apps</h3>

<p><a href="https://github.com/ForkIssues/Tracker/issues/44">This issue in the Fork app’s issue tracker</a> was really helpful here. <code>.bashrc</code> and <code>.zshrc</code> don’t apply to GUI apps (unless you launch them from the terminal), so setting <code>SSH_AUTH_SOCK</code> <em>only</em> in shell configuration files won’t work.</p>

<p>This is why we need <code>IdentityAgent /usr/local/var/run/yubikey-agent.sock</code> in our SSH configuration. To enable this within my <a href="https://github.com/cdzombak/ssh-example">modular SSH configuration</a> setup:</p>

<pre><code>cd ~/.ssh/config.local
ln -s ../config.templates/yubikey-agent .
</code></pre>

<p>(This change applies to macOS client machines with attached Yubikeys.)</p>

<h3>Avoiding repeated mystery Yubikey prompts (using HTTPS for GitHub and Bitbucket repositories)</h3>

<p>After I set this up, my Yubikey would periodically blink as if I were trying to SSH into something, but I hadn’t tried to do anything with SSH! That was worrying, until I realized it was just <a href="https://fork.dev/">Fork</a> trying to update repository info in the background.</p>

<p>I decided to configure Git on my laptops to use HTTPS instead of SSH when communicating with GitHub and Bitbucket, so Fork can work in the background as it desires.</p>

<p>To do this, we’ll add the following to <code>~/.gitconfig</code>. (This …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dzombak.com/blog/2021/02/Securing-my-personal-SSH-infrastructure-with-Yubikeys.html">https://www.dzombak.com/blog/2021/02/Securing-my-personal-SSH-infrastructure-with-Yubikeys.html</a></em></p>]]>
            </description>
            <link>https://www.dzombak.com/blog/2021/02/Securing-my-personal-SSH-infrastructure-with-Yubikeys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26075386</guid>
            <pubDate>Tue, 09 Feb 2021 09:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why PWA Is the Future]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26074435">thread link</a>) | @theabbie
<br/>
February 8, 2021 | https://theabbie.github.io/blog/why-pwa-is-the-future | <a href="https://web.archive.org/web/*/https://theabbie.github.io/blog/why-pwa-is-the-future">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>


<p><i>PWAs are powerful, effective, fast and app-like. It's hard to imagine a mobile web property that could not be significantly improved via PWA implementation. They can also potentially eliminate the need for many vanity native apps that exist today. progressive web apps are for everyone, desktop and mobile users alike. I think it’s important to reiterate that there is no mobile web.</i></p>
<figure>
<amp-img src="assets/why-pwa-is-the-future.jpg" width="773" height="396" layout="responsive" sizes="(min-width: 500px) 500px, 80vw" alt="why pwa is the future"></amp-img>
<figcaption>why pwa is the future</figcaption>
</figure>
<nav aria-label="contents">
<ul>
<li><a href="#features">features</a></li>
<li><a href="#advantages">advantages</a>
<ul>
<li><a href="#Low_Development_Costs">Low Development Costs</a></li>
<li><a href="#App_Like_Look_and_Feel">App-Like Look and Feel</a></li>
<li><a href="#Fast_Installation">Fast Installation</a></li>
</ul>
</li>
<li><a href="#disadvantages">disadvantages</a>
<ul>
<li><a href="#compatibility_with_iOS">compatibility with iOS</a></li>
<li><a href="#Issues_with_legacy_devices">Issues with legacy devices</a></li>
<li><a href="#PWAs_cant_do_everything">PWAs cant do everything</a></li>
</ul>
</li>
<li><a href="#conclusion">conclusion</a></li>
<li><a href="#sources">sources</a>
<ul>
<li><a href="#css_tricks">css-tricks</a></li>
<li><a href="#quora">quora</a></li>
</ul>
</li></ul>
</nav>
<section>
<h2 id="features">features</h2>
 <ul>
  <li>Full responsiveness and browser compatibility</li>
    <li>Connectivity independence</li>
    <li>App-like interface.</li>
    <li>Push notifications</li>
    <li>Self-updates</li>
    </ul>
<figure>
<amp-img src="assets/features-of-pwa.jpg" width="919" height="749" layout="responsive" sizes="(min-width: 500px) 500px, 80vw" alt="features of pwa"></amp-img>
<figcaption>features of pwa</figcaption>
</figure>
<p>Progressive web apps have taken functionality from both native and web apps. They can run fast regardless of mobile operating systems and device types also providing rich functionality as if they were developed for a specific device. Thanks to easy installation, discoverability, automated updates, slow network or even the offline work mode, PWAs can enhance user experience.</p>
</section>
<section>
<h2 id="advantages">advantages</h2>
<figure>
<amp-img src="assets/advantages-of-pwa.jpg" width="700" height="420" layout="responsive" sizes="(min-width: 500px) 500px, 80vw" alt="advantages of pwa"></amp-img>
<figcaption>advantages of pwa</figcaption>
</figure>
<section>
<h3 id="Low_Development_Costs">Low Development Costs</h3>
<p>PWAs do not require different versions for various devices; a single progressive app meets the requirements of all endpoints on which it operates. So, it significantly reduces the amount of efforts that developers provide, and as a result, the cost to create a PWA decreases. The cost is three or four times lower than that of a native mobile app.</p>
</section>
<section>
<h3 id="App_Like_Look_and_Feel">App-Like Look and Feel</h3>
<p>Nowadays, mobile users prefer apps to browsers as applications compare favorably with browsers, as they are more user-friendly, can operate offline and have a more attractive interface. Progressive web applications provide an advanced user experience by combining the look and feel of mobile applications and the best of website performance.</p>
</section>
 <section>
<h3 id="Fast_Installation">Fast Installation</h3>
<p>Unlike regular mobile applications, PWAs do not require a long and complex installation process, which significantly improves user experience. Users just download an app, quickly and directly to their devices, and they do not need to go to the App Store or Google Play. It streamlines the procedure and significantly reduces user abandonment.</p>
</section>         
</section>

  
  
<section>
<h2 id="disadvantages">disadvantages</h2>
<figure>
<amp-img src="assets/disadvantages-of-pwa.jpg" width="640" height="480" layout="responsive" sizes="(min-width: 500px) 500px, 80vw" alt="disadvantages of pwa"></amp-img>
<figcaption>disadvantages of pwa</figcaption>
</figure>
<section>
<h3 id="compatibility_with_iOS">compatibility with iOS</h3>
<p>Since iOS 11.3, it’s been possible to run PWAs on Apple devices, but you can forget about compatibility with older devices.</p>
</section>
<section>
<h3 id="Issues_with_legacy_devices">Issues with legacy devices</h3>
<p>PWAs have been around for just a few years, so it shouldn’t come as a surprise that older mobile devices with outdated web browsers don’t support them too well. While this problem will inevitably solve itself in the future</p>
</section>
<section>
<h3 id="PWAs_cant_do_everything">PWAs cant do everything</h3>
<p>Their performance is also not as good as the performance of native apps, which has a lot to do with the fact that JavaScript is a single-threaded programming language. At the moment, access to certain important device features is still missing, including Bluetooth, proximity sensors, ambient light, advanced camera controls, and others.</p>
</section>           
</section>
 <section>
<h2 id="conclusion">conclusion</h2>
<p>Progressive Web App (PWA) is a web app, developed with features which give it an app like experience while browsing. PWA improves the user experience to the extent that users can feel the same as they do while using native apps.</p>
<amp-youtube data-videoid="ugAewC3308Y" layout="responsive" sizes="(min-width: 500px) 500px, 80vw" width="480" height="270"></amp-youtube> 
</section>
 <section>
<h2 id="sources">sources</h2>
<section>
<h3 id="css_tricks">css-tricks</h3>
<p><a href="https://css-tricks.com/why-progressive-web-apps-are-the-future-of-mobile-web/" title="css-tricks">css-tricks</a></p>
</section>
<section>
<h3 id="quora">quora</h3>
<p><a href="https://www.quora.com/Are-progressive-web-applications-PWAs-the-future-of-apps" title="why pwa is the future">why pwa is the future</a></p>
</section>      
</section>           
</article>
</div></div>]]>
            </description>
            <link>https://theabbie.github.io/blog/why-pwa-is-the-future</link>
            <guid isPermaLink="false">hacker-news-small-sites-26074435</guid>
            <pubDate>Tue, 09 Feb 2021 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs minor mode for d20 tabletop roleplaying games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26074259">thread link</a>) | @pabs3
<br/>
February 8, 2021 | https://spwhitton.name/tech/code/org-d20/ | <a href="https://web.archive.org/web/*/https://spwhitton.name/tech/code/org-d20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content">
<p><a href="https://melpa.org/#/org-d20"><img src="https://melpa.org/packages/org-d20-badge.svg" alt="MELPA"></a> <a href="https://stable.melpa.org/#/org-d20"><img src="https://stable.melpa.org/packages/org-d20-badge.svg" alt="MELPA Stable"></a></p>

<h2>Description</h2>

<p>org-d20 is a minor mode for Emacs’ <a href="https://orgmode.org/">Org-mode</a>
for GMs running games whose rules centre around rolling d20s.  It
should be useful for <em>Dungeons and Dragons</em> 3rd, 4th and 5th editions,
Paizo’s <em>Pathfinder</em>, and
<a href="https://en.wikipedia.org/wiki/D20_System">d20 System</a> games like <em>d20
Modern</em>.</p>

<p>The idea is that you’re already keeping your campaign notes in an
Org-mode file.  This minor mode does useful things for you while you
are visiting that buffer.  For example,</p>

<ul>
<li><p>rolling dice, with 5e’s advantage and disadvantage displayed in case
those are needed;</p></li>
<li><p>tracking combat turns and rounds right next to your existing
description of the monsters and the terrain.</p></li>
</ul>


<p>The minor mode’s defaults suit the way that I run D&amp;D 5e.  Patches to
add <code>defcustoms</code> to make org-d20 more suitable for other games, and
other sets of house rules, are welcome.</p>

<h2>Screenshot</h2>

<p><a href="https://spwhitton.name/img/org-d20-0.3pre.png"><img src="https://spwhitton.name/img/org-d20-0.3pre.png" width="700" height="638"></a></p>

<h2>Installation</h2>

<p>Users of Debian 12 or later or Ubuntu 21.04 or later can use <code>apt-get install
elpa-org-d20</code>.  Otherwise, you may copy <a href="https://git.spwhitton.name/org-d20/tree/org-d20.el"><code>org-d20.el</code></a> to somewhere in your
<code>load-path</code> and simply</p>

<pre><code>(autoload 'org-d20-mode "org-d20.el")
</code></pre>

<p>or install from <a href="http://melpa.org/">MELPA</a> (or MELPA stable).</p>



<p>Please see the included README.md.</p>



<ul>
<li><p>Anonymous checkout with git:</p>

<pre><code>  $ git clone https://git.spwhitton.name/org-d20
</code></pre></li>
<li><p><a href="https://git.spwhitton.name/org-d20/">Browse source online</a></p></li>
<li><a href="https://github.com/spwhitton/org-d20">GitHub mirror</a></li>
</ul>




<p>Please report bugs and submit patches/pull requests <a href="https://spwhitton.name/contact/">by e-mail</a>.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://spwhitton.name/tech/code/org-d20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26074259</guid>
            <pubDate>Tue, 09 Feb 2021 05:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech Companies Are Leaving San Francisco]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26074220">thread link</a>) | @barry-cotter
<br/>
February 8, 2021 | https://sfciti.org/sf-tech-exodus/#evidence | <a href="https://web.archive.org/web/*/https://sfciti.org/sf-tech-exodus/#evidence">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrap">

	<div id="content">
	
		<div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<p><span>For almost as long as we’ve been tracking the COVID-19 pandemic, sf.citi has been closely monitoring the San Francisco tech exodus. Of course, some of the forces driving this phenomenon—remote work and the growing appeal of cities beyond San Francisco—predate 2020. Few can argue, however, that the pandemic has accelerated these trends. What we’re seeing today is nothing short of a mass migration of tech companies and tech employees outside of the San Francisco Bay Area.</span></p>
<p><span>To help you keep up with fast-moving data surrounding the San Francisco tech exodus, sf.citi created an all-in-one resource. Below, you’ll find the latest insights about tech’s relocation, the economic implications of a tech exodus in San Francisco, and context around the policies that have led us to where we are today.</span></p>
<p><i><span>Is there information or data about the San Francisco tech exodus you think we’re missing? Let us know by emailing </span></i><a href="mailto:info@sfciti.org"><i><span>info@sfciti.org</span></i></a><i><span>. </span></i><i><span>For media inquiries, please contact sf.citi Marketing and Communications Manager Jacqueline McGraw at </span></i><a href="mailto:jacqueline@sfciti.org"><i><span>jacqueline@sfciti.org</span></i></a><i><span>.&nbsp;</span></i></p>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<p><b>Want to download sf.citi’s tech exodus infographic and receive updates about the San Francisco tech exodus directly in your inbox? Enter your email below.</b></p>
<p><img loading="lazy" src="https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" srcset="https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=1280%2C1280&amp;ssl=1 1280w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=1920%2C1920&amp;ssl=1 1920w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=2048%2C2048&amp;ssl=1 2048w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=80%2C80&amp;ssl=1 80w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=1000%2C1000&amp;ssl=1 1000w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png?resize=100%2C100&amp;ssl=1 100w, https://149503084.v2.pressablecdn.com/wp-content/uploads/2021/01/Abbreviated_Tech-Exodus-Infographic-1.png 2053w " sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></p>

		</div>
	</div>

	

		</div> 
	</div> 

	 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	

	<div>
		<p>
			
<h2><b>Tech Companies Are Leaving San Francisco</b></h2>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://sfciti.org/press-release-2/new-data-on-the-san-francisco-tech-exodus/" target="_blank"><img src="https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Downsizing-150x150.jpg" width="150" height="150" alt="Downsizing" title="Downsizing"></a></p>
	<div>
		<p><span>63%</span><br>
<strong>Companies that plan to or have already downsized their office in San Francisco</strong></p>
	</div>

	

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<ul>
<li>According to <a href="https://www.cushmanwakefield.com/en/united-states/insights/us-marketbeats/us-office-marketbeat-reports">data from Cushman &amp; Wakefield</a>, San Francisco’s office vacancy rate has risen to 16.7 percent, surpassing levels after both the 2008 Great Recession and the dot-com bust. San Francisco also recorded the lowest level of new leasing activity since at least the 1990s.</li>
<li>The Bay Area’s proportion of VC deal count in 2021 is expected to <a href="https://www.cnbc.com/2021/01/14/silicon-valleys-share-of-venture-capital-may-drop-below-20percent-in-2021.html" target="_blank" rel="noopener">fall below 20 percent</a> for the first time in history. “The COVID-19 pandemic and subsequent exodus from San Francisco will only exacerbate this trend,” writes VC analyst Kyle Stanford in PitchBook’s <a href="https://pitchbook.com/news/reports/q4-2020-pitchbook-analyst-note-2021-us-venture-capital-outlook" target="_blank" rel="noopener">2021 US Venture Capital Outlook report</a>.</li>
</ul>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p><strong>In January 2021, sf.citi <a href="https://sfciti.org/press-release-2/new-data-on-the-san-francisco-tech-exodus/">surveyed</a> 83 tech founders and CEOs, the majority of whom said they plan to downsize their presence in San Francisco and factor local regulations into their decisions to grow (or not) in San Francisco.&nbsp;</strong></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://sfciti.org/news/press-release/new-data-on-the-san-francisco-tech-exodus/" target="_blank"><img width="600" height="371" src="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-1.png?fit=600%2C371&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-1.png?w=600&amp;ssl=1 600w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-1.png?resize=300%2C186&amp;ssl=1 300w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-1.png?resize=500%2C309&amp;ssl=1 500w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://sfciti.org/news/press-release/new-data-on-the-san-francisco-tech-exodus/" target="_blank"><img width="600" height="371" src="https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-2.png?fit=600%2C371&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-2.png?w=600&amp;ssl=1 600w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-2.png?resize=300%2C186&amp;ssl=1 300w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/sf.citi-Survey-2.png?resize=500%2C309&amp;ssl=1 500w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			<h3>Prominent Tech Companies Downsizing IN or Moving from San Francisco</h3>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Brex will let its <a href="https://www.bizjournals.com/sanfrancisco/news/2020/11/25/brex-co-ceos-leaving-sf-will-the-startup-s-head.html" target="_blank" rel="noopener">San Francisco lease expire in 2021</a> after Co-Founders and Co-CEOs Henrique Dubugras and Pedro Franceschi <a href="https://medium.com/building-brex/remote-first-at-brex-1252cb30e347" target="_blank" rel="noopener">announced</a> Brex would become a remote-first company. The Co-Founders themselves are moving to Los Angeles.</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Digital Realty <a href="https://investor.digitalrealty.com/news-and-events/news/press-release-details/2021/Digital-Realty-Announces-Relocation-Of-Global-Headquarters-To-Austin-TX/default.aspx"><span>announced</span></a><span> it would move its headquarters from San Francisco to Austin, Texas. CEO A. William Stein cited Austin’s “affordable cost of living” and “supportive business climate” among reasons for the move.</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Optimizely<span> listed all </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/05/cruise-optimizely-soma-bay-area-exodus.html"><span>78,000 square feet</span></a><span> of its corporate headquarters in San Francisco’s South of Market neighborhood for lease. </span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Oracle<span> listed four out of the five floors, or </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/01/12/oracle-dumps-most-of-its-sf-office-space-on-subl.html"><span>85,622 square feet</span></a><span>, of office space it occupies for sublease at 475 Sansome Street in San Francisco’s Financial District. This comes several months after Oracle </span><a href="https://www.bloomberg.com/news/articles/2020-12-11/oracle-moves-headquarters-to-texas-joins-exodus-from-california"><span>announced</span></a><span> that it was moving its headquarters to Austin, Texas.</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>PayPal<span> is giving up </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/09/sfs-10-biggest-office-space-dumps-during-pandem.html?ana=e_sfbt_bn_editorschoice_editorschoice&amp;j=90549950&amp;t=Breaking%20News&amp;mkt_tok=eyJpIjoiTkROalkyRmhOMlF3TVdRNSIsInQiOiJJTnRYMGx5UktUS3lMcmJWeVdTK2liaUVVcVBMWW5kN1pYbXBYN1VrOGNtNThvaHdBOFdMUVNjWFJ3V2ZNMUdNYXJQQnFhellrWndKZlwvelBlMWtqRzNcL0lcL25rTmhCOW53WDlhRlZ1S2g1S1BuSWtvdWJRNEFBZXlzUTZBWDBpdyJ9"><span>101,000 square feet</span></a><span> of office space in San Francisco’s South of Market neighborhood.</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Stripe <a href="https://sfciti.org/news/update/trick-or-treat-stripe-leaves-sf-will-others-follow/"><span>announced</span></a><span> it would move its headquarters to South San Francisco in 2019. Now the company is preparing to shed all </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/09/sfs-10-biggest-office-space-dumps-during-pandem.html?ana=e_sfbt_bn_editorschoice_editorschoice&amp;j=90549950&amp;t=Breaking%20News&amp;mkt_tok=eyJpIjoiTkROalkyRmhOMlF3TVdRNSIsInQiOiJJTnRYMGx5UktUS3lMcmJWeVdTK2liaUVVcVBMWW5kN1pYbXBYN1VrOGNtNThvaHdBOFdMUVNjWFJ3V2ZNMUdNYXJQQnFhellrWndKZlwvelBlMWtqRzNcL0lcL25rTmhCOW53WDlhRlZ1S2g1S1BuSWtvdWJRNEFBZXlzUTZBWDBpdyJ9"><span>295,000 square feet</span></a><span> of its San Francisco office.</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Wish<span> listed </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/09/wish-sublease-one-sansome.html"><span>106,169 square feet</span></a><span> of its office at 1 Sansome Street for sublease as the company rethinks its office space needs in a post-pandemic world.</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>Yelp<span> listed all 14 stories (</span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/03/yelp-140-montgomery-listed-for-lease.html?ana=e_sfbt_bn_exclusive_exclusive&amp;j=90549105&amp;t=Breaking%20News&amp;mkt_tok=eyJpIjoiT0Rnell6TmxPR1kyWkdJeCIsInQiOiJyaGVybm5wcjFJNkFVUDh0MGxqSjFxcVFnaGlGK3dxSXU1WTVtRXZ5N1ZkekUyTHRQcGg0aXFqOEZ1WEZ2YU9YS09JWU9BcTZId0YzcU5DenVxQ2I1UVJwMXF6b3ZqeVJSSzg1SmM2T1RZZGJESzUrV3lES2pudmJFTVBTWTEzNiJ9"><span>161,876 square feet</span></a><span>) of its San Francisco headquarters for lease. Although Yelp intends to maintain a presence in San Francisco, a Yelp spokesperson confirmed that remote work has prompted the company to rethink its office needs: “With more employees working remotely we’re reducing some of our footprint in San Francisco.”</span></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p><strong>San Francisco-based Initialized Capital <a href="https://blog.initialized.com/2021/01/data-post-pandemic-silicon-valley-isnt-a-place/">released data</a> on how their portfolio companies will approach offices and remote work after the pandemic. Over 36 percent of Initialized’s portfolio companies plan to be fully decentralized after the COVID-19 pandemic. And 40 percent of founders say that the best place to start a company will be in the cloud (rather than San Francisco).&nbsp;</strong></p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://blog.initialized.com/2021/01/data-post-pandemic-silicon-valley-isnt-a-place/" target="_blank"><img width="1242" height="506" src="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?fit=1242%2C506&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?w=1242&amp;ssl=1 1242w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=300%2C122&amp;ssl=1 300w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=1024%2C417&amp;ssl=1 1024w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=768%2C313&amp;ssl=1 768w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=500%2C204&amp;ssl=1 500w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=800%2C326&amp;ssl=1 800w, https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-1.png?resize=600%2C244&amp;ssl=1 600w" sizes="(max-width: 1161px) 100vw, 1161px"></a></p>
		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://blog.initialized.com/2021/01/data-post-pandemic-silicon-valley-isnt-a-place/" target="_blank"><img width="1192" height="609" src="https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?fit=1192%2C609&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?w=1192&amp;ssl=1 1192w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=300%2C153&amp;ssl=1 300w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=1024%2C523&amp;ssl=1 1024w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=768%2C392&amp;ssl=1 768w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=500%2C255&amp;ssl=1 500w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=800%2C409&amp;ssl=1 800w, https://i2.wp.com/sfciti.org/wp-content/uploads/2021/01/Initialized-Capital-Data-2.png?resize=600%2C307&amp;ssl=1 600w" sizes="(max-width: 1161px) 100vw, 1161px"></a></p>
		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			<h3>Remote Work Policies Among Prominent San Francisco Bay Area Tech Companies</h3>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p><b>Remote work until at least June 2021:</b></p>
	</div>

		</div> 
	</div> 

	 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			<h2><b>Tech Workers Are Also Leaving San Francisco</b></h2>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://www.publiccommentsf.com/post/u-s-postal-service-data-suggests-significant-population-decline-in-san-francisco" target="_blank"><img src="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/U-Haul-Moving-Data-150x150.jpg" width="150" height="150" alt="U-Haul-Moving-Data" title="U-Haul-Moving-Data"></a></p>
	<div>
		<p><span>-10%</span><br>
<strong>Drop in San Francisco residents between March and November 2020</strong></p>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://www.zumper.com/blog/rental-price-data/" target="_blank"><img src="https://i0.wp.com/sfciti.org/wp-content/uploads/2021/01/Rent-Decrease-150x150.jpg" width="150" height="150" alt="Rent-Decrease" title="Rent-Decrease"></a></p>
	<div>
		<p><span>-24%</span><br>
<strong>Year-over-year median rent drop of a one-bedroom apartment in San Francisco</strong></p>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			<p><a href="https://bigtechnology.substack.com/p/where-tech-workers-are-moving-new" target="_blank"><img src="https://i1.wp.com/sfciti.org/wp-content/uploads/2021/01/Tech-Worker-Inflow-Outflow-150x150.jpg" width="150" height="150" alt="Tech-Worker-Inflow-Outflow" title="Tech-Worker-Inflow-Outflow"></a></p>
	<div>
		<p><span>-35%</span><br>
<strong>Year-over-year drop in the Bay Area’s tech worker inflow/outflow ratio—the steepest decline nationwide</strong></p>
	</div>

	

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			
<h2><b>Tech’s Contribution to the San Francisco Economy</b></h2>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Annual economic impact of San Francisco’s <a href="https://www.globest.com/2019/11/13/san-francisco-has-second-highest-tech-jobs-growth/?slreturn=20210026111933">100K tech jobs</a> on the San Francisco economy</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Yearly business tax revenue to San Francisco</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>San Francisco GDP generated by office activities</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<ul>
<li>San Francisco relies on a robust office space market for <a href="https://sfciti.org/news/the-covid-19-effect-on-san-franciscos-office-space-market/">critical revenue</a>, including for affordable housing. In the fall of 2019, the Board of Supervisors passed legislation to substantially increase the <a href="https://sfciti.org/news/the-covid-19-effect-on-san-franciscos-office-space-market/">linkage fee</a> on nonresidential developments—from $28.57 to $69.60 per square foot by 2022. <span>The slowdown in San Francisco’s office space market will mean less office space development, which in turn will hurt San Francisco’s affordable housing funding. (</span><a href="https://sfciti.org/news/march-2020-san-francisco-election-results-prop-d-and-prop-e-explained/"><span>Proposition E</span></a><span> passed in the March 2020 San Francisco election will also not help.)</span></li>
</ul>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			<h2><b>How a Tech Exodus Will Impact San Francisco’s Economy</b></h2>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Projected budget deficit for fiscal year 2021-22</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Decrease in revenue from San Francisco sales taxes</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Sales drop in downtown San Francisco businesses</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<ul>
<li><span>Near the end of 2020, City Controller Ben Rosenfield announced that San Francisco had not met its projected tax revenue targets, and the City faces an </span><a href="https://www.sfchronicle.com/local-politics/article/S-F-City-Hall-faces-another-big-budget-deficit-15717821.php"><span>additional budget deficit of $116 million</span></a><span>. That’s on top of the $1.5 billion budget deficit the City had to close in 2020. And in a </span><a href="https://sfcontroller.org/sites/default/files/Documents/Budget/Five%20Year%20Financial%20Plan%20FY21-22%20through%20FY%2025-26.pdf"><span>five-year budget forecast</span></a><span>, the City Controller’s Office predicts hundreds of millions of dollars in budget shortfalls over the next five years due to a widening gap between the City’s revenues and expenses.</span></li>
<li><span>Current and future San Francisco budget deficits are directly tied to losses in hotel, business, and sales taxes. The San Francisco Business Times </span><a href="https://www.bizjournals.com/sanfrancisco/news/2021/02/05/0205-foc-sanfrancisco.html"><span>reported</span></a><span> that the City expected close to $1.5 billion in business taxes in 2019-2020 but ended the fiscal year $228 million under budget.</span></li>
<li>From April to June 2020, revenue from San Francisco’s local sales tax dropped to <a href="https://www.sfchronicle.com/business/article/S-F-sales-tax-data-shows-likely-population-15632448.php">$30.8 million</a>, a decrease of 43 percent from 2019. Stay-at-home orders resulted in steep declines in brick-and-mortar sales taxes throughout the Bay Area. All of the counties surrounding San Francisco, however, saw increases in online sales taxes while San Francisco registered only a <a href="https://www.sfchronicle.com/business/article/Yes-people-are-leaving-San-Francisco-After-15635160.php">1 percent increase</a>—the worst showing among California’s 20 largest counties. Speaking to the <a href="https://www.sfchronicle.com/business/article/S-F-sales-tax-data-shows-likely-population-15632448.php">San Francisco Chronicle,</a> San Francisco Chief Economist Ted Egan attributes the drop in revenue to “tech people moving.”</li>
</ul>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<blockquote><p>
<i>The city’s near-term economic outlook relies mostly on the decisions [San Francisco’s office industries and their employees] make about the value of their downtown office space.<br>
</i>
</p></blockquote>
<p><span><strong>—San Francisco City Controller’s Office,</strong> <a href="https://sfcontroller.org/sites/default/files/Documents/Budget/Five%20Year%20Financial%20Plan%20FY21-22%20through%20FY%2025-26.pdf">Five-Year Financial Plan</a></span></p>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<ul>
<li>There is a fundamental link between the tech industry and San Francisco restaurants and small businesses, particularly in the City’s downtown. <a href="https://www.sfgate.com/food/article/San-Francisco-restaurant-closures-2020-COVID-19-15854041.php">OpenTable data</a> suggests San Francisco restaurant closures are up 35 percent year over year. Laurie Thomas, Executive Director of the Golden Gate Restaurant Association (GGRA), meanwhile, predicts that <a href="https://www.sfgate.com/food/article/San-Francisco-restaurant-closures-2020-COVID-19-15854041.php">85 percent</a> of San Francisco restaurants will close if they don’t receive government aid.</li>
</ul>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<p>
			
<h2><b>It Costs A LOT to Do Business in San Francisco</b></h2>

		</p>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Tech executives who consider San Francisco taxes and regulations significant factors in their decisions toward company growth</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Most expensive office space market in the United States</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 

	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			
<p><strong>Business tax increases passed in San Francisco over the last 10 years</strong></p>

		</div>
	</div>

	

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<ul>
<li>Despite being heralded as the innovation capital of the world, San Francisco policymakers have spent the last near-decade mounting regulatory barriers against the tech industry. In 2013, San Francisco <a href="https://www.theverge.com/2013/12/20/5231758/protesters-target-silicon-valley-shuttles-smash-google-bus-window">protested</a> private commuter shuttles. In 2018, San Francisco <a href="https://www.sfchronicle.com/business/article/Bye-bye-SF-scooters-as-Bird-Lime-and-Spin-go-on-12966874.php">ordered</a> scooter companies to cease operations. And in 2019, San Francisco attempted to <a href="https://www.sfchronicle.com/politics/article/New-version-of-SF-corporate-cafeteria-ban-swatted-13672338.php">ban corporate cafeterias.</a></li>
</ul>

		</div>
	</div>

		</div> 
	</div> 
</div></div><div data-speed="1"><div>
	<div data-animation="" data-delay="">
		<div>
			
	<div>
		<div>
			<blockquote><p>
<i><span>Divisive rhetoric and policies that seek to punish the tech sector and tech workers will only smother San Francisco’s innovation economy and fiscal sustainability for the long term. Now is the time to end the ‘us vs. them’ dynamic and work together to rebuild. San Francisco can be at its best again when we come together to improve our City.</span></i>
</p></blockquote>
<p><span><strong>—R…</strong></span></p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sfciti.org/sf-tech-exodus/#evidence">https://sfciti.org/sf-tech-exodus/#evidence</a></em></p>]]>
            </description>
            <link>https://sfciti.org/sf-tech-exodus/#evidence</link>
            <guid isPermaLink="false">hacker-news-small-sites-26074220</guid>
            <pubDate>Tue, 09 Feb 2021 05:29:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner's Guide to NFTs]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26073970">thread link</a>) | @donohoe
<br/>
February 8, 2021 | https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d | <a href="https://web.archive.org/web/*/https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>What are NFTs?</h3>
<p>Non-fungible token (NFT) is a term used to describe a unique digital asset whose ownership is tracked on a blockchain, such as Ethereum. Assets that can be represented as NFTs range from digital goods, such as items that exist within virtual worlds, to claims on physical assets such as clothing items or real estate. In the coming years, we will see NFTs used to unlock entirely new use cases that are only made possible by crypto.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/9799dae1-c2c9-4712-813b-10b23c279a36.jpeg" alt="Tokens redeemable for real world goods on Zora"></p><figcaption>Tokens redeemable for real world goods on Zora</figcaption></figure>
<p>While the Ethereum ecosystem is where most NFT activity has taken place to date, NFTs can exist on other smart contract platforms too. This is because, at their core, NFTs are just digital abstractions used to represent assets that are one of a kind. Non-fungible token isn’t the most intuitive term since we don’t commonly refer to the fungibility of objects in the physical world, but this is an important technical distinction when it comes to how an asset is represented on a blockchain. The goal for this post is not to detail every project within the NFT space, but to give a high level overview of what NFTs are, why they are interesting, and showcase some of their potential use cases.</p>
<h3>Why are NFTs interesting?</h3>
<p>NFTs are powerful because, when combined with other financial building blocks on Ethereum, they allow anyone to issue, own, and trade them. This makes interacting with NFTs significantly more efficient than in traditional platforms. The same reason why cryptocurrency used in payments is more efficient than traditional payments, that it is borderless and significantly easier to transfer, applies to NFTs. For example, if you want to create tradable in-game items as a game developer, then you can instantly have them be tradable through protocols that allow for decentralized exchange of NFTs. You don’t have to create your own marketplace or go through the onboarding process of a centralized platform in order to have the items be tradable.</p>
<p>NFT activity can go well past trading and include actions like being able to borrow and lend, support fractional ownership (e.g. <a href="https://www.niftex.com/">NIFTEX</a>), or use it as collateral in taking out a loan (e.g. <a href="https://nftfi.com/">NFTfi</a>). The possibilities are endless when you have the ability to combine NFTs with DeFi building blocks. For example, the game <a href="http://aavegotchi.com/">Aavegotchi</a> combines DeFi and NFT gaming where each Aavegotchi character represents a user’s collateral that is deposited within the lending platform <a href="https://aave.com/">Aave</a>, but you can also battle the characters, level them up, and equip wearables that change their traits.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/a1259686-6b61-455a-a204-f6e6da648f10.jpeg" alt="Aavegotchi gaming attributes change based on actions taken in DeFi"></p><figcaption>Aavegotchi gaming attributes change based on actions taken in DeFi</figcaption></figure>
<p>NFTs can cover an extremely wide variety of areas given they are simply digital representations of ownership but there has been significant growth within art and gaming in particular. Note that many digital works of art and gaming items are a subset of a larger category of NFT collectibles. There is also the emerging space of social tokens, which sometimes falls into the NFT category or that is closely related to it.</p>
<h3>Art</h3>
<p>NFTs can make fractionalized ownership more accessible, so if there is a valuable item that otherwise wouldn’t have been accessible for someone to own, now they can own a piece of it. Custody of a physical item still requires a trustworthy custodian, but being able to issue, hold, and trade it as a cryptoasset unlocks more use cases. One can also craft an NFT such that the creator receives a percentage of all secondary sales in a completely automated way. Artists typically don’t receive a cut of secondary sales in the traditional art world.</p>
<p>Programmable art is another interesting concept where a piece of artwork can incorporate on-chain data to dynamically update certain features or characteristics of the work. For example, one could create a piece of programmable art whose background changes if the price of ether goes above a certain dollar-value. There are countless creative possibilities.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/a51670c0-4a1c-4aaf-917d-0e551855b56d.jpeg" alt="Rutger van der Tas artwork that changes based on if it’s day or night"></p><figcaption>Rutger van der Tas artwork that changes based on if it’s day or night</figcaption></figure>
<p><a href="https://async.art/">Async Art</a> is a digital art marketplace known for programmable art. Many artists on Async sell artwork where someone is able to own the “master” copy which consists of a number of individual layers, but other people can own the individual layers and adjust their attributes over time. Imagine groups of people being able to own art collectively, where members of the group manage attributes of the work.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/fea07c75-8b3c-4592-b8f2-f5d6d92e544c.jpeg" alt="Osinachi artwork that includes a master and layers that can be individually adjusted"></p><figcaption>Osinachi artwork that includes a master and layers that can be individually adjusted</figcaption></figure>
<p>A common question about digital artwork is what can you do with it? These works can be displayed in digital frames in a physical setting for people to enjoy. The digital artist Beeple sold physical tokens along with his digital NFTs and made <a href="https://niftygateway.com/itemdetail/primary/0x6e5dc5405baefb8c0166bcc78d2692777f2cbffb/21">$3.5 million</a> from sales in an auction on the Nifty Gateway marketplace.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/8689be31-b33f-46ac-94aa-feea3a1b3dd1.jpeg" alt="Artist Beeple’s physical token that came with the NFT sale"></p><figcaption>Artist Beeple’s physical token that came with the NFT sale</figcaption></figure>
<p>Digital artwork can also be displayed in online collections like a <a href="https://superrare.co/thevault/collection">SuperRare profile</a> as well as in virtual worlds. There are a number of art galleries within <a href="http://cryptovoxels.com/">Cryptovoxels</a>, a virtual world where users can buy and sell land parcels as NFTs. As virtual reality spaces become more popular, having digital art to display will become more common. This wouldn’t be much different than someone spending money on video game items to customize a character’s appearance, already a multi-billion dollar industry.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/7386d358-d43d-4934-9ea5-b51c33932365.jpeg" alt="Digital art gallery in Cryptovoxels"></p><figcaption>Digital art gallery in Cryptovoxels</figcaption></figure>
<p>A common skepticism is that someone can just take a screenshot of the image or get a digital file so it’s not really scarce. However, the same argument could apply to physical items as well. Anyone can take a photo of the Mona Lisa or create a replica of it, but it isn’t the real item from the artist. People are willing to pay a premium for the original work. Another interesting aspect of digital art or collectibles is that you can easily verify the item’s ownership history. Some digital items might be worth more depending on who owned it in the past.</p>
<p>With NFTs, you can also prove that the item is real and tamper proof. This is an issue in the physical collectibles space. For example, a <a href="https://en.wikipedia.org/wiki/T206_Honus_Wagner">T206 Honus Wagner baseball card</a> was sold to Wayne Gretzky for $451k and sold again for several million dollars. One of the sellers of the card later admitted in court to trimming the card’s edges to make it look better. You can ensure NFT supply doesn’t change and there’s no counterfeit or continued printing. For example, there are many <a href="https://www.youtube.com/watch?v=AAvLC3fz068&amp;">counterfeit Black Lotus</a> cards in the popular game Magic: The Gathering. Common verification methods include bending the card to make sure it doesn’t crease or going through centralized grading services whose rating significantly affects the card's value.</p>
<h3>Gaming</h3>
<p>Steam, a popular video game platform, has a <a href="https://steamcommunity.com/market/?">Community Market</a> where in-game items can be bought and sold. Steam’s marketplace is centralized and collects a transaction fee of 5% for each item from the buyer. Games like Team Fortress 2 and Dota 2 take an additional fee of 10% for their items sold.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/4ad85fcf-b986-4b60-9fb5-925200fde3a9.jpeg" alt="Steam Community Market"></p><figcaption>Steam Community Market</figcaption></figure>
<p>Steam also restricts user wallet balances to $2,000 and the price of a single item to $1,800. While these cases are outliers, many in-game items can actually sell for significantly larger amounts such as the <a href="https://www.engadget.com/2013-11-06-dota-2-pink-war-dog-courier-sells-for-38-000.html">DotA 2 pink war dog courier</a> for $38,000. Within the crypto space there have also been high priced sales such as the $170,000 <a href="https://thenextweb.com/hardfork/2018/09/05/most-expensive-cryptokitty/">CryptoKitty</a>. Similarly Magic: The Gathering’s coveted <a href="https://www.polygon.com/2019/3/5/18251623/magic-the-gathering-black-lotus-auction-price">Black Lotus</a> card sold for $166,100. There is certainly demand for valuable in-game items. In decentralized marketplaces, there isn’t a limit imposed on what game items can be sold and for what amount.</p>
<p>Decentralized marketplaces can significantly reduce transaction fees due to the improved efficiency of starting up and operating a marketplace. Marketplaces can also improve overall user experience and increase interest in the game. Hearthstone is a wildly popular digital collectible card game created by Blizzard Entertainment that had over <a href="https://variety.com/2018/gaming/news/hearthstone-has-over-100-million-players-1203019919/">100 million players</a> in 2018. Hearthstone opted to not have a marketplace for their cards which leaves opportunity for other digital collectible card games that allow for an open marketplace. <a href="https://godsunchained.com/">Gods Unchained</a> and <a href="https://www.skyweaver.net/">SkyWeaver</a> are two trading card games (TCGs) that have cards that are freely tradable. You are also able to earn cards as you level up in the game. Players that did not purchase packs of cards will still be able to improve upon the game’s default decks. It’s an exciting feeling knowing that the earned cards have real world value and can be sold or traded for other cards. Gods Unchained also lets users earn tokens for when they win a match or refer their friend. The tokens themselves unlock rare in-game items and are also freely tradable.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/aa82c586-39b6-46b1-ae55-cb8a2e44c8e1.jpeg" alt="Gods Unchained"></p><figcaption>Gods Unchained</figcaption></figure>
<p>One of the most popular games in crypto is <a href="https://axieinfinity.com/">Axie Infinity</a>. You battle with a team of pet Axies and level them up. There's no aspect of the gameplay that feels like a blockchain game but there is the added benefit of being able to openly trade the Axies on NFT marketplaces such as <a href="https://opensea.io/">OpenSea</a>. The game has become popular in the <a href="https://www.coindesk.com/nft-game-filipinos-covid">Philippines</a> and earning tokens from the game has become a viable source of income for players even <a href="https://www.playtoearn.online/2020/07/08/axie-infinity-beats-minimum-wage-in-many-countries/">beating minimum wage</a> in many countries. There is also a decentralized autonomous organization (DAO) called <a href="https://yieldguild.io/">Yield Guild Games</a> which leases Axies to players that want to get started with the game but don’t have the funds to purchase them. Several rare Axies were even <a href="https://www.delphidigital.io/reports/why-we-spent-159k-on-digital-battle-pets-2/">purchased</a> for $159,000 total.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/26353bcc-0d05-47ea-89ac-fcdc9d2dd848.jpeg" alt="Axie Infinity battle"></p><figcaption>Axie Infinity battle</figcaption></figure>
<p>There’s another popular game <a href="https://zkga.me/">Dark Forest</a> where you can explore different planets and collect Artifact NFTs on new planets, which give bonuses when attached to the planet. Being able to discover and collect these items or even win them in a battle and then trade them in decentralized marketplaces can make the game even more fun.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/be66b61a-05f0-46b7-aa8f-f7ed542d5cd3.jpeg" alt="Planet in Dark Forest which has an Artifact NFT"></p><figcaption>Planet in Dark Forest which has an Artifact NFT</figcaption></figure>
<p>One concern with making in-game items tradable is that the ability to trade items can negatively affect the gameplay as people are focused on …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d">https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d</a></em></p>]]>
            </description>
            <link>https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073970</guid>
            <pubDate>Tue, 09 Feb 2021 04:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The speed of science]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26073541">thread link</a>) | @salonium_
<br/>
February 8, 2021 | https://worksinprogress.co/issue/the-speed-of-science/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/the-speed-of-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>The 21st century has seen some phenomenal advances in our ability to make scientific discoveries. Scientists have developed <a href="https://www.nature.com/articles/nrd.2017.243">new technology</a> to build vaccines swiftly, <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">new algorithms</a> to predict the structure of proteins accurately, <a href="https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-Data">new equipment</a> to sequence DNA rapidly, and <a href="https://www.vox.com/platform/amp/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">new engineering solutions</a> to harvest energy efficiently. But in many fields of science, reliable knowledge and progress advance <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">staggeringly</a> <a href="https://marginalrevolution.com/marginalrevolution/2019/11/is-the-rate-of-scientific-progress-slowing-down.html">slowly</a>. What slows it down? And what can we learn from individual fields of science to pick up the pace across the board – without compromising on quality?</p>
<p>By and large, scientific research is published in journals in the form of papers – static documents that do not update with new data or new methods. Instead of sharing the data and the code that produces their results, most scientists simply publish a textual description of their research in online publications. These publications are usually hidden behind paywalls, making it harder for outsiders to verify their authenticity.</p>
<p>On the occasion when a reader spots a discrepancy in the data or an error in the methods, they must read the intricate details of a study’s method scrupulously, and cross-check the statistics manually. When scientists don’t share the data to produce their results openly, the task becomes even harder. The process of error correction – from scientists publishing a paper, to readers spotting errors, to having the paper corrected or retracted – can take <a href="https://retractionwatch.com/2017/04/26/university-asked-numerous-retractions-eight-months-later-three-journals-done-nothing/">years</a>, assuming those errors are spotted at all.</p>
<p>When scientists reference previous research, they cite entire papers, not specific results or values from them. And although there is <a href="https://mattsclancy.substack.com/p/does-science-self-correct">evidence</a> that scientists hold back from citing papers once they have been retracted, the problem is compounded over time – consider, for example, a researcher who cites a study that itself derives its data or assumptions from prior research that has been disputed, corrected or retracted. The longer it takes to sift through the science, to identify which results are accurate, the longer it takes to gather an understanding of scientific knowledge.</p>
<p>What makes the problem even more challenging is that flaws in a study are not necessarily mathematical errors. In many situations, researchers make fairly arbitrary decisions as to how they collect their data, which methods they apply to analyse them, and which results they report – altogether leaving readers blind to the impact of these decisions on the results.</p>
<p>This murkiness can result in what is known as p-hacking: when researchers selectively apply arbitrary methods in order to achieve a particular result. For example, in a study that compares the well-being of overweight people to that of underweight people, researchers may find that certain cut-offs of weight (or certain subgroups in their sample) provide the result they’re looking for, while others don’t. And they may decide to only publish the particular methods that provided that result.</p>
<p>If a reader can’t find out how different versions of a study method have affected the results, how are they to know whether the finding really was robust – that it would be found regardless of how the data was looked at?</p>
<p>Now, it’s common to assume that these errors and flaws are largely smoothed out during the process of peer review, where peer scientists are asked to scrutinise a study and recommend to journal editors whether it should be revised or even published at all. But unfortunately peer review often fails to accomplish this, as the scientist Stuart Ritchie has described in his book <a href="https://us.macmillan.com/books/9781250222695"><i>Science Fictions</i></a>.</p>
<p>Substandard methods and questionable research practices are widespread even in published work. There is an enormous number of journals available, with different standards of publication, in which scientists can publish their work if they are rejected by some. And many lines of <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full">evidence</a> suggest that ‘high impact’ journals (journals which are said to be highly reputable and have a wide reach) accept papers with similar or weaker methods than low-impact journals do.</p>
<p>Peer review instead functions predominantly as a practice of gatekeeping, as the philosophers of science Liam Bright and Remco Heesen have <a href="https://academic.oup.com/bjps/advance-article/doi/10.1093/bjps/axz029/5526887">explained</a>. Reviewers provide scientists with comments that are rarely made public. Whether research is published in a particular journal largely depends on the idiosyncratic decisions of reviewers who are available at the time and who are liked by the journal’s editors.</p>
<p>Peer review filters which research is published, with no use of transparent metrics for others to understand the reasoning behind these choices. The lack of transparency lends itself to misconduct – reviewers may discourage the publishing of science that challenges the prevailing consensus of the time or fails to replicate it – and hype, encouraging the publication of results that seem exciting over those that provide nuance.</p>
<p>These decisions have consequences, because journals are the dominant platform for sharing scientific research. When non-scientists, who want to apply scientific knowledge elsewhere, read research, they have little way of knowing which methods are sound and which results are reproducible or replicable.	<sup data-close="x" data-content="[1]">[1]</sup>
	<span>Reproducibility relates to whether the results can be reproduced using the same data and code as in the original analysis. Replicability relates to whether other scientists find similar results in their own studies.</span>
	 Other scientists can face the same problems, finding it difficult to assess the state of knowledge in a field, particularly if they have expertise in a different subject. This is troubling: the longer it takes to sift through the research to find out which results are reliable, the longer it takes to apply knowledge to solve new problems.</p>
<p>This view paints a bleak picture of the state of scientific knowledge, and the question that arises is: is all of science like this?</p>
<p>Fortunately, the answer is no. But unfortunately, many good practices are fairly modern and limited to specific domains. Here are some of them.</p>
<p>The remarkable <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">breakthrough</a> by DeepMind in 2020 – in accurately predicting the folded structure of proteins using only the code of protein sequences – was made possible because DeepMind’s AlphaFold algorithm was trained using data from <a href="https://www.rcsb.org/pages/about-us/index">Protein Data Bank</a>, a vast public database that dates back to 1971. Molecular scientists have been carefully applying difficult laboratory techniques to establish the structure of proteins and have manually submitted information about them to this database <a href="https://journals.iucr.org/a/issues/2008/01/00/sc5004/">for decades</a>. In parallel, data managers have been reviewing each of their submissions for accuracy. The platform now harbours over 150,000 curated entries of protein structures.</p>
<p>With databases like this, the benefits to other scientists are enormous: specifically, understanding the structure of proteins can help scientists design precise drugs that fit into them, as has been done for the <a href="https://cen.acs.org/analytical-chemistry/structural-biology/structural-biologists-revealed-new-coronaviruss/98/i17">spike protein</a> of the coronavirus. It can also help them understand why resistance to a drug has developed, such as in <a href="https://www.nature.com/scitable/topicpage/the-protein-data-bank-exploring-biomolecular-structure-14199109/">HIV research</a>. But more broadly, individual researchers no longer have to rediscover these protein structures over and over again if they have already been shared publicly, if they want to use that knowledge for other purposes.</p>
<p>The practice of sharing data is also the norm in the neighbouring field of genomics. The tradition largely stems from the <a href="https://en.wikipedia.org/wiki/Human_Genome_Project">Human Genome Project</a>, which began in 1990 and aimed to determine the entire code of the human genome. During the project, a group of scientists developed protocols called the <a href="https://www.annualreviews.org/doi/10.1146/annurev-genom-083115-022515">Bermuda Principles</a>, which recommended that labs working on the project should upload the details of any new genetic sequences that they discovered onto public data repositories on a daily basis.</p>
<p>Though the project was completed in 2003, the movement paved the way for data sharing principles in many genetic projects to come, such as the HapMap project, the 1000 Genomes project, dbGaP, and more recently, GISAID and NextStrain – two databases which publicly share genomes of the SARS-CoV-2 (Covid-19) virus.	<sup data-close="x" data-content="[2]">[2]</sup>
	<span>The HapMap project is a project that maps common genetic mutations of the human genome, while the 1000 Genomes project aims to develop a map of rare genetic mutations. dbGaP is a database of genetic mutations that are associated with medical traits and diseases.</span>
	 As with protein databases, these open sharing practices are remarkably important in genomics, in particular because they allow scientists to investigate a large number of genes and mutations at the same time, each detailed with a large amount of information that other scientists have collected.</p>
<p>These databases are immensely useful in sharing <i>data</i> for other researchers to analyse, but different tools are necessary for researchers to share the code used to <i>analyse data</i> – for example, if they want to test specific hypotheses. Some researchers voluntarily share their analysis code on <a href="https://en.wikipedia.org/wiki/Git">GitHub</a> and <a href="http://osf.io/">OSF</a>, two platforms where people can upload their data, code and research plans and update them when changes are made. But the practice of sharing code is not widely used by scientists even within these fields.</p>
<p>In computer science however, there are examples of journals that work with version control tools like Git. Take <a href="https://peerj.com/articles/cs-147/">JOSS</a> as an illustration, a journal that publishes research describing open source software. JOSS is actually built upon the platform of GitHub: software developers submit their software together with working papers describing them to the journal via GitHub, and the journal’s reviewers provide comments on their code and suggest revisions to their work publicly. Both reviewers’ comments and past versions of the software are therefore transparent and accessible to the public.</p>
<p>Apart from these examples of sharing data and code openly, some fields already commonly try to tackle p-hacking and other questionable research practices, described before. In economics, researchers typically perform “<a href="http://www.nickchk.com/robustness.html">robustness checks</a>” to demonstrate that their …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/the-speed-of-science/">https://worksinprogress.co/issue/the-speed-of-science/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/the-speed-of-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073541</guid>
            <pubDate>Tue, 09 Feb 2021 03:43:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning an old Amazon Kindle into a eInk development platform]]>
            </title>
            <description>
<![CDATA[
Score 362 | Comments 87 (<a href="https://news.ycombinator.com/item?id=26073463">thread link</a>) | @miles
<br/>
February 8, 2021 | https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1721">

	

	
			<figure>
				<img width="998" height="1331" src="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=998" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg 998w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=225 225w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=768 768w" sizes="(max-width: 998px) 100vw, 998px" data-attachment-id="1751" data-permalink="https://blog.lidskialf.net/kindle_serial_magnified/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg" data-orig-size="998,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_serial_magnified" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=225" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=768">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I fancied getting an eink screen to use for future projects. I bought a wee one with a raspberry pi “hat” attached. However, I realised later that I could maybe just re-purpose an old Amazon Kindle ebook reader.</p>



<p>I’ve messed with Kindles before, ages ago: I ported an <a href="https://blog.lidskialf.net/2010/10/09/kif-an-infocom-text-adventure-interpreter-for-the-kindle/">Infocom interpreter</a> and a <a href="https://blog.lidskialf.net/2010/10/20/mangle-a-better-manga-reader-for-the-kindle/">Manga</a> reader to it. I managed to get Amazon’s own software to load them as “Kindlets” and show them integrated into their ebook reader. However, now I just want a nice cheap Linux based eink development platform.</p>



<p>Cheap Kindle From Ebay (and why)</p>



<p>So, off to ebay I went! I saw a number of really cheap ones marked “BLOCKED BY AMAZON”; I decided not to go for these since theoretically they might have been stolen. In the end, I went for £7 Kindle 4 “non-touch”.</p>



<p>A few days later, it turned up. And I discovered <em>why</em> it might have been so cheap: its stuck in some sort of unquittable demo mode:</p>



<figure><img data-attachment-id="1725" data-permalink="https://blog.lidskialf.net/kindle_demo_mode/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg" data-orig-size="892,1239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_demo_mode" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=216" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737" src="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737 737w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=108 108w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=216 216w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg 892w" sizes="(max-width: 737px) 100vw, 737px"></figure>



<p>I did some googling and although it seems later Kindle versions can be un-demo-mode-ed, nothing seemed to work for this version. I don’t actually care though; I don’t want to run the original Kindle ebook software on this.</p>



<p>So, the next step is to gain access. Browsing the <a href="https://www.mobileread.com/forums/showthread.php?t=166687">mobileread forums</a> showed it has a debug serial port: time to open the case!</p>



<p>Physical Access Granted!</p>



<p>This was kinda tricky! There are multiple clips all round it and the case is glued onto the battery compartment, so judicious application of a Big Knife was required to persuade it to let go. I cleaned the glue up with some Acetone.</p>



<figure><img data-attachment-id="1729" data-permalink="https://blog.lidskialf.net/kindle_illustrated/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg" data-orig-size="998,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_illustrated" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=225" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768" src="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=225 225w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg 998w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<ul><li>Red: annoying clips</li><li>Purple: <strong>really</strong> annoying glue.</li><li>Yellow: the serial port!</li></ul>



<p>As usual for this sort of thing, the serial port is missing its socket, so we need to solder onto the tiny contacts on the board. I like to use ~0.2mm wirewrap wire for this sort of thing, and the surface mount rework bit for my soldering iron:</p>







<p>I don’t want to leave any wires flapping about, but I also know at some point I’m going to screw up and need serial port console access, so I came up with a solution and attached it:</p>







<p>I superglued a piece of Veroboard onto the kindle’s PCB, then soldered wirewrap wires from the tiny PCB contacts onto one end. Finally, I soldered a larger, more conventional “Dupont” cable socket on the other end so I could easily attach and detach from it. Oh, the top cable on the Kindle PCB is 0v/GND, the others are TX and RX (I forget the order of those two).</p>



<p>Final hurdle: the kindle serial port runs at 1.8v, so I needed a serial port adaptor which supports that:</p>



<figure><img data-attachment-id="1737" data-permalink="https://blog.lidskialf.net/kindle_usbserial/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg" data-orig-size="545,828" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_usbserial" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=197" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=545" src="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=545" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg 545w, https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=99 99w, https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=197 197w" sizes="(max-width: 545px) 100vw, 545px"></figure>



<p>The one I bought does 5v. 3.3v, 2.5v, and 1.8v: it’s pretty neat!</p>



<p>Root Access Granted!</p>



<p>Next, I attached the serial adapter to my laptop, ran the <strong>minicom</strong> serial port software and rebooted the Kindle. Then, once I (inevitably) swapped the TX and RX wires around, I was greeted by this!</p>



<pre><code>U-Boot 2009.08-lab126 (Aug 29 2012 - 12:55:24)

CPU:   Freescale i.MX50 family 1.1V at 800 MHz
mx50 pll1: 800MHz
mx50 pll2: 400MHz
mx50 pll3: 216MHz
ipg clock     : 50000000Hz
ipg per clock : 50000000Hz
uart clock    : 24000000Hz
ahb clock     : 100000000Hz
axi_a clock   : 400000000Hz
axi_b clock   : 200000000Hz
weim_clock    : 100000000Hz
ddr clock     : 800000000Hz
esdhc1 clock  : 80000000Hz
esdhc2 clock  : 80000000Hz
esdhc3 clock  : 80000000Hz
esdhc4 clock  : 80000000Hz
MMC:  FSL_ESDHC: 0, FSL_ESDHC: 1
Board: Tequila
Boot Reason: [POR]
Boot Device: MMC
Board Id: 0031701123730Z56
S/N: B02317022392005M
Initing MDDR memory
ZQ calibration complete: 0x128=0xfffe0010 0x12C=0xffffffff
DRAM:  256 MB
Using default environment

In:    serial
Out:   logbuff
Err:   logbuff
Quick Memory Test 0x70000000, 0x10000000
POST done in 13 ms
Hit any key to stop autoboot:  0 
## Booting kernel from Legacy Image at 70800000 ...
   Image Name:   Linux-2.6.31-rt11-lab126
   Image Type:   ARM Linux Kernel Image (uncompressed)
   Data Size:    4777568 Bytes =  4.6 MB
   Load Address: 70008000
   Entry Point:  70008000
   Verifying Checksum ... OK
   Loading Kernel Image ... OK
OK
Starting kernel ...

[snip]

Welcome to Kindle!

kindle login: </code></pre>



<p>Great, so that’s booting the uboot bootloader, then booting into linux and asking me to login.</p>



<p>Trying to login as root prompts for a password: Hmm… However, I already knew from previous Kindle stuff that you can generate the password from the serial number. I found <a href="https://www.sven.de/kindle/">this website</a> which generates a number of possible passwords for a specific device: Mine was the third on the list.</p>



<p>In case that site dies here’s the key snippet of Javascript:</p>



<pre><code>var md5 = hex_md5(serial);
document.getElementById("rootpw").innerHTML = "fiona" + md5.substring(7,11);
document.getElementById("rootpw2").innerHTML = "fiona" + md5.substring(7,10);
document.getElementById("rootpw3").innerHTML = "fiona" + md5.substr(13,3);</code></pre>



<p>Oh: I forgot to mention how I extracted the device’s serial number. Well, plugging it into USB doesn’t really “work”: you can’t mount these demo devices as disks. But, under linux, it still outputs the serial number in linux’s <strong>dmesg</strong> output (you can also get it using <strong>printenv</strong> in uboot if you press enter when it says “Hit any key to stop autoboot”):</p>



<pre><code>[128033.676587] usb 1-2: new high-speed USB device number 51 using xhci_hcd
[128033.829631] usb 1-2: New USB device found, idVendor=1949, idProduct=0004, bcdDevice= 1.00
[128033.829638] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3
[128033.829642] usb 1-2: Product: Amazon Kindle
[128033.829645] usb 1-2: Manufacturer: Amazon
[128033.829648] usb 1-2: SerialNumber: XXXXXXXXXXXXXXXX
</code></pre>



<p>Cool! We have root and can login! Now to figure out how to make it a bit easier to do stuff on it.</p>



<p>Dumping The System</p>



<p>First step is usually to dump the disks for analysis on another computer.</p>



<p>Checking <code>/proc/mounts</code> shows multiple partitions of the main disk on <code>/dev/mmcblk0</code>.</p>



<p>Running <code>fdisk /dev/mmcblk0</code> gives the following:</p>



<pre><code>Units = cylinders of 64 * 512 = 32768 bytes

        Device Boot      Start         End      Blocks  Id System
/dev/mmcblk0p1   *        1025       12224      358400  83 Linux
/dev/mmcblk0p2           12225       14272       65536  83 Linux
/dev/mmcblk0p3           14273       15296       32768  83 Linux
/dev/mmcblk0p4           15297       59776     1423360   b Win95 FAT32</code></pre>



<ul><li>So, four partitions, three linux, and one FAT32. </li><li>The first disk starts quite far into the disk: turns out the kernel is stored in that “missing” area. </li><li>Poking about a bit more shows partition 1 is the normal system, 2 is a sort of diagnostic tool partition, 3 is for storing internal private state of the kindle (eg wifi passwords). Finally, 4 is the one you see when you plug a kindle in over USB: its where your books would reside.</li><li>Partition 4 is mounted at /mnt/us.</li></ul>



<p>I dumped the start of the disk and partitions 1-3 onto /mnt/us using dd (I like to take a complete raw image if I can so I can restore it in case something goes wrong):</p>



<pre><code>dd if=/dev/mmcblk0 of=/mnt/us/kindle.img bs=32768 count=15297</code></pre>



<p>Although this Kindle doesn’t show a disk over USB, since I have root, I can simply make it do it:</p>



<pre><code>rmmod g_file_storage
modprobe g_file_storage file=/dev/mmcblk0p4</code></pre>



<p>It popped up on my laptop so I copied everything off.</p>



<p>System Analysis</p>



<p>Finally, I mounted the partitions in kindle.img on my laptop with:</p>



<pre><code>kpartx -v kindle.img</code></pre>



<p>I could then mount the individual partitions on my laptop. I extracted all the files into a folder so I could poke around them and grep them easily. I figured out:</p>



<ul><li>It uses <code>rc.d</code> as its system init system, so there are lots of nice plain text scripts.</li><li>Init level 5 is the “normal” system running the ebook software</li><li>The ebook software is in <code>/opt/amazon</code> and is in Java (I kinda already knew this, but needed a quick refresher).</li><li>There’s a whole load of interesting plain text “diag” scripts for testing.</li><li>There’s a rather nifty <code>wifid</code> daemon for managing the wifi connection: I figured out how to talk to this from the diag scripts.</li><li>You can write to the eink screen from the command line using the <code>/usr/sbin/eips</code> command (<a href="https://wiki.mobileread.com/wiki/Eips">docs here</a>).</li><li>I couldn’t find an obvious “turn off demo mode” switch: it appears the demo mode is a customised build of the Java ebook software.</li><li>The following system services are to do with unsupported features, the ebook software, or talking back to amazon: <code>S50wan S70wand S75phd S81usbnetd S93webreaderd S94browserd S95framework S96boot_finished</code>.</li></ul>



<p>Talking To Wifid</p>



<p>You can use the built in wifid to connect to wifi and manage your wifi profiles. Oh, also, remember many Kindles only support 2.4Ghz wifi when you wonder why it isn’t working 😉</p>



<p><strong>List number of WIFI profiles:</strong></p>



<p><code>lipc-get-prop com.lab126.wifid profileCount</code></p>



<p><strong>Show contents of a WIFI profile:</strong></p>



<p><code>echo "{index=(0)}" | lipc-hash-prop com.lab126.wifid profileData</code></p>



<p><strong>Delete a WIFI profile:</strong></p>



<p><code>lipc-set-prop com.lab126.wifid deleteProfile WIFIESSID</code></p>



<p><strong>Create a WIFI profile:</strong></p>



<p><code>echo '{essid="WIFIESSID", smethod="wpa2", secured="yes", psk="WIFIPSK"}' | lipc-hash-prop com.lab126.wifid createProfile</code></p>



<p>smethod can be one of open,wep,wpa,wpa2 (if you choose open, set secured to “no”)</p>



<p>WIFIPSK is the WIFI PSK as generated with the <code>wpa_passphrase</code> utility (which is actually on the kindle): a normal “wifi passphrase” will not work.</p>



<p><strong>Connect a WIFI profile:</strong></p>



<p><code>lipc-set-prop com.lab126.wifid cmConnect WIFIESSID</code></p>



<p><strong>Show WIFI connection status:</strong></p>



<p><code>echo "{index = (0)}" | lipc-hash-prop -n com.lab126.wifid currentEssid</code></p>



<p>Making Changes To Root</p>



<p>Many of the following instructions need to change the root disk on the kindle. However, by default it is mounted in read only mode, preventing modification. To fix, run this command on the kindle:</p>



<pre><code>mntroot rw</code></pre>



<p>When done, set it back to read only mode to prevent any unwanted changes:</p>



<pre><code>mntroot ro</code></pre>



<p>Installing Dropbear SSH</p>



<p>I wanted to be able to ssh into my kindle, so I needed to install the <a href="https://matt.ucc.asn.au/dropbear/dropbear.html">dropbear</a> ssh daemon. Of course this is an ARM based device, so I either had to compile it myself or find it somewhere. Luckily …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/">https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/</a></em></p>]]>
            </description>
            <link>https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073463</guid>
            <pubDate>Tue, 09 Feb 2021 03:21:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything You Hate About Clubhouse Is Why It Will Win]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26073074">thread link</a>) | @tosh
<br/>
February 8, 2021 | https://www.swyx.io/clubhouse-hate/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/clubhouse-hate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>You can listen to <a href="https://share.transistor.fm/s/6719542d">an audio version of this essay here</a>.</em></p>
<p>Trust me, I <em>tried</em> to make the Clubhouse bear case.</p>
<p>The original title of this post was "Everything Clubhouse Did Right — and Why It Will Fail Anyway". The exercise forced me to list the reasons why it wasn't worth $1 billion - why live conference calls are inferior to existing formats like podcasts and Discord.</p>
<p>When I was done, I went for a walk to think about it. By the time I came back, I had done a complete 180. (Note - <em>this was even before I heard about the Elon event</em>)</p>
<p>I <em>still</em> dislike the Clubhouse experience. I wouldn't recommend it to you. But all the reasons I dislike it are the same reasons it will work:</p>
<ul>
  <li><strong>Clubhouse is exclusive</strong>. You have hoops to jump and gates to open every step of the way. It's iOS only. Invite only. Requires your phone number for no goddamn reason. And once you're through <em>all of that</em> you gain the privilege of being in the voiceless audience hoping senpai will notice your raised hand and puffed up bio.</li>
  <li><strong>Clubhouse is ephemeral</strong>. Conversations aren't recorded. Your work doesn't compound and isn't searchable. This is <em>horrible</em> for ROI on your time as a content creator.</li>
  <li><strong>Clubhouse is live-only</strong>. If all the convos are happening in Pacific Time and you live in Europe, tough luck. If you came in halfway and have no idea what was said, tough luck. The only way to be fully involved is to turn on mobile notifications and track scheduled chats. Causing more — not less — distraction and work for you.</li>
  <li><strong>Clubhouse enhances existing privilege</strong>. Because automated recommendations aren't possible, Clubhouse mostly relies on a Twitter-like follow graph. To gain a following you mostly already have to be famous off-platform or well-connected to people who will bring you up on stage ("second-degree famous"). Choosing a <a href="https://www.eugenewei.com/blog/2019/2/19/status-as-a-service">Status as a Service</a> model (Twitter) over a <a href="https://www.eugenewei.com/blog/2020/8/3/tiktok-and-the-sorting-hat">Sorting Hat</a> model (TikTok) sacrifices discovery for establishment.</li>
  <li><strong>Clubhouse is a terrible listening experience</strong>. There's no audience chat or polling. Obnoxious speakers can dominate the conversation. <a href="https://twitter.com/wongmjane/status/1355817942093496320?s=20">Trolls</a> and <a href="https://www.dailydot.com/unclick/tiffany-haddish-bullies-doctor-on-clubhouse-covid/">harassment</a> abound. You can't play at 2x or rewind an important part. Podcasts were trending towards better audio and editing, Clubhouse regresses to shitty phone mics with feedback and connection issues. Signal is scarce, noise is rampant.</li>
</ul>
<p>In my original write up I listed the many better offerings in every dimension. Want to listen to interviews with great audio and show notes? Podcasts. Want ultrascalable livestreaming? Twitch. Want livestreamed audio with recording and submitted questions? <a href="https://twitter.com/N8Elliott/status/1355203379392176131?s=20">Capiche</a>. Want to do an audio webinar? Use Zoom with the camera off. Want voice with text chat? Discord. Just want a Clubhouse clone with less friction? <a href="https://twitter.com/TwitterSpaces">Twitter Spaces</a>.</p>
<p>When I was done listing the alternatives, I knew I had made a mistake. They checked more boxes on a feature comparison basis. But social media doesn't work like that. I was trying to be logical in a <em>socio</em>-logical domain.</p>
<p>I had conclusively <em>PROVED</em>, with my big brain and fancy words, how profoundly inferior Clubhouse was. No compounding creator should prefer it, and no self respecting listener should enjoy it, compared to alternatives.</p>
<p>But the majority of people don't work like that:</p>
<ul>
  <li>Some people are turned off by exclusivity and friction. But <em>most people</em> take it as social proof of something cool.</li>
  <li>Some creators are turned off by ephemerality. But <em>more people</em> will start trying precisely because it's easy and doesn't matter. The Elon Musks and Vlad Tenevs of the world will be less guarded, despite clearly knowing anything they say will be recorded, because <em><a href="https://en.wikipedia.org/wiki/The_medium_is_the_message">the medium is the message</a></em>.</li>
  <li>Some people are turned off by demands on their time. But <em>most people</em> leave mobile notifications on and the live nature of chats creates some of the most urgent notifications you'll get on your phone, second only to a call from your mother. The synchronicity creates an <em>event</em> — a clear Before and After where you can excitedly gossip and feel superior to people out of the loop. This is a rarity in an everything-async world.</li>
  <li>Some people are turned off by stacked decks. But <em>most people</em> just want to follow celebrities and experts and aren't interested in the challenging, messy work of finding people on the way up.</li>
  <li>Some people are turned off by the listening experience. But Clubhouse is <a href="https://www.swyx.io/good-enough/">Good Enough</a>, especially if content is created sooner and in bigger quantity than available anywhere else.</li>
</ul>
<p>Clubhouse should've died <a href="https://www.theverge.com/interface/2020/7/8/21316172/clubhouse-content-moderation-taylor-lorenz-harassment-abuse">in July when the VC and Media abuse cases erupted</a>. Instead it came back stronger than ever, standing at <a href="https://web.archive.org/web/20210131175202/https://www.businessinsider.com/why-the-hype-about-1-billion-clubhouse-not-so-crazy-2021-1">2 million weekly active users</a>. <strong>If any of these negatives mattered</strong>, the app should have seen extreme churn. Instead, <a href="https://a16z.com/2021/01/24/investing-in-clubhouse/">Andrew Chen</a>, <a href="https://twitter.com/rrhoover/status/1353393250552270850">Ryan Hoover</a>, and <a href="https://www.indiehackers.com/post/gumroad-is-switching-from-zoom-to-clubhouse-34e4b4e5e1">Sahil Lavingia</a> — who do this for a living and have insider knowledge of metrics — value it above $1 billion dollars, six months after it was <a href="https://www.forbes.com/sites/alexkonrad/2020/05/15/andreessen-horowitz-wins-vc-sweepstakes-to-back-clubhouse-voice-app/?sh=5b8466d56f2a">valued at $100 million</a>.</p>
<p><strong>People. Aren't. Churning.</strong> No matter how much you may hate the app — usage is going <em>up</em>. This is scary and worth taking note. Clubhouse is already showing signs of successful expansion in Asia (read: non-English Clubhouses).</p>
<p>Instagram had 30 million MAUs when Facebook bought it for $1 billion. Whatsapp had 450m for $19 billion. By Whatsapp metrics, Clubhouse is wildly overvalued (lets say it has 10m MAU right now). But audio isn't text. <a href="https://alexdanco.com/2019/10/17/the-audio-revolution/">Alex Danco says</a> that texting is a cold medium, while audio is the hottest medium of all. He was mildly wrong — podcasting is still kinda lukewarm — but <strong><em>live, ephemeral</em></strong> audio is so hot you will literally drop everything and stay up late and ignore your partner to go listen to Elon.</p>
<p>Worse is better. The exact reasons you hate Clubhouse — the kind of thing that drives you to read an article like this to the end — are the exact same reasons it is going to win.</p>
<hr>
<p><em>if you're interested - here was <a href="https://gist.github.com/sw-yx/d3e27a36eba965fcd4183d0575d34640">my initial negative conclusion</a>.</em></p>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/clubhouse-hate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073074</guid>
            <pubDate>Tue, 09 Feb 2021 02:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SafeLife: Safety Benchmarks for Reinforcement Learning (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26072842">thread link</a>) | @apsec112
<br/>
February 8, 2021 | https://pde.is/posts/safelife/ | <a href="https://web.archive.org/web/*/https://pde.is/posts/safelife/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>By Carroll Wainwright and Peter Eckersley<br>
<span>Published on 2019-12-04, on the <a href="https://www.partnershiponai.org/safelife/">PAI blog</a></span>.</p>
<p><span>The Partnership on AI (PAI) is today releasing SafeLife – a novel reinforcement learning environment that tests the safety of reinforcement learning agents and the algorithms that train them. SafeLife version 1.0 focuses on the problem of avoiding negative side effects—how can we train an agent to do what we want it to do but nothing more? The environment has simple rules, but rich and complex dynamics, and generally gives the agent lots of power to make big changes on its way to completing its goals. A safe agent will only change that which is necessary, but an unsafe agent will often make a big mess of things and not know how to clean it up.</span></p>
<p><span>SafeLife is part of a broader PAI initiative to develop benchmarks for safety, fairness, and other ethical objectives for machine learning systems. Since so much of machine learning is driven, shaped, and measured by </span><a href="https://eff.org/ai/metrics"><span>benchmarks</span></a><span> (and the datasets and environments they are based on), we believe it is essential that those benchmarks come to incorporate safety and ethics goals on a widespread basis, and we’re working to make that happen.</span></p>
<p><span>If you want to try out SafeLife for yourself, you can </span><a href="https://github.com/PartnershipOnAI/safelife/"><span>download the code</span></a><span> and try playing some of the puzzle levels. If you’d like to see how to create an AI to play SafeLife, additional details about the environment and our initial agent training can be found</span>&nbsp;<a href="https://arxiv.org/abs/1912.01217">in our paper</a>.</p>
<h3>The Problem of Side Effects</h3>
<p><span>Reinforcement learning agents are rapidly growing in capabilities. They can </span><a href="https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go"><span>beat masters in chess and go</span></a><span>, control robotic hands with enough manual dexterity </span><a href="https://openai.com/blog/solving-rubiks-cube/"><span>to solve a Rubik’s Cube</span></a><span>, and potentially be applied across many domains with </span><a href="https://arxiv.org/abs/1911.08265"><span>variable and unknown rules</span></a><span>.</span> <span>As reinforcement learning agents start to get deployed in real-world high-stakes scenarios, it is critical to make sure that they operate within appropriate (and often quite strict and intricate) safety constraints. However, the whole point of reinforcement learning is that it can greedily search for novel techniques when solving a problem. </span><b>If we can’t predict what an AI is going to do, how can we predict that it will be safe?</b><span> In practice, reinforcement learning can only be used in the real world in settings where safety is so well understood that constraints can be exactly and correctly codified in advance. </span><span>Other tasks, like safely controlling the behavior of a robot when it is interacting with the world at large, are much more challenging.</span></p>
<p><span>One of the thorniest </span><a href="https://arxiv.org/abs/1606.06565"><span>problems in AI safety</span></a><span> is learning to avoid negative side effects. Usually, when we give an agent a task, we have something specific in mind that the agent should do. At the same time, we have a huge implicit list of things that the agent should </span><i><span>not</span></i><span> do. When we train a robot to fetch the coffee, we want it to efficiently brew the tastiest cup possible. But we also do not want the robot to step on the cat (even if it’s in the way), or rob the local grocer (even if it’s cheaper than paying), or crash the stock market (even if it would bring down the price of beans). Specifying all the things that the robot should not do is a near impossible task; we just want our delicious cup of coffee, nothing more.</span></p>
<p><span>Difficult though this problem may be, there has been some promising research on how to avoid side effects in general. The </span><a href="https://arxiv.org/abs/1806.01186"><span>proposed</span></a> <a href="https://arxiv.org/abs/1902.09725"><span>techniques</span></a><span> have been tested on hand-crafted Sokoban-style environments which have demonstrated both the problem and the ways in which naive solutions may fail. However, these environments are very small; they can easily be overfit, and the “effects” tend to be straightforward and isolated. </span><b>Until now, there has been no rich environment with difficult goals in which effects are both necessary and required at different scales. SafeLife aims to fill this gap.</b></p>
<h3>Rules of the Game</h3>
<div><p><img src="https://pde.is/posts/img/pattern-demo.gif"></p><p>Figure 1. Creating complex patterns in SafeLife.</p>
</div>
<p><span>SafeLife is based on </span><a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life"><span>Conway’s Game of Life</span></a><span>, a set of rules for cellular automata on an infinite two-dimensional grid. In Conway’s Game of Life, every cell on the grid is either “alive” or “dead”. At each time step, the entire grid is updated. Any living cell with fewer than two or more than three living neighbors dies, and any dead cell with exactly three living neighbors comes alive. All other cells retain their previous state. With just these simple rules, extraordinarily complex patterns can emerge. Some patterns will be static—they won’t change between time steps. Other patterns will oscillate between two, three, </span><a href="https://www.conwaylife.com/wiki/Jason%27s_p156"><span>or more</span></a><span> states. Gliders and spaceships travel across the grid, while guns and </span><a href="https://en.wikipedia.org/wiki/Puffer_train"><span>puffers</span></a><span> can produce never-ending streams of new patterns.</span></p>
<p><span>Despite its name, Conway’s Game of Life is not actually a game—there are no players, and there are no choices to be made. In SafeLife we’ve minimally extended the rules by adding a player, player goals, and a level exit. At each time step, the player can choose to move one space along the board, create a new life cell in an adjacent space, or destroy a cell in an adjacent space. By judiciously creating and destroying life cells, the player can build up quite complicated patterns (as seen above!). By matching these patterns to goal cells, the player earns points and eventually opens the exit to the next level.</span></p>
<p><span>We add a few more cell types to allow richer dynamics. There are indestructible walls and trees, movable crates, and spawning cells that are capable of generating never-ending streams of new random patterns. Cells also come in different colors. Some colors, like green and yellow, are neutral and should be left alone by safe agents, while red cells denote unwanted patterns which yield rewards when removed.</span></p>
<h3>Agent behaviors and benchmark levels</h3>
<p><span>We trained agents on five different tasks: building and removing patterns on initially static boards, building and removing patterns on dynamic boards, and navigating across maze-like boards. All of the training levels were randomly generated, and agent performance was graded on a set of 100 fixed benchmark levels for each task.</span></p>
<p><span>In order to form a baseline, we trained agents with </span><a href="https://arxiv.org/abs/1707.06347"><span>proximal policy optimization</span></a><span>,</span><span> both with and without a simple side effect impact penalty. </span><span>The penalty we chose simply punishes the agent every time a cell changes away from its starting state. This is not a good way to measure side effects! It is, however, an </span><i><span>easy</span></i><span> way to measure side effects, and helps illustrate the shortcomings of side effect impact penalties more generally.</span></p>
<h5>Agents in Static Environments</h5>
<p><span>A static environment is the easiest environment in which one can measure side effects. Since the environment doesn’t change without agent input, </span><i><span>any</span></i><span> change in the environment must be due to agent behavior. The agent is the cause of every effect. Our simple side effect impact penalty performs quite well here.</span></p>
<p><span>When agents are trained without an impact penalty they tend to make a big mess.&nbsp;<i>&nbsp;</i></span></p>
<div><p><img src="https://pde.is/posts/img/benchmark-append-still-013_p0.gif"> <img src="https://pde.is/posts/img/benchmark-prune-still-003_p0.gif"></p><p>Figure 2. Left: an unsafe agent builds new patterns while disrupting existing ones. Right: an unsafe agent destroys red patterns along with much of the rest of the level.</p>
</div>
<p><span>In Figure 2, the image on the left shows a pattern-building agent that has learned how to construct stable 2-by-2 blocks that it can place on top of goal cells. The agent has not, however, learned to do so without disrupting nearby green patterns. Once the green pattern has been removed, the agent can more easily make its own pattern in its place.</span></p>
<p><span>Likewise, the image on the right in Figure 2 shows a pattern-destroying agent that has learned that the easiest way to remove red cells is to disrupt </span><i><span>all</span></i><span> cells. Even a totally random agent can accomplish this—patterns on this particular task tend towards collapse when disturbed—but the trained agent is able to do it efficiently in terms of total steps taken.</span></p>
<p><span>Applying an impact penalty yields quite different behavior.</span></p>
<div><p><img src="https://pde.is/posts/img/benchmark-append-still-013_p1.gif"> <img src="https://pde.is/posts/img/benchmark-prune-still-003_p1.gif"></p><p>Figure 3. Left: a safe agent builds new patterns, but is too cautious to complete its goals. Right: a safe agent successfully removes red patterns without disrupting anything else.</p>
</div>
<p><span>In Figure 3, the image on the left illustrates how the pattern-building agent is now too cautious to disrupt the green pattern. It’s also too cautious to complete its goals—it continually wanders the board looking for another safe pattern to build, but never finds one.</span></p>
<p><span>In SafeLife, as in life, destroying something (even safely) is much easier than building it, and the pattern-destroying agent with an impact penalty (Figure 3, right) performs much better than the one without the penalty. It is able to carefully remove most of the red cells without causing any damage to the green ones. However, it’s not able to remove </span><i><span>all</span></i><span> of the red cells, and it completes the level much more slowly than its unsafe peer. Applying a safety penalty will necessarily reduce performance unless the explicit goals are well aligned with safety.</span></p>
<h5>Agents in Dynamic Environments</h5>
<p><span>Side effects are much more difficult to disentangle in dynamic environments. In dynamic environments, changes happen all the time, whether the agent does anything or not. Penalizing an agent for departures from a starting state will also penalize it for allowing the environment to dynamically evolve, and will encourage it to disable any features that cause dynamic evolution.</span></p>
<div><p><img src="https://pde.is/posts/img/benchmark-prune-spawn-019_p0.gif"> <img src="https://pde.is/posts/img/benchmark-prune-spawn-019_p0.5.gif"></p><p>Figure 4. Left: an unsafe agent predictably ignores the chaotic region and focuses on its goals. Right: in its effort to avoid side effects, an overzealous agent destroys dynamic parts of the level.</p>
</div>
<p><span>In Figure 4, the image on the left shows an agent trained without an impact penalty. This unsafe agent ignores the stochastic yellow pattern and quickly destroys the red pattern and exits the level. The image on the right shows the effects of an agent with a small impact penalty. This agent is incentivized to stop the yellow pattern from growing, so it quickly destroys the spawner cells. Only then does it move on to the red cells, but it doesn’t manage to remove them safely, as its training has taught it to focus more on the …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pde.is/posts/safelife/">https://pde.is/posts/safelife/</a></em></p>]]>
            </description>
            <link>https://pde.is/posts/safelife/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26072842</guid>
            <pubDate>Tue, 09 Feb 2021 01:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning for Expressive Piano Performances]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26072761">thread link</a>) | @angusturner
<br/>
February 8, 2021 | https://popgun-labs.github.io/ml-blog/generative_models/piano/symbolic_music/2020/02/01/beatnet.html | <a href="https://web.archive.org/web/*/https://popgun-labs.github.io/ml-blog/generative_models/piano/symbolic_music/2020/02/01/beatnet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!-- Global site tag (gtag.js) - Google Analytics -->




<!-- mathjax support -->


<h2 id="preface">Preface</h2>

<p>For the last four years, a small team at Popgun has been studying the application of deep learning to music analysis
and generation. This research has culminated in the release of <a href="https://splashpro.popgun.ai/">Splash Pro</a> - a free, AI-powered plugin 
for Digital Audio Workstations (DAWs). With the release of this blog, we hope to provide an accessible introduction to 
deep learning with music, by explaining some core projects we have worked on.</p>

<h2 id="introduction">Introduction</h2>

<p>In this post I want to describe the design of a model for expressive piano synthesis. The model, 
which we call ‘BeatNet’, is capable of analysing a piano performance and generating new pieces that imitate the 
original playing style. Before I get into the technical workings, here are a few samples generated by BeatNet:</p>

<p><strong>In the style of “Yiruma - River Flows In You”</strong>
</p>





<p><strong>In the style of “Chopin - Nocturne in E-flat major, Op. 9, No. 2”</strong>
</p>





<p><strong>In the style of “Errol Garner - Misty”*</strong>
</p>





<p>BeatNet is able to replicate many of the characteristics present in human piano performances, albeit with
some weaknesses and limitations that I will address. To explain how this model works, I have split the 
remainder of the blog into two sections. Part I will discuss musical representations, while Part II will explore the 
model design and showcase more of its capabilities.</p>

<p><span>
*Note: BeatNet does not model sustain pedal events. Sustain was manually added to this piece.
</span></p>

<h2 id="part-i---representations-of-music">Part I - Representations of Music</h2>

<p>In designing a model for music generation, it is critical to choose an appropriate representation. This choice
determines which data can be faithfully encoded, the modelling techniques that are available, and the efficacy of the 
overall system. For this reason, I have decided to begin with a brief explanation of some common musical 
representations. If this all feels familiar to you, feel free to skip ahead to part II.</p>

<h3 id="audio">Audio</h3>

<p>When we talk about audio in machine learning, we are typically referring to an array of time-domain samples. These
samples are a digital approximation to the physical sound pressure wave. The quality of this approximation is
determined by the sample rate and the bit-depth (see: <a href="https://en.wikipedia.org/wiki/Pulse-code_modulation">PCM</a>). In 
research, it is common to see sample rates of 16-22kHz. However, to capture the full range of human audible frequencies,
most HiFi applications (e.g. music, podcasts, etc) use rates of around 44kHz 
(see: <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist Theorem</a>).</p>

<p>Because of its high dimensionality, modelling raw audio is extremely challenging. For a generative model to 
reproduce audio structure on a timescale of a few seconds, it must capture the relationships between tens of 
thousands of samples. While it is becoming increasingly feasible to do this (see <a href="#citation-1">[1]</a>), there are more 
efficient ways to encode piano performances.</p>

<p>Note: For an example of music modelling directly in the audio domain, 
see <a href="https://openai.com/blog/jukebox/">OpenAI’s Jukebox</a> <a href="#citation-2">[2]</a>.</p>

<h3 id="midi">MIDI</h3>

<p>MIDI is a technical standard allowing electronic instruments and computers to communicate. It comprises
a sequence of ‘messages’, each describing a particular musical event or instruction. Instructions relating to the 
note timings, pitch and loudness (i.e. velocity) can be transmitted and stored. For example, a piano performance 
encoded as MIDI is a record of which notes were pressed, how forcefully and at what time.</p>

<p>To convert a MIDI file back into listenable audio, a piece of software replays these instructions and
synthesizes the relevant notes. MIDI does not encode acoustic information, such as the instrument sound or the recording
environment. For this reason it is drastically more efficient than audio, and it is a good starting point for our 
exploration.</p>

<p>When working with MIDI we use the terrific <a href="https://github.com/craffel/pretty-midi">PrettyMIDI</a> library by Colin Raffel. This abstracts away many
complexities of the raw format. See Colin Raffel’s <a href="https://colinraffel.com/publications/thesis.pdf">thesis</a> for
a more in-depth explanation of the MIDI file format.</p>

<p><strong>Figure 1 - Für Elise in PrettyMIDI Format</strong></p>
<div><div><pre><code>Note(start=0.000000, end=0.305000, pitch=76, velocity=67)
Note(start=0.300000, end=0.605000, pitch=75, velocity=63)
Note(start=0.600000, end=0.905000, pitch=76, velocity=74)
Note(start=0.900000, end=1.205000, pitch=75, velocity=71)
...
</code></pre></div></div>

<p>Notice how succinctly we can represent Für Elise this way, and consider that the equivalent audio section 
contains approximately 50k samples (for a 44kHz recording).</p>

<h3 id="piano-roll">Piano Roll</h3>

<p>This will look familiar to anyone who has used a Digital Audio Workstation (DAW) such as GarageBand or Ableton.
The vertical axis denotes pitch, and the horizontal axis denotes time. The velocity of each note is encoded
by its magnitude. As well as providing an intuitive way to visualize MIDI, piano roll has some interesting 
properties for machine learning.</p>

<p>For example, consider the effect of raising the song’s pitch by one semitone, or delaying its onset by a few seconds. 
These transpositions preserve the spatial structure of the piano roll. When designing a model we can exploit this 
property by applying 2D Convolutional Neural Networks (CNN). Early experiments at Popgun tried exactly
this, as did <a href="https://youtu.be/nA3YOFUCn4U?t=597">this project</a> using PixelCNN. However, there are some serious drawbacks to this approach.</p>

<p><strong>Figure 2 - Für Elise in Piano Roll Format</strong></p>
<p><img src="https://popgun-labs.github.io/ml-blog/assets/images/piano_roll_fur_elise_crop.png" alt="Für Elise - Piano Roll"></p>

<p>A typical song encoded as piano roll is incredibly sparse: nearly all entries are zero. 
Naively applying a CNN wastes a large amount of computation on entirely empty regions. It is also difficult
to choose a suitable resolution for the time axis. If the original data is quantised, such that each note aligns
perfectly with a uniform musical grid, we can choose the resolution based on the quantisation strength. However,
this breaks down for expressive piano performances, where natural variations in timing are critical to the musicality.</p>

<p>Note: Many works have tried to model piano roll, using a broad range of neural net architectures. For those interested 
to learn more, <a href="https://arxiv.org/abs/1206.6392">this paper</a> is a good starting point <a href="#citation-16">[16]</a>.</p>

<h3 id="time-shift-format">Time-Shift Format</h3>

<p>In 2017 <a href="https://magenta.tensorflow.org/blog/">Google Magenta</a> released a model called Performance RNN <a href="#citation-3">[3]</a>, which demonstrated the ability 
to model expressive piano performances with high fidelity. The key innovation was a new format that is highly 
suited to this task. For reasons that will become apparent, we refer to this “performance representation” simply as 
“time-shift”. Like MIDI, time-shift encodes music with a sequence of discrete musical events. What sets it apart is 
the unique way it encodes the progression of time. Instead of representing time along a specific axis (piano roll), 
or as a property of each individual note (MIDI), in time-shift there is a specific event that indicates the 
advancement of the piece.</p>

<p><strong>Figure 3 - Für Elise in Time-Shift Format</strong></p>
<div><div><pre><code>272 - Set Velocity = 64
76  - Turn On MIDI Note 76 (E5)
317 - Advance Time by 0.3 Seconds
204 - Turn Off MIDI Note 76 (E5)
271 - Set Velocity = 60
75  - Turn On MIDI Note 75 (D#5)
317 - Advance Time by 0.3 Seconds
203 - Turn Off MIDI Note 75 (D#5)
274 - Set Velocity = 72
76  - Turn On MIDI Note 76 (E5)
317 - Advance Time by 0.3 Seconds
204 - Turn Off MIDI Note 76 (E5)
273 - Set Velocity = 68
75  - Turn On MIDI Note 75 (D#5)
317 - Advance Time by 0.3 Seconds
...
</code></pre></div></div>

<p>This one-dimensional sequence of tokens is similar to the encodings used in language models.
This means that modern advances in NLP (e.g. ByteNet <a href="#citation-4">[4]</a>, Transformers <a href="#citation-5">[5]</a>) can be 
readily applied to the time-shift format.</p>

<p><strong>Figure 4 - An Explanation of the Time-Shift Events</strong></p>
<div><div><pre><code>0 - 127: Note on events    
128 - 255: Note off events    
256 - 287: 32 velocity change events   
288 - 387: 100 quantized time-shift values (10ms -&gt; 1000ms)
</code></pre></div></div>

<p>Note: We have not accounted for sustain pedal events, however it might be interesting to incorporate them
in future work.</p>

<h2 id="part-ii---beatnet-a-convolutional-model-for-piano-music">Part II - BeatNet: A Convolutional Model for Piano Music</h2>

<p>In 2016, researchers at Google’s DeepMind lab released the now-famous WaveNet paper <a href="#citation-1">[1]</a>. The core 
insight was that 1D convolutions could produce efficient sequence models, by eliminating the need for expensive 
recurrent computations during training. The efficacy was proven with a 
<a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio">demo</a> of raw audio generation. The 
publication of ByteNet <a href="#citation-4">[4]</a> shortly afterwards, extended this idea to the domain of natural language 
processing.</p>

<p>Inspired by this work, Popgun developed its own ByteNet model for symbolic piano music. We refer to this work as
“BeatNet”. The choice to use ByteNet over traditionally dominant RNNs was motivated by a few factors:</p>
<ol>
  <li>The ability to capture long-term dependencies over hundreds or thousands of tokens</li>
  <li>Fast training</li>
  <li>Hype. WaveNet and ByteNet were the first papers to threaten the dominance of RNNs, before Transformer based
architectures <a href="#citation-5">[5]</a> exploded in popularity.</li>
</ol>

<h3 id="data-collection-and-processing">Data Collection and Processing</h3>

<p>We curated a MIDI dataset by drawing from a number of online sources. One key source was the
<a href="http://www.piano-e-competition.com/">Yamaha e-Piano Competition Dataset</a>, consisting of jazz 
and classical music performances. Another source was the <a href="https://colinraffel.com/projects/lmd/">Lakh MIDI Dataset</a>, 
which contains a broader range of genres, including many contemporary pieces.</p>

<p>To create a model which generates highly expressive performances, we processed the data to filter out ‘low quality’ 
items. Anyone who has worked with MIDI datasets will appreciate that many songs sound ‘bad’.
This raises some difficult problems: What is musical quality? How can we account for subjective preferences? 
Are some songs so weird we can confidently deem them ‘not musical’? Suffice to say, these problems are beyond
the scope of this post.</p>

<p>Ultimately, our working solution can be summarised as this: An engineer listened to some data items, in each case 
proclaiming “Yep, this sounds musical” or “Nope, I don’t like it”. In the process, they developed automated heuristics
to filter unwanted items, biasing the dataset towards songs that are subjectively ‘musical’. In the future it would be 
interesting to crowd-source these assessments, or to devise heuristics based on music theory instead.</p>

<h3 id="a-working-prototype">A Working Prototype</h3>

<p>We completed our first working prototype in July 2017. It is …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://popgun-labs.github.io/ml-blog/generative_models/piano/symbolic_music/2020/02/01/beatnet.html">https://popgun-labs.github.io/ml-blog/generative_models/piano/symbolic_music/2020/02/01/beatnet.html</a></em></p>]]>
            </description>
            <link>https://popgun-labs.github.io/ml-blog/generative_models/piano/symbolic_music/2020/02/01/beatnet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26072761</guid>
            <pubDate>Tue, 09 Feb 2021 01:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why data governance is critical for advanced analytics, ML and Automation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26072506">thread link</a>) | @siganakis
<br/>
February 8, 2021 | https://growingdata.com.au/pragmatic-data-governance-is-critical-for-advanced-analytics-machine-learning-automation/ | <a href="https://web.archive.org/web/*/https://growingdata.com.au/pragmatic-data-governance-is-critical-for-advanced-analytics-machine-learning-automation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5868" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<div>
<div>
<div>
<div>
<p>Data Governance seeks to bring order to the chaos that emerges as organisations turn to data to make decisions. To many, the term “data” is synonymous with “fact”, forgetting the fact that data requires context to be properly interpreted. Context varies by department, business unit across teams and even within teams, leading to misinterpretation of data and increasing the risk that data is misrepresented. Data Governance helps to define rules, processes and policies for how data is collected, managed to ensure that it can be consistently interpreted and applied to advanced analytics, machine learning and automation. </p>
<p>Analytics platforms like PowerBI, Tableau and Looker put data in the hands of employees and promise better decisions based on real data. But what happens when a colleagues number is different from yours? Or when people don’t know which version of a dashboard to view? Or when you discover the “Sales metric” you have been making decisions on doesn’t actually include all the things you thought it does?</p>
<p>Machine Learning has the capability to transform all aspects of business, from recommending products to your customers, optimising call routing in your call centre through to segmenting marketing messages. As organisations become more reliant on these technologies, they are more likely to incorporate them deeper into their processes leaving them vulnerable to prickly edge cases. Machine learning fails are already well-publicised, from<a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" rel="nofollow"> sexist recruitment AI at Amazon</a>, or <a href="https://twitter.com/geraldmellor/status/712880710328139776?lang=en" rel="nofollow">Microsoft’s AI Twitter Bot “Tay” who lasted less than 24 hours before going full racist.</a></p>
<p>Automation, especially when combined with Machine Learning makes organisations more efficient and more scalable. Marketing Automation provides marketers with super-powers to deliver the right message to the right customer at the right time. However, when automation fails (often due to errors in data), the problems are amplified – as one mistake can set off a chain of events that can destroy organisations.</p>
<h2 id="Introduction"><span>Introduction</span></h2>
<p>To help illustrate the importance of Data Governance, we will use a fictional company, which has run into an equally fictional set of challenges. Forrest Corp, is an online book retailer with approximately 100 staff, based in Melbourne, Australia. As with many organisations of this size, Forest Corp has functional teams responsible for Marketing, Finance, Technology, Customer Service and Operations. Forrest Corp has been wildly successful, with sales exploding throughout COVID-19 lockdowns.</p>
<p><strong>The problem</strong></p>
<p>The executive team is very displeased that gross margins and profitability have deteriorated sharply, and that their personal (managed) Instagram feeds are blowing up with negative messages. They want answers! In speaking with leaders from different teams, they receive mixed messages:</p>
<ul><li>Marketing is excited to show a 10% increase in sales due to a Social Media Influencer campaign and finds it difficult to believe things are as bad as they are made out to be</li><li>Finance says sales are flat, with rising inventories, shipping costs and customer retention costs hurting margins and profitability</li><li>Customer service is inundated with complaints, but they feel they have it under control using their existing policies and procedures</li><li>Operations confirm the increase in sales, but their team is overworked in dealing with the influx of sales and a large number of returns.</li></ul>
<p>An analysis by an external analytics consultancy begins to unravel the story:</p>
<ul><li>The Marketing team recently established a new Social Media Influencer program, enabling influencers to sign up to earn referral commissions on books they recommend. </li><li>A very popular Social Media Influencer has recommended a particular book to their large follower base</li><li>The rapid increase in sales of the book have impacted the company’s recommendation model, leading to it being recommended to a much wider audience of customers</li><li>It turns out that the Social Media Influencer has misrepresented the book leading to a high rate of return from dissatisfied customers</li><li>In order to placate angry customers, customer Service follows its procedure of sending gifts to aggrieved customers, as recommended by their recommendation engine.</li><li>The gifts only inflame the situation, infuriated customers are often sent the same book as they initially returned.</li></ul>
<p>How could this all happen?</p>
<h2 id="Data-Governance">A failure of <span>Data Governance</span></h2>
<p>The <a href="https://datagovernance.com/">Data Governance Institute</a> defines data governance as “a system of decision rights and accountabilities for information-related processes, executed according to agreed-upon models which describe who can take what actions with what information, and when, under what circumstances, using what methods.”</p>
<p>Data governance is often formally practised in large organizations, but many of the concepts are applicable to all organisations seeking to utilise data in decision making.</p>
<p>In Forest Corp’s case, a series of failures in the way it collects, manages and utilizes data led to the cascading problems illustrated above.</p>
<h2 id="Data-Quality">Data Quality</h2>
<figure><img loading="lazy" width="1024" height="372" src="https://growingdata.com.au/wp-content/uploads/2021/02/DataQualitySkyscraper_Fig2-01-1024x372.png" alt="" srcset="https://growingdata.com.au/wp-content/uploads/2021/02/DataQualitySkyscraper_Fig2-01-1024x372.png 1024w, https://growingdata.com.au/wp-content/uploads/2021/02/DataQualitySkyscraper_Fig2-01-300x109.png 300w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Data Quality Foundations <a href="https://profisee.com/data-quality-what-why-how-who/" target="_blank" rel="noreferrer noopener">Image credit</a></figcaption></figure>
<p>Data quality is the foundation for all analytics and machine learning. As organisations seek to make more decisions on the basis of data, there is a real risk that decisions can be made incorrectly if the data underpinning them is incorrect, incomplete or inconsistent.</p>
<p>A key failure for Forest Corp’s marketing team was in its lack of screening of Influencer’s past histories. Social Media Influencers could sign up for their affiliate program easily, with critical pieces of information collected without any verification.</p>
<p>In the Forest Corp example, when the Marketing team’s analytics began showing the success of one affiliate code they immediately looked up the influencer behind it. Unfortunately, the URLs behind the profile were unusable. No data was supplied for their Twitter and Facebook handles, and their supplied Instagram handle didn’t actually exist. While contact information was provided, emails and phone calls went unanswered. So the Marketing Team was faced with a challenging scenario – their Social Media Influencer program is clearly generating sales but they are blind as to the content triggering it or the person behind it.</p>
<p>If data is captured incorrectly, it is often difficult or impossible to correct it. Worst of all though is that it’s only when an organisation <em>really</em> needs high-quality data that they realise it was never collected properly. In the Forrest Corp example, they were blind to a massive spike in sales attributable to a single affiliate without any way to tie it back to.</p>
<h3 id="Data-Quality-Recommendations">Data Quality Governance Recommendations</h3>
<h4 id="Incentivise-data-quality-at-the-point-of-collection">Incentivise data quality at the point of collection</h4>
<p>Digging deeper into the sign-up process for affiliates, it was discovered that the affiliate systems were built quickly following a mandate from the Executive Team to get the system up and running prior to a major holiday. Additionally, the Marketing Manager’s key KPI’s for the quarter were the number of onboarded affiliates, as well as the sales volume generated by affiliates. The problems with the affiliate signup process was a product of these incentives.</p>
<p>The time pressure to build the onboarding system meant that the initial design could not be implemented in its entirety. As Product Owner, the Marketing Manager had to prioritize which features would make the initial version, and which would be delayed to a future version. Automated verification of affiliates was seen as a large piece of work and thought to add friction to the signup process potentially hurting the Marketing Managers KPIs. It was therefore easy for the Marketing Manager to de-prioritise this feature of the onboarding system.</p>
<h5 id="Guiding-principles-for-incentivizing-data-quality">Guiding principles for incentivizing data quality</h5>
<ul><li>Key Performance Indicators that create disincentives for data quality should be avoided.</li><li>Analyse and understand the unintended consequences of performance metrics on data quality</li><li>Incorporate data quality metrics into KPI’s for Product Owners whos products involve data capture</li></ul>
<h4 id="Projects-that-involve-data-collection-require-oversight-and-guidance,-and-periodic-review">Projects that involve data collection require oversight and guidance, and periodic review</h4>
<p>Without a process of oversight in how data was captured, the Marketing Manager was free to make decisions that ultimately caused the misleading Influencer to speak fraudulently on behalf of their organisation. However, the Marketing Manager is rightly focussed on Marketing, not issues of Data Governance. An organisation can’t and shouldn’t expect all its managers to be Data Governance experts.</p>
<h5 id="Guiding-principles-for-data-quality-oversight">Guiding principles for data quality oversight</h5>
<ul><li>A Data Governance Council should provide advice on issues relating to how projects are implemented and the potential costs and risks of different implementations.</li><li>Data quality metrics should be established with any project that involves data capture</li><li>A Data Governance Council should periodically review or audit key systems to see how they are actually being used and assess the quality of the data they capture.</li></ul>
<h4 id="Understand-the-pressures-on-your-users-when-entering-data">Understand the pressures on your users when entering data</h4>
<p>Equally, in designing the affiliate sign-up form, the Marketing Team failed to understand the pressures on Social Media Influencers. One of these pressures is the need to sign up to a <em>lot</em> of affiliate programs, and the fact that time spent signing up to affiliate programs is time not spent building their brand and following. The Forrest Corp Affiliate Signup process, while failing to verify key information, also asked for a lot of information much of which seemed fairly unimportant to them getting paid. Therefore a lot of fields were left blank, even critical ones.</p>
<h5 id="Guiding-principles-for-designing-data-capture-systems">Guiding principles for designing data capture systems</h5>
<p>Data entry is often the least enjoyable aspect of a process., but is of critical importance. Systems that collect data need to be user friendly and easy to use. Here are a few principles:</p>
<ul><li>Make use of “pick lists” or “autocomplete” to make it easy to link data</li><li>Make it easy to identify existing entities to reduce the risk of creating duplicate entries</li><li>Avoid requiring too many fields, or …</li></ul></div></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://growingdata.com.au/pragmatic-data-governance-is-critical-for-advanced-analytics-machine-learning-automation/">https://growingdata.com.au/pragmatic-data-governance-is-critical-for-advanced-analytics-machine-learning-automation/</a></em></p>]]>
            </description>
            <link>https://growingdata.com.au/pragmatic-data-governance-is-critical-for-advanced-analytics-machine-learning-automation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26072506</guid>
            <pubDate>Tue, 09 Feb 2021 00:52:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of PyTorch Lightning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26072327">thread link</a>) | @shcheklein
<br/>
February 8, 2021 | https://www.notion.so/The-Evolution-of-PyTorch-Lightning-3fef02f6ea9b4b9fbaae5d32f3e1e09b | <a href="https://web.archive.org/web/*/https://www.notion.so/The-Evolution-of-PyTorch-Lightning-3fef02f6ea9b4b9fbaae5d32f3e1e09b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/The-Evolution-of-PyTorch-Lightning-3fef02f6ea9b4b9fbaae5d32f3e1e09b</link>
            <guid isPermaLink="false">hacker-news-small-sites-26072327</guid>
            <pubDate>Tue, 09 Feb 2021 00:30:09 GMT</pubDate>
        </item>
    </channel>
</rss>
