<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 05 Jan 2021 12:53:30 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 05 Jan 2021 12:53:30 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Want other to talk? Be a listener]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25620297">thread link</a>) | @docuru
<br/>
January 2, 2021 | https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener | <a href="https://web.archive.org/web/*/https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>Sometimes ago, I saw a manager complain about how hard it is to talk to his staffs. While there can be many reasons, but one I’ve seen more often. That’s the manager isn’t a listener, even though he/she is listening.</p><p>The different about listening and a listener is that, a listener had a reputation for listening</p><p>Let’s say a manager asked his staff to discus about work performance issue, try to understand and improve it. Though, the manager doesn’t feel the discussion was open enough.</p><p>In the past, the manager often don’t take his staff words serious, dismiss their ideas. Eventually, his staffs will assume him won’t take serious.</p><p>Often, when you often listen to people, you train them to talk. Otherwise, taking people words lightly, you accidentally train them to ignore.</p></div></div>]]>
            </description>
            <link>https://hieunc.treen.it/posts/1bwCK4dKtVs-want-other-to-talk-try-to-be-a-listener</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620297</guid>
            <pubDate>Sun, 03 Jan 2021 07:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Repl-Driven Programming]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25620256">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | http://mikelevins.github.io/posts/2020-12-18-repl-driven/ | <a href="https://web.archive.org/web/*/http://mikelevins.github.io/posts/2020-12-18-repl-driven/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			
			<div>

				<div>

					

					<p>Once upon a time, someone with the handle “entha_saava” posted this question on <a href="https://news.ycombinator.com/item?id=23791152">Hacker News</a>:</p>
<blockquote>
<p>Can someone knowledgeable explain how are lisp REPLs different from
Python / Ruby REPLs? What is the differentiating point of REPL
driven development?</p>
</blockquote>
<p>The answer is that there is a <a href="http://mikelevins.github.io/2020/02/03/programming-as-teaching.html">particular kind of programming</a>
in which you build a program by <em>interacting</em> with it as it runs, and
there are certain languages and runtimes that are designed from the
ground up to support that kind of programming.</p>
<p>Python and Ruby are not examples of such languages.</p>
<p>Why not? That’s the crux of entha_saava’s question, right? What are
these <strong>repl-driven</strong> programming systems, and what makes them
different from Python and Ruby and every other language that offers a
repl?</p>
<p>For that matter, what’s a repl?</p>
<p>The word <strong>repl</strong> is an acronym that stands for <strong>read-eval-print
loop</strong>. The term comes from the history of Lisp. From the start, sixty
years ago, the standard way of working with a Lisp has been to start a
language processor, type expressions at its prompt, and wait for it to
evaluate the expressions and print their results, before prompting for
another expression. Read, eval, print. Loop.</p>
<p>Nowadays, repls are all the rage. Every language and its brother
offers a repl. There’s a website, <a href="https://repl.it/">repl.it</a>, whose
entire purpose is to provide all the repls.</p>
<p>It doesn’t actually provide <em>all</em> the repls, of course. What’s
particularly ironic is that it doesn’t provide either of the canonical
repl-driven development environments: Common Lisp and Smalltalk.</p>
<p>That brings us back to entha_saava’s question: if Common Lisp and
Smalltalk are repl-driven environments, and Python and Ruby are not,
what’s the difference? What do Lisp and Smalltalk have that Python and
Ruby don’t?</p>
<p>What they have is a language and runtime system that are designed from
the ground up with the assumption that you’re going to develop
programs by starting the language engine and talking to it, teaching
it how to be your program <em>interactively</em>, by changing it <em>while it
runs</em>.</p>
<p>I can hear the objections formulating already. I’ve seen them
before. Yes, every language with a repl can do some things in the
repl. Obviously that’s true; if it weren’t, then the repl would be
entirely useless.</p>
<p>Being able to do <em>some</em> things in the repl does not make an engine
into a repl-driven programming environment. What distinguishes
old-fashioned Lisp and Smalltalk environments is that you can do
<em>everything</em> in the repl. They place no gratuitous limitations on what
you can do; if the language and runtime can do it, then the repl can
do it.</p>
<p>For example, you can ask the current version of Clozure Common Lisp to
rebuild itself from scratch by evaluating the following expression at
the repl prompt:</p>
<pre><code>(rebuild-ccl :full t)
</code></pre>
<p>CCL responds by completely rebuilding itself from source.</p>
<p>The point is not that you would want to rebuild CCL this way all the
time. The point is that there are no artificial limitations on what
the repl can do. The full range of the development system’s
capabilities is accessible from the repl.</p>
<p>That’s one of the first things I notice when using newer, lesser
repls: I’m always running into things I can’t do from the repl.</p>
<p>It’s not just about freedom from restrictions, though. Proper support
for interactive programming means that the language and its runtime
have positive features that support changing your program <em>while it
runs</em>.</p>
<p>Try this in your favorite repl:</p>
<p>Define a function, <code>foo</code>, that calls some other function, <code>bar</code>, that
is not yet defined. Now call <code>foo</code>. What happens?</p>
<p>Obviously, the call to <code>foo</code> breaks, because <code>bar</code> is not defined. But
what happens when it breaks? What happens next?</p>
<p>If your favorite repl is Python’s or Ruby’s or any of a few dozen
other modern repls, the answer is most likely that it prints an error
message and returns to its prompt. In some cases, perhaps it crashes.</p>
<p>So what’s my point, right? What else could it do?</p>
<p>The answer to that question is the “differentiating point” of
repl-driven programming. In an old-fashioned Lisp or Smalltalk
environment, the break in <code>foo</code> drops you into a <strong>breakloop</strong>.</p>
<p>A <strong>breakloop</strong> is a full-featured repl, complete with all of the
tools of the main repl, but it exists inside the dynamic environment
of the broken function. From the breakloop you can roam up and down
the suspended call stack, examining all variables that are lexically
visible from each stack frame. In fact, you can inspect all live data
in the running program.</p>
<p>What’s more, you can <em>edit</em> all live data in the program. If you think
that a break was caused by a wrong value in some particular variable
or field, you can interactively change it and resume the suspended
function. If it now works correctly, then congratulations; you found
the problem!</p>
<p>Moreover, because the entire language and development system are
available, unrestricted, in the repl, you can define the missing
function <code>bar</code>, resume <code>foo</code>, and get a sensible result.</p>
<p>In fact, there’s a style of programming, well known in Lisp and
Smalltalk circles, in which you define a toplevel function with calls
to other functions that don’t yet exist, and then define those
functions as you go in the resulting breakloops. It’s a fast way to
implement a procedure when you already know how it should work.</p>
<p>If you’re a user of old-fashioned Lisp or Smalltalk systems then this
all sounds obvious to you, but that reaction is not common. Surprise
is much more common, or even suspicion: what’s the catch?</p>
<p>The catch is that the designers of your language system had to think
that facility through in the planning stages. You don’t get a decent
implementation of it by bolting it on after the fact. Breakloops need
<em>full</em> access to the <em>entire</em> development system, interactively, with
a computation and its call stack suspended in the breakloop’s
environment.</p>
<p>Let’s take another example of a facility designed to support
interactive programming. Once again, try this in your favorite repl:</p>
<p>Define a datatype. I mean a class, a struct, a record type–whatever
user-defined type your favorite language supports. Make some instances
of it. Write some functions (or methods, or procedures, or whatever)
to operate on them.</p>
<p>Now change the definition of the type. What happens?</p>
<p>Does your language runtime notice that the definition of the type has
changed? Does it realize that the existing instances have a new
definition? When something touches one of them, does it automatically
reinitialize it to conform to the new definition, or, if it doesn’t
know how to do that, does it start a breakloop and ask you what to do
about it?</p>
<p>If the answer is “yes,” then you’re probably using a Lisp or Smalltalk
system. If the answer is “no,” then you’re missing a crucial element
of repl-driven development.</p>
<p>Remember: the point is to support programming <em>interactively</em>. You
don’t want to have to kill your program and rebuild it from scratch
just because you changed a definition. That’s silly; adding and
changing definitions is most of what you do! If your development
environment is going to support interactive development, then it had
better know how to keep your program running when you change some
definitions.</p>
<p>Old-fashioned Lisp and Smalltalk system know how to do that. There are
also a few other kinds of systems, mostly older ones, that know how to
do it.</p>
<p>These are not eccentric new ideas out of left field. They’ve been
around for half a century. They contribute materially to productivity
in interactive development.</p>
<p>They’re what sets <strong>repl-driven development</strong> apart from mere
development with a repl.</p>
<p>Now, not every programmer prefers that kind of development. Some
programmers prefer to think of development as a process of designing,
planning, making blueprints, and assembling parts on a
workbench. There’s nothing wrong with that. Indeed, a
multibillion-dollar international industry has been built upon it.</p>
<p>But if you prefer interactive development, if it’s more natural to
you, then it can make you enormously more productive, not to mention
happier in your work.</p>
<p>Interactive development with a proper repl-driven environment is the
exception. Most programming is done in other ways.</p>
<p>As a consequence, there are a lot of programmers out there who’ve
never even heard of it, who have no idea that it exists. My intuition
is that some fraction of those programmers would prefer well-supported
interactive programming, and would benefit from it, if they just knew
what it was.</p>
<p>Maybe if enough programmers are exposed to that style of programming
then we’ll begin to see new tools that embrace it.</p>


				</div>

			</div>
			
		</div>
	</div></div>]]>
            </description>
            <link>http://mikelevins.github.io/posts/2020-12-18-repl-driven/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620256</guid>
            <pubDate>Sun, 03 Jan 2021 07:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Sublime Text of X”]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25620176">thread link</a>) | @mastermojo
<br/>
January 2, 2021 | http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/ | <a href="https://web.archive.org/web/*/http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        




<article>
  <!-- date:       2021-02-01 -->
<!-- Why does the date cause the post to not render? -->

<center>
<small>
Note: The author has never paid for, is not affiliated with, and is not endorsing Superhuman as a product.
</small>
</center>

<h3 id="superhuman">Superhuman</h3>

<p>Superhuman is an invite-only $30/month email client.<sup id="fnref:pricing" role="doc-noteref"><a href="#fn:pricing">1</a></sup> People like it for its sleek design, responsive speed, and suite of keyboard shortcuts to improve a user’s email efficiency. People justify this purchase over free alternatives by the fact that they spend hours on email everyday. Part of Superhuman’s feature offering includes read statuses, which is useful for executives and sales people who like to keep a pulse on their conversations.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/superhuman.png" alt="Superhuman Product Screenshot"></p>

<p>Users love Superhuman. Take a quick peak on Twitter<sup id="fnref:twitter" role="doc-noteref"><a href="#fn:twitter">2</a></sup> at the effusive praise the company gets. Andreessen Horowitz led the latest investment round in the company with a valuation of roughly $260 million.</p>

<p>Following in the tailwind of this prosumer email client that has taken Silicon Valley and Twitter by storm are a suite of companies claiming to be “Superhuman for x”.<sup id="fnref:superhumanofx" role="doc-noteref"><a href="#fn:superhumanofx">3</a></sup></p>

<p>As identified by Todd Goldberg, the “Superhuman of X” has the following traits:</p>
<ul>
  <li>Designed for speed.</li>
  <li>Built as an opinionated product experience for a specific use case and/or target audience.</li>
  <li>Driven primarily by keyboard shortcuts.</li>
  <li>Beautiful and thoughtfully designed.</li>
  <li><em>Optional</em>: Built as a modern alternative to a product that has legacy distribution effects</li>
  <li><em>Optional</em>: Positioned as a premium product vs. free alternatives.</li>
</ul>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/commands_superhuman.png" alt="Superhuman Commands Screenshot"><br>
<small>
  Superhuman Command bar: short-cut triggered command search bar
</small></p>

<hr>

<center>
<small>
Note: The author has never paid for, is not affiliated with, but likes using Sublime Text as a product.
</small>
</center>

<h3 id="sublime-text">Sublime Text</h3>

<p>I present Sublime Text: a piece of software more than a decade older than Superhuman, that shares the above attributes. Sublime can be driven primarily by keyboard shortcuts. It’s as thoughtfully designed as I have been shamefully unwilling to purchase the non-trial version for 80 USD. The similarities lie much deeper than that. Sublime has two close-to-instant-speed search-bars: one for opening a file in your project [goto] and one for executing commands.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/commands_sublime.png" alt="Sublime Commands Screenshot"><br>
<small>
  Sublime Text Command Palette: short-cut triggered command search bar
</small><br></p>

<p>Sublime Text is also simultaneously opinionated but also configurable. It is simple enough for a programmer to install, open, and “hit the ground running” on a big project with a combination of GOTO (⌘+P) and project search (⌘+Shift+F).</p>

<hr>

<h3 id="the-sublime-text-of-x">The “Sublime Text of X”</h3>

<p>Without futhur ado, I present a case study sampling of “Sublime Texts of X”.</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/sublime.png" alt="Sublime Text Screenshot"><br>
<small>The (Eponymous) Sublime Text of Text Editors: <a href="https://www.sublimetext.com/">https://www.sublimetext.com/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/fman.png" alt="Fman Product Screenshot"><br>
<small>The Sublime Text of Finder/File Explorer: <a href="https://fman.io/">https://fman.io/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/linear.png" alt="Linear Product Screenshot"><br>
<small>The Sublime Text of Task/Bug Tracking: <a href="https://linear.app/">https://linear.app/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/cron.png" alt="Cron Product Screenshot"><br>
<small>The Sublime Text of Calendars: <a href="https://cron.app/">https://cron.app/</a>
</small></p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/merge.png" alt="Sublime Merge Product Screenshot"><br>
<small>The Sublime Text of Git GUI Clients: <a href="https://www.sublimemerge.com/">https://www.sublimemerge.com/</a>
</small></p>

<p>The “Sublime Text of X” is software having the following traits:</p>
<ul>
  <li>Designed for speed.</li>
  <li>Built as an opinionated product experience for a specific use case and/or target audience.</li>
  <li>Driven primarily by keyboard shortcuts.</li>
  <li>Beautiful and thoughtfully designed.</li>
  <li><span><em>Not Optional</em>: &nbsp;Dark mode&nbsp;</span></li>
</ul>

<p>I look forward to a <del>bright</del> dark future where everything can be done fast and efficiently through keyboard shortcuts. If there are other startups or products that give you Sublime Text vibes I would love to know!</p>

<p><img src="http://www.growthalytics.com/images/2021-01-02-the-sublime-text-editor-of-x/terminal.png" alt="Terminal Product Screenshot"><br></p>

<hr>



</article>





<br>
<hr>






      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://www.growthalytics.com/startups/programming/product/2021/01/02/the-sublime-text-editor-of-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620176</guid>
            <pubDate>Sun, 03 Jan 2021 07:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ordered Key-Value Stores]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25620137">thread link</a>) | @timhigins
<br/>
January 2, 2021 | https://hyper.dev/ordered-key-value-stores.html | <a href="https://web.archive.org/web/*/https://hyper.dev/ordered-key-value-stores.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hyper.dev/ordered-key-value-stores.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620137</guid>
            <pubDate>Sun, 03 Jan 2021 07:06:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Design Patterns as a Book]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25620110">thread link</a>) | @WnZ39p0Dgydaz1
<br/>
January 2, 2021 | https://rust-unofficial.github.io/patterns/ | <a href="https://web.archive.org/web/*/https://rust-unofficial.github.io/patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<h2><a href="#design-patterns" id="design-patterns">Design patterns</a></h2>
<p>When developing programs, we have to solve many problems. A program can be viewed as a solution to a problem. It can also be viewed as a collection of solutions to many different problems. All of these solutions work together to solve a bigger problem.</p>
<h2><a href="#design-patterns-in-rust" id="design-patterns-in-rust">Design patterns in Rust</a></h2>
<p>There are many problems that share the same form. Due to the fact that Rust is not object-oriented design patterns vary with respect to other object-oriented programming languages. While the details are different, since they have the same form they can be solved using the same fundamental methods. </p>
<p><a href="https://rust-unofficial.github.io/patterns/patterns/index.html">Design patterns</a> are methods to solve common problems when writing software.</p>
<p><a href="https://rust-unofficial.github.io/patterns/anti_patterns/index.html">Anti-patterns</a> are methods to solve these same common problems. </p>
<p>However, while design patterns give us benefits, anti-patterns create more problems.</p>
<p><a href="https://rust-unofficial.github.io/patterns/idioms/index.html">Idioms</a> are guidelines to follow when coding. They are social norms of the community. 
You can break them, but if you do you should have a good reason for it. </p>
<p>TODO: Mention why Rust is a bit special - functional elements, type system, borrow checker</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://rust-unofficial.github.io/patterns/idioms/index.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://rust-unofficial.github.io/patterns/idioms/index.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://rust-unofficial.github.io/patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25620110</guid>
            <pubDate>Sun, 03 Jan 2021 06:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The design flaws of password managers]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25619451">thread link</a>) | @_wldu
<br/>
January 2, 2021 | https://www.go350.com/posts/the-design-flaws-of-password-managers/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/the-design-flaws-of-password-managers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I once worked in highly regulated environments and needed a way to recall dozens of complex passwords that changed frequently. I tried to use a password manager, but could not due to the burdens and insecurity of some common design flaws. I wrote a Deterministic Password Generator <a href="https://github.com/62726164/dpg">DPG</a> to address this.</p><p>If after reading this you still wish to use a traditional password manager, I suggest that you put your passwords into a plain text file and symmetrically encrypt it with <a href="https://gnupg.org/">GnuPG</a> or use <a href="https://www.pwsafe.org/">Password Safe</a>. I have no relation with either.</p><p>Here are three common design flaws in password managers:</p><ol><li>Password storage</li><li>Reliance on remote systems</li><li>Web browser integration</li></ol><h2 id="password-storage">Password storage</h2><p>When passwords are stored, they must be encrypted and then retrieved later when needed. Storage, of any type, is a burden. Users are required to backup stored passwords, synchronize them across devices and implement measures to protect them.</p><p>Users must also devise a master password to unlock the encrypted passwords stored by the password manager. This is similar to a <a href="https://en.wikipedia.org/wiki/Master_keying">master key</a>. It is generally accepted that master keyed locks are less secure than non-master keyed locks. If the master password is exposed, then confidence (in all the passwords that it unlocks) is lost.</p><p>And, are we certain that the encryption used to store the passwords is implemented correctly? Has the encryption been externally validated? Some password managers are closed-source and proprietary and cannot be examined.</p><p>Encryption is hard. Even respected, expert developers with many years of experience (who seldom make mistakes) <a href="http://www.daemonology.net/blog/2011-01-18-tarsnap-critical-security-bug.html">do make mistakes</a> that render encryption weak or in some cases almost useless.</p><h2 id="reliance-on-remote-systems">Reliance on remote systems</h2><p>Ironically, password managers rely on remote systems largely because they store passwords. The first design flaw causes the second.</p><p>Remote systems are outside the user’s control. They are opaque and cannot be examined and should not be trusted with password management. These systems may not be available when needed. They may not be storing or transmitting passwords correctly.</p><p>Externally, the systems may seem correct (strong HTTPS, reasonable CSP) but behind the scenes, no one really knows what’s going on. How are the passwords being transmitted, generated and stored internally? Who has access to them?</p><p>Several popular cloud-based password managers have reported security breaches: <a href="https://www.darkreading.com/attacks-breaches/onelogin-breach-reignites-concerns-over-password-managers/d/d-id/1329034">1</a>, <a href="https://arstechnica.com/information-technology/2017/03/potent-lastpass-exploit-underscores-the-dark-side-of-password-managers/">2</a>, <a href="https://www.wired.com/2015/06/hack-brief-password-manager-lastpass-got-breached-hard/">3</a>.</p><h2 id="web-browser-integration">Web browser integration</h2><p>Web browsers today have “everything but the kitchen sink” capabilities built-in and are becoming more and more complex each year. They are turning into whole platforms that have browser plug-ins and extensions for every possible need known to humankind.</p><p>While many of these add-ons are handy and useful, we should not trust them with password management. Browsers are just too complex and have far too much going on.</p><h2 id="dpg">DPG</h2><p>I wrote DPG (The Deterministic Password Generator) around 2010 to address the design flaws described above. Here are its key concepts.</p><ol><li>Never store passwords. Rather, generate them as needed based on user input. The need to backup, synchronize and properly encrypt passwords is removed. There is no master password that immediately unlocks all of the other passwords. There is nothing to become lost, stolen or corrupt.</li><li>Only run locally on end-use devices. No reliance on remote systems or web browsers.</li><li><a href="https://github.com/62726164/dpg">DPG is open-source</a> and has several implementations. The passwords it generates can be verified and validated by external implementations in multiple programming languages.</li></ol><h2 id="conclusion">Conclusion</h2><p>DPG removes many of the flaws that I have experienced with traditional password managers over the years. Try it. You may like it. I hope you find it as useful as I have.</p><ul><li><a href="https://www.go350.com/tags/passwords">passwords</a></li><li><a href="https://www.go350.com/tags/compliance">compliance</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/the-design-flaws-of-password-managers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619451</guid>
            <pubDate>Sun, 03 Jan 2021 04:27:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stanford University Supplementary Essays]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619387">thread link</a>) | @crazypython
<br/>
January 2, 2021 | https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/ | <a href="https://web.archive.org/web/*/https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">



<!-- Sect: Hero
================================================== -->	
<header>
 <div>
 	<div>
	  <p><span>September 20, 2019</span></p>
			<h4>Stanford University</h4>
  </div>
 </div>
</header>

<!-- Article: Content
================================================== -->
<section>
	<div>
	<p>Please write a short essay in response to each of the three essay topics below. There is a 100-word minimum and a 250-word maximum for each essay.
</p>		<p>First, let’s briefly get a sense of what 250 words means. It’s two average paragraphs, or three lean paragraphs. Also known as: not a ton of space! The burden is on you to think about the meatiest point you need to make, and then to build your surrounding elements strategically, so that they help you deliver that point with maximum impact, concisely. It’s not as easy as it may sound. For our analysis, we’re mostly going to dig into the “meat” aspect.</p>
<h3>Essay 1: The Stanford community is deeply curious and driven to learn in and out of the classroom. Reflect on an idea or experience that makes you genuinely excited about learning.</h3>
<p>Strangely, this one rides or dies on the PROOF that you’re actually, truly, genuinely excited about learning. What serves as proof? Action. The stuff YOU DO in response to the stuff you’re inspired by… that demonstrates it, and makes it real. Anyone can CLAIM to be super inspired by X Y and Z and talk about it. But if all they do is talk, does it really matter? Not exactly the world’s sexiest Zen koan, but you get the idea.</p>
<p>Something to consider here – something common to folks who are genuinely excited about learning – is an unusual comfort level with being WRONG. A thirst for learning is predicated on (1) acknowledging that you don’t know everything already, and (2) that the stuff you may THINK you know, is wrong or incomplete. Why mention this? Cuz it can help your case to give EVIDENCE of that. Have you ever been wrong about something, and were THRILLED to discover what ended up being a BETTER WAY OF LOOKING AT SOMETHING? Walk us through what it felt like, why it might have felt bad at some point, but why it felt GOOD eventually to have developed, improved, evolved. We need to really PROVE that you’re turned on by learning, and admitting that you’ve been wrong (and loved it), is an excellent way to do so.</p>
<p>Another way, alluded to earlier, is purely through action. Is there evidence of “tirelessness” when you’re attempting to learn something? We need to see ways in which you pursue this thing, especially when it’s INCONVENIENT to do so. In other words, if your pursuit is compelling, but kinda expected, it won’t weigh as much. If you decided you wanted to get some cereal, and then went out and bought yourself some cereal… um, okay? But if on the way, it started to rain, and a hurricane arrived, and the store closed, so you hitchhiked to another location, and that store was closed too, so you decided to call your friend you know who happened to have an extra box, but he wasn’t home, so you decided to……. [yada yada]…. You ended up with your box of Crispix. Now THAT GUY’s interest in “cereal” seems unimpeachable, no? Show us how, when pursuing something for the sake of learning, you’ve done it (1) when no one else was looking, or (2) when it became inconvenient to do so, but you still did it, or (3) when the risk of continuing to do it started to outweigh the benefits, or… you get the idea.</p>
<p>Most students will focus on THE THING they’re excited about, rather than proving their excitement through action. It’s that second group that ultimately wins, because we now have reason to believe that they have that forward-leaning trait which will carry them through college and beyond. (And that’s whole point of this question – to make sure you won’t drop out in freshman year when you take a class that’s harder than any class you’ve ever taken before.)</p>
<h3>Essay 2: Virtually all of Stanford’s undergraduates live on campus. Write a note to your future roommate that reveals something about you or that will help your roommate—and us—know you better.</h3>
<p>Classic Stanford undergrad question. The mistake we see 95% of the time on first drafts is the impulse to try to “slip in” resume highlights. As if this is a veiled attempt by Stanford to get those highlights, instead of, you know, just asking for them. The way to impress Stanford here is through honesty and charm. But mostly honesty.</p>
<p>Indulge us here and take two swings at this. On the first attempt, get it out of your system, whatever letter you want to write, just take a crack and then file it away for the time being.</p>
<p>On your second attempt, go with us on a little journey. Start by <strong>creating a roommate</strong>, leaving everything to chance (the same way it’ll more or less work out when you’re actually assigned a roommate in your freshman dorm). For starters, your roommate will almost certainly be the same gender. Now, generate a bunch of parameters, like ethnicity, height, weight, athletic/ musical/etc., liberal/conservative, east coast/southern/west-coast/etc., affable/surly, cool/not-so-cool, American/foreign-born/etc.…. Don’t spend too much time, because it doesn’t really matter much. Give this guy or gal a name. Again, don’t get stuck on this, the idea is to paint a vague picture. But once you have this picture, commit to it for a second. Imagine a real person on the other end.</p>
<p>Now, you’re gonna address a fresh new letter to this person. If the open-ended-ness of the Stanford prompt leaves you stuck, consider some of the following ideas. Write the letter using one of the following:</p>
<ul>
<li>What if your roommate just confided in you, and told you an incredible secret. Something that leaves your roommate in an extremely vulnerable emotional state having just put him/herself on the line. What might you reveal about YOURSELF in response? “Hey, so here’s something most people don’t know about ME…” (What might follow that up?)</li>
<li>Treat it as though it were a dating profile. What kinds of preferences would you reveal about yourself that might give the BEST clues about what you’re all about? Think about quirks and specificity here. If you were to say “I like Chinese food” it doesn’t say all that much since so many different types of people would fall under that same category. If, however, you were to say you absolutely HATE the HBO show “Game of Thrones” that would have the opposite effect since “most people are obsessed with that show (INCLUDING ALL OF US AT ADMISSIONADO, SO WATCH YOUR STEP!).” Can you stack up a few such preferences that, when summed, may help someone get a sense for what you’re all about, and even better, become more curious to get to know you better?</li>
<li>You know that classic question “if you were stuck on a desert island forever, what album would you bring?” … You can put a twist on it here. Name a few KEY possessions you’re gonna bring that’ll be essential to your comfort. Forget bland necessities like “a toothbrush” (since everyone will be packing one of those). More like, the “sounds of the rainforest” you use to lull yourself to sleep every night. Stuff like that. And possibly even suggest a few things you DON’T have that your roommate may bring to complete the set for total roommate symbiosis. You don’t need to follow this conceit exactly, but maybe this gives you an idea from which you can springboard to help show us something about who you are exactly, and what makes you … you.</li>
</ul>
<h3>Essay 3: Tell us about something that is meaningful to you, and why?</h3>
<p>Ha, in 250 words… you’re asked to grapple with one of life’s more challenging questions. A fitting test for a place like Stanford. Let’s start with what NOT to do.</p>
<p>Extinguish the desire to imagine what Stanford wants to hear. If you pen a response that you <strong>BELIEVE</strong> will put you in good stead because you think it shows maturity, or emotional intelligence, or whatever else… you are in for a crash landing. Or, tell you what, let’s a make a deal. Write that version, and keep it handy. Now write <strong>ANOTHER</strong> version that may never ever see the light of day. Think of this as a private diary entry. An exercise that may lead to something. But take the pressure away that someone might read it, so be more honest than you might want to be otherwise.</p>
<p>For this version, imagine you’re addressing a &nbsp;huge crowd (as if you are the Pope, or MLK), and it’s a crowd of people who… aren’t really contributing all that positively to society. Maybe they’re lazy. Maybe they’re irresponsible. Maybe they’re disaffected. Maybe they’re dangerous. Let’s just call them the folks who aren’t model citizens of the world.</p>
<p>What might you say to inspire these folks? Think about it. If you were to say something obvious, wouldn’t it run the risk of not having much of an impact? Make it less about you (just for a second), and instead think about what you might say to inspire this crowd. If you were to say “say no to drugs” or “do unto others…” or “cherish each day as though it were your last” … hasn’t everyone heard it already? If they haven’t internalized those ideas, they’re certainly not gonna do so just because <strong>YOU</strong> said it, right? But they might if they hear something <strong>NEW</strong>, something fresh about what matters, in a way that may cause them to re-evaluate things or see things through a new lens.</p>
<p>Obviously, you won’t want to write about something trivial, like “driving a nice car matters because the value of a smooth ride is more pleasing than a bumpy one.” Unless it’s a cracking metaphor, something like that might make your message seem like you didn’t give it a whole lot of thought, or, worse, you’re someone who’s so privileged that that type of material comfort is truly something that matters more than deeper, cooler things. So, it probably will have to do with human interaction, or a way of approaching things, or a state of being, or the like. Think about where others are going wrong. What are others <strong>MISSING</strong>, in a way that leads to irresponsible behavior, actions, attitudes, etc.? What matters to <strong>YOU</strong> that makes you feel like your compass is pointed in a better direction?</p>
<p>This conceit (of addressing a crowd) is meant to unlock ideas, not for you to embrace the idea too literally. You’re not proselytizing. So, if it helps, use your imagination of …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/">https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/</a></em></p>]]>
            </description>
            <link>https://admissionado.com/resources/essay-analysis/stanford-essay-analysis-short-essays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619387</guid>
            <pubDate>Sun, 03 Jan 2021 04:18:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Complete Their Thought]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619124">thread link</a>) | @ny2ko
<br/>
January 2, 2021 | https://nngorok.com/don-t-complete-their-thought | <a href="https://web.archive.org/web/*/https://nngorok.com/don-t-complete-their-thought">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <p><a href="https://nngorok.com/don-t-complete-their-thought">January 3, 2021</a></p>
<p>I’ve recently been thinking about why listening can be very difficult. One aspect that always comes to mind, a practice that is exceptionally difficult to give up, is the tendency to finish other’s thoughts. Here’s some similar scenarios to illustrate:</p>
<p>Meet Alice, a senior engineer on a team and Bob a recent addition on the team.</p>
<blockquote>
<p>Bob: Hey Alice. Got a sec?<br> Alice: Sure Bob. What’s up?<br> Bob: I was trying to use system X and I run into problem Y. I …<br> Alice: Oh, must be issue Z? That concurrency bug surfaces from time to time.</p>
</blockquote>
<p>This can go one of 2 ways. Either, Alice is on the money and has helped Bob figure it quickly.</p>
<blockquote>
<p>Bob: Oh! Right! I hadn’t thought about that. Why is that?<br> Alice: My pleasure.<br> etc.</p>
</blockquote>
<p>Or alternatively, Alice is off the mark:</p>
<blockquote>
<p>Bob: I don’t think so. I’m seeing more of issue A.<br> Alice: I see. Must be the installation ordering!<br> etc.</p>
</blockquote>
<p>In both these cases, Alice quickly concludes what issue Bob might be facing. With her wealth of experience on the team and deep knowledge of the systems, she is able to usually have a good idea what the issue is. However, in both cases, Alice unintentionally doesn’t allow Bob to complete his thoughts. What else could Bob have said about the issue? He, for instance, could have elaborated on the steps he had taken so far, and how he went about trying to figure out the issue. All this information could have given Alice more context and a better opportunity to coach Bob as he ramps up on the team even better. It also could have fostered more relationship building between them. Unfortunately, this doesn’t happen.</p>
<p>Cases such as this are very common. Let’s look at Juan a manager and Neda, an engineer that reports to him:</p>
<blockquote>
<p>Juan: Hey Neda! How’s the project going?<br> Neda: The project is coming along well. I do have some reservations on it’s value to the company. It…<br> Juan: What aspects are giving you reservations?<br> Neda: The project will take Y months and at best generate Z in revenue. <span>I…</span><br> Juan: That sounds pretty decent to me. This project has been a long time coming and will have impact around the company beyond revenue. It will…</p>
</blockquote>
<p>Juan does a good job trying to understand the problem a bit better at the start asking a clarifying question. However, when he gets a whiff of what he thinks the issue is, he quickly jumps to address it, attempting to complete Neda’s thoughts.</p>
<p>Unfortunately, it isn’t possible to truly know what another’s thoughts are. We simply cannot <strong>(yet)</strong> read each other’s minds. If we don’t let others finish their thought, we risk souring the conversation and/or relationship: whether that means the other person has to correct us and redirect the conversation or that the other person resorts to not voicing their opinions.</p>
<p>We all have busy schedules and want to be efficient in our conversations. As leaders, we often are having similar conversations with many different people. So much so, that we usually know what the person is<span></span> <span>“</span>getting at”; it is very tempting to make the connections! The crux though, is that when we guess wrong, it can be disastrous.</p>
<p>So the next time you have the urge, pressing as it may be, to complete someone’s thoughts, hold your tongue. Let them go over what they think even if you’ve heard it all before. Before you respond, ask yourself, have they finished their thought? Are you about to complete their thought because you think you know what they are getting at? Don’t respond until they finish. With all the context they give you, give them that great response! They will appreciate you for it. If you really must, and can’t fight the urge, count down for 5 seconds of silence or try asking a clarifying question instead.</p>
          

          



          

          <hr>

          <a href="https://nngorok.com/managers-should-code-but-not-at-work">
            <h5>Previous post</h5>
            <span>Managers should code, but not at work</span>
            <span>Should managers code? This question doesn’t seem to have a clear answer. There are proponents and opponents to the debate, each having valid points</span>
          </a>

        </div>

      </div>
    </div></div>]]>
            </description>
            <link>https://nngorok.com/don-t-complete-their-thought</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619124</guid>
            <pubDate>Sun, 03 Jan 2021 03:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Concepts of Legibility]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25619052">thread link</a>) | @jashkenas
<br/>
January 2, 2021 | https://ideolalia.com/essays/two-concepts-of-legibility.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/two-concepts-of-legibility.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>In <a href="https://en.wikipedia.org/wiki/Seeing_Like_a_State"><em>Seeing Like a State</em></a>, James C. Scott defines “legibility” as something a state imposes on its people and resources.  It is a coercive abstraction, not only treating different people, places, and ways of life as if they were the same<sup id="fnref:abstraction"><a href="#fn:abstraction">1</a></sup>, but creating an environment which encourages people to forget those differences ever existed.</p>

<p>One of Scott’s first examples is land ownership in pre-modern rural villages, each of which had its own peculiar practices built over generations, describing the obligations between neighbors, the obligations between relatives, and the use of common pastures and forests.  These practices were perfectly legible within a given village, but a cacophonous mess to state officials trying to understand all of them at once.</p>

<p>And so the states sent in surveyors, who drew sharp boundaries on their maps.  A year later came the tax collectors, maps in hand.  If a family paid taxes on what was once common property, they had little motivation to let their neighbors continue to use it.  Instead, the villagers reshaped their lives to fit the maps.</p>

<p>In <a href="https://en.wikipedia.org/wiki/The_Image_of_the_City"><em>The Image of the City</em></a>, Kevin Lynch defines “legibility” as something that a complex environment offers to its inhabitants, allowing them to easily navigate it.  It is a clarifying abstraction, making the world more than an endless deluge of minute details.</p>

<p>Lynch interviewed long-time residents of various cities, and asked them to describe how they’d navigate from one part of the city to another.  He created reference maps of shared elements from these journeys, representing how each city was understood by its people.</p>

<p>Some cities, such as Boston, were highly legible; its map was full of reference points, and its residents were confident in each step of their imagined journey.  Other cities were less so:</p>

<blockquote>
  <p>[A]lmost anyone can, if attentive, learn to navigate in Jersey City, but only at the cost of some effort and uncertainty.  Moreover, the positive values of legible surroundings are missing: the emotional satisfaction, the framework for communication or conceptual organization, the new depths that it may bring to everyday experience.</p>
</blockquote>

<p>The moral hazard described in <em>Seeing Like a State</em> exists in any field of design.  In software, for instance, anywhere one implementation cannot be easily exchanged for another, users are forced to bend themselves to the needs of their software.  This is trivially true of enterprise software, since the users are not the buyers, but given the increasingly <a href="https://en.wikipedia.org/wiki/Zero_to_One">monopolistic bent</a> of all software companies, it can be also true in the consumer space.</p>

<p>This is worrisome, not least because of the tech industry’s continuous attempts to resurrect <a href="https://en.wikipedia.org/wiki/Logical_positivism">logical positivism</a>.  Someone who claims their design was conceived from first principles has almost always injected their own biases and incuriosity into those principles.  As coercive abstractions, these designs will preserve whatever is familiar to a small, homogeneous group, and allow everything else to wither away.</p>

<p>Scott offers prescriptions for avoiding the problems he describes, but they’re mostly process-oriented (“take small steps”, “favor reversibility”) and entirely focused on harm reduction.  For Scott, abstraction is always something done to people, never for people.</p>

<p>But this is just one side of the coin; to apply the insights in either book we must understand both kinds of legibility, and what separates them.  To get there, though, we must first explore two works of fiction.</p>

<hr>

<p>The Gnostics were a collection of early Christian sects which fused the gospels with Platonic dualism.<sup id="fnref:gnostics"><a href="#fn:gnostics">2</a></sup>  A true Creator was responsible for the world of ideal forms, while a lesser being, a <strong>demiurge</strong>, was responsible for the pale shadow of our physical world.  For the Gnostics, the work of the demiurge was a veil over our eyes, created out of malice or ineptitude, and their goal was to pierce that veil, to achieve <strong>gnosis</strong>.</p>

<p>Philip K. Dick had a lifelong fascination with the Gnostics, and their ideas appear constantly throughout his novels.  Nowhere is this more evident than in <a href="https://en.wikipedia.org/wiki/The_Three_Stigmata_of_Palmer_Eldritch"><em>The Three Stigmata of Palmer Eldritch</em></a>.</p>

<p>In the novel, the Earth has become uninhabitably hot, forcing everyone to take shelter in buildings or subterranean structures during the day.  People are being forcibly migrated to even more hardscrabble lives on nearby planets, which can only be escaped via Perky Pat layouts, effectively Barbie Dream Houses they can temporarily inhabit using Can-D, a drug illicitly distributed by the creators of Perky Pat.</p>

<p>Using the drug, users are transported to a single, perfect day in San Francisco, before the Earth became too hot, in the bodies of a wealthy, beautiful couple.  They can accessorize their escapism by purchasing “minned” items, which will appear full-size and functional within Perky Pat’s world.</p>

<p>This is a false gnosis, layering something simple and idealized atop the messiness of the physical world, rather than peeling it back.  False gnosis is a central theme in all of Dick’s writing, which makes him perhaps the only science-fiction author who truly anticipated our present day.  Like everyone else, he failed to predict the smartphone, but he alone seemed to understand how completely technology could intermediate our understanding of the world.<sup id="fnref:cyberspace"><a href="#fn:cyberspace">3</a></sup></p>

<p><em>Three Stigmata</em> begins with the return of Palmer Eldritch, an industrialist who had travelled to Proxima Centauri in search of new business opportunities.  He has brought with him a new drug, Chew-Z, which promises the same escape as Can-D without the need to buy any accessories.</p>

<p>Anyone taking Chew-Z can create their own world to inhabit, but every person in that world takes on aspects of Eldritch himself, sharing his prosthetic hand, eyes, and mouth.  Even as the drug seems to subside, Eldritch remains, making it impossible to know what’s real.</p>

<p>In time, it’s revealed that the returned Eldritch is not the businessman, but rather a dying demiurge who has assumed his form.  He toys with anyone who takes Chew-Z, creating escapist fantasies that prove to be every bit as flawed as their real lives.  By the end, Eldritch has begun to merge with humanity, even infecting people who never touched the drug.</p>

<p>Eldritch doesn’t offer gnosis, but neither does he offer pure escapism like Perky Pat.  He gives humanity an understanding of <em>himself</em>, of the nature of the veil over our eyes.  Even if it tells us nothing of what lays beyond, Dick seems to suggest it’s the most we can hope for.<sup id="fnref:exegesis"><a href="#fn:exegesis">4</a></sup></p>

<p>A different sort of demiurge is portrayed in Italo Calvino’s <a href="https://en.wikipedia.org/wiki/Invisible_Cities"><em>Invisible Cities</em></a>, in which Marco Polo tells Kublai Khan of all the cities he’s seen in his travels.  They sit in the Khan’s palace, at the center of an empire which has exceeded his grasp:</p>

<blockquote>
  <p>It is the desperate moment when we discover that this empire, which had seemed to us the sum of all wonders, is an endless, formless ruin, that corruption’s gangrene has spread too far to be healed by our scepter, that the triumph over enemy sovereigns has made us the heirs of their long undoing.  Only in Marco Polo’s accounts was Kublai Khan able to discern, through the walls and towers destined to crumble, the tracery of a pattern so subtle it could escape the termites’ gnawing.</p>
</blockquote>

<p>His descriptions of the cities, however, are narrow.  In one, he only describes a memory it evokes.  In another, he only describes the relationship between the city and its reflection in the surrounding water.  Sometimes the cities themselves are narrow; one such city has been reduced to freestanding pipes, with attached bathtubs and fountains, populated by nymphs and naiads.</p>

<p>These are pieces of cities, mixed and distilled from everything Polo has seen in his travels.  But at their core, they are facets of a city he never describes, the city he knows best, his birthplace:</p>

<blockquote>
  <p>And Polo said: “Every time I describe a city I am saying something about Venice.”</p>
</blockquote>

<blockquote>
  <p>“When I ask you about other cities, I want to hear about them.  And about Venice, when I ask you about Venice.”</p>
</blockquote>

<blockquote>
  <p>“To distinguish the other cities’ qualities, I must speak of a first city that remains implicit.  For me it is Venice.”</p>
</blockquote>

<p>Marco Polo is a worldly man, but he is not of the world; he is Venetian, and everything is understood and remembered through that lens.  What he has discovered, in the course of his travels, is that certain pieces of Venice are timeless.  These are what will survive the collapse of the Khan’s empire, what will constantly reoccur throughout time; always different in detail, but unmistakably the same.</p>

<p>And yet Polo, just like Eldritch, does not offer true gnosis.  Each city hides all but a tiny piece of Venice through omission and fantastic obfuscations like the nymphs and naiads.  Unlike Eldritch, however, he offers choice.  The set of cities he describes is neither minimal nor exhaustive; each can be considered or ignored in isolation.</p>

<p>These cities may obscure their underlying reality, but they don’t attempt to replace it.  Instead, they simply reveal a resonance, a commonality of experience we might otherwise have missed.</p>

<hr>

<p>The legibility described in <em>Seeing Like a State</em>, and imposed by Palmer Eldritch, is <strong>singular</strong>; It overrides our own experience, forcing us to live within the mind of its creator.  The legibility described in <em>Image of the City</em>, and offered by Marco Polo, is <strong>faceted</strong>; it complements our own experience, allowing us to apply it where we see fit.</p>

<p>Creating singular legibility is simple: find something that’s easy for you to understand, and force people to use it.  What’s hard is using it responsibly; to predict its full effect, you’d need to first have an exhaustive understanding of the environments in which it will be used.</p>

<p>Faceted legibility is more forgiving, allowing us to understand the world incrementally and collaboratively.  It’s not, however, something we can simply create on our own.  Instead, we can only lay the groundwork and hope it flourishes.</p>

<p>How do we lay the proper groundwork?  It depends on what you’re …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/two-concepts-of-legibility.html">https://ideolalia.com/essays/two-concepts-of-legibility.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/two-concepts-of-legibility.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25619052</guid>
            <pubDate>Sun, 03 Jan 2021 03:18:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Comfortably in Thick Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25618959">thread link</a>) | @AceyMan
<br/>
January 2, 2021 | https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html | <a href="https://web.archive.org/web/*/https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<p>Writing in a thick notebook can be troublesome when you get close to the end of a page. If you're like most people you will encounter a zone where the palm, fingernails or wrist (which I will refer to collectively as "palm") of your writing hand have nowhere to rest, and you may find yourself trying to "float" your hand over the page. As a result, control of the pen-tip becomes enough of an effort to hamper the free-flow of thoughts from the brain through the nervous system to their final conversion to written word.</p>

<p>At best, you get your point across, but usually not without some effort, frustration, and sloppy penmanship.</p>

<p>I suppose one could simply turn to a fresh page before this becomes an issue. That would probably be ok with cheap notebooks, but if you are reading this, yours is probably not cheap, and you intend to wring out all of its value by using every bit of its space.</p>

<p>Thus, as your palm starts to drift off the bottom edge of the page, it needs somewhere to rest...two possible solutions come to mind...one is free, the other cheap:</p>

<p>1. The Smart Phone Trick (free)</p>
<p>2. The Writing Mat (cheap)</p>


<p><strong>The Smart Phone Trick</strong></p>

<p>Placing your smartphone at the bottom of the book at the right point serves as a rest for your palm. It feels like instant relief, at least compared to the alternative of doing nothing at all. It's as if your hand lost its balance at the edge of the page, and the phone is there to catch it.</p>

<p>A smart phone is also a very good thickness (about 10mm) for this purpose. At some point it will be lower than the page you are writing in, and at other points higher, but the differential will never be very great because you won't always need it.</p>

<p>A thin paperback also works well for this purpose, but it can't be too wide or long because it will use up a lot of desk space and may even dig into your forearm. And you'll have to always remember to have it on hand. So, a smartphone is nearly the perfect size....and it is very handy for many of us most of the time. It may take some trial-and-error to figure out exactly when and where you need to deploy the device, but once you do, you will once again find your thoughts freely flowing to any point on the page.</p>

<p>And, as a pen-and-paper person, you may gain some satisfaction from knowing that technology doesn't always exist just for its own sake.</p>


<p><strong>The Writing Mat</strong></p>

<p>Writing mats (sold on this site) are great for enhancing the pen-to-paper connection, and if while writing you press hard with fine points it will protect the lower pages from impressions.</p>

<p>They are also great as a lower extension of the page you are writing on. For that purpose the thin plastic mats seem to work better than the soft mats because they are stiffer and give more support to the palm. But the soft ones work fine too. As you get to that troublesome point on the page, you just keep moving the mat down as long as you need to, and it provides a gentle slope on which your palm can rest.</p>

<p>The mat should be at least the same size as the paper. It can be larger, but larger doesn't have any real advantage other than being able to work with more notebook sizes. They are also harder to carry around. But even if you have the perfect size mat, you have to remember to have it with you, so you may prefer the smart phone trick anyway.</p>


<p><strong>Conclusion</strong></p>

<p>There are many folks that don't write in notebooks because of this very issue, but given these simple solutions it doesn't have to be hard at all. There is also a certain feeling of satisfaction, security and abundance when writing in a thick notebook, and anyone can deploy these or similar tactics in order to get the full experience.</p>


<p><img title="img-1731.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1731.jpg?t=1398725710" alt="img-1731.jpg" width="600" height="600"></p>

<p><img title="img-1732.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1732.jpg?t=1398725710" alt="img-1732.jpg" width="600" height="600"></p>



<p><img title="img-1734.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1734.jpg?t=1398725710" alt="img-1734.jpg" width="600" height="600"></p>


<p><img title="img-1762.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1762.jpg?t=1398725710" alt="img-1762.jpg" width="600" height="600"></p>

<p><img title="img-1763.jpg" src="https://cdn2.bigcommerce.com/server1300/e595f90m/product_images/uploaded_images/img-1763.jpg?t=1398725710" alt="img-1763.jpg" width="600" height="600"></p>
	
	</div></div>]]>
            </description>
            <link>https://www.nanamipaper.com/pages/writing-comfortably-in-thick-notebooks-tomoe-river.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618959</guid>
            <pubDate>Sun, 03 Jan 2021 03:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[After APIs, Webhooks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25618908">thread link</a>) | @vitoc
<br/>
January 2, 2021 | https://docs.prudent.me/blog/2020/12/6/webhooks | <a href="https://web.archive.org/web/*/https://docs.prudent.me/blog/2020/12/6/webhooks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We hear a lot about APIs as financial institutions open up their services for public access, but webhooks can be just as useful for user experience in personal finance management.</p>
<p>APIs are more passive whereas webhooks are more pro-active.</p>
<p>This makes a difference from a programmatic point of view, which then affects user experience.</p>
<p>You can imagine this difference with e-mail for example.</p>
<p>Imagine a time before push notifications. Without push notification, the manifest practice is to "Check mail". Remember those quaint days when we used to push that Send/Receive button? That's API call for you.</p>
<p>While we can code applications in such a way as to check an API very often, it's not very bandwidth-compute-energy efficient.</p>
<p>Webhooks are much better. Like push notification, applications gets notified when a transaction happens and changes its state accordingly.</p>
<p>Along with the change of state, any other triggers or reactive components can then come alive, a much better pattern :)</p>
<p><a href="https://docs.prudent.me/blog/2020/12/6/ideal-experience">More on what webhooks can do for Prudent UX here...</a></p>
<p><a href="https://stripe.com/docs/webhooks">Stripe's excellent webhooks</a></p>
<p><a href="https://en.wikipedia.org/wiki/Push_technology">Wikipedia entry on Push technology in general (with examples of how it is implemented, including long polling, which I think is not ideal)</a></p>
</span></p></div></div></div>]]>
            </description>
            <link>https://docs.prudent.me/blog/2020/12/6/webhooks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618908</guid>
            <pubDate>Sun, 03 Jan 2021 02:53:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's Snowing in My CPU – A Snowflake Catalogue]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618902">thread link</a>) | @sytelus
<br/>
January 2, 2021 | http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">






<!-- elapsed slogan/addthis 0.001134 -->
<hr>


<!-- elapsed masthead 0.000449 -->






 <!-- header -->

<!-- elapsed header 0.00212 -->




<!-- elapsed masthead/badge/about 0.000546 -->


<p><span>
Scientific graphical abstracts — design guidelines
<a href="http://mkweb.bcgsc.ca/graphical.abstract.design"><img src="http://mkweb.bcgsc.ca/gfx/arrow-right-news.png"></a>
</span>














</p>
<hr>
<!-- elapsed news 0.001733 -->



<hr>
<!-- elapsed on the side 0.002217 -->





<div id="projects">




<div>










<p>
Art is science in love.
<br>
<span>— E.F. Weisslitz</span>
</p>






<p>Somewhere in the world, it's snowing. But you don't need to go far—it's always snowing on this page. Explore <a href="http://mkweb.bcgsc.ca/snowflakes/random.mhtml">light flurries</a>, <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml">snowflake families</a> and <a href="http://mkweb.bcgsc.ca/snowflakes/flake.mhtml?flake=autqzcws">individual flakes</a>. There are many <a href="http://mkweb.bcgsc.ca/snowflakes/oddities.mhtml">unusual snowflakes</a> and snowflake <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml?family=12">family 12</a> and <a href="http://mkweb.bcgsc.ca/snowflakes/families.mhtml?family=46">family 46</a> are very interesting. 

</p><p>But don't settle for only pixel snowflakes—<a href="http://mkweb.bcgsc.ca/snowflakes/snowflake.3dprint.mhtml?name=morptel">make an STL file and 3D print your own flakes</a>!

</p><p>Ad blockers may interfere with some flake images—the names of flakes can trigger ad filters.













<a id="l0home"></a>
</p>








<h2>In silico flurries: computing a world of snowflakes</h2>

<p>High-resolution images from our Scientific American article <a href="https://blogs.scientificamerican.com/sa-visual/in-silico-flurries/">In Silico Flurries: computing a world of snowflakes</a>.





</p><div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/1.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/1.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 1.</b> An example of a snowflake grown using the Gravner-Griffeath model. Various amounts of ice (encoded by the blue tone) at different parts of the snowflake make up the six-fold radially symmetric shape.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/1.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/2.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/2.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 2.</b> The Gravner-Griffeath model is a type of reaction-diffusion system, with three kinds of “morphogens”: ice, quasi-liquid and vapor. The model is deterministic—given a set of parameters the output is always the same. Optionally the model can include randomness by perturbing the amount of vapor mass in every site at each step.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/2.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/3.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/3.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 3.</b> The evolution of the snowflake from Figure 1 to full size at 15,353 growth steps.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/3.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/4.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/4.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 4.</b> The effect of varying each of the model parameters on the shape of the snowflake in Figure 1, whose parameter value is shown as a red dot. The images sample the parameter values shown by small black ticks. The distribution of snowflakes in our collection by parameter value is shown as a gray histogram. The median is the long black line among the bins.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/4.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/5.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/5.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 5.</b> Our collection of snowflakes clustered based on structural similarity. Clusters are projected onto two dimensions using t-SNE. The snowflakes are themselves arranged on a hex grid to allow tighter packing.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/5.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/6.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/6.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 6.</b> A collection of paths in the two-dimensional t-SNE space of the snowflakes, affectionately named “The Flube.”


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/6.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/7.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/7.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 7.</b> A sample of the snowflakes found at the t-SNE hex grid of each station in The Flube, showing the variation in shape within and between clusters.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/7.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/8.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/8.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 8.</b> The relationship between parameter values and t-SNE clustering. Each snowflake is drawn as a circle colored by the relative difference of the snowflake’s parameter with the median value. The lines of The Flube are superimposed to help interpret the variation in shape in Figure 7.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/8.png">zoom</a>)
</p>
</div></div>








<div><div>

<p><a href="http://mkweb.bcgsc.ca/snowflakes/figs/9.png">


<img src="http://mkweb.bcgsc.ca/snowflakes/figs/9.png" alt="Martin Krzywinski @MKrzywinski mkweb.bcgsc.ca" width="850px">

</a></p><p><span>▲</span> <b>Figure 9.</b> A hand-drawn interpretation of the t-SNE map in Figure 5. Geographical features encode parameter values: woods (low ρ), grassland (low β), marsh (low μ) and desert (high θ). The speed at which the snowflake grew (steps to reach full size, n) is encoded by mountains (high n) and ice cliffs (low n). All names are generated using an RNN trained on 257 names of countries. The Flube network is drawn as thin lines with stations as loops with cities (medium size text) placed at the location of station positions in Figure 6.


(<a href="http://mkweb.bcgsc.ca/snowflakes/figs/9.png">zoom</a>)
</p>
</div></div>



















</div>
</div>


<!-- elapsed page content 1.334684 -->



<!-- elapsed thoughts 0.002699 -->



<hr>


<!-- elapsed value 0.000167 -->


<!-- elapsed keywords 0.000175 -->

 <!-- footer -->
<!-- elapsed footer 0.000477 -->

</div></div>]]>
            </description>
            <link>http://mkweb.bcgsc.ca/snowflakes/sciam.mhtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618902</guid>
            <pubDate>Sun, 03 Jan 2021 02:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Indifference Engine: An Ecological Characterization of Bitcoin [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618883">thread link</a>) | @sp332
<br/>
January 2, 2021 | https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Wassim+Alsindi">Wassim Alsindi</a>

</p>


<!-- %h3 About -->
<p>"As Bitcoin surpasses previous price records and re-enters mainstream consciousness following several wilderness years, the twelve-year-old cryptocurrency appears to have “arrived” in the eyes of the market. The value proposition of an ungoverned, uncensorable digital means of value transfer is clear for all to see…but can humanity and Earth afford the thermodynamic price tag? </p>

<p>To maintain the integrity of the transaction record, the Bitcoin network creates a hard boundary to the outside through exacting validation requirements. However it does not possess any feedback mechanism or capacity to respond to the consequences of the thermoeconomic challenges it issues. This insensitivity of ‘mined’ cryptocurrencies to the energy sources used to secure them has led to criticism as to their inability to mitigate their ecological externalities."</p>

<h3>Download</h3>
<div>
<p>

Downloads will appear here, once final recordings are released.
</p></div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-685465-the_indifference_engine_an_ecological_characterisation_of_bitcoin</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618883</guid>
            <pubDate>Sun, 03 Jan 2021 02:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Survey Chicken]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618712">thread link</a>) | @exolymph
<br/>
January 2, 2021 | https://carcinisation.com/2020/12/11/survey-chicken/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/12/11/survey-chicken/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-738">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>



<p>As a banana who lives among humans, I am naturally interested in humans, and in the social sciences they use to study themselves. This essay is my current response to the Thiel question: “What important truth do very few people agree with you on?” And my answer is that surveys are bullshit.</p>



<p>In the abstract, I think a lot of people would agree with me that surveys are bullshit. What I don’t think is widely known is how much “knowledge” is based on survey evidence, and what poor evidence it makes in the contexts in which it is used. The nutrition study that claims that eating hot chili peppers makes you live longer is based on surveys. The twin study about the heritability of joining a gang or carrying a gun is based on surveys of young people. The economics study claiming that long commutes reduce happiness is based on surveys, as are all studies of happiness, like the one that claims that people without a college degree are much less happy than they were in the 1970s. The study that claims that pornography is a substitute for marriage is based on surveys. That criminology statistic about domestic violence or sexual assault or drug use or the association of crime with personality factors is almost certainly based on surveys. (Violent crime studies and statistics are particularly likely to be based on extremely cursed instruments, especially the Conflict Tactics Scale, the Sexual Experiences Survey, and their descendants.) Medical studies of pain and fatigue rely on surveys. Almost every study of a psychiatric condition is based on surveys, even if an expert interviewer is taking the survey on the subject’s behalf (e.g. the Hamilton Depression Rating Scale). Many studies that purport to be about suicide are actually based on surveys of suicidal thoughts or behaviors. In the field of political science, election polls and elections themselves are surveys.&nbsp;</p>



<p>What I mean by “surveys” is standard written (or spoken) instruments, composed mostly of language, that are administered to subjects, who give responses, and whose responses are treated as quantitative information, which may then be subjected to statistical analysis. It is not the case that knowledge can never be obtained in this manner. But the idea that there exists some survey, and some survey conditions, that might plausibly produce the knowledge claimed, tends to lead to a mental process of filling in the blanks, of giving the benefit of the doubt to surveys in the ordinary case. But, I think, the ordinary survey, in its ordinary conditions, is of no evidentiary value for any important claim. Just because there exist rare conditions where survey responses tightly map to some condition measurable in other ways does not mean that the vast majority of surveys have any value.&nbsp;</p>



<p>Survey evidence seems to be a new phenomenon. Robert Groves (2011) argues that it is a 20th century phenomenon, arising in the 1930s, achieving a golden age from the 1960s to the 1990s, and then falling off in prestige and reliability after that.&nbsp;</p>



<p>Why is it important that surveys are new? I think it is important to remember that there is no ancestral practice equivalent to surveys. That is to say, there is no ancient human practice or context in which people anonymously tell the pure, innocent truth with language, in response to questioning, with no thought for the motives of the questioner or the effect of their answers. However, in the new, wholly invented ethnomethod of [doing a survey], it is imagined that subjects do tell the innocent truth, comprehending the underlying sense of the question but not answering with any motive or particularity of context. The anonymity of survey takers is given as proof that they feel free to tell the truth, rather than being perceived as a bar to asking them what they might have meant by their responses.</p>



<p>To get at the philosophical weirdness of the survey, it is necessary to dissect the phenomenon of survey-taking in detail. First I will consider the legal perspective, since that is an ancient domain of getting at truth through language in particular contexts.&nbsp;</p>



<p><strong>Surveys and Legal Evidence</strong></p>



<p>The vast majority of evidence in the legal context is and has always been testimonial. That is, a witness testifies in language to communicate some fact to the judge or jury, and the judge or jury then decides how much to believe it. This is true even for modern DNA evidence: the expert witness testifies about the alleged meaning of the laboratory findings, even if documents (also testimony of the writer or preparer) are also given to the trier of fact to examine. Good evidence and garbage evidence are both usually testimony.&nbsp;</p>



<p>In the English common law tradition, the biggest rule about testimonial evidence is hearsay. To put it colloquially, the hearsay rule says that testimony has to come from the horse’s mouth. If you saw someone run a red light and crash into a fire truck, you could undergo the ritual of being put under oath (agreeing that negative legal consequences could befall you for untrue speech), and testify about what you saw in court. Then you would be subject to the further ritual of cross-examination, in which all the aspects of your testimony could be questioned: your vision, whether you had your glasses on, where you were positioned, what specifically you mean by “crashed,” your relationship with the driver, and perhaps even whether you had a past conviction for forgery, which might make you seem like a liar in general. Those responsible for deciding whether to believe your testimony would have the chance to look at your face and mannerisms while testifying, to look at your clothes and hair and grooming, to see whether your eyes are bloodshot, in order to judge your responses to questioning. This may seem superficial and unfortunate, but in conversation we make these judgments all the time. And a witness may lose credibility for appearing too slick as often as for appearing too tattered, as in ordinary life.</p>



<p>However, if you wanted to testify about what you heard <em>someone else</em> say, someone who isn’t present for ritual oath-taking and questioning, that would be hearsay, admissible only under a list of exceptions. The exceptions to the hearsay rule are generally contexts in which language evidence is considered particularly likely to be accurate and truthful, such as a record kept in the ordinary course of business, or an emotional shout just after the crash (the idea being that you wouldn’t have time to think up a lie).&nbsp;</p>



<p>Survey evidence, then, is plainly hearsay, since when we hear claims based on survey evidence, we get no opportunity to judge the credibility of the statements as we might in conversation (much less under oath). However, survey evidence is often admissible in legal proceedings, particularly under the much-abused “state of mind” exception. But I think the more common reasoning underlying admission of survey evidence is as stated by a legal scholar at the beginning of the golden age of surveys (Zeisel 1959): “[S]ince surveys provide the best, <strong>if not the only</strong>, evidence on certain issues, and since expert knowledge in the field has advanced sufficiently to protect the trier of the facts from error, the law may well lower its heavy guard” (bolded emphasis mine). In other words, survey evidence is admissible because there’s no other way to get at the underlying facts. Consider trademark confusion: how would one measure whether consumers confuse one mark with another except by asking them in some clever way? The phenomenon of confusion is hidden in the minds of consumers, and can’t be measured with calipers or rulers.&nbsp;</p>



<p>Even when surveys are the only way to get at some particular knowledge, they may be done well or poorly. Zeisel (1959), citing <em>Coca-Cola v. Nehi Corp.</em>, 27 Del. Ch. 318, 326, 36 A.2d 156 (1944), says:</p>



<blockquote><p>Other aspects of an interview can also become grounds for criticism. Word association tests given to students in a classroom were rejected because their reactions were “bound to differ from that of the buyer in the market place when confronted with the.., beverage …. ” As another court remarked, “the issue is not whether the goods would be confused by a casual observer, but [rather] .. .by a prospective purchaser at the time he considered making the purchase. If the interviewee is not in a buying mood but is just in a friendly mood answering a pollster, his degree of attention is quite different.”</p></blockquote>



<p>That is to say, even though a survey might be the only way to judge the phenomenon of confusion, a college classroom was judged to be sufficiently different from shopping in a store (e.g.) to render the survey meaningless. I find this standard touchingly exacting compared to the present lax standard for taking survey evidence seriously. The present standard seems to be that the more math you do to survey data, the more reliable it is.</p>



<p>The meaning of my title is from a joke told at the end of <em>Annie Hall</em>:</p>



<blockquote><p>I thought of that old joke—you know, this guy goes to a psychiatrist and say doc, my brother’s crazy! He thinks he’s a chicken. And the doc says, why don’t you turn him in? Then the guy says, I would, but I need the eggs. I guess that’s pretty much now how I feel about relationships. They’re totally crazy, irrational, and absurd, but I guess we keep going through it because most of us need the eggs.</p></blockquote>



<p>Surveys are perhaps the only way to get certain information, information about the most important and pressing phenomena, about happiness and suffering in all its forms. These are eggs that most of us need. So even though surveys are bullshit, they are not “turned in” like the unfortunate brother in Woody Allen’s joke, but embraced in a plausibility structure whose maintenance is widespread and in which we are all complicit.</p>



<p><strong>The Phenomenon of the Survey</strong></p>



<p>To understand what’s wrong with surveys, we must alternate between critically examining survey …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/12/11/survey-chicken/">https://carcinisation.com/2020/12/11/survey-chicken/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/12/11/survey-chicken/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618712</guid>
            <pubDate>Sun, 03 Jan 2021 02:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Technology in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618655">thread link</a>) | @telltruth
<br/>
January 2, 2021 | https://elidourado.com/blog/notes-on-technology-2020s/ | <a href="https://web.archive.org/web/*/https://elidourado.com/blog/notes-on-technology-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content"><p>As we start a new decade, it’s a good time to reflect on expectations for the next 10 years. Tyler thinks the Great Stagnation <a href="https://marginalrevolution.com/marginalrevolution/2020/12/why-did-the-great-stagnation-end.html">could be ending</a>. Caleb sees <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">cracks</a>. Noah expresses <a href="https://noahpinion.substack.com/p/techno-optimism-for-the-2020s">techno-optimism</a>. In this post, my aim is not to predict an end or non-end to stagnation. Rather, it is to think through the particulars of how technology could evolve over the next decade. Then we can assess separately whether we should consider it the Roaring 20s or the Boring 20s.</p><p>What would constitute an end to the Great Stagnation? Any precise cutoff will be arbitrary, but for the sake of discussion, let’s say sustained growth in <a href="https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/">utilization-adjusted total factor productivity</a> of 2 percent per year. By comparison, mean utilization-adjusted TFP growth from 1947 through 1972 was 2.1 percent. Since 2005, it has been 0.17 percent. (Note: it is important to use the utilization-adjusted series, as this corrects for the business cycle.)</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a7a8a1d9e4c4d1050c2902966a316436559074f1/cd6b6/img/tfp.png" alt="Total factor productivity in the U.S. since 1947" title="Total factor productivity in the U.S. since 1947"></p><p>Whatever your cutoff for TFP growth, one of my convictions is that scientific breakthroughs alone are not enough to drive an end to the Great Stagnation. TFP only budges when new technologies are adopted at scale, and generally this means products, not just science. Science lays critical groundwork for new technology, but after all the science is done, much work remains. Someone must shepherd the breakthrough to the product stage, where it can actually affect TFP. This means building businesses, surmounting regulatory obstacles, and scaling production.</p><p>With that caveat firmly in mind, what will the next decade bring in terms of meaningful technological change? Here’s what I’m watching.</p><h2 id="biotech-and-health">Biotech and health</h2><p>We are coming off a huge win: two new mRNA COVID vaccines, conceived and brought to market in less than a year. The ability to encode and deploy arbitrary mRNA in our bodies sure seems like a game changer—it allows us to essentially program our cells to make whatever proteins we want. In the case of the COVID vaccines, the vaccine payload instructs our cells to make the coronavirus spike protein, which our immune system then learns to attack. Bert Hubert has a <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">fascinating write-up</a> of the “code” in the vaccine.</p><p>Bringing a brand new vaccine to market in less than a year—using a never-before-applied-in-humans-at-scale technology no less—is a world record, but it could have been even faster. As David Wallace-Wells <a href="https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html">emphasizes</a>, Moderna’s vaccine was designed by January 13. We had it the whole time. Some delay was necessary to determine effective dosing. Some further regulatory delay may have been warranted to ensure the vaccine was safe and to ascertain its efficacy. But as Wallace-Wells indicates, the regulatory outcome was never really in doubt. “None of the scientists I spoke to for this story were at all surprised by either outcome,” he writes. “All said they expected the vaccines were safe and effective all along.”</p><p>What should we make of the fact that all of the scientists knew all along that Moderna’s vaccine would work? The question in my mind is: what other mRNA treatments do we have the whole time? What if I told you Moderna has an <a href="https://www.poz.com/article/experimental-hiv-vaccine-stimulates-production-neutralizing-antibodies">HIV vaccine candidate</a>? HIV lacks SARS-CoV-2’s telltale spike protein and thus may prove a more challenging foe—but don’t you wonder, if we treated the problem with real urgency, whether new mRNA technology could wipe out the AIDS epidemic this decade? I do.</p><p>And mRNA technology can be deployed against more than just viruses. Both Moderna and BioNTech have personalized vaccine candidates targeting cancer. Although called a “cancer vaccine,” the treatment is only administered once the subject has cancer—it isn’t preventative. The companies use an algorithm to analyze the genetic sequences of the tumor and the patient’s healthy cells and predict which molecules could be used to generate a strong immune response against the cancer. “I was actually witnessing the cancer cells shrinking before my eyes,” <a href="https://www.nature.com/articles/d41586-019-03072-8">said</a> Brad Kremer, a melanoma patient who received the BioNTech treatment. So let’s milk mRNA technology for all it’s worth this decade. It can save us from more than just a pandemic.</p><p>What about CRISPR? It is a great example of a technology that has not yet made a meaningful economic contribution. Although the technique for editing DNA was discovered in 2012—and a Nobel Prize was awarded to its two discoverers this year—no treatment using CRISPR has been approved outside of clinical trials. So far, its impact has been limited to making researchers more productive—not a bad thing, to be sure, but not close to CRISPR’s full potential. As trials progress, however, I do think some CRISPR treatments will come online in the next few years, especially those targeting genetic disorders that we have very limited means of otherwise treating.</p><p>DeepMind’s <a href="https://medium.com/cgo-benchmark/deepminds-protein-folding-solution-what-just-happened-279d32e8d0f">protein-folding breakthrough</a> signals a promising decade for the science of proteomics. Most directly, being able to predict protein shapes will enable us to discover drugs more rapidly. Buuuut, because drug trials take many years, we might expect this technology not to really be felt by the general public until the 2030s.</p><p>What DeepMind’s achievement indicates to me the most is that machine learning is actually useful. This might seem obvious, but consider: most applications of machine learning so far—excluding autonomous vehicles, which have themselves not really arrived yet—are toys. I love watching AlphaZero crush Stockfish on YouTube, but chess is literally a game. GPT-3 produced some fun demos. AlphaFold heralds something different—non-toy superhuman performance is now here, and I am interested to see what else it can do. Aside from the aforementioned AVs, I expect it to be applied widely in other areas of biology. Again, it will take a long time for the breakthroughs to trickle down into products, but at least the 2030s should be sick. I mean, not sick. Healthy.</p><p>Let’s talk about life extension, one of my favorite biotech topics. 2020 was a big year for the Conboy Lab at Berkeley, which proved that all the weird past findings about “<a href="https://en.wikipedia.org/wiki/Parabiosis">young blood</a>” extending life were not actually due to any elixir in the blood of children (thank goodness). Rather, the rejuvenating aspects of young blood experiments were due to the dilution of harmful factors in old blood. By mechanically removing plasma and replacing it with saline and enough albumin to replace what was taken out, they diluted aged blood factors in both mice and humans and were able to <a href="https://www.aging-us.com/article/103418/text#fulltext">rejuvenate germ layer tissues</a> and <a href="https://link.springer.com/article/10.1007/s11357-020-00297-8">improve cognition by reducing neuroinflammation</a>.</p><p>These findings are exciting not only because they represent a scientific advance in understanding aging, but also because they herald the first real anti-aging product that could come to market. Therapeutic plasma exchange is FDA-approved (not for aging, but for a bunch of other conditions). I imagine there remain prohibitions on advertising that it can add years to your life, but it is safe, and a doctor can prescribe it off label. It’s also cheap. An automated plasmapheresis machine—which lets you do treatment after treatment—can be bought online for under $3,000. That is less than the cost of a single transfusion of young blood sold by the startup <a href="https://www.ambrosiaplasma.com/">Ambrosia</a>. How long until someone opens a clinic offering plasma dilution? I bet someone tries it in 2021. If it works, people will get over the weirdness, and it could be commonplace by 2030.</p><p>Another longevity product that is about to get hot: aging clocks based on DNA methylation or proteomics. Do you want to know how biologically old you are? Today, for a few hundred dollars, you can get a test that will tell you. As these tests become better and cheaper, self-experimenters are going to have a field day. Doing before-and-after aging tests, anyone who can get their hands on human growth hormone could replicate the protocol used by <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/acel.13028">Fahy et al.</a> to rejuvenate the thymus. As the thymus is a critical element of the immune system, decline of which is a critical factor in aging, this is non-trivial rejuvenation. The Fahy study found that 12 months of treatment created about 2.5 years of epigenetic rejuvenation, with results accelerating in the last quarter of the trial.</p><p>There is a lot more in the <a href="https://www.lifespan.io/road-maps/the-rejuvenation-roadmap/">Rejuvenation Roadmap</a>—dozens of possible life-extending treatments are at various stages of development. There’s a good chance a few senolytic drugs will be approved by the end of the decade. As I noted <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">yesterday at Fortune</a>, we spend less than 1% of the NIH budget on aging biology—we should raise that by a lot.</p><p>Unlike others, I am not-so-bullish on metformin. It does seem to reduce all-cause mortality in Americans, but it may do so because <a href="https://www.liebertpub.com/doi/10.1089/met.2018.0105">88% of Americans are metabolically unhealthy</a>. If you are one of the 12%, and you should strive to be, I don’t think metformin will do much for you.</p><p>One final biotech observation: every year, the Apple Watch gets a new health-related sensor. This year it was blood oxygen, pretty good for detecting if you might have COVID! Fast forward to 2030 and wearables will have at least 10 more health-related sensors than they do today. Some no-brainers are body temperature, blood pressure, and blood glucose sensors. What will the other 7 be? At some point, it becomes possible to replace a lot of primary care with continuous monitoring. A few smart algorithms to provide simple medical advice could improve population-level health without much cost. More data could also yield faster, more accurate, and of course more remote diagnoses when you do have to see a doctor.</p><p>There is a lot in biotech that is promising right now, but in more than any other field, it is important not to be seduced by the sexy headlines showing rapid scientific progress. Don’t get complacent. Biology is proceeding faster than medical productivity because a lot of the wonderful discoveries are not being translated into approved treatments and products at a decent rate. Let’s salute and cheer for the discoveries, but spare many thoughts for the entrepreneurs trying to bring treatments to market.</p><h2 id="energy">Energy</h2><p>The 2010s were the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elidourado.com/blog/notes-on-technology-2020s/">https://elidourado.com/blog/notes-on-technology-2020s/</a></em></p>]]>
            </description>
            <link>https://elidourado.com/blog/notes-on-technology-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618655</guid>
            <pubDate>Sun, 03 Jan 2021 02:02:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tritris]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25618535">thread link</a>) | @beefman
<br/>
January 2, 2021 | https://goel25.github.io/tritris/ | <a href="https://web.archive.org/web/*/https://goel25.github.io/tritris/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="title">
            
            <div><p>
                Welcome to Tritris!
                <br>
                Use the pieces to fill as many lines as possible before the game
                gets too fast and you top out!
                </p><p>
                
                Click the <b>"How to Play"</b> button for controls and
                strategies. </p><p>
                
                <a href="https://youtu.be/HMkfj1OJ08Q">
                    <b>Watch the video!</b>
                    <img width="30" src="https://goel25.github.io/tritris/assets/youtubeLogo.png">
                </a></p><p>
                
                <label>Sound</label>
                </p></div>
        </div><div id="tutorial">
            
            <hr>
            <h3>Controls</h3>
            <p>
                Use the arrow keys to move left and right. Press down to soft
                drop. Use Z and X to rotate. Press enter to pause/unpause. Press
                escape to quick reset.
            </p>
            <hr>
            <h3>Pieces</h3>
            <p>
                There are 7 pieces total. There are 6 pieces made out of every
                possible configuration of 3 triangles, and 1 piece made out of a
                single triangle, which will always spawn in groups of 3.
                <img src="https://goel25.github.io/tritris/assets/allPieces.png">
            </p>
            <hr>
            <h3>Mechanics</h3>
            <p>
                The mechanics are very similar to NES Tetris. It uses the same
                DAS, entry delay, and level speed timings.<br>
                All of the pieces are made out of 3 connected right triangles.
                There is also a white, single triangle piece which can be used
                to fix holes in your stack. It will always come out 3 at a time.
                The single triangle is also special, lines will only be cleared
                once they have all been placed. This allows you to fill 3 lines
                to score a Tritris!
            </p>
            <hr>
            <h3>Phasing</h3>
            <p>
                <b>IMPORTANT - Since the release of the Youtube video, phasing
                    has become easier. There are no longer any frame-perfect
                    tricks. Instead, all phases can be performed by holding each
                    key (rotate can now be held to become "charged").</b>
                <br>
                One of the most unique mechanics of Tritris is phasing. A piece
                will always move to the next location as long as the next
                location is valid (no intersecting triangles). By moving a piece
                in multiple ways at the same time, pieces are able to do many
                types of tucks and spins. Below are a few examples.
            </p>
            <div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/down.gif"></p><p>
                        The pieces are able to easily move down into an empty
                        space.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/downRotate.gif"></p><p>
                        For the bottom right triangle, X (rotate) is held once
                        above the desired position.
                        <b>Due to the phasing update, down does not need to be pressed.</b>
                        Once all 3 triangles are placed, the line clears.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/downMove.gif"></p><p>
                        Left or right are held when the piece is above the
                        desired position, and when the piece moves down, it also
                        moves horizontally.
                    </p>
                </div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/multiple.gif"></p><p>Here are a few examples of some phases!</p>
                </div>
            </div>
            <br>
            <hr>

            <h3>Scoring</h3>
            <div>
                <div>
                    <p><img src="https://goel25.github.io/tritris/assets/tritris.gif"></p><p>A Tritris is scored!</p>
                </div>
                <p>
                    In Tritris, clearing 4 lines at a time is not possible, so
                    the highest score value is obtained from 3 lines at a time,
                    a Tritris. This can only be achieved by settings up 3 rows,
                    each missing only one triangle, then placing a single
                    triangle in each row. Once all triangles are placed, the
                    rows clear and a Tritris is scored!
                    <br>
                    A triple is equivalent to a Tetris in NES Tetris, a double
                    is equivalent to a triple, and a single is equivalent to a
                    double.
                </p>
            </div>

            <hr>
            <br>
            </div></div>]]>
            </description>
            <link>https://goel25.github.io/tritris/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618535</guid>
            <pubDate>Sun, 03 Jan 2021 01:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Repl-Driven Programming]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25618457">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://mikelevins.github.io/2020/12/18/repl-driven.html | <a href="https://web.archive.org/web/*/https://mikelevins.github.io/2020/12/18/repl-driven.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mikelevins.github.io/2020/12/18/repl-driven.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618457</guid>
            <pubDate>Sun, 03 Jan 2021 01:25:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Software Engineering with Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618391">thread link</a>) | @kawera
<br/>
January 2, 2021 | https://merely-useful.github.io/py-rse/index.html | <a href="https://web.archive.org/web/*/https://merely-useful.github.io/py-rse/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">

<div id="welcome">

<blockquote>
<p>It’s still magic even if you know how it’s done.</p>
<p>— Terry Pratchett</p>
</blockquote>
<p>Software is now as essential to research as telescopes, test tubes, and reference libraries.
This means that researchers <em>need</em> to know how to build, check, use, and share programs.
However,
most introductions to programming focus on developing commercial applications,
not on exploring problems whose answers aren’t yet known.
Our goal is to show you how to do that,
both on your own and as part of a team.</p>
<p>We believe every researcher should know
how to write short programs that clean and analyze data in a reproducible way
and how to use version control to keep track of what they have done.
But just as some astronomers spend their careers designing telescopes,
some researchers focus on building the software that makes research possible.
People who do this are called <a href="https://merely-useful.github.io/py-rse/glossary.html#rse">research software engineers</a>;
the aim of this book is to get you ready for this role by helping you go from
writing code for yourself to creating tools that help your entire field advance.</p>
<div id="intro-big-picture">
<h2> The Big Picture</h2>
<p>Our approach to research software engineering is based on three related concepts:</p>
<ul>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#open_science">Open science</a>: Making data, methods, and results
freely available to all by publishing them under <a href="https://merely-useful.github.io/py-rse/glossary.html#open_license">open
licenses</a>.</p></li>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#reproducible_research">Reproducible research</a>: Ensuring that anyone
with access to the data and software can feasibly reproduce results, both to
check them and to build on them.</p></li>
<li><p><a href="https://merely-useful.github.io/py-rse/glossary.html#sustainable_software">Sustainable software</a>: The ease with which to
maintain and extend it rather than to replace it. Sustainability isn’t
just a property of the software: it also depends on the skills and culture
of its users.</p></li>
</ul>
<p>People often conflate these three ideas,
but they are distinct.
For example,
if you share your data and the programs that analyze it,
but don’t document what steps to take in what order,
your work is open but not reproducible.
Conversely,
if you completely automate your analysis,
but your data is only available to people in your lab,
your work is reproducible but not open.
Finally,
if a software package is being maintained by a couple of post-docs
who are being paid a fraction of what they could earn in industry
and have no realistic hope of promotion because their field doesn’t value tool building,
then sooner or later it will become <a href="https://merely-useful.github.io/py-rse/glossary.html#abandonware">abandonware</a>,
at which point openness and reproducibility become less relevant.</p>
<p>Nobody argues that research should be irreproducible or unsustainable,
but “not against it” and actively supporting it are very different things.
Academia doesn’t yet know how to reward people for writing useful software,
so while you may be thanked,
the effort you put in may not translate into academic job security or decent pay.</p>
<p>Some people worry that if they make their data and code publicly available,
someone else will use it and publish a result they could have come up with themselves.
This is almost unheard of in practice,
but that doesn’t stop it being used as a scare tactic.
Other people are afraid of looking foolish or incompetent by sharing code that might contain bugs.
This isn’t just <a href="https://merely-useful.github.io/py-rse/glossary.html#impostor_syndrome">impostor syndrome</a>:
members of marginalized groups are frequently judged more harshly than others,
so being wrong in public is much riskier for them.</p>
<p>With this course, we hope to give researchers the tools and knowledge to be
better research software developers, to be more efficient in their work, make
less mistakes, and work more openly and reproducibly.
We hope that by having more researchers with these skills and knowledge,
research culture can improve to address the issues raised above.</p>
</div>
<div id="intro-personas">
<h2> Intended Audience</h2>
<p>This book is written for researchers who are already using Python for their data analysis,
but who want to take their coding and software development to the next level.
You don’t have to be highly proficient with Python,
but you should already be comfortable doing things like reading data from files
and writing loops, conditionals, and functions.
The following personas are examples of the types of people
that are our target audience.</p>
<dl>
<dt>Amira Khan</dt>
<dd>completed a master’s in library science five years ago
and has since worked for a small aid organization.
She did some statistics during her degree,
and has learned some R and Python by doing data science courses online,
but has no formal training in programming.
Amira would like to tidy up the scripts, data sets, and reports she has created
in order to share them with her colleagues.
These lessons will show her how to do this.
</dd>
<dt>Jun Hsu</dt>
<dd>completed an <a href="https://www.insightdatascience.com/">Insight Data Science</a> fellowship last year after doing a PhD in Geology
and now works for a company that does forensic audits.
He uses a variety of machine learning and visualization packages,
and would now like to turn some of his own work into an open source project.
This book will show him how such a project should be organized
and how to encourage people to contribute to it.
</dd>
<dt>Sami Virtanen</dt>
<dd>became a competent programmer during a bachelor’s degree in applied math
and was then hired by the university’s research computing center.
The kinds of applications they are being asked to support
have shifted from fluid dynamics to data analysis;
this guide will teach them how to build and run data pipelines
so that they can pass those skills on to their users.
</dd>
</dl>
</div>
<div id="intro-syllabus">
<h2> What You Will Learn</h2>
<p>Rather than simply providing reference material about good coding practices,
the book follows Amira and Sami as they work together to write an actual software package
to address a real research question.
The data analysis task that we focus on
relates to a fascinating result in the field of quantitative linguistics.
<a href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s Law</a> states that the second most common word in a body of text
appears half as often as the most common,
the third most common appears a third as often, and so on.
To test whether Zipf’s Law holds for a collection of classic novels
that are freely available from <a href="https://www.gutenberg.org/">Project Gutenberg</a>,
we write a software package that counts and analyzes the word frequency distribution
in any arbitrary body of text.</p>
<p>In the process of writing and publishing a Python package to verify Zipf’s Law,
we will show you how to:</p>
<ul>
<li>Organize small and medium-sized data science projects.</li>
<li>Use the Unix shell to efficiently manage your data and code.</li>
<li>Write Python programs that can be used on the command line.</li>
<li>Use Git and GitHub to track and share your work.</li>
<li>Work productively in a small team where everyone is welcome.</li>
<li>Use Make to automate complex workflows.</li>
<li>Enable users to configure your software without modifying it directly.</li>
<li>Test your software and know which parts have not yet been tested.</li>
<li>Find, handle, and fix errors in your code.</li>
<li>Publish your code and research in open and reproducible ways.</li>
<li>Create Python packages that can be installed in standard ways.</li>
</ul>
</div>
<div id="intro-using">
<h2> Using this Book</h2>
<p>This book was written to be used as the material for a (potentially) semester
long course at the university level,
although it can also be used for independent self-study.
Participatory live-coding is the anticipated style for teaching the material,
rather than lectures simply talking about the code presented <span>(Brown and Wilson <a href="https://merely-useful.github.io/py-rse/references.html#ref-Brow2018" role="doc-biblioref">2018</a>; Wilson <a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2018" role="doc-biblioref">2019</a><a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2018" role="doc-biblioref">a</a>)</span>.
The chapters and their content are generally designed to be used in the order
given.</p>
<p>Chapters are structured with the introduction at the start, content in the middle,
and exercises at the end. Callout boxes are interspersed throughout the content
to be used as a supplement to the main text,
but not a requirement for the course overall.
Early chapters have many small exercises;
later chapters have fewer but larger exercises.
In order to break up long periods of live-coding while teaching,
it may be preferable to stop and complete some of the exercises
at key points throughout the chapter,
rather than waiting until the end.
Possible exercise solutions are provided (Appendix&nbsp;<a href="https://merely-useful.github.io/py-rse/solutions.html#solutions">A</a>),
in addition to learning objectives (Appendix <a href="https://merely-useful.github.io/py-rse/objectives.html#objectives">B</a>)
and key points (Appendix <a href="https://merely-useful.github.io/py-rse/keypoints.html#keypoints">C</a>) for each chapter.</p>
</div>

<div id="intro-ack">
<h2> Acknowledgments</h2>
<p>This book owes its existence to
everyone we met through <a href="https://carpentries.org/">The Carpentries</a>.
We are also grateful to <a href="https://www.insightdatascience.com/">Insight Data Science</a> for sponsoring the early stages of this work,
to the authors of <span>Noble (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Nobl2009" role="doc-biblioref">2009</a>)</span>, <span>Haddock and Dunn (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Hadd2010" role="doc-biblioref">2010</a>)</span>, <span>Wilson et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2014" role="doc-biblioref">2014</a>)</span>, <span>Scopatz and Huff (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Scop2015" role="doc-biblioref">2015</a>)</span>, <span>Taschuk and Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Tasc2017" role="doc-biblioref">2017</a>)</span>, <span>Wilson et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2017" role="doc-biblioref">2017</a>)</span>, <span>Brown and Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Brow2018" role="doc-biblioref">2018</a>)</span>, <span>Devenyi et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Deve2018" role="doc-biblioref">2018</a>)</span>, <span>Sholler et al. (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Shol2019" role="doc-biblioref">2019</a>)</span>, <span>Wilson (<a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2019" role="doc-biblioref">2019</a><a href="https://merely-useful.github.io/py-rse/references.html#ref-Wils2019" role="doc-biblioref">b</a>)</span>
and to everyone who has contributed, including Madeleine Bonsma-Fisher,
Jonathan Dursi,
Christina Koch,
Sara Mahallati,
Brandeis Marshall,
and Elizabeth Wickes.</p>
<ul>
<li><p>Many of the explanations and exercises in Chapters&nbsp;<a href="https://merely-useful.github.io/py-rse/bash-basics.html#bash-basics">2</a>–<a href="https://merely-useful.github.io/py-rse/bash-advanced.html#bash-advanced">4</a>
have been adapted from Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/shell-novice/"><em>The Unix Shell</em></a>.</p></li>
<li><p>Many of explanations and exercises in Chapters&nbsp;<a href="https://merely-useful.github.io/py-rse/git-cmdline.html#git-cmdline">6</a> and&nbsp;<a href="https://merely-useful.github.io/py-rse/git-advanced.html#git-advanced">7</a>
have been adapted from Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/git-novice/"><em>Version Control with Git</em></a> and an
<a href="https://uw-madison-datascience.github.io/git-novice-custom/">adaptation/extension of that lesson</a> maintained by
the University of Wisconsin-Madison Data Science Hub.</p></li>
<li><p>Chapter&nbsp;<a href="https://merely-useful.github.io/py-rse/automate.html#automate">9</a> is based on Software Carpentry’s lesson
<a href="http://swcarpentry.github.io/make-novice/"><em>Automation and Make</em></a>
and on Jonathan Dursi’s
<a href="https://github.com/ljdursi/make_pattern_rules"><em>Introduction to Pattern Rules</em></a>.</p></li>
<li><p>Chapter&nbsp;<a href="https://merely-useful.github.io/py-rse/packaging.html#packaging">14</a> is based in part on <a href="https://python-102.readthedocs.io/"><em>Python 102</em></a>
by Ashwin Srinath.</p></li>
</ul>
</div>
<div id="dedications">
<h2> Dedications</h2>
<div><p>To David Flanders<br>
who taught me so much about growing and sustaining coding communities.<br>
— Damien</p><p>
&nbsp;
To the UofT Coders Group<br>
who taught us much more than we taught them.<br>
— Luke and Joel</p><p>
&nbsp;
To my parents Judy and John<br>
who taught me to love books and everything I can learn from them.<br>
— Kate</p><p>
&nbsp;
To Joshua.<br>
— Charlotte</p><p>
&nbsp;
To Brent Gorda<br>
without whom none of this would have happened.<br>
— Greg</p><p>
&nbsp;
All royalties from this book are being donated to The Carpentries,<br>
an organization that teaches foundational coding and data science
skills<br>
to researchers worldwide.</p></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://merely-useful.github.io/py-rse/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618391</guid>
            <pubDate>Sun, 03 Jan 2021 01:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encrypted Backup Shootout]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25618346">thread link</a>) | @andrewchambers
<br/>
January 2, 2021 | https://acha.ninja/blog/encrypted_backup_shootout/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/encrypted_backup_shootout/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Recently I have been spending time on improving the performance of <a href="https://github.com/andrewchambers/bupstash">bupstash</a> (my encrypted backup tool), and wanted to compare it to some existing tools to try and find its relative performance in the backup tool landscape.</p>
<p>This post compares <a href="https://github.com/andrewchambers/bupstash">bupstash</a>, <a href="https://restic.net/">restic</a>, <a href="https://www.borgbackup.org/">borg backup</a> and plain old tar + gzip + GPG across a series of simple benchmarks.</p>
<p>What do all these tools have in common?</p>
<ul>
<li>They encrypt data at rest.</li>
<li>They compress data.</li>
<li>They have some form of incremental and/or deduplicated snapshotting.</li>
<li>They are all pretty great backup systems.</li>
</ul>
<p>Feel free to checkout the project websites to learn more, let’s get to the benchmarks.</p>
<h2 id="benchmarks">Benchmarks</h2>
<p>For these tests we are using the following versions of the given software:</p>
<ul>
<li>GNU tar 1.32 + gzip 1.10 + GPG 2.2.23</li>
<li>Bupstash 0.6.1</li>
<li>Borg 1.1.14</li>
<li>Restic 0.11.0</li>
</ul>
<p>The test machine has an AMD Ryzen Threadripper 1950X 16-Core Processor with 16 GB of ram, and an NVMe SSD hard drive. It is probably best to simply compare results relatively, as reproducing my test environment exactly would be difficult.</p>
<p>The scripts I used for my benchmarking can be found <a href="https://github.com/andrewchambers/EncryptedBackupShootout">here</a>, though they will definitely need tweaking for your environment.</p>
<h3 id="deduplication-and-compression">Deduplication and compression</h3>
<p>For this benchmark we take 20 different consecutive versions of the linux kernel source code and add them all to the same directory, we then create a snapshot and measure the size of the resulting tarball/repository.</p>
<p>The linux kernel versions chosen for this test are all the consecutive git commits preceeding version 5.9, with the resulting directory containing 21 GB of uncompressed files.</p>
<p><img src="https://acha.ninja/img/Test_Snapshot_Size.svg" alt="plot"></p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Size</th>
<th>Compression Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash</td>
<td>0.378 GB</td>
<td>55x</td>
</tr>
<tr>
<td>borg</td>
<td>0.476 GB</td>
<td>49x</td>
</tr>
<tr>
<td>restic</td>
<td>1.5 GB</td>
<td>14x</td>
</tr>
<tr>
<td>tar + gzip + gpg</td>
<td>3.6 GB</td>
<td>5.8x</td>
</tr>
</tbody>
</table>
<p>This benchmark shows the advantage the more sophisticated tools have over plain tarballs, they all have extremely good compression ratios when similar data is added multiple times to
a backup repository.</p>
<h3 id="creating-a-fresh-directory-snapshot">Creating a fresh directory snapshot</h3>
<p>For this benchmark we are snapshotting a copy of the linux
5.9.8 source code.</p>
<p>The directory we are snapshotting is 1.1 GB comprised of 74725 files and directories.</p>
<p>The snapshots are all made to tmpfs so hopefully does not measure delays introduced by the network or disk activity.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash put</td>
<td>3.939 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.026 s</td>
</tr>
<tr>
<td>borg create</td>
<td>13.831 s</td>
</tr>
<tr>
<td>tar | gzip | gpg</td>
<td>24.505 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the clear winner here for raw snapshotting speed.</p>
<h3 id="sending-a-fresh-snapshot-to-a-remote-server">Sending a fresh snapshot to a remote server</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh. This benchmark should only be considered an approximation of the effect latency has on the tool performance as it is so dependent on network speeds.</p>
<p>At the time of benchmarking my connection to the remote server can be summarized as follows:</p>
<ul>
<li>server -&gt; client 10MiB/s</li>
<li>client -&gt; client 2.5MiB/s</li>
<li>ping 32 milliseconds</li>
</ul>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Remote_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar | gzip | gpg | ssh</td>
<td>72.640 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>121.817 s</td>
</tr>
<tr>
<td>borg create</td>
<td>143.942 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>414.859 s</td>
</tr>
</tbody>
</table>
</details>
<p>Plain tar takes the win, Restic performs poorly here, it has a far more latency-sensitive upload protocol.</p>
<h3 id="creating-an-incremental-directory-snapshot">Creating an incremental directory snapshot</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark, except now we measure the time for an incremental snapshot using the builtin caching mechanism of the tools. What this means is each tool keeps a record of what files it has already sent, and is able to
skip doing that work again.</p>
<p><img src="https://acha.ninja/img/Time_for_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg</td>
<td>0.209 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.394 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>3.916 s</td>
</tr>
<tr>
<td>borg create</td>
<td>7.724 s</td>
</tr>
</tbody>
</table>
</details>
<p>Incremental tar is the clear winner here, but why are the other tools slower? I think this is mainly because the other tools present each snapshot to the user as a full backup and thus do extra work to spare the end user from managing incremental backups manually.</p>
<p>It is also interesting to me that <code>bupstash put</code> is an order of magnitude faster than the other similar tools, though I currently can not explain clearly why that may be the case.</p>
<h3 id="sending-an-incremental-snapshot-to-a-remote-server">Sending an incremental snapshot to a remote server</h3>
<p>This benchmark is the same as the incremental local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh.</p>
<p>Benchmark conditions are the same as the fresh remote snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg | ssh</td>
<td>0.779 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.999 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.140 s</td>
</tr>
<tr>
<td>borg create</td>
<td>10.772 s</td>
</tr>
</tbody>
</table>
</details>
<p>These results match closely with the local incremental snapshots.</p>
<h3 id="restoring-a-snapshot">Restoring a snapshot</h3>
<p>In this benchmark we will restore the snapshot made in the fresh local snapshot benchmark to tmpfs. This is what measuring what happens when you need to do a bulk disaster recovery from your backup repository.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash get | tar -x</td>
<td>2.712 s</td>
</tr>
<tr>
<td>gpg -d | gzip -d | tar -x</td>
<td>4.449 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>4.890 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>9.694 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the winner for restoring backups.</p>
<h3 id="restoring-a-snapshot-from-a-remote-server">Restoring a snapshot from a remote server</h3>
<p>In this benchmark we will restore the snapshot made in the fresh remote snapshot benchmark to tmpfs. The main difference from the previous benchmark is the introduction of
an internet connection between the backup repository and restore point.</p>
<p>Network conditions are the same as the fresh network snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>ssh | gpg -d | gzip -d | tar -x</td>
<td>28.082 s</td>
</tr>
<tr>
<td>bupstash get | tar -x</td>
<td>48.893 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>52.931 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>146.098 s</td>
</tr>
</tbody>
</table>
</details>
<p>Interestingly, the introduction of the network pushed tar ahead of bupstash for backup restoration - this is something I am very interested in investigating further.</p>
<h3 id="pruning-an-old-backup">Pruning an old backup</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository on the same computer. For this test we generate a backup repository with 50 different snapshots of different versions of the linux kernel source code and then time how long it takes to remove one of the snapshots. This benchmark simulates
cycling old backups out of your backup repository when you no longer need them.</p>
<p>Tar with incremental backups does not easily support pruning of old backups, so does not participate in this benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>0.0386 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>0.497 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>2.030 s</td>
</tr>
</tbody>
</table>
</details>
<p>The bupstash garbage collector is an order of magnitue faster than both restic and borg at pruning the backup repository.</p>
<h3 id="pruning-an-old-backup-on-a-remote-server">Pruning an old backup on a remote server</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository stored on a remote server. The remote server is the same as the one used in fresh remote snapshot benchmark, and the test data is the same as the local prune bench mark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>2.137 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>3.111 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>145.540 s</td>
</tr>
</tbody>
</table>
</details>
<p>Once again restic suffers the worst from introduced network latency of all the tools.</p>
<h3 id="approximate-peak-client-side-ram-usage">Approximate peak client side ram usage</h3>
<p>For this benchmark we repeat the fresh snapshot benchmark, but measure the peak client ram usage (RSS) as reported by the ‘time’ command. For tar we approximate this by summing the peak memory usage across tar, gpg and gzip.</p>
<p><img src="https://acha.ninja/img/Test_Peak_Memory_Usage.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Peak Memory Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar + gzip + GPG</td>
<td>10.312 MB</td>
</tr>
<tr>
<td>bupstash</td>
<td>18.192 MB</td>
</tr>
<tr>
<td>borg</td>
<td>96.696 MB</td>
</tr>
<tr>
<td>restic</td>
<td>191.252 MB</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is very memory-efficient compared to restic and borg, but ultimately loses out to the simplicity of tar + gzip + GPG.</p>
<h2 id="conclusions-and-discussion">Conclusions and discussion</h2>
<p>GNU Tar + gzip + gpg is an excellent encrypted backup option and performed better than I expected. I think tar and gpg is still a great choice for users who prefer to DIY their own backup scripts. With this in mind, we must ask what are the problems with tar that the other tools address? My opinion is that managing
incremental backups, deduplication, pruning, and searching backups are far more difficult when using incremental tar compared to borg/restic/bupstash. With incremental tar, it quickly becomes quite hard to track which incremental
tarballs depend on eachother and you often need to periodically do full snapshots - losing most of the speed benefits.</p>
<p>As the biased author of bupstash, I am also pleased with how it has performed and hope I can push it further in the future. Restic, while fast at local operation, seems to trail the other tools when network latency is thrown into the mix. Borg is an all-around great tool and performed very well.</p>
<p>I can see both strengths and room for improvement in each of the tools tested, and encourage everyone to give them a try for yourself if you haven’t already.</p>
<p>As always, thank you for your time and see you next time :).</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/encrypted_backup_shootout/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618346</guid>
            <pubDate>Sun, 03 Jan 2021 01:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Golang for You]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618264">thread link</a>) | @gurjeet
<br/>
January 2, 2021 | https://gurjeet.singh.im/blog/no-golang-for-you | <a href="https://web.archive.org/web/*/https://gurjeet.singh.im/blog/no-golang-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The blog post <a href="https://fasterthanli.me/articles/i-want-off-mr-golangs-wild-ride">“I want off Mr. Golang’s Wild Ride”</a> by Amos incited
me to write a comment on its <a href="https://news.ycombinator.com/item?id=25616593">HN</a> submission page. But as the comment ran 5
paragraphs long, I have turned it into this blog post.</p>

<p>It is a well written and in-depth look at the rot inside the Golang ecosystem.
Make sure to read to the end and notice that the rot started at the core
contributors level.</p>

<p>Golang’s tagline, from their <a href="https://github.com/golang/go">repository</a>, is “Go is an open source
programming language that makes it easy to build simple, reliable, and efficient
software.”</p>

<p>Reading this post by Amos should make it clear to you that Golang has succeeded
ONLY in the “simple” part of the claim; unless written with extreme care,
programs written in Golang are neither reliable, nor efficient.</p>

<p>Amos presents some examples of why I have disliked Golang since the beginning.
After having used Golang for a few years seriously, I disliked it enough to
start a fork of the language named <a href="https://github.com/gurjeet/gofy/tree/gofy">GoFY</a>. I named the language as such
because, since the beginning when I saw some of initial presentations by Rob
Pike specifically, and some others’ presentations and blog posts generally, they
had an air of ego when dismissing others’ opinions and concerns, and appeared to
say “these are our decisions, that is how it is, and if you don’t like it, Go
F*** Yourself”. So the project name was a GoFY to them back, from me.</p>

<p>I’m sure it looks a great language from afar, and for newcomers. But as a
seasoned developer who has seen a few other languages in thier lifetime, you
will quickly begin to see the problems with the language and the ecosystem
around it.  The astute among you may notice that in my <a href="https://gurjeet.singh.im/blog/persistence-perseverance">post yesterday</a> I
did not claim to be an expert in Golang; it’s hard to be an expert in something
that’s fragile, flaky and full of special cases. For the same reason I
never took up using MySQL; I have heard enough stories of its flakiness and
special cases that it never looked like a solid technology to me. I openly and
whole-heartedly recommend learning and using <a href="https://www.postgresql.org/">Postgres</a> to anyone who would
listen.</p>

<p>Fortunately I did not invest any more time in it other than to document a few
times in section <a href="https://github.com/gurjeet/gofy/tree/gofy#gofy-desired-differences">“GoFY Desired Differences”</a> as to what I would
like to see different in the GoFY language, which in turn would make it better
than Golang, at least for long-time systems developers like myself. I am glad I
didn’t burn any oil on it because creating a new language, even a fork, is
neither easy nor quick.</p>


  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gurjeet.singh.im/blog/no-golang-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618264</guid>
            <pubDate>Sun, 03 Jan 2021 00:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Work, a Pictorial Essay]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618219">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://joinmarket.me/blog/blog/pow-a-pictorial-essay/ | <a href="https://web.archive.org/web/*/https://joinmarket.me/blog/blog/pow-a-pictorial-essay/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>In the modern nation state, courts ("justice") operate with the threat of violence. The exact way a dispute is settled varies (jury, single judge, etc.), but the "finality" of the resolution they provide is based on the fact that the state asserts the final say, and if you don't agree, it doesn't matter, because they have men with guns. Importantly, they don't just have <em>some</em> men with guns (that's something <em>you</em> might have, too), they have an overwhelming number of men and increasingly large guns depending on how much you don't want to accept their say.</p>
<p>If you are thinking "that's a stupidly over-simplified way of thinking about modern justice systems", then that's fine; a lot of what follows is precisely about the <em>finesse</em> around this simplified view of the world.</p>
<h3>The threat is stronger than its execution</h3>
<p>This aphorism comes from the world of chess (as far as I gather); it's somehow both obvious but also subtle at the same time.
Forgive the sidetrack, but it reminds me of the possible originator of this phrase, a controversial figure in the history of chess - Aron Nimzowitsch. One (apocryphal?) <a href="http://www.caissa.com/ext/bulletin/ms/tlda0000/fms1221935698008892000004-%22Why-must-I-lose-to-this-IDIOT-%22">story</a> of him features him pointing at his grandmaster opponent and loudly proclaiming "Why must I lose to this idiot?!". But to the matter in hand - Nimzowitsch wrote one of the most famous early-ish treatises on chess strategy called "My System".</p>
<p><img src="https://joinmarket.me/images/aronsystem.jpeg" width="436" height="436"></p>
<p>in this book he popularised (amongst many other less controversial things) the idea of <strong>overprotection</strong> - so for example, you have a pawn on square e5, and he considered it good strategy to protect it with a knight on f3, a rook on e1 and a bishop on g3 etc. etc. Many players - indeed top grandmasters - today find this idea faintly ridiculous. What interests me is that when they deride the idea they essentially never give credence to the element of truth it surely contains, which is this: if N &gt; 1 pieces protect a key square, it means that <em>any</em> of them can move without losing protection of that square. In other words the <em>potential</em> for <em>any</em> piece to move is preserved (contrasted with a single protector, which is therefore bound and cannot move away from protection).</p>
<p><img src="https://joinmarket.me/images/overprotection.png" width="436" height="436"></p>
<p>The idea behind the phrase "the threat is stronger than its execution" - which sounds paradoxical at first - is similar. Potentiality is more difficult for the adversary to handle than actuality, mostly because the adversary may have to handle many potential actions, rather than the one that is actualised.</p>
<p>This can manifest psychologically - inducing <em>fear</em> in an enemy is often a very excellent strategy, rather than directly attacking them. But it's important to understand that it's not just mind games. It's a matter of economy, and a matter of abstraction. Just like in the development of quantitative disciplines (all the way from early mathematics to modern computer programming, and much modern science), the development of abstractions allows for economy, which maximally leverages resources, and even open up whole new dimensions that were previously inaccessible.</p>
<h3>The virtualization of violence</h3>
<p>This line of thinking naturally leads us to how violence as a concrete actualization of will tends to get abstracted away. This is seen across nature, <em>not</em> only in human societies. It's well understood how access to mating in social animals (various types of mammals) is "arbitrated" through combat, and importantly, the combat is rarely to-the-death. Even more strikingly, the "combat" is reduced to competition over attributes <em>which might allow for better success in combat</em>. The obvious example is the stag's antlers:</p>
<p><img src="https://joinmarket.me/images/antlers1.jpeg" width="436" height="436"></p>
<p>That's a lot of physical raw material, requiring a lot of nutrition, and with unclear direct utility (very inefficient!). These are only a quasi-abstraction from real horns designed to kill - they <em>can</em> kill other stags, but apparently it's very rare, but they have evolved to be very visually assessable by other stags, and their complex geometry allows for battles ("horns locked") which are more of an assessment of the ability to kill, than an attempt to do so. There are of course many further examples that are more obviously abstractions. Further, displays may not be of attributes designed to inflict violence, but attributes that display high levels of general fitness, which itself is an abstraction from "ability to gather a lot of resources". The peacock being the most famous visually striking example, albeit the exact mechanisms involved may not be a matter of settled science.</p>
<p>i<img src="https://joinmarket.me/images/peacock.jpg" width="436" height="436"></p>
<p>I will leave the biologists to extend this list further with more obscure examples...</p>
<p>A rather interesting summary of one perspective on these phenomena is <a href="https://en.wikipedia.org/wiki/Handicap_principle">the handicap principle</a> (which somehow I had not read before writing most of this document, and as you will understand from reading it, I now rather wish I had!).</p>
<p>Also, the two examples we've seen so far show how there are two sides to this phenomenon: show dominance by showing the <em>ability</em> to win a fight without fighting; show superior suitability by showing the <em>ability</em> to gather resources without actually gathering resources. They are clearly not <em>completely</em> distinct.</p>
<h3>The same in modern human society</h3>
<p>We can see both types of 'abstraction' very clearly even in modern society. The violence-competition is virtualized in sport, most obviously:</p>
<p><img src="https://joinmarket.me/images/gridiron.jpeg" width="436" height="436"></p>
<p>(It's probably not an accident that in many places, sportsmen are pretty much at the top of the mating hierarchy, at least to some females!). But lest we get <em>too</em> abstract, let's not forget that just generally, displays of violence <em>capability</em> are also a big part of human society, even at the nation-state level:</p>
<p><img src="https://joinmarket.me/images/militaryparadewithtanks.jpeg" width="436" height="436"></p>
<p>Once we start thinking about human behaviour this way, we can see it everywhere. Consider the engagement ring and ask yourself where this tradition might come from:</p>
<p><img src="https://joinmarket.me/images/engagementring.jpeg" width="436" height="436"></p>
<p>We are not so different from peacocks here ... and it's not of course "irrational" in any but the most inane sense. Look at the analogy between the peacock's display and the engagement ring more closely, both:</p>
<ul>
<li>are costly in resources to create</li>
<li>are visually appealing</li>
<li>are (visually) very distinct from the normal "stuff" in the environment</li>
<li>are very immediately and easily recognized <em>by any viewer, on their own</em></li>
<li>signal that the creator is part of a group (genetic, or cultural)</li>
</ul>
<p>Much less obvious I think is that the <em>permanence</em> of these displays is not central. Sometimes they are very delicate and fragile (think: flowers, think: sports displays with substantial risk of injury that would cause permanent inability to repeat them), and this is <em>almost</em> the point - to the receiver of the signal, what matters is that the signal was unambiguously difficult to create. What matters much less is the "substrate", i.e. what the signal is "made of". This is part of the insight in the "handicap principle":</p>
<blockquote>
<p><strong>what matters is what you <em>couldn't</em> do, because you did this.</strong></p>
</blockquote>
<p><img src="https://joinmarket.me/images/smallbirdinjungle.jpeg" width="436" height="436"></p>
<p>Further, imagine yourself as a small bird in the jungle - to find mating partners in this <strong>extremely</strong> noisy environment, you are looking for a small signal - a patch of bright colour - in this high noise environment. You want the signal to be unambiguous - blue where everything is green, yellow, brown, red - and costly. You don't want to have to compare it to something else to check it's correct (is it the same color as something else on the other side of the jungle? sheesh!). You really don't care about semantics - you don't care what the signal "means", except specifically that it's in some sense pre-agreed (perhaps genetically? see the last bullet point); to an outsider the signal could be outlandish or ridiculous, and that doesn't matter.</p>
<h3>The court, the bank, and the abstraction of money</h3>
<p><img src="https://joinmarket.me/images/bankofmontreal.jpeg" width="436" height="436"></p>
<p>You can see it in architecture; there is of course a very good reason why historically banks were built of extremely sturdy materials, at considerable cost. They were originally actually vaults for high concentrations of physical wealth, and had to protect well from direct frontal assault.</p>
<p><img src="https://joinmarket.me/images/hongkong.jpeg" width="436" height="436"></p>
<p>Nowadays this is another abstraction of the type already mentioned; if an organization put <em>that</em> much money into building such an imposing building or flashy skyscraper, they're hardly likely to steal my pathetic little stash! Court buildings likewise represent an abstraction of the state's power, and so do government offices (this is particularly obvious in more authoritarian states like China, where the government buildings in smaller towns look almost absurd (this example is very typical, in Luxian):</p>
<p><img src="https://joinmarket.me/images/luxian.jpeg" width="436" height="436"></p>
<p>The whole "virtualization" paradigm, taking concrete physical force and replacing it with "threats, stronger than executions" has entirely entered the realm of money too. Not to dip my toe into the various debates about the origin of money, I'll just talk about recent history: we moved from bearer instruments and certificates for bearer instruments, through to certificates representing pure "fiat" in the literal sense - fiat meaning the will of the governing power, essentially. So "fiat is backed by men with guns", the famous <a href="https://www.youtube.com/watch?v=MJWi8VUHUzk">Krugman</a> quote,</p>
<p><img src="https://joinmarket.me/images/krugman.jpeg" width="436" height="436"></p>
<p>... is certainly right <em>in essence</em> even if you quibble over various details. In the same way that courts are "backed by men with guns".</p>
<p>But I think it's important to step back and consider what role money takes in a society - its purpose is always exactly abstraction. It solves the "double coincidence of wants" problem by creating an entirely new class of good that no one originally wanted (this is the counter intuitive about much mathematics - to solve a problem involving 2 or 3 things you add another thing, superficially making everything more complicated, but suddenly everything 'falls into place', creating a new structure with more symmetry. For example, if the general solution of polynomials is tortuous and even insoluble (see: <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Galois</a>) for real numbers, by adding an apparent complexity: a new made-up solution to x^2=-1, you suddenly find that everything cleans itself up (see: <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra">the fundamental theorem of algebra</a>). Money does something similar, because we replace an O(N^2) pricing problem with an O(N) problem - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joinmarket.me/blog/blog/pow-a-pictorial-essay/">https://joinmarket.me/blog/blog/pow-a-pictorial-essay/</a></em></p>]]>
            </description>
            <link>https://joinmarket.me/blog/blog/pow-a-pictorial-essay/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618219</guid>
            <pubDate>Sun, 03 Jan 2021 00:45:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Android Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25618065">thread link</a>) | @xearl
<br/>
January 2, 2021 | https://madaidans-insecurities.github.io/android.html | <a href="https://web.archive.org/web/*/https://madaidans-insecurities.github.io/android.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  

  <p><i><time datetime="2020-12-30">Last edited: December 30, 2020</time></i></p>

  <p>
    By default, Android has a strong security model and incorporates <a href="https://source.android.com/security/selinux/">
    full system SELinux policies</a>, <a href="https://source.android.com/security/app-sandbox">strong app sandboxing</a>,
    <a href="https://source.android.com/security/verifiedboot">full verified boot</a>, modern exploit mitigations like
    <a href="https://source.android.com/devices/tech/debug/cfi">fine-grained forward-edge Control-Flow Integrity</a> and
    <a href="https://source.android.com/devices/tech/debug/shadow-call-stack">ShadowCallStack</a>, widespread use of
    memory-safe languages (Java / Kotlin) and more. As such, this article explains common ways in which people worsen the
    security model rather than criticisms of the security model itself.
  </p>

  <h2 id="unlocking-the-bootloader"><a href="#unlocking-the-bootloader">Unlocking the bootloader</a></h2>

  <div><p>
    Unlocking the bootloader in Android is a large security risk. It disables <a href="https://source.android.com/security/verifiedboot/">verified boot</a>, a fundamental part of the security
    model. Verified boot ensures the integrity of the base system and boot chain to prevent <a href="https://en.wikipedia.org/wiki/Evil_maid_attack">
    evil maid attacks</a> and malware persistence. </p><p>
    
    Contrary to common assumptions, verified boot is not just important for physical security — it prevents the persistence
    of <b>any</b> tampering with your system, be it from a physical attacker or a malicious application that has managed to
    hook itself into the operating system. For example, if a remote attacker has managed to exploit the system and gain high
    privileges, verified boot would revert their changes upon reboot and ensure that they cannot persist.
  </p></div>

  <h2 id="rooting"><a href="#rooting">Rooting your device</a></h2>

  <div><p>
    Rooting your device allows an attacker to easily gain extremely high privileges. Android's architecture is built
    upon <a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege">principle of least privilege</a>. By default,
    unrestricted root is found nowhere in the system due to the <a href="https://source.android.com/security/selinux">
    full system SELinux policy</a>. Even the init system does not have unrestricted root access. Exposing privileges far
    greater than any other part of the OS to the application layer is not a good idea. </p><p>
    
    It does not matter if you have to whitelist apps that have root. An attacker can fake user input by for example,
    <a href="https://en.wikipedia.org/wiki/Clickjacking">clickjacking</a> or they can exploit vulnerabilities in apps that
    you have granted root to. By rooting your device, you are breaking Android's security model and adding further layers
    of trust where it is inappropriate. </p><p>
    
    A common argument for rooting is that Linux allows root but this does not account for the fact that the average
    desktop Linux system does not have a security model like Android does. On the usual Linux system, <a href="https://madaidans-insecurities.github.io/linux.html#root">gaining root is extremely easy</a>. This is why Linux hardening procedures often involve
    restricting access to the root account.
  </p></div>

  <h2 id="custom-roms"><a href="#custom-roms">Custom ROMs</a></h2>

  <p>
    The majority of custom ROMs severely weaken the security model by disabling verified boot, using userdebug builds,
    disabling SELinux, and various other issues. Furthermore, you are also usually at the mercy of the maintainer to
    apply security updates properly. Certain ROMs often apply security patches late or sometimes not apply them at all,
    especially when it comes to firmware patches.
  </p>

  <h3 id="lineageos"><a href="#lineageos">LineageOS</a></h3>

  <p>
    A common ROM that has many of these issues is <a href="https://lineageos.org/">LineageOS</a>:
  </p>

  <ul>
    <li>
      LineageOS <a href="https://github.com/LineageOS/hudson/blob/master/lineage-build-targets">uses
      userdebug builds by default</a>. This <a href="https://source.android.com/setup/build/building#choose-a-target">
      adds many debugging features as additional attack surface</a>. It also weakens various SELinux polices and exposes
      root access via adb which <a href="#root">as discussed above</a>, is not a good idea.
    </li>

    <li>
      LineageOS requires an unlocked bootloader, therefore disabling verified boot which <a href="#unlocking-the-bootloader">
      is essential to verify the integrity of the operating system</a>.
    </li>

    <li>
      It does not implement <a href="https://source.android.com/security/verifiedboot/verified-boot#rollback-protection">
      rollback protection</a>. This allows an attacker to downgrade the system to an older version and then exploit already
      patched vulnerabilities. The default updater even allows you to downgrade versions yourself.
    </li>

    <li>
      Most LineageOS builds also do not include firmware updates which prevents users from getting new patches to fix
      vulnerabilities. Instead, it gives a pop-up advising users to flash updates manually that most people will simply
      ignore.
    </li>
  </ul>

  <p>
    This is a non-exhaustive list. There are more issues than just those listed above. LineageOS (and most other custom
    ROMs) are focused on customizing the device and not privacy or security. Of course, you could build LineageOS yourself
    to fix many of these issues but most users will not be capable of doing so.
  </p>

  <h2 id="microg-signature-spoofing"><a href="#microg-signature-spoofing">MicroG / Signature Spoofing</a></h2>

  <div>
    <p><a href="https://microg.org/">MicroG</a> is a common alternative to Google Play Services. It is often used to get rid
    of Google's tracking but most people do not realise that this can potentially worsen security as it
    <a href="https://github.com/microg/android_packages_apps_GmsCore/wiki/Signature-Spoofing">requires signature spoofing
    support</a> which allows apps to request to bypass signature verification. </p><p>
    
    Although, some signature spoofing implementations restrict it to make it less bad such as <a href="https://gitlab.com/calyxos/platform_frameworks_base/commit/dccce9d969f11c1739d19855ade9ccfbacf8ef76">CalyxOS'
    implementation</a> which allows only microG to spoof the Play Services signature and nothing else.
  </p></div>

  <h2 id="firewalls"><a href="#firewalls">Firewalls</a></h2>

  <div><p>
    Firewalls such as <a href="https://github.com/ukanth/afwall/">AFWall+</a> or <a href="https://www.netguard.me/">
    Netguard</a> are regularly used on Android to attempt to block network access from a specific app but these
    do not reliably work — apps can use IPC to bypass the restrictions. If you cut off network access to an app, it
    will not prevent the app from sending an <a href="https://developer.android.com/reference/android/content/Intent">
    intent</a> to another app (such as the browser) to make it make the same connection. </p><p>
    
    Many apps already do this unintentionally whilst using APIs such as the <a href="https://developer.android.com/reference/android/app/DownloadManager">download manager</a>. </p><p>
    
    The most effective way to block network access is to revoke the <code>INTERNET</code> permission from the app
    like <a href="https://github.com/GrapheneOS/platform_frameworks_base/commit/5e2898e9d21dd6802bb0b0139e7e496c41e1cd80">
    GrapheneOS allows you to do</a>. This prevents abusing OS APIs to initiate network connections as they contain checks
    for that permission, one example of which is the aforementioned download manager. You should also run the app in its
    own user or work profile to ensure that it cannot abuse third party apps either.
  </p></div>

  <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>

  

  <p>
    <a href="https://madaidans-insecurities.github.io/index.html">Go back</a>
  </p>

  
  


</div>]]>
            </description>
            <link>https://madaidans-insecurities.github.io/android.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618065</guid>
            <pubDate>Sun, 03 Jan 2021 00:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25618048">thread link</a>) | @barry-cotter
<br/>
January 2, 2021 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618048</guid>
            <pubDate>Sun, 03 Jan 2021 00:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dug, A global DNS propagation checker on your CLI]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25618012">thread link</a>) | @monkaiju
<br/>
January 2, 2021 | https://git.kaijucode.com/matt/dug | <a href="https://web.archive.org/web/*/https://git.kaijucode.com/matt/dug">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="count_prompt">You can not select more than 25 topics</span>
			<span id="format_prompt">Topics must start with a letter or number, can include dashes ('-') and can be up to 35 characters long.</span>
		</p><div>
	
	<div>
		<div>
			
				
<p><a href="https://drone.kaijucode.com/matt/dug" rel="nofollow"><img src="https://drone.kaijucode.com/api/badges/matt/dug/status.svg" alt="Build Status"></a></p>
<p>The <strong>real</strong> repository is located <a href="https://git.kaijucode.com/matt/dug" rel="nofollow">here</a></p>
<p>The GitHub repository <a href="https://github.com/unfrl/dug" rel="nofollow">here</a> is used for issues and stars <span aria-label="glowing star">🌟</span></p>
<p>A powerful global DNS progagation checker that can output in a variety of formats.</p>
<p>The goal of dug is to make it easy to check the propagation of DNS records. It is also capable of providing templated output that can be used in scripts for things like monitoring.</p>
<h2 id="user-content-usage">Usage</h2>
<p>Until theres a wiki for this, the easiest way to explore dug is through the help.</p>
<ul>
<li><code>dug help</code> -&gt; Get top level help explaining the different verbs</li>
<li><code>dug help run</code> or <code>dug run --help</code> -&gt; Get details about a specific verb (run, which is the default)</li>
<li><code>dug help update</code> or <code>dug update --help</code> -&gt; Get details about the update verb</li>
</ul>
<p>The simplest way to get started is to just run a query against the domain whose DNS records you’re updating.
For example: <code>dug git.kaijucode.com</code>:
<a href="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif1.gif" rel="nofollow"><img src="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif1.gif" alt=""></a></p>
<p>You can also do complicated things like ask for specific record types, get the output as json, and pipe it into other applications: <code>dug git.kaijucode.com -q A --output-format JSON --output-template Ipaddress,city,value,responsetime | jq</code>:
<a href="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif2.gif" rel="nofollow"><img src="https://git.kaijucode.com/matt/dug/media/branch/main/cli/Resources/gif2.gif" alt=""></a></p>
<h2 id="user-content-installation">Installation</h2>
<h3 id="user-content-linux-deb-debian-ubuntu-mint-pop-os">Linux Deb (Debian, Ubuntu, Mint, Pop!_os)</h3>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .deb package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.linux-x64.deb</code></li>
</ul>
</li>
<li>On most distros double clicking the .deb package will allow you to install via a UI, alternatively it can be installed by running <code>sudo dpkg -i ./dug.&lt;version&gt;.linux-x64.deb</code></li>
</ol>
<h3 id="user-content-linux-rpm-rhel-centos-fedora">Linux RPM (RHEL, CentOS, Fedora)</h3>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .rpm package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.linux-x64.rpm</code></li>
</ul>
</li>
<li>On most distros double clicking the .deb package will allow you to install via a UI, alternatively it can be installed by running <code>rpm -i ./dug.&lt;version&gt;.linux-x64.deb</code></li>
</ol>
<h3 id="user-content-arch">Arch</h3>
<ol>
<li>A friend put dug in the AUR! <a href="https://aur.archlinux.org/packages/dug-git/" rel="nofollow">here</a></li>
</ol>
<h3 id="user-content-osx">OSX</h3>
<blockquote>
<p>Not Officially Supported Yet</p>
</blockquote>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the osx binary.
<ul>
<li>It should look like <code>dug-osx-x64</code></li>
</ul>
</li>
<li>You should be able to download that, make is executable, and run it from the terminal. Then you can put it somewhere and update your path so you can execute it from anywhere.</li>
</ol>
<h3 id="user-content-windows">Windows</h3>
<h4 id="user-content-chocolatey-choco-cli">Chocolatey (choco cli)</h4>
<blockquote>
<p>Waiting on chocolatey to approve my package, then I can publish there so this wont require a manual download. <a href="https://chocolatey.org/packages/dug" rel="nofollow">here</a></p>
</blockquote>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .nupkg package.
<ul>
<li>It should look like <code>dug.&lt;version&gt;.nupkg</code></li>
</ul>
</li>
<li>Install by running <code>choco install dug.&lt;version&gt;.nupkg</code></li>
</ol>
<h4 id="user-content-executable">Executable</h4>
<ol>
<li>Go to the <a href="https://git.kaijucode.com/matt/dug/releases" rel="nofollow">latest release</a> and download the .exe binary.
<ul>
<li>It should look like <code>dug.exe</code></li>
</ul>
</li>
<li>You should be able to download that and run it from the terminal. Then you can put it somewhere and update your path so you can execute it from anywhere.</li>
</ol>
<h3 id="user-content-npm">NPM</h3>
<blockquote>
<p>EXPERIMENTAL! (Currently only supports linux-x64)</p>
</blockquote>
<ol>
<li>Run: <code>npm -g @unfrl/dug</code></li>
</ol>
<p>Idk why I wanted to publish it on npm as well, its really not a good way to distribute a binary...</p>
<h2 id="user-content-development">Development</h2>
<p>This is a .net 5 project, so as long as you have the dotnet cli, available <a href="https://dotnet.microsoft.com/download/dotnet/5.0" rel="nofollow">here</a> you should be able to do the following: <code>dotnet build ./cli</code></p>
<p>The project was developed in VSCode so the debugger profiles that I have used are available if you’re also using VSCode.</p>
<h2 id="user-content-license">License</h2>
<p>The license used by dug, <a href="https://git.kaijucode.com/matt/dug/src/branch/main/cli/LICENSE" rel="nofollow">here</a>, is very explicitly designed to try to keep capitalists from benefiting from this tool. This is not a traditional license but it is very simple, please read it.</p>
<p>Made with <span aria-label="red heart">❤️</span> by <a href="https://unfrl.com/" rel="nofollow">Unfrl</a></p>

			
		</div>
	</div>
</div></div>]]>
            </description>
            <link>https://git.kaijucode.com/matt/dug</link>
            <guid isPermaLink="false">hacker-news-small-sites-25618012</guid>
            <pubDate>Sun, 03 Jan 2021 00:12:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Penrose Tiling image using each RGB colour exactly once]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25617861">thread link</a>) | @rahimnathwani
<br/>
January 2, 2021 | https://allrgb.com/penrose-tiling | <a href="https://web.archive.org/web/*/https://allrgb.com/penrose-tiling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://allrgb.com/penrose-tiling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25617861</guid>
            <pubDate>Sat, 02 Jan 2021 23:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use FusionAuth JWT tokens and claims with Hasura GraphQL to auth requests]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25617644">thread link</a>) | @mooreds
<br/>
January 2, 2021 | https://fusionauth.io/community/forum/topic/696/how-to-use-fusionauth-jwt-token-and-claims-with-hasura-graphql-to-authenticate-graphql-requests | <a href="https://web.archive.org/web/*/https://fusionauth.io/community/forum/topic/696/how-to-use-fusionauth-jwt-token-and-claims-with-hasura-graphql-to-authenticate-graphql-requests">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div component="post/content" itemprop="text">
	<p dir="auto">Re: <a href="https://fusionauth.io/community/forum/topic/382/gatsby-hasura-fusionauth-kintohub-my-dream-stack">Gatsby + Hasura + FusionAuth + KintoHub (My Dream Stack)</a></p>
<p dir="auto">There are several aspects you need to think about this topic. The first thing requires us to make our setup correct and authenticate GraphQL requests. The second part requires figuring out how to use refresh JWT tokens to continue operation without breaking something.</p>
<p dir="auto"><strong>This post covers the first part:  The Setup and authenticating the requests</strong></p>
<p dir="auto"><strong>1 - Add Hasura custom claims in the JWT</strong></p>
<ul>
<li>Create a Lambda function on FusionAuth to add Hasura claims to the tokens you issued. It's <a href="https://github.com/FusionAuth/fusionauth-issues/issues/61#issuecomment-493317279" rel="nofollow">pretty much covered on this GitHub issue</a></li>
<li>To do that, go to <a href="https://fusionauth:9011/admin/lambda/" rel="nofollow">https://fusionauth:9011/admin/lambda/</a></li>
<li>Add a new Lambda function with a name you can easily recognize later like "Populate - Hasura GraphQL Custom JWT Claims"</li>
<li>Leave ID empty, as you should always do <img src="https://fusionauth.io/community/forum/plugins/nodebb-plugin-emoji/emoji/android/1f642.png?v=9ro6udfbar8" title=":)" alt="ðŸ™‚"></li>
<li>Select JWT Populate as the type</li>
<li>Add <a href="https://fusionauth.io/community/forum/uid/3">@robotdan</a>'s code in the code area</li>
</ul>
<pre><code>// Using the user and registration parameters add additional values to the jwt object.
function populate(jwt, user, registration) {
// When writing a lambda we've added a few helpers to make life easier.
// console.info('Hello World'); # This will create an EventLog of type Information
// console.error('Not good.'); # This will create an EventLog of type Error
// console.debug('Step 42 completed.'); # This will create an EventLog of type Debug
//
   jwt["https://hasura.io/jwt/claims"] = {
    "x-hasura-allowed-roles": ["editor","user", "some-other-role"],
    "x-hasura-default-role": "user",
    "x-hasura-user-id": user.id,
    "x-hasura-org-id": "123",
    "x-hasura-custom": "custom-value"
  };
// To dump an entire object to the EventLog you can use JSON.stringify, for example:
// console.info(JSON.stringify(user));
// Happy coding! Populate your JWT here.
console.info(JSON.stringify(jwt, null, 2));
console.info(JSON.stringify(user, null, 2));
}
</code></pre>
<ul>
<li>Roles are used in Step #5 below. You'll have to figure it out later by yourself depending on your needs</li>
<li>Save your function<br>
<img src="https://fusionauth.io/community/forum/assets/uploads/files/1609169320679-add-hasura-claims.png" alt="add-hasura-claims.png"></li>
</ul>
<p dir="auto"><strong>2- Tell your FusionAuth app to use the lambda</strong></p>
<ul>
<li>Find your FusionAuth app here <a href="https://fusionauth:9011/admin/application/" rel="nofollow">https://fusionauth:9011/admin/application/</a> and click edit.</li>
<li>Edit your app</li>
<li>Click on the JWT tab</li>
<li>Enable the JWT if you haven't before</li>
<li>Set <em><strong>Access Token populate lambda</strong></em> to your newly created lambda<br>
<img src="https://fusionauth.io/community/forum/assets/uploads/files/1609169294607-app-lambda.png" alt="app-lambda.png"></li>
</ul>
<p dir="auto"><strong>3 - Create a Signing key on FusionAuth</strong></p>
<ul>
<li>Go to <a href="https://fusioauth:9011/admin/key/" rel="nofollow">https://fusioauth:9011/admin/key/</a></li>
<li>Create a new key based on <a href="https://stackoverflow.com/questions/39239051/rs256-vs-hs256-whats-the-difference" rel="nofollow">your choice of algorithm</a>. I'd go with RSA256 or RSA512 since you don't need to share your private key with Hasura or anybody else</li>
</ul>
<p dir="auto"><strong>4- Tell your Fusion App to use the key</strong></p>
<ul>
<li>You've created a key. Now you need to have your tokens be signed with it. Find your FusionAuth app here <a href="https://fusionauth:9011/admin/application/" rel="nofollow">https://fusionauth:9011/admin/application/</a> and click edit.</li>
<li>Click on the JWT tab</li>
<li>Select your Key created before for <em><strong>Access Token signing key</strong></em></li>
<li>Select your Key created before for <em><strong>Id Token signing key</strong></em></li>
<li>Save your app</li>
</ul>
<p dir="auto"><strong>5- Tell Hasura where to get the signing public keys</strong></p>
<ul>
<li>Hasura has a config parameter named <em><strong>HASURA_GRAPHQL_JWT_SECRET</strong></em>, which it uses to grab public keys to verify your Auth header tokens. Put it in your docker-compose file. (or into the file you set your Hasura config)</li>
</ul>
<pre><code>HASURA_GRAPHQL_JWT_SECRET='{"type": "RS512", "jwk_url": "https://fusionauth/.well-known/jwks"}'
</code></pre>
<p dir="auto"><strong>6- Restart your Hasura instance</strong></p>
<ul>
<li>If you're using Docker, you'd do</li>
</ul>
<pre><code>docker restart hasura_docker_image_name
</code></pre>
<p dir="auto"><strong>7- Tell your Hasura how to use  row or column level permissions for the tables you track</strong></p>
<ul>
<li>Hasura helps you to set row or column level permissions on the DATA page of its dashboard. Find your table and set select permission as it described <a href="https://hasura.io/learn/graphql/hasura-auth-slack/access-control/1-user-permissions/" rel="nofollow">in this tutorial</a></li>
<li>Basically, add your user group, and set your permission to check the user-id set in the request's header.</li>
</ul>
<pre><code>{"users_id":{"_eq":"x-hasura-user-id"}}
</code></pre>
<ul>
<li>Here, I set "user" role permission on my app's user "Settings" table we store user-specific settings so only the user in auth header could get the data that strictly belongs to him/her<br>
<img src="https://fusionauth.io/community/forum/assets/uploads/files/1609168109230-set-user-select-permission.png" alt="set-user-select-permission.png"></li>
</ul>
<p dir="auto"><strong>8- You're pretty much ready to make a request now with your token</strong></p>
<ul>
<li>I Assume you've used one of the workflows to get your auth bearer token from FusionAuth. <a href="https://fusionauth.io/learn/expert-advice/authentication/login-authentication-workflows/" rel="nofollow">They cover pretty much every scenario on their blog you can find here, a must-read!</a>.</li>
<li>Make a Curl request or use a tool like Postman.</li>
<li>Authentication header</li>
<li>Make your request for the logged-in user by sending his/her token</li>
</ul>
<pre><code>curl -X POST https://publish.graph.circleboom.com/v1/graphql -H 'Authorization: Bearer eyJhb..............' -H 'Content-Type: application/json' -d '{"query": "{ settings { job_start_time } }" }'
</code></pre>
<ul>
<li>Get your user-specific answer back for the token owner</li>
</ul>
<pre><code>{"data":{"settings":[{"job_start_time":"22:30:00"}]}}
</code></pre>
<p dir="auto"><strong>Next:</strong> Refresh JWT token by following <a href="https://hasura.io/blog/best-practices-of-using-jwt-with-graphql/" rel="nofollow">The Ultimate Guide to handling JWTs on frontend clients (GraphQL)</a> *</p>

</div></div>]]>
            </description>
            <link>https://fusionauth.io/community/forum/topic/696/how-to-use-fusionauth-jwt-token-and-claims-with-hasura-graphql-to-authenticate-graphql-requests</link>
            <guid isPermaLink="false">hacker-news-small-sites-25617644</guid>
            <pubDate>Sat, 02 Jan 2021 23:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a startup can survive technical debt]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25617083">thread link</a>) | @fidrelity
<br/>
January 2, 2021 | https://andreschweighofer.com/tech/how-your-startup-can-survive-technical-debt/ | <a href="https://web.archive.org/web/*/https://andreschweighofer.com/tech/how-your-startup-can-survive-technical-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-387">

	<!-- .entry-header -->

	
	<div>

		
<p>How can your early stage startup use technical debt to survive and thrive? How does technical debt in young startups look and where does it come from?</p>



<p>It’s hard to avoid technical debt completely but you can manage it and use it to your advantage. Let us have a look how technical debt is created in startups and how you can keep it in check even when your company is in hyper growth.</p>



<figure><img src="https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt-1024x648.jpg" alt="" srcset="https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt-1024x648.jpg 1024w, https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt-300x190.jpg 300w, https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt-768x486.jpg 768w, https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt-648x410.jpg 648w, https://andreschweighofer.com/wp-content/uploads/2021/01/survive-technical-debt.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>The paradox of success</h2>



<p>The most common way for startups to create technical debt is ironically the very thing that makes them succeed: A validated idea. You build things and test them out. Most ideas don’t stick. You move on. Until suddenly you have something that people really want and things spin out of control. That hacked together throwaway prototype is so sticky you can’t afford to lose your momentum. There is no time to rebuild it. You build upon it. That’s your first piece of technical debt – your prototype turned MVP.</p>



<h2>The right kind of technical debt</h2>



<p>The successful prototype sounds much like a eulogy of failed startups but it doesn’t have to be. Up to this point your technical debt is manageable and it’s enabling you to stay in business. You have turned your throwaway prototype into a bridge loan to get to the next milestone. You can use it to close the next funding round or spend money on customer acquisition to grab a foothold in the market.</p>



<h2>Paying the interest on your technical debt</h2>



<p>If you keep funding your success with debt it will catch up to you once one of two things happen. Either your growth will slow down or your technical debt has accumulated and development slows down. Both lead to you struggling to pay the interest on your debt. So it’s vital so reduce your technical debt <em>before</em> it spirals out of control. Here is a strategy to do exactly that.</p>



<h2>Balancing the short term with the long term</h2>



<p>When you build out your product you will come across technical debt. At this point don’t work around it but work through the technical debt. You need to <a href="https://killalldefects.com/2019/12/24/technical-debt-as-risks/">understand the risk your technical debt carries</a> and not get lost in the short term opportunities ahead. As a lead engineer or CTO it’s your responsibility to advocate maintenance work as a <em>Must have</em>, not a <em>nice to have</em>.</p>



<p>Unfortunately this ties the faith of your startup’s technical debt to one single person – you. To mitigate this we can try to bake it into the organisation’s behaviour by designing a process which balances the short term and long term thinking.</p>



<h2>Manage technical debt through your product</h2>



<p>When you build something new you should commit to do two things with it: Either you remove the feature if it does not bring in the expected results or you iterate on it. Axe any code before it turns into a liability or grant yourself the time to fix it and redo it properly. This strategy is effective because when you build a new feature you know the least about it, so even if you tried you probably couldn’t build it completely <em>right</em>. But once you’ve released it you have learned a lot more which will help greatly paying back that technical debt.</p>



<p>With this commitment the burden of fixing technical debt is not solely on you anymore. The product side is now your party in crime. However, in an early startup that probably just means two people instead of one. Once your organisation grows you need to ensure this attitude survives.</p>



<h2>Culture can beat technical debt</h2>



<p>When your company grows you want to fight technical debt before it gets out of control. Unfortunately the rapidly changing structures in a fast growing startup are a great breeding ground for technical debt.</p>



<p>You can try to establish specific roles like architects and lead engineers and processes like code reviews to fight your technical debt. But an engineer can’t manage technical debt unless the organisation enables them to. You need to create a culture which balances the short term with the long term thinking. A culture where engineers can take pride in their craft and not have to be the bad guys who say No all the time. Here are some hints how such a culture could look like.</p>



<h3>Do less but do it well</h3>



<p>Instead of getting <a href="https://andreschweighofer.com/agile/anxiety-in-product-development/">trapped in a fear driven culture</a> focus on your strengths. What makes your startup stand out from the competitors? Hone that skill. This is important to cut out distractions. It also keeps the technical debt at bay because you’re not racing from one feature to the next.</p>



<h3>Celebrate your engineering</h3>



<p>What your startup celebrates and rewards is what it creates more of. So if you only celebrate sale numbers and growth rates but none of your engineering accomplishments you end up with stunted engineering. So celebrate the engineering solutions and put the engineers in the spotlight. They are behind the scenes of product too often.</p>



<h3>Hire the best and train them</h3>



<p>Your technical debt is rarely caused by just bad engineering. But it can be part of the problem. Great engineers can avoid many forms of careless technical debt. You should leverage their skills to keep the growth of your technical debt in check. We all want to hire the best engineers. That’s easier said than done. But you can work with what you already have. Invest in training your engineers the best you can. This not only avoids technical debt but greatly improves the satisfaction of your engineers and their retention.</p>







<p>What makes startups successful is often the root of their technical debt. If your startup struggles with technical debt it’s important to note that this is neither a death&nbsp;sentence nor something to be ignored. Use it wisely and give your organisation room to tackle it so your startup can continue to thrive.</p>


		
	</div>

	

</article></div>]]>
            </description>
            <link>https://andreschweighofer.com/tech/how-your-startup-can-survive-technical-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25617083</guid>
            <pubDate>Sat, 02 Jan 2021 22:15:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Simple Ways to Refactor Terrible Code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25616757">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://martinheinz.dev/blog/40 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/40">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/40</link>
            <guid isPermaLink="false">hacker-news-small-sites-25616757</guid>
            <pubDate>Sat, 02 Jan 2021 21:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Being Generic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25616645">thread link</a>) | @cshou
<br/>
January 2, 2021 | https://b.cluelessme.dev/p/the-power-of-being-generic?r=dl1ud&utm_campaign=post&utm_medium=web&utm_source=hackernews | <a href="https://web.archive.org/web/*/https://b.cluelessme.dev/p/the-power-of-being-generic?r=dl1ud&utm_campaign=post&utm_medium=web&utm_source=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9e89288-2dab-4202-b59c-19f6ab133e2a_626x440.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9e89288-2dab-4202-b59c-19f6ab133e2a_626x440.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a9e89288-2dab-4202-b59c-19f6ab133e2a_626x440.jpeg&quot;,&quot;height&quot;:440,&quot;width&quot;:626,&quot;resizeWidth&quot;:442,&quot;bytes&quot;:26803,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>It’s the beginning of year 2021. If you have some new year resolutions and you’re a casual person like me, I’m sharing one tip worked really well for me, in the hope it can help you to stick with your resolutions a little bit longer.</p><blockquote><p>Being generic with your plans.</p></blockquote><p>Being generic means having a sense of big directions (the <em>motion</em> towards your goals) rather than <em>specific</em> objectives. E.g. “To read <em>more</em> books about a topic” or simply “to read <em>more</em> books” is a big direction while “to read 2 books each month” is a specific objective. “To lose some weight” is a direction while “to lose 50 lbs” is a specific objective.</p><p>For many years I believed in setting specific, measurable objectives for personal habits/resolutions. After all, the idea is promoted a lot in business world, such as setting <a href="https://en.wikipedia.org/wiki/SMART_criteria">SMART</a> goals. But one day I realized that unless my personal goal is specific by nature, being <em>specific</em> is actually counterproductive - it has a major problem.</p><blockquote><p>Before we start (moving towards our goal), we usually don’t know what plan works the best <em>for us</em>. Setting specific objectives prematurely tends to anchor misleading expectations, and thus causes negative feelings when the specifics aren’t met.</p></blockquote><p>Life is eventful and full of uncertainty. A seemingly viable plan this week could turn to be unrealistic in the next month. There are two common problems:</p><ul><li><p>Over-committing. This could be due to incorrect estimation of one’s ability, capacity or willpower, or it could be caused by unforeseeable life events. </p></li><li><p>What worked for others doesn’t necessarily work for me. E.g. To read more, some people are more productive reading a short period everyday while others could prefer reading full days over the weekends. Just <em>think</em> whether we will resonate with a routine doesn’t always tell the truth; we have to <em>experience</em> it to tell. </p></li></ul><p>I once set a resolution to read 1 hour everyday. But in the very next week my workload turned heavy and I didn’t have time to read anything over the weekdays. I felt so defeated regarding my reading “progress” and started to consider myself not the type of person that reads. I didn’t even think about reading for a little bit over the weekends when I actually had time.</p><p>Being specific draws our attention to the specifics (reading 1h everyday) rather than the big direction (read more books). The corollary is that such a plan would be disruption-prone. But, you see, a disrupted plan itself is not that harmful. It’s the negative feeling caused by the disruption that’s really destructive - it’s the catalyst for a vicious circle. </p><ol><li><p>The more you’re off the track (from the specifics you set)</p></li><li><p>The more unforgiving you become about the “mistakes”; the unforgivingness might (unconsciously) come from a sense of shame, anger or disappointment</p></li><li><p>The more likely you’re going to <em>deny your identity</em> being the type of person that is capable of achieving your goal</p></li><li><p>The more likely you choose to give up and become further off-track</p></li></ol><p>Being generic helps to break the circle. Because there is no specific objective to hit, we wouldn’t be distracted by the specifics, and thus not feel as strongly off-track when we miss the mark in the near term. More importantly it eases the negative feelings about ourselves and <strong>lowers the emotional barrier for us to refocus on the motion towards the goals</strong>. If the current schedule or routine stopped working, then find another. If it’s just a pause of the plan, then resume it later.</p><p>The essential logic behind is to <strong>make it easy to recover from setbacks and refocus on actions</strong>. According to the theory of <a href="https://en.wikipedia.org/wiki/Cognitive_dissonance">cognitive dissonance</a>, our mind tends to agree with our actions. Our action forges our identity, and our identity reinforces our action. That’s the virtuous circle that backs any sustainable behavior. </p><p>But there is a catch. We still need to somehow measure the progress to make sure we’re not simply procrastinating or staying in place.</p><blockquote><p>Measure <em>incremental</em>, instead of <em>absolute</em>, progress. </p></blockquote><p>Did I read more this month than last month? Did I exercise more than last week? Such incremental progress might look trivial, but it augments our confidence via action which reinforces our belief in certain identity, e.g. I am the type of person that can read.</p><p>Hopefully at one point we will reach a desired activeness level. But will it last? Likely. If you entered the virtuous circle for long enough, the belief in your identity probably has been forged, and you have probably found a routine that worked for you. At this point, it’s pretty much autopilot mode to carry out the desired activity. </p><p>OK. There is another catch. To form the habits to reach your goals, it definitely takes more than just being generic. I highly recommend the book <a href="https://www.amazon.com/Atomic-Habits-Proven-Build-Break/dp/0735211299/ref=sr_1_1?dchild=1&amp;keywords=atomic+habits&amp;qid=1609621310&amp;sr=8-1">Atomic Habits</a>. The author provides tons of practical advices about forming habits. “Make it easy” is one of the four principles in the book. Being generic is my insight to how to make it a little bit easier.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F05d330e5-90bd-45b9-821a-431f65770996_331x499.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F05d330e5-90bd-45b9-821a-431f65770996_331x499.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/05d330e5-90bd-45b9-821a-431f65770996_331x499.jpeg&quot;,&quot;height&quot;:499,&quot;width&quot;:331,&quot;resizeWidth&quot;:203,&quot;bytes&quot;:30823,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Hope you stick with your new year resolutions, and have a great new year!</p></div></div>]]>
            </description>
            <link>https://b.cluelessme.dev/p/the-power-of-being-generic?r=dl1ud&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25616645</guid>
            <pubDate>Sat, 02 Jan 2021 21:20:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to overcome Phone Addiction]]>
            </title>
            <description>
<![CDATA[
Score 652 | Comments 255 (<a href="https://news.ycombinator.com/item?id=25616472">thread link</a>) | @Shred77
<br/>
January 2, 2021 | https://cognitiontoday.com/phone-addiction-coping-solutions-research-statistics/ | <a href="https://web.archive.org/web/*/https://cognitiontoday.com/phone-addiction-coping-solutions-research-statistics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Phone addiction is one of the <a href="https://academicjournals.org/journal/AJBM/article-abstract/F86F13618106" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">biggest non-drug addiction</a> in human history. Studies show that <em>excessive phone</em> use is linked to <a href="https://cognitiontoday.com/procrastinating-with-your-phone-reduce-procrastinatory-phone-dependence/" data-wpel-link="internal" target="_self" rel="follow noopener noreferrer">procrastination</a>, <a href="https://europepmc.org/article/med/29877640" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">suicide</a> (<a href="https://www.indiatvnews.com/technology/news-pubg-mobile-addiction-13-year-old-boy-commits-suicide-over-the-mobile-game-635604" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer"><em>example</em></a>), <a href="https://www.mdpi.com/1660-4601/14/7/701" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">spoilt sleep</a>, <a href="https://www.onlinescientificresearch.com/articles/social-media-internet-and-electronic-devices-addiction-among-children-and-adolescents-in-global-contexts-modern-cities.pdf" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">food and water neglect</a>, <a href="https://headachejournal.onlinelibrary.wiley.com/doi/abs/10.1111/head.12840" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">headaches</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2352853217300159" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">lower productivity</a>, <a href="https://aisel.aisnet.org/ecis2016_rp/109/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">unstable relationships</a>, poor physical health (<a href="https://www.omicsonline.org/a-study-on-some-of-the-common-health-effects-of-cell-phones-amongst-college-students-2161-0711.1000214.php?aid=14036" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">eye strain, body-aches</a>, <a href="https://www.jstage.jst.go.jp/article/jpts/26/4/26_jpts-2013-459/_article/-char/ja/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">posture</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5680647/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">hand strain</a>), and poor mental health (<a href="http://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE01121669" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">depression</a>,<a href="https://link.springer.com/article/10.1007/s10826-018-01323-2" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer"> </a><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/smi.2805" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">anxiety, stress</a>). Some of these problems can be both causes and effects of phone addiction (procrastination, anxiety, unstable relationships, etc.).</p>



<p>So what can be done about phone addiction in a world that <a href="https://www.emerald.com/insight/content/doi/10.1108/IntR-08-2012-0155/full/html" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">loves the internet so much</a>? After all, it helps <a href="https://journals.sagepub.com/doi/abs/10.1177/0733464816669805" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">older people stay independent</a>, <a href="https://cognitiontoday.com/effect-of-social-media-on-mental-health-well-being/" data-wpel-link="internal" target="_self" rel="follow noopener noreferrer">gratifies our social needs, comforts us from stress</a>, and <a href="https://www.jstor.org/stable/44430520?seq=1" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">helps us learn</a> (common interest groups, affinity spaces).</p>




<p><strong>Trivia:</strong> When you are bored in face-to-face conversations or don’t want to interact with others, do you slowly start using your phone and divert your attention away from the person? Snubbing another person in favor of your phone is called <em>phubbing</em> (phone + snubbing) and it is a <a href="https://www.sciencedirect.com/science/article/pii/S0747563215300704" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">common complaint in relationships</a>. <em>Phubbing your partner is called Pphubbing or Partner phubbing and research acknowledges that it worsens relationship satisfaction, life satisfaction, and could also add to depression.</em> Phubbing could be a form of social exclusion and researchers argue that <a href="https://cyberpsychology.eu/article/view/12590/11560" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">even watching others phub</a> can induce stress and lower regard for the phubbers.</p>



<h2><span id="What_is_phone_addiction">What is phone addiction?</span></h2>



<p>Let’s first understand what is phone addiction and what counts as excessive phone use.  Phone addiction or compulsive phone use goes along-side internet addiction and social media addiction. Psychologists also call it “problematic phone use.” For this post, we will consider them together. Cell-phones are habit-forming – once you go down that rabbit hole, you use more and more. Like drugs, one can get hooked to a phone or an activity on the phone that leads to addiction. There is abuse without control, changes in mood, excessive desire to use, withdrawals like irritability and anger when you can’t use the phone, low tolerance to avoid the phone, and the phone interferes with life in a negative way. </p>



<p>Strictly speaking, addiction is “the loss of control, the establishment of a dependent relationship, tolerance, the need for progressively more time and dedication, and severe interference with daily life (Echeburua et al., 2009).” Phones, internet-based activities, and any technology for that matter can <a href="https://www.frontiersin.org/articles/10.3389/fpsyt.2016.00175/full" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">become an addiction</a> in the truest sense (even though many disagree). And sometimes, phone addicts need to be rehabilitated in a hospital.</p>



<p>Not all phone use is a sign of addiction, even if the volume of use is high. A <em>loss of control</em> in how the phone is used and <em>psychological dependency</em> is an indicator of addiction. <a href="https://academic.oup.com/hcr/article-abstract/42/3/441/4064735?redirectedFrom=fulltext" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Recreational phone use</a> and productive phone use isn’t the problem, it’s the inability to regulate usage and unhealthy coping for larger problems that usually makes screen-time problematic. If you are addicted to your phone, you probably can’t let go of phone-related activities no matter how often you tell yourself you need to let go.</p>




<p>People often get addicted to the phone because they want to <em>escape from reality</em>, <em>gain social karma</em>, <em>cope with stress caused by social anxiety and low self-esteem</em>, <em>follow their greed for social validation</em>, <em>likes</em>, <em>and other types of rewards</em>, or <em>play rewarding games</em>. The constant flow of digital rewards and information can <em>pull</em> a person into addiction and day-to-day difficulties can <em>push</em> a person toward addiction. Social media addiction usually comes down to these “internet reward points.”</p>



<div><figure><img width="640" height="426" src="https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321.jpg" alt="Phone addiction" srcset="https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321.jpg 640w, https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20640%20426'%3E%3C/svg%3E" data-lazy-srcset="https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321.jpg 640w, https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321-300x200.jpg 300w" data-lazy-src="https://cognitiontoday.com/wp-content/uploads/2020/08/pexels-roman-odintsov-4555321.jpg"></figure></div>



<h3><span id="Indicators_of_problematic_phone_use">Indicators of problematic phone use</span></h3>



<p><strong>There is no cut-off point to show you are addicted to your phone which everyone agrees to but here are some indicators</strong>.</p>



<ol><li>You spend continuous hours on the phone to play games, scroll through social media, open and close apps, text people to invite a chat, etc.</li><li>You frequently pick up the phone without any aim to check for notifications or see if something has changed in your social feeds.</li><li>Your online and offline behavior gets more integrated and you don’t know what you did in the digital reality or the material reality.</li><li>You get restless if your phone is dead or has low-battery, is out-of-coverage, or low on data/balance.</li><li>You treat your phone as a security blanket without which you get uncomfortable in social gatherings.</li><li>Your day-to-day activities take a backseat, relationships are strained, and you can’t focus and commit to the important things in your life.</li><li>You feel bad about yourself and you go online to feel good but you end up feeling worse looking at what others are doing.<em> Such compulsive phone use is likely to emerge from other mental health issues.</em></li></ol>



<h3><span id="Common_examples_of_problematic_phone_use">Common examples of problematic phone use</span></h3>



<ol><li>Infinitely scrolling through Instagram.</li><li>Playing Call of Duty or PubG for hours and social activities contain little to no honest communication.</li><li>Excessive display of hurt, loneliness, attention-seeking behavior, hate, jealousy, and disapproval on social media.</li><li>Social needs are not met (sexual intimacy, close friendship, physical touch, etc.) and online alternatives are used to compensate for poor social health (chatbots, echo-chambers, porn, social gaming, virtual reality social games like second life, camming relationships).</li><li>Inability to feel pleasure and excitement in the offline world but excessive emotions are tied to online rewards like gambling, likes, shares, followers, sexting, masturbation to porn, etc.</li><li><em>FOMO</em> (fear of missing out) and <em>Nomophobia</em> (no-mobile phobia) cause mental and physical discomfort.</li><li>You frequently experience <em>Ringxiety</em> or <em>Textaphrenia</em> or Phantom notifications – the feeling that you received a notification when you actually did not.</li></ol>



<h2><span id="Statistics_on_phone_and_internet_use">Statistics on phone and internet use</span></h2>



<ol><li><a href="https://blog.rescuetime.com/screen-time-stats-2018/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">According to a 2019 report</a>, the average person spends about 3.5 hours on their phone in a day with the top 20% of people spending more than 4.5 hours a day. <a href="https://www.washingtonpost.com/technology/2020/03/24/screen-time-iphone-coronavirus-quarantine-covid/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">The quarantine</a> has increased these numbers – many users report over 8 hours a day.</li><li>The 2019 report also says that 70% of all phone use lasts lesser than 2 minutes and 50% of all phone pick-ups occur within 3 minutes of the previous pick-up.</li><li><a href="https://wearesocial.com/blog/2019/01/digital-2019-global-internet-use-accelerates" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Another 2019 report</a> (2018 data) says at least 3.3 billion people use the internet and social media from their phones.</li><li><a href="https://www.comscore.com/Insights/Presentations-and-Whitepapers/2019/Global-State-of-Mobile" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">Comscore’s 2019 Global state of mobile</a> report says 70% of all digital media engagement in the US happens from a smartphone. So TV, games, laptops, gaming consoles, theatres, etc. are all squeezed into the tiny remainder of 30%. </li></ol>



<h2><span id="Important_research_highlights_on_phone_addiction">Important research highlights on phone addiction</span></h2>



<p>Phone addiction goes <a href="https://www.tandfonline.com/doi/abs/10.1080/08934215.2020.1780456" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">hand in hand</a> with anxiety and that anxiety often lowers the motivation to engage with people in real life. This is a huge problem because re-connecting with people in the offline world is a solution that improves the quality of life. The unnecessary drop in motivation because of addiction makes it that much harder to maintain social health.</p>



<p>Phone addiction can <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306460319311839" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">cause poor cognitive performance</a> in day-to-day life. That means poor attention, poor memory, poor reasoning skills, bad decision making, etc. One of the main reasons is the role of sleep. Addiction can disturb sleep and sleep worsens cognitive performance. However, self-regulation (personal control, commitment to healthy choices, tolerating negative emotions) can counter the negative effects of addiction and that can help you overcome it.</p>



<p><a href="https://www.sciencedirect.com/science/article/pii/S0190740919311296" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">A dysfunctional family can push</a> children into addiction and one reason is social anxiety. A broken family or unhealthy parenting like neglect or excessive control can often hamper emotional growth. Children might fail to learn how to behave in social settings. There may be a fear of ridicule, disapproval, disappointment, etc. or simply a looming belief like “I am not good enough” or “I am a bad child” that creates pressure on children. These fears or thoughts transfer into the real-world and children cope with the social anxiety it causes by withdrawing into their phones – where the fantasy digital world rescues them from their real life. Fortunately, mindfulness – being aware of your actions and living in the moment as an observer – can reduce the negative impact of phone addiction.</p>




<p>Underlying mental health conditions like bipolar disorder, depression, anxiety, and attachment issues can <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7215249/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">increase the risk</a> of phone addiction. And improving mental health can <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4354213/" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">counter addiction</a>. Proneness to boredom <a href="https://journals.sagepub.com/doi/abs/10.1177/0894439317741087" data-wpel-link="external" target="_blank" rel="nofollow external noopener noreferrer">can increase</a> the likelihood of problematic phone use but not the frequency of phone use. This ultimately makes boredom a pathway between problematic phone use and anxiety or depression.</p>







<h2><span id="9_Ways_to_overcome_phone_addiction_and_reduce_screen_time">9 Ways to overcome phone addiction and reduce screen time</span></h2>



<h3><span id="1_Schedule_a_time_for_un-monitored_phone_use">1.&nbsp;<strong>Schedule a time for un-monitored phone use</strong></span></h3>



<p>Grant yourself as much time as you want within a fixed daily limit at a specific hour of the day. As long as you can first demonstrate some output. Random notifications and random experiences are potent in pulling you to check your phone precisely because they are random. Unpredictable notifications and call-to-actions are hard to anticipate so the brain maximizes their potential reward (feeling great) by constantly creating the urge to pick up the phone and check. Schedule an hour to commit to your phone or make it a rule to check it every 45 minutes. That way, the rewards will be hard to anticipate but they will occur at a known time and your brain will find it easier to adjust than completely abandoning your phone.</p>




<h3><span id="2_Interrupt_your_habitual_routine">2.&nbsp;<strong>Interrupt your habitual routine</strong>&nbsp;</span></h3>



<p>Habits are hard to break because neurons in your brain rigidly fire a certain way. Once an action is repeated enough, neural circuits become efficient. They then direct and dictate behavior automatically. Countering their tendencies becomes harder. Higher the repetitions, the more stable those neurons get. These neural circuits fire in a predictable way and they fire automatically with almost no external push. You may have little to no awareness about the start of habitual actions. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cognitiontoday.com/phone-addiction-coping-solutions-research-statistics/">https://cognitiontoday.com/phone-addiction-coping-solutions-research-statistics/</a></em></p>]]>
            </description>
            <link>https://cognitiontoday.com/phone-addiction-coping-solutions-research-statistics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25616472</guid>
            <pubDate>Sat, 02 Jan 2021 20:59:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whack-A-Mole: Reverse Engineering the 'Wie Is de Mol?' App]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25615817">thread link</a>) | @ndrong
<br/>
January 2, 2021 | https://n04m.nl/reverse-engineering-the-wie-is-de-mol-app | <a href="https://web.archive.org/web/*/https://n04m.nl/reverse-engineering-the-wie-is-de-mol-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="wie-is-de-mol">Wie is de Mol?</h2><p><em>Wie is de Mol?</em> (‘Who is the Mole?’) is a popular Dutch television game show, currently airing its 21st season. Contestants compete in challenges to win money that goes into a shared prize pool. One of the contestants acts as a mole, attempting to sabotage the other contestants in their efforts to win challenges. The identity of the mole is unknown and it is up to the contestants to determine who it might be. Every episode a contestant leaves the show, until the final contestant leaves with the money collected during the season.</p><p>For the last couple of years, my colleagues have been competing in a group in the <em>Wie is de Mol?</em> app, available for <a href="https://apps.apple.com/nl/app/avrotros-wie-is-de-mol/id760264022" target="_blank" rel="noreferrer">iOS</a> and <a href="https://play.google.com/store/apps/details?id=nl.avro.demol" target="_blank" rel="noreferrer">Android</a>. The app allows users to place a bet (using free digital tokens, there are no payments involved as far as I know) on the persons who they deem most likely to be the mole.</p><p>When I received an invitation from a colleague for this year’s group, I couldn’t resist to take a look inside the Android app and its accompying API to see whether I could dig up any interesting vulnerabilities. I should note that I first made sure that the broadcasting network, AVRO, has a <a href="https://www.avrotros.nl/privacy/responsible-disclosure/" target="_blank" rel="noreferrer">vulnerability disclosure policy</a> in place that allows such research. They appear to welcome security research, so off we go!</p><h2 id="preface">Preface</h2><p>My goal for this post is to share my process in tackling challenges that may occur while reverse engineering an Android application in a black box setting, therefore I won’t delve into too much detail on the usage of any of the tools listed below. Having a basic understanding of Android and web applications is recommended.</p><div><table><thead><tr><td>Application <!-- -->&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;</td><td>Usage</td></tr></thead><tbody><tr><td><a href="https://ibotpeaches.github.io/Apktool/" target="_blank" rel="noreferrer">Apktool</a></td><td>Used to disassemble the Android application and to inject Frida Gadget as a native library</td></tr><tr><td><a href="https://frida.re/" target="_blank" rel="noreferrer">Frida</a></td><td>Used for dynamic instrumentation at runtime</td></tr><tr><td><a href="https://portswigger.net/burp" target="_blank" rel="noreferrer">Burp Suite</a></td><td>Used to intercept traffic between the Android app and its backend</td></tr><tr><td><a href="https://gchq.github.io/CyberChef/" target="_blank" rel="noreferrer">CyberChef</a></td><td>Used for quick encoding/decoding/hashing/etc.</td></tr></tbody></table></div><p>For information on how to inject Frida Gadget into the apk, please take a look at one of the many tutorials out there, such as <a href="https://fadeevab.com/frida-gadget-injection-on-android-no-root-2-methods/" target="_blank" rel="noreferrer">this one</a> or <a href="https://koz.io/using-frida-on-android-without-root/" target="_blank" rel="noreferrer">this one</a>.</p><h2 id="intercepting-http-traffic">Intercepting HTTP Traffic</h2><p>Frida enables us to override common certificate pinning implementations, so we can intercept traffic using a proxy of our choosing (in this case, Burp Suite). After setting up the environment, launch the Android application and interact with it to generate some traffic. Let’s start out by pressing the ‘I forgot my password’ button, resulting in the following request and response:</p><p><strong> Request </strong></p><div><pre><p><span>1</span><span>POST /profile/forgot_password/ HTTP/1.1</span></p><p><span>2</span><span>Content-Type: application/json; charset=UTF-8</span></p><p><span>3</span><span>Content-Length: 26</span></p><p><span>4</span><span>Host: api.wieisdemol.nl</span></p><p><span>5</span><span>Connection: close</span></p><p><span>6</span><span>Accept-Encoding: gzip, deflate</span></p><p><span>7</span><span>User-Agent: okhttp/4.7.2</span></p><p><span>8</span><span>X-Signature: HMAC widm-api:UaXaUB6YCKY2AeeuFk00K/Cj5O5cB77NivxtWFT03iU=</span></p><p><span>9</span><span>Date: 2021-01-01T23:38:50.529</span></p><p><span>10</span><span></span></p><p><span>11</span><span>{"email":"***REDACTED***"}</span></p></pre></div><p><strong> Response</strong></p><div><pre><p><span>1</span><span>HTTP/1.1 400 Bad Request</span></p><p><span>2</span><span>Server: nginx/1.19.5</span></p><p><span>3</span><span>Date: Fri, 01 Jan 2021 22:38:50 GMT</span></p><p><span>4</span><span>Content-Type: application/json</span></p><p><span>5</span><span>Content-Length: 131</span></p><p><span>6</span><span>x-config-version: 9</span></p><p><span>7</span><span>Via: 1.1 google</span></p><p><span>8</span><span>Alt-Svc: clear</span></p><p><span>9</span><span>Connection: close</span></p><p><span>10</span><span></span></p><p><span>11</span><span>{"detail":{"email":["Geen e-mailaccount gevonden.\nMisschien was je ingelogd met een social account (bijv. Facebook of Google)?"]}}</span></p></pre></div><p>Notice the <code>X-Signature</code> header in the request: this header provides a <a href="https://en.wikipedia.org/wiki/HMAC" target="_blank" rel="noreferrer">HMAC signature</a> which is verified by the backend, so as to ensure the integrity of the message. Sending a request with an invalid signature, or with no signature at all, results in a 403 response code:</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://n04m.nl/static/a664c58d3e9d5878254accd879beb9fc/4f0f6/invalid_signature.webp 1828w" sizes="(max-width: 1828px) 100vw, 1828px" type="image/webp">
        <source srcset="https://n04m.nl/static/a664c58d3e9d5878254accd879beb9fc/11735/invalid_signature.png 1828w" sizes="(max-width: 1828px) 100vw, 1828px" type="image/png">
        <p><img src="https://n04m.nl/static/a664c58d3e9d5878254accd879beb9fc/11735/invalid_signature.png" alt="Image showing a HTTP 403 response as a result of a request with an invalid signature."></p>
      </picture>
    </span></p><figcaption>Response based on a request with an invalid signature.</figcaption></div><p>This makes modifying requests a bit harder, because we will need to resign the message before sending it to the API. Fortunately, we have the application’s decompiled bytecode at hand to take a look at what’s going on.</p><h2 id="inside-the-hmac">Inside the HMAC</h2><p>In the decompiled bytecode (a.k.a. smali), we can simply search for the string <code>HMAC</code>  and see what pops up. Results turn out to be limited, and we can determine that the signature is composed using the SHA256 hashing function in the following method:</p><div><pre><p><span>1</span><span>.method public static final calculateHmac(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)[B</span></p><p><span>2</span><span></span></p><p><span>3</span><span>.locals 9</span></p><p><span>4</span><span></span></p><p><span>5</span><span>const-string v0, "secret"</span></p><p><span>6</span><span>  </span></p><p><span>7</span><span>invoke-static {p0, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>8</span><span></span></p><p><span>9</span><span>const-string v0, "method"</span></p><p><span>10</span><span>  </span></p><p><span>11</span><span>invoke-static {p1, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>12</span><span></span></p><p><span>13</span><span>const-string v0, "body"</span></p><p><span>14</span><span>  </span></p><p><span>15</span><span>invoke-static {p2, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>16</span><span>  </span></p><p><span>17</span><span>const-string v0, "contentType"</span></p><p><span>18</span><span></span></p><p><span>19</span><span>invoke-static {p3, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>20</span><span>  </span></p><p><span>21</span><span>const-string v0, "date"</span></p><p><span>22</span><span>  </span></p><p><span>23</span><span>invoke-static {p4, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>24</span><span></span></p><p><span>25</span><span>const-string v0, "path"</span></p><p><span>26</span><span></span></p><p><span>27</span><span>invoke-static {p5, v0}, Lv/x/c/i;-&gt;e(Ljava/lang/Object;Ljava/lang/String;)V</span></p><p><span>28</span><span></span></p><p><span>29</span><span>[... snip ...]</span></p></pre></div><p>Using Frida, we can override the <code>calculateHmac</code> method to log its arguments before executing, resulting in the following data:</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"0"</span><span>:</span><span> </span><span>"d9913722-3b89-4705-a4b6-f5d413733e6a"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"1"</span><span>:</span><span> </span><span>"POST"</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>"2"</span><span>:</span><span> </span><span>"{\"email\":\"***REDACTED***\"}"</span><span>,</span><span></span></p><p><span>5</span><span>  </span><span>"3"</span><span>:</span><span> </span><span>"application/json; charset=UTF-8"</span><span>,</span><span></span></p><p><span>6</span><span>  </span><span>"4"</span><span>:</span><span> </span><span>"2021-01-01T22:13:30.166"</span><span>,</span><span></span></p><p><span>7</span><span>  </span><span>"5"</span><span>:</span><span> </span><span>"/profile/forgot_password/"</span><span></span></p><p><span>8</span><span></span><span>}</span></p></pre></div><p>Notice how these arguments line up perfectly with the method signature as seen in the decompiled bytecode above. As an added bonus, we now have the UTF-8 encoded ‘secret’ key used to sign messages: <code>d9913722-3b89-4705-a4b6-f5d413733e6a</code>.</p><p>Remember that a HMAC function takes two arguments: a key and a message. Therefore, the aforementioned arguments need to be transformed into a message (i.e. a byte sequence) before being passed onto the hashing function. Usually developers simply compose the message by concatenating the strings. However, on occasion, a custom implementation is used. To be on the safe side, as well as to avoid making false assumptions, let’s <a href="https://gist.github.com/NDrong/2dea662016704fb99edcf0e9c7961e5f" target="_blank" rel="noreferrer">hook the call to the class method</a> that makes the actual call into the crypto library. This method is aptly named <code>hmac</code> and, as expected, accepts two strings: the message to be signed and a key. Logging provides the following arguments:</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"0"</span><span>:</span><span> </span><span>"POST\n078bdf5f7296200ae9a89901305dec37852dbf84e21496550ad2c477149aa6ac\napplication/json; charset=UTF-8\n2021-01-01T22:13:30.166\n/profile/forgot_password/"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"1"</span><span>:</span><span> </span><span>"d9913722-3b89-4705-a4b6-f5d413733e6a"</span><span></span></p><p><span>4</span><span></span><span>}</span></p></pre></div><p>It appears that the strings, as seen in the first argument, are separated by newline characters. Somewhat surprisingly, a sequence that we haven’t seen before surfaces: <code>078bdf5f7296200ae9a89901305dec37852dbf84e21496550ad2c477149aa6ac</code>. Looking at our findings so far, notice that this sequence is right where the body of the request was placed before. Perhaps this represents a hash of the body? Since I’m not sure what this seemingly random sequence denotes, we’ll return to the decompiled methods to take a closer look.</p><p>Following some of the cross-references, it doesn’t take long to find a call to another class implementing hashing, this time using a SHA-256 message digest (i.e. good-old hashing without any secrets). Internally, a call is made into Java’s built-in security library:</p><div><pre><p><span>1</span><span>invoke-static {p1}, Ljava/security/MessageDigest;-&gt;getInstance(Ljava/lang/String;)Ljava/security/MessageDigest;</span></p><p><span>2</span><span></span></p><p><span>3</span><span>move-result-object p1</span></p><p><span>4</span><span></span></p><p><span>5</span><span>invoke-virtual {p1, p0}, Ljava/security/MessageDigest;-&gt;digest([B)[B</span></p></pre></div><p>Let’s verify whether we can compute the exact same hash for the request shown above, by applying the SHA-256 hashing algorithm to the request body. Start out by hashing the body of the request using <a href="https://gchq.github.io/CyberChef/#recipe=SHA2('256')" target="_blank" rel="noreferrer">CyberChef</a>, like so:</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://n04m.nl/static/8d100468d07edad2a64b81de46079995/a3bc4/cyberchef_hash.webp 2500w,https://n04m.nl/static/8d100468d07edad2a64b81de46079995/417e5/cyberchef_hash.webp 2698w" sizes="(max-width: 2698px) 100vw, 2698px" type="image/webp">
        <source srcset="https://n04m.nl/static/8d100468d07edad2a64b81de46079995/082ed/cyberchef_hash.png 2500w,https://n04m.nl/static/8d100468d07edad2a64b81de46079995/d35e2/cyberchef_hash.png 2698w" sizes="(max-width: 2698px) 100vw, 2698px" type="image/png">
        <p><img src="https://n04m.nl/static/8d100468d07edad2a64b81de46079995/d35e2/cyberchef_hash.png" alt="Image showing a hash of the body using CyberChef"></p>
      </picture>
    </span></p><figcaption>SHA-256 message digest generated using CyberChef.</figcaption></div><p>Great, that’s the exact same hash as seen in the arguments above. Notice that I excluded the backslashes in the JSON, as these were added by <code>JSON.stringify</code> in our Frida script (due to escaping) and are therefore not part of the original body (as confirmed by the original request at the top of this post).</p><p>Now that we have all the arguments we need, all that’s left is to compute the final HMAC used to verify the integrity of the HTTP request. Again, we could use <a href="https://gchq.github.io/CyberChef/#recipe=HMAC(%7B'option':'UTF8','string':'d9913722-3b89-4705-a4b6-f5d413733e6a'%7D,'SHA256')" target="_blank" rel="noreferrer">CyberChef</a> to do the heavy lifting for us, but for some reason I did not manage to get CyberChef to produce the same results as the built-in Java library, most likely due to encoding differences. Therefore, I wrote a small Python script based on a ready-to-use snippet I found <a href="https://www.jokecamp.com/blog/examples-of-creating-base64-hashes-using-hmac-sha256-in-different-languages/#python3" target="_blank" rel="noreferrer">online</a>. Computing the signature using this script indeed results in the expected base64 encoded string as present in the original request:</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://n04m.nl/static/6991a17d0a934967d2876ea4f085b6eb/a3bc4/request_signer.webp 2500w,https://n04m.nl/static/6991a17d0a934967d2876ea4f085b6eb/490e8/request_signer.webp 3288w" sizes="(max-width: 3288px) 100vw, 3288px" type="image/webp">
        <source srcset="https://n04m.nl/static/6991a17d0a934967d2876ea4f085b6eb/082ed/request_signer.png 2500w,https://n04m.nl/static/6991a17d0a934967d2876ea4f085b6eb/37222/request_signer.png 3288w" sizes="(max-width: 3288px) 100vw, 3288px" type="image/png">
        <p><img src="https://n04m.nl/static/6991a17d0a934967d2876ea4f085b6eb/37222/request_signer.png" alt="Image showing the output of the request signing script."></p>
      </picture>
    </span></p><figcaption>Output from the first version of the request signer, now available on <a href="https://github.com/NDrong/widm_request_signer" target="_blank" rel="noopener,noreferrer">GitHub</a>.</figcaption></div><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://n04m.nl/static/0be4dcbc2b074737d2de64f875c92bfa/a3bc4/original_request.webp 2500w,https://n04m.nl/static/0be4dcbc2b074737d2de64f875c92bfa/cda37/original_request.webp 2738w" sizes="(max-width: 2738px) 100vw, 2738px" type="image/webp">
        <source srcset="https://n04m.nl/static/0be4dcbc2b074737d2de64f875c92bfa/082ed/original_request.png 2500w,https://n04m.nl/static/0be4dcbc2b074737d2de64f875c92bfa/81fe0/original_request.png 2738w" sizes="(max-width: 2738px) 100vw, 2738px" type="image/png">
        <p><img src="https://n04m.nl/static/0be4dcbc2b074737d2de64f875c92bfa/81fe0/original_request.png" alt="Image showing the original request and response, highlighting the signature in the request."></p>
      </picture>
    </span></p><figcaption>Original request (and response) highlighting the matching signature.</figcaption></div><h2 id="automated-request-signing">Automated Request Signing</h2><p>In order to effectively interact with the API, some automation might come in useful. Specifically, we want to be able to compose arbitrary requests, which we can then copy-paste into a tool to generate a valid HMAC signature, requiring as little manual labor as needed. Since we’ve already done most of the work, creating a Python script is not that much effort. You can find the resulting script <a href="https://github.com/NDrong/widm_request_signer" target="_blank" rel="noreferrer">in this repository</a>.</p><h2 id="whats-next">What’s Next?</h2><p>Now that we have successfully reverse engineered the signing algorithm, we can continue using the app as one normally would, while intercepting requests in the background. We can analyze these requests for interesting behavior, modifying and signing them as we please, thanks to our automated request signer. At the moment, I haven’t found any vulnerabilities yet, but if I find anything interesting, I’ll be sure to update this post once the issue has been resolved by the broadcasting network.
If you find a vulnerability using any of the methods described here, please let me know! You can contact me on Twitter or via any of the links down in the footer of the page. Thanks for stopping by! :)</p></div></article></div>]]>
            </description>
            <link>https://n04m.nl/reverse-engineering-the-wie-is-de-mol-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-25615817</guid>
            <pubDate>Sat, 02 Jan 2021 19:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from Hugo to Nuxt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25615627">thread link</a>) | @kleinrein
<br/>
January 2, 2021 | https://www.andreasrein.net/posts/hugo-to-nuxt | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/hugo-to-nuxt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have been using Hugo to generate my blog, but since I'm not so comfortable with Go, I wanted to try out something fresh and familiar. Between Gridsome and Nuxt, I chose Nuxt.</p>

<h2 id="hugo---gridsome--nuxt">Hugo -&gt; Gridsome || Nuxt</h2>
<p>Hugo has been working well for me but I find the template language unintuitive and compared to using Vue single-file components, it's like pitch-dark night and blending sunny day. Gridsome was also on my radar but it fell short for me. Some of my reasons were:</p>
<h3 id="gridsome-vs-nuxt">Gridsome vs. Nuxt</h3>
<ul>
<li>Relative immature project: <strong>Aug. 2018</strong> <em>vs.</em> <strong>Jan. 2017</strong>.</li>
<li>Low number of core contributors: <strong>1</strong> <em>vs.</em> <strong>5</strong>. (over 100 commits total).</li>
<li>Pure popularity: <strong>7.1k</strong> GitHub stars <em>vs.</em> <strong>32.6k</strong> Github stars.</li>
<li>Opinionated GraphQL data layer. But this can be a positive for someone.</li>
</ul>
<p>All in all, Gridsome is a young project so a lot can change in time. For now, I'm going for Nuxt.</p>
<h2 id="nuxt">Nuxt</h2>
<p>Generating the Nuxt project filled my developer heart with bliss and thrill. I was intrigued by picking Programming language, Package manager, UI framework, Linting tools, Testing framework, Rendering mode, Deployment target, and Development tools. So far, so good. Try it yourself by running this yarn command <code>yarn create nuxt-app nuxt-blog</code>. If you want to generate a static website choose:</p>
<ul>
<li>Nuxt.js modules: Content</li>
<li>Rendering mode: Universal (SSR / SSG)</li>
</ul>
<p>When I opened the project in VSCode, it hit me, this was the right choice for my dev blog. I was sitting comfortably in front of a clean and developer-friendly directory structure. My markdown articles are stored in <code>content/articles</code>. The documentation of Nuxt and it's static module: Nuxt Content was easy to follow and lovely to read. They also have a nice <a href="https://nuxtjs.org/blog/creating-blog-with-nuxt-content" rel="nofollow noopener noreferrer" target="_blank">guide</a> for creating a blog using Nuxt content.</p>
<p>Listing out the articles is done in <code>pages/index.vue</code> and it roughly look like so:</p>
<div><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>posts__container<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span>
        <span>v-for</span><span><span>=</span><span>"</span>article of articles<span>"</span></span>
        <span>:key</span><span><span>=</span><span>"</span>article.slug<span>"</span></span>
        <span>class</span><span><span>=</span><span>"</span>post__container<span>"</span></span>
      <span>&gt;</span></span>
        <span><span><span>&lt;</span>NuxtLink</span>
          <span>class</span><span><span>=</span><span>"</span>post__link<span>"</span></span>
          <span>:to</span><span><span>=</span><span>"</span>{ name: <span>'</span>posts-slug<span>'</span>, params: { slug: article.slug } }<span>"</span></span>
        <span>&gt;</span></span>
          <span><span><span>&lt;</span>img</span>
            <span>class</span><span><span>=</span><span>"</span>post__image<span>"</span></span>
            <span>:src</span><span><span>=</span><span>"</span>article.featuredImage<span>"</span></span>
          <span>&gt;</span></span>
          <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
            <span><span><span>&lt;</span>h3</span> <span>class</span><span><span>=</span><span>"</span>post__title<span>"</span></span><span>&gt;</span></span>
              {{ article.title }}
            <span><span><span>&lt;/</span>h3</span><span>&gt;</span></span>
            <span><span><span>&lt;</span>p</span><span>&gt;</span></span>{{ article.description }}<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
          <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
          <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>post__date<span>"</span></span><span>&gt;</span></span>
            {{ article.date }}
          <span><span><span>&lt;/</span>span</span><span>&gt;</span></span>

          <span><span><span>&lt;</span>p</span><span>&gt;</span></span>
            {{ article.body.children[0].children[0].value }}
          <span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
        <span><span><span>&lt;/</span>NuxtLink</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>export</span> <span>default</span> <span>{</span>
  <span>async</span> <span>asyncData</span> <span>(</span><span><span>{</span> $content<span>,</span> params <span>}</span></span><span>)</span> <span>{</span>
    <span>const</span> articles <span>=</span> <span>await</span> <span>$content</span><span>(</span><span>'articles'</span><span>,</span> params<span>.</span><span>slug</span><span>)</span>
      <span>.</span><span>only</span><span>(</span><span>[</span><span>'title'</span><span>,</span> <span>'description'</span><span>,</span> <span>'featuredImage'</span><span>,</span> <span>'slug'</span><span>,</span> <span>'author'</span><span>,</span> <span>'date'</span><span>,</span> <span>'body'</span><span>]</span><span>)</span>
      <span>.</span><span>sortBy</span><span>(</span><span>'date'</span><span>,</span> <span>'desc'</span><span>)</span>
      <span>.</span><span>fetch</span><span>(</span><span>)</span>

    <span>return</span> <span>{</span>
      articles
    <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
</code></pre></div>
<p>Viewing a simple article is done in <code>pages/posts/_slug.vue</code>.</p>
<div><pre><code><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>article</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>img</span>
        <span>class</span><span><span>=</span><span>"</span>image__featured<span>"</span></span>
        <span>:src</span><span><span>=</span><span>"</span>article.featuredImage<span>"</span></span>
        <span>:alt</span><span><span>=</span><span>"</span>article.alt<span>"</span></span>
      <span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>article__container<span>"</span></span><span>&gt;</span></span>
        <span><span><span>&lt;</span>h1</span><span>&gt;</span></span>{{ article.title }}<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
        <span><span><span>&lt;</span>p</span> <span>class</span><span><span>=</span><span>"</span>article__date<span>"</span></span><span>&gt;</span></span>
          {{ article.date }}
        <span><span><span>&lt;/</span>p</span><span>&gt;</span></span>

        <span><span><span>&lt;</span>nuxt-content</span> <span>:document</span><span><span>=</span><span>"</span>article<span>"</span></span> <span>/&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>article</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
<span>export</span> <span>default</span> <span>{</span>
  <span>async</span> <span>asyncData</span> <span>(</span><span><span>{</span> $content<span>,</span> params <span>}</span></span><span>)</span> <span>{</span>
    <span>const</span> articles <span>=</span> <span>await</span> <span>$content</span><span>(</span><span>'articles'</span><span>)</span><span>.</span><span>where</span><span>(</span><span>{</span> slug<span>:</span> params<span>.</span><span>slug</span> <span>}</span><span>)</span><span>.</span><span>fetch</span><span>(</span><span>)</span>
    <span>const</span> article <span>=</span> articles<span>[</span><span>0</span><span>]</span>
    <span>return</span> <span>{</span> article <span>}</span>
  <span>}</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
</code></pre></div>
<h2 id="the-road-ahead">The road ahead</h2>
<p>So far I have been delighted developing the blog in Nuxt. If you already have a love for Vue, there is no need to evaluate other options, Nuxt is for you. My plan is to extend the site using Vue components and write more articles. But life can be busy so we will see how it goes.</p>
<p>That was it so I wish you all a happy new year and don't forget to wear a mask 😷.</p></div></div>]]>
            </description>
            <link>https://www.andreasrein.net/posts/hugo-to-nuxt</link>
            <guid isPermaLink="false">hacker-news-small-sites-25615627</guid>
            <pubDate>Sat, 02 Jan 2021 19:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upcoming Ruling in Assange Trial Threatens More Than Just Freedom of the Press]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25615595">thread link</a>) | @therockspush
<br/>
January 2, 2021 | https://covertactionmagazine.com/2021/01/02/upcoming-ruling-in-assange-trial-threatens-more-than-just-freedom-of-the-press/ | <a href="https://web.archive.org/web/*/https://covertactionmagazine.com/2021/01/02/upcoming-ruling-in-assange-trial-threatens-more-than-just-freedom-of-the-press/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<figure><img data-attachment-id="10875" data-permalink="https://covertactionmagazine.com/2021/01/02/upcoming-ruling-in-assange-trial-threatens-more-than-just-freedom-of-the-press/assange1a/" data-orig-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="assange1a" data-image-description="" data-medium-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?fit=696%2C522&amp;ssl=1" loading="lazy" width="696" height="522" src="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=696%2C522&amp;ssl=1" alt="" srcset="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?w=800&amp;ssl=1 800w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=150%2C113&amp;ssl=1 150w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=696%2C522&amp;ssl=1 696w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange1a.jpg?resize=265%2C198&amp;ssl=1 265w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Stella Moris and son Gabriel, right, and Max leave Belmarsh prison after visiting her partner and their father, Julian Assange. [Source: <a href="https://www.irishexaminer.com/world/arid-40037597.html">irishexaminer.com</a>]</figcaption></figure>



<p><strong>His two children could lose their father for the rest of their lives</strong></p>



<p>Although important legal principles are at stake in the extradition trial of Julian Assange, for which a ruling will be handed down on January 4, it should not be forgotten that there are important human issues at stake as well.&nbsp;</p>



<p>One such issue is Assange’s health, which has progressively worsened under what seems to be cruel and even sadistic maltreatment by the British government, including the refusal of appropriate medical care and confining him in his cell for 23 hours a day, seven days a week.&nbsp;</p>



<p>The other is that, if the Judge’s ruling is adverse, Julian’s two children may never see their father again.</p>



<p>Many stories have been written about the legal issues in Julian’s case, and the chilling effect that his extradition to the U.S.—where he will almost certainly be imprisoned for life—would have on journalists around the world who seek to expose the lies and crimes committed by their own governments.</p>



<p>Most of those stories present Julian, primarily, as a symbol, a hero to his principles, and an ominous example in how far tyrannical governments and corrupt politicians will go to keep their citizens ignorant and submissive.&nbsp;</p>



<p>But Julian is more than a symbol. He is also a father, a husband-to-be (even if he may have to be married in prison) and, most importantly, a human being—one who, as the world watches in horror and shame, is being subjected to calculated assaults on his physical and mental health in hopes that he will quickly die and spare the British and American governments the embarrassment of having to deal with him.</p>



<p>For nearly three years Assange and his partner, Stella Moris, had successfully kept their personal relationship and the existence of their two children a secret. Moris only revealed it (on April 11)&nbsp;because&nbsp;“Julian’s poor physical health puts him at serious risk, like many other&nbsp;vulnerable people, and I don’t believe he will survive infection with coronavirus”—which had been spreading rapidly through the British prison system, especially at Belmarsh, the high security prison in which Assange is being held.&nbsp;</p>



<figure><img data-attachment-id="10858" data-permalink="https://covertactionmagazine.com/assange2/" data-orig-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?fit=932%2C728&amp;ssl=1" data-orig-size="932,728" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="assange2" data-image-description="" data-medium-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?fit=300%2C234&amp;ssl=1" data-large-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?fit=696%2C544&amp;ssl=1" loading="lazy" width="696" height="544" src="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?resize=696%2C544&amp;ssl=1" alt="" srcset="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?w=932&amp;ssl=1 932w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?resize=300%2C234&amp;ssl=1 300w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?resize=768%2C600&amp;ssl=1 768w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?resize=150%2C117&amp;ssl=1 150w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange2.png?resize=696%2C544&amp;ssl=1 696w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>[Source: <a href="https://trevorfitzgibb1.medium.com/is-assange-about-to-be-epsteined-da6f736eb8c5">trevorfitzgibb1.medium.com</a>]</figcaption></figure>



<p>As a prison, Belmarsh has a very bad reputation, and is ordinarily reserved for the most violent and dangerous prisoners, which Assange was certainly not. Once known as <a href="https://www.businessinsider.com/julian-assange-being-held-in-uk-belmarsh-prison-known-as-britains-guantanamo-bay-2019-4">“Britain’s Guantanamo Bay,”</a> a number of its inmates participated in high profile terrorist attacks, and at least one ISIS executioner, nicknamed “<a href="https://www.independent.co.uk/news/uk/crime/terror-attacks-uk-prison-belmarsh-streatham-radicalisation-a9332531.html">Jihadi John”</a> resides there.</p>



<p>For much of his stay at Belmarsh, Assange has been forced to remain in his cell for 23 hours a day and has even been <a href="https://theintercept.com/2020/10/06/julian-assange-trial-extradition/">deprived of a radio</a>. Three prisoners have died at Belmarsh this year under unexplained circumstances, and another was discovered dead in his cell just last month.&nbsp;With Coronavirus spreading throughout the facility, the danger to Assange increases every day.</p>



<figure><img data-attachment-id="10859" data-permalink="https://covertactionmagazine.com/assange3/" data-orig-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?fit=936%2C702&amp;ssl=1" data-orig-size="936,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="assange3" data-image-description="" data-medium-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?fit=696%2C522&amp;ssl=1" loading="lazy" width="696" height="522" src="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=696%2C522&amp;ssl=1" alt="" srcset="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?w=936&amp;ssl=1 936w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=150%2C113&amp;ssl=1 150w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=696%2C522&amp;ssl=1 696w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange3.png?resize=265%2C198&amp;ssl=1 265w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Belmarsh prison, “Britain’s Guantanamo Bay” where Assange is being held. [Source: <a href="https://www.independent.co.uk/news/uk/crime/terror-attacks-uk-prison-belmarsh-streatham-radicalisation-a9332531.html">independent.co.uk</a>]</figcaption></figure>



<p>Noting Assange’s growing fragility, Moris said that, “I have discovered that love makes the most intolerable circumstances seem bearable but this is different, I am now terrified I will not see him alive again.”&nbsp;</p>



<p>Stella Moris, 37, is a South African-born attorney who met&nbsp;Assange in 2011, after she had been engaged by his legal team to help fight his extradition.</p>



<p>“Over time,” she said, “Julian and I developed a strong intellectual and emotional bond. He became my best friend and I became his.” Their actual relationship began in 2015, under what she described as “extraordinary circumstances.” They became engaged in 2017.</p>



<figure><img data-attachment-id="10860" data-permalink="https://covertactionmagazine.com/assange4/" data-orig-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?fit=936%2C620&amp;ssl=1" data-orig-size="936,620" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="assange4" data-image-description="" data-medium-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?fit=300%2C199&amp;ssl=1" data-large-file="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?fit=696%2C461&amp;ssl=1" loading="lazy" width="696" height="461" src="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?resize=696%2C461&amp;ssl=1" alt="" srcset="https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?w=936&amp;ssl=1 936w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?resize=300%2C199&amp;ssl=1 300w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?resize=768%2C509&amp;ssl=1 768w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?resize=150%2C99&amp;ssl=1 150w, https://i1.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange4.png?resize=696%2C461&amp;ssl=1 696w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Assange and Moris at the Ecuadorian embassy. [Source: <a href="https://www.wsws.org/en/articles/2020/04/13/assa-a13.html">wsws.org</a>]</figcaption></figure>



<p>Moris had been raising their two children on her own, as a single mother, and did her best to shield them from the harmful publicity she knew would surround them if their existence became known. But she changed her mind and finally went public, she said, because their lives were now “on the brink,” with Assange facing death every day as a result of his rapidly deteriorating health, which made him all the more vulnerable to the wave of Covid-19 spreading through Belmarsh.</p>



<p>“Julian has been fiercely protective of me and has done his best to shield me from the nightmares of his life,” she said. “I have lived quietly and privately, raising Gabriel and Max on my own and longing for the day we could be together as a family. Now I have to speak out because I can see that his life is on the brink.”</p>



<p>In a&nbsp;<a href="https://www.dailymail.co.uk/news/article-8210957/WikiLeaks-boss-Julian-Assange-fathered-two-children-inside-Ecuadorian-embassy-lawyer.html" target="_blank" rel="noreferrer noopener">video interview with the Daily Mail</a>, Moris revealed that, via a secret video hookup, Assange was able to observe the births of both of his children in real time, at the hospital in London. He later was also able to meet Gabriel in person after Moris smuggled him into the embassy, without revealing that Assange was the father.&nbsp;</p>



<figure><img data-attachment-id="10861" data-permalink="https://covertactionmagazine.com/assange5/" data-orig-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?fit=936%2C626&amp;ssl=1" data-orig-size="936,626" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="assange5" data-image-description="" data-medium-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?fit=300%2C201&amp;ssl=1" data-large-file="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?fit=696%2C465&amp;ssl=1" loading="lazy" width="696" height="465" src="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?resize=696%2C465&amp;ssl=1" alt="" srcset="https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?w=936&amp;ssl=1 936w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?resize=300%2C201&amp;ssl=1 300w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?resize=768%2C514&amp;ssl=1 768w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?resize=150%2C100&amp;ssl=1 150w, https://i0.wp.com/covertactionmagazine.com/wp-content/uploads/2021/01/assange5.png?resize=696%2C465&amp;ssl=1 696w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Assange with son Gabriel. [Source: <a href="https://www.msn.com/en-my/news/world/wikileaks-boss-julian-assange-fathered-two-children-inside-the-ecuadorian-embassy-with-lawyer-37-who-fell-in-love-with-him-while-helping-his-fight-against-extradition-to-the-us/ar-BB12uXkY">msn.com]</a></figcaption></figure>



<p>She further revealed that both boys had visited their father in prison, and that the couple planned to marry, even if Assange had to spend the rest of his life behind bars.</p>



<p>Moris says they were told by someone on the Ecuadorean embassy staff that the CIA (which had illegally planted spy cameras all over Assange’s quarters, including his bathroom) had tried to steal some of Gabriel’s DNA from his diaper because they suspected that Assange might be the father and wanted confirmation.</p>



<p>There were also reports that the U.S.&nbsp;plotted to kill Julian Assange and make it look like an accident, and that spies discussed kidnapping or poisoning him in the Ecuadorean embassy. That story appeared in the&nbsp;<a href="https://www.dailymail.co.uk/news/article-8041597/US-plotted-kill-Julian-Assange-make-look-like-accident.html" target="_blank" rel="noreferrer noopener">February 25 Daily Mail</a>, but was surprisingly (or not so surprisingly) not followed up by corporate media.&nbsp;</p>



<p>Although not often covered, the human side of Julian Assange, even when reported, has too often been presented by the media in lurid tabloid fashion, not for sympathy but for sensation.</p>



<p>There has, in fact, been precious little sympathy for Assange in the media, and as a result his case has not been widely—or fairly—covered. The BBC, especially, has virtually buried all mention of the trial, even though it is taking place in their own backyard, and will have a huge impact on the way their reporters will be able to cover the news in the future.</p>



<p>What we and the rest of the world—especially members of the working press—will now have to do is simply bite our nails until Judge Vanessa Baraitser (a notoriously “hanging judge” with a 96% record of approving extraditions) hands down her ruling on January 4.</p>



<div><figure><img data-attachment-id="8007" data-permalink="https://covertactionmagazine.com/?attachment_id=8007" data-orig-file="https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?fit=900%2C600&amp;ssl=1" data-orig-size="900,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="CAM-5" data-image-description="" data-medium-file="https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?fit=696%2C464&amp;ssl=1" loading="lazy" src="https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=30%2C20&amp;ssl=1" alt="" width="30" height="20" srcset="https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?w=900&amp;ssl=1 900w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=150%2C100&amp;ssl=1 150w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=218%2C150&amp;ssl=1 218w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=696%2C464&amp;ssl=1 696w, https://i2.wp.com/covertactionmagazine.com/wp-content/uploads/2020/09/CAM-5.jpg?resize=100%2C70&amp;ssl=1 100w" sizes="(max-width: 30px) 100vw, 30px" data-recalc-dims="1"></figure></div>



<hr>



<p><strong><a href="https://covertactionmagazine.com/author/stephenmbrown/">Steve Brown</a></strong> is a member of the Editorial Board of <em>CovertAction Magazine</em>.</p>



<hr>







<h2 id="block-64cb3d1b-8390-433a-a4ef-4eb0460e07dc"><span><em><strong>CovertAction Magazine</strong></em> is made possible by <strong><a rel="noreferrer noopener" href="https://covertactionmagazine.com/subscribe/" target="_blank">subscriptions</a></strong>, <strong><a rel="noreferrer noopener" href="https://covertactionmagazine.com/orders/" target="_blank">orders</a></strong> and&nbsp;<strong><a rel="noreferrer noopener" href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=SA3KBFLUKNW5E&amp;source=url" target="_blank">donations</a></strong>&nbsp;from readers like you.</span></h2>



<figure>
<table>
<tbody>
<tr>
<td data-align="center">&nbsp;</td>
<td data-align="center"></td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
</figure>



<div id="block-4d163e24-2402-41b2-809c-c3462f97ad4f"><p>When you donate to <strong>CovertAction</strong>, you are supporting investigative journalism.&nbsp;Your contributions go directly to supporting the development, production, editing, and dissemination of the Magazine.</p><p><em><strong>CovertAction Magazine</strong></em>&nbsp;does not receive corporate or government sponsorship and does not sell advertisements. Yet, we hold a steadfast commitment to providing compensation for writers, editorial and technical support. Your support helps facilitate this compensation&nbsp;as well as increase the caliber of this work.</p><p>Please make a donation by clicking on the donate logo above and typing in the amount and your credit or debit card information.</p><p><strong><em>CovertAction Magazine,</em></strong> <strong><em>CovertAction Quarterly</em></strong>&nbsp;and <strong><em>CovertAction Information Bulletin</em></strong> are projects of&nbsp;<strong>Covert Action Publications, Inc.</strong>, a not-for-profit organization incorporated in the State of New York.</p></div>



<h3 id="block-81ef0adf-47e6-483a-a318-b1ad6e5c8ab9"><strong><span>We sincerely thank you for your support.</span></strong></h3>



<p id="block-ba75ceca-1810-4c4c-b2ed-1e90e170967c"><strong>Disclaimer:</strong>&nbsp;The contents of this article are the sole responsibility of the author(s). Covert Action Publications, Inc. (CAP), including its Board of Directors (BD), Editorial Board (EB), Advisory Board (AB), staff, volunteers and its projects (including&nbsp;<em>CoverAction Magazine</em>) are not responsible for any inaccurate or incorrect statement in this article. This article also does not necessarily represent the views the BD, the EB, the AB, staff, volunteers, or any members of its projects.</p>



<p id="block-e8ee8eef-59bb-4766-8473-48785f70e5ea"><strong>Republishing:</strong><em> CovertAction Magazine</em> (CAM) grants permission to cross-post CAM articles on not-for-profit community internet sites as long as the source is acknowledged together with a hyperlink to the original&nbsp;<em>CoverAction Magazine</em> article. Also, kindly let us know at <a href="mailto:info@CovertActionMagazine.com">info@CovertActionMagazine.com</a>. For publication of CAM&nbsp;articles in print or other forms including commercial internet sites, contact: <a href="mailto:info@CovertActionMagazine.com">info@CovertActionMagazine.com</a>.</p>



<p id="block-42cfb5ce-6c15-4a03-8ff1-111d2cd10672"><strong>By using this site, you agree to these terms above.</strong></p>
        </div></div>]]>
            </description>
            <link>https://covertactionmagazine.com/2021/01/02/upcoming-ruling-in-assange-trial-threatens-more-than-just-freedom-of-the-press/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25615595</guid>
            <pubDate>Sat, 02 Jan 2021 19:25:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powerful Life Skills]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25615082">thread link</a>) | @hidden-spyder
<br/>
January 2, 2021 | https://neilkakkar.com/powerful-life-skills.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/powerful-life-skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Over the past few years, I’ve noticed certain skills in people I admire, from Paul Graham, Vitalik Buterin, to Ender Wiggin.</p>

<p>Most normal people like me don’t realise these are skills. This makes the skills powerful - not everyone can see them, and very few people have mastered them.</p>

<p>However, I aim to change that. What follows below are 10 skills sourced from admirable people that I want to develop this decade.</p>

<p>Powerful life skills make powerful people.</p>

<h2 id="learn-to-take-compounding-seriously">Learn to take compounding seriously</h2>

<p>It’s not just your wealth that compounds, but life experience and knowledge, too.</p>

<p>So, learn the most basic, most useful skills first. The longer you wait to learn skills like these, the less time there is for compounding magic. That’s what this entire list is about: powerful skills to learn and use for the rest of your life.</p>

<p>And even though you’ve heard about compounding, this item is first on the list, because <a href="https://neilkakkar.com/taking-ideas-seriously.html">taking ideas seriously is hard</a>.</p>

<p>A good way to figure out what compounds is <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">to figure out what’s a platform</a>.</p>

<h2 id="learn-to-develop-taste">Learn to develop taste</h2>

<p>Despite prevalent beliefs, taste isn’t subjective.</p>

<p>While it may seem like it on the outside, when you say “I just love this painting” or “I just love this coffee machine” - all it means is that the defining characteristics are illegible to you. And noticing this is the first step.</p>

<p>Let’s take a specific example. Say you’re designing a high quality clay pot - and you’ve never done this before.</p>

<p>What’s a good way to develop taste for quality here?</p>

<p>If you’ve heard this claypot parable, you know the answer: start by making lots of crap pots.</p>

<blockquote>
  <div><p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A,” forty pounds a “B,” and so on. Those being graded on “quality,” however, needed to produce only one pot—albeit a perfect one—to get an “A.”</p><p>

Well, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work—and learning from their mistakes—the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. - <a href="https://amzn.to/3o9o17A" target="_blank" rel="noopener">Art and Fear</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p></div>
</blockquote>

<p>Let others tell you what you’ve made is crap. Learn why. Notice when they tell you something is great. Figure out why.</p>

<p>This transfers to writing as well: Popular advice to get better is to write a lot of junk, do it a 100 times, and pay particular attention to what is received well. Here’s <a href="http://www.paulgraham.com/taste.html" target="_blank" rel="noopener">another example - developing taste for design</a>.</p>

<p>In effect, you bootstrap good taste by first learning what others consider good. Then, <a href="#learn-to-see-systems">you see the system behind it</a>. Then you break the rules and still manage to awe.</p>

<p>Then you’ve developed taste.</p>

<h2 id="learn-to-sequence-things-well">Learn to sequence things well</h2>

<p>Waking up when others are asleep and getting lots done is a super power. It’s born out of a system of <a href="https://neilkakkar.com/sequencing-things-in-the-right-order.html">learning to sequence things well</a>.</p>

<p>It means choosing the right time for that Netflix binge.</p>

<p>It means being prepared before the meeting, not scrambling to get things done after.</p>

<p>It means reading the coursebook before the lecture, not after.</p>

<h2 id="learn-to-see-what-others-see">Learn to see what others see</h2>

<p>How well can you understand other people? Can you sense their desires, their concerns, and what events lead to those desires and concerns?</p>

<p>If you can do this, you can understand them. But not before.</p>

<blockquote>
  <p>In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it’s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. - <a href="https://amzn.to/2KKe8Px" target="_blank" rel="noopener">Ender’s Game</a><sup id="fnref:1"><a href="#fn:1">2</a></sup></p>
</blockquote>

<p>It’s worth going this far because understanding is powerful. It helps you empathise. It helps you negotiate. It helps you figure out why you don’t have product-market fit. It helps you learn quickly: you can switch through personas and see what will and won’t work.</p>

<p>How do you do learn to see? I know no better way than to practice. Try it a 100 times. <a href="https://neilkakkar.com/subscribe">Come back next year</a>, and maybe I’ll have a better way once I’ve done it a 100 times.</p>

<h2 id="learn-to-make-and-execute-decisions-quickly">Learn to make and execute decisions quickly</h2>

<p>Most people have a bias towards analysis-paralysis versus getting shit done.</p>

<p>When decisions are reversible - and they mostly are - speed is a super power. Cultivating a habit of making decisions quickly, and then executing them is better than just thinking about it.</p>

<p>Training this skill begins as easily as deciding what to eat on a huge menu. It’s a small step, but over time, <a href="#learn-to-take-compounding-seriously">even the smallest steps compound</a>.</p>

<blockquote>
  <p>“Hesitation is always easy, rarely useful” - Prof. Quirrel alterego, <a href="http://www.hpmor.com/" target="_blank" rel="noopener">HPMOR</a></p>
</blockquote>

<p>Here’s an <a href="https://firstround.com/review/speed-as-a-habit/" target="_blank" rel="noopener">example in the context of business</a>. And a <a href="https://twitter.com/sama/status/1345140364995227648" target="_blank" rel="noopener">tweet from Sam Altman</a>.</p>

<h2 id="learn-to-spot-a-convex-or-concave-world">Learn to spot a convex or concave world</h2>

<p>In the world of viral infections, a 50% lockdown is worse than a 0% and a 100% lockdown, both. The virus isn’t contained, and businesses have to shut down, too.</p>

<p>In the world of immigration policies, letting some specific people in is better than letting no one or everyone in. The middle ground is better than the extremes.</p>

<p>When the best of both worlds is great, you’re in a concave disposition.</p>

<p>When the best of both worlds is worse than either, you’re in a convex disposition.</p>

<p>The world is sometimes concave, and sometimes convex. Knowing your topology can help you make better decisions.</p>

<p>I first noted this when <a href="https://vitalik.ca/general/2020/11/08/concave.html" target="_blank" rel="noopener">Vitalik Buterin explained it</a>. Read it for more concrete examples.</p>

<!-- ## Learn to do obvious things -->

<h2 id="learn-to-tell-stories">Learn to tell stories</h2>

<p>People donate more to charity when they know a single victim’s story, versus statistics of a thousand deaths. It’s called the <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a>, but it’s the power of stories over facts. The right framing gets you further than all the facts combined.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.”</p>
</blockquote>

<p>Ideas &amp; facts contextualised by stories are more powerful than either alone.</p>

<p><i></i><b>The Skill of Storytelling</b><br>
There’s lots to unpack here, and this is the first skill I’ve been working on for the past few months. Watch out for a long blogpost in 2 weeks!</p>

<h2 id="learn-to-dive-into-the-source-code-when-documentation-isnt-enough">Learn to dive into the source code when documentation isn’t enough</h2>

<p>Sometimes, there’s no precedent for what you want to do. Or the people who did it before didn’t write a manual.</p>

<p>In cases like these, figuring things out for yourself is powerful. Research papers and obscure books aren’t just for scientists. They’re freely available on the internet* for all of humanity to use. Learn to use it. Learn about resources like <a href="https://sci-hub.do/" target="_blank" rel="noopener">SciHub</a>, <a href="https://libgen.xyz/" target="_blank" rel="noopener">LibGen</a>, and hiring researchers. You’re allowed to hire people (specially graduate students!) to satisfy your research concerns.</p>

<p>… and when you’re done, <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html#writing-code">preserve context for future you</a>.</p>

<p>It’s a lot like trying to use an API that has no documentation. Would’ve been easy if there was documentation, but there isn’t. So you got to do it the hard way: read the source code and figure out what you need to make things work.</p>

<p>It’s also like <a href="https://neilkakkar.com/A-framework-for-First-Principles-Thinking.html">figuring out what you need to build rockets yourself</a> when existing ones are too expensive.</p>

<p><a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" target="_blank" rel="noopener">More resources here</a>.</p>

<h2 id="learn-to-be-specific">Learn to be specific</h2>

<p>Every time I gave an example above, I was training my specificity muscles.</p>

<p>Most of the time, most people don’t know what they’re talking about. Not being specific is a sign of that. The more abstract the word, the harder it is to pin down a meaning.</p>

<p>For example, “negative ramifications” doesn’t tell you what exactly happened, while “the sonic boom from the new supersonic jet destroyed windows in a 100m radius” is a lot more specific.</p>

<p>Learn to be specific, and learn to spot when others aren’t. <a href="https://www.lesswrong.com/posts/NgtYDP3ZtLJaM248W/sotw-be-specific" target="_blank" rel="noopener">Here’s how</a>.</p>

<h2 id="learn-to-see-systems">Learn to see systems</h2>

<p>There’s two kinds of people.</p>

<ul>
  <li>Bob, who will see this list, find some skills very interesting, and then go about honing those skills</li>
  <li>Alice, who will see this list, and wonder how I came up with these
<!-- - The Inspiration-Junkie, who will lurk and move on to the next inspiring post without changing anything -->
</li>
</ul>

<p>Alice would then try to understand the system that generated these ideas. Then, she’ll adopt the system, and come up with skills possibly more relevant to herself.</p>

<p>Having the option to do both is powerful. Since Bob is the default, <a href="https://neilkakkar.com/How-to-see-Systems-in-everyday-life.html">learn to be like Alice</a>. Choose <a href="https://neilkakkar.com/understanding-systems.html">systems when things are important</a> to you. Choose hacks when you need a quickfix.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>



    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/powerful-life-skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25615082</guid>
            <pubDate>Sat, 02 Jan 2021 18:32:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning to Write (On the Internet)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25614714">thread link</a>) | @n2parko
<br/>
January 2, 2021 | https://n2parko.com/p/learning-to-write-on-the-internet | <a href="https://web.archive.org/web/*/https://n2parko.com/p/learning-to-write-on-the-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've had the same New Years Resolution for the last three years. Write More. And every year, for the past three years, December would roll around and I would have inevitably...well...not written. There were a series of impediments that always seemed to stand in the way. Not enough time. Not knowing what to write about. Fear of writing uninspiring or boring essays.</p><p>This post marks the 12th essay I've written &amp; published in 2020. One post a month (though I started late and crammed in December). I have <em>finally</em> fulfilled my writing resolution of 2017 🙌</p><p>I've found writing to be an incredibly fulfilling way to spend my quarantine, and I want to share the practical lessons I've learned from (most failing) to develop a writing habit. There's plenty of good resources on how to write (recommend <a href="https://www.julian.com/guide/write/intro">here</a>, <a href="https://moretothat.com/visual-storytelling/">here</a>, <a href="https://www.amazon.com/Writing-10th-Anniversary-Memoir-Craft/dp/1439156816">here</a>, <a href="http://www.paulgraham.com/useful.html">here</a>), so this isn't meant to be a comprehensive how-to guide for starting a blog. </p><p>But if you're thinking about starting a writing habit in 2021 or stuck in a rut on your writing, here's how I overcame it.</p><h2>Multiplayer Writing &gt; Single Player</h2><p>There was one takeaway that rose above the rest: writing is better when you write with others. Your essays will get better with crit and revisions, yes, but the experience of creating the essay is more fun when you write with friends.</p><p>The trope of the recluse writer returning from the cabin with a masterpiece in hand is eclipsed many-fold by the press rooms, the writers workshops, the smokey Parisian writing clubs. For many years I thought I needed a cabin and some quiet, when in reality I needed a crowded and busy writers’ room.</p><p>We started a writing community in our work slack channel for people trying to write more (#yolo-writers). It became a place where you can share a rough draft and get honest feedback on it. It created accountability (and FOMO) when everyone is sharing their drafts and publishing. It's a messy exchange of ideas on all kinds of topics that people are thinking about, but there is no shortage of new connections and ways of thinking about the idea.</p><p>Having a personal "editorial board" is helpful for a few reasons. The first is that it builds confidence, because you share your post with someone who is not you and they will typically have (at least some) nice things to say. The second is that they help you unpack the important pieces of the post.</p><p>Our #yolo-writers channel turned writing from single-player game into a multi-player game.</p><h2>Build Your Writing Funnel</h2><p>One of the ways a "funnel", or series of steps you need to go through to get your ideas out into the world:</p><ol><li><p><strong>Idea</strong> - first you need to pick something to write about, which can be a challenge if there are no constraints.</p></li><li><p><strong>Draft</strong> - this is where you take your idea and bang out a first draft. It requires hands on the keyboard, good space to think, and a touch of inspiration</p></li><li><p><strong>Edit</strong> - You need to take what is unlikely a good first draft and turn it into something that you think is valuable (either to the reader, or yourself)</p></li><li><p><strong>Publish &amp; Share</strong> - You need to hit the <code>Publish</code> button, and see the post live on the internet, and share it with folks</p></li></ol><p>By thinking about your essays as a funnel, you can figure out where you are jammed. Do you not have enough ideas? Are you not converting those ideas into drafts? Does it take too long to edit them?</p><p>Here's a snapshot of my writing funnel stats. You can see that I have a backlog of ideas for blog posts, a bunch of active drafts, a few in the Editing, and 11 published.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5871fd6-c6b6-48fd-a506-7f71550377e5_1666x1028.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5871fd6-c6b6-48fd-a506-7f71550377e5_1666x1028.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d5871fd6-c6b6-48fd-a506-7f71550377e5_1666x1028.png&quot;,&quot;height&quot;:898,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:60680,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>This is a pretty different approach to writing than what I've come across in school or work. In those contexts, there is a clear assignment and corresponding topic. There's a due date. With personal writing and essays, all of these constraints are relaxed so you can pick ideas up write, and edit as you please.</p><h3>Ideas 💡</h3><p>I have many more <strong>Ideas</strong> than I have <strong>Drafts</strong>. That's because (a) many of my Ideas are not actually interesting enough to warrant an essay and (b) it's a lot easier to add an idea to my list than to write an essay.</p><p>I like to have a place to put ideas as they come up. I have a Notion writing board and I'll create a new post with the headline as the idea, and link to whatever made me think of the idea. Sometimes I'll add some initial thoughts, but at this point I really just want to capture the idea and return to it later when I'm ready to write.</p><p>There's a great segment on <a href="https://www.thisamericanlife.org/348/tough-room">This American Life</a>, where Ira Glass goes into the writers room at The Onion. The writers go through a brutal process every week of creating over 600 headlines for the satirical paper, only to whittle the list down to 16 articles that actually get written.  The problem is that many of the <em><strong>headlines</strong></em> are funny on the surface, but there's no depth to the joke.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F71cc5073-c3a5-4b3c-90d2-6a14212a150f_1486x896.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F71cc5073-c3a5-4b3c-90d2-6a14212a150f_1486x896.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/71cc5073-c3a5-4b3c-90d2-6a14212a150f_1486x896.png&quot;,&quot;height&quot;:878,&quot;width&quot;:1456,&quot;resizeWidth&quot;:573,&quot;bytes&quot;:377452,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>https://www.thisamericanlife.org/426/transcript</figcaption></figure></div><p>I've found the same with essay ideas. By the numbers, only about 1 in 5 of my ideas have actually materialized into an essay. This isn't from a lack of trying, many of them just don't go anywhere. Which means that ~80% of the ideas I think are good at the time, turn out to not be viable ideas at all! </p><p>Ideas will come throughout the day — on a run, in a meeting — so it's good to have an easy way to capture and figure out if it's a good idea later. </p><p>What topics should you write about? "Write whatever you want!" is not super helpful, but is the reality when starting out. This turned out to be the biggest impediments for me when getting this project off the ground. I didn't think I had a unique perspective on a particular topic. But I was pleasantly surprised to see how that vague concern came crumbling down.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F589359e1-c537-4ecc-8974-7a7c912a1971_2198x546.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F589359e1-c537-4ecc-8974-7a7c912a1971_2198x546.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/589359e1-c537-4ecc-8974-7a7c912a1971_2198x546.png&quot;,&quot;height&quot;:362,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:123850,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>Snapshot of my writing funnel…Ideas column is a dumping ground to mine later</figcaption></figure></div><p>It turns out that nobody sees and thinks about the world the way you do. Every thought and problem you've solved is unique to your experience. By sharing your experience, you can hear from others who have faced similar challenges and came to different conclusions, or can use your experience to guide their own.</p><p>There is a specific type of idea that I've found really fulfilling, and easy to write. "Project" posts document a specific project that you've attempted. It can be big, or small, functional, creative, engineering, art, analytics, home improvement. It doesn't matter. <a href="https://n2parko.com/p/select-robinhood-stocks">Abstract Capital</a> and <a href="https://n2parko.com/p/squatbot">Squatbot</a> are two examples this where the bulk of the work is in working on the project. Just make sure you document as you go!</p><h3>Draft ✍️</h3><p>Once I had an ideas board going, I'd pick an idea and write a first draft.</p><p>Your first draft is going to suck. You will probably despise the idea by the time you are finished with your first draft. You will regret your decision to write at all. It's pretty painful.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F906aed2d-470a-4aa9-a120-ca783abe8209_1288x754.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F906aed2d-470a-4aa9-a120-ca783abe8209_1288x754.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/906aed2d-470a-4aa9-a120-ca783abe8209_1288x754.png&quot;,&quot;height&quot;:754,&quot;width&quot;:1288,&quot;resizeWidth&quot;:603,&quot;bytes&quot;:152585,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>The emotional rollercoaster of writing a new essay</figcaption></figure></div><p>As I write these words, I am filled with self-doubt. <em>Is this point I'm making here so obvious? What do I know about blogging?</em> It's natural in the draft stage to feel impostor Syndrome. Push through.</p><p>The best advice I can share is to think of this draft as <a href="https://42floors.com/blog/startups/thirty-percent-feedback">30% "done"-ness</a> of what you will eventually publish. This can help alleviate some of the self-inflicted doubts and writer's block that comes with aiming for perfection. Your goal is to sketch out the idea, not to write a Pulitzer-winning piece.</p><p>I've found weekend mornings — after the first cup of coffee begins to kick in —  to be the best time to pull up my ideas board and start drafting.</p><h3>Edit ✂️</h3><p>Next comes the editing process. I like to let my Drafts air out on the shelf for a day or two after writing. I'll re-read and edit for clarity, before sharing with my "editorial board" (aka #yolo-writers)</p><p>At work, we created a slack channel called #yolo-writers with a few folks who were interested in writing more. Whenever anyone is ready for feedback, they share in the channel and a few people respond with feedback. We loosely follow the "ABCD" framework for giving feedback:</p><p>Here's an example of the type of feedback you can get in #yolo-writers (from <a href="https://twitter.com/osamakhn">Osama</a>): </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd688e751-7a8b-4d7d-ba58-43f8f1bd912f_1392x666.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd688e751-7a8b-4d7d-ba58-43f8f1bd912f_1392x666.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d688e751-7a8b-4d7d-ba58-43f8f1bd912f_1392x666.png&quot;,&quot;height&quot;:666,&quot;width&quot;:1392,&quot;resizeWidth&quot;:635,&quot;bytes&quot;:289524,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>some great questions you’ll get from an honest editor </figcaption></figure></div><h3>Publish &amp; Share 🖨️</h3><p>Hit the button! I am admittedly not great at marketing what I write. I write because it's personally fulfilling and helps clarify my thinking, so I'll point you to some strategies that Lenny Rachitsky recommends on building <a href="https://www.youtube.com/watch?v=EaeuZAqJwEY">his newsletter community</a>. But it's a really great feeling when someone references or engages with something that you wrote. Remember that feeling next time you're procrastinating or feeling embarrassed about a draft.</p><h2>KYSS</h2><p>Keep Your Stack Simple. KYSS. I repeat: Keep Your Stack Simple.</p><p>There was a point during the year where I was running Google Lighthouse tests to figure out how to optimize my page load performance for a <a href="https://github.com/ijjk/notion-blog">Next.js app running on Vercel powered by a Notion backend</a>. I wanted some analytics so I got Segment implemented and built a dashboard in Amplitude.</p><p>Worrying about my writing tech stack turned out to be a very good way to distract myself from <em>actually</em> writing. This is a common trap I've seen others fall into. My only advice is to recognize that this is a means of procrastinating, take a break instead of falling down an optimization rabbit hole, and come back when you're ready to write.</p><p>In the end, I simplified:</p><ul><li><p>I write and edit in <a href="https://n2parko.com/p/www.notion.so">Notion</a></p></li><li><p>I draw diagrams in <a href="https://excalidraw.com/">Excalidraw</a></p></li><li><p>I publish on <a href="https://n2parko.com/">Substack</a></p></li></ul><p>There's a bit of copy-pasting between Notion —&gt; Substack to get a post live, but I like being able to keep the Writing Funnel on a board in Notion and prefer the editor.</p><h2>Write for Your Why</h2><p>There are a lot of reasons to write more. It can help clarify your thinking, sharpen your ideas, build your community, release the pent up ideas in your brain. Reflecting on the reason <em><strong>why</strong></em> you're picking up a writing habit can help quell the internal excuses that are preventing you from doing it. At the end of the day, the <em>why</em> is personal.</p><p>If you are just getting started...don't write for others, write for yourself! The biggest mental blocker I had was in trying to fulfill some vague expectation of (future, imaginary) readers...when in reality, the value came from the messy exchange of ideas …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://n2parko.com/p/learning-to-write-on-the-internet">https://n2parko.com/p/learning-to-write-on-the-internet</a></em></p>]]>
            </description>
            <link>https://n2parko.com/p/learning-to-write-on-the-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25614714</guid>
            <pubDate>Sat, 02 Jan 2021 17:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing Money: A Functional Trilemma for the Digital Age]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25614264">thread link</a>) | @eevoy
<br/>
January 2, 2021 | http://thinking.farm/essays/2020-12-29-designing-money/ | <a href="https://web.archive.org/web/*/http://thinking.farm/essays/2020-12-29-designing-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body-container"><div id="content">
<section id="main-single">
    <article>

        <h2><a href="http://thinking.farm/essays/2020-12-29-designing-money/">Designing Money: A Functional Trilemma for the Digital Age</a></h2>
            
            <section id="single-content">
                <p><em><strong>TL;DR: We need a new way to understand moneyâ€”instead of discussing what money is we are best served by clarifying what money does. I propose a trilemma of functions that money can support:</strong></em></p>
<ul>
<li><em><strong>adaptive supply</strong></em></li>
<li><em><strong>durable value</strong></em></li>
<li><em><strong>stable peg</strong></em></li>
</ul>
<p><em><strong>Fiat moneys support adaptive supply and value durabilityâ€”these are good media of exchange. Collateral moneys support value durability and peg stabilityâ€”these are good stores of value. Rebasing moneys support adaptive supply and peg stabilityâ€”these are good units of account.</strong></em></p>
<p><em><strong>Moneys that try to support all three functions are fragile and inevitably break, reverting to their most stable configurations. Fiat moneys with managed exchange rates eventually revert to pure fiat and give up peg stability, often through painful devaluations. Collateral moneys with fractional reserves eventually revert to full collateralization and give up adaptive supply, shrinking the money supply in circulation, often trigerring financial panics and crises.</strong></em></p>
<p><em><strong>More importantly, this fragility remains regardless of the size of the money supplyâ€”it cannot be eliminated by â€œbootstrappingâ€� or â€œgrowingâ€� out of it.</strong></em></p>
<h2 id="introduction">Introduction</h2>
<p>It is time to do away with the conventional economistsâ€™ definition of money as a unit of account, store of value, and medium of exchange. For one, is a definition derived from myths about the origins of money, positing a progression from barter and the problem of coincidence of wants, to free trade and precious metals. More importantly, the definition is useless when it comes to designing money, leading to endless debates about what counts as money, not how it could be made.</p>
<h2 id="a-new-typologythe-functional-trilemma">A new typologyâ€”the functional trilemma</h2>
<p>I believe it is time to focus less on what money <strong>is</strong> and more on what money <strong>does</strong>. Thus, I propose a new typology based on a trilemma of three functions that money can supportâ€”adaptive supply, durable value, and a stable peg. In the long-run, each money can only support two of these functions. Those that try to support all three will inevitably revert back to their most robust two-function configuration, like how a rubber band stretched over three pegs might slip to just two.</p>
<p>We can derive the traditional economics definition and classify historical monetary systems just by combining these three functions. More importantly, the functional trilemma is a map to the design limitations of digital money, and highlights the fragility that will break the newest generation of â€œstablecoinâ€� protocols, which try to do too much.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/trilemma.jpeg" width="100%"> 
</figure>

<p>Let us define these three functions in more detail. By adaptive supply, I mean that supply is a function of demand: \(\ S=f(D) \). By durable valueI mean that the purchasing power of a money stock stays constant across time:\(\ v_t (S) = v_{t+n} (S) \). By stable peg I mean that the measured purchasing power of a single money unit stays constant across time: \(\ v_t (unit) = v_{t+n} (unit) \).</p>
<h2 id="fiat-collateral-and-rebasing-moneys">Fiat, collateral, and rebasing moneys</h2>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/fiat.jpeg" width="100%"> 
</figure>

<p>Letâ€™s flesh the trilemma with three robust classes of money designsâ€”fiat, collateral, and rebasing moneys. We can represent them with some examples from traditional and digital finance:the US dollar (USD), USD Coin (USDC) , and Ampleforth (Ample/AMPL).</p>
<p>Fiat moneys are the easiest to understand: 1) their supply is modulated by the authorities to meet demand, and 2) the purchasing power of the total stock of money, in the long run, is stable over time. Monetary policy, for the most part, produces changes in consumer or asset price levels, as well as a redistribution of resources, but cannot change the long-run level of economic activity. For these reasons, pure fiat currencies have free floating exchange rates–that is, they cannot support a stable peg.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/collateral.jpeg" width="100%"> 
</figure>

<p>Collateral moneys like USDC or currency boards with convertibility (also called redeemability) have 1) a stable peg, since convertibility into the reserve assets anchors the price, and 2) durable value, since each unit is backed by an exact quantity of the reserve asset, and is constant across time. In the case of USDC, each coin is backed by exactly one USD. Collateral moneys are the quintessential â€œstores of valueâ€�â€”many emerging market residents prefer that their national currency have a hard peg, as it guarantees that their savings and investments can retain their value over time, instead of suffering from inflation and devaluation.</p>
<p>Collateral moneys do not have adaptive supply, however. They can only mint or redeem money according to the amount of assets in their reserves. In a true specie standard, this was determined by the supply of gold or silver. In the age of the dollar, the reserves are held in dollars or other qualifying foreign exchange. In the case of USDC, the supply is a strict function of the amount of USD locked into custodian institutions, the same is true of wrapped Bitcoin (wBTC). Neither USDC or wBTC supply are functions of market demand for USDC or wBTC.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/rebasing.jpeg" width="100%"> 
</figure>

<p>Lastly, consider what it would mean for a money to have both adaptive supply and a stable pegâ€”this combination is the trickiest one of them all, because it is so unintuitive, and historically rare. These are rebasing moneys.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/ampl-illustration.jpg" width="100%"> <figcaption>
            <h4>Illustration of automatically changing AMPL balances over time (Ampleforth.org)</h4>
        </figcaption>
</figure>

<p>The Ampleforth protocol adjusts the balances in owners’ wallets–this is a process called rebasing. When demand for Amples is high, the number of AMPL in wallets increases, and when demand is low, the number of AMPL decreases–so I might have 1 AMPL today, 3 tomorrow, and 2 the day after. Physically, this system is impossible to recreate, though Nobel Prize-winning economist James Buchanan dreamed of such an automatically adjusting digital money in the late 1950s. He imagined it would be run out of a massive mainframe, to which the keys to change its code had been destroyed, making it tamper-proof.</p>
<p>So far 1) the purchasing power of a single AMPL has remained more or less equal to the 2019 USD (when it was launched), and 2) the AMPL supply is responsive to demand. However, the purchasing power of the AMPL money stock has not remained constantâ€”it has risen and fallen, sometimes by more than an order of magnitude!</p>
<p>From a historical perspective, Amples have some similarity to the â€œvirtual tael/silverâ€� or <em>xuliang/xuyin</em> è™›å…©/è™›éŠ€ of the Qing Empire. During the Qing, the empireâ€™s vast majority of circulating media of commercial exchange were copper cash éŒ¢. Cash was the preferred money in the countryside where over 90% of the population worked. In cities and interregional trade lived a zoo of silver ingots called taels, as well as silver and gold coins, all minted locally or abroad. It took historians a long time to understand this financial system and how it worked without a unified territorial currency. Though assaying was sometimes used, for the most part taels and coins circulated at different prices in different regions. Thus, two taels or coins by different mints, even if they have the same silver content, could carry different prices.</p>
<p>The empireâ€™s Board of Revenue, however, kept its books in a unit called the <em>kuping tael</em> åº«å¹³å…©â€”taxes had to be settled and remitted in this unit. Long-dated commercial contracts were also in <em>kupingliang</em>. The price of silver and copper coins might fluctuate depending on how many were being minted or melted down, but the government and the private sector certainly thought contracts in <em>kupingliang</em> were more stable in value. Organizations rarely kept assets physically in this unit, which is why they were called â€œvirtualâ€� (though è™› also means “false”). To settle contracts or taxes one could either buy the <em>kupingliang</em> on the market, or the receiving authority could â€œconvertâ€� a payment into <em>kupingliang</em> at a rate of their choosing or estimate. Digital money is different because this second option is not availableâ€”smart contracts require the actual token in question to be settled. So a contract denominated in AMPL needs AMPL tokens to settle!</p>
<h2 id="two-is-company-three-is-a-fragile-crowd">Two is company, three is a (fragile) crowd</h2>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/econ.jpeg" width="100%"> 
</figure>

<p>We can see from this excursion that the Economics 101 three-part definition of money is mistaken–money does NOT have to simultaneously satisfy all three properties! In fact, good money designs are robust because they are great at just one thing–whether that is as a store of value, medium of exchange, or unit of account. How is that the case? The economists definition’s three parts are actually equivalent to the two-function combinations embedded in the trilemma: fiat moneys are great media of exchange, collateral moneys are the best stores of value, and rebasing moneys are the ideal units of account. Since moneys can only robustly support two of three functions in the trilemma, this means that historical moneys robustly fulfilled only one part of the Economics 101 definition. <strong>In fact, history shows that moneys which try to fulfill all three functions inevitably have to snap back into a robust two-function configuration.</strong> In other words, to be robust, money has to focus on a fiat, collateral, or rebasing design.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/managed.jpeg" width="100%"> 
</figure>

<p>Well, what about a fiat system with a managed peg, one might say? Most fiat currencies today have a â€œmanaged float,â€� where the central bank intervenes in foreign exchange markets to anchor the price of its money. But the arrangement is unstableâ€”it cannot last forever, and historically pegs have always broken down, usually when the central bank runs out of reserves. In those moments, the true nature of the system is revealed. In the case of the Mexican 1994 crisis or the Asian financial crisis of 1997, these currencies were exposed as true fiat moneys when they gave up their fixed exchange rates.</p>
<figure>
    <img src="http://thinking.farm/2020-12-29-designing-money/fractional.jpeg" width="100%"> 
</figure>

<p>Something similar happens with collateral moneys that try to make their supply more responsive to money demand. A classic situation is …</p></section></article></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thinking.farm/essays/2020-12-29-designing-money/">http://thinking.farm/essays/2020-12-29-designing-money/</a></em></p>]]>
            </description>
            <link>http://thinking.farm/essays/2020-12-29-designing-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25614264</guid>
            <pubDate>Sat, 02 Jan 2021 17:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Technology in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25614086">thread link</a>) | @yarapavan
<br/>
January 2, 2021 | https://elidourado.com/blog/notes-on-technology-2020s/ | <a href="https://web.archive.org/web/*/https://elidourado.com/blog/notes-on-technology-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content"><p>As we start a new decade, it’s a good time to reflect on expectations for the next 10 years. Tyler thinks the Great Stagnation <a href="https://marginalrevolution.com/marginalrevolution/2020/12/why-did-the-great-stagnation-end.html">could be ending</a>. Caleb sees <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">cracks</a>. Noah expresses <a href="https://noahpinion.substack.com/p/techno-optimism-for-the-2020s">techno-optimism</a>. In this post, my aim is not to predict an end or non-end to stagnation. Rather, it is to think through the particulars of how technology could evolve over the next decade. Then we can assess separately whether we should consider it the Roaring 20s or the Boring 20s.</p><p>What would constitute an end to the Great Stagnation? Any precise cutoff will be arbitrary, but for the sake of discussion, let’s say sustained growth in <a href="https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/">utilization-adjusted total factor productivity</a> of 2 percent per year. By comparison, mean utilization-adjusted TFP growth from 1947 through 1972 was 2.1 percent. Since 2005, it has been 0.17 percent. (Note: it is important to use the utilization-adjusted series, as this corrects for the business cycle.)</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a7a8a1d9e4c4d1050c2902966a316436559074f1/cd6b6/img/tfp.png" alt="Total factor productivity in the U.S. since 1947" title="Total factor productivity in the U.S. since 1947"></p><p>Whatever your cutoff for TFP growth, one of my convictions is that scientific breakthroughs alone are not enough to drive an end to the Great Stagnation. TFP only budges when new technologies are adopted at scale, and generally this means products, not just science. Science lays critical groundwork for new technology, but after all the science is done, much work remains. Someone must shepherd the breakthrough to the product stage, where it can actually affect TFP. This means building businesses, surmounting regulatory obstacles, and scaling production.</p><p>With that caveat firmly in mind, what will the next decade bring in terms of meaningful technological change? Here’s what I’m watching.</p><h2 id="biotech-and-health">Biotech and health</h2><p>We are coming off a huge win: two new mRNA COVID vaccines, conceived and brought to market in less than a year. The ability to encode and deploy arbitrary mRNA in our bodies sure seems like a game changer—it allows us to essentially program our cells to make whatever proteins we want. In the case of the COVID vaccines, the vaccine payload instructs our cells to make the coronavirus spike protein, which our immune system then learns to attack. Bert Hubert has a <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">fascinating write-up</a> of the “code” in the vaccine.</p><p>Bringing a brand new vaccine to market in less than a year—using a never-before-applied-in-humans-at-scale technology no less—is a world record, but it could have been even faster. As David Wallace-Wells <a href="https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html">emphasizes</a>, Moderna’s vaccine was designed by January 13. We had it the whole time. Some delay was necessary to determine effective dosing. Some further regulatory delay may have been warranted to ensure the vaccine was safe and to ascertain its efficacy. But as Wallace-Wells indicates, the regulatory outcome was never really in doubt. “None of the scientists I spoke to for this story were at all surprised by either outcome,” he writes. “All said they expected the vaccines were safe and effective all along.”</p><p>What should we make of the fact that all of the scientists knew all along that Moderna’s vaccine would work? The question in my mind is: what other mRNA treatments do we have the whole time? What if I told you Moderna has an <a href="https://www.poz.com/article/experimental-hiv-vaccine-stimulates-production-neutralizing-antibodies">HIV vaccine candidate</a>? HIV lacks SARS-CoV-2’s telltale spike protein and thus may prove a more challenging foe—but don’t you wonder, if we treated the problem with real urgency, whether new mRNA technology could wipe out the AIDS epidemic this decade? I do.</p><p>And mRNA technology can be deployed against more than just viruses. Both Moderna and BioNTech have personalized vaccine candidates targeting cancer. Although called a “cancer vaccine,” the treatment is only administered once the subject has cancer—it isn’t preventative. The companies use an algorithm to analyze the genetic sequences of the tumor and the patient’s healthy cells and predict which molecules could be used to generate a strong immune response against the cancer. “I was actually witnessing the cancer cells shrinking before my eyes,” <a href="https://www.nature.com/articles/d41586-019-03072-8">said</a> Brad Kremer, a melanoma patient who received the BioNTech treatment. So let’s milk mRNA technology for all it’s worth this decade. It can save us from more than just a pandemic.</p><p>What about CRISPR? It is a great example of a technology that has not yet made a meaningful economic contribution. Although the technique for editing DNA was discovered in 2012—and a Nobel Prize was awarded to its two discoverers this year—no treatment using CRISPR has been approved outside of clinical trials. So far, its impact has been limited to making researchers more productive—not a bad thing, to be sure, but not close to CRISPR’s full potential. As trials progress, however, I do think some CRISPR treatments will come online in the next few years, especially those targeting genetic disorders that we have very limited means of otherwise treating.</p><p>DeepMind’s <a href="https://medium.com/cgo-benchmark/deepminds-protein-folding-solution-what-just-happened-279d32e8d0f">protein-folding breakthrough</a> signals a promising decade for the science of proteomics. Most directly, being able to predict protein shapes will enable us to discover drugs more rapidly. Buuuut, because drug trials take many years, we might expect this technology not to really be felt by the general public until the 2030s.</p><p>What DeepMind’s achievement indicates to me the most is that machine learning is actually useful. This might seem obvious, but consider: most applications of machine learning so far—excluding autonomous vehicles, which have themselves not really arrived yet—are toys. I love watching AlphaZero crush Stockfish on YouTube, but chess is literally a game. GPT-3 produced some fun demos. AlphaFold heralds something different—non-toy superhuman performance is now here, and I am interested to see what else it can do. Aside from the aforementioned AVs, I expect it to be applied widely in other areas of biology. Again, it will take a long time for the breakthroughs to trickle down into products, but at least the 2030s should be sick. I mean, not sick. Healthy.</p><p>Let’s talk about life extension, one of my favorite biotech topics. 2020 was a big year for the Conboy Lab at Berkeley, which proved that all the weird past findings about “<a href="https://en.wikipedia.org/wiki/Parabiosis">young blood</a>” extending life were not actually due to any elixir in the blood of children (thank goodness). Rather, the rejuvenating aspects of young blood experiments were due to the dilution of harmful factors in old blood. By mechanically removing plasma and replacing it with saline and enough albumin to replace what was taken out, they diluted aged blood factors in both mice and humans and were able to <a href="https://www.aging-us.com/article/103418/text#fulltext">rejuvenate germ layer tissues</a> and <a href="https://link.springer.com/article/10.1007/s11357-020-00297-8">improve cognition by reducing neuroinflammation</a>.</p><p>These findings are exciting not only because they represent a scientific advance in understanding aging, but also because they herald the first real anti-aging product that could come to market. Therapeutic plasma exchange is FDA-approved (not for aging, but for a bunch of other conditions). I imagine there remain prohibitions on advertising that it can add years to your life, but it is safe, and a doctor can prescribe it off label. It’s also cheap. An automated plasmapheresis machine—which lets you do treatment after treatment—can be bought online for under $3,000. That is less than the cost of a single transfusion of young blood sold by the startup <a href="https://www.ambrosiaplasma.com/">Ambrosia</a>. How long until someone opens a clinic offering plasma dilution? I bet someone tries it in 2021. If it works, people will get over the weirdness, and it could be commonplace by 2030.</p><p>Another longevity product that is about to get hot: aging clocks based on DNA methylation or proteomics. Do you want to know how biologically old you are? Today, for a few hundred dollars, you can get a test that will tell you. As these tests become better and cheaper, self-experimenters are going to have a field day. Doing before-and-after aging tests, anyone who can get their hands on human growth hormone could replicate the protocol used by <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/acel.13028">Fahy et al.</a> to rejuvenate the thymus. As the thymus is a critical element of the immune system, decline of which is a critical factor in aging, this is non-trivial rejuvenation. The Fahy study found that 12 months of treatment created about 2.5 years of epigenetic rejuvenation, with results accelerating in the last quarter of the trial.</p><p>There is a lot more in the <a href="https://www.lifespan.io/road-maps/the-rejuvenation-roadmap/">Rejuvenation Roadmap</a>—dozens of possible life-extending treatments are at various stages of development. There’s a good chance a few senolytic drugs will be approved by the end of the decade. As I noted <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">yesterday at Fortune</a>, we spend less than 1% of the NIH budget on aging biology—we should raise that by a lot.</p><p>Unlike others, I am not-so-bullish on metformin. It does seem to reduce all-cause mortality in Americans, but it may do so because <a href="https://www.liebertpub.com/doi/10.1089/met.2018.0105">88% of Americans are metabolically unhealthy</a>. If you are one of the 12%, and you should strive to be, I don’t think metformin will do much for you.</p><p>One final biotech observation: every year, the Apple Watch gets a new health-related sensor. This year it was blood oxygen, pretty good for detecting if you might have COVID! Fast forward to 2030 and wearables will have at least 10 more health-related sensors than they do today. Some no-brainers are body temperature, blood pressure, and blood glucose sensors. What will the other 7 be? At some point, it becomes possible to replace a lot of primary care with continuous monitoring. A few smart algorithms to provide simple medical advice could improve population-level health without much cost. More data could also yield faster, more accurate, and of course more remote diagnoses when you do have to see a doctor.</p><p>There is a lot in biotech that is promising right now, but in more than any other field, it is important not to be seduced by the sexy headlines showing rapid scientific progress. Don’t get complacent. Biology is proceeding faster than medical productivity because a lot of the wonderful discoveries are not being translated into approved treatments and products at a decent rate. Let’s salute and cheer for the discoveries, but spare many thoughts for the entrepreneurs trying to bring treatments to market.</p><h2 id="energy">Energy</h2><p>The 2010s were the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elidourado.com/blog/notes-on-technology-2020s/">https://elidourado.com/blog/notes-on-technology-2020s/</a></em></p>]]>
            </description>
            <link>https://elidourado.com/blog/notes-on-technology-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25614086</guid>
            <pubDate>Sat, 02 Jan 2021 16:51:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamicland Geokit: Augmented Reality Maps]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25613847">thread link</a>) | @tobestobestobes
<br/>
January 2, 2021 | https://omar.website/posts/notes-from-dynamicland-geokit/ | <a href="https://web.archive.org/web/*/https://omar.website/posts/notes-from-dynamicland-geokit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      



<p>Hey ___,</p>

<p>I know you've been curious about some of the stuff I've done at
<a href="https://dynamicland.org/">Dynamicland</a>. It might be a while until you
can make it out here and visit in person, so I'll try to explain one
project of mine, Geokit, from top to bottom, to give you some of the
flavor.</p>

<p>I'll discuss what Geokit actually is and what you do with it
first, and then I'll explain how it's made. That explanation might
help you understand how people make things in Dynamicland in
general. It's the kind of detail that isn't covered in the zine or on
the Dynamicland website.</p>

<p>I sort of hope you read this, come here yourself, and reimplement
Geokit better.</p>

<h2 id="what-geokit-is">What Geokit is</h2>

<p><img src="https://omar.website/posts/notes-from-dynamicland-geokit/tweet.jpg">
</p>

<p>Geokit is a 'kit' or 'library' for building and viewing maps.</p>

<p>One Dynamicland researcher, <a href="https://twitter.com/lukexi">Luke
Iannini</a>, writes about his experiences
with Geokit:</p>

<blockquote>
<p>The real estate group that owns the building Dynamicland lives in
uses their purchasing power to influence the city to improve
infrastructure to the underserved areas of Oakland they develop
in. The head of this initiative was visiting the space, and she
began describing her work while we were gathered around the lunch
table, which happened to have Geokit spread across it looking at
Oakland. Without breaking the flow of conversation, I dealt the
transit card to display the bus routes, and she grabbed the “zoom
and pan dial”<sup id="fnref:dial"><a rel="footnote" href="#fn:dial">1</a></sup> without any instruction to zoom in on a portion
of West Oakland — noticing a huge hole in route coverage she’d never
seen before where she knew there were tons of working families. We
spent the next 15 minutes exploring as she taught me more about the
city's transit details than I ever knew I wanted to know.</p>

<p>In another case at a party I learned that a person I’d just met grew
up in the same city as me (Tucson, AZ) when she searched for it to
print it out, and we then bonded deeply over looking at the
incredibly stark racial divisions in North and South Tucson that we
knew from experience but had never seen laid out in raw data.</p>

<p>I’ve never had experiences like these in any other medium. Buildings
don’t tend to have detailed racial, transit and elevation maps of
every city in the US on the walls. In theory you could pull this
data up on your personal iPad, praying there aren’t any embarrassing
notifications and hopefully remembering what you were even going to
look at by the time you’re past the lock screen looking at 24
rainbow-gradient icons and red bubbles, but I am personally not in
the habit of pulling out my devices in the middle of parties. In
both of these cases these just-dynamic-enough maps were <em>places</em> at
the party, just like the appetizers table and the piano, where
people could casually gather, play and converse.</p>
</blockquote>

<p>Geokit lives on a shelf when it's not in use, so I'll take it off the
shelf and lay it out on a table:</p>

<div>
<iframe width="90%" height="315" src="https://www.youtube-nocookie.com/embed/_MENkVUZq54?showinfo=0&amp;ecver=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p>Taking Geokit off the shelf. Some other kits below it; <a href="https://twitter.com/smd4/status/1002410711354523648">general tools</a> on
the right</p>
</div>

<h3 id="geokit-in-action">Geokit in action</h3>

<p>I'm going to pull up a map of San Francisco and zoom into Dolores
Park.</p>

<p>I'll start by typing into the "Geomap above from place search" page,
which turns the giant blank page above it into a map.</p>

<div>
<video controls="">
  <source src="https://omar.website/posts/notes-from-dynamicland-geokit/typing-place-search.mp4" type="video/mp4">
</video>
<p>Typing places into Geokit and seeing maps</p>
</div>

<p>If you were here in person, I'd hand <em>you</em> the keyboard, and I bet
you'd want to type your hometown in. But I'll just use San Francisco.</p>

<p>OK, now I want to zoom in to the park. I have a tool for zooming, the
"Map magnifier with IR (infrared) dial" page (the smaller page on the
right). When I put that page on the table, it becomes a zoomed-in
'inset map.'</p>

<div>
<p><img src="https://omar.website/posts/notes-from-dynamicland-geokit/ir-dial-labeled.jpg"></p><p>Inset map (right) shows a zoomed-in view of the dial's
location on the big map (left)</p>
</div>

<p>I also have to put this rotating dial on the big map of SF, which
controls both the location and zoom level of the inset map. Moving the
dial pans the inset map, and rotating the dial zooms it in and
out. Being able to
<a href="https://en.wikipedia.org/wiki/Direct_manipulation_interface">directly</a>
move the map position is really satisfying.</p>

<p>In this next clip, I put the dial down and then pan over and zoom the
inset map to Dolores Park in the Mission.</p>

<div>
<video controls="">
  <source src="https://omar.website/posts/notes-from-dynamicland-geokit/ir-dial.mp4" type="video/mp4">
</video>
<p>Using the dial to pan and zoom the inset map to Dolores Park</p>
</div>

<p>Now I'm curious about this part of the neighborhood. How diverse is
it?  How has it changed over time? Are there stark dividing lines?
I'll apply some data layers: a color-coded demographic map (<a href="https://demographics.virginia.edu/DotMap/">"racial
dot map"</a>), and then street
lines and labels on top so the map is more understandable. I point
them at the big map first, then point them at the zoomed map (just to
show that both work).</p>

<div>
<video controls="">
  <source src="https://omar.website/posts/notes-from-dynamicland-geokit/ir-dial-tilelayers.mp4" type="video/mp4">
</video>
<p>Applying tilelayer overlays to the big map and then
just to the inset map</p>
</div>

<div>
<p><img src="https://omar.website/posts/notes-from-dynamicland-geokit/dolores-park-racial-dot-map.jpg"></p><p>Seeing demographics around Dolores Park by pointing
the "Demographic dots tilelayer" page at the inset map. The color legend is
written on that tilelayer page – an advantage of using real paper
rather than a screen</p>
</div>

<p>Check out how the west (toward Castro) is bluer on the inset map,
while the east (toward Mission) is more orange.<sup id="fnref:census"><a rel="footnote" href="#fn:census">2</a></sup> Imagine
having multiple people at the table: each person might have their
personal view on smaller pages, but the table can all share the big
map at the center.</p>

<h4 id="zoom-lenses">Zoom lenses</h4>

<p>To be honest, this whole project started with a <a href="https://omar.website/posts/notes-from-dynamicland-geokit/zoom-lens-series.jpg">very clear
image</a> I had in my head. I wanted to make <em>zoom
lenses</em>, where you could point a lens at a map to zoom into it, then
point a lens at that lens... so I want to show you those lenses now.</p>

<div>
<iframe width="90%" height="315" src="https://www.youtube-nocookie.com/embed/awHtInUjPBQ?showinfo=0&amp;ecver=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p>Applying a zoom lens to the inset map, then
applying a zoom lens to that zoom lens</p>
</div>

<p>You can see me playing with the OpenPTMap (public transport) tilelayer
as I mess with zoom, applying it here and there at various zoom levels
(it propagates down from wherever I put it). The layer shows some bus
lines, as well as the J-Church light rail line.<sup id="fnref:whitespots"><a rel="footnote" href="#fn:whitespots">3</a></sup> I'm
trying to get the <em>flexibility</em> of these tools across to you: layers
work everywhere and zoom works everywhere, and you can pull a tool out
and use it wherever and whenever you want.</p>

<p>Here's my play on <a href="https://en.wikipedia.org/wiki/Powers_of_Ten_(film)">Powers of
Ten</a> in Geokit:
starting from the Earth, I apply a zoom lens, then a lens to that
lens, and so on, until I get down to our neighborhood in Oakland.</p>



<p>I can even print a map. I have a printed map of San Francisco here,
for instance. I use exactly the same tools on this printout: I look at
public transit lines, then demographics, then I zoom and pan around
east of Golden Gate Park.</p>

<div>
<iframe width="90%" height="315" src="https://www.youtube-nocookie.com/embed/nfDOzBiwvuE?showinfo=0&amp;ecver=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p>Working with a printed map: applying tilelayers
and zoom lens
</p></div>

<p>Even if Geokit isn't drawing any tiles on a map and it's just a
printout, it's still a fully functioning map.</p>

<div>
<blockquote data-lang="en"><div lang="en" dir="ltr"><p>…and a "map" page is just any page which represents a (lon1, lat1, lon2, lat2) geographic box, even if it doesn't render any tiles!</p><p>(e.g. the printed maps are still meaningful maps even though there is no projection on them)</p></div>— Omar Rizwan (@rsnous) <a href="https://twitter.com/rsnous/status/990405274526662656?ref_src=twsrc%5Etfw">April 29, 2018</a></blockquote>
</div>

<p>I've been using San Francisco as an example, but I could have entered
any place in the world, and everything would have worked exactly the
same.<sup id="fnref:except"><a rel="footnote" href="#fn:except">4</a></sup></p>

<p>The one-page 'engine' page makes all these maps and tools work, and
that little engine doesn't need to know anything about the stuff built
above it. Basically, the engine takes a page representing some
geographic coordinates, and it draws some map tiles from the Internet
on top. I'll show how you might build that engine from scratch here in
Dynamicland, step by step.</p>

<h3 id="all-the-parts">All the parts</h3>

<p>These are all the 'game pieces' inside the kit. Each page is both a
little computer program and an <em>object</em> that people and other pages
can see and work with. Some pages are face-down, but most of them are
face-up, which means they're running right now. (Face-up is the side
with the colored dots.)</p>



<p>You often <strong>point</strong> one page at another to make it do something, like
how the <em>zoom lens</em> points at the <em>printed map</em>, or how the <em>keyboard</em>
points at the <em>text box</em> which points at the <em>big map</em>.</p>

<p>We have a few ways to get a map of a place:</p>

<ul>
<li>⌨️<strong>type a place name</strong> into the text box to search for it</li>
<li>use a premade map like my <strong>📄 printed map</strong> of SF</li>
<li>apply the <strong>🔍 zoom lens</strong> to an existing map: the lens becomes a zoomed-in map
of the green region it points at</li>
<li>use the <strong>🎛 zoom &amp; pan dial</strong> ('loupe') page on an existing map: it zooms into
wherever the dial is, and you rotate the dial to change the zoom
level</li>
</ul>

<p>These parts are the ones in the kit right now, but anyone here can
make new parts: you could come here and write up a new kind of
tilelayer or a new way to make maps.</p>

<p>That's why I call Geokit a kit and not an application: it's naturally
extensible. You could come here, pull a keyboard off the shelf, point
it at any part of Geokit, and just start editing it and printing new
stuff for your own use. You might provide a new tileset to answer some
question you have, or come up with a new zoom mechanism to derive
maps. (I'll explain how to do both of those things in this writeup!)
You have the same status that I do, and you don't have to open your
laptop and download and recompile some source code if you want to
change something.</p>

<h2 id="background-on-realtalk">Background on Realtalk</h2>

<p><a href="https://dynamicland.org/">Dynamicland</a> is a place – a land – in
Oakland, California.</p>

<p><a href="https://harc.ycr.org/project/realtalk/">Realtalk</a> is the programming
system that runs inside Dynamicland. It includes a superset of the
<a href="https://en.wikipedia.org/wiki/Lua_(programming_language)">Lua programming
language</a>. You
do 'pure' computation in Lua, but you use special Realtalk extensions
to do all communication with other pages and with the outside world.</p>

<div>
<p><img src="https://omar.website/posts/notes-from-dynamicland-geokit/realtalk-cheat-sheet.png"></p><p>An overview of Realtalk concepts and syntax, by
<a href="https://twitter.com/telogram">Tabitha Yong</a></p>
</div>

<p>The Realtalk 'operating system' already knows about some wishes as
part of its standard library, so we can say things like <code>Wish (you) is
labelled "Bella".</code> and <code>Wish (you) is highlighted "green".</code> and they
work right away. But we can also make up our own claims and wishes:</p>
<div><pre><span></span><span>-- Made-up claim demo</span>
Claim (you) blahblahblah.

<span>-- Made-up claim when demo</span>
When <span>/</span>page<span>/</span> blahblahblah:
    Wish (page) is highlighted <span>"blue"</span>.
End
</pre></div>

<div>
<p><a href="https://omar.website/posts/notes-from-dynamicland-geokit/made-up-claim.jpg"><img src="https://omar.website/posts/notes-from-dynamicland-geokit/made-up-claim.jpg"></a></p><p>Acting on claim syntax that I just made up (<a href="https://omar.website/posts/notes-from-dynamicland-geokit/made-up-claim.jpg">full size</a>)</p>
</div>

<p>Why is "Made-up claim demo" highlighted in blue? What will happen if I
flip "Made-up claim when demo" face-down?</p>

<h3 id="realtalk-and-the-rest-of-dynamicland">Realtalk and the rest of Dynamicland</h3>

<p>I'm mainly going to discuss Realtalk here, so I'm writing in a form
that will look almost like any other tutorial about how to do a</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omar.website/posts/notes-from-dynamicland-geokit/">https://omar.website/posts/notes-from-dynamicland-geokit/</a></em></p>]]>
            </description>
            <link>https://omar.website/posts/notes-from-dynamicland-geokit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613847</guid>
            <pubDate>Sat, 02 Jan 2021 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seek Ideas at the Right Level of Abstraction (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25613713">thread link</a>) | @TRC_0FF
<br/>
January 2, 2021 | https://commoncog.com/blog/the-right-level-of-abstraction/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/the-right-level-of-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>One of the more intriguing qualities of the most effective people I know is that they tend have an ability to think ‘at the right level of abstraction’. Not too high; not too low. Just right for the problem they’re solving.</p><p>Historically, I haven’t been very good at this.</p><p>When I first moved to Vietnam, I wrote a personal essay about betting on Asia. The piece was logically coherent and tightly argued, but it was also laughably wrong. I argued that Asia was the future. I argued that a young person of Asian descent would do better to learn how to build companies in Asia; that the problems of Asia were different from the problems of Silicon Valley. I argued that if you wanted to build a tech company under such constraints, an Asian startup should be focused on Asian problems: the larger, the more valuable, and the more overlooked by Silicon Valley, the better. I used manufacturing as a thought experiment.</p><p>But I was wrong.</p><p>It wasn’t that any of these points were necessarily <em>mistaken</em> — arguably, the most successful Asian startups were started by Asian people and built to solve Asian problems. (This is the problem with tightly argued generalities: they often contain truisms). The issue with my argument was that it was simply <em>irrelevant</em> — it didn’t matter if all of these things were true. It didn’t matter that the centre of global power was shifting East; it didn’t matter that venture capital didn’t give a shit about Asia in 2014 but changed its mind quickly; it didn’t matter that Asian unicorns would emerge over the course of the 2010s. I was too small to take advantage of any of these shifts. I was a young person moving into a job. I was thinking at the wrong level of abstraction.</p><p>Much later, I discovered an old nut by investors Warren Buffett and Charlie Munger, which they named the Noah Rule (after the <a href="https://en.wikipedia.org/wiki/Noah">biblical story</a>): ‘predicting rain doesn’t count, building an ark does’. To hijack that aphorism a little, I was essentially gesticulating at all the storm clouds in the horizon, reporting on the shapes of the cumulonimbuses, telling everyone who would listen about the coming thunderstorm. But I had no carpentry skills to speak of; I couldn't take advantage of any of these analyses. It was a waste of time.</p><h2 id="reasoning-at-the-wrong-level">Reasoning at the Wrong Level</h2><p>I occasionally talk to juniors from my alma mater. They tend to be interested in a conversation after learning that I write a blog about careers; on my end, I’m more than happy to talk to them so I can hear about the changes that have occurred in the School of Computing, which I loved.</p><p>One common pattern that emerges from those conversations are versions of the same reasoning that led me to write my <em>Because Asia</em> essay. The arguments tend to be made by incredibly smart, analytical people: my juniors would explain to me that venture capital in Asia is under-developed, or that Singapore is a terrible place to work in because of bad incentives for remote FAANG offices, or perhaps that Singapore will be caught between Great Power conflict, or perhaps its advantages in the first 50 years of its life no longer hold true for the next 50. They then conclude that perhaps it would be better to move out from Singapore, and seek their fortunes elsewhere.</p><p>The arguments tend to be well-articulated, intelligent analyses of macro-level trends. But I now suspect they are wasteful attempts at thinking. Like my essay about Asian startups, the arguments operate at the wrong level of abstraction — wrong, that is, for the decisions these people are to make.</p><p>It doesn’t matter if Singapore is geopolitically challenged, or that it faces new challenges in the 2020s or that VC money is skipping SG entirely and flowing into Indonesia. What matters for these students are questions at a lower level of abstraction: “What are my career goals, and which companies may I work at to advance towards those goals?” along with “What are the market/regulatory/economic shifts that are <em>affecting those companies directly</em>?” These questions operate at the right level of abstraction. Commentary about macro-economic trends do not.</p><p>Why? I think the answer is obvious when you think about it for a bit: macro-economic shifts trickle a long way down, through a complex system, before they become local trends. These shifts may or may not result in the outcomes you expect. So if you operate at a much lower level in the system, and you want to make a decision about your career, you should probably pay attention to the local trends <em>first</em>, without thinking about the macro-economic shifts that may or may not have led to them.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Another way of thinking about this is that proximate causes (the cause immediately preceding an event) are easier to reason about than remote causes (causes that are further away from the event at question, but that contribute through the chain of causality). Remote causes are often complex and intertwined with a huge number of factors (think: the Fed raising the interest rate, and affecting the whole economy in one fell swoop); proximate causes are simpler to think about. And so it is usually more effective to focus on proximate causes, because any change in the macro-environment that will affect you will likely show up as a proximate cause <em>first</em>. The way I like to think about this is that remote causes are akin to the interactions of water molecules in a vapour cloud — you’ll have to spend a huge amount of analytical power to figure out if they’ll ultimately affect your windows. The effective person won’t bother with any of that; they would instead watch for the movement of water droplets on glass.</p><p>I mentioned previously that I ran a software engineering office in Vietnam, and that none of the trends that I wrote about in my Asia essay ultimately mattered to my stint there. What ended up being important were the following shifts:</p><ul><li>Regulatory changes by the Singapore government, that affected our customers.</li><li>What our customers did (these were mostly retail companies; so we paid attention to things that affected them — including what their landlords were doing.)</li><li>What our competitors did.</li><li>The shape of the labour market in Vietnam, where I had to hire from.</li></ul><p>It's mistaken to think that analysis of these topics are <em>always</em> less time consuming than macro-level analysis — in reality, some investigations demanded about the same amount of time and energy that you might have expected from a study of geopolitical trends.</p><p>But they were two important differences:</p><ol><li>These topics sat at the ‘right’ level of abstraction — it was nearer to the business, and therefore nearer to the decisions that we had to make. This made them more useful.</li><li>I couldn’t use any of these insights to sound smart in normal conversation. The intelligence was hard-won, but too specific to our industry to be interesting to most of my friends.</li></ol><h2 id="an-appreciation-for-complex-adaptive-systems">An Appreciation for Complex Adaptive Systems</h2><p>There’s another explanation for the effect that I think is worth talking about.</p><p>Many of the systems we operate in are complex adaptive systems. They are:</p><ol><li>Complex, for they consist of many interweaving parts.</li><li>Adaptive, for they consist of many agents that compete, cooperate, and adapt to each other.</li><li>A system, for these interconnected elements may be said to be coherently organised.</li></ol><p>Complex adaptive systems lie at the heart of a field of study we now call ‘complexity science’. The most approachable popular introduction to the field of complexity science is M. Mitchell Waldrop’s <a href="https://www.goodreads.com/book/show/337123.Complexity"><em>Complexity</em></a>, which examines the founding of The Santa Fe Institute — a multi-disciplinary research organisation set up to study such systems.</p><p>The book explains complex adaptive systems as follows (forgive this long excerpt; Waldrop has a tendency to drag explanations out to make them more palatable):</p><blockquote>(…) the economy is an example par excellence of what the Santa Fe Institute had come to call “complex adaptive systems.” In the natural world such systems included brains, immune systems, ecologies, cells, developing embryos, and ant colonies. In the human world they included cultural and social systems such as political parties or scientific communities. Once you learned how to recognize them, in fact, these systems were everywhere. But wherever you found them, said Holland, they all seemed to share certain crucial properties.<p>First, he said, each of these systems is a network of many “agents” acting in parallel. In a brain the agents are nerve cells, in an ecology the agents are species, in a cell the agents are organelles such as the nucleus and the mitochondria, in an embryo the agents are cells, and so on. In an economy, the agents might be individuals or households. Or if you were looking at business cycles, the agents might be firms. And if you were looking at international trade, the agents might even be whole nations. But regardless of how you define them, each agent finds itself in an environment produced by its interactions with the other agents in the system. It is constantly acting and reacting to what the other agents are doing. And because of that, essentially nothing in its environment is fixed.</p><p>Furthermore, said Holland, the control of a complex adaptive system tends to be highly dispersed. There is no master neuron in the brain, for example, nor is there any master cell within a developing embryo. If there is to be any coherent behavior in the system, it has to arise from competition and cooperation among the agents themselves. This is true even in an economy. Ask any president trying to cope with a stubborn recession: no matter what Washington does to fiddle with interest rates and tax policy and the money supply, the overall behavior of the economy is still the result of myriad economic decisions made every day by millions of individual people.</p><p>Second, said Holland, a complex adaptive system has many levels of organization, with agents at any one level serving as the building blocks for agents at a higher level. A group of proteins, lipids, and nucleic acids will form a cell, a group of cells will form a …</p></blockquote></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/the-right-level-of-abstraction/">https://commoncog.com/blog/the-right-level-of-abstraction/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/the-right-level-of-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613713</guid>
            <pubDate>Sat, 02 Jan 2021 16:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving the 1973 Unix text to voice translator]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25613576">thread link</a>) | @chrisparnin
<br/>
January 2, 2021 | https://www.spinellis.gr/blog/20210102/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20210102/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>The early Research Edition Unix versions featured a program that would turn a stream of ASCII text into utterances that could be played by a voice synthesizer. The source code of this program was lost for years. Here's the story of how I brought it back to life.</p>
<h3 id="finding-the-lost-code">Finding the lost code</h3>
<p>The (early 1973) Third Research Edition of Unix <a href="https://dspinellis.github.io/unix-v3man/v3man.pdf#page=130">documented</a> a program that would receive as input ASCII text and convert it into phonemes that could then be played by a <a href="https://en.wikipedia.org/wiki/Votrax">Votrax</a> voice synthesizer made by the Vocal Interface Division of Federal Screw Works. The program was written by <a href="https://en.wikipedia.org/wiki/Douglas_McIlroy">M. D. McIlroy</a>, who documented its operation in a detailed <a href="https://www.cs.dartmouth.edu/~doug/speak.tar">technical report</a>.</p>
<p>Although the program appeared in the Unix manual pages up to the 1975 <a href="https://ia800600.us.archive.org/19/items/v6-manual/v6-manual.pdf#page=251">Sixth Research Edition</a>, its source code was missing from the archives that had survived. Even its author lacked a copy.</p>
<p>Fortunately, in 2011, Jonathan Gevaryahu <a href="https://web.archive.org/web/20140620170452/https://minnie.tuhs.org/pipermail/tuhs/2011-December/002538.html">found</a> most parts of the program's source code in unallocated space of a Sixth Research Edition disk dump. (This means that the code was once stored on disk, but was later deleted, and the parts where it resided were never allocated to other uses.) Even better, he could reconstruct a single block that was missing from the program's compiled version, which was also available. Based on these findings, I added the <a href="https://github.com/dspinellis/unix-history-repo/blob/Research-V6-Snapshot-Development/usr/source/s2/speak.c">speak source code</a> and the <a href="https://github.com/dspinellis/unix-history-repo/blob/Research-V6-Snapshot-Development/usr/source/s2/speak.v">speech rules</a> to the <a href="https://github.com/dspinellis/unix-history-repo">GiHub repository of Unix history</a> I am maintaining.</p>
<h3 id="reviving-the-code">Reviving the code</h3>
<p>To see how the program was working, I experimented with making it run and compile. As the program was written in an ancient dialect of C and was also unlikely to be portable, I first tried to make it work on a Sixth Edition Unix running on a <a href="https://en.wikipedia.org/wiki/SIMH">SIMH</a> PDP-11 emulator. This attempt quickly failed, because the console wasn't reliable enough to allow me to transfer the code via copy-paste.</p>
<p>I then run the PDP-11 2.11 BSD Unix on the same emulator, which offers rudimentary internet connection capabilities. After configuring a <code>.rhosts</code> file to allow remote copying (to obtain remote access, you simply add your remote host and user name), I was able to move the code to that machine.</p>
<p>However, compiling the code wasn't immediately possible. To make it compile I</p>
<ul>
<li>changed the old <code>=+</code>, <code>=^</code> to the modern <code>+=</code>, <code>^=</code> operators,</li>
<li>added forward declarations for functions returning pointers,</li>
<li>inserted an assignment operator in initialized constants (<code>int tflag 0;</code> became <code>int tflag = 0;</code> — I didn't even know this form ever existed),</li>
<li>changed calls from <code>seek</code> to <code>lseek</code>, and</li>
<li>added a proper exit code to <code>exit</code>.</li>
</ul>
<p>At that stage the program could compile, but was crashing when I tried to run it. Given that 2.11 BSD lacked <em>gdb</em> and was generally slow and difficult to use, I decided to port the program to modern Unix/Linux. I also added more declarations, including full function prototypes to find other problems. (In early versions of C you didn't need to declare a function before using it.) I then methodically removed all compiler warnings, which allowed me to pinpoint a variable that was declared as a pointer but used as an integer. By correcting its declaration I fixed the initial crash.</p>
<p>Now I had a program that compiled and run, but was still crashing in some cases, and also wasn't producing correct output. For this further changes were needed.</p>
<ul>
<li>I replaced writing to a string with a write to a <code>char</code> array.</li>
<li>I corrected the size of a structure that was assumed to be 4.</li>
<li>I documented some functions to be able to follow the program logic.</li>
<li>I fixed the assumption that integers occupied two bytes.</li>
<li>I replaced integers initialized as pairs of characters (e.g. <code>'u1'</code>) with a macro that initialized the value in an endian-neutral manner.</li>
</ul>
<p>After these changes the program was able to compile the rules file and produce <a href="https://www.tuhs.org/Archive/Distributions/Research/Dennis_v5/v5man.pdf#page=285">Votrax phoneme codes</a>.</p>
<h3 id="getting-voice-output">Getting voice output</h3>
<p>Votrax voice synthesizers and their descendant chips (which appear to use similar phoneme codes) <a href="http://www.redcedar.com/sc01.htm">are not longer marketed</a>. In order to listen to the generated voice I needed a workaround. My first attempt was to use samples from the <a href="https://github.com/sealj553/votrax-speak">votrax-speak GitHub repository</a>. Converting the phoneme Votrax codes into their mnemonic names, and passing the corresponding sample files as arguments to <a href="https://en.wikipedia.org/wiki/SoX">SoX</a>, allowed me to create a sound file consisting of the phonemes played together. However, the generated sound file was almost unintelligible. As I read later, a great advantage of Votrax synthesizers was how they merged together the phonemes into continuous speech, which was not the case with my approach.</p>
<p>My second attempt involved using the phoneme output functionality of the <a href="https://github.com/espeak-ng/espeak-ng">espeak-ng</a> program. For this I created <a href="https://github.com/dspinellis/speak/blob/master/votrax-espeak.md">a map</a> between the Votrax phoneme codes and the corresponding <a href="http://espeak.sourceforge.net/phonemes.html">espeak phonemes</a>, which I then coded into a <em>sed</em> script that would feed <em>espeak</em> with the output of Unix <em>speak</em>. Through this method I was finally able to produce somewhat intelligible speech with a pipeline, such as the following.</p>
<div><pre><code><span>echo</span> Hello world <span>|</span>
<span>speak</span> speak.m <span>|</span>
<span>LC_ALL=</span>C <span>./votrax-espeak.sed</span> <span>|</span>
<span>espeak</span></code></pre></div>
<h3 id="code-availability">Code availability</h3>
<p>The revived source code is available in <a href="https://github.com/dspinellis/speak">this GiHub repository</a>.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20210102#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20210102/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613576</guid>
            <pubDate>Sat, 02 Jan 2021 15:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate MacBook+PC Monitor Showdown]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25613244">thread link</a>) | @yeahgoodok
<br/>
January 2, 2021 | https://jamejone.github.io/2021/01/01/the-ultimate-macbook-pc-monitor-showdown/ | <a href="https://web.archive.org/web/*/https://jamejone.github.io/2021/01/01/the-ultimate-macbook-pc-monitor-showdown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <header> <h3> <a href="https://jamejone.github.io/" title="Home">So long, and thanks for all the bits</a> </h3> <h3> <small>an engineering blog</small> </h3>  </header> <main> <article>  <span> <time datetime="2021-01-01T00:00:00+00:00">Jan 1, 2021</time> · 2 minutes to read </span> <p><img src="https://jamejone.github.io/generated/public/usb-c-monitor-800-785df26bf.jpg" srcset="https://jamejone.github.io/generated/public/usb-c-monitor-400-785df26bf.jpg 400w, https://jamejone.github.io/generated/public/usb-c-monitor-600-785df26bf.jpg 600w, https://jamejone.github.io/generated/public/usb-c-monitor-800-785df26bf.jpg 800w, https://jamejone.github.io/generated/public/usb-c-monitor-1000-785df26bf.jpg 1000w"></p> <p>Like many folks finding their way through the COVID-19 pandemic, I’ve <a href="https://twitter.com/james_output/status/1320110838792003584">recently accepted a job</a> working permanently remote. So for the foreseeable future my workstation will be pulling double-duty for macOS-based software development with a MacBook Pro and Windows-based gaming on a PC.</p> <p>Modern monitors come with a lot of interesting features. Did you know you can connect a MacBook to a monitor using a single USB-C cable and transmit USB, power, audio <strong><em>and</em></strong> video?</p> <p>Unfortunately, it’s not as simple as knowing whether a monitor supports USB-C. Many monitors support USB-C but don’t have any sort of way to pipe the audio out from the monitor (for example, to a sound bar). And some monitors have USB-C and audio out, but only provide 15W of power.</p> <p>With enough features, the monitor effectively acts as a KVM+audio, like so:</p> <p><img src="https://jamejone.github.io/public/usb-c-monitor-diagram.png" alt="USB-C monitor diagram"></p> <p>So I set out to identify a monitor that meets all of my criteria. Specifically:</p> <ul> <li>Has a built-in KVM switch that lets me easily switch between my PC and MacBook.</li> <li>Provides at least 60W power over USB-C (the bare minimum to power a 16-inch MacBook Pro).</li> <li>Some sort of audio output (almost always analog).</li> <li>Upstream USB-B Port so that I can plug my keyboard and mouse into the monitor and pipe PC audio through the monitor to the sound bar.</li> <li>VESA mountable.</li> <li>IPS panel. The viewing angles on my TN panel are so bad it interferes with my work so IPS is a must.</li> <li>27” or 34” ultrawide @ 1440p. Good for gaming and happens to be <a href="https://bjango.com/articles/macexternaldisplays/">the ideal non-retina DPI for macOS</a>. Full retina @ 5k instead of 1440p would be nice, but unfortunately I couldn’t find such a monitor that meets all the minimum criteria. Awkward DPIs are a deal-breaker due to scaling and “shimmering” effects mentioned in the linked post.</li> </ul> <p>Nice-to-haves:</p> <ul> <li>Adaptive sync (AS).</li> <li>144hz refresh rate. At 60hz I lose track of my mouse cursor in League of Legends and we can’t have that!</li> <li>90W power delivery over USB-C.</li> <li>Reasonable price.</li> </ul> <p>Here’s what I found after about 15 hours of research:</p> <table> <thead> <tr> <th>Model</th> <th>Size</th> <th>Pros</th> <th>Cons</th> </tr> </thead> <tbody> <tr> <td>ViewSonic VP2771</td> <td>27” 1440p</td> <td>$200-$450</td> <td>60hz, 60W USB-C</td> </tr> <tr> <td>LG 34WK95C-W</td> <td>34” 1440p UW</td> <td>Adaptive Sync</td> <td>75hz, 60W USB-C, ~$1,000</td> </tr> <tr> <td>Dell U3421WE</td> <td>34” 1440p UW</td> <td>90W USB-C</td> <td>60hz, ~$1,000</td> </tr> <tr> <td>LG 34WK95U</td> <td>34” 4k UW</td> <td>85W USB-C</td> <td>60hz, ~$1,300, awkward DPI</td> </tr> <tr> <td>Dell U3219Q</td> <td>32” 4k</td> <td>90W USB-C</td> <td>60hz, ~$800, awkward DPI</td> </tr> <tr> <td>BenQ PD3220U</td> <td>32” 4k</td> <td>85W USB-C</td> <td>60hz, ~$1,200, awkward DPI</td> </tr> <tr> <td>Razer Raptor 27</td> <td>27” 1440p</td> <td>AS, 144hz, HDR</td> <td>15W USB-C, No VESA mount, $700</td> </tr> <tr> <td>Philips 346B1C</td> <td>34” 1440p UW</td> <td>90W, AS, $450</td> <td>100hz, VA panel</td> </tr> <tr> <td>Acer Predator X34 S</td> <td>34” 1440p UW</td> <td><strong>200hz</strong>, AS, 85W</td> <td>Not available (yet)</td> </tr> </tbody> </table> <p>I can’t guarantee this is an exhaustive list, but it might be. I left off monitors that are no longer for sale or lack crucial features like an audio output or upstream USB-B port.</p> <p>As you can see, there’s no ideal monitor except for the Acer Predator X34 S, which <a href="https://www.tomshardware.com/news/acer-predator-x34-s-a-34-inch-200hz-nano-ips-curved-monitor-w-05ms-response-time">isn’t available in the US yet and currently costs ¥9999</a> (roughly $1,500). In terms of what’s available today, you ultimately need to choose whether you want to sacrifice refresh rate, VESA mounting, USB-C charging, or panel type.</p> <p>As luck would have it, I ended up snagging a ViewSonic VP2771 on eBay for $200 shipped. After all, I still have a 144hz TN panel that I can keep plugged into the gaming PC. It’s not ideal but it’ll work until I get my hands on that Acer.</p> <p>Let me know in the comments if you find a monitor that should be in this list. If you want to play League of Legends together you can find me under the summoner name JamesJonesJrJr.</p> <p>Stay safe out there, friends.</p> <h3>Thanks for reading. Feel free to leave a comment.</h3>  </article>  </main>  </div></div>]]>
            </description>
            <link>https://jamejone.github.io/2021/01/01/the-ultimate-macbook-pc-monitor-showdown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613244</guid>
            <pubDate>Sat, 02 Jan 2021 15:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on My (Machine Learning) PhD Journey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25613226">thread link</a>) | @homarp
<br/>
January 2, 2021 | https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/ | <a href="https://web.archive.org/web/*/https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>2020 has been an incredibly challenging year, and on a personal note, has marked an important milestone — graduating with my PhD in computer science from Cornell University. This has been a six year journey, where my personal growth as a machine learning researcher (from thrills of first discoveries to the laborious grind through publication rejections to identifying a broader research vision) also took place against the backdrop of the rapid growth and change of the entire field (<a href="https://neurips.cc/Conferences/2014">2014 NeurIPS</a>: ~2k attendees, <a href="https://neurips.cc/Conferences/2020">2020 NeurIPS</a>: ~20k attendees).</p>

<p>With this year coming to an end, I’ve put together some of my reflections and lessons learned from my (Machine Learning) PhD experiences. I discuss topics including expectations going in, common challenges during the PhD (and some strategies for helping with them), keeping up with papers, the community nature of research and developing a research vision. I hope that these topics are helpful in navigating the PhD and research in Machine Learning!</p>

<ol id="markdown-toc">
  <li><a href="#expectations-going-into-the-phd" id="markdown-toc-expectations-going-into-the-phd">Expectations going into the PhD</a></li>
  <li><a href="#common-challenges-through-the-journey" id="markdown-toc-common-challenges-through-the-journey">Common Challenges through the Journey</a>    <ol>
      <li><a href="#feeling-completely-stuck" id="markdown-toc-feeling-completely-stuck">Feeling completely stuck</a></li>
      <li><a href="#feeling-overwhelmed-with-keeping-up-with-ml-progress" id="markdown-toc-feeling-overwhelmed-with-keeping-up-with-ml-progress">Feeling overwhelmed with keeping up with ML progress</a></li>
      <li><a href="#feeling-isolated" id="markdown-toc-feeling-isolated">Feeling Isolated</a></li>
    </ol>
  </li>
  <li><a href="#three-useful-personal-skills" id="markdown-toc-three-useful-personal-skills">Three Useful Personal Skills</a></li>
  <li><a href="#keeping-notes-on-papers-and-ideas" id="markdown-toc-keeping-notes-on-papers-and-ideas">Keeping Notes on Papers and Ideas</a></li>
  <li><a href="#the-importance-of-community" id="markdown-toc-the-importance-of-community">The Importance of Community</a></li>
  <li><a href="#developing-a-research-vision" id="markdown-toc-developing-a-research-vision">Developing a Research Vision</a></li>
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
</ol>

<h3 id="expectations-going-into-the-phd">Expectations going into the PhD</h3>
<p>In the post title, I’ve referred to the PhD as a “journey”, an aspect often underappreciated, particularly if one is coming straight out of undergrad (which was my experience). A typical Machine Learning PhD is going to be ~5-6 years of relatively unstructured time, and during this, not only will you learn research skills and knowledge about the field, but you’ll also develop personal preferences on how interesting specific problems are, the aesthetics of different subfields, and even perspectives on the <em>type</em> of work being done across academia/industry/policy/nonprofits.</p>

<p>These evolving personal preferences will influence the type of research you decide to work on, and even the post-PhD career path you pick. But particularly at the start of the PhD, it’s hard to predict how these personal perspectives will evolve. In my case, I started my PhD fully assuming I’d stay in industry, part way through began seriously considering academia, and at the end made the very difficult decision to turn down academic offers and stay on in industry. So going into the PhD program, it’s often helpful to take it step by step, and focus on getting the most out of the experience (learning/research/community participation), instead of a very specific desired outcome (which is prone to change, and may also add unnecessary pressure.)</p>

<h3 id="common-challenges-through-the-journey">Common Challenges through the Journey</h3>
<p>Doing a PhD can be an immensely rewarding experience, and, particularly in Machine Learning, offers the chance to contribute to fundamental scientific understanding as well as impactful technology deployment. I’ve been grateful to my PhD for providing many opportunities to experience both of these! However, the duration and unstructured nature of the PhD can also make it challenging. My journey definitely consisted of ups and downs, and at various times I’ve struggled with feeling isolated, completely stuck, and even overwhelmed by trying to keep up with the rapid pace of progress. Looking back, and through discussion with peers, I now know these low points can unfortunately be quite common. But because these experiences are shared across many people, there can also be strategies for working through them. Below I discuss some of these experiences and strategies.</p>

<h4 id="feeling-completely-stuck">Feeling completely stuck</h4>
<p>One very common challenge is feeling completely stuck, either on a specific project or with regards to the research process on the whole.</p>

<p>If the challenge is a specific project, where you’ve pushed hard and it’s still not quite working, then some strategies that might help are</p>
<ul>
  <li><strong>Making a write up</strong>: Collect any partial experimental results, mathematical insights, jotted notes on motivation, etc and take time to put together a write up. This can help with providing a picture of where things stand and where the important gaps are.</li>
  <li><strong>Pivot</strong>: if there’s a specific part of the project that’s not working, is there the possibility to reframe the question (possibly taking inspiration from related work) to make it more tractable?</li>
  <li><strong>Forming connections</strong>: are there links between what the current project focuses on and other areas of study? Can that connection be explored in this project? This can both help progress and in making the project relevant to a broader community.</li>
  <li><strong>Feedback on writeup</strong>: It might also be helpful to get feedback on the project write up from peers, collaborators and friends in the research community. They may be able to offer new perspectives or suggest improvements.</li>
  <li><strong>Workshop submission</strong>: it can also be useful to make a workshop submission. This also provides a chance to help collect together all the research results and get useful feedback. (For some time now, I’ve gained the most out of the workshops at machine learning conferences, due to being able to discuss/get feedback on ongoing directions and meeting other researchers working on the same area.)</li>
  <li><strong>Wrap up and move on</strong>: Occasionally, there may be a project which sounded promising in the beginning, but has been difficult to make work, and is also inherently challenging to reframe or form connections to other areas. In this (difficult) situation, it may make most sense to wrap up the project quickly and move on. If you have partial results, it’s likely worthwhile to create a final writeup of those and share, so one option is to do this, get confirmation from collaborators and final feedback, and keep it as an arXiv preprint or workshop paper.</li>
</ul>

<p>If the feeling of being stuck originates from the research process more broadly, one important point I’ve realised is that <em>gaining research maturity can often be very hard to measure, especially when evaluating yourself!</em> Midway through my PhD, I started working on some healthcare applications, and was only making slow headway on learning about the area/writing papers. This had me feeling stuck and somewhat frustrated at my slowdown in research progress. But when I re-read some papers that I’d first come across at the start of my PhD, the depth and context with which I could understand their results was strikingly different from earlier on.</p>

<p>Critical aspects of research maturity — understanding the broader context of results, being able to form connections between different areas, quickly narrowing in on novel key contributions in your subfield — don’t immediately translate to tangible outputs (more papers). But they’re central for becoming an independent researcher with a rich research vision — arguably the main research goal of the PhD. And if you’re reading papers, learning about the field, and working on research directions yourself, (and maybe even teaching/mentoring) most likely you’re making progress on all of these important aspects!</p>

<h4 id="feeling-overwhelmed-with-keeping-up-with-ml-progress">Feeling overwhelmed with keeping up with ML progress</h4>
<p>Machine Learning is a vibrant, fast-paced field. But the flipside of this is drowning in the flood of new papers, new preprints, new blogposts, new implementations, new frameworks, etc, etc. (Fun statistic: NeurIPS this past year had ~10k submissions and ~2k accepted papers — no wonder we’re feeling overwhelmed!)</p>

<p>My strategy in dealing with this has been</p>
<ol>
  <li><strong>Have a number of go-to links to find references to related papers.</strong> For me, this has been a combination of (i) subscribing to the arxiv stat.ML cs.LG mailing lists, <a href="http://www.arxiv-sanity.com/">arXiv-sanity</a>, Twitter, (occasionally) <a href="https://www.reddit.com/r/MachineLearning/">reddit/MachineLearning</a>, <a href="https://paperswithcode.com/">paperswithcode</a> and perusing <a href="https://www.semanticscholar.org/">Semantic Scholar</a>/<a href="https://scholar.google.com/">Google Scholar</a>.</li>
  <li><strong>Keep a reading list of papers</strong> If I come across an interesting paper but don’t have time to read it then (often the case), I make a note of it and try to return to it later.</li>
  <li><strong>Have a paper reading strategy</strong> If a paper is very close to research directions I’m actively working on, I’ll read it in detail, otherwise I’ll skim the abstract to get a high level picture.</li>
  <li><strong>Occasionally read up on different areas</strong> Occasionally (maybe once per year), I’ll look into a few interesting areas I’m not working on, and read several papers in each to get a sense of what is being worked on.</li>
</ol>

<p>It’s also helpful to remember that (i) <em>everyone</em> feels overwhelmed with the rate of publishing and (ii) many papers may rely on the same underlying idea, and often being familiar with the idea is enough for keeping up with the field.</p>

<h4 id="feeling-isolated">Feeling Isolated</h4>
<p>Another common challenge in the PhD is struggling with feelings of isolation. In the first couple of years of my PhD, some projects required that I kept laser focus on very narrow, specific questions, which were also highly laborious and (felt) never-ending. During those times, it was hard not to feel completely cut-off from other researchers and the broader field, and I’m very grateful for all the support and guidance from my PhD advisor in pushing through that situation.</p>

<p>More broadly, this scenario can be common especially earlier on during the PhD, where you might simultaneously be learning how to see through a research project from start to finish, and at the same time have less context and connections to the broader research field/community. Maintaining connections to the field/community can be very helpful in making sure you don’t feel isolated. Some ways to do this could be: (i) setting up collaborations with (senior) students/postdocs (ii) getting feedback on your work in progress – this might be your advisor/lab, but could also be other peers/mentors working in the field (iii) actively participating in the broader community, whether that’s through simply attending conferences, mentoring or organizing workshops.</p>

<h3 id="three-useful-personal-skills">Three Useful Personal Skills</h3>
<p>Having discussed some of the common challenges faced in the PhD and ways to help address them, the rest of this post will overview some useful considerations for research progress.</p>

<p>In particular, …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/">https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/</a></em></p>]]>
            </description>
            <link>https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613226</guid>
            <pubDate>Sat, 02 Jan 2021 15:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shen Language in 15 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25613204">thread link</a>) | @asimjalis
<br/>
January 2, 2021 | http://www.shenlanguage.org/shenin15min.htm | <a href="https://web.archive.org/web/*/http://www.shenlanguage.org/shenin15min.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.shenlanguage.org/shenin15min.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613204</guid>
            <pubDate>Sat, 02 Jan 2021 14:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up personal OKR (objectives and key-results)]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25613187">thread link</a>) | @pravj
<br/>
January 2, 2021 | https://hackpravj.com/blog/personal-okr-2021-plan/ | <a href="https://web.archive.org/web/*/https://hackpravj.com/blog/personal-okr-2021-plan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
            

          

			


			

      <div>
        <p>This article describes the approach I’m following to set personal goals for myself, in the form of Objectives and Key-results (OKR).</p>
<blockquote>
<p>If you are new to OKR, scroll down to the <strong>Resources</strong> section for more details.</p>
</blockquote>
<p><img src="https://hackpravj.com/images/pageimage-setting-up-personal-okr-jfm-2021.png" alt="Personal OKR for JFM 2021" title="Personal OKR for JFM 2021"></p>
<blockquote>
<p>A publically available worksheet for my personal OKRs for January-February-March 2021 is available <a href="https://docs.google.com/spreadsheets/d/1hN5ldi0SgoGFyvXwyLCmf98337AyIt1xzbynVicGH-8/edit?usp=sharing">here</a>.</p>
</blockquote>
<p>I’ve worked them out in order to:</p>
<ul>
<li>Get a better grip on the concept by implementing them in a relatively newer setting/environment outside of the work</li>
<li>Effectively set goals in the personal life where it’s easy to measure progress and find out weeker/strong areas to work on</li>
</ul>
<p>I will continue updating this article and the attached document in case of any changes or updates. If you want to discuss more, or in case of any feedback, please reach out to me at <a href="https://twitter.com/hackpravj">@hackpravj</a></p>
<h3 id="themes">Themes</h3>
<p>Start with the themes representing the different areas of life. For example, in your case, it can be Personal-finance, Health, Creativity, and more. You can have your own personal reasons behind selecting the final themes.</p>
<p>Here are the 7 separate themes in my current plan.</p>
<ol>
<li>Health</li>
<li>Habits</li>
<li>Networking</li>
<li>Reading</li>
<li>Writing</li>
<li>Learning</li>
<li>Relationships</li>
</ol>
<h3 id="backlog">Backlog</h3>
<p>For each of the themes, I came up with a backlog of aspirations and ideas.</p>
<p>This has helped me connect the ideas with each other if there is any such possibility, OR ruling out ideas that are duplicate to each other.</p>
<p>Some of the themes or ideas that didn’t make it to the current plan, will be considered during the next quarter’s OKRs.</p>
<h3 id="objectives">Objectives</h3>
<p>To come up with the objectives associated with the themes, ask yourself</p>
<ul>
<li>Where do you want to reach? (in relation to this theme or some specific area related to the theme)</li>
</ul>
<blockquote>
<p>As a rule-of-thumb, objectives are ambitious and qualitatively represent an end state. It’s more of an outcome, rather than an output.</p>
</blockquote>
<p>For example, if you’ve selected “Health” as one of the themes, the following can be an objective for you:</p>
<ul>
<li>Objective-1: Get in a better shape</li>
</ul>
<h3 id="key-results">Key-results</h3>
<p>Once you’ve decided your objective, the key-results will be a mechanism to show your progress towards that objective.</p>
<p>To come up with the key-results associated with the objective, ask yourself</p>
<ul>
<li>How will I know I am getting there (<em>reaching the objective</em>)?</li>
</ul>
<blockquote>
<p>Key-results are milestones that will move you closer to the objective if achieved.</p>
</blockquote>
<p>Considering the earlier example of the Objective (<em>Get in a better shape</em>), here are two representative key-results:</p>
<ul>
<li>Key-result-1: Reduce weight by 10 kilograms (<em>or pounds</em>)</li>
<li>Key-result-2: Achieve a daily step count of 10K steps walked</li>
</ul>
<h3 id="initiatives">Initiatives</h3>
<p>Once you know the key-results, ask yourself the following question to come up with the initiatives:</p>
<ul>
<li>What are we doing to get there (to the milestone set by the key-result)?</li>
</ul>
<blockquote>
<p>One of the common mistake during OKR planning is; ignoring the difference between the initiatives/key-results.</p>
</blockquote>
<p>For example, consider the first key-result (<em>Reduce weight by 10 kilograms</em>), there can be different initiatives (that you can do to reach the milestone set by the key-result).</p>
<ul>
<li>Initiative-1: Limit total meals per day to 2</li>
<li>Initiative-2: Stop eating after 7 PM</li>
<li>Initiative-3: Start intermittent-fasting every other day</li>
</ul>
<h3 id="okr-check-in">OKR check-in</h3>
<p>As you’re moving ahead with your OKR planning, you need to ensure that you’re regularly measuring your progress.</p>
<h3 id="measurement">Measurement</h3>
<ul>
<li>You can provide different weights to the key-results associated with an objective.
<ul>
<li>For example, the first key-result (<em>Reduce weight by 10 kilograms</em>) can take up 70% (<em>relatively higher</em>) weightage than the second key-result (<em>Walking 10K steps daily</em>).</li>
</ul>
</li>
<li>The progress for a key-result can be measured based on the % completion of the same.
<ul>
<li>A typically considered “sweet-spot” for OKRs is 60-70%.</li>
<li>If a key-result’s progress is higher than 70%, it might be a sign of lower ambitious objectives.</li>
</ul>
</li>
</ul>
<h3 id="summary">Summary</h3>
<ul>
<li>OKRs can also be implemented in personal life, out of the business/work (refer to Manas’s work on personal OKR [<a href="https://manassaloi.com/2020/01/15/personal-OKRs-2020.html">start</a>] [<a href="https://manassaloi.com/2020/12/31/okrs-2020-update.html">final update</a>]).</li>
<li>They serve as a goal-setting tool that helps you assess your progress on a regular basis.</li>
</ul>
<h3 id="resources">Resources</h3>
<ol>
<li><a href="https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/">Google’s guide to OKR</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLE7C8Y5NNLkMrMsqbe0igtYgPopb7IXBH">OKR training session (YouTube playlist</a>) by Directi CEO Bhavin Turakia</li>
<li>I will be maintaining a Twitter thread for the same topic, <a href="https://twitter.com/hackpravj/status/1345382233851326464">here</a>.</li>
</ol>
<hr>
<p>If you work at the intersection of <strong>Product-Management</strong> and <strong>Artificial-Intelligence</strong>, I would love to <strong>connect and exchange notes</strong> with you regarding your experience/learnings.</p>
<ul>
<li>Can we connect over <a href="https://hackpravj.com/cdn-cgi/l/email-protection#7f171e1c140f0d1e09153f18121e1613511c1012">email</a> OR <a href="https://twitter.com/hackpravj">Twitter</a>?</li>
</ul>
<hr>
<p>If you want to discuss more, or in case of any feedback, please reach out to me at <a href="https://twitter.com/hackpravj">@hackpravj</a></p>

      </div>
	
			

      </section></div></div>]]>
            </description>
            <link>https://hackpravj.com/blog/personal-okr-2021-plan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613187</guid>
            <pubDate>Sat, 02 Jan 2021 14:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The PHP-Documentation has moved to Git]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25613132">thread link</a>) | @Garbage
<br/>
January 2, 2021 | https://externals.io/message/112662 | <a href="https://web.archive.org/web/*/https://externals.io/message/112662">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Hey folks!</p>
<p>The PHP-Documentation has moved to git!</p>
<p>Not at the same day as the PHP8-release but at least in the same year ;-)</p>
<p>Nikita and myself took the last steps today to finalize what a number of <br>
people have been working on for the last at least 4 years.</p>
<p>Thanks to Derick, Rasmus, Sara, Paul, Peter, Gabriel and a lot of others <br>
for their support, encouragement and help.</p>
<p>So from now on there is no possibility to contribute to the <br>
documentation via SVN. All the contributions have to go via git now.</p>
<p>Details regarding setup can be found at <br>
<a href="https://github.com/php/doc-base/blob/master/README.md" rel="nofollow" target="_blank">https://github.com/php/doc-base/blob/master/README.md</a></p>
<p>This move also means that there are now mirrors of the documentation at <br>
github through which contributions can be made now.</p>
<p>There are some minor things still waiting to happen like the revcheck <br>
(which is currently being worked on) or not all github mirrors having <br>
actually "mirrored" yet (as they need a propper commit to start the <br>
mirroring).</p>
<p>But in general: It is done!</p>
<p>What is the next goal now? Create the best documentation PHP has ever had!</p>
<p>Cheers</p>
<h2>Andreas</h2>
<pre><code>                                                          ,,,
                                                         (o o)
</code></pre>
<p>+---------------------------------------------------------ooO-(_)-Ooo-+ <br>
| Andreas Heigl                                                       | <br>
| <a href="https://externals.io/cdn-cgi/l/email-protection#c0a1aea4b2a5a1b380a8a5a9a7aceeafb2a7" rel="nofollow" target="_blank">mailto:<span data-cfemail="7b1a151f091e1a083b131e121c175514091c">[email&nbsp;protected]</span></a>                  N 50°22'59.5" E 08°23'58" | <br>
| <a href="https://andreas.heigl.org/" rel="nofollow" target="_blank">https://andreas.heigl.org</a>                                           | <br>
+---------------------------------------------------------------------+ <br>
| <a href="https://hei.gl/appointmentwithandreas" rel="nofollow" target="_blank">https://hei.gl/appointmentwithandreas</a>                               | <br>
+---------------------------------------------------------------------+</p>

            </div></div>]]>
            </description>
            <link>https://externals.io/message/112662</link>
            <guid isPermaLink="false">hacker-news-small-sites-25613132</guid>
            <pubDate>Sat, 02 Jan 2021 14:49:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't let design and UX get in the way of shipping early and often]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25612995">thread link</a>) | @simplecto
<br/>
January 2, 2021 | https://www.simplecto.com/i-dont-let-design-ux-get-in-the-way-of-shipping-early-and-often/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/i-dont-let-design-ux-get-in-the-way-of-shipping-early-and-often/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>I've never had a customer complain about the design.</p><p>It feels worse to have a nicely designed product that does not work as expected (or at all).</p><p>I am not a designer. It is not a skill that I care to improve. Instead I would rather rely on the best practices of frameworks like <a href="https://getbootstrap.com/">Bootstrap</a> to get me there (at least in the beginning). In my experience design is something to consider later on the the product lifecycle. <strong>I am more interested in how things work vs. how things look.</strong></p><p>This is how I think about product life-cycles:</p><h3 id="phase-1-speed-shipping-and-finding-what-makes-it-sticky-">Phase 1: Speed, shipping, and finding what makes it sticky. </h3><p>It is hacky, has duplicated code, and probably some dead code paths. Invite only and only for the most forgiving users. I only need a few users who will probably expose the major flaws here. I usually don't write any tests. I don't add too many third-party libraries or utilities at this point. For me this is just <a href="https://djangoproject.com/">Django</a> and <a href="https://getbootstrap.com/">Bootstrap</a>. <strong>Use the defaults!</strong></p><h3 id="phase-2-lay-the-groundwork-for-robustness-">Phase 2: Lay the groundwork for robustness. </h3><p>Unit tests, application metrics, logs, and repeatable, consistent deployments. I don't have to get everything right, but I must make these decisions and commit to them. Biggest challenge is to keep my early-invite users engaged. The early users and my own testing revals the hot-spots that need more attention (unit tests or end-to-end test).</p><h3 id="phase-3-make-bigger-changes-with-confidence">Phase 3: Make bigger changes with confidence</h3><p>Now that we have testing in place we can refactor, clean up dead code paths, and redundant &nbsp;UI code with more confidence. This is a good time to onboard junior developers into the project. Or, in my case, this is when I feel comfortable hiring a contractor to work on "the little things" (tm). Maybe I offer-up another round of invites to a wider network of potential customers.</p><h3 id="phase-4-prepare-for-a-broader-market-showing">Phase 4: Prepare for a broader market showing</h3><p>At this point we have a reasonably stable product. We understand our own development workflow as well as the strongest customer use cases. Now I start making basic user documentation and videos. This becomes the v1 of my marketing materials and social media story-telling. <strong>Note: documentation can go a long way to patch over incomplete or hard-to-use parts of your application.</strong> This is my public beta phase (usually the Reid Hoffman embarrassment stage)</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">"If you review your first site version and don’t feel embarrassment, you spent too much time on it." - Reid Hoffman (via <a href="https://twitter.com/37signals?ref_src=twsrc%5Etfw">@37signals</a>)</p>— LinkedIn (@LinkedIn) <a href="https://twitter.com/LinkedIn/status/1876035921?ref_src=twsrc%5Etfw">May 21, 2009</a></blockquote>

</figure><h3 id="phase-5-i-feel-pretty">Phase 5: I feel pretty</h3><p>Now that we are in public beta it is time to consider the design. The first 4 phases have helped us create a deeper understanding of the problem space, our core customers (their needs, industry, and expectations), and ourselves. We probably know our pain-points and deficiencies well enough to have solid asks to a designer/UX. I want them focused on real problems, not exploring around looking for things to do. Real output here is "<em>I want designs and flows that work in the app that we can display in marketing materials</em>"</p><h3 id="maturing-into-a-real-sdlc-with-design-support">Maturing into a real SDLC with design support</h3><p>From here on out this is more of a traditional SDLC (Software development life-cycle) process. There is more <strong>structured iteration</strong> around development, market feedback, and experimentation. Design has been integrated into the process but only in a supporting role. </p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/i-dont-let-design-ux-get-in-the-way-of-shipping-early-and-often/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25612995</guid>
            <pubDate>Sat, 02 Jan 2021 14:24:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will at least one Metaculus user report positive Covid test by the end of 2020?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25612898">thread link</a>) | @monort
<br/>
January 2, 2021 | https://www.metaculus.com/questions/3724/will-at-least-one-metaculus-user-report-a-positive-test-result-for-novel-coronavirus-by-the-end-of-2020/ | <a href="https://web.archive.org/web/*/https://www.metaculus.com/questions/3724/will-at-least-one-metaculus-user-report-a-positive-test-result-for-novel-coronavirus-by-the-end-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.metaculus.com/questions/3724/will-at-least-one-metaculus-user-report-a-positive-test-result-for-novel-coronavirus-by-the-end-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25612898</guid>
            <pubDate>Sat, 02 Jan 2021 14:06:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encrypted Backup Shootout]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25612525">thread link</a>) | @todsacerdoti
<br/>
January 2, 2021 | https://acha.ninja/blog/encrypted_backup_shootout/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/encrypted_backup_shootout/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Recently I have been spending time on improving the performance of <a href="https://github.com/andrewchambers/bupstash">bupstash</a> (my encrypted backup tool), and wanted to compare it to some existing tools to try and find its relative performance in the backup tool landscape.</p>
<p>This post compares <a href="https://github.com/andrewchambers/bupstash">bupstash</a>, <a href="https://restic.net/">restic</a>, <a href="https://www.borgbackup.org/">borg backup</a> and plain old tar + gzip + GPG across a series of simple benchmarks.</p>
<p>What do all these tools have in common?</p>
<ul>
<li>They encrypt data at rest.</li>
<li>They compress data.</li>
<li>They have some form of incremental and/or deduplicated snapshotting.</li>
<li>They are all pretty great backup systems.</li>
</ul>
<p>Feel free to checkout the project websites to learn more, let’s get to the benchmarks.</p>
<h2 id="benchmarks">Benchmarks</h2>
<p>For these tests we are using the following versions of the given software:</p>
<ul>
<li>GNU tar 1.32 + gzip 1.10 + GPG 2.2.23</li>
<li>Bupstash 0.6.1</li>
<li>Borg 1.1.14</li>
<li>Restic 0.11.0</li>
</ul>
<p>The test machine has an AMD Ryzen Threadripper 1950X 16-Core Processor with 16 GB of ram, and an NVMe SSD hard drive. It is probably best to simply compare results relatively, as reproducing my test environment exactly would be difficult.</p>
<p>The scripts I used for my benchmarking can be found <a href="https://github.com/andrewchambers/EncryptedBackupShootout">here</a>, though they will definitely need tweaking for your environment.</p>
<h3 id="deduplication-and-compression">Deduplication and compression</h3>
<p>For this benchmark we take 20 different consecutive versions of the linux kernel source code and add them all to the same directory, we then create a snapshot and measure the size of the resulting tarball/repository.</p>
<p>The linux kernel versions chosen for this test are all the consecutive git commits preceeding version 5.9, with the resulting directory containing 21 GB of uncompressed files.</p>
<p><img src="https://acha.ninja/img/Test_Snapshot_Size.svg" alt="plot"></p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Size</th>
<th>Compression Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash</td>
<td>0.378 GB</td>
<td>55x</td>
</tr>
<tr>
<td>borg</td>
<td>0.476 GB</td>
<td>49x</td>
</tr>
<tr>
<td>restic</td>
<td>1.5 GB</td>
<td>14x</td>
</tr>
<tr>
<td>tar + gzip + gpg</td>
<td>3.6 GB</td>
<td>5.8x</td>
</tr>
</tbody>
</table>
<p>This benchmark shows the advantage the more sophisticated tools have over plain tarballs, they all have extremely good compression ratios when similar data is added multiple times to
a backup repository.</p>
<h3 id="creating-a-fresh-directory-snapshot">Creating a fresh directory snapshot</h3>
<p>For this benchmark we are snapshotting a copy of the linux
5.9.8 source code.</p>
<p>The directory we are snapshotting is 1.1 GB comprised of 74725 files and directories.</p>
<p>The snapshots are all made to tmpfs so hopefully does not measure delays introduced by the network or disk activity.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash put</td>
<td>3.939 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.026 s</td>
</tr>
<tr>
<td>borg create</td>
<td>13.831 s</td>
</tr>
<tr>
<td>tar | gzip | gpg</td>
<td>24.505 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the clear winner here for raw snapshotting speed.</p>
<h3 id="sending-a-fresh-snapshot-to-a-remote-server">Sending a fresh snapshot to a remote server</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh. This benchmark should only be considered an approximation of the effect latency has on the tool performance as it is so dependent on network speeds.</p>
<p>At the time of benchmarking my connection to the remote server can be summarized as follows:</p>
<ul>
<li>server -&gt; client 10MiB/s</li>
<li>client -&gt; client 2.5MiB/s</li>
<li>ping 32 milliseconds</li>
</ul>
<p><img src="https://acha.ninja/img/Time_for_1.1_GB_Remote_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar | gzip | gpg | ssh</td>
<td>72.640 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>121.817 s</td>
</tr>
<tr>
<td>borg create</td>
<td>143.942 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>414.859 s</td>
</tr>
</tbody>
</table>
</details>
<p>Plain tar takes the win, Restic performs poorly here, it has a far more latency-sensitive upload protocol.</p>
<h3 id="creating-an-incremental-directory-snapshot">Creating an incremental directory snapshot</h3>
<p>This benchmark is the same as the fresh local snapshot benchmark, except now we measure the time for an incremental snapshot using the builtin caching mechanism of the tools. What this means is each tool keeps a record of what files it has already sent, and is able to
skip doing that work again.</p>
<p><img src="https://acha.ninja/img/Time_for_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg</td>
<td>0.209 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.394 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>3.916 s</td>
</tr>
<tr>
<td>borg create</td>
<td>7.724 s</td>
</tr>
</tbody>
</table>
</details>
<p>Incremental tar is the clear winner here, but why are the other tools slower? I think this is mainly because the other tools present each snapshot to the user as a full backup and thus do extra work to spare the end user from managing incremental backups manually.</p>
<p>It is also interesting to me that <code>bupstash put</code> is an order of magnitude faster than the other similar tools, though I currently can not explain clearly why that may be the case.</p>
<h3 id="sending-an-incremental-snapshot-to-a-remote-server">Sending an incremental snapshot to a remote server</h3>
<p>This benchmark is the same as the incremental local snapshot benchmark except the files are sent to a remote server hosted on google cloud via ssh.</p>
<p>Benchmark conditions are the same as the fresh remote snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Incremental_Snapshot.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar –listed-incremental | gzip | gpg | ssh</td>
<td>0.779 s</td>
</tr>
<tr>
<td>bupstash put</td>
<td>0.999 s</td>
</tr>
<tr>
<td>restic backup</td>
<td>6.140 s</td>
</tr>
<tr>
<td>borg create</td>
<td>10.772 s</td>
</tr>
</tbody>
</table>
</details>
<p>These results match closely with the local incremental snapshots.</p>
<h3 id="restoring-a-snapshot">Restoring a snapshot</h3>
<p>In this benchmark we will restore the snapshot made in the fresh local snapshot benchmark to tmpfs. This is what measuring what happens when you need to do a bulk disaster recovery from your backup repository.</p>
<p><img src="https://acha.ninja/img/Time_for_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash get | tar -x</td>
<td>2.712 s</td>
</tr>
<tr>
<td>gpg -d | gzip -d | tar -x</td>
<td>4.449 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>4.890 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>9.694 s</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is the winner for restoring backups.</p>
<h3 id="restoring-a-snapshot-from-a-remote-server">Restoring a snapshot from a remote server</h3>
<p>In this benchmark we will restore the snapshot made in the fresh remote snapshot benchmark to tmpfs. The main difference from the previous benchmark is the introduction of
an internet connection between the backup repository and restore point.</p>
<p>Network conditions are the same as the fresh network snapshot benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_1.1GB_Restore.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>ssh | gpg -d | gzip -d | tar -x</td>
<td>28.082 s</td>
</tr>
<tr>
<td>bupstash get | tar -x</td>
<td>48.893 s</td>
</tr>
<tr>
<td>borg extract</td>
<td>52.931 s</td>
</tr>
<tr>
<td>restic restore</td>
<td>146.098 s</td>
</tr>
</tbody>
</table>
</details>
<p>Interestingly, the introduction of the network pushed tar ahead of bupstash for backup restoration - this is something I am very interested in investigating further.</p>
<h3 id="pruning-an-old-backup">Pruning an old backup</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository on the same computer. For this test we generate a backup repository with 50 different snapshots of different versions of the linux kernel source code and then time how long it takes to remove one of the snapshots. This benchmark simulates
cycling old backups out of your backup repository when you no longer need them.</p>
<p>Tar with incremental backups does not easily support pruning of old backups, so does not participate in this benchmark.</p>
<p><img src="https://acha.ninja/img/Time_for_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>0.0386 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>0.497 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>2.030 s</td>
</tr>
</tbody>
</table>
</details>
<p>The bupstash garbage collector is an order of magnitue faster than both restic and borg at pruning the backup repository.</p>
<h3 id="pruning-an-old-backup-on-a-remote-server">Pruning an old backup on a remote server</h3>
<p>In this benchmark we will be removing an old snapshot from the backup repository stored on a remote server. The remote server is the same as the one used in fresh remote snapshot benchmark, and the test data is the same as the local prune bench mark.</p>
<p><img src="https://acha.ninja/img/Time_for_Remote_Snapshot_Removal.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Mean Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>bupstash rm &amp;&amp; bupstash gc</td>
<td>2.137 s</td>
</tr>
<tr>
<td>borg delete</td>
<td>3.111 s</td>
</tr>
<tr>
<td>restic forget &amp;&amp; restic prune</td>
<td>145.540 s</td>
</tr>
</tbody>
</table>
</details>
<p>Once again restic suffers the worst from introduced network latency of all the tools.</p>
<h3 id="approximate-peak-client-side-ram-usage">Approximate peak client side ram usage</h3>
<p>For this benchmark we repeat the fresh snapshot benchmark, but measure the peak client ram usage (RSS) as reported by the ‘time’ command. For tar we approximate this by summing the peak memory usage across tar, gpg and gzip.</p>
<p><img src="https://acha.ninja/img/Test_Peak_Memory_Usage.svg" alt="plot"></p>
<details>
<summary>Raw data (Click to expand)</summary>
<table>
<thead>
<tr>
<th>Command</th>
<th>Peak Memory Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>tar + gzip + GPG</td>
<td>10.312 MB</td>
</tr>
<tr>
<td>bupstash</td>
<td>18.192 MB</td>
</tr>
<tr>
<td>borg</td>
<td>96.696 MB</td>
</tr>
<tr>
<td>restic</td>
<td>191.252 MB</td>
</tr>
</tbody>
</table>
</details>
<p>Bupstash is very memory-efficient compared to restic and borg, but ultimately loses out to the simplicity of tar + gzip + GPG.</p>
<h2 id="conclusions-and-discussion">Conclusions and discussion</h2>
<p>GNU Tar + gzip + gpg is an excellent encrypted backup option and performed better than I expected. I think tar and gpg is still a great choice for users who prefer to DIY their own backup scripts. With this in mind, we must ask what are the problems with tar that the other tools address? My opinion is that managing
incremental backups, deduplication, pruning, and searching backups are far more difficult when using incremental tar compared to borg/restic/bupstash. With incremental tar, it quickly becomes quite hard to track which incremental
tarballs depend on eachother and you often need to periodically do full snapshots - losing most of the speed benefits.</p>
<p>As the biased author of bupstash, I am also pleased with how it has performed and hope I can push it further in the future. Restic, while fast at local operation, seems to trail the other tools when network latency is thrown into the mix. Borg is an all-around great tool and performed very well.</p>
<p>I can see both strengths and room for improvement in each of the tools tested, and encourage everyone to give them a try for yourself if you haven’t already.</p>
<p>As always, thank you for your time and see you next time :).</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/encrypted_backup_shootout/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25612525</guid>
            <pubDate>Sat, 02 Jan 2021 12:55:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start Linux Kernel Hacking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25612045">thread link</a>) | @edddie
<br/>
January 2, 2021 | https://bodunhu.com/blog/posts/kernelhacking | <a href="https://web.archive.org/web/*/https://bodunhu.com/blog/posts/kernelhacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p> 
<a href="https://www.redandblack.com/opinion/opinion-make-the-switch-to-a-linux-operating-system/article_0b8bb324-5425-11e9-9d96-ab61c820e566.html">
<img src="https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/linux_kernel_hacking/linux.jpg" width="80%">
</a>
</p>

<p>This is a summary of how to compile and boot the Linux kernel on the KVM-qemu virtual machine. It coveres how to get a VM running in KVM, how to build a customized kernel, and how to use GDB with the Linux kernel. The experiment is conducted on an amd64 architecture CPU. We use Ubuntu as our testing environment but the steps covered here should apply to other distros as well.
<!--description--></p>

<h2 id="getting-a-vm-running-in-kvm">Getting a VM running in KVM</h2>
<p>The Ubuntu ISO image is downloaded from the <a href="https://ubuntu.com/download/desktop">Canonical website</a>. The kernel is downloaded directly from <a href="https://www.kernel.org/">kernel.org</a>. The specs of our test environment is:</p>

<ul>
  <li>CPU: Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz</li>
  <li>RAM: 32 GB</li>
  <li>Host and Guest OS: Ubuntu 20.04.1 LTS</li>
  <li>Host Kernel Version: 5.4.0-47-generic</li>
  <li>GCC: 7.5.0</li>
  <li>QEMU emulator version: 4.2.0</li>
  <li>Guest Kernel Version: 5.8.6</li>
</ul>

<p>After we obtained the Ubuntu ISO image, we use GUI virt-manager to install the OS. One thing to notice here is the default directory for virtual disks is <code>/var/lib/libvirt/images</code>, since my system partition is located on a seperate SSD with limited space, the virtual disk directory is changed to my <code>/home</code> directory instead.</p>

<p>We also create the new virtual disk inside virt-manager. We chose raw format instead of qcow2. Creating a new image file can also be done in command line using:</p>
<div><div><pre><code>qemu-img create <span>-f</span> raw <span>-o</span> <span>preallocation</span><span>=</span>full vmdisk.img 40G
</code></pre></div></div>

<p>The preallocation can be turn either on or off depends on personal choices. After the disk image is created, we proceeds in virt-manager to install Ubuntu on the newly allocated virtual disk. We enabled storage for this virtual machine so that we don't need to repeat the installation process everytime we launch the VM. One thing to be noticed here is we don't need swap area inside a virtual machine. We can simply use the whole virtual disk for <code>/</code> partition.</p>

<p>To start the VM from cmd, you might need to change the owner of the disk image. We add the user to both <code>kvm</code> and <code>libvirt</code>. The image created or accessed by virt-manager seems to change the file owner to libvirt-qemu, which may cause problems when starting from cmd.</p>

<p>After the installation is finished, we can simply launch the virtual machine inside virt-manager through its GUI interface. We can also use command line to start the VM:</p>
<div><div><pre><code>kvm <span>-accel</span> kvm <span>-m</span> 8G <span>-smp</span> 6 <span>--snapshot</span> <span>-drive</span> <span>format</span><span>=</span>raw,file<span>=</span>/home/ed/virtimg/ubuntu20.04
</code></pre></div></div>

<p>The argument <code>-accel kvm</code> enables Kernel-based Virtual Machine full virtualization, which uses hardware acceleration. Without this option the VM will become extremely slow. The <code>-m 8G</code> assigns the given amount of memory to the VM. The <code>-smp 6</code> assigns the given number of cores to the guest if the host has multiple cores. The <code>--snapshot</code> ensures that no changes are made to your image during an execution so you can do something dangerous and have the original image file preserved. The <code>-drive</code> option specifies the location of the virtual disk and its format. We will use some of these options later.</p>

<p>To confirm the VM has internet access, simply execution <code>apt install pkg-name</code> in the guest terminal. No error message would indicates properlu functioning network access from the guest VM. For example, when we execute <code>sudo apt install llvm</code> it shows:</p>

<div><div><pre><code>Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following additional packages will be installed:
  llvm-runtime
The following NEW packages will be installed:
  llvm llvm-runtime
0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.
Need to get 6,796 B of archives.
After this operation, 128 kB of additional disk space will be used.
Do you want to continue? [Y/n] 
</code></pre></div></div>

<h2 id="building-the-kernel">Building the Kernel</h2>
<p>We can use out customized kernel for our newly created VM. After we obtain the Linux kernel from <a href="https://www.kernel.org/">kernel.org</a>, we extract teh source into &lt;kernel dir&gt; and create a separate build directory &lt;kbuild&gt; (outside &lt;kernel dir&gt;).</p>

<p>Then we enter the &lt;kbuild&gt; directory, run</p>

<div><div><pre><code><span>yes</span> <span>""</span> | make <span>-C</span> /home/ed/Desktop/linux_kernel/kbuild <span>O</span><span>=</span><span>$(</span><span>pwd</span><span>)</span> config
</code></pre></div></div>

<p>This will create a <code>.config</code> file inside &lt;kbuild&gt; with the default options selected. We then open the configuration file and ensures <code>CONFIG_SATA_AHCI=y</code>, which builds the SATA disk driver into the kernel. That will allow your kernel to boot off a (virtual) SATA drive without having to load a module to do it.</p>

<p>Next we build the kernel by running <code>make</code> in &lt;kbuild&gt;. We use the -j 6 option speedup the building process using multiple processor cores. This process can take a long time.</p>

<h2 id="build-and-install-kernel-modules">Build and Install Kernel Modules</h2>
<p>To build modules locally on host, we create another seperate &lt;install_mod_dir&gt; directory for building kernel modules. Then in &lt;kbuild&gt;, execute</p>

<div><div><pre><code>make INSTALL_MOD_PATH=/home/ed/Desktop/linux_kernel/install_mod_dir modules_install 
</code></pre></div></div>

<p>Now there is a <code>lib</code> directory inside <code>/home/ed/Desktop/linux_kernel/install_mod_dir</code>, which holds all the kernel modules we are about to install.</p>

<p>The complete list of modules can be listed using <code>cat modules.builtin</code> inside <code>lib/moduels/5.8.6</code>. Here is a <a href="https://gist.github.com/BDHU/4d31d18ad106a13caceac4a961d04a44">link</a> to all the modules being built. We didn't modify anything in the configuration.</p>

<p>Then we use guestmount to mount the virtual disk to a mount point on the host</p>

<div><div><pre><code>guestmount -a /home/ed/virtimg/ubuntu20.04 -i ~/vm/linux/
</code></pre></div></div>
<p>In Ubuntu this step yields the following message:</p>

<div><div><pre><code>libguestfs: error: /usr/bin/supermin exited with error status 1.
To see full error messages you may need to enable debugging.
Do:
  export LIBGUESTFS_DEBUG=1 LIBGUESTFS_TRACE=1
and run the command again.  For further information, read:
  http://libguestfs.org/guestfs-faq.1.html#debugging-libguestfs
You can also run 'libguestfs-test-tool' and post the *complete* output
into a bug report or message to the libguestfs mailing list.
</code></pre></div></div>

<p>The underlying problem is that the kernel cannot be read and according to the <a href="https://askubuntu.com/questions/1046828/how-to-run-libguestfs-tools-tools-such-as-virt-make-fs-without-sudo">post</a> and the <a href="https://bugs.launchpad.net/fuel/+bug/1467579">bug report</a> on Ubuntu Launchpad.</p>

<p>To fix the issue, we need to run</p>

<div><div><pre><code>sudo chmod +r /boot/vmlinuz-*
</code></pre></div></div>

<p>We can verify the contents inside ~/vm/linux by simply cd into it.</p>

<p>To install the modules we just built, we can copy the <code>&lt;install_mod_dir&gt;lib/modules</code> into the mounted filesystem <code>&lt;mount_point&gt;/lib/modules</code>.</p>

<p>Finally, we unmount the filesystem by doing</p>

<div><div><pre><code>fusermount -u /mnt/hdd1/vm/linux
</code></pre></div></div>

<h2 id="booting-kvm-with-new-kernel">Booting KVM with new Kernel</h2>
<p>To boot up the VM with the new kernel, we will add a few extra command line options to kvm. For convenience, we put the scritps into a file. It's also available on <a href="https://gist.github.com/BDHU/8c6ab518ab37571a1cae132d79ac9a9e">gist</a>:</p>

<div><div><pre><code><span>#!/bin/bash</span>

kvm <span>\</span>
    <span>-s</span> <span>\</span>
    <span>-display</span> gtk <span>\</span>
    <span>-cpu</span> host <span>\</span>
    <span>-vga</span> qxl <span>\</span>
    <span>-accel</span> kvm <span>\</span>
    <span>-kernel</span> <span>"/home/ed/Desktop/linux_kernel/kbuild/arch/x86/boot/bzImage"</span> <span>\</span>
    <span>-append</span> <span>"root=/dev/sda1 console=ttyS0,115200n8 nokaslr"</span> <span>\</span>
    <span>-drive</span> <span>format</span><span>=</span>raw,file<span>=</span>/home/ed/virtimg/ubuntu20.04 <span>\</span>
    <span>-m</span> 8G <span>\</span>
    <span>-smp</span> 6 <span>\</span>
    <span>--snapshot</span> <span>\</span>
    <span>-S</span>
</code></pre></div></div>

<p>Aside from the command line arguments we discussed before, there are a few new members here. the <code>-s</code> switch is a shorthand for <code>-gdb tcp::1234</code>. The <code>-display gtk</code> is optional. It enables the opengl context in the display device for gtk display output. <code>-cpu host</code> says the guest should emulate the host processor. <code>-vga qxl</code>  enables 3D acceleration on the guest system. <code>-vga virtio</code> also offers good performance in our case. <code>-kernel</code> allows bootloader to pickup the new kernel. The <code>-append</code> along with its arguments specifies where the root partition of the hard disk is and the console parameter adds a serial console at boot so you can see boot messages. The <code>--snapshot</code> in QEMU says the images that refer to an original image will use Redirect-on-Write to avoid changing the original image. The <code>-S</code> means the kernel won't start executing unless we attach a debugger to it. We only use it later in the debugging stage.</p>

<p>Again, we can verify there is internet access using the new kernel using <code>apt update</code>. There are no errors shown, which indicates the network is functioning correctly.</p>

<h2 id="booting-process">Booting Process</h2>
<p>Now we are able to boot up the VM successfully, we can first measure how much time the kernel spends in booting. Running <code>dmesg -d</code> shows the timestamp and time delta spent between messages. The final line shows <code>[10.842998]</code>. If we use <code>systemd-analyze</code>, it outputs</p>

<div><div><pre><code>Startup finished in 795ms (kernel) + 5.451s (userspace) = 6.247s
graphical.target reached after 5.439s in userspace
</code></pre></div></div>

<p>The reason why there is a gap between these two measurement is because <code>dmesg</code> is not a reliable test of how long a boot-up process goes. <code>dmesg</code> itself merely collects information. The drivers and other system processes can output messages at any point in time. There may or may not be processes spawning between those messages.</p>

<p>Next, we are going to look at how PCI device is involved in kernel startup. <code>lspci</code> outputs the follow</p>

<div><div><pre><code>00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)
00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE [Natoma/Triton II]
00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 03)
00:02.0 VGA compatible controller: Red Hat, Inc. Virtio GPU (rev 01)
00:03.0 Ethernet controller: Intel Corporation 82540EM Gigabit Ethernet Controller (rev 03)
</code></pre></div></div>

<p>We can use the PCI address here to search for corresponding information in <code>dmesg</code>. For example, if we use the domain value \(0000:\) as query, we get something like:</p>

<div><div><pre><code>[    0.295026] PCI host bridge to bus 0000:00
[    0.299055] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000
[    0.300133] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100
[    0.301163] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180
[    0.311006] pci 0000:00:02.0: [1af4:1050] type 00 class 0x030000
[    0.319650] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000
</code></pre></div></div>

<p>The full result is also available as <a href="https://gist.github.com/BDHU/4d31d18ad106a13caceac4a961d04a44#file-dmesg_output">gist</a>.</p>

<p>The <code>lspci</code> command specifies the type of device right after the address. For example, the first one is host bridge. We specifically selected the message in the <em>type 00 class</em> format here. The significance here is that the class value actually telss us the type of the corresponding device. We can check the <a href="https://github.com/torvalds/linux/blob/master/include/linux/pci_ids.h">include/linux/pci_ids.h</a> for each macro respectively. For example,</p>

<div><div><pre><code><span>#define …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bodunhu.com/blog/posts/kernelhacking">https://bodunhu.com/blog/posts/kernelhacking</a></em></p>]]>
            </description>
            <link>https://bodunhu.com/blog/posts/kernelhacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25612045</guid>
            <pubDate>Sat, 02 Jan 2021 11:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My personal OKR for 2021 (More to be added)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25612033">thread link</a>) | @gogo61
<br/>
January 2, 2021 | https://rohitgupta.site/OKR-2021-bebdabc9fe244142b6befc805d2e02de | <a href="https://web.archive.org/web/*/https://rohitgupta.site/OKR-2021-bebdabc9fe244142b6befc805d2e02de">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rohitgupta.site/OKR-2021-bebdabc9fe244142b6befc805d2e02de</link>
            <guid isPermaLink="false">hacker-news-small-sites-25612033</guid>
            <pubDate>Sat, 02 Jan 2021 11:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Environments Demystified]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25611307">thread link</a>) | @meribold
<br/>
January 2, 2021 | https://meribold.org/python/2018/02/13/virtual-environments-9487/ | <a href="https://web.archive.org/web/*/https://meribold.org/python/2018/02/13/virtual-environments-9487/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  <header>
    
    <time datetime="2018-02-13T00:00:00+08:00">2018-02-13</time>
  </header>
  <p><img src="https://meribold.org/assets/virtual-boy-avgn.jpg" alt="The nerd with his Virtual Boy"></p>

<p>Here’s a non-exhaustive list of programs that are all meant to help create or manage
virtual environments in some way:</p>

<blockquote>
  <p><a href="https://github.com/ofek/hatch">Hatch</a>,
  <a href="https://pypi.python.org/pypi/VirtualEnvManager">VirtualEnvManager</a>,
  <a href="https://github.com/kennethreitz/autoenv">autoenv</a>,
  <a href="https://github.com/PyAr/fades">fades</a>,
  <a href="https://gist.github.com/datagrok/2199506#a-better-activate-inve">inve</a>,
  <a href="https://github.com/berdario/pew">pew</a>,
  <a href="https://github.com/kennethreitz/pipenv">pipenv</a>,
  <a href="https://github.com/pyenv/pyenv-virtualenv">pyenv-virtualenv</a>,
  <a href="https://github.com/pyenv/pyenv-virtualenvwrapper">pyenv-virtualenvwrapper</a>,
  <a href="https://github.com/pyenv/pyenv">pyenv</a>,
  <a href="https://github.com/python/cpython/blob/3.6/Tools/scripts/pyvenv">pyvenv</a>,
  <a href="https://github.com/kvbik/rvirtualenv">rvirtualenv</a>,
  <a href="https://github.com/tox-dev/tox">tox</a>,
  <a href="https://github.com/borntyping/v">v</a>,
  <a href="https://docs.python.org/3/library/venv.html" title="The Python Standard Library: venv — Creation of virtual environments">venv</a>,
  <a href="https://pypi.python.org/pypi/vex">vex</a>,
  <a href="http://peak.telecommunity.com/DevCenter/EasyInstall#creating-a-virtual-python">virtual-python</a>,
  <a href="https://github.com/brainsik/virtualenv-burrito">virtualenv-burrito</a>,
  <a href="https://github.com/brbsix/virtualenv-mv">virtualenv-mv</a>,
  <a href="https://github.com/pypa/virtualenv">virtualenv</a>,
  <a href="https://pypi.python.org/pypi/virtualenvwrapper-win">virtualenvwrapper-win</a>,
  <a href="https://pypi.python.org/pypi/virtualenvwrapper">virtualenvwrapper</a>,
  <a href="https://pypi.python.org/pypi/workingenv.py">workingenv</a></p>
</blockquote>

<p>Clearly, this stuff must be really hard to get right.  I also must be a moron, since,
after having written some thousand lines of Python, I don’t even know what problem we are
trying to solve here, and the abundance of relevant programs with subtly different names
has deterred me from reading up on it so far.</p>

<h2 id="so-what-is-a-virtual-environment">So what <em>is</em> a virtual environment?</h2>

<p>The <a href="https://docs.python.org/3/tutorial/venv.html" title="The Python Tutorial: Virtual Environments and Packages">official docs’ tutorial</a> describes a virtual environment as</p>

<blockquote>
  <p>a self-contained directory tree that contains a Python installation for a particular
  version of Python, plus a number of additional packages.</p>
</blockquote>

<p>So it’s a directory with a Python interpreter?  Easy enough.</p>

<div><pre><code><span>$ </span>mkdir virtual_env
<span>$ </span>cp /bin/python3 virtual_env/
</code></pre>
</div>

<p>Let’s see.  Directory?  Check.  Contains a Python installation?  Check.  Contains a number
of additional packages?  Zero is a number!  (Check.)  Particular version?  Um…</p>

<div><pre><code><span>$ </span><span>cd </span>virtual_env/
<span>$ </span>./python3 --version
Python 3.6.3
</code></pre>
</div>

<p>I think that will do.  Is it self-contained, though?  It doesn’t contain itself…</p>

<p><span>
<img src="https://meribold.org/assets/russell.png" alt="Another nerd: Bertrand Russell in 1916" title="Consider the directory containing all directories that don't contain themselves.">
</span></p>

<p>Jokes aside, there are only two things missing to actually make our directory a virtual
environment as specified by <a href="https://www.python.org/dev/peps/pep-0405/" title="PEP 405 -- Python Virtual Environments"><abbr title="Python Enhancement Proposal">PEP</abbr> 405</a>, the proposal that integrated a standard mechanism
for virtual environments with Python.<sup id="fnref:before-405"><a href="#fn:before-405">1</a></sup></p>

<ol>
  <li>A file named <code>pyvenv.cfg</code> containing the line <code>home = /usr/bin</code></li>
  <li>A <code>lib/python3.6/site-packages</code> subdirectory</li>
</ol>

<p>(Both paths are subject to the <abbr title="Operating system">OS</abbr> and the second one also to the Python version used.)</p>

<div><pre><code><span>$ </span><span>echo</span> <span>'home = /usr/bin'</span> &gt; pyvenv.cfg
<span>$ </span>mkdir -p lib/python3.6/site-packages
</code></pre>
</div>

<p>I will also move the Python binary into a <code>bin</code> subdirectory.<sup id="fnref:why-tho"><a href="#fn:why-tho">2</a></sup></p>

<div><pre><code><span>$ </span>mkdir bin <span>&amp;&amp;</span> mv python3 bin/
</code></pre>
</div>

<!-- >   [T]he internal virtual environment layout mimics the layout of the Python installation
>   itself on each platform.  
>   ---<https://www.python.org/dev/peps/pep-0405/#creating-virtual-environments> -->

<p>Fair.  We have a directory that formally qualifies as a virtual environment:</p>

<div><pre><code><span>$ </span>tree --noreport
.
├── bin
│&nbsp;&nbsp; └── python3
├── lib
│&nbsp;&nbsp; └── python3.6
│&nbsp;&nbsp;     └── site-packages
└── pyvenv.cfg
</code></pre>
</div>

<p>This leads us to the next question.</p>

<h2 id="whats-the-point">What’s the point?</h2>

<p>When we run our copy of the Python binary, the <code>pyvenv.cfg</code> file changes what happens
during startup: the presence of the <code>home</code> key tells Python the binary belongs to a
virtual environment, the key’s value (<code>/usr/bin</code>) tells it where to find a complete Python
installation that includes the standard library.</p>

<p>The bottom line is that <code>./lib/python3.6/site-packages</code> becomes part of the <a href="https://docs.python.org/3/library/site.html">module search
path</a>.  The point is that we can now install packages to that location, in particular,
specific versions that may conflict with the dependencies of another Python program on the
same system.<sup id="fnref:python-level-isolation"><a href="#fn:python-level-isolation">3</a></sup></p>

<p>For example, if your project needs exactly version 0.0.3 of
<a href="https://pypi.python.org/pypi/left-pad">left-pad</a>:</p>

<div><pre><code><span>$ </span>pip3 install -t lib/python3.6/site-packages/ left-pad<span>==</span>0.0.3
</code></pre>
</div>

<p>Now this will work:</p>

<div><pre><code><span>$ </span>./bin/python3 -c <span>'import left_pad'</span>
</code></pre>
</div>

<p>While this should raise <a href="https://docs.python.org/3/library/exceptions.html#ModuleNotFoundError"><code>ModuleNotFoundError</code></a>, as desired:</p>

<div><pre><code><span>$ </span>python3 -c <span>'import left_pad'</span>
</code></pre>
</div>

<p>Another project on the same system could have a different version of left-pad in its own
virtual environment, without interfering with this one.</p>

<!--
TODO: talk about isolation from the system-level and user-level site-packages directories?
-->



<p>In practice, one does not simply create virtual environments by hand, which brings us back
to the dauntingly long list of tools above.  Fortunately, one of them is not like the
others.  While it’s predated by most of them, this one ships with Python as part of the
standard library: <a href="https://docs.python.org/3/library/venv.html" title="The Python Standard Library: venv — Creation of virtual environments"><em>venv</em></a>.<sup id="fnref:venv-and-pyvenv"><a href="#fn:venv-and-pyvenv">4</a></sup></p>

<p>In its simplest form, venv is used to create a virtual environment like so:</p>

<div><pre><code><span>$ </span>python3 -m venv virtual_env
</code></pre>
</div>

<p>This creates the <code>virtual_env</code> directory and also copies or symlinks the Python
interpreter:</p>

<div><pre><code><span>$ </span><span>cd </span>virtual_env
<span>$ </span>find -name python3
./bin/python3
</code></pre>
</div>

<p>It also copies a bunch of other stuff: I get 650 files in 89 subdirectories amounting to
about 10 MiB in total.  One of those files is the <code>pip</code> binary, and we can use it to
install packages into the virtual environment without passing extra command-line
arguments:</p>

<div><pre><code><span>$ </span>./bin/pip install left-pad
</code></pre>
</div>

<p>You can read more about using venv and <em>optional</em> magic like “activate” scripts in the
<a href="https://docs.python.org/3/tutorial/venv.html">Python tutorial</a> or venv’s
<a href="https://docs.python.org/3/library/venv.html">documentation</a>—this post is only meant to
boil down what a virtual environment actually is.</p>

<h2 id="summary">Summary</h2>

<p>A virtual environment is a directory containing a Python interpreter, a special
<code>pyvenv.cfg</code> file that affects startup of the interpreter, and some third-party Python
packages.  Python packages installed into a virtual environment will not interfere with
other Python applications on the same system.  The “<a href="https://docs.python.org/3/installing/">standard tool for creating virtual
environments</a>” is venv.</p>

<h2 id="appendix-history">Appendix: History</h2>

<!-- TODO: When and by whom was the term "virtual environment" coined? -->

<p>I think Ian Bicking’s <a href="https://web.archive.org/web/20051203055434/http://svn.colorstudy.com/home/ianb/non_root_python.py"><code>non_root_python.py</code></a> qualifies as the first tool for creating
virtual environments.  Based on that, <a href="http://peak.telecommunity.com/dist/virtual-python.py"><code>virtual-python.py</code></a> was
<a href="https://github.com/pypa/setuptools/commit/3df2aabcc056e6d001355d4cec780437387ac4fa">added</a> to <a href="https://en.wikipedia.org/wiki/Setuptools#EasyInstall">EasyInstall</a> in version
<a href="http://peak.telecommunity.com/DevCenter/EasyInstall#release-notes-change-history">0.6a6</a> in October 2005.  Here’s a timeline summarizing some
main events.</p>

<dl>
  <dt>2005-10-17</dt>
  <dd><a href="http://peak.telecommunity.com/dist/virtual-python.py"><code>virtual-python.py</code></a> is <a href="https://github.com/pypa/setuptools/commit/3df2aabcc056e6d001355d4cec780437387ac4fa">added</a> to EasyInstall.</dd>
  <dt>2006-03-08</dt>
  <dd>Ian Bicking, the author of <a href="https://web.archive.org/web/20051203055434/http://svn.colorstudy.com/home/ianb/non_root_python.py"><code>non_root_python.py</code></a>—on which <a href="http://peak.telecommunity.com/dist/virtual-python.py"><code>virtual-python.py</code></a>
is based—publishes a blog post about improving <a href="http://peak.telecommunity.com/dist/virtual-python.py"><code>virtual-python.py</code></a> titled
“<a href="http://www.ianbicking.org/working-env-brainstorm.html">Working Environment Brainstorm</a>”.</dd>
  <dt>2006-03-15</dt>
  <dd>Ian Bicking <a href="http://www.ianbicking.org/working-env.html">announces</a> <a href="https://web.archive.org/web/20060425105635/http://svn.colorstudy.com/home/ianb/working-env.py"><code>working-env.py</code></a>.</dd>
  <dt>2006-04-26</dt>
  <dd>Ian Bicking <a href="http://www.ianbicking.org/workingenv-revisited.html">announces</a> an improved version of
<a href="https://web.archive.org/web/20060425105635/http://svn.colorstudy.com/home/ianb/working-env.py"><code>working-env.py</code></a> called <a href="https://web.archive.org/web/20060516191525/http://svn.colorstudy.com:80/home/ianb/workingenv">workingenv</a>.
<!-- 
TODO: did anything important happen here?
 --></dd>
  <dt>2007-09-14</dt>
  <dd><a href="https://github.com/pypa/virtualenv/commit/e02aa46f4f0eb5321c31641e89bde2c9b92547bb">virtualenv</a>’s first commit</dd>
  <dt>2007-10-10</dt>
  <dd>Ian Bicking announces <a href="https://github.com/pypa/virtualenv">virtualenv</a>: “<a href="http://www.ianbicking.org/blog/2007/10/workingenv-is-dead-long-live-virtualenv.html">Workingenv is dead, long live
Virtualenv!</a>”</dd>
  <dt>2009-10-24</dt>
  <dd><a href="http://peak.telecommunity.com/dist/virtual-python.py"><code>virtual-python.py</code></a> is <a href="https://github.com/pypa/setuptools/commit/43d34734c801d2d9a72d5fa6e7fc74d80bdc11c1">removed</a> from EasyInstall.
<!-- 
TODO: did anything important happen here?
 --></dd>
  <dt>2011-06-13</dt>
  <dd><a href="https://www.python.org/dev/peps/pep-0405/" title="PEP 405 -- Python Virtual Environments"><abbr title="Python Enhancement Proposal">PEP</abbr> 405</a> is created.</dd>
  <dt>2012-05-25</dt>
  <dd><a href="https://www.python.org/dev/peps/pep-0405/" title="PEP 405 -- Python Virtual Environments"><abbr title="Python Enhancement Proposal">PEP</abbr> 405</a> is accepted for inclusion in Python 3.3.</dd>
  <dt>2012-09-29</dt>
  <dd><a href="https://docs.python.org/dev/whatsnew/3.3.html#pep-405-virtual-environments">Python 3.3</a> is released; <a href="https://docs.python.org/3/library/venv.html" title="The Python Standard Library: venv — Creation of virtual environments">venv</a> and <a href="https://github.com/python/cpython/blob/3.6/Tools/scripts/pyvenv">pyvenv</a> become part of the
standard library.</dd>
  <dt>2014-03-16</dt>
  <dd><a href="https://docs.python.org/dev/whatsnew/3.4.html">Python 3.4</a> is released; “<a href="https://docs.python.org/3/installing/">[venv] defaults to installing <abbr title="pip installs packages">pip</abbr> into all created
virtual environments.</a>”</dd>
  <dt>2015-09-13</dt>
  <dd><a href="https://docs.python.org/dev/whatsnew/3.5.html">Python 3.5</a> is released.  “<a href="https://docs.python.org/3/installing/">The use of venv is now recommended for creating virtual
environments.</a>”</dd>
  <dt>2016-12-23</dt>
  <dd><a href="https://docs.python.org/dev/whatsnew/3.6.html#id8">Python 3.6</a> is released; “<a href="https://docs.python.org/3/installing/">pyvenv was the recommended tool for creating virtual
environments for Python 3.3 and 3.4, and is deprecated in Python 3.6.</a>”</dd>
</dl>

<h2 id="image-sources">Image sources</h2>

<p>The “Virtual Boy” image is used with permission from <a href="https://en.wikipedia.org/wiki/James_Rolfe">James
Rolfe</a>.</p>



<!-- vim: set tw=90 sts=-1 sw=4 et spell wrap: -->


</article>

    </div></div>]]>
            </description>
            <link>https://meribold.org/python/2018/02/13/virtual-environments-9487/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25611307</guid>
            <pubDate>Sat, 02 Jan 2021 08:31:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A review of endianness bugs in Qt, and how they were fixed]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25611172">thread link</a>) | @pabs3
<br/>
January 1, 2021 | https://mitya57.me/weblog/2021/01/qt-big-endian-history.html | <a href="https://web.archive.org/web/*/https://mitya57.me/weblog/2021/01/qt-big-endian-history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article itemscope="" itemtype="http://schema.org/Article">
			
		
		
		
		<p>As you may know, I am Qt 5 maintainer in Debian. Maintaning Qt means not only
bumping the version each time a new version is released, but also making sure
Qt builds successfully on all architectures that are supported in Debian (and
for some submodules, the automatic tests pass).</p>
<p>An important sort of build failures are endianness specific failures. Most
widely used architectures (x86_64, aarch64) are little endian. However, Debian
officially supports one big endian architecture (<a href="https://en.wikipedia.org/wiki/Linux_on_IBM_Z">s390x</a>), and unofficially
a few more ports are provided, such as <a href="https://wiki.debian.org/PPC64">ppc64</a> and <a href="https://wiki.debian.org/Sparc64">sparc64</a>.</p>
<p>Unfortunately, Qt upstream does not have any big endian machine in their CI
system, so endianness issues get noticed only when the packages fail to build
on our build daemons. In the last years I have discovered and fixed some such
issues in various parts of Qt, so I decided to write a post to illustrate how
to write really cross-platform C/C++ code.</p>
<h2>Issue 1: the WebP image format handler (<a href="https://codereview.qt-project.org/c/qt/qtimageformats/+/86275">code review</a>)</h2>
<p>The relevant code snippet is:</p>
<div><pre><span></span><code><span>if</span> <span>(</span><span>srcImage</span><span>.</span><span>format</span><span>()</span> <span>!=</span> <span>QImage</span><span>::</span><span>Format_ARGB32</span><span>)</span>
    <span>srcImage</span> <span>=</span> <span>srcImage</span><span>.</span><span>convertToFormat</span><span>(</span><span>QImage</span><span>::</span><span>Format_ARGB32</span><span>);</span>
<span>// ...</span>
<span>if</span> <span>(</span><span>!</span><span>WebPPictureImportBGRA</span><span>(</span><span>&amp;</span><span>picture</span><span>,</span> <span>srcImage</span><span>.</span><span>bits</span><span>(),</span> <span>srcImage</span><span>.</span><span>bytesPerLine</span><span>()))</span> <span>{</span>
    <span>// ...</span>
<span>}</span>
</code></pre></div>

<p>The code here is serializing the images into <code>QImage::Format_ARGB32</code> format, and
then passing the bytes into WebP’s import function. With this format, the image
is stored using a 32-bit ARGB format (0xAARRGGBB). This means that the bytes
will be 0xBB, 0xGG, 0xRR, 0xAA or little endian and 0xAA, 0xRR, 0xGG, 0xBB on
big endian. However, <code>WebPPictureImportBGRA</code> expects the first format on all
architectures.</p>
<p>The fix was to use <code>QImage::Format_RGBA8888</code>. As the <a href="https://doc.qt.io/qt-5/qimage.html#Format-enum">QImage documentation</a>
says, with this format <em>the order of the colors is the same on any architecture
if read as bytes 0xRR, 0xGG, 0xBB, 0xAA</em>.</p>
<h2>Issue 2: <code>qimage_converter_map</code> structure (<a href="https://codereview.qt-project.org/c/qt/qtbase/+/101769">code review</a>)</h2>
<p>The code seems to already support big endian. But maybe you can spot the error?</p>
<div><pre><span></span><code><span>#if Q_BYTE_ORDER == Q_LITTLE_ENDIAN</span>
        <span>0</span><span>,</span>
        <span>convert_ARGB_to_ARGB_PM</span><span>,</span>
<span>#else</span>
        <span>0</span><span>,</span>
        <span>0</span>
<span>#endif</span>
</code></pre></div>

<p>It is the missing comma! It is present in the little endian block, but not in
the big endian one. This was fixed trivially.</p>
<h2>Issue 3: QHandle, part of Qt 3D module (<a href="https://codereview.qt-project.org/c/qt/qt3d/+/162737">code review</a>)</h2>
<p>QHandle class uses a union that is declared as follows:</p>
<div><pre><span></span><code><span>struct</span> <span>Data</span> <span>{</span>
    <span>quint32</span> <span>m_index</span> <span>:</span> <span>IndexBits</span><span>;</span>
    <span>quint32</span> <span>m_counter</span> <span>:</span> <span>CounterBits</span><span>;</span>
    <span>quint32</span> <span>m_unused</span> <span>:</span> <span>2</span><span>;</span>
<span>};</span>
<span>union</span> <span>{</span>
    <span>Data</span> <span>d</span><span>;</span>
    <span>quint32</span> <span>m_handle</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>The sizes are declared such as IndexBits + CounterBits + 2 is always
equal to 32 (four bytes).</p>
<p>Then we have a constructor that sets the values of Data struct:</p>
<div><pre><span></span><code><span>QHandle</span><span>(</span><span>quint32</span> <span>i</span><span>,</span> <span>quint32</span> <span>count</span><span>)</span>
<span>{</span>
    <span>d</span><span>.</span><span>m_index</span> <span>=</span> <span>i</span><span>;</span>
    <span>d</span><span>.</span><span>m_counter</span> <span>=</span> <span>count</span><span>;</span>
    <span>d</span><span>.</span><span>m_unused</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>The value of <code>m_handle</code> will be different depending on endianness!
So the test that was expecting a particular value with given constructor
arguments was failing. I fixed it by using the following macro:</p>
<div><pre><span></span><code><span>#if Q_BYTE_ORDER == Q_BIG_ENDIAN</span>
<span>#define GET_EXPECTED_HANDLE(qHandle) ((qHandle.index() &lt;&lt; (qHandle.CounterBits + 2)) + (qHandle.counter() &lt;&lt; 2))</span>
<span>#else </span><span>/* Q_LITTLE_ENDIAN */</span><span></span>
<span>#define GET_EXPECTED_HANDLE(qHandle) (qHandle.index() + (qHandle.counter() &lt;&lt; qHandle.IndexBits))</span>
<span>#endif</span>
</code></pre></div>

<h2>Issue 4: QML compiler (<a href="https://codereview.qt-project.org/c/qt/qtdeclarative/+/197746">code review</a>)</h2>
<p>The QML compiler used a helper class named LEUInt32 (based on <a href="https://doc.qt.io/qt-5/qleinteger.html">QLEInteger</a>)
that always stored the numbers in little endian internally. This class
can be safely mixed with native quint32 on little endian systems, but not
on big endian.</p>
<p>Usually the compiler would warn about type mismatch, but here the code used
<code>reinterpret_cast</code>, such as:</p>
<div><pre><span></span><code><span>quint32</span> <span>*</span><span>objectTable</span> <span>=</span> <span>reinterpret_cast</span><span>&lt;</span><span>quint32</span><span>*&gt;</span><span>(</span><span>data</span> <span>+</span> <span>qmlUnit</span><span>-&gt;</span><span>offsetToObjects</span><span>);</span>
</code></pre></div>

<p>So this was not noticed on build time, but the compiler was crashing. The fix
was trivial again, replacing quint32 with QLEUInt32.</p>
<h2>Issue 5: QModbusPdu, part of Qt Serial Bus module (<a href="https://codereview.qt-project.org/c/qt/qtserialbus/+/245206">code review</a>)</h2>
<p>The code snippet is simple:</p>
<div><pre><span></span><code><span>QModbusPdu</span><span>::</span><span>FunctionCode</span> <span>code</span> <span>=</span> <span>QModbusPdu</span><span>::</span><span>Invalid</span><span>;</span>
<span>if</span> <span>(</span><span>stream</span><span>.</span><span>readRawData</span><span>((</span><span>char</span> <span>*</span><span>)</span> <span>(</span><span>&amp;</span><span>code</span><span>),</span> <span>sizeof</span><span>(</span><span>quint8</span><span>))</span> <span>!=</span> <span>sizeof</span><span>(</span><span>quint8</span><span>))</span>
    <span>return</span> <span>stream</span><span>;</span>
</code></pre></div>

<p><code>QModbusPdu::FunctionCode</code> is an enum, so <code>code</code> is a multi-byte value (even if
only one byte is significant). However, <code>(char *) (&amp;code)</code> returns a pointer to
the first byte of it. It is the needed byte on little endian systems, but it is
the wrong byte on big endian ones!</p>
<p>The correct fix was using a temporary one-byte variable:</p>
<div><pre><span></span><code><span>quint8</span> <span>codeByte</span> <span>=</span> <span>0</span><span>;</span>
<span>if</span> <span>(</span><span>stream</span><span>.</span><span>readRawData</span><span>((</span><span>char</span> <span>*</span><span>)</span> <span>(</span><span>&amp;</span><span>codeByte</span><span>),</span> <span>sizeof</span><span>(</span><span>quint8</span><span>))</span> <span>!=</span> <span>sizeof</span><span>(</span><span>quint8</span><span>))</span>
    <span>return</span> <span>stream</span><span>;</span>
<span>QModbusPdu</span><span>::</span><span>FunctionCode</span> <span>code</span> <span>=</span> <span>(</span><span>QModbusPdu</span><span>::</span><span>FunctionCode</span><span>)</span> <span>codeByte</span><span>;</span>
</code></pre></div>

<h2>Issue 6: <code>qt_is_ascii</code> (<a href="https://codereview.qt-project.org/c/qt/qtbase/+/258164">code review</a>)</h2>
<p>This function, as the name says, checks whether a string is ASCII. It does
that by splitting the string into 4-byte chunks:</p>
<div><pre><span></span><code><span>while</span> <span>(</span><span>ptr</span> <span>+</span> <span>4</span> <span>&lt;=</span> <span>end</span><span>)</span> <span>{</span>
    <span>quint32</span> <span>data</span> <span>=</span> <span>qFromUnaligned</span><span>&lt;</span><span>quint32</span><span>&gt;</span><span>(</span><span>ptr</span><span>);</span>
    <span>if</span> <span>(</span><span>data</span> <span>&amp;=</span> <span>0x80808080U</span><span>)</span> <span>{</span>
        <span>uint</span> <span>idx</span> <span>=</span> <span>qCountTrailingZeroBits</span><span>(</span><span>data</span><span>);</span>
        <span>ptr</span> <span>+=</span> <span>idx</span> <span>/</span> <span>8</span><span>;</span>
        <span>return</span> <span>false</span><span>;</span>
    <span>}</span>
    <span>ptr</span> <span>+=</span> <span>4</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><code>idx / 8</code> is the number of trailing zero bytes. However, the bytes which are
trailing on little endian are actually leading on big endian! So we can use
<code>qCountLeadingZeroBits</code> there.</p>
<h2>Issue 7: the bundled copy of tinycbor (<a href="https://github.com/thiagomacieira/tinycbor/pull/1">upstream pull request</a>)</h2>
<p>Similar to issue 5, the code was reading into the wrong byte:</p>
<div><pre><span></span><code><span>if</span> <span>(</span><span>bytesNeeded</span> <span>&lt;=</span> <span>2</span><span>)</span> <span>{</span>
    <span>read_bytes_unchecked</span><span>(</span><span>it</span><span>,</span> <span>&amp;</span><span>it</span><span>-&gt;</span><span>extra</span><span>,</span> <span>1</span><span>,</span> <span>bytesNeeded</span><span>);</span>
    <span>if</span> <span>(</span><span>bytesNeeded</span> <span>==</span> <span>2</span><span>)</span>
        <span>it</span><span>-&gt;</span><span>extra</span> <span>=</span> <span>cbor_ntohs</span><span>(</span><span>it</span><span>-&gt;</span><span>extra</span><span>);</span>
<span>}</span>
</code></pre></div>

<p><code>extra</code> has type uint16_t, so it has two bytes. When we need only one byte,
we read into the wrong byte, so the resulting number is 256 times higher on
big endian than it should be. Adding a temporary one-byte variable fixed it.</p>
<h2>Issue 8: perfparser, part of Qt Creator (<a href="https://codereview.qt-project.org/c/qt-creator/perfparser/+/305990">code review</a>)</h2>
<p>Here it is not trivial to find the issue just looking at the code:</p>
<div><pre><span></span><code><span>qint32</span> <span>dataStreamVersion</span> <span>=</span> <span>qToLittleEndian</span><span>(</span><span>QDataStream</span><span>::</span><span>Qt_DefaultCompiledVersion</span><span>);</span>
</code></pre></div>

<p>However the linker was producing an error:</p>
<blockquote>
<p>undefined reference to `QDataStream::Version qbswap<qdatastream::version>(QDataStream::Version)'</qdatastream::version></p>
</blockquote>
<p>On little endian systems, <code>qToLittleEndian</code> is a no-op, but on big endian
systems, it is a template function defined for some known types. But it turns
out we need to explicitly convert enum values to a simple type, so the fix
was passing <code>qint32(QDataStream::Qt_DefaultCompiledVersion)</code> to that function.</p>
<h2>Issue 9: Qt Personal Information Management (<a href="https://codereview.qt-project.org/c/qt/qtpim/+/319865">code review</a>)</h2>
<p>The code in test was trying to represent a number as a sequence of bytes,
using <code>reinterpret_cast</code>:</p>
<div><pre><span></span><code><span>static</span> <span>inline</span> <span>QContactId</span> <span>makeId</span><span>(</span><span>const</span> <span>QString</span> <span>&amp;</span><span>managerName</span><span>,</span> <span>uint</span> <span>id</span><span>)</span>
<span>{</span>
    <span>return</span> <span>QContactId</span><span>(</span><span>QStringLiteral</span><span>(</span><span>"qtcontacts:basic%1:"</span><span>).</span><span>arg</span><span>(</span><span>managerName</span><span>),</span> <span>QByteArray</span><span>(</span><span>reinterpret_cast</span><span>&lt;</span><span>const</span> <span>char</span> <span>*&gt;</span><span>(</span><span>&amp;</span><span>id</span><span>),</span> <span>sizeof</span><span>(</span><span>uint</span><span>)));</span>
<span>}</span>
</code></pre></div>

<p>The order of bytes will be different on little endian and big endian systems!
The fix was adding this line to the beginning of the function:</p>
<div><pre><span></span><code><span>id</span> <span>=</span> <span>qToLittleEndian</span><span>(</span><span>id</span><span>);</span>
</code></pre></div>

<p>This will cause the bytes to be reversed on big endian systems.</p>
<h2>What remains unfixed</h2>
<p>There are still some bugs, which require deeper investigation, for example:</p>
<ul>
<li><a href="https://bugreports.qt.io/browse/QTBUG-56806">https://bugreports.qt.io/browse/QTBUG-56806</a></li>
<li><a href="https://bugreports.qt.io/browse/QTBUG-56975">https://bugreports.qt.io/browse/QTBUG-56975</a></li>
</ul>
<p>P.S. We are <a href="https://perezmeyer.blogspot.com/2020/08/stepping-down-as-qt-6-maintainers.html">looking for new people</a> to help with maintaining Qt 6.
Join our team if you want to do some fun work like described above!</p>	

	</article>

		  </div>	
		  
		  

	  </div></div>]]>
            </description>
            <link>https://mitya57.me/weblog/2021/01/qt-big-endian-history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25611172</guid>
            <pubDate>Sat, 02 Jan 2021 07:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing Out Algebraic Effects in OCaml for Game Animations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25611061">thread link</a>) | @gopiandcode
<br/>
January 1, 2021 | http://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html | <a href="https://web.archive.org/web/*/http://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article role="article">

<small>
<time datetime="2021-01-01T07:56:45+00:00">January</time>
<time datetime="2021-01-01T07:56:45+00:00">01</time>
<time datetime="2021-01-01T07:56:45+00:00">2021</time>
</small>
<a href="file:///home/kirang/org/html/tags.html#ocaml"><small>#ocaml</small></a>
<a href="file:///home/kirang/org/html/tags.html#effects"><small>#effects</small></a>
<a href="file:///home/kirang/org/html/tags.html#animations"><small>#animations</small></a>
<a href="file:///home/kirang/org/html/tags.html#game"><small>#game</small></a>
<div id="text-orgeddd4fe">
<p>
Recently, I had the pleasure of talking with KC Sivaramakrishnan - one
of the lead developers of the OCaml multicore project - when he came
to NUS to give us a talk on his work on multicore and a potential new
language feature for OCaml: <b>Algebraic effects</b>.  At a high level, the
run-down on algebraic effects is that they can be considered as a sort
of alternative to monads,<sup><a id="fnr.1" href="#fn.1">1</a></sup> however with the key benefit that they
<i>play a lot nicer</i> with existing direct-style code and thus might be a
<i>more fluid</i> and <i>ergonomic</i> tool.  One of my most surprising takeaways
from meeting KC was in realising the significant amount of progress
that had already been made on implementing algebraic effects in
OCaml - in fact, algebraic effects, far from just being a far-off
pipe-dream (cough, modular implicits, cough), are actually at a point
where it is possible (<i>fairly easy even</i>) to play with them right now
(albeit using an experimental fork of the OCaml compiler).
</p>

<p>
Indeed, this is exactly what I have been working on over the past few
weeks - so moved was I by the world of possibilities opened up by this
development, I immediately set about experimenting on inserting
algebraic effects into various OCaml projects that I happened have
handy at the time.  Over the course of these experiments, I ended up
considering the application of algebraic effects to functional game
development, and in the process stumbled upon a rather elegant pattern
for representing animations in a functional style.  In fact, this
pattern actually ended up solving a longstanding issue I was having
with managing the control flow for animations alongside game logic,
and so I think it forms a rather nice setting for exploring the
benefits of algebraic effects, hence this post.
</p>

 


<p>
In the rest of this blog post, I'm going to provide a <i>gentle
introduction</i> to algebraic effects, provided in the context of their
use in implementing <b>functional game animations</b> - we'll look at using
algebraic effects to implement 3 different case studies of <i>relatively
complex</i> animations (see above) for games in a fluid and elegant way.
Hopefully, through exploring these case-studies, you should be able to
gain a better understanding of the pros and cons of algebraic effects
and why they are certainly something to be excited about.
</p>

<p>
The executable code for the entire blog post can be found at:<sup><a id="fnr.2" href="#fn.2">2</a></sup> <a href="https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects">https://gitlab.com/gopiandcode/ocaml-game-animations-with-algebraic-effects</a>
</p>
</div>

<div id="outline-container-orgbc783f7">
<h3 id="orgbc783f7">The vision: Functional Game Development</h3>
<div id="text-orgbc783f7">
<p>
While our final code uses a mix of functional and imperative code (as
is idiomatic OCaml style), our journey really begins in the world of
pure functional games.
</p>

<div> 
<p><img src="http://gopiandcode.uk/images/functional_update.png" alt="functional_update.png"></p><div><p> 
Fundamentally, functional games work by separating
the execution of a game into two distinct functions representing the main phases of the game loop:
</p>
<ul>
<li><b>an update function</b> that takes user input and time and updates the state of the world</li>
<li><b>a draw function</b> that displays the current state of the world to the
screen.</li>
</ul>
<p>
The idea here is that while the state of the game may change over time, the individual update and draw functions are pure and referentially transparent, and thus come with all the usual benefits of functional code (modularity and compositionality, reusable code, easier to reason about etc.).
</p></div> 
</div> 


<p>
To see these ideas in practice, suppose we wanted to implement a simple menu for a game:
</p><p><img src="http://gopiandcode.uk/images/a_game_menu.png" alt="a_game_menu.png">
</p> 


<p>
Following the functional approach, we could define the state of our menu as follows:
</p>
<div>
<pre><span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> int<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
Using this fairly simple state, we can easily
write a pure draw function for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>draw_item</span><span> </span><span>~</span><span>pos </span><span>~</span><span>is_active txt</span> <span>=</span> <span>...</span> <span>(* </span><span>draw an individual menu item </span><span>*)</span>

<span>let</span> <span>draw</span> <span>{</span>selected<span>;</span>options<span>}</span> <span>=</span>
    <span>List.</span>iteri <span>(</span><span>fun</span> <span>ind option</span> <span>-&gt;</span>  
       draw_item <span>~pos</span><span>:</span>ind <span>~is_active</span><span>:(</span>ind <span>=</span> selected<span>)</span> option
    <span>)</span> options
</pre>
</div>

<p>
Similarly, if we wanted to make the menu respond to user inputs, we
can write a functional update operation for the menu as follows:
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key</span> <span>=</span> 
   <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
   <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
   <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
   <span>match</span> key <span>with</span>
   <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> next menu.selected<span>}</span>
   <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> prev menu.selected<span>}</span>
</pre>
</div>

<p>
Hooking these all up together, the main loop for our program might then look as follows:
</p>
<div>
<pre><span>let</span> <span>main</span><span> </span><span>()</span> <span>:</span> <span>unit</span> <span>=</span> 
   <span>let</span> <span>rec</span> <span>loop</span><span> menu</span> <span>=</span> 
      draw menu<span>;</span>
      <span>let</span> <span>input</span> <span>=</span> get_input <span>()</span> <span>in</span>
      <span>let</span> <span>menu</span> <span>=</span> update menu input <span>in</span>
      loop menu <span>in</span>
   loop <span>{</span>selected<span>=</span>0<span>;</span> options<span>=[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]}</span>
</pre>
</div>

<p>
And tada! We now have a fully functional menu that <i>dynamically</i>
responds and updates to user inputs, and we were able to do it all
without having to ever dirty our hands with any <b>evil impure code</b>.
</p>

<p><img src="http://gopiandcode.uk/images/functional_menu.png" alt="functional_menu.png">
</p> 


<p>
Functional game development sounds great, right?
</p>
</div>
</div>

<div id="outline-container-orge7daf0a">
<h3 id="orge7daf0a">The challenge: Managing animations</h3>
<div id="text-orge7daf0a">
<p>
The stuff that I presented in the previous section is nothing new -
there are countless prior blog posts and videos on the web that all
describe this style of a game engine, and it paints a very pretty
picture.
</p>

<p>
Unfortunately, I am afraid to say, not all is as it seems in the land
of functional game development, and when you start using this
methodology to develop any kind of <i>non-trivial</i> games, you can quickly
find yourself running into edge-cases, and one <i>particularly nefarious</i>
example of such issues is handling animations.
</p>

<p>
Returning back to our running example of a game menu, suppose we now
wanted to come back and add a <i>simple</i> quality of life feature to our
menu - nothing complex, just a <b>fade-in</b> between states of the menu.
</p>

<p>
In other words, when the user presses a button, there should be small
<b>time-delay</b> as the menu <i>gradually transitions</i> from the original state
to the new one:
</p>

<p><img src="http://gopiandcode.uk/images/functional_animation.png" alt="functional_animation.png"> 
</p> 


<p>
<i>Okay, sure - that's not a complex transformation - so this should be
simple to implement within our framework, right?</i>
</p>

<div> 
<p><img src="http://gopiandcode.uk/images/functional_update_q.png" alt="functional_update_q.png"></p><div> 


<p>
<b>Unfortunately, no.</b>
</p>

<p>
Our methodology so far was based entirely around the assumption that
the update function is <i>pure</i> and <i>stateless</i> and should be called on each
frame of the game.
</p>

<p>
As such, if we were to return a new menu with the next item selected
when the user presses down, the <b>transformation would be immediate</b>
rather than the <i>gradual change</i> we want.
</p>

<p>
<i>So what exactly should we return from our update function then?</i>
</p></div> 
</div> 


<p>
If one were to strictly adhere to the functional game development
paradigm, then one hacky way to achieve this would be to explicitly
track the state of animations in the menu.
</p>

<p>
For example, we can update our definition of menu to be as follows:
</p>
<div>
<pre><span>type</span> <span>time</span> <span>=</span> int
<span>type</span> <span>state</span> <span>=</span> <span>Static</span> <span>of</span> int <span>|</span> <span>MovingBetween</span> <span>of</span> int <span>*</span> int <span>*</span> time
<span>type</span> <span>menu</span> <span>=</span> <span>{</span> selected<span>:</span> state<span>;</span> options<span>:</span> string list<span>;</span> <span>}</span>
</pre>
</div>

<p>
The idea here is that the <code>state</code> type tracks the two possible states of the menu and its animations:
</p>
<ul>
<li>either the animation is complete and the menu is static</li>
<li>or the menu is in the middle of an animation between two states
with some amount of <code>time</code> (in ms) remaining.</li>
</ul>

<p>
With this change, we can then write our update function as follows
(now updated to take an additional time parameter tracking the time
between frames):
</p>
<div>
<pre><span>let</span> <span>update</span><span> menu key delta</span> <span>=</span> 
  <span>let</span> <span>len</span> <span>=</span> length menu.options <span>in</span>
  <span>let</span> <span>next</span><span> pos</span> <span>=</span> <span>(</span>pos <span>+</span> 1<span>)</span> <span>mod</span> len <span>in</span>
  <span>let</span> <span>prev</span><span> pos</span> <span>=</span> <span>(</span>pos <span>-</span> 1 <span>+</span> len<span>)</span> <span>mod</span> len <span>in</span>
  <span>match</span> menu.state <span>with</span>
  <span>|</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span>new_ind<span>,</span> remaining<span>)</span> <span>-&gt;</span>
    <span>let</span> <span>remaining</span> <span>=</span> remaining <span>-</span> delta <span>in</span>
    <span>if</span> remaining <span>&lt;</span> 0 <span>(* </span><span>is animation completed? </span><span>*)</span>
    <span>then</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>Static</span> new_ind<span>}</span> <span>(* </span><span>yes: return to static </span><span>*)</span>
    <span>else</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>old_ind<span>,</span> new_ind<span>,</span> remaining<span>)}</span>
  <span>|</span> <span>Static</span> ind <span>-&gt;</span>
    <span>match</span> key <span>with</span> <span>(* </span><span>only process inputs when animations completed </span><span>*)</span>
    <span>|</span> <span>Up</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> next menu.selected<span>,</span> 100<span>)}</span>
    <span>|</span> <span>Down</span> <span>-&gt;</span> <span>{</span>menu <span>with</span> selected <span>=</span> <span>MovingBetween</span> <span>(</span>ind<span>,</span> prev menu.selected<span>,</span> 100<span>)}</span>
</pre>
</div>
<p>
So this will work decently well, however, we're now starting to mix
our animation code with the logic of the program, making it harder to
understand and also more probable for bugs to creep in.  Additionally,
while this happens to work for our simple example, the pattern isn't
scalable - adding more animations would require rewriting the entire
function.
</p>

<p>
Clearly, taking this purely functional approach to games development
has some <b>serious difficulties</b> with managing animations, but it would
be unfair to say that this is uniquely due to the functional
approach:
</p>

<p><b><i>The challenge of balancing animations flow with logic is inherent to the domain</i></b>
</p>


<p>
For the rest of this blog post, we'll shift gears to investigate how
algebraic effects can be used to implement animations when dealing
with a slightly more imperative game structure, however this is mainly
to simplify the implementation: the core ideas presented below can be
easily ported to a pure implementation.
</p>
</div>
</div>

<div id="outline-container-org0873648">
<h3 id="org0873648">Algebraic effects to the rescue</h3>
<div id="text-org0873648">
<p>
Taking a step back from our previous example, the fundamental issue
was that we were trying to mix <b>two</b> separate threads of control - one
for the core logic, and a separate one for the animation - in other
words, what we need is some kind of <b>non-local control flow</b>.
</p>

<p>
….as it just so happens, this is exactly the functionality that
algebraic effects provide.
</p>
</div>

<div id="outline-container-org7da722a">
<h4 id="org7da722a">What are algebraic effects?</h4>
<div id="text-org7da722a">
<p>
We'll sidestep a more detailed discussion of the theory, and instead
focus on the general picture for the end user: algebraic effects as
effectively "resumable" exceptions.<sup><a id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
When defining an effect, the user specifies the type of the input
supplied by the caller, and the type of the output that the effect
should return on completion:
</p>


<p>
To perform an effect, we can use the builtin primitive perform:
</p>

<p>
At this point, the execution of the current program is stopped (much
like an exception), and control changes up the stack until the nearest
effect handler:
</p>
<div>
<pre><span>try</span> 
   <span>...</span>
   perform <span>(</span><span>A</span> 1<span>)</span>
   <span>...</span>   
<span>with</span> 
  <span>|</span> effect <span>(</span><span>A</span> v<span>)</span> k <span>-&gt;</span>
    <span>(* </span><span>control changes to here </span><span>*)</span>
</pre>
</div>
<p>
At the site of the effect handler, the user …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html">http://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</a></em></p>]]>
            </description>
            <link>http://gopiandcode.uk/logs/log-bye-bye-monads-algebraic-effects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25611061</guid>
            <pubDate>Sat, 02 Jan 2021 07:23:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taskflow v3.0 Released – General-Purpose Heterogeneous Task Programming System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25610811">thread link</a>) | @twhuang
<br/>
January 1, 2021 | https://taskflow.github.io/taskflow/release-3-0-0.html | <a href="https://web.archive.org/web/*/https://taskflow.github.io/taskflow/release-3-0-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
  <div>
    <div>
      <div>
        
        
<p>Taskflow 3.0.0 is the 1st release in the 3.x line! This release includes several new changes such as CPU-GPU tasking, algorithm collection, enhanced web-based profiler, documentation, and unit tests.</p><section id="release-3-0-0_download"><h2><a href="#release-3-0-0_download">Download</a></h2><p>Taskflow 3.0.0 can be downloaded from <a href="https://github.com/taskflow/taskflow/releases/tag/v3.0.0">here</a>.</p></section><section id="release-3-0-0_system_requirements"><h2><a href="#release-3-0-0_system_requirements">System Requirements</a></h2><p>To use Taskflow v3.0.0, you need a compiler that supports C++17:</p><ul><li>GNU C++ Compiler at least v7.0 with -std=c++17</li><li>Clang C++ Compiler at least v6.0 with -std=c++17</li><li>Microsoft Visual Studio at least v19.27 with /std:c++17</li><li>AppleClang Xode Version at least v12.0 with -std=c++17</li><li>Nvidia CUDA Toolkit and Compiler (nvcc) at least v11.1 with -std=c++17</li><li>Intel C++ Compiler (nvcc) at least v19.0.1 with -std=c++17</li></ul><p>Taskflow works on Linux, Windows, and Mac OS X.</p></section><section id="release-3-0-0_working_items"><h2><a href="#release-3-0-0_working_items">Working Items</a></h2><ul><li>enhancing the taskflow profiler (<a href="https://github.com/taskflow/tfprof">TFProf</a>)</li><li>adding methods for updating <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlow.html">tf::<wbr>cudaFlow</a> (with unit tests)</li><li>adding support for <a href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a></li><li>adding support for <a href="https://developer.nvidia.com/cudnn">cuDNN</a></li><li>adding support for SYCL (ComputeCpp and DPC++)</li></ul></section><section id="release-3-0-0_new_features"><h2><a href="#release-3-0-0_new_features">New Features</a></h2><section id="release-3-0-0_taskflow_core"><h3><a href="#release-3-0-0_taskflow_core">Taskflow Core</a></h3><ul><li>replaced all non-standard libraries with C++17 STL (e.g., <a href="https://en.cppreference.com/w/cpp/utility/optional">std::<wbr>optional</a>, <a href="https://en.cppreference.com/w/cpp/utility/variant">std::<wbr>variant</a>)</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1WorkerView.html">tf::<wbr>WorkerView</a> for users to observe the running works of tasks</li><li>added asynchronous tasking (see <a href="https://taskflow.github.io/taskflow/AsyncTasking.html">Asynchronous Tasking</a>)</li><li>modified <a href="https://taskflow.github.io/taskflow/classtf_1_1ObserverInterface.html#a3e3a9f7f1d43691794e487b8787b01a0">tf::<wbr>ObserverInterface::<wbr>on_entry</a> and <a href="https://taskflow.github.io/taskflow/classtf_1_1ObserverInterface.html#aa59a59a59eadd4eb6ba20ecdfcae882b">tf::<wbr>ObserverInterface::<wbr>on_exit</a> to take <a href="https://taskflow.github.io/taskflow/classtf_1_1WorkerView.html">tf::<wbr>WorkerView</a></li><li>added a custom graph interface to support dynamic polymorphism for tf::cudaGraph</li><li>supported separate compilations between Taskflow and CUDA (see <a href="https://taskflow.github.io/taskflow/CompileTaskflowWithCUDA.html">Compile Taskflow with CUDA</a>)</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1Semaphore.html">tf::<wbr>Semaphore</a> and <a href="https://taskflow.github.io/taskflow/classtf_1_1CriticalSection.html">tf::<wbr>CriticalSection</a> to limit the maximum concurrency</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1Future.html">tf::<wbr>Future</a> to support cancellation of submitted tasks (see <a href="https://taskflow.github.io/taskflow/RequestCancellation.html">Request Cancellation</a>)</li></ul></section><section id="release-3-0-0_cudaflow"><h3><a href="#release-3-0-0_cudaflow">cudaFlow</a></h3><ul><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlowCapturer.html">tf::<wbr>cudaFlowCapturer</a> for building a cudaFlow through stream capture (see <a href="https://taskflow.github.io/taskflow/GPUTaskingcudaFlowCapturer.html">GPU Tasking (cudaFlowCapturer)</a>)</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlowCapturerBase.html">tf::<wbr>cudaFlowCapturerBase</a> for creating custom capturers</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlow.html#a89c389fff64a16e5dd8c60875d3b514d">tf::<wbr>cudaFlow::<wbr>capture</a> for capturing a cudaFlow within a parent cudaFlow</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169">tf::<wbr>Taskflow::<wbr>emplace_on</a> to place a cudaFlow on a GPU</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlow.html#a7f97b68fa7c889db49b26aa71a46a7cf">tf::<wbr>cudaFlow::<wbr>dump</a> and <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlowCapturer.html#a90d1265bcc27647906bed6e6876c9aa7">tf::<wbr>cudaFlowCapturer::<wbr>dump</a> to visualize cudaFlow</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">tf::<wbr>cudaFlow::<wbr>offload</a> and update methods to run and update a cudaFlow explicitly</li><li>supported standalone cudaFlow (see <a href="https://taskflow.github.io/taskflow/GPUTaskingcudaFlow.html#UsecudaFlowInAStandaloneEnvironment">Use cudaFlow in a Standalone Environment</a>)</li><li>supported standalone cudaFlowCapturer (see <a href="https://taskflow.github.io/taskflow/GPUTaskingcudaFlowCapturer.html#UsecudaFlowCapturerInAStandaloneEnvironment">Use cudaFlow Capturer in a Standalone Environment</a>)</li><li>added <a href="https://taskflow.github.io/taskflow/classtf_1_1cublasFlowCapturer.html">tf::<wbr>cublasFlowCapturer</a> to support <a href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a> (see <a href="https://taskflow.github.io/taskflow/LinearAlgebracublasFlowCapturer.html">Linear Algebra (cublasFlowCapturer)</a>)</li></ul></section><section id="release-3-0-0_utilities"><h3><a href="#release-3-0-0_utilities">Utilities</a></h3><ul><li>added utility functions to grab the cuda device properties (see <a href="https://taskflow.github.io/taskflow/cuda__device_8hpp.html">cuda_<wbr>device.hpp</a>)</li><li>added utility functions to control cuda memory (see <a href="https://taskflow.github.io/taskflow/cuda__memory_8hpp.html">cuda_<wbr>memory.hpp</a>)</li><li>added utility functions for common mathematics operations</li><li>added serializer and deserializer libraries to support tfprof</li><li>added per-thread pool for CUDA streams to improve performance</li></ul></section><section id="release-3-0-0_profiler"><h3><a href="#release-3-0-0_profiler">Taskflow Profiler (TFProf)</a></h3><ul><li>added visualization for asynchronous tasks</li><li>added server-based profiler to support large profiling data (see <a href="https://taskflow.github.io/taskflow/Profiler.html">Profile Taskflow Programs</a>)</li></ul></section></section><section id="release-3-0-0_new_algorithms"><h2><a href="#release-3-0-0_new_algorithms">New Algorithms</a></h2><section id="release-3-0-0_cpu_algorithms"><h3><a href="#release-3-0-0_cpu_algorithms">CPU Algorithms</a></h3><ul><li>added parallel sort (see <a href="https://taskflow.github.io/taskflow/ParallelSort.html">Parallel Sort</a>)</li></ul></section><section id="release-3-0-0_gpu_algorithms"><h3><a href="#release-3-0-0_gpu_algorithms">GPU Algorithms</a></h3><ul><li>added single task (see <a href="https://taskflow.github.io/taskflow/SingleTaskCUDA.html">Single Task (cudaFlow)</a>)</li><li>added parallel iterations (see <a href="https://taskflow.github.io/taskflow/ForEachCUDA.html">Parallel Iterations (cudaFlow)</a>)</li><li>added parallel transforms (see <a href="https://taskflow.github.io/taskflow/ParallelTransformsCUDA.html">Parallel Transforms (cudaFlow)</a>)</li><li>added parallel reduction (see <a href="https://taskflow.github.io/taskflow/CUDAReduce.html">Parallel Reduction (cudaFlow)</a>)</li></ul></section></section><section id="release-3-0-0_bug_fixes"><h2><a href="#release-3-0-0_bug_fixes">Bug Fixes</a></h2><ul><li>fixed the bug in stream capturing (need to use <code>ThreadLocal</code> mode)</li><li>fixed the bug in reporting wrong worker ids when compiling a shared library due to the use of <code>thread_local</code> (now with C++17 <code>inline</code> variable)</li></ul></section><section id="release-3-0-0_breaking_changes"><h2><a href="#release-3-0-0_breaking_changes">Breaking Changes</a></h2><ul><li>changed the returned values of asynchronous tasks to be <a href="https://en.cppreference.com/w/cpp/utility/optional">std::<wbr>optional</a> in order to support cancellation (see <a href="https://taskflow.github.io/taskflow/AsyncTasking.html">Asynchronous Tasking</a> and <a href="https://taskflow.github.io/taskflow/RequestCancellation.html">Request Cancellation</a>)</li></ul></section><section id="release-3-0-0_deprecated_items"><h2><a href="#release-3-0-0_deprecated_items">Deprecated and Removed Items</a></h2><ul><li>removed tf::cudaFlow::device; users may call <a href="https://taskflow.github.io/taskflow/classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169">tf::<wbr>Taskflow::<wbr>emplace_on</a> to associate a cudaflow with a GPU device</li><li>removed tf::cudaFlow::join, use <a href="https://taskflow.github.io/taskflow/classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">tf::<wbr>cudaFlow::<wbr>offload</a> instead</li><li>removed the legacy tf::Framework</li><li>removed external mutable use of <a href="https://taskflow.github.io/taskflow/classtf_1_1TaskView.html">tf::<wbr>TaskView</a></li></ul></section><section id="release-3-0-0_documentation"><h2><a href="#release-3-0-0_documentation">Documentation</a></h2><ul><li>added <a href="https://taskflow.github.io/taskflow/CompileTaskflowWithCUDA.html">Compile Taskflow with CUDA</a></li><li>added <a href="https://taskflow.github.io/taskflow/BenchmarkTaskflow.html">Benchmark Taskflow</a></li><li>added <a href="https://taskflow.github.io/taskflow/LimitTheMaximumConcurrency.html">Limit the Maximum Concurrency</a></li><li>added <a href="https://taskflow.github.io/taskflow/AsyncTasking.html">Asynchronous Tasking</a></li><li>added <a href="https://taskflow.github.io/taskflow/GPUTaskingcudaFlowCapturer.html">GPU Tasking (cudaFlowCapturer)</a></li><li>added <a href="https://taskflow.github.io/taskflow/RequestCancellation.html">Request Cancellation</a></li><li>added <a href="https://taskflow.github.io/taskflow/Profiler.html">Profile Taskflow Programs</a></li><li>added <a href="https://taskflow.github.io/taskflow/GPUAlgorithms.html">GPU Algorithms</a><ul><li><a href="https://taskflow.github.io/taskflow/SingleTaskCUDA.html">Single Task (cudaFlow)</a> to run a kernel function in just a single thread</li><li><a href="https://taskflow.github.io/taskflow/ForEachCUDA.html">Parallel Iterations (cudaFlow)</a> to perform parallel iterations over a range of items</li><li><a href="https://taskflow.github.io/taskflow/ParallelTransformsCUDA.html">Parallel Transforms (cudaFlow)</a> to perform parallel transforms over a range of items</li><li><a href="https://taskflow.github.io/taskflow/CUDAReduce.html">Parallel Reduction (cudaFlow)</a> to perform parallel reduction over a range of items</li><li><a href="https://taskflow.github.io/taskflow/LinearAlgebracublasFlowCapturer.html">Linear Algebra (cublasFlowCapturer)</a> to build GPU-accelerated linear algebra applications</li></ul></li><li>added <a href="https://taskflow.github.io/taskflow/Governance.html">Governance</a><ul><li><a href="https://taskflow.github.io/taskflow/rules.html">Rules</a></li><li><a href="https://taskflow.github.io/taskflow/team.html">Team</a></li><li><a href="https://taskflow.github.io/taskflow/codeofconduct.html">Code of Conduct</a></li></ul></li><li>added <a href="https://taskflow.github.io/taskflow/Contributing.html">Contributing</a><ul><li><a href="https://taskflow.github.io/taskflow/guidelines.html">Guidelines</a></li><li><a href="https://taskflow.github.io/taskflow/contributors.html">Contributors</a></li></ul></li><li>revised <a href="https://taskflow.github.io/taskflow/ConditionalTasking.html">Conditional Tasking</a></li><li>revised documentation pages for files</li></ul></section><section id="release-3-0-0_miscellaneous_items"><h2><a href="#release-3-0-0_miscellaneous_items">Miscellaneous Items</a></h2><p>We have presented Taskflow in the following C++ venues with recorded videos:</p><ul><li><a href="https://www.youtube.com/watch?v=MX15huP5DsM">2020 CppCon Taskflow Talk</a></li><li><a href="https://www.youtube.com/watch?v=u8Mc_WgGwVY">2020 MUC++ Taskflow Talk</a></li></ul><p>We have published Taskflow in the following conferences and journals:</p><ul><li>Tsung-Wei Huang, "<a href="https://taskflow.github.io/taskflow/iccad20.pdf">A General-purpose Parallel and Heterogeneous Task Programming System for VLSI CAD</a>," <em>IEEE/ACM International Conference on Computer-aided Design (ICCAD)</em>, CA, 2020</li><li>Chun-Xun Lin, Tsung-Wei Huang, and Martin Wong, "<a href="https://taskflow.github.io/taskflow/icpads20.pdf">An Efficient Work-Stealing Scheduler for Task Dependency Graph</a>," <em>IEEE International Conference on Parallel and Distributed Systems (ICPADS)</em>, Hong Kong, 2020</li><li>Tsung-Wei Huang, Dian-Lun Lin, Yibo Lin, and Chun-Xun Lin, "Cpp-Taskflow: A General-purpose Parallel Task Programming System at Scale," <em>IEEE Transactions on Computer-aided Design of Integrated Circuits and Systems (TCAD)</em>, to appear, 2020</li></ul></section>
      </div>
    </div>
  </div>
</article></div></div>]]>
            </description>
            <link>https://taskflow.github.io/taskflow/release-3-0-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25610811</guid>
            <pubDate>Sat, 02 Jan 2021 06:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Front Page Explorer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25610696">thread link</a>) | @flurly
<br/>
January 1, 2021 | https://flurly.com/p/explorehackernews | <a href="https://web.archive.org/web/*/https://flurly.com/p/explorehackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Update Official Website - <a href="https://explorehackernews.xyz/">https://explorehackernews.xyz/</a></p>
<h2>Features</h2>
<ul>
<li>A Multi-year database of Daily Ranked Hacker News Front Page posts.</li>
<li>Tens of Thousands of records from multiple years, with more being added.</li>
<li>Multiple data points, including Date, Post Rank, Post Title, Keywords, Posted on Week Day, Posting at Hour, Post Domain, Post URL, Posted by User, No. of Comments, Score, etc.</li>
<li>Filterable and Searchable Color Coded Database
Included only the curated and Top Ranked posts from the front page for each day of the year(s)(30 per day).</li>
</ul>
<h2>Sample Database</h2>
<p>You can access a sample database here - <a href="https://airtable.com/shrLkLzcdbKFjlvpQ/tblXMVT0J5gpujOK3">https://airtable.com/shrLkLzcdbKFjlvpQ/tblXMVT0J5gpujOK3</a></p>
<h2>Some Example Use Cases</h2>
<ul>
<li>You are about to launch something(products, startups, * books, blogs, podcasts, etc.) and want to get on the front page of Hacker News, this will be a good database for you to refer to understand what kind of posts get ranked on the front page.</li>
<li>You can use this database to Publish your own Analysis, in the form of a paper, blog article, or even a Hacker News </li>
<li>How To Success Guide.</li>
<li>You could use this data to create an App that discovers interesting posts on various topics.</li>
<li>Discover interesting top-rated posts that you have missed in the past in your area, For example, what kind of Podcast submissions get ranked on the Front Page.</li>
<li>Do some Trend Analysis on the data.</li>
</ul>
<h2>FAQs</h2>
<p>What format does data come in?</p>
<p>It's an Airtable Database, that you receive the link to. You can then use it any number of ways </p>
<p>Bookmark the link and use it directly in the browser
Save it to your Airtable account
Export data to CSV format to use it further in Excel, Google sheets, or any number of databases for further processing
Do I need to purchase Airtable to use this?</p>
<p>No.</p>
<p>Does it contain all Hacker News Posts?</p>
<p>No. This is a curated and polished dataset of only the Top Ranked Posts that appeared on hacker News Front Page Every Day.</p>
<p>What's your Refund Policy?</p>
<p>100% Money-Back Guarantee (30 Days).</p>
<p>Get in touch
If you have further questions. you can contact me via </p>
<ul>
<li>
<p>Twitter - <a href="https://twitter.com/harishkgarg">https://twitter.com/harishkgarg</a> or </p>
</li>
<li>
<p>email - <a href="mailto:harish@harishgarg.com">harish@harishgarg.com</a></p>
</li>
</ul>
<p>Not Associated with Hacker News in any way</p>
</div></div></div>]]>
            </description>
            <link>https://flurly.com/p/explorehackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25610696</guid>
            <pubDate>Sat, 02 Jan 2021 05:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Not to Teach Recursion]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25610690">thread link</a>) | @alokrai
<br/>
January 1, 2021 | https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/ | <a href="https://web.archive.org/web/*/https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><table><tbody><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Some_.Canonical_.Examples%29" data-pltdoc="x">1<span>&nbsp;</span>Some Canonical Examples</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Factorial%29" data-pltdoc="x">1.1<span>&nbsp;</span>Factorial</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Fibonacci%29" data-pltdoc="x">1.2<span>&nbsp;</span>Fibonacci</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Euclid_s_.Algorithm%29" data-pltdoc="x">1.3<span>&nbsp;</span>Euclid’s Algorithm</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Towers_of_.Hanoi%29" data-pltdoc="x">1.4<span>&nbsp;</span>Towers of Hanoi</a></p></td></tr><tr><td></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Recursion_versus_.Cyclicity%29" data-pltdoc="x">2<span>&nbsp;</span>Recursion versus Cyclicity</a></p></td></tr><tr><td></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Is_.Recursion_in_the_.Problem_%29" data-pltdoc="x">3<span>&nbsp;</span>Is Recursion in the Problem?</a></p></td></tr><tr><td></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.How_to_.Teach_.Recursion%29" data-pltdoc="x">4<span>&nbsp;</span>How to Teach Recursion</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Function_.Follows_.Form%29" data-pltdoc="x">4.1<span>&nbsp;</span>Function Follows Form</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.One_.Datatype__.Many_.Problems%29" data-pltdoc="x">4.2<span>&nbsp;</span>One Datatype, Many Problems</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.When_.Recursion_.Becomes_.Difficult%29" data-pltdoc="x">4.3<span>&nbsp;</span>When Recursion Becomes Difficult</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Back_to_the_.Canonical_.Problems%29" data-pltdoc="x">4.4<span>&nbsp;</span>Back to the Canonical Problems</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Going_.Beyond_.Loops%29" data-pltdoc="x">4.5<span>&nbsp;</span>Going Beyond Loops</a></p></td></tr><tr><td><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.That_.Was_.Pretty_.Dense%29" data-pltdoc="x">4.6<span>&nbsp;</span>That Was Pretty Dense</a></p></td></tr></tbody></table><p>We all know how to teach recursion. We’ve done it for decades. We pick some
honored, time-tested examples—<wbr>Fibonacci numbers and factorial being leading
candidates—<wbr>and use them to teach the general idea. They’re so canonical they
come directly from the gods: you can find these in books by people like
Niklaus Wirth.</p><p>But I’m here to tell you they got it wrong, and everyone’s been getting it
wrong ever since. Students come away underwhelmed and baffled, and go on to
become the next generation of teachers who repeat this process. However, we
need not repeat this cycle; we have much better methods.</p><h3>1<tt>&nbsp;</tt><a name="(part._.Some_.Canonical_.Examples)"></a>Some Canonical Examples</h3><p>Let’s start by looking at what’s wrong with our canonical examples.</p><h4>1.1<tt>&nbsp;</tt><a name="(part._.Factorial)"></a>Factorial</h4><p>First off, almost nobody has ever needed to compute a factorial. I’ve been
programming for about 35 years and the only times I’ve needed to compute a
factorial was when doing recreational mathematics or using programming to
explore some especially thorny combinatorics problem. Otherwise, I’ve never had
any need for factorials.</p><p>Second, the answer isn’t <span>meaningful</span>. Quick, what’s the factorial of 13?
Most people have no idea and (related to the above) don’t care. There’s nothing
recognizable about the answer. The only reason most programmers recognize the
number 3628800 is because we’ve tested factorial on a “big enough number” to
confirm that it worked, not because we actually cared about it. If you adopt a
curriculum that asks students to <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/wk-examplar/">develop examples
before they write code</a>, students would be hard-pressed to write the answer
independently; many would resort to implementing it first and plugging in the
answer.</p><p>Third, factorial has poor numeric properties in most languages. Unless you have
built-in, automatic support for big numbers, you will soon either get answers
that print in odd-looking scientific notation, or worse, overflow (on many
languages, with default integers, factorial of 17 is -288522240).</p><p>Finally, many students have written factorial-like programs before, perhaps
even factorial itself, using loops. A natural question they (should!) ask an
instructor is, “Why should I do this again?” The answer, inevitably, is,
“Because I’m asking you to.” There’s no better way to turn off a student.</p><p>So let’s summarize the “recursion experience”: a useless problem, with
unrecognizable answers, with wonky-looking behavior, using an unnecessary new
technique that you’re forced to use “because”.</p><h4>1.2<tt>&nbsp;</tt><a name="(part._.Fibonacci)"></a>Fibonacci</h4><p>Let’s turn our gaze to Fibonacci.</p><p>First off, almost nobody has ever needed to compute a Fibonacci number,
either. I’ve been programming for about 35 years and the only times I’ve needed
it was when doing recrea—<wbr>you see where this is going.<span><span><span>I do find them
useful to convert beween miles and kilometers, though.</span></span></span></p><p>Second, the answer isn’t meaningful, and students would again be hard-pressed
to write the answer independently (what, keep track of all those
calls?!?). Third, it has poor numeric properties: around 44, Fibonacci is
correct, then becomes negative (which is obviously incorrect), then immediately
again is a very reasonable-looking positive number that just happens to be
completely wrong. The main reason we haven’t cared for decades is because we
really just don’t have much use for Fibonacci numbers.</p><p>Finally, it has atrocious time-complexity.</p><p>So let’s summarize the “recursion experience”: a useless problem, with
unrecognizable answers, with wonky-looking behavior, that runs really sloooowly
(and worse, the slowness first creeps up on you stealthily and then suddenly
administers a hammer-blow to the back of your head). In fact, its main value is
as a function that you should <span>not</span> write (straightforwardly) recursively.</p><p>This is how we teach recursion.</p><h4>1.3<tt>&nbsp;</tt><a name="(part._.Euclid_s_.Algorithm)"></a>Euclid’s Algorithm</h4><p>Oh, I’m not done.</p><p>Another famous mathematician, another famous function.</p><p>Okay, I’ll grant, many students have at least heard of the greatest common
divisor. They may vaguely recall using it in school for dealing with
fractions. So it has familiarity going for it.</p><p>Unfortunately, it was useful in a context that <span>no longer makes
sense</span>. Once you have a programming language, you have a calculator. Unless
you’re implementing a calculator (and perhaps even then), you have no real need
to implement Euclid’s algorithm.</p><p>And even if you do, admit it: you don’t remember why Euclid’s algorithm
works. I certainly have to re-derive why it produces the right answer every
time I’ve implemented it (purely for illustrative purposes, every few
years). Otherwise, it’s just a mystical pattern.</p><p>So what’s the lesson we get from Euclid’s algorithm? That recursion is for
encoding mystical patterns for no-longer-useful functions? In fact, is
recursion useful for anything <span>other</span> than weird math functions?</p><h4>1.4<tt>&nbsp;</tt><a name="(part._.Towers_of_.Hanoi)"></a>Towers of Hanoi</h4><p>Oh yes it is! Maybe that’s why we have this old standby.</p><p>First, we’ll start with some invented Eastern mysticism. Orientalism is always
a good pedagogic device, right?</p><p>Next, it’s a problem fraught with questions of representation: how exactly do
you represent the content of the towers? That is actually a somewhat
interesting question for a beginning student, but (a) it’s not obvious until
you’ve had some programming practice, and (b) it has absolutely nothing to do
with recursion. So you have a hard, unrelated sub-problem in the middle of your
example that “demonstrates” recursion. Doesn’t that utterly violate the
pedagogic principle of changing just one thing at a time so students can focus
on what’s salient? (And don’t forget, this is another problem with exponential
time behavior!)</p><p>Furthermore, if you don’t tell students the (recursive) solution and leave them
to figure it out for themselves, you haven’t given them a programming problem:
you’ve given them a puzzle. Those are different things. In particular, the
Towers of Hanoi is a particularly <span>difficult</span> kind of recursion—<wbr>oh, you
didn’t know there are different kinds of recursion? Read on.</p><p>Finally, again, does anyone care? Do students believe they would be called on
to help monks move disks around? What other problem is similar to this one? And
if there are any, do we teach them, or do we present these magnificently
isolated monks…in magnificent isolation?</p><p>What’s worse is that so many of these are fundamentally <span>static</span> problems:
there are only so many interesting inputs, and each one has a completely
deterministic solution, so once one builds up a table of outputs for standard
inputs, the problem is essentially solved. For such problems, it would be smart
(especially when the run-time complexity is exponential in the input) to just
stash the answers and never run the code again.<span><span><span>Yes, I know,
memoization.</span></span></span></p><h3>2<tt>&nbsp;</tt><a name="(part._.Recursion_versus_.Cyclicity)"></a>Recursion versus Cyclicity</h3><p>Another standard, time-honored pedagogic device is the dumb joke: “to
understand recursion you must understand recursion”, and so on.</p><p>These confuse recursion with cyclicity.</p><p>If you don’t understand the difference, don’t use the dumb jokes.</p><p>If you do understand the difference, don’t use the dumb jokes then
either. They’re still <span>dumb</span> jokes.</p><h3>3<tt>&nbsp;</tt><a name="(part._.Is_.Recursion_in_the_.Problem_)"></a>Is Recursion in the Problem?</h3><p>An attempt at a better answer might be that a <span>problem</span> is “inherently”
recursive. However, that’s just a limitation of viewpoint. There’s nothing more
inherently recursive than iterative about factorial. All the problems above can
be expressed even more declaratively, as in a mathematical specification, that
eliminates any implementation directive (e.g.: the greatest common divisor is the
<span>greatest</span>, <span>common</span>, <span>divisor</span>: the definition of the problem
says nothing about how to find it, and searching through all numbers to find
divisors that are common and taking the largest one is no less valid a
solution).</p><p>No, the essence lies elsewhere. But we’re getting closer.</p><h3>4<tt>&nbsp;</tt><a name="(part._.How_to_.Teach_.Recursion)"></a>How to Teach Recursion</h3><p>Wait up, I didn’t promise this. Check the title again.</p><p>But I know, I can’t just stop here. So I’ll give you a brief peek of how to
proceed.</p><p>In <span><a href="https://htdp.org/">How to Design Programs</a></span> (<span>HTDP</span>), we have a rather different view of
recursion. The key idea is this.</p><h4>4.1<tt>&nbsp;</tt><a name="(part._.Function_.Follows_.Form)"></a>Function Follows Form</h4><p>Where does recursion come from? <span>HTDP</span> argues that it arises from
<span>self-references in data</span>. That is, <span>recursive data suggest recursive
solutions</span>. This is the key insight you need for understanding recursion. Not
only does it make sense once you think about it, it also demonstrates why most
other approaches to teaching recursion are essentially incorrect.</p><p><span>HTDP</span> teaches a design “recipe”. In it, you describe your program’s (or
function’s) data structures, and identify self-references in these
data. Self-referential data are pretty straightforward: even kids can understand
them. For instance, even a child informed about biology can answer basic
questions like these:
</p><div><table><tbody><tr><td><p><span>- Does a child have (biological) parents?</span></p></td></tr><tr><td><p><span>- Yes.</span></p></td></tr><tr><td><p><span>- How many?</span></p></td></tr><tr><td><p><span>- Two, a (biological) male and (biological) female.</span></p></td></tr><tr><td><p><span>- Does the female have parents?</span></p></td></tr><tr><td><p><span>- Yes.</span></p></td></tr><tr><td><p><span>- How many?</span></p></td></tr><tr><td><p><span>- Two, a (biological) mother and a (biological) father.</span></p></td></tr><tr><td><p><span>- Does the male…</span></p></td></tr></tbody></table></div><p>They can see where this goes. They grasp the idea of a (biological) family tree
pretty intuitively. They can similarly see other kinds of self-referential data
even at a young age, well before they program.</p><p>Next, <span>HTDP</span> explains how the structure of the data suggest a structure to the
solution. This solution structure is generic, and called the “template”. You
arrive at this entirely mechanically from the data structure, even before
you’ve contemplated the exact problem you’re trying to solve.</p><p>(The template is not a rule, it’s a suggestion. It helps you overcome the
“blank page” problem by offering the outline of a suggestion. Sometimes, the
template leads to a correct but insufficiently-efficient solution. Such a
solution is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/">https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/</a></em></p>]]>
            </description>
            <link>https://parentheticallyspeaking.org/articles/how-not-to-teach-recursion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25610690</guid>
            <pubDate>Sat, 02 Jan 2021 05:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Ray Kurzweil’s 1998 predictions about 2019 are faring]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25610275">thread link</a>) | @apsec112
<br/>
January 1, 2021 | https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/ | <a href="https://web.archive.org/web/*/https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1933">
		<!-- .entry-header -->

	
	<div>
		
<p>This is the fourth…and LAST…entry in my series of blog posts analyzing the accuracy of Ray Kurzweil’s predictions about what things would be like in 2019. These predictions come from his 1998 book&nbsp;<em>The Age of Spiritual Machines</em>.&nbsp;You can view the previous installments of this series here:</p>



<p><a href="https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-1/">Part 1</a></p>



<p><a href="https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-2/">Part 2</a></p>



<p><a href="https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-3/">Part 3</a></p>



<p><strong><em>“An undercurrent of concern is developing with regard to the influence of machine intelligence. There continue to be differences between human and machine intelligence, but the advantages of human intelligence are becoming more difficult to identify and articulate. Computer intelligence is thoroughly interwoven into the mechanisms of civilization and is designed to be outwardly subservient to apparent human control. On the one hand, human transactions and decisions require by law a human agent of responsibility, even if fully initiated by machine intelligence. On the other hand, few decisions are made without significant involvement and consultation with machine-based intelligence.”</em></strong></p>



<p><strong>MOSTLY RIGHT</strong></p>



<p>Technological advances have moved concerns over the influence of machine intelligence to the fore in developed countries. In many domains of skill previously considered hallmarks of intelligent thinking, such as driving vehicles, recognizing images and faces, analyzing data, writing short documents, and even diagnosing diseases, machines had achieved human levels of performance by the end of 2019. And in a few niche tasks, such as playing Go, chess, or poker, machines were superhuman. Eroded human dominance in these and other fields did indeed force philosophers and scientists to grapple with the meaning of “intelligence” and “creativity,” and made it harder yet more important to define how human thinking was still special and useful. </p>



<p>While the prospect of artificial general intelligence was still viewed with skepticism, there was no real doubt among experts and laypeople in 2019 that task-specific AIs and robots would continue improving, and without any clear upper limit to their performance. This made technological unemployment and the solutions for it frequent topics of public discussion across the developed world. In 2019, one of the candidates for the upcoming U.S. Presidential election, Andrew Yang, even made these issues central to his political platform. </p>



<p>If “algorithms” is another name for “computer intelligence” in the prediction’s text, then yes, it is woven into the mechanisms of civilization and is ostensibly under human control, but in fact drives human thinking and behavior. To the latter point, great alarm has been raised over how algorithms used by social media companies and advertisers affect sociopolitical beliefs (particularly, conspiracy thinking and closedmindedness), spending decisions, and mental health. </p>



<p>Human transactions and decisions still require a “human agent of responsibility”: Autonomous cars aren’t allowed to drive unless a human is in the driver’s seat, human beings ultimately own and trade (or authorize the trading of) all assets, and no military lets its autonomous fighting machines kill people without orders from a human. The only part of the prediction that seems wrong is the last sentence. Probably most decisions that humans make are done without consulting a “machine-based intelligence.” Consider that most daily purchases (e.g. – where to go for lunch, where to get gas, whether and how to pay a utility bill) involve little thought or analysis. A frighteningly large share of investment choices are also made instinctively, with benefit of little or no research. However, it should be noted that one area of human decision-making, dating, has become much more data-driven, and it was common in 2019 for people to use sorting algorithms, personality test results, and other filters to choose potential mates. </p>



<p><strong><em>“Public and private spaces are routinely monitored by machine intelligence to prevent interpersonal violence.”</em></strong></p>



<p><strong>MOSTLY RIGHT</strong></p>



<p>Gunfire detection systems, which are comprised of networks of microphones emplaced across an area and which use machine intelligence to recognize the sounds of gunshots and to triangulate their origins, were emplaced in over 100 cities at the end of 2019. The dominant company in this niche industry, “ShotSpotter,” used human analysts to review its systems’ results before forwarding alerts to local police departments, so the systems were not truly automated, but nonetheless they made heavy use of machine intelligence. </p>



<p>Automated license plate reader cameras, which are commonly mounted next to roads or on police cars, also use machine intelligence and are widespread. The technology has definitely reduced violent crime, as it has allowed police to track down stolen vehicles and cars belonging to violent criminals faster than would have otherwise been possible. </p>



<p>In some countries, surveillance cameras with facial recognition technology monitor many public spaces. The cameras compare the people they see to mugshots of criminals, and alert the local police whenever a wanted person is seen. China is probably the world leader in facial recognition surveillance, and in a famous 2018 case, it used the technology to find one criminal among 60,000 people who attended a concert in Nanchang. </p>



<p>At the end of 2019, several organizations were researching ways to use machine learning for real-time recognition of violent behavior in surveillance camera feeds, but the systems were not accurate enough for commercial use. </p>



<p><strong><em>“People attempt to protect their privacy with near-unbreakable encryption technologies, but privacy continues to be a major political and social issue with each individual’s practically every move stored in a database somewhere.” </em></strong></p>



<p><strong>RIGHT</strong></p>



<p>In 2013, National Security Agency (NSA) analyst Edward Snowden leaked a massive number of secret documents, revealing the true extent of his employer’s global electronic surveillance. The world was shocked to learn that the NSA was routinely tracking the locations and cell phone call traffic of millions of people, and gathering enormous volumes of data from personal emails, internet browsing histories, and other electronic communications by forcing private telecom and internet companies (e.g. – Verizon, Google, Apple) to let it secretly search through their databases. Together with British intelligence, the NSA has the tools to spy on the electronic devices and internet usage of almost anyone on Earth. </p>



<div><figure><img data-attachment-id="2011" data-permalink="https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/edward-snowden/" data-orig-file="https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?fit=992%2C744&amp;ssl=1" data-orig-size="992,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="edward-snowden" data-image-description="" data-medium-file="https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?fit=525%2C394&amp;ssl=1" loading="lazy" width="525" height="394" src="https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?resize=525%2C394&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?w=992&amp;ssl=1 992w, https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/www.militantfuturist.com/wp-content/uploads/2020/12/edward-snowden.jpg?resize=768%2C576&amp;ssl=1 768w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1"><figcaption>Edward Snowden</figcaption></figure></div>



<p>Snowden also revealed that the NSA unsurprisingly had sophisticated means for cracking encrypted communications, which it routinely deployed against people it was spying on, but that even its capabilities had limits. Because some commercially available encryption tools were too time-consuming or too technically challenging to crack, the NSA secretly pressured software companies and computing hardware manufacturers to install “backdoors” in their products, which would allow the Agency to bypass any encryption their owners implemented. </p>



<p>During the 2010s, big tech titans like Facebook, Google, Amazon, and Apple also came under major scrutiny for quietly gathering vast amounts of personal data from their users, and reselling it to third parties to make hundreds of billions of dollars. The decade also saw many epic thefts of sensitive personal data from corporate and government databases, affecting hundreds of millions of people worldwide. </p>



<p>With these events in mind, it’s quite true that concerns over digital privacy and confidentiality of personal data have become “major political and social issues,” and that there’s growing displeasure at the fact that “each individual’s practically every move stored in a database somewhere.” The response has been strongest in the European Union, which, in 2018, enacted the most stringent and impactful law to protect the digital rights of individuals–the “General Data Protection Regulation” (GDPR). </p>



<p>Widespread awareness of secret government surveillance programs and of the risk of personal electronic messages being made public thanks to hacks have also bolstered interest in commercial encryption. “Whatsapp” is a common text messaging app with built-in end-to-end encryption. It was invented in 2016 and had 1.5 billion users by 2019. “Tor” is a web browser with built-in encryption that became relatively common during the 2010s after it was learned even the NSA couldn’t spy on people who used it. Additionally, virtual private networks (VPNs), which provide an intermediate level of data privacy protection for little expense and hassle, are in common use. </p>



<p><strong><em>“The existence of the human underclass continues as an issue. While there is sufficient prosperity to provide basic necessities (secure housing and food, among others) without significant strain to the economy, old controversies persist regarding issues of responsibility and opportunity.” </em></strong></p>



<p><strong>RIGHT</strong></p>



<p>It’s unclear whether this prediction pertained to the U.S., to rich countries in aggregate, or to the world as a whole, and “underclass” is not defined, so we can’t say whether it refers only to desperately poor people who are literally starving, or to people who are better off than that but still under major daily stress due to lack of money. Whatever the case, by any reasonable definition, there is an “underclass” of people in almost every country. </p>



<p>In the U.S. and other rich countries, welfare states provide even the poorest people with access to housing, food, and other needs, though there are still those who go without because severe mental illness and/or drug addiction keep them stuck in homeless lifestyles and render them too behaviorally disorganized to apply for government help or to be admitted into free group housing. Some people also live in destitution in rich countries because they are illegal immigrants or fugitives with arrest warrants, and contacting the authorities for welfare assistance would lead to their detection and …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/">https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/</a></em></p>]]>
            </description>
            <link>https://www.militantfuturist.com/how-ray-kurzweils-2019-predictions-are-faring-pt-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25610275</guid>
            <pubDate>Sat, 02 Jan 2021 04:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive Version of “Programmer's Competency Matrix”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25609608">thread link</a>) | @cuamckuu
<br/>
January 1, 2021 | http://cuamckuu.github.io/index.html | <a href="https://web.archive.org/web/*/http://cuamckuu.github.io/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://cuamckuu.github.io/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25609608</guid>
            <pubDate>Sat, 02 Jan 2021 02:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started in Robotics]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25608932">thread link</a>) | @networdtwo
<br/>
January 1, 2021 | https://allshire.org/getting-started-robotics/ | <a href="https://web.archive.org/web/*/https://allshire.org/getting-started-robotics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://allshire.org/img/post/getting-started/spot_mini.jpg">
<figcaption>Boston Dynamics' Spot Mini Robot. <em><a href="https://commons.wikimedia.org/wiki/File:SpotMini,_Boston_Dynamics,_Robot.jpg">CC</a></em></figcaption>
</figure>
<p>People sometimes ask me for robotics resources. There aren’t many high quality internet-first lists available on this topic, so I made one I can link to. I’ll continually update this list so feel free to give <strong><a href="mailto:arthur@allshire.org">suggestions if things are missing or you have better links</a></strong>.</p>
<p>There’s some more interesting comments on this topic in the <a href="https://news.ycombinator.com/item?id=25608932">Hacker News discussion</a>.</p>
<h3 id="general-advice">General Advice</h3>
<p>Robotics can be overwhelming from the sheer number of fields involved (everything from mathematics to physics to computer science to mechanical engineering enters in). Remember: <em>you won’t start as an expert in anything; you can’t end up as an expert in everything</em>. Also learning will not be a linear path; outside of courses, acquire knowledge as you need it in projects.</p>
<p>Try as much as possible to avoid this antipattern (I still struggle)…
</p><blockquote><p lang="en" dir="ltr">An illustrated guide to learning absolutely nothing <a href="https://t.co/bKIMX2r6iU">pic.twitter.com/bKIMX2r6iU</a></p>— Eugene Vinitsky (@EugeneVinitsky) <a href="https://twitter.com/EugeneVinitsky/status/1343701831210307586?ref_src=twsrc%5Etfw">December 28, 2020</a></blockquote>


<h4 id="communities">Communities</h4>
<p>Instead of attempting to pre-load your head with maximum theory, try to get as much <strong>practical experience</strong> as possible (see below), whether that be joining a club, lab, or if you’re lucky in an internship or job.</p>
<p>It is incredibly hard to do something on your own without some kind of <a href="https://dcgross.com/the-environment-diet/">environmental forcing function</a>.  If at all possible, embed yourself in a community of people working on problems of interest to you.</p>
<ul>
<li><a href="https://www.firstinspires.org/robotics/frc">FIRST robotics competition</a> - Simply put, FRC was the awesomest thing ever for me. If you can find a team, beg them to let you participate…</li>
<li>If you are a student at a university - try joining a lab!</li>
</ul>
<p>Unfortunately outside of these robotics is currently not an easy field to break into. The sheer number of ‘moving parts’ to a (useful) robotic system - from hardware to drivers to algorithms to user interfaces - means it’s tough to hack together a demo in a few weeks, get users, and bootstrap / apply to some accelerator like in many software projects. Making the jump from “hacker” to “career”, even with all the knowledge in the world is hard. If you know solutions to this, let me know.</p>
<h3 id="prerequisites">Prerequisites</h3>
<p><strong>Computer programming</strong> - this is essential if you want to do basically anything in robotics. Python and <a href="https://www.stroustrup.com/Tour.html">C++</a> are the most important languages to know - learn both.
Familiarity with basic data-structures and algorithms concepts is helpful for problem solving and in some fields like motion planning but initially less vital than you may think - it’s not necessary to be a master leetcoder.</p>
<p><strong>Maths</strong></p>
<ul>
<li>Linear algebra - vital in most topics beyond basic basic control. If you want to become an expert, <a href="https://linear.axler.net/">Axler’s book</a> is good (though I didn’t make it through the whole thing 😳).</li>
<li>Calculus - fundamental differential calculus and partial derivatives is required to understand optimisation algorithms which are everywhere in robo.</li>
<li>The book <a href="https://pimbook.org/">A Programmer’s Introduction to Mathematics</a> is actually a solid foundation if you want a quick overview of both of the above topics.</li>
</ul>
<h3 id="important-concepts">Important Concepts</h3>
<p><strong>Controllers</strong></p>
<ul>
<li>Wiki’s <a href="https://en.wikipedia.org/wiki/PID_controller">PID controller</a> isn’t bad if you want to learn the basics (<a href="https://www.argmin.net/2018/04/19/pid/">95%</a> of controllers used in industry are PID). Ben Recht’s <a href="https://www.argmin.net/2018/04/19/pid/">blog post</a> is also decent.</li>
<li><a href="https://web.stanford.edu/class/archive/ee/ee392m/ee392m.1056/">These course slides</a> are good for basics and more advanced concepts like <strong>MPC</strong> .</li>
<li><a href="https://janismac.github.io/ControlChallenges/">Control challenges</a> is a set of (very fun) challenges that will allow you to test your ability to write basic controllers.</li>
<li><a href="https://www.youtube.com/watch?v=8319J1BEHwM">This talk</a> from FIRST Robotics team 254 is great for going over the basics of robot control and showing how we can improve on basic PID using simple interpolation.</li>
</ul>
<p><strong>Mathematics and Mechanics of Robotics &amp; Manipulation</strong> - This set of <a href="http://www.nathanratliff.com/pedagogy">notes by Nathan Ratliff</a> provides a great overview of many topics.  These <a href="https://ethz.ch/content/dam/ethz/special-interest/mavt/robotics-n-intelligent-systems/rsl-dam/documents/RobotDynamics2017/RD_HS2017script.pdf">notes on robot dynamics</a> from ETH are also great.</p>
<p><strong>Filtering</strong> - <a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python">Kalman and Bayesian Filters in Python</a> is a great read with interactive notebook examples throughout. Good for building intuition on both Bayesian statistics as well as how filters for linear and nonlinear dynamical systems work. The <a href="https://en.wikipedia.org/wiki/Kalman_filter#Technical_description_and_context">wiki article on the Kalman Filter</a>  and <a href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">this blog post</a> is also well written if you want a shorter overview.</p>
<p><strong>Machine Learning &amp; Neural Networks</strong> - Focus less on the basics of machine learning than the application of neural networks as function approximators, which is their primary utility as perception and decision making modules in robotics. <a href="http://neuralnetworksanddeeplearning.com/">Michael Nielsen’s book</a> is my favourite resource in this regard. The <a href="https://www.deeplearningbook.org/">canonical deep learning book</a> is good reference but you don’t need to read the whole thing - pick out specific topics as required.</p>
<p><strong>Path and motion planning</strong> - Wiki has a <a href="https://en.wikipedia.org/wiki/Motion_planning">decent overview</a> and details some <a href="https://en.wikipedia.org/wiki/Rapidly-exploring_random_tree">basic</a> <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">algorithms</a>. I haven’t read it but this book is apparently a <a href="http://lavalle.pl/planning/">good comprehensive guide</a>, and a course based on it is available <a href="https://web.eecs.umich.edu/~dmitryb/courses/winter2019motionplanning/index.html">here</a>.</p>
<p><strong>Reinforcement Learning</strong> &amp; more on controllers - Ben Recht’s “<a href="http://www.argmin.net/2018/06/25/outsider-rl/">outsider’s tour of RL</a>” provides a nice concise overview of many relevant concepts and ties them to classical control. <a href="https://openai.com/blog/spinning-up-in-deep-rl/">Spinning up in Deep Reinforcement Learning</a> is another great reference on the topic and exhibits many of the most important algorithms for research in the field.</p>
<h3 id="other-topics--resources">Other Topics &amp; Resources</h3>
<h4 id="books">Books</h4>
<ul>
<li>For beginners looking for a single book, <a href="https://link.springer.com/book/10.1007/978-3-319-62533-1">Elements of Robotics</a> looks like an a great resource, and I’m only sorry it didn’t exist when I was starting. Provides self-contained introductions to many topics listed, pitched at a level high-schoolers / beginning university students can understand.</li>
<li><a href="https://www.springer.com/gp/book/9781846286414">Robotics: Modelling, Planning and Control</a> is <a href="https://news.ycombinator.com/item?id=25609653">apparently</a> an all time classic covering many topics listed above..</li>
<li>Convex Optimisation is used in everything from simulators to controllers and beyond. I intend to read the <a href="https://web.stanford.edu/~boyd/cvxbook/">canonical book</a> (free) at some point.</li>
</ul>
<h4 id="courses">Courses</h4>
<ul>
<li>The Berkley <strong><a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/">Advanced Robotics</a></strong> course provides relatively self contained expositions of many topics in lecture format (don’t be scared off by the ‘advanced' moniker, it’s not that incomprehensible 😅.)</li>
<li>Russ Tedrake’s courses on <a href="http://underactuated.mit.edu/">Underactuated Robotics</a> and <a href="http://manipulation.csail.mit.edu/">Manipulation</a> seem really high quality (I haven’t gotten around to doing them myself yet).</li>
</ul>
<h3 id="software">Software</h3>
<p>The space of software is so vast I couldn’t fit it all here… <a href="http://jslee02.github.io/awesome-robotics-libraries/">this list</a> provides a much more comprehensive overview in this regard. Some utilities I’ve found useful are:</p>
<ul>
<li><a href="https://www.ros.org/install/">ROS</a> is very widely used many projects, worth picking up the basics.</li>
<li><a href="https://docs.ray.io/en/latest/rllib.html">RLLib</a> has implementations of many reinforcement learning algorithms and support for distributed training.</li>
</ul>
<h4 id="simulators">Simulators</h4>
<ul>
<li><a href="https://github.com/ARISE-Initiative/robosuite">Robosuite</a> is great for robot learning and has many richly-designed built-in environments.</li>
<li><a href="https://developer.nvidia.com/isaac-gym">Isaac Gym</a> is recently released and provides extremely fast samples for reinforcement learning. It does this by running thousands of environments in parallel on the GPU (in almost all other sims physics is run on the CPU meaning you can only run one environment at once). You can train tasks in minutes that previously took hours.</li>
</ul>
<h3 id="interesting-lines-of-work">Interesting Lines of Work</h3>
<ul>
<li><strong>Domain Randomisation</strong>  is highly underrated, and will likely get more important as we get faster simulators which are able to generalize better. <a href="https://openai.com/blog/learning-dexterity/">Learning Dexterity</a> from OpenAI is a very interesting paper, and the <a href="https://www.youtube.com/watch?v=SRupIVknV-A">line</a> of <a href="https://arxiv.org/pdf/1906.01728.pdf">work</a> around improving simulator parameter show two different and interesting takes on this powerful approach.</li>
<li><strong>Hierarchy</strong> in reinforcement learning has shown promising results in getting behaviour that generalises, the <a href="https://arxiv.org/pdf/1909.08399.pdf">DeepGait</a> and <a href="https://arxiv.org/abs/2011.15119">UniCon</a> paper being two interesting examples.</li>
<li><a href="https://arxiv.org/abs/1910.03135">DexPilot</a> is a really cool low-cost system for teleoperation (<a href="https://www.youtube.com/watch?v=qGE-deYfb8I">video</a>). Partially inspired <a href="https://allshire.org/teleop/">my piece on teleoperation</a>.</li>
</ul>
<h3 id="hardware">Hardware</h3>
<p>Probably my weakest area… up for recommendations about specific great resources.
<a href="https://www.onshape.com/en/">OnShape</a> is a great resource for designing things and is great even with minimal CAD experience (even I am able to use it!)</p>
<p><a href="https://open-dynamic-robot-initiative.github.io/">Open Dynamic Robot initiative</a> has many robots that you can build with off-the-shelf components.</p>
<p>Others' recommendations -</p>
<p>In the HN thread, <a href="https://news.ycombinator.com/item?id=25612255">contingencies had some tips</a> on how to get started yourself on the hardware side.</p>
<p>I’m told cadathons such as those <a href="https://blogs.solidworks.com/tech/2020/03/20-years-of-model-mania.html">organised by Solidworks</a> are a good way to get started. They also have a <a href="https://my.solidworks.com/training/path/14/cswa-exam-prep-course">series of lessons</a> on CADding fundamentals.</p>
<p><a href="https://grabcad.com/">GrabCAD</a> has big libries of pre-existing models you can use.</p>
<h3 id="business--higher-level-thinking">Business &amp; Higher-Level Thinking</h3>
<p>Very interesting side of things, however there is somewhat of a paucity of great resources (I’m pretty sure many in the space refrain from publishing their theses.) Please send if you have others I have missed!</p>
<ul>
<li>Michael Dempsey has some <a href="http://www.michaeldempsey.me/archive.html">great writing</a> on the business of autonomy.</li>
<li>Trucks VC has an interesting newsletter about <a href="https://www.trucks.vc/">autonomy</a>.</li>
<li>Jessy Lin wrote <a href="http://jessylin.com/blog/">some essays</a> on topic surrounding the economics and future of autonomy and HRI.</li>
<li><a href="https://rodneybrooks.com/blog/">Rodney Brooks</a> makes predictions in the robotics space on a yearly basis and has some good rigorous thinking on there.</li>
<li><a href="https://www.eetimes.com/">EE Times</a> has news and frequent opinion pieces in this space.</li>
<li>Though inexperienced, I sometimes try my best to <a href="https://allshire.org/">write on this topic</a> :)</li>
</ul>

</div></div>]]>
            </description>
            <link>https://allshire.org/getting-started-robotics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25608932</guid>
            <pubDate>Sat, 02 Jan 2021 00:33:42 GMT</pubDate>
        </item>
    </channel>
</rss>
