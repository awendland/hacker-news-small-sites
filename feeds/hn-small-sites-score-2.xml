<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 13 Dec 2020 08:34:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 13 Dec 2020 08:34:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Start a Podcast in 2021 – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384162">thread link</a>) | @tomhuntio
<br/>
December 11, 2020 | https://www.bcast.fm/blog/how-to-start-a-podcast | <a href="https://web.archive.org/web/*/https://www.bcast.fm/blog/how-to-start-a-podcast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong><em>This is the first post in the three-part series. Part two focuses on </em></strong><a href="https://www.bcast.fm/blog/how-to-launch-a-podcast" target="_blank"><strong><em>how to launch a podcast</em></strong></a><strong><em>, and part three focuses on how to grow a podcast.</em></strong></p><p>The podcast industry is snowballing.&nbsp;</p><p>But don’t worry, the number of listeners is growing faster than the number of podcasts. </p><p>All the BIG tech businesses are investing heavily in the podcast space, bringing bigger and better audio tools, which in turn bring more people to podcasts.</p><ul role="list"><li>Apple - Apple Podcasts and AirPods</li><li>Google - Google Podcasts and Google Podcast Manager</li><li>Spotify - Spotify for Podcasters</li><li>Amazon - Amazon Music and Alexa</li></ul><p>We’re talking billions of dollars being spent on enabling more and more people to flood into podcasts… you just have to be there to mop them up :)</p><figure id="w-node-f4cfd1480d0a-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93b331b3c358913488_4X1o_362OKLNxFY5BysBQvm9-hmMKWsrZaYwN-X3atvqRXHV361ktXo_hXBJN6mXC1rcbQHcBBZFbUFOMmLssnfNVUcMlMpj6fuFnM6sFzOiVmQ2lzBMzssQmMlu-AgzVQtfxVz2.gif" alt=""></p></figure><p>Research has shown that over <a href="https://www.statista.com/statistics/786826/podcast-listeners-in-the-us/" target="_blank">103 million Americans have at least one podcast</a> they listen to every month in the US – this number will keep growing. Despite this... there are still over 600 blogs for every podcast in the world ;)</p><figure id="w-node-a4cc97581060-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf92a6071203f4bd93fc_s-So6SEwWD4eheC2_twd61hX0idTzHglF81LuQoxdwe3gACuUrSqGmx5PPGKQkwEaZ5d_iWW9BsNFTCyJ8JUodSpf5Qoyk6lnOHAlFA3ODwgO1SO4jvmFBofVKLD4lsVuIu4aigH.png" alt=""></p><figcaption><em>Source: Statista.com</em></figcaption></figure><p><strong>A podcast will grow your brand.</strong></p><p>Whether that be you as a person or you for your business. There are many reasons why you should start a podcast.</p><p>And fortunately, if you want to know the right steps to make to start a successful podcast, you are in the right place.</p><p>In this easy-to-understand step-by-step guide, we will break down everything you need to start your podcast for free from developing a plan to securing the right equipment and software to use.&nbsp;</p><p>Bookmark this page and keep referring back to as you move through the process of starting your first (or next!) podcast, and when you launch make sure you ping us a link by email to <a href="mailto:support@bcast.fm">support@bcast.fm</a> - we will subscribe!</p><figure id="w-node-e9418c7b6c75-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93154cd636df1dd20b_QUaPSMMrdnQRcLu0jfIP-o-iLKto34jtuaLiEPQDSJSu_4NBmW8vDPuKaMumd-4VF51oguynh0RW81UeQZxtwWyfiC0zuL0wQBmwBpBM-GP81DiWV9UUle1Jr44v-JSw_CB6HxYs.gif" alt=""></p></figure><h2><strong>STEP 1: DEVELOP A PLAN</strong></h2><p>Of course... you need a solid plan before starting a podcast. </p><p>Your podcast is a result of your thoughts and actions, and this is why you need a plan. You need to be deliberate about what you create. Your podcast gets its uniqueness from you, as you are the creator and director. </p><p>Your podcast is a result of your<strong> imagination</strong> and your <strong>ability to execute</strong>.</p><p>You must have a reason for starting your podcast, and this where the “WHY” and “WHAT” questions come in. The answer to these questions will help you create a podcast that is both unique to you but will also be able to add massive value to anyone that subscribes.&nbsp;</p><h3><strong>Why Do You Want To Start A Podcast?</strong></h3><p>There are various reasons for starting a podcast, and it varies per person. This question can have a lot of answers, but your conviction is the most important factor.</p><p><em>How much do you want to start a podcast?</em></p><p>Because if your answer is not a firm yes, then you may have challenges putting in the consistent effort to make it grow.</p><p><em>Why do you want to start a podcast?</em></p><p>There could be various reasons...<br></p><ul role="list"><li>To promote your business</li><li>To talk about your passion</li><li>To preach to the world</li><li>To share your message</li><li>To establish yourself as an authority</li><li>To have fun</li></ul><p>Whatever your reason is, you must be convinced.</p><p>This conviction will help you create a lasting relationship with your audience as you continue to execute over time when others fail to be consistent.</p><p>If&nbsp;you look at all the most popular podcasts... you will see that they have been running for years and even decades. This is what you must be prepared to do to generate a sizeable audience.</p><h3><strong>What Is The Topic Of Your Podcast?</strong></h3><p>It's now time to choose a theme/topic for your podcast. </p><p>This is the BIG one. It's make or break.</p><p>You MUST consider:</p><ul role="list"><li>Your passion on the topic</li><li>Your expertise and experience of the topic</li><li>The ability for your to monetise the topic</li></ul><p>Here at bCast, we are all about podcast profitability. We're not hobbyists. We know you need to get paid if you're going to do this for the long term and build a podcast worth listening to.</p><p>Now monetisation can come from advertising... so you don't necessarily need to have products or services in the niche or topic of your podcast... but you will need an intense passion.</p><p>Once you have spent a long time sitting in a dark room thinking about this... you then need to understand the #1 thing that will define the success or failure of your podcast:</p><p><strong><em>How are you different or better for a specific group of people?</em></strong></p><p>As if you are not... and you don't have a load of money to spend on Facebook Ads, it's going to be hard to make your podcast grow. Trust me... we know.</p><p>Maybe you only ask specific types of questions; perhaps you focus on a particular niche, perhaps you only interview three people at a time… it can be anything as long as it makes you different or better for a specific group of people.</p><p>If you are VERY particular about this… you will more than double your chances of succeeding.</p><h3><strong>Who Are Your Listeners?</strong></h3><p>Now that you have answered the WHY and WHAT, it is time to answer the WHO question.</p><p>Every podcast needs listeners, and in order for your podcast to grow... you must know exactly who your listeners are and where to find them.&nbsp;</p><figure id="w-node-08046cb77a20-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf937aa690314e79dafd__co8aVE5evZ3_Tzk8ZugkGqAFkT8oBN3HT-ksoEWq5FNU4yYXhOaV3P8uJZ27GaH8Ha-aIdbGh3PPQqOLLXsAZ-K6sSfKjXfmjcmVJW5xRfolNsufXY7OnFRKVLn4GMako-ZIAM_.gif" alt=""></p></figure><p>You need to find out:</p><ul role="list"><li>Where they are&nbsp;</li><li>How old they are</li><li>What catches their attention</li><li>What they eat for breakfast</li><li>Who they hate</li><li>Who they love</li></ul><p>This is why it's normally a great strategy for you to actually BE&nbsp;YOUR&nbsp;PERFECT&nbsp;LISTENER. This is a shortcut through this stage of the process as if this is the case, you should know the answers to all of those questions ;)</p><p>Once this is defined you then need to list out a number of places where these people hang out online:</p><ul role="list"><li>Blogs</li><li>Other podcasts</li><li>Facebook Groups</li><li>subReddits</li><li>Linkedin Groups</li><li>YouTube Channels</li></ul><p>We will need this list later in the process when we move through the launch and grow stages.</p><h3><strong>How Do You Name Your Podcast?</strong></h3><p>There are a number of strategies to follow here...</p><ul role="list"><li><strong><em>Make it concise</em></strong></li></ul><p>Succinct podcast names land better as they convey the message most strongly.</p><ul role="list"><li><strong><em>Do not neglect the relevant keyword</em></strong></li></ul><p><strong><em>‍</em></strong>If your podcast is about soccer, let the name convey that; this is important in searches, as your podcast name will pop up in searches related to your industry.</p><ul role="list"><li>‍<strong><em>Make it easy on the tongue</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want a twisted name, as you will mention it time and again on your podcast – it should be smooth to say.</p><ul role="list"><li><strong><em>Keep it simple</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want the stress of explaining your podcast name every time. Embrace simplicity</p><ul role="list"><li><strong><em>Look out for rhyme and alliteration opportunities</em></strong></li></ul><p>The best names of anything normally incorporate rhyme and/or alliteration... be on the look out for these opportunities and incorporate them if they arise.</p><p>To make this clearer... here are some great examples along with an explanation for why:</p><p><a href="https://podcasts.bcast.fm/sales-ops-demystified" target="_blank"><strong>Sales Ops Demystified</strong></a>: We include the core key word AND the value proposition of the show. It's clear and concise and succinctly tells the potential listener why they should listen.</p><p><a href="https://podcasts.bcast.fm/mobile-growth-pancakes" target="_blank"><strong>Mobile Growth and Pancakes</strong></a>: Keyword conscious and not boring. This podcast name is exciting, and a listener will want to hear what they have to say. It lays a foundation for what to expect, which is discussing mobile growth in a fun and slightly... different way.&nbsp;</p><p><a href="https://podcasts.bcast.fm/shine-a-podcast-by-star" target="_blank"><strong>Shine: a Podcast by Star</strong></a>: Simple and short. The host already directs the listener's thought from the first word. It also promotes the host, as a name is attached to the podcast and conveys an aspect of the hosts brand: shining through technology.</p><p><a href="https://podcasts.bcast.fm/be-more-a-podcast-by-peakon" target="_blank"><strong>Be More - a podcast by Peakon</strong></a>: If you want to be more, you have to listen. Everyone wants to be more, and this podcast name exploits that emotional aspect with this name: it's aspirational. The listener wants to know how they can "be more".&nbsp;</p><h3><strong>How Do You Describe Your Podcast?</strong></h3><p>Research has shown that your <a href="https://www.thepodcasthost.com/promotion/podcast-discoverability/" target="_blank">podcast description</a> is the number one factor that new listeners consider when deciding whether to subscribe. When describing your podcast, you must be able to offer value to the listener quickly. You must tell in precise terms, what they stand to gain by listening to your show.</p><p>You also have to consider search engines as you construct e your podcast description. Your show description must be able to rank to stand a chance of getting any free exposure from Google. Include relevant keywords in the industry you cover.&nbsp;</p><p>When writing your description, you should consider attention span. You need to grab listeners' attention by putting the juicy points first. You also need to make fair use of the description by avoiding repetition.&nbsp;</p><p>Be concise, offer value, and grab attention with the first lines.&nbsp;</p><h3><strong>How Do You Pick The Right Category For Your Podcast?</strong></h3><p>The primary way podcast listeners discover podcasts is through searching within podcast listening apps. They navigate through different categories and topics and look for the best shows in that category – <strong>this is why</strong> you need to place your podcast in the right category. It will increase the chance that your perfect listener will discover your podcast.</p><p>You get three chances:</p><ul role="list"><li>1 Primary category</li><li>2 Sub categories</li></ul><p>I won't share much more on this as I assume you know the category in which your podcast should reside!</p><h3><strong>What Podcast Format Should You Adopt?</strong></h3><p>There are different formats for podcasts. The good thing is, you have creative control over the structure of your podcast. In most cases, the format you choose depends on the message you are trying to convey to your audience.&nbsp;</p><p>There are different types of formats:</p><ul role="list"><li><strong>Interview podcast:</strong> this format involves a host that brings guests on the show, and interviews them. These guests are usually experts in their field, and the host asks them relevant questions in their industry.&nbsp;</li><li><strong>Monologue podcast:</strong> this format involves the host alone. The host will run solo and speak about their experiences and area of expertise. It is mostly educational and a teaching type of format.</li><li><strong>Co-hosted podcast:</strong> this format will involve two hosts that will have conversations. They share their experiences and have a back and forth when needed.&nbsp;</li><li><strong>Story-based podcast:</strong> this format involves a host that tells a story like a drama to the audience. The story could be fiction or non-fiction. The host finds ways to spice it up through the use of different effects.</li></ul><p>That said, there is room for more than one format on your podcast. You could adopt different forms for different episodes, depending on the message you are trying to pass.</p><p>So why not start out with one... test, gather …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bcast.fm/blog/how-to-start-a-podcast">https://www.bcast.fm/blog/how-to-start-a-podcast</a></em></p>]]>
            </description>
            <link>https://www.bcast.fm/blog/how-to-start-a-podcast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384162</guid>
            <pubDate>Fri, 11 Dec 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can have democracy or we can have Facebook]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25383976">thread link</a>) | @imartin2k
<br/>
December 11, 2020 | https://the.ink/p/we-can-have-democracy-or-we-can-have | <a href="https://web.archive.org/web/*/https://the.ink/p/we-can-have-democracy-or-we-can-have">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg&quot;,&quot;height&quot;:798,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:277616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Being on the phone with <a href="https://twitter.com/matthewstoller">Matt Stoller</a> when a giant antitrust case is announced against Facebook is like texting with the pope when the Second Coming, you know, comes.</p><p>It’s a little on the nose. A little exciting.</p><p>I’d been wanting to talk to Matt for a while, in part because the pope actually turned down my recent interview request (someone please tell him how book tours work).</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png&quot;,&quot;height&quot;:264,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:51146,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>And in part because I consider him (Matt) one of the more interesting, iconoclastic, morally committed, unpredictable, critics-may-care thinkers today. In the course of a typical Twitter day, which is a week in human time, I agree with Matt, disagree with him, wish I had thought of something he said, regret something he said on his behalf, retweet something he wrote, and make a mental note to talk with him soon. So I did.</p><p>And there we were, talking about everything — his political education, why he goes back and forth between thinking of himself as a progressive and not, his highly influential recent book, “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>” — when my phone began to crackle with <a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">news of an historic antitrust case against Facebook</a>.</p><p>Naturally, I began to ask Matt about it. What he said was so compelling that I’ve decided to break our interview into two issues of the newsletter. Today: Matt Stoller on Facebook, this important case, and how monopoly is mistaken as a policy issue when in fact it represents an existential question of whether we are actually a democracy.</p><p>Then, before long, <a href="https://www.imdb.com/title/tt0107144/">part deux</a>, the political education of Matt Stoller — thinker, writer, civil servant, trustbuster, Twitter beefer, and, presently, aspiring political philosopher.</p><p>Without shame, I’ll add, in the spirit of Matt’s ideas, that if you want to do your part to support small, independent media, and haven’t yet, consider subscribing to The Ink.</p><h3>“The way we do business is the way we do justice”: a conversation with Matt Stoller, part one</h3><p>ANAND: Right as we're talking, I get a news alert: “<a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">Facebook illegally crushed competition by buying up its rivals, according to lawsuits filed by 48 states and federal regulators</a>.” So this is the big case that we've been waiting for. Can you explain to a person who has never focused on this issue before in their life, and who just uses Facebook to try to get with their high-school ex, why is this a big deal? What does this mean?</p><p>MATT: So Facebook is a financial conglomerate. People think of Facebook as that website you use or the app that you use, but really Facebook, as a political institution, is a financial conglomerate and owns dozens of different companies, including Instagram and WhatsApp and Facebook, the social network. And it's a giant advertising company. So they have roughly three billion users. And they try to get their users to do things that their advertisers want them to do, because that's how you sell advertising.</p><p>The business model is to divert revenue that used to go to newspapers and publishers to themselves. And so by manipulating people in this specific way that they do, which is to keep them using their system and keep surveilling them so that they can target them with ads, they are, in the process, crushing newspapers and publishers, who no longer have any financing, particularly local newspapers and niche publications like Black-owned newspapers.</p><p>So increasingly those kinds of publications don't exist. You don't have reporters covering state houses and city halls and whatnot. Instead, people are now consuming things that Facebook likes them to consume because it keeps them using, and it keeps them available to sell ads to them, which are anti-social publications or posts, like anti-vax stuff or QAnon or whatever it is.</p><p>So that's the basic problem. It's a $70-, $80-, $100-billion-a-year revenue company that's destroying newspapers and publishers all over the world and getting people to pass conspiracy theories to each other so that Facebook can make money on advertising.</p><p>ANAND: You're an anti-monopoly guy. If there were three or five companies in healthy competition with each other, all doing exactly what you just described, wouldn't it still be problematic? Is the issue here that there's only one of them of that heft, or would a competitive market with five such players still be incredibly troubling?</p><p>MATT: There's a lot more that you have to do than just break them up. But the answer is, it would improve things dramatically if they were broken up, and you don't have to imagine it.</p><p>There used to be a bunch of social networks. Facebook's main competitor was Myspace, but there were a bunch of others. There was BlackPlanet; there was Friendster. And the way that Facebook actually defeated Myspace was by promising a safer, more private experience. They defeated Myspace by saying, We will treat your data carefully; in fact, when we change the terms of service, we will let our users vote on the terms of service.</p><p>This was back in 2007, 2008, 2009. And once they killed their competition, and then they bought up nascent competitors like Instagram and WhatsApp, then they didn't have to compete by offering a higher-quality service, a.k.a one that was less intrusive in terms of surveillance. They could just surveil anybody they wanted, and you didn't really have a choice.</p><p>ANAND: Where do you think this case is going?</p><p>MATT: They’re going to aim to break up the company. The House Antitrust Subcommittee did this long investigation of big tech, which includes Facebook. And one of the things they found is that Mark Zuckerberg was writing emails saying they were buying these companies to block competition. And so that's evidence that the mergers were illegal, because you're not supposed to buy companies to block competition. That's a violation of the Clayton Act. My guess is that they're going to have a pretty good complaint.&nbsp;</p><p>ANAND: Based on the history of such cases, would your assumption be that Facebook is broken up within a period of years?</p><p>MATT: Yes.</p><p>However, we haven't enforced the law for 20 years, so it’s not entirely clear. The law at this point is crazy and incoherent because we haven't done enforcement, and to the extent that we have, judges have just made wildly inconsistent rulings.</p><p>ANAND: This kind of action that's being announced today is the epitome of a systemic, public response to a problem. And when I, like you, advocate for those types of things, I often hear this response that I'm sure you do, too, which is, “OK, that's fine, but what about individual actions?” A lot of people are like, “Yes, let’s delete Facebook.” Or: “Why aren't you supporting the Facebook boycott?”, and there are different views on it.</p><p>There are some people who make the argument that those kind of small personal things are sideshows, distractions, maybe even unhelpful, because they reduce the perceived need for bigger systemic change. I fall more into that camp. There are others who say it's a gateway drug, it's a waystation, like: “Delete Facebook and then work yourself up to a political response." How do you weigh in on that?</p><p>MATT: I think it's a bad vision of politics. It's not doing politics to say, “Me, as a consumer, I can change power arrangements based on what I consume or don’t.” That's a real 1970s consumer-rights Democrat vision of the world, and that's one in which you as a citizen are irrelevant.</p><p>A boycott is only political if the goal is a policy change. If you go in and you say, "Well, I don't like Facebook, I want to change Facebook, so I'm going to delete Facebook," that's not going to do anything. If it's part of some larger political action saying, "Well, I'm going to delete Facebook, and then I'm going to push policymakers to break it up," I mean, I guess that makes sense.</p><p>But the general view of these boycotts is that just not using Facebook is the political action. But that's actually not a political action.</p><p>ANAND: An issue like monopoly is different from, say, healthcare, where you don't have to explain to most people the problem with our healthcare system. How do you think about making the issue of monopoly real to people and vivid and relevant to their lives?</p><p>MATT: I'm going to challenge the premise. I don't think monopoly is an <em>issue</em>. I think monopoly is a worldview.</p><p>My book is called “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>.” Anti-monopolism is a lens through which you understand power, and particularly commercial power. That’s the lens that I see the world through. And I don't just focus on Facebook or Google. I’m focused on anti-monopolism in general. How you use business institutions to coerce and bully — or liberate — other people in your society.</p><p>There's a monopolist who controls the cheerleading industry, which is very weird. I just learned there is a private-equity company that is trying to monopolize the software that churches run. There is a monopoly of Ultimate Fighting Championship-style contests. And then in healthcare there are endless numbers of monopolists. Ultimately, what a monopolist is is a person or institution that is controlling and governing a market. It's a private government versus a public government.</p><p>ANAND: You’re saying it’s incompatible with democracy.</p><p>MATT: Right. It’s a different system. When Mark Zuckerberg says he’s going to arrange electoral discourse in this particular way, or going to start a <a href="https://www.businessinsider.com/meet-the-first-20-members-of-facebook-supreme-court-2020-5">Supreme Court</a>, or going to ban this or allow that, he is operating as the global privacy commissioner. <a href="https://www.vox.com/the-big-idea/2018/4/9/17214752/zuckerberg-facebook-power-regulation-data-privacy-control-political-theory-data-breach-king">He even said</a>, "In a lot of ways Facebook is more like a government than a traditional company." That's a direct quote.</p><p>As a society, the way we do business is the way we do justice.</p><p>ANAND: Understanding how these platforms work, do you think that if Mark Zuckerberg wanted to tip an election, he could? Would that even be illegal under our current system?</p><p>MATT: I don't know if it's possible, but it's certainly legal if he decided to.</p><p>I listened to this podcast with Zuckerberg where he said — this was right before he became unpopular, so he was still being relatively …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">https://the.ink/p/we-can-have-democracy-or-we-can-have</a></em></p>]]>
            </description>
            <link>https://the.ink/p/we-can-have-democracy-or-we-can-have</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383976</guid>
            <pubDate>Fri, 11 Dec 2020 09:48:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Operators 101]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383807">thread link</a>) | @evenh
<br/>
December 11, 2020 | https://thecloud.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://thecloud.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.imgur.com/PRCyBqa.jpg" alt=""><div><section><p>Kubernetes has become the <em>de facto</em> container orchestrator since it's initial release in 2014. It is a great tool for managing diverse workloads in clusters of machines, possibly spanning multiple availability zones. As the usage grows, new requirements for how to deploy and operate specialized software emerges. The Operator pattern is one of the more prominent responses to these new requirements.</p>
</section><article><section><p>The Operator pattern is best described in the <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">official Kubernetes documentation</a>:</p>
<blockquote>
<p>The Operator pattern aims to capture the key aim of a human operator who is managing a service or set of services. Human operators who look after specific applications and services have deep knowledge of how the system ought to behave, how to deploy it, and how to react if there are problems.</p>
<p>People who run workloads on Kubernetes often like to use automation to take care of repeatable tasks. The Operator pattern captures how you can write code to automate a task beyond what Kubernetes itself provides.</p>
</blockquote>
<p><strong>TL;DR</strong> Operators automate operation of applications and services with human know-how.</p>
<h2>How does an Operator work?</h2>
<p>An Operator consists at a minimum of one Custom Resource Definition (<code>CRD</code>) and a Controller. The <code>CRD</code> describes the various configuration options for this kind of resource. Given a custom resource for a <code>PostgresDatabase</code>, one might find options for specifying custom <code>StorageClass</code>es, resource allocation, backup schedule/destinations, authentication methods, etc.</p>
<p>Given an instance (<code>CR</code>) of <code>PostgresDatabase</code>, it's now the job of the controller to ensure that the desired state is reconciled with the cluster. In this example one can assume that the controller will create a <code>StatefulSet</code> for running the database itself, along with needed configuration in a <code>ConfigMap</code>, certificates for mutual TLS in a <code>Secret</code>. Backup can be done by either mounting and writing to a volume defined in the <code>CR</code> or injecting a sidecar for sending backups to another location.</p>
<p>Patching, reboots and failovers can be specified in the <code>CR</code> and taken care of by the controller, using methods recommended by experienced DBA's. The fact that complex operational knowledge can be encoded into the controller is a key enabler for many organizations that would like to run complex software, but not necessarily invest countless hours into learning the nitty-gritty details on how to operate it.</p>
<p>Like any other software there will be bugs and abstractions will leak. There's no silver bullet.</p>
<h2>How do I create my own Operator?</h2>
<p>As with the rest of the Kubernetes community, multiple solutions exists.</p>
<ul>
<li>For a declarative experience, check out <a href="https://kudo.dev/">KUDU</a></li>
<li>If you'd like a more official way to do it, see <a href="https://github.com/kubernetes-sigs/kubebuilder">kubebuilder</a></li>
<li>The most popular option seems to be <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a></li>
</ul>
<p>As with most cloud native software, Go seems to be the lingua franca. There is nothing stopping you from writing an Operator in Java, C#, Python or any other language that can communicate with the Kubernetes APIs.</p>
<h2>Examples of known Operators</h2>
<p>The community has produced a lot of Operators for about everything one can imagine. These are some popular examples:</p>
<ul>
<li><a href="https://github.com/argoproj/argo-cd">Argo CD</a> – a  declarative, GitOps continuous delivery tool for Kubernetes.</li>
<li><a href="https://github.com/jetstack/cert-manager">cert-manager</a> – automatically provisions TLS certificates via the ACME protocol. Can be used with certificate issuers such as <a href="https://letsencrypt.org/">Let's Encrypt</a>, <a href="https://www.buypass.no/ssl/resources/acme-free-ssl">Buypass</a> and <a href="https://zerossl.com/documentation/acme/">ZeroSSL</a>.</li>
<li><a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a> – often used in combination with <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus</a> for a batteries included monitoring suite</li>
<li><a href="https://kubedb.com/">KubeDB</a> – a real-life implementation of the <code>PostgresDatabase</code> example, plus support for MySQL/MariaDB/MongoDB/Redis/Memcached and more</li>
</ul>
<p><small>Header image: RIA Novosti archive, image #305015 / Alexey Danichev / CC-BY-SA 3.0</small></p></section></article></div></article><section><ul><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://thecloud.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383807</guid>
            <pubDate>Fri, 11 Dec 2020 09:13:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – A Devastating Form of Digital Extortion]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383148">thread link</a>) | @roberla
<br/>
December 10, 2020 | https://security.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We live in a digital era where the most precious commodity no longer is oil or gold, but data. But what if this data, including personal files, customer lists and company data, flight traffic information, or even sensitive hospital records were stolen? What would you do, or pay, to get it back?</p>
</section><article><section><p>Ransomware has been on the rise the past years, where criminals effectively take all the data on your computer hostage and demand a ransom to give it back to you. Refusing to pay may result in your data being lost permanently. </p>
<p>Everyone is a potential target for ransomware, including single individuals, small to large companies, and even public institutions. A disconcerting trend is the targeting of hospitals and the public sector. Only last year the Hollywood Presbyterian Medical Center in Los Angeles was <a href="https://sanfrancisco.cbslocal.com/2016/02/18/california-hospital-ransomware-attack-hackers/">attacked by ransomware</a>, blocking the company’s access to their own network and crucial patient data for 10 whole days. The hospital ended up paying the ransom of $17 000 in bitcoin to decrypt the data. </p>
<p>The demands have also increased drastically the last few years, where the <a href="https://www.coveware.com/blog/q2-2020-ransomware-marketplace-report">average ransom payment</a> having increased to an exorbitant $178 000 in Q2 of 2020. Some bigger companies also receive very high demands. For instance, Garmin was attacked in 2020 with an initial ransom demand of $10 million, which some <a href="https://www.bleepingcomputer.com/news/security/confirmed-garmin-received-decryptor-for-wastedlocker-ransomware/">sources</a> claim they chose to pay. And this does not include the costs of other factors such as downtime, loss of revenue, mistrust from consumers, and resources used to get everything up and running again. </p>
<p>Clearly, ransomware is a growing problem with an increase in both attacks and in the ransom demands themselves, as well as the targeting of sectors with the possible consequence of directly endangering lives. </p>
<p>But how to the criminals make their attacks so successful, either forcing a victim to pay or having to accept the loss of their data? The main principle of ransomware is that attackers will encrypt all the files rendering them unreadable, and only by buying the key to decrypt the files will they be accessible again. The first step to achieve this, is to obtain access to a computer or network in order to install the ransomware. </p>
<h2>How does ransomware get installed on my computer?</h2>
<p>Ransomware is a type of malware, which is a malicious piece of software that installs itself without permission on someone’s computer or even an organization’s whole system. The most common ways the attackers get access to your computer are:</p>
<ol>
<li>Phishing – a cyber-attack imitating a trusted source, where an employee or private person is tricked into installing the malware without knowing it. This can be through clicking a link or downloading an attachment in a seemingly legit email.</li>
<li>Drive by downloads – visiting compromised websites that then installs the malware on your computer.</li>
<li>Security vulnerabilities – if systems are not up to date and are known to have weaknesses, then attackers will exploit these to install their malware. </li>
</ol>
<h2>How does ransomware encrypt my files?</h2>
<p>Once the ransomware is installed, it encrypts all the data on your computer. Unfortunately, the encryption methods used now are so complex that it is unfeasible to decrypt the files without the decryption key, which is known only to the attackers. To achieve a secure encryption of your data, the attackers use a combination of symmetric and asymmetric encryption. </p>
<h4>Symmetric encryption</h4>
<p>One of the oldest ciphers in history is the shift cipher, which shifts each letter a set number of times back or forth in the alphabet. Knowing this set number, also referred to as the “key”, is therefore enough to both encrypt and decrypt a text. Julius Caesar was believed to use a shift cipher, substituting each letter with the one 3 spaces to the right. This is one of the simplest examples of a symmetric encryption. </p>
<p>Today, there are more advanced versions, which can be broadly categorized as block ciphers (encrypts in byte-sized blocks) or stream ciphers (encrypts single digits). These methods are fast and only require the same key to encrypt and decrypt. </p>
<h4>Asymmetric encryption</h4>
<p>Asymmetric encryption is slower and uses two keys instead of one: one public and one private. The private key is only in the possession of the key pair owner, whereas the public one is widely distributed. When using the public key to encrypt a message it can only be decrypted using the private key, and vice versa.  </p>
<h4>Ransomware take advantage of both encryption methods.</h4>
<p>One of the most common ways a ransomware takes over your computer, is through the following steps:</p>
<ol>
<li>When the ransomware is installed on a computer, it comes with an asymmetric public key, which it used to establish contact with the attackers’ server. All communication is encrypted using this asymmetric encryption, making it impossible to intercept and interpret the communication between the affected computer and the server. </li>
<li>The ransomware will then request a new asymmetric public key from the server, which is specific for the victim’s computer (making it impossible to share a key with other victims). </li>
<li>Once received, the ransomware also creates a symmetric key, which quickly encrypts all the files. </li>
<li>The symmetric key is then encrypted using the asymmetric key specific to the victim. This means that only the private key on the attackers’ server can be used to unlock the symmetric key, which again will decrypt all the files. </li>
</ol>
<p>This makes the whole process fast and yet very secure, and almost impossible to decrypt without paying the ransom. </p>
<h2>Victims of ransomware</h2>
<p>Originally, ransomware was used to target individuals, with a low enough ransom so most people would choose to pay. While individuals are still affected, organizations are targeted on a more regular basis, and can offer a more lucrative pay-off if successful. In fact, <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">one study</a> showed that over half of the companies had been subjected to a ransomware attack in the past year, and that 73% of these attacks were successful. A recent trend also shows an increase in attacks targeting <a href="https://edition.cnn.com/2020/10/28/politics/hospitals-targeted-ransomware-attacks/index.html">government institutions and hospitals</a>.  </p>
<h2>Costs and solutions</h2>
<p>An estimate shows that total ransom demands will reach a staggering <a href="https://cybersecurityventures.com/global-ransomware-damage-costs-predicted-to-reach-20-billion-usd-by-2021/">20 billion USD by 2021</a>. </p>
<p>While paying the ransom is strongly discouraged as it helps create a marked for extorting money in this manner, some still choose to pay the ransom to retrieve their data. One recent <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> of 5000 IT people showed that about 26% chose to pay and that of these, 95% did actually get the decryption key needed to unlock their files again. Over half chose not to pay and instead used backups of their data, while the rest used other methods.</p>
<p>However, even though paying up may seem like the best way to get things restored again, it may actually double the costs of being affected. All organizations attacked by ransomware had a high cost due to downtime, network costs, lost opportunity etc. even without paying the ransom. In fact, the authors of this <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> argue that the organizations that chose to pay  had the same costs as those who did not with getting their systems back online, except they also had the cost of removing the encryption in addition to their other expenses.</p>
<p>As most attacks are successful and as it is nearly impossible to decrypt your files after an attack, it’s best to try and prevent an attack in the first place. Good strategies include having regular and off-site backup of data, installing anti-ransomware on your system, training employees in recognizing phishing, and closing any technological vulnerabilites that could be exploited. Stay tuned for more on this and other good preventative measure in our next article.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383148</guid>
            <pubDate>Fri, 11 Dec 2020 06:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some doctors, therapists get Health Canada permission to use magic mushrooms]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25382497">thread link</a>) | @billyharris
<br/>
December 10, 2020 | https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4039727.1492805330!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/63883228.jpg"></p></div><figcaption>Psilocybin is the ingredient in magic mushrooms that causes hallucinations, but in medically supervised settings, can also potentially help people overcome depression.<!-- --> <!-- -->(Shutterstock / gsplanet)</figcaption></figure><p><span><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.&nbsp;</p>  <p>Health Canada says it granted 16 exemptions to a selection of nurses, doctors, therapists and social workers, allowing them to possess and use&nbsp;psilocybin&nbsp;for personal training without fear of prosecution under the country's drug laws.&nbsp;</p>  <p>"This is not a small step. This is a seismic step," said Dr. Sean O'Sullivan, a Tillsonburg, Ont., doctor and medical director of TheraPsil, a non-profit group that advocates for the therapeutic use of psilocybin.&nbsp;</p>  <p>"This is permission from the Ministry of Health and the Minister of Health to allow therapists to forward their own training in psychedelic medicine."&nbsp;</p>  <p><span><span><div><div role="button" tabindex="0" title="Mushrooms: The Magic Medicine"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/337/291/Sickboy-640x360.jpg" alt=""></p><p><span>Sickboy</span><span>1:02:33</span><span>Mushrooms: The Magic Medicine</span></p></div></div></div><span>Thomas Hartle never used drugs before his Stage IV cancer diagnosis. That’s changed thanks to Therapsil. A couple months ago, he became the first Canadian to legally use psychedelic mushrooms to treat end of life anxiety and depression. Take a listen to his story with an open mind.<!-- --> <!-- -->1:02:33</span></span></span><span><ul><li><a href="https://www.cbc.ca/news/health/microdosing-pschedelics-study-1.4771647" data-contentid="" flag="" text="How and why people 'microdose' tiny hits of psychedelic drugs"><span>How and why people 'microdose' tiny hits of psychedelic drugs</span></a></li></ul></span></p>  <p>The move comes after Health Canada&nbsp;gave <a href="https://www.cbc.ca/news/canada/british-columbia/magic-mushrooms-therapy-1.5675637" target="_blank">four exemptions to palliative care patients</a> to use the drug&nbsp;for end-of-life psychotherapy in August. Since then, other exemptions have been given to patients who want to use magic mushrooms.&nbsp;</p>  <p>The exemptions for health professionals will allow those who want to treat patients with psilocybin&nbsp;to understand what it would feel like and how best to use it.&nbsp;</p>  <p>They are good for one year.&nbsp;</p>  <p>"Psychedelic substances and treatment using these substances, such as&nbsp;psilocybin, is a growing area of scientific study and research. Because&nbsp;psilocybin&nbsp;is not an authorized therapeutic substance, the availability of rigorous scientific evidence demonstrating its safety and efficacy is limited," Health Canada said in a statement to CBC News.&nbsp;</p>  <p>"The exemptions do not permit the health care professionals to prescribe or provide mushrooms containing&nbsp;psilocybin&nbsp;to another person. There are no drugs containing&nbsp;psilocybin&nbsp;that have been authorized&nbsp; by Health Canada. Health Canada's decision to grant these exemptions does not constitute an opinion or endorsement from Health Canada on&nbsp;psilocybin-assisted psychotherapy, training, or the safety, effectiveness, or quality of&nbsp;psilocybin."</p>  <h2>Psychiatrists, nurses given exemptions</h2>  <p>"This is an immense step that the minister has taken, and a very wise step, a step that is totally congruent with the science and the published literature and is a very courageous move on her part and on our government's part," O'Sullivan said.&nbsp;</p>  <p>Psychedelic therapies such as psilocybin and LSD have had negative reputations, in part because of the war on drugs, O'Sullivan said.&nbsp;</p>    <p>"The war on drugs has been an unmitigated disaster worldwide. It has criminalized behaviour that does not need to be criminalized. Cannabis has been legalized, and the sky has not fallen," O'Sullivan said.&nbsp;</p>  <p>Those who have been given exemptions include psychiatrists associated with the University of Toronto, a community psychiatrist in Hamilton and his partner, as well as health professionals in Calgary and British Columbia.&nbsp;</p>  <p>O'Sullivan and his wife both got an exemption. He is a general practitioner and she is a therapist. He said it's important for doctors who could eventually prescribe psychedelics to be well versed in their effects.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/dr-sean-o-sullivan.JPG 300w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/dr-sean-o-sullivan.JPG 460w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/dr-sean-o-sullivan.JPG 620w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG 780w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/dr-sean-o-sullivan.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG"></p></div><figcaption>Dr. Sean O'Sullivan is one of 16 health professionals who has been granted an exemption from Canada's drug laws to use magic mushrooms. <!-- --> <!-- -->(Submitted by Sean O'Sullivan)</figcaption></figure></span></p>  <p>"You would not expect a guide to take any journey over any terrain with&nbsp;which the guide was not familiar. When it comes to psychedelics, the terrain is so unusual and so outlandish that it is absolutely imperative that the therapist have familiarity with the realms of the human unconscious that are visited under psychedelics because they can help guide the patient through situations that might seem utterly bizarre, even psychotic to an untrained therapist," O'Sullivan said.</p>  <p>"Great information can be obtained if you dissect and unpack that material that comes up under these medications."</p>  <p>Psilocybin&nbsp;allows the brain to put away the "default mode network," the part of our brain that worries about taxes and dinner and the shopping list, and dive deeper.&nbsp;</p>    <p>"If you look at your <a href="https://www.cbc.ca/news/health/seeking-seat-of-consciousness-in-dark-side-of-brain-1.1415607" target="_blank">default mode network</a>, you will find that the themes that come up are the same themes that came up last year and the year before and the decade before," O'Sullivan said. "Psychedelics disassemble the default mode network and they allow a person to have new experiences in a carefully controlled clinical setting. When the default mode network is put back together, it's not put back together in the same way as it was previously."</p>  <p>That's why a single dose of a psychedelic medicine can have more effect than years of talk therapy or medication, he said.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382497</guid>
            <pubDate>Fri, 11 Dec 2020 05:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Economics of Software Performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381748">thread link</a>) | @ivanmontillam
<br/>
December 10, 2020 | https://www.ivanmontilla.com/2020/12/economics-of-software-performance/ | <a href="https://web.archive.org/web/*/https://www.ivanmontilla.com/2020/12/economics-of-software-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.ivanmontilla.com/2020/12/economics-of-software-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381748</guid>
            <pubDate>Fri, 11 Dec 2020 02:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clubhouse Conversation with Dylan Field]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381458">thread link</a>) | @giacaglia
<br/>
December 10, 2020 | https://www.joinclubhouse.com/event/9mW6WaMX | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/event/9mW6WaMX">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinclubhouse.com/event/9mW6WaMX</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381458</guid>
            <pubDate>Fri, 11 Dec 2020 02:15:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Alternatives]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 170 (<a href="https://news.ycombinator.com/item?id=25380999">thread link</a>) | @yepgwer
<br/>
December 10, 2020 | https://justprivacy.org/google-alternatives/ | <a href="https://web.archive.org/web/*/https://justprivacy.org/google-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span color="000000"><p>We may earn a small commission if you choose to purchase from our links <strong>(at no extra cost to you!)</strong></p></span></p><div data-elementor-type="wp-post" data-elementor-id="989" data-elementor-settings="[]"><div><div><section data-id="10b593b" data-element_type="section"></section><section data-id="c631736" data-element_type="section"><div><div><div data-id="72201ec" data-element_type="column"><div><div><div data-id="e877a4b" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" alt="Google Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" data-srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" sizes="(max-width: 992px) 100vw, 992px" title="Google Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="c32dc21" data-element_type="section"><div><div><div data-id="af9583c" data-element_type="column"><div><div><div data-id="797f602" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The purpose of this guide is to be the most in-depth list of the best alternatives to Google and its products.</p><p>Privacy and security of personal data online has become more of an issue, this means people are trying to find alternatives to Google.</p><p>The way Google makes money is by data collection and advertisements, with both affect your online privacy. The more data Google has on you the better they can find out what you’re interested in (target you) and therefore make more money off you. Did you know Google had over <a href="https://www.statista.com/statistics/267606/quarterly-revenue-of-google/" target="_blank" rel="noopener">$159 billion dollars in revenue</a> in 2019?</p><p>However, there is a growing amount of people who are looking for alternatives to Google.</p><p><span>Note:</span> None of these alternatives are in order, it depends on you’re specific needs.</p></div></div></div></div></div></div></div></div></section><section data-id="8997902" data-element_type="section"><div><div><div data-id="b2c7c82" data-element_type="column"><div><div><div data-id="a225dd3" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Search Engine Alternatives</h2></p></div><div data-id="6838ece" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="519" src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" alt="Google Search Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" data-srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" sizes="(max-width: 992px) 100vw, 992px" title="Google Search Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="4d6be8b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Privacy and Google search don’t go hand in hand. When you use Google search, they will record your IP address, your search terms, and usually a unique ID.</p><p>Here are some good alternatives to Google search.</p><ol><li><a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> – An internet search engine whose goal is to protect users’ privacy and avoiding personalized search results (tracking).</li><li><a href="https://www.qwant.com/" target="_blank" rel="noopener">Qwant</a> – Is a French search engine that doesn’t track users.</li><li><a href="https://searx.me/" target="_blank" rel="noopener">SearX</a> – Is a free metasearch engine, intended to protect the privacy of its users.</li><li><a href="https://startpage.com/" target="_blank" rel="noopener">Startpage</a> – a search engine extension that allows users to browse while not being tracked.</li><li><a href="https://swisscows.com/" target="_blank" rel="noopener">SwissCows</a> – Is a Swiss search engine that was launched in 2014. They don’t keep track of the searches done on their site.</li><li><a href="https://www.mojeek.com/" target="_blank" rel="noopener">Mojeek</a> – Is a UK-based search engine, they are independent and have unbiased results which means no user tracking.</li><li><a href="https://metager.org/" target="_blank" rel="noopener">MetaGer</a> – Is a search engine based on protecting users’ privacy, it’s also based in Germany.</li><li><a href="https://yandex.com/" target="_blank" rel="noopener">Yandex Search</a> – Is a search engine based in Russia and owned by a Russian corporation <a href="https://en.wikipedia.org/wiki/Yandex" target="_blank" rel="noopener">Yandex</a>.</li><li><a href="https://yacy.net/" target="_blank" rel="noopener">YaCy</a> – Is a free search engine built on principles of P2P (peer-to-peer) networks.</li></ol><p>Most of the search engines above are metasearch engines (except Mokeej and Yandex) meaning they source their search results from larger search engines like Google and Bing.</p></div></div></div></div></div></div></div></div></section><section data-id="56efb89" data-element_type="section"><div><div><div data-id="1091847" data-element_type="column"><div><div><div data-id="653fe9a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Chrome Alternatives</h2></p></div><div data-id="0470836" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" alt="Chrome Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Chrome Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="25f82ad" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Chrome is an extremely popular web browser and billions of searches are done monthly.</p><p>As you can see Google has 92.07% of the Search Engine Market Share Worldwide as of February 2020!</p></div></div></div><div data-id="e99d120" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noopener"> <img width="992" height="269" src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" alt="Market Share Chrome" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" data-srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" sizes="(max-width: 992px) 100vw, 992px" title="Market Share Chrome Google Alternatives: Protecting Your Data">		</a></p></div></div><div data-id="2d8725f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Remember that Google Chrome is not only a search engine but a super successful data collection tool! More and more people are noticing this. There are many articles saying that Google Chrome has become spyware!</p><p>If you want to read more about this you can read this forum on <a href="https://www.reddit.com/r/BATProject/comments/c3q51d/goodbye_chrome_googles_web_browser_has_become_spy/?utm_source=share&amp;utm_medium=web2x" target="_blank" rel="noopener">Reddit</a> and an article on <a href="https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/" target="_blank" rel="noopener">Washington Post.</a></p><p>Here are some good alternatives to Chrome:</p><ol><li><a href="https://www.torproject.org/projects/torbrowser.html.en" target="_blank" rel="noopener">Tor Browser</a> – Is a global and decentralized computer network. This allows you to hide from tracking and surveillance.</li><li><a href="https://www.mozilla.org/fr/firefox/new/" target="_blank" rel="noopener">Firefox</a> – Is a free and open-source web browser, it was developed by Mozilla Foundation and help from thousands of volunteers!</li><li><a href="https://brave.com/fr/" target="_blank" rel="noopener">Brave</a> – Is an open-source web browser whose goal is to protect the privacy of their users by blocking trackers or preferring pages in HTTPS.</li><li><a href="https://info.ecosia.org/" target="_blank" rel="nofollow noopener">ecosia</a> – Berlin-based search engine whose profits go into planting trees to fight against climate change! They are also privacy-friendly and ethical.</li><li><a href="https://iridiumbrowser.de/" target="_blank" rel="noopener">Iridium Browser</a> – Is based on the Chromium codebase. All modifications enhance privacy for the user.</li><li><a href="https://ungoogled-software.github.io/ungoogled-chromium-binaries/" target="_blank" rel="noopener">Ungoogled Chromium</a> – Is an open-source version of Chromium that has been modified to enhance users’ privacy.</li><li><a href="https://www.waterfox.net/" target="_blank" rel="noopener">Waterfox</a> – Is an open-source web browser that is based on Mozilla Firefox. Its purpose is to be speedy and ethical.</li><li><a href="https://www.epicbrowser.com/" target="_blank" rel="noopener">Epic Browser</a> – Is a “Privacy Browser” that is a secure chromium-based web browser.</li><li><a href="https://www.gnu.org/software/gnuzilla/" target="_blank" rel="noopener">GNUzilla</a> – Its a GNU version of the Mozilla suite. Its main advantage is that it’s ethical and entirely free!</li></ol><p>There are other alternatives to Google Chrome like Apple’s Safari and Microsoft’s Edge but many of these have serious privacy issues.</p></div></div></div></div></div></div></div></div></section><section data-id="0f232f2" data-element_type="section"><div><div><div data-id="dcd92ec" data-element_type="column"><div><div><div data-id="c5b213d" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" alt="Gmail Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="acb282e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Your inbox is where the most important information is sent. You can find a lot of information on a person based on your inbox.</p><p>The unfortunate thing is that Google and its partners have access to all your information and they can <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">collect data</a>, they can display ads inside your inbox, and the contents of your inbox are shared with random <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">third parties</a>.</p><p>Here are some more secure Gmail alternatives:</p><ol><li><a href="https://protonmail.com/" target="_blank" rel="noopener">ProtonMail</a> – Is an encrypted email service created in 2013 by CERN and MIT scientists.</li><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a> – Is a German-based email provider that is open-sourced with end-to-end email software. Tutanota also offers a web messaging service.</li><li><a href="https://posteo.de/en/" target="_blank" rel="noopener">Posteo</a> – Is a German email provider whose IT foundation is based on open-source software. They also use green energy from Greenpeace Energy and is also ad-free! The service costs € 1 per month.</li><li><a href="https://runbox.com/" target="_blank" rel="noopener">Runbox</a> – Is a company that provides email and web hosting services. It was founded in March 2011 and its headquarters are located in Oslo.</li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a> – Its an ad-free and secure email provider based in Germany, they offer a calendar, contacts lists and more.</li><li><a href="https://www.startmail.com/" target="_blank" rel="noopener">StartMail</a> – Is created by the people who created StartPage (a secure search engine).&nbsp;</li><li><a href="https://mailfence.com/en/" target="_blank" rel="noopener">Mailfence</a> – Is an encrypted email service based in Belgium. It offers free accounts.</li><li><a href="https://countermail.com/" target="_blank" rel="noopener">CounterMail</a> – Is a secure email provider that is based in Sweden.&nbsp;</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9dd4dfa" data-element_type="section"><div><div><div data-id="5d3cd03" data-element_type="column"><div><div><div data-id="6d29af4" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Calendar Alternatives</h2></p></div><div data-id="fc23717" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" alt="Gmail Alternatives 1" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives 1 Google Alternatives: Protecting Your Data"></p></div></div><div data-id="a3398d3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Calendar is amazing it helps users manage their time, set goals, and remember things.</p><p>There are many upsides to Google’s Calendar app but there are some major privacy issues and many people are looking for alternatives.</p><p>Here are multiple Google Calendar alternatives:</p><ol><li><a href="https://www.simplemobiletools.com/" target="_blank" rel="noopener">Simple Calendar</a> – It’s an ad-free app without any unnecessary permissions.</li><li><a href="https://fruux.com/" target="_blank" rel="noopener">Fruux</a> – Offers a free account, supports many operating systems, and is open-source.</li><li><a href="https://timetreeapp.com/intl/en/" target="_blank" rel="noopener">TimeTree</a> – It offers a free account and supports Android, iOS, and browser.</li><li><a href="https://protonmail.com/blog/protoncalendar-beta-announcement/" target="_blank" rel="noopener">ProtonCalendar</a> – Created by the same people who made ProtonMail!</li><li><a href="https://github.com/Kartones/flask-calendar#introduction" target="_blank" rel="noopener">Flask-Calendar</a> – Basic, self-hosted Calendar, has a few features as well</li></ol><p>There are a few services that offer both email and calendar services in one:</p><ul><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a></li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a></li><li><a href="https://posteo.de/" target="_blank" rel="noopener">Posteo</a></li><li><a href="https://mailfence.com/" target="_blank" rel="noopener">Mailfence</a></li><li><a href="https://outlook.live.com/" target="_blank" rel="noopener">Outlook</a></li></ul></div></div></div></div></div></div></div></div></section><section data-id="c72fb6b" data-element_type="section"><div><div><div data-id="f3c4b93" data-element_type="column"><div><div><div data-id="021a025" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Drive Alternatives</h2></p></div><div data-id="a27452e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" alt="Google Drive Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Drive Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="067a2fa" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Drive is a popular option because it’s free and extremely convenient, but Google doesn’t care about users’ privacy that much. It collects your data and uses it for their own purposes.</p><p>Here are some good Drive Alternatives:</p><ol><li><a href="https://www.dropbox.com/" target="_blank" rel="noopener">Dropbox</a> – Is a file hosting service owned by the American company Dropbox.</li><li><a href="https://www.sync.com/" target="_blank" rel="noopener">Sync.com</a> – Is based in Canada. They offer secure and encrypted cloud storage for both businesses and individuals.</li><li><a href="https://mega.nz/" target="_blank" rel="noopener">Mega</a> – Is a secure cloud storage service that offers free 50 GB of storage.</li><li><a href="https://nextcloud.com/" target="_blank" rel="noopener">Nextcloud</a> – This is a free and open-source file sharing platform that is based in Germany.</li><li><a href="https://github.com/syncthing/syncthing/tree/master" target="_blank" rel="noopener">Syncthing</a> – Peer-to-peer, an open-sourced cloud storage platform.</li><li><a href="https://tresorit.com/" target="_blank" rel="noopener">Tresorit</a>d Hungary that is serious about en<span>&nbsp;– Is a storage service based in Switzerland enhanced</span>&nbsp;security and data encryption.&nbsp;</li><li><a href="https://owncloud.org/" target="_blank" rel="noopener">ownCloud</a> – This is an open-source file sharing platform based in Germany.</li><li><a href="http://www.infomaniak.com/" target="_blank" rel="noopener">Infomaniak</a> – Switzerland-based privacy-friendly service that offers drive, calendar, and more services.</li></ol><p>Some of my recommendations above (Dropbox, Mega) aren’t the best for privacy but are much more privacy-friendly than Google Drive.</p></div></div></div></div></div></div></div></div></section><section data-id="560065d" data-element_type="section"><div><div><div data-id="473c144" data-element_type="column"><div><div><div data-id="f1693c6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" alt="Google Docs Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Docs Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="98b5c8d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Docs offers users to create documents easily online. But Google makes its money through data collection and Google’s bots have been caught crawling through users’ documents.</p><p>Here are some good alternatives to Google Drive:</p><ol><li><a href="https://www.zoho.com/docs/" target="_blank" rel="noopener">Zoho Office</a> – This is a good Google alternative for docs since it has a good interface and works well.</li><li><a href="https://etherpad.org/" target="_blank" rel="noopener">EtherPad</a> – Is an online free text editor that allows users to work collaboratively and in real-time.</li><li><a href="https://cryptpad.fr/" target="_blank" rel="noopener">CryptPad</a> – Is a great privacy-focused alternative to Google Docs.</li><li><a href="https://www.openoffice.org/" target="_blank" rel="noopener">Apache OpenOffice</a> – Is a good office suite platform that is also available <span>offline.</span></li><li><a href="https://personal.onlyoffice.com/" target="_blank" rel="noopener">OnlyOffice</a> – Is a multifunctional online office suite.</li><li><a href="https://www.nuclino.com/" target="_blank" rel="noopener">Nuclino</a> – Is a cloud-based collaboration software that allows teams to work on projects together and share information in real-time.</li><li><a href="https://flibreoffice.org/" target="_blank" rel="noopener">LibreOffice</a> – Is a good free and open-sourced office suite that is also available <span>offline.</span></li></ol></div></div></div></div></div></div></div></div></section><section data-id="46d2732" data-element_type="section"><div><div><div data-id="c3a000e" data-element_type="column"><div><div><div data-id="2f0a056" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" alt="YouTube Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="YouTube Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="46501a2" data-element_type="section"><div><div><div data-id="ce19e75" data-element_type="column"><div><div><div data-id="8f49f0c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Photos Alternatives</h2></p></div><div data-id="3b7c0a6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" alt="Google Photos Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Photos Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="9979111" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google offers unlimited storage for photo’s but Google isn’t doing it to be nice. They will use your photos to scan your pictures and track things you do. I don’t think Google or any company needs to know that much about you.</p><p>Here are a few good Google Photo’s alternatives:</p><ol><li><a href="https://piwigo.org/" target="_blank" rel="noopener">Piwigo</a> – Is an open-source photo gallery software.&nbsp;</li><li><a href="https://zyl.ai/" target="_blank" rel="noopener">Zyl</a> – Is a great mobile app that cares about privacy.</li><li><a href="https://crypt.ee/" target="_blank" rel="noopener">Cryptee</a> –&nbsp; Is a great option if you’re serious about your privacy. They offer many services as well as not just photos.</li><li><a href="https://cluster.co/" target="_blank" rel="noopener">Cluster</a> – A free app that’s allows you to create photo albums and share them with people you choose.</li><li><a href="https://photostructure.com/" target="_blank" rel="noopener">PhotoStructure</a> – relatively new self-hosted privacy-friendly photo manager</li></ol></div></div></div></div></div></div></div></div></section><section data-id="e855368" data-element_type="section"><div><div><div data-id="205ce2f" data-element_type="column"><div><div><div data-id="2236d87" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Analytics Alternatives</h2></p></div><div data-id="643d0e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" alt="Google Analytics Alternative" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Analytics Alternative Google Alternatives: Protecting Your Data"></p></div></div><div data-id="fc58c6b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>If you’re running a website there are good reasons to use alternatives to Google Analytics. One, you’re respecting your visitor’s privacy and there are more friendly alternatives.</p><p>Websites who run Google Adsense campaigns are the ones who usually use Google Analytics because it would be much more difficult to track your results without it.</p><p>Here are a few Analytics alternatives:</p><ol><li><a href="https://plausible.io/" target="_blank" rel="nofollow noopener">Plausible</a> – A simple and privacy-friendly alternative to Google Analytics. It’s also lightweight, open-source, and has no cookies.</li><li><a href="https://matomo.org/" target="_blank" rel="noopener">Matomo</a> – It was formerly Piwik, and is an open-sourced platform that understands the privacy of the users. It also allows website admins to import historic Google Analytics data to Matomo.</li><li><a href="https://usefathom.com/" target="_blank" rel="noopener">Fathom Analytics</a> – Is an open-sourced website analytics platform that is efficient and fast. (<a href="https://github.com/usefathom/fathom" target="_blank" rel="noopener">GitHub</a>)</li><li><a href="https://clicky.com/" target="_blank" rel="noopener">Clicky</a> – Is a good alternative to Google Analytics because it keeps the user’s privacy by making their IP anonymous. It’s also efficient and user-friendly. It is also certified by <a href="https://www.privacyshield.gov/welcome" target="_blank" rel="noopener">Privacy Shield</a>!</li><li><a href="https://www.atinternet.com/en/" target="_blank" rel="noopener">AT Internet</a> – Is a French company that was created in 1996. It’s good for performance measurement or sites, and applications.</li><li><a href="https://www.foxmetrics.com/" target="_blank" rel="noopener">FoxMetrics</a> – Is a platform that allows you to understand and analyze your customer’s actions from your desktop and mobile device.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9f07b94" data-element_type="section"><div><div><div data-id="5b063df" data-element_type="column"><div><div><div data-id="dafc60c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Translate Alternatives</h2></p></div><div data-id="eb7e8e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" alt="Google Translate Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Translate Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="bae68a8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google has many privacy issues and Google Translate is no exception. Google …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justprivacy.org/google-alternatives/">https://justprivacy.org/google-alternatives/</a></em></p>]]>
            </description>
            <link>https://justprivacy.org/google-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380999</guid>
            <pubDate>Fri, 11 Dec 2020 00:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kubernetes Pod Gets an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380898">thread link</a>) | @freedomben
<br/>
December 10, 2020 | https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the core requirements of the
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model" target="_blank" rel="noopener">Kubernetes networking model</a> is that every pod should get its own IP address and that every pod in the cluster should be able to talk to it using this IP address. There are several network providers (flannel, calico, canal, etc.) that implement this networking model.</p><p>As I started working on Kubernetes, it wasn’t completely clear to me how every pod is assigned an IP address. I understood how various components worked independently, however, it wasn’t clear how these components fit together. For instance, I understood what CNI plugins were, however, I didn’t know how they were invoked. So, I wanted to write this post to share what I have learned about various networking components and how they are stitched together in a kubernetes cluster for every pod to receive an IP address.</p><p>There are various ways of setting up networking in kubernetes and various options for a container runtime. For this post, I will use
<a href="https://github.com/coreos/flannel" target="_blank" rel="noopener">Flannel</a> as the network provider and
<a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">Containerd</a> as the container runtime. Also, I am going to assume that you know how container networking works and only share a very brief overview below for context.</p><h2 id="some-background-concepts">Some Background Concepts</h2><h3 id="container-networking-a-very-brief-overview">Container Networking: A Very Brief Overview</h3><p>There are some really good posts explaining how container networking works. For context, I will go over a very high level overview here with a single approach that involves linux bridge networking and packet encapsulation. I am skipping details here as container networking deserves a blog post of itself. Some of the posts that I have found to be very educational in this space are
<a href="#container-networking">linked in the references below</a>.</p><h4 id="containers-on-the-same-host">Containers on the same host</h4><p>One of the ways containers running on the same host can talk to each other via their IP addresses is through a linux bridge. In the kubernetes (and docker) world, a
<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth (virtual ethernet)</a> device is created to achieve this. One end of this veth device is inserted into the container network namespace and the other end is connected to a
<a href="https://wiki.archlinux.org/index.php/Network_bridge" target="_blank" rel="noopener">linux bridge</a> on the host network. All containers on the same host have one end of this veth pair connected to the linux bridge and they can talk to each other using their IP addresses via the bridge. The linux bridge is also assigned an IP address and it acts as a gateway for egress traffic from pods destined to different nodes.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/bridge-networking.png" alt="bridge networking"></p><h4 id="containers-on-different-hosts">Containers on different hosts</h4><p>One of the ways containers running on different hosts can talk to each other via their IP addresses is by using packet encapsulation. Flannel supports this through
<a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">vxlan</a> which wraps the original packet inside a UDP packet and sends it to the destination.</p><p>In a kubernetes cluster, flannel creates a vxlan device and some route table entries on each of the nodes. Every packet that’s destined for a container on a different host goes through the vxlan device and is encapsulated in a UDP packet. On the destination, the encapsulated packet is retrieved and the packet is routed through to the destined pod.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/flannel-networking.png" alt="flannel networking"></p><p><em>NOTE: This is just one of the ways how networking between containers can be configured.</em></p><h3 id="what-is-cri">What Is CRI?</h3><p><a href="https://github.com/kubernetes/cri-api" target="_blank" rel="noopener">CRI (Container Runtime Interface)</a> is a plugin interface that allows kubelet to use different container runtimes. Various container runtimes implement the CRI API and this allows users to use the container runtime of their choice in their kubernetes installation.</p><h3 id="what-is-cni">What is CNI?</h3><p><a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI project</a> includes a
<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">spec</a> to provide a generic plugin-based networking solution for linux containers. It also consists of various
<a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">plugins</a> which perform different functions in configuring the pod network. A CNI plugin is an executable that follows the CNI spec and we’ll discuss some plugins in the post below.</p><h2 id="assigning-subnets-to-nodes-for-pod-ip-addresses">Assigning Subnets To Nodes For Pod IP Addresses</h2><p>If all pods are required to have an IP address, it’s important to ensure that all pods across the entire cluster have a unique IP address. This is achieved by assigning each node a unique subnet from which pods are assigned IP addresses on that node.</p><h3 id="node-ipam-controller">Node IPAM Controller</h3><p>When <code>nodeipam</code> is passed as an option to the
<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager’s</a> <code>--controllers</code> command line flag, it allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network). Since these podCIDRs are disjoint subnets, it allows assigning each pod a unique IP address.</p><p>A kubernetes node is assigned a podCIDR when the node first registers with the cluster. To change the podCIDR allocated to nodes in a cluster, nodes need to be de-registered and then re-registered with any configuration changes first applied to the kubernetes control plane. <code>podCIDR</code> for a node can be listed using the following command.</p><pre><code>$ kubectl get no &lt;nodeName&gt; -o json | jq '.spec.podCIDR'
10.244.0.0/24
</code></pre><h2 id="kubelet-container-runtime-and-cni-plugins---how-its-all-stitched-together">Kubelet, Container Runtime and CNI Plugins - how it’s all stitched together</h2><p>When a pod is scheduled on a node, a lot of things happen to start up a pod. In this section, I’ll only focus on the interactions that relate to configuring network for the pod.</p><p>Once a pod is scheduled on the node, the following interactions result in configuring the network and starting the application container.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-flowchart.png" alt="kubelet-cri-cni-flowchart"></p><p>Ref:
<a href="https://github.com/containerd/cri/blob/v1.11.1/docs/architecture.md" target="_blank" rel="noopener">Containerd cri plugin architecture</a></p><h2 id="interactions-between-container-runtime-and-cni-plugins">Interactions between Container Runtime and CNI Plugins</h2><p>Every network provider has a CNI plugin which is invoked by the container runtime to configure network for a pod as it’s started. With containerd as the container runtime,
<a href="https://github.com/containerd/cri" target="_blank" rel="noopener">Containerd CRI plugin</a> invokes the CNI plugin. Every network provider also has an agent that’s installed on each of the kubernetes node to configure pod networking. When the network provider agent is installed, it either ships with the CNI config or it creates one on the node which is then used by the CRI plugin to figure out which CNI plugin to call.</p><p>The location for the CNI config file is configurable and the default value is <code>/etc/cni/net.d/&lt;config-file&gt;</code>. CNI plugins need to be shipped on every node by the cluster administrators. The location for CNI plugins is configurable as well and the default value is <code>/opt/cni/bin</code>.</p><p>In case of containerd as the container runtime, path for CNI configuration and CNI plugin binaries can be specified under <code>[plugins."io.containerd.grpc.v1.cri".cni]</code> section of the
<a href="https://github.com/containerd/cri/blob/master/docs/config.md" target="_blank" rel="noopener">containerd config</a>.</p><p>Since we are referring to Flannel as the network provider here, I’ll talk a little about how Flannel is set up. Flanneld is the Flannel daemon and is typically installed on a kubernetes cluster as a daemonset with <code>install-cni</code> as an
<a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml#L172" target="_blank" rel="noopener">init container</a>. The <code>install-cni</code> container creates the
<a href="https://gist.github.com/ronaknnathani/957a56210bd4fbd8e11120273c6b4ede" target="_blank" rel="noopener">CNI configuration file</a> - <code>/etc/cni/net.d/10-flannel.conflist</code> - on each node. Flanneld creates a vxlan device, fetches networking metadata from the apiserver and watches for updates on pods. As pods are created, it distributes routes for all pods across the entire cluster and these routes allow pods to connect to each other via their IP addresses. For details on how flannel works, I recommend the
<a href="#how-flannel-works">linked references below</a>.</p><p>The interactions between Containerd CRI Plugin and CNI plugins can be visualized as follows:
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-interactions.png" alt="kubelet-cri-cni-interactions"></p><p>As described above, kubelet calls the Containerd CRI plugin in order to create a pod and Containerd CRI plugin calls the CNI plugin to configure network for the pod. The network provider CNI plugin calls other base CNI plugins to configure the network. The interactions between CNI plugins are described below.</p><h3 id="interactions-between-cni-plugins">Interactions Between CNI Plugins</h3><p>There are various CNI plugins that help configure networking between containers on a host. For this post, we will refer to 3 plugins.</p><h4 id="flannel-cni-plugin">Flannel CNI Plugin</h4><p>When using Flannel as the network provider, the Containerd CRI plugin invokes the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">Flannel CNI plugin</a> using the CNI configuration file - <code>/etc/cni/net.d/10-flannel.conflist</code>.</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cni0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
		 "ipMasq": false,
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    }
  ]
}
</code></pre><p>The Fannel CNI plugin works in conjunction with Flanneld. When Flanneld starts up, it fetches the podCIDR and other network related details from the apiserver and stores them in a file - <code>/run/flannel/subnet.env</code>.</p><pre><code>FLANNEL_NETWORK=10.244.0.0/16 
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450 
FLANNEL_IPMASQ=false
</code></pre><p>The Flannel CNI plugin uses the information in <code>/run/flannel/subnet.env</code> to configure and invoke the bridge CNI plugin.</p><h4 id="bridge-cni-plugin">Bridge CNI Plugin</h4><p>Flannel CNI plugin calls the Bridge CNI plugin with the following configuration:</p><pre><code>{
  "name": "cni0",
  "type": "bridge",
  "mtu": 1450,
  "ipMasq": false,
  "isGateway": true,
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24"
  }
}
</code></pre><p>When
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge" target="_blank" rel="noopener">Bridge CNI plugin</a> is invoked for the first time, it creates a linux bridge with the <code>"name": "cni0"</code> specified in the config file. For every pod, it then creates a veth pair - one end of the pair is in the container’s network namespace and the other end is connected to the linux bridge on the host network. With Bridge CNI plugin, all containers on a host are connected to the linux bridge on the host network.</p><p>After configuring the veth pair, Bridge plugin invokes the host-local IPAM CNI plugin. Which IPAM plugin to use can be configured in the CNI config CRI plugin uses to call the flannel CNI plugin.</p><h4 id="host-local-ipam-cni-plugins">Host-local IPAM CNI plugins</h4><p>The Bridge CNI plugin calls the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local" target="_blank" rel="noopener">host-local IPAM CNI plugin</a> with the following configuration:</p><pre><code>{
  "name": "cni0",
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24",
    "dataDir": "/var/lib/cni/networks"
  }
}
</code></pre><p>Host-local IPAM (IP Address Management) plugin returns an IP address for the container from the <code>subnet</code> and stores the allocated IP locally on the host under the directory specified under <code>dataDir</code> - <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code>. <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code> file contains the container ID to which the IP is assigned.</p><p>When invoked, the host-local IPAM plugin returns the following payload</p><pre><code>{
  "ip4": {
    "ip": "10.244.4.2",
    "gateway": "10.244.4.3"
  },
  "dns": {}
}
</code></pre><h2 id="summary">Summary</h2><p>Kube-controller-manager assigns a podCIDR to each node. Pods on a node are …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380898</guid>
            <pubDate>Fri, 11 Dec 2020 00:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplify, batch, and cache: how Shopify optimized storefront response times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380697">thread link</a>) | @vaillancourtmax
<br/>
December 10, 2020 | https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering | <a href="https://web.archive.org/web/*/https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><em><strong>On December 16, 2020 Shipit! presents: Performance Tips from the Storefront Renderer Team.&nbsp;Celso and Maxime will share how the&nbsp;team optimized this Ruby application for the particular use case of serving storefront traffic. <a href="#Register">Please Register!</a></strong></em></p>
<p><strong>By Celso Dantas and Maxime Vaillancourt</strong></p>
<p>In the previous post about <a href="https://shopify.engineering/how-shopify-reduced-storefront-response-times-rewrite" target="_blank" title="How Shopify Reduced Storefront Response Times with a Rewrite" rel="nofollow noopener noreferrer">our new storefront rendering engine</a>, we described how we went about the rewrite process and smoothly transitioned to serve storefront requests with the new implementation. As a follow-up and based on readers’ comments and questions, this post dives deeper into the technical details of how we built the new storefront rendering engine to be faster than the previous implementation.</p>
<p>To set the table, let’s see how the new storefront rendering engine performs:</p>
<ul>
<li>It generates a response in less than ~45ms for 75% of storefront requests;</li>
<li>It generates a response in less than ~230ms for 90% of storefront requests;</li>
<li>It generates a response in less than ~900ms for 99% of storefront requests.</li>
</ul>
<p>Thanks to the new storefront rendering engine, the average storefront response is nearly 5x faster than with the previous implementation. Of course, how fast the rendering engine is able to process a request and spit out a response depends on two key factors: the shop’s Liquid theme implementation, and the number of resources needed to process the request. To get a better idea of where the storefront rendering engine spends its time when processing a request, try using the <a href="https://shopify.engineering/in-depth-liquid-render-analysis-shopify-theme-inspector-chrome-extension" target="_blank" title="How to Do an In-depth Liquid Render Analysis with Theme Inspector" rel="nofollow noopener noreferrer">Shopify Theme Inspector</a>: this tool will help you identify potential bottlenecks so you can work on improving performance in those areas.</p>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250">
<figcaption>A simplified data schema of the application</figcaption>
</figure>
<p>Before we cover each topic, let’s briefly describe our application stack. As mentioned in the previous post, the new storefront rendering engine is a Ruby application. It talks to a sharded MySQL database and uses Redis to store and retrieve cached data.</p>
<p>Optimizing how we load all that data is extremely important. As one of our requirements was to improve rendering time for Storefront requests. Here are some of the approaches that we took to accomplish that.</p>

<p>To reduce the number of network round trips to the database, we use <a href="https://dev.mysql.com/doc/internals/en/multi-statement.html" target="_blank" title="MySQL - 14.8.2 Multi-Statement" rel="nofollow noopener noreferrer">MySQL’s multi-statement feature</a> to allow sending multiple queries at once. With a single request to the database, we can load data from multiple tables at once. Here’s a simplified example:</p>
<figure>

</figure>
<p>This request is especially useful to batch-load a lot of data very early in the response lifecycle based on the incoming request. After identifying the type of request, we trigger a single multi-statement query to fetch the data we need for that particular request in one go, which we’ll discuss later in this blog post. For example, for a request for a product page, we’ll load data for the product, its variants, its images, and other product-related resources in addition to information about the shop and the storefront theme, all in a single round-trip to MySQL.</p>

<p>As shown above, the new storefront rendering engine uses handcrafted, optimized SQL queries. This allows us to easily write fine-tuned SQL queries to select only the columns we need for each resource and leverage JOINs and sub-SELECT statements to optimize data loading based on the resources to load which are sometimes less straightforward to implement with a full-service object-relational mapping (ORM) layer.</p>
<p>However, the main benefit of this approach is the tiny memory footprint of using a raw MySQL client compared to using an object-relational mapping (ORM) layer that’s unnecessarily complex for our needs. Since there’s no unnecessary abstraction, forgoing the use of an ORM drastically simplifies the flow of data. Once the raw rows come back from MySQL, we effectively use the simplest ORM possible: we create plain old Ruby objects from the raw rows to model the business domain. We then use these Ruby objects for the remainder of the request. Below is an example of how it’s done.</p>
<figure>

</figure>
<p>Of course, not using an ORM layer comes with a cost: if implemented poorly, this approach can lead to more complexity leaking into the application code. Creating thin model abstractions using plain old Ruby objects prevents this from happening, and makes it easier to interact with resources while meeting our performance criteria. Of course, this approach isn’t particularly common and has the potential to cause panic in software engineers who aren’t heavily involved in performance work, instead worrying about schema migrations and compatibility issues. However, when speed is critical, we accept to take on that complexity.</p>

<p>An HTTP request for a Shopify storefront may end up requiring many different resources from data stores to render properly. For example, a request for a product page could lead to requiring information about other products, images, variants, inventory information, and a whole lot of other data not loaded on multi-statement select. The first time the storefront rendering engine loads this page, it needs to query the database, sometimes making multiple requests, to retrieve all the information it needs. This usually happens during the request at any given time.</p>
<figure><img alt="A flow diagram showing the Storefront Renderer's requests from  the data stores and how it uses a Query Book Keeper Middlewear to eager-load data" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269" src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269">
<figcaption>Flow of a request with the Book-keeping solution</figcaption>
</figure>
<p>As it retrieves this data for the first time, the storefront rendering engine keeps track of the queries it performed on the database for that particular product page and stores that list of queries in a key-value store for later use. When an HTTP request for the same product page comes in later (which it knows when the cache key matches), the rendering engine looks up the list of queries it performed throughout the previous request of the same type and performs those queries all at once, at the very beginning of the current request, because we’re pretty confident we’ll need them for this request (since they were used in the previous request).</p>
<p>This book-keeping mechanism lets us eager-load data we’re pretty confident we’ll need. Of course, when a page changes, this may lead to over-fetching and/or under-fetching, which is expected, and the shape of the data we fetch stabilizes quickly over time as more requests come in.</p>
<p>On the other side, some liquid models of Shopify’s storefronts are not accessed as frequently, and we don’t need to eager-load data related to them. If we did, we’d increase I/O wait time for something that we probably wouldn’t use very often. What the new rendering engine does instead is lazy-load this data by default. Unless the book-keeping mechanism described above eager-loads it, we’ll defer retrieving data to only load it if it’s needed for a particular request.</p>

<p>Much like a CPU’s caching architecture, the new rendering engine implements multiple layers of caching to accelerate responses.</p>
<p>A critical aside before we jump into this section: adding caching should never be the first step towards building performance-oriented software. Start by building a solution that’s extremely fast from the get go, even without caching. Once this is achieved, then consider adding caching to reduce load on the various components on the system while accelerating frequent use cases. Caching is like a sharp knife and can introduce hard to detect bugs.</p>
<h2>In-Memory Cache</h2>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. Within the Storefront Renderer is an In-memory cache. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398">
<figcaption>A simplified data schema of the application with an in-memory cache for the Storefront Renderer</figcaption>
</figure>
<p>At the frontline of our caching system is an in-memory cache that you can essentially think of as a global hash that’s shared across requests within each web worker. Much like the majority of our caching mechanisms, this caching layer uses the LRU caching algorithm. As a result, we use this caching layer for data that’s accessed very often. This layer is especially useful in high throughput scenarios such as flash sales.</p>
<h2>Node-local Shared Caching</h2>
<p>As a second layer on top of the in-memory cache, the new rendering engine leverages a node-local Redis store that’s shared across all server workers on the same node. Since the database is available on the same machine as the rendering engine process itself, this node-local data transfer prevents network overhead and improves response times. As a result, multiple Ruby processes benefit from sharing cached data with one another.</p>
<h2>Full-page Caching</h2>
<p>Once the rendering engine successfully renders a full storefront response for a particular type of request, we store the final output (most often an HTML or JSON string) into the local Redis for later retrieval for subsequent requests that match the same cache key. This full-page caching solution lets us prevent regenerating storefront responses if we can by using the output we previously computed.</p>
<h2>Database Query Results Caching</h2>
<p>In a scenario where the full-page output cache, the in-memory cache, and the node-local cache doesn’t have a valid entry for a given request, we need to reach all the way to the database. Once we get a result back from MySQL, we transparently cache the results in Redis for later retrieval based on the queries and their parameters. As long as the cache keys don’t change, running the same database queries over and over always hit Redis instead of reaching all the way to the database.</p>
<h2>Liquid Object Memoizer</h2>
<p>Thanks to the Liquid templating language, merchants and partners may build custom storefront themes. When loading a particular storefront page, it’s possible that the Liquid template to render includes multiple references to the same object. This is common on the product page for example, where the template will include many references to the product object: <br><code>{{ product.title }}</code>, <code>{{ product.description }}</code>, <code>{{ product.featured_media }}</code>, and others.</p>
<p>Of course, when each of these are executed, we don’t fetch the product over and over again from the database—we fetch it once, then keep it in memory for later use throughout the request lifecycle. This means that if the same product object is required multiple times at different locations during the render process, we’ll always use the same one and only instance of it throughout the entire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380697</guid>
            <pubDate>Fri, 11 Dec 2020 00:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Older patients 23% more likely to die if surgery occurs on surgeon's birthday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380320">thread link</a>) | @Bologo
<br/>
December 10, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main">
						<div>
							<div>
																																								<div>

								
<p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p>



<p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p>



<p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p>



<h2>Distractions during the most common emergency surgery types </h2>



<p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p>



<p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p>



<p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p>



<p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p>



<h2>A natural experiment: ER surgery on the doctor’s birthday</h2>



<p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p>



<p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. </p>



<p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p>



<h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2>



<p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p>



<p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p>



<p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p>



<h2><strong>Limitations</strong> <strong>and future directions</strong></h2>



<p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p>



<p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p>



<hr>



<p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a> <br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p>
<p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p>  
  
  
  

  
																</div><!-- .entry-content -->

								
								
																</div>

						</div>

					</article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380320</guid>
            <pubDate>Thu, 10 Dec 2020 23:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Mutual TLS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25380003">thread link</a>) | @dogecoinbase
<br/>
December 10, 2020 | https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f | <a href="https://web.archive.org/web/*/https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380003</guid>
            <pubDate>Thu, 10 Dec 2020 23:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeBSD Remote Process Plugin: Final Milestone Achieved]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379737">thread link</a>) | @fcambus
<br/>
December 10, 2020 | https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Moritz Systems have been <a href="https://www.moritz.systems/blog/lldb-debugger-improvements-for-freebsd/">contracted</a>
by the <a href="https://freebsdfoundation.org/">FreeBSD Foundation</a> to modernize the
<a href="https://lldb.llvm.org/">LLDB</a> debugger’s support for
<a href="https://www.freebsd.org/">FreeBSD</a>.  We are working on a new plugin
utilizing the more modern client-server layout that is already used
by Darwin, Linux, NetBSD and (unofficially) OpenBSD.  The new plugin is
going to gradually replace the legacy one.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/LLVM_Logo.svg" alt="LLVM">
</p><center><small><small>This dragon image is owned by Apple Inc.</small></small></center>

<p>The Project Schedule was divided into three milestones, each taking
approximately one month:</p>

<ul>
<li>M1 Introduce new FreeBSD Remote Process Plugin for x86_64 with
basic support and upstream to LLVM.</li>
<li>M2 Ensure and add the mandated features in the project (process
launch, process attach (pid), process attach (name), userland
core files, breakpoints, watchpoints, threads, remote debugging)
for FreeBSD/amd64 and FreeBSD/i386.</li>
<li>M3 Iterate over the LLDB tests. Detect and as time permits fix bugs.
Ensure bug reports for each non-fixed and known problem. Add missing
man pages and update the FreeBSD Handbook.</li>
</ul>

<p>In the <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-is-now-the-default-in-lldb/">previous report</a>
we have announced the completion of the second project’s milestone,
that is achieving the feature parity with the legacy plugin and enabling
the new plugin by default on 32 and 64-bit x86.  We have explained how different
platforms express process and thread identifiers and how <code>SIGTRAP</code> is used
to deliver event notifications to the debugger.  We have also described
the two alternative approaches on hooking the debugger up to the process -
either via launching it, or attaching to a running process.</p>

<p>The third milestone was focused on fixing bugs, updating the test suite
state and documentation.  We are proud to announce that this stage
is finished as well, and therefore <strong>the whole contract is accomplished
timely and successfully</strong>.
In this article, we would like to shortly summarize our work
and describe some of the more interesting areas of focus in detail.</p>

<h2 id="a-race-condition-while-copying-watchpoints-to-new-threads">A race condition while copying watchpoints to new threads</h2>

<p>The primary goal in the third milestone was to go through failing tests
and either fix them, or at least document the failures and mark
the respective tests as expected to fail.  The first really interesting
problem we’ve found while investigating the
<a href="https://github.com/llvm/llvm-project/blob/7e2ef84fe7232368f92ec0835c3eda869c85a445/lldb/test/API/commands/watchpoints/multiple_threads/main.cpp">commands/watchpoints/multiple_threads</a>
test.
The purpose of the test is to verify that watchpoints work when
the respective variables are altered by a non-main thread.</p>

<p>Originally, the test was done in two variants: with the watchpoint being
set before starting the new thread, and after starting it.  The first
variant was supposed to verify whether LLDB correctly copies existing
watchpoints to new threads as they are being started.  The second
variant verified whether the <code>watchpoint</code> command correctly adds
the new watchpoint to all running threads.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/debug_regs_copying.svg" alt="Debug Registers in threading application"></p>

<p>What’s important here is that hardware-assisted watchpoints on x86
are configured via altering the state of Debug Registers.  Like other
register sets, the values of DRs are thread-local, and therefore
the debugger needs to set them separately for every thread.
Furthermore, new threads inherit the DR state from parent threads
on FreeBSD, and our original watchpoint code relied on new threads
having the correct DR at start.</p>

<p>However, there is a catch.  The new thread is not reported to
the debugger until it is actually ready to start.  During this time,
the DRs are copied from the parent thread and it continues execution.
In fact, it is entirely feasible that the process is stopped due
to breakpoint in the parent thread before the new thread is actually
reported ready.  This creates an ample opportunity for the user to set
a new watchpoint, and this is precisely what happened to us during
the test.</p>

<p>At this point, the debugger is not yet aware that another thread
is being created.  However, the kernel has already copied the Debug
Register values from the parent thread.  As a result, the new thread
is created with the old DR values, while the debugger assumed that it
had the new values instead.</p>

<p>We have <a href="https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=250954">reported this confusing behavior</a>
to the FreeBSD Bugzilla.  For the time being, we’ve changed the plugin
to explicitly copy DRs when a new thread is reported, therefore
guaranteeing that any changes during the problematic period are
propagated.  We have also extended the original test to cover three
scenarios: watchpoint set before requesting the new thread, watchpoint
set immediately after requesting it (i.e. falling into our race
condition) and watchpoint set after waiting for the new thread
to actually start running (i.e. covering the original intent).</p>

<h2 id="simplifying-the-register-reading-and-writing-logic">Simplifying the register reading and writing logic</h2>

<p>The original register reading and writing logic in the new plugin
has been inspired by the code present in the NetBSD plugin.  It roughly
consisted of <a href="https://github.com/llvm/llvm-project/commit/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2#diff-fe8211dffcb3e79e018065063ac970a718e5905c699517348d80c61859fcd989L538">a large switch-case construct</a>
that mapped enumeration values into appropriate operations on system
structures.  There were three large switches in total: one for reading
register values, one for writing register values and one for mapping
enumeration values from i386 to amd64 platform.  Furthermore, the first
two needed large separate variants for i386 and amd64.</p>

<p>At the same time, LLDB already carried another set of register
information that was created via macros by inspecting struct field
offsets and sizes.  Unlike the plugin logic, it did not use system
structures but instead <a href="https://github.com/llvm/llvm-project/blob/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2/lldb/source/Plugins/Process/Utility/RegisterContextFreeBSD_x86_64.cpp#L17">inlined them</a>.
This is because the same structures are used to access core dumps,
and avoiding system headers makes it possible to compile the code
and inspect FreeBSD core dumps on other systems.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/register_mode.svg" alt="LLDB Registers"></p>

<p>Unlike NetBSD, the Linux plugin actually reused the offsets and sizes
from this data to access register sets.  We have decided to follow suit,
and replace the aforementioned custom logic with accesses based
on offset and size values, and this allowed us to reduce code
duplication significantly.  We have also added platform-specific <a href="https://github.com/llvm/llvm-project/blob/6adb55877c4bae6c75ab0d2c0374fab6787bff2d/lldb/unittests/Process/Utility/RegisterContextFreeBSDTest.cpp">tests
that verify that the offsets and sizes are correct, compared to system
structures</a>.</p>

<p>What’s even more important is that this change improved maintainability
a lot.  We have had hit cryptic bugs that turned out to be caused
by wrong integer type being used inside the switch-case.  Storing
the sizes inside a list makes it possible to easily verify their
correctness and avoid future bugs due to size mismatches.</p>

<h2 id="fixing-cases-of-the-legacy-plugin-being-wrongly-used">Fixing cases of the legacy plugin being wrongly used</h2>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/lldb_plugins.svg" alt="LLDB plugins"></p>

<p>The process plugins in LLDB are split into two kinds: client plugins
and server plugins.  Client plugins are used by the LLDB client, while
server plugins are used by <code>lldb-server</code> to implement the remote
protocol.  The legacy FreeBSD plugin is a client plugin - it is loaded
by LLDB and used to debug a program.  The modern FreeBSD plugin is
a server plugin - it is loaded by the LLDB server and used to implement
the GDB remote protocol.  Another plugin called <code>gdb-remote</code> provides
a glue between the client and server.  It is loaded by the client,
it spawns lldb-server and fulfills client’s requests by communicating
with the server.</p>

<p>Therefore, by switching between the legacy and remote FreeBSD plugins,
we are actually switching between using the legacy client plugin
and the <code>gdb-remote</code> plugin that spawns lldb-server with the remote
FreeBSD plugin.  Our original switching logic (based on the prior art
from the Windows plugin) consisted of two pieces: <a href="https://github.com/llvm/llvm-project/blob/2c2eb5e6702bf3bbb8fb8f09790b1ab7b139e879/lldb/source/Plugins/Platform/FreeBSD/PlatformFreeBSD.cpp#L250">a boolean switch in
PlatformFreeBSD</a>
and a code blocking the legacy plugin from being loaded when the new
plugin should be used.  However, we have established that the latter
is not really necessary, and we have removed the latter part as we
changed the preferred plugin.</p>

<p>During the final testing period, we’ve found and fixed two cases where
this was not correct: when choosing plugin for <code>process connect</code>,
and when attaching to a running process.</p>

<p>The <code>process connect</code> command is supposed to iterate through all
available process plugins, find one that initializes successfully
and use it to establish a connection to the server.  However, it lacked
any means of actually determining whether the plugin in consideration
supported remote connections at all.  This was acceptable for
non-transitional platforms that had only one candidate client plugin.
However, on FreeBSD it could randomly choose either the legacy plugin,
or the <code>gdb-remote</code> plugin.  To resolve this, we have added <a href="https://github.com/llvm/llvm-project/commit/18e4272a4fe4667a44f4d323140645a83ddfd864">explicit
filtering for remote connection support</a>,
using similar approach as for determining core file support.</p>

<p>The plugin used for launching and attaching processes was supposed
to be controlled by the aforementioned boolean switch.  If the new
plugin was to be used, the method returned true and the launch/attach
implementation from
<a href="https://github.com/llvm/llvm-project/blob/1a1cc0ba7db549025ab1a504633ae4554042fd60/lldb/source/Plugins/Platform/POSIX/PlatformPOSIX.cpp#L359">PlatformPOSIX</a>
was being used.  Otherwise, it returned false and the legacy plugin
kicked in.</p>

<p>The <code>PlatformPOSIX::DebugProcess()</code> method used to launch programs
explicitly forced the <code>gdb-remote</code> plugin.  However,
the <code>PlatformPOSIX::Attach()</code> method did not specify the plugin name
and could therefore use either.  To fix this, we’ve updated it to force
<code>gdb-remote</code> consistently within the class.</p>

<h2 id="the-interaction-between-dynamic-loader-and-the-debugger">The interaction between dynamic loader and the debugger</h2>

<p>The dynamic loader is the system component responsible for loading
shared libraries that are used by the program.  This includes both
loading the linked libraries as specified by <code>DT_NEEDED</code> ELF header,
and loading additional modules at runtime via <code>dlopen(3)</code>.</p>

<p>The dynamic linker provides a <code>r_debug</code> structure that can be used
by the debugger to inspect its state, as well as monitor events - that
is, loading and unloading shared libraries.  The <code>r_debug</code> structure
is consistent across most of the Unix systems (with Solaris being
an exception).  On FreeBSD, it is declared in <code>&lt;sys/link_elf.h&gt;</code> as:</p>

<div><pre><code data-lang="c"><span>struct</span> r_debug {
        <span>int</span>             r_version;      <span>/* Currently '1' */</span>
        <span>struct</span> link_map <span>*</span>r_map;         <span>/* list of loaded images */</span>
        <span>void</span>            (<span>*</span>r_brk)(<span>struct</span> r_debug <span>*</span>, <span>struct</span> link_map <span>*</span>);
                                        <span>/* pointer to break point */</span>
        <span>enum</span> {
                RT_CONSISTENT,          <span>/* things are …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379737</guid>
            <pubDate>Thu, 10 Dec 2020 22:37:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast Feedback Pyramid]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379658">thread link</a>) | @atomkirk
<br/>
December 10, 2020 | https://atomkirk.com/2020-07-27-fast-feedback-pyramid/ | <a href="https://web.archive.org/web/*/https://atomkirk.com/2020-07-27-fast-feedback-pyramid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 27, 2020</p></header><section><p>I wrote before about the importance of <a href="https://atomkirk.com/2020-07-01-fast-feedback-loops/">fast feedback loops</a> and
the <a href="http://localhost:8000/2020-07-16-the-5-categories-of-bugs/">5 categories of bugs</a> and today I thought about how
this could be represented as a pyramid, much like the <a href="https://martinfowler.com/articles/practical-test-pyramid.html#:~:text=The%20%22Test%20Pyramid%22%20is%20a,put%20it%20into%20practice%20properly.">Test Pyramid</a>.</p>
<p><span>
      <a href="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Fast feedback pyramid" title="Fast feedback pyramid" src="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png" srcset="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/12f09/pyramid.png 148w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e4a3f/pyramid.png 295w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png 590w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/efc66/pyramid.png 885w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/c83ae/pyramid.png 1180w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png 1963w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Toward the bottom are the mistakes we make as programmers most frequently. They are also typically the fastest to catch
and correct.</p>
<p>Syntax errors happen as soon as you save the file and try to build. It’s even the very first thing a compiler
will do: parse your files. If it can’t parse it, you’ll get a syntax error.</p>
<p>Second, we type function/variable names wrong or we forget the shape of data in a variable and use it wrong. If you’ve
got a good test pyramid, your tests will run fast and often and hopefully catch these problems quickly. But it requires
that your tests are thorough and optimized. Let’s face it, this is hard and most test suites aren’t. That’s why a
lot of teams
are turning to type safety, because you can collapse the second level into the first so that both syntax and
reference/type errors are caught immediately when you try to compile/build.</p>
<p>Type safety also allows powerful tooling that can tighten feedback loops further by offering relevant suggestions, information
on hover &amp; descriptive inline errors.</p>
<p>And, once again, with languages with value type errors and exhaustive results handling (i.e. Elm, Rust, etc.), you can
even make the third layer of this pyramid provide immediate feedback at build time, further tightening your feedback
loop.</p></section><hr></article></div>]]>
            </description>
            <link>https://atomkirk.com/2020-07-27-fast-feedback-pyramid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379658</guid>
            <pubDate>Thu, 10 Dec 2020 22:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reddit is down (10th Dec 2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379256">thread link</a>) | @mystcb
<br/>
December 10, 2020 | https://www.redditstatus.com/incidents/qr5vky5kwn3r | <a href="https://web.archive.org/web/*/https://www.redditstatus.com/incidents/qr5vky5kwn3r">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    

    <div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <p>
            Resolved
          </p>
          <div>
            <p>
              This incident has been resolved.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642418000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:20</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to monitor for any further issues.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642044000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:14</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Monitoring
          </p>
          <div>
            <p>
              A fix has been implemented and we are monitoring the results.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642008000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to work on a fix for this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642004000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              Systems are slowly recovering, but we are still seeing elevated error rates and degradation in our mobile clients.
            </p>
            <p>
              Posted <span data-datetime-unix="1607640732000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:52</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Identified
          </p>
          <div>
            <p>
              reddit.com is currently down. A fix has been identified and is in the process of being applied.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637872000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:04</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Investigating
          </p>
          <div>
            <p>
              We are currently investigating this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637171000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">13:52</var> PST
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: reddit.com (Desktop Web, Mobile Web, Native Mobile Apps).
        </p>
    </div>

    
  </div>

  
</div></div>]]>
            </description>
            <link>https://www.redditstatus.com/incidents/qr5vky5kwn3r</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379256</guid>
            <pubDate>Thu, 10 Dec 2020 21:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepMind’s AlphaFold 2–An Impressive Advance with Hyperbolic Coverage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25379061">thread link</a>) | @andreyk
<br/>
December 10, 2020 | https://www.skynettoday.com/briefs/alphafold2 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/alphafold2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>DeepMind’s AlphaFold 2, a deep-learning model that predicts protein structures, achieved significant improvements over other methods in the biannual CAPS protein folding prediction competition.</li>
  <li>The improvements are so large that some claim protein folding is a solved problem. However, while almost all applaud the impressive advancement, many note the caveats and limitations of AlphaFold 2 in both the problem of protein folding and downstream uses in biology.</li>
  <li>After weighing the opinions of many experts, we take the view that while AlphaFold 2 should be celebrated, it is still just one step (though a big one!), and will not significantly advance practical applications like drug discovery.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>On the last day of November 2020, Critical Assessment of Structure Prediction (CASP), a biennial challenge for computational biologists on the problem of “protein folding”, released its results, showing DeepMind’s AI-driven <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">Alphafold 2</a> outperforming its competitors by a large margin. 
The pace of Alphafold’s improvement came as a shock to many researchers and mainstream media publications, <a href="https://www.bbc.com/news/science-environment-55133972">who heralded the development as a game-changer for biology</a>. 
Others acknowledged the uses of the tool, but <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">cautioned that there were many more challenges </a>in the protein-folding prediction space that may warrant a tempering of expectations, let alone the broader field of biology.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image1.png" alt="AlphaFold 2's CAPS results.">
  <figcaption>
    Left: AlphaFold 2’s impressive score on the CAPS protein folding competition. Right: Examples of predicted (blue) vs. actual (green) protein structures.
    Source: <a href="https://www.deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind</a>
  </figcaption>
</figure>

<p>In the world of proteins, form determines function. 
Thus, the ability to look forward and predict protein structures would help all kinds of biology subfields, from the more basic science work to drug discovery. 
Historically, attempts to model proteins have failed due to exponentially increasing computing costs, but <a href="https://dl.acm.org/doi/pdf/10.5555/3433701.3433707">specialized computational hardware</a> appears well-equipped to address this issue.</p>

<p>Alphafold made some waves with its 2018 CASP win, but the <a href="https://www.sciencemag.org/news/2018/12/google-s-deepmind-aces-protein-folding">media coverage was decidedly more muted then</a>. 
The pace of Alphafold’s 2020 improvement on top of its own success in 2018 was shocking for many experts, who felt that a solution to the <a href="https://scitechdaily.com/major-scientific-advance-deepmind-ai-alphafold-solves-50-year-old-grand-challenge-of-protein-structure-prediction/">50-year old protein-solving problem </a>was finally in sight. 
One important note is that AlphaFold 2, like other methods submitted to CASP, doesn’t actually model <em>how</em> proteins fold - it just predicts the final structure of the protein after it has folded.</p>

<p>There are a number of quality blog posts that explain protein folding and AlphaFold 2. <a href="https://twitter.com/jasoncrawford">Jason Crawford</a> at Roots of Progress gives an accessible review of protein folding in <a href="https://rootsofprogress.org/alphafold-protein-folding-explainer">What is the “protein folding problem”? A brief explanation.</a> It is also summarized in this excellent Twitter thread:</p>

<blockquote><div lang="en" dir="ltr"><p>Today Google <a href="https://twitter.com/DeepMind?ref_src=twsrc%5Etfw">@DeepMind</a> announced that their deep learning system AlphaFold has achieved unprecedented levels of accuracy on the “protein folding problem”, a grand challenge problem in computational biochemistry.</p><p>What is this problem, and why is it hard?<a href="https://t.co/OjbP3RBPEi">https://t.co/OjbP3RBPEi</a></p></div>— Jason Crawford (@jasoncrawford) <a href="https://twitter.com/jasoncrawford/status/1333576221418930176?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote>


<p>For a more technical explanation of AlphaFold 2 itself, we refer readers to the blog posts by <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">Mohammed AlQuraishi</a> and <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">Carlos Outeiral</a>. In summary, DeepMind trained a neural network model on 170k known protein structures in the publicly available <a href="https://www.rcsb.org/">Protein Data Bank dataset (PDB)</a>. In addition to its many novel architecture designs, one important aspect of this neural network seems to be its use of attention mechanisms, a similar kind of architecture used by recent state-of-the-art language models like GPT-3.</p>

<blockquote><p lang="en" dir="ltr">An attention-based technique was used, which has shown promise across ML in language/vision/etc. This allows for efficient learning (ie capturing relations between elements) and uncovering broader principles: <a href="https://t.co/hKTcb5mTkr">https://t.co/hKTcb5mTkr</a></p>— Ali Madani (@thisismadani) <a href="https://twitter.com/thisismadani/status/1333481997210161160?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<blockquote><div lang="en" dir="ltr"><p>Very exciting results this week from AlphaFold in CASP14. An incredible and inspiring achievement by the DeepMind team. Many new possibilities.</p><p>*Attention* mechanism is key to the result. Interestingly we find the exact same in our work on *unsupervised* learning for proteins.</p></div>— Alex Rives (@alexrives) <a href="https://twitter.com/alexrives/status/1334942570682716163?ref_src=twsrc%5Etfw">December 4, 2020</a></blockquote>


<h2 id="the-reactions">The Reactions</h2>

<h3 id="from-the-press">From the Press</h3>

<p>The press was very optimistic about AlphaFold 2’s progress in protein folding and its broader implications in biology and beyond, with headlines like:</p>

<ul>
  <li>Nature: <a href="https://www.nature.com/articles/d41586-020-03348-4">‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures</a></li>
  <li>Science: <a href="https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures">‘The game has changed.’ AI triumphs at solving protein structures</a></li>
  <li>MIT Tech Review: <a href="https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/">DeepMind’s protein-folding AI has solved a 50-year-old grand challenge of biology</a></li>
  <li>IEEE Spectrum: <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/medical-ai/alphafold-proves-that-ai-can-crack-fundamental-scientific-problems">AlphaFold Proves That AI Can Crack Fundamental Scientific Problems</a></li>
</ul>

<h3 id="from-the-experts">From the Experts</h3>

<p><a href="https://twitter.com/c_outeiral/status/1334779365280903169">Carlos Outeiral</a>, Computational Biology research scientist at Oxford, also highlighted the “astoundingly” impressive results of AlphaFold 2, in the post <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">CASP14: what Google DeepMind’s AlphaFold 2 really achieved, and what it means for protein folding, biology and bioinformatics</a>:</p>

<blockquote>
  <p>After three decades of competitions, the assessors declared that AlphaFold 2 had succeeded in solving a challenge open for 50 years: to develop a method that can accurately, generally and competitively predict a protein structure from its sequence (or, well, a multiple sequence alignment, as we will see later). There are caveats and edge cases, as in any application — but the magnitude of the breakthrough, as well as its potential impact, are undeniable.</p>
</blockquote>

<p>Comparing AlphaFold 2’s results to those of other methods: “AlphaFold 2’s accuracy is simply on a whole different level.”</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image2.png" alt="Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.">
  <figcaption>
  Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.
  Source: <a href="https://predictioncenter.org/casp14/zscores_final.cgi">CAPS</a>
  </figcaption>
</figure>

<p>Similarly, <a href="https://twitter.com/MoAlQuraishi">Mohammed AlQuraishi</a>, Professor of Systems Biology at Columbia, gave praise to DeepMind’s achievements:</p>

<blockquote><p lang="en" dir="ltr">CASP14 <a href="https://twitter.com/hashtag/s?src=hash&amp;ref_src=twsrc%5Etfw">#s</a> just came out and they’re astounding—DeepMind looks to have solved protein structure prediction. Median GDT_TS went from 68.5 (CASP13) to 92.4!!!! Cf. their 2nd best CASP13 struct scored 92.8 (out of 100). Median RMSD is 2.1Å. I think it's over <a href="https://t.co/dQ1BOJWuwn">https://t.co/dQ1BOJWuwn</a></p>— Mohammed AlQuraishi (@MoAlQuraishi) <a href="https://twitter.com/MoAlQuraishi/status/1333383634649313280?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<p>In his detailed blog post last year on the first iteration of AlphaFold, <a href="https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/#s2.2">AlphaFold @ CASP13: “What just happened?”</a>, Professor AlQuraishi discussed what DeepMind’s progress meant for academia and pharmaceutical companies:</p>

<ul>
  <li>This is “an indictment of academic science” - “There are dozens of academic groups, with researchers likely numbering in the (low) hundreds, working on protein structure prediction. […] For DeepMind’s group of ~10 researchers, with primarily (but certainly not exclusively) ML expertise, to so thoroughly route everyone surely demonstrates the structural inefficiency of academic science.”</li>
  <li>This is also “an indictment of pharma” - “What is worse than academic groups getting scooped by DeepMind? The fact that the collective powers of Novartis, Pfizer, etc, with their hundreds of thousands (~million?) of employees, let an industrial lab that is a complete outsider to the field, with virtually no prior molecular sciences experience, come in and thoroughly beat them on a problem that is, quite frankly, of far greater importance to pharmaceuticals than it is to Alphabet.”</li>
</ul>

<p>Responding to this year’s AlphaFold 2 is his new post <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">AlphaFold2 @ CASP14: “It feels like one’s child has left home.”</a>:</p>

<ul>
  <li>While AlphaFold 2 still has a lot of caveats, Professor AlQuraishi defends using “solved” to describe protein folding, at least in the scientific sense. He argues the remaining deficiencies of AlphaFold 2 are not scientific problems, but rather engineering ones. While engineering problems can still be exceedingly difficult, “competent domain experts know the pieces that need to fall into place to solve them.”</li>
  <li>As for AlphaFold 2’s potential applications to advance biology as a whole: “It won’t happen overnight. None of what I’m saying here will. It will take years and maybe decades, but now that protein structure prediction has become an engineering exercise, we know that many of these ideas can be realized.”</li>
</ul>

<p>Specifically for drug development:</p>
<blockquote>
  <p>I will end this section with the question that gets asked most often about protein structure prediction—will it change drug discovery? Truthfully, in the short term, the answer is most likely no. But it’s complicated. 
One important thing to note is that, of the entire drug development pipeline, the early discovery stage is just that, an early stage. Even if crystallography were to become fast and routine, it would still not fundamentally alter the dynamics of drug discovery as it is practiced today, as most of the cost is in the later stages of drug development beyond medicinal chemistry and well into biology and physiology. Reliable protein structure prediction doesn’t change that.</p>
</blockquote>

<p>However, not everyone saw the same magnitude of advancement in AlphaFold 2.
In the post <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">No, DeepMind has not solved protein folding</a>, <a href="https://twitter.com/Stephen_Curry">Stephen Curry</a>, Professor of Structural Biology at Imperial College London, cautioned against using the word “solved” to describe protein folding:</p>

<blockquote>
  <p>But we are not yet at the point where we can say that protein folding is ‘solved’. For one thing, only two-thirds of DeepMind’s solutions were comparable to the experimentally determined structure of the protein. This is impressive but you have to bear in mind that they didn’t know which two-thirds of their predictions were correct until the comparison with experimental solutions was made. Would you buy a satnav that was only 67% accurate?
So a dose of realism is required. It is also difficult to see right now, despite DeepMind’s impressive performance, that this will immediately transform biology.</p>
</blockquote>

<p>Despite AlphaFold 2’s average accuracy of 1.6 Å:</p>
<blockquote>
  <p>it’s still not nearly good enough for delivering reliable insights into protein chemistry or drug design. To do that, we want to be confident of atomic positions to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/briefs/alphafold2">https://www.skynettoday.com/briefs/alphafold2</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/alphafold2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379061</guid>
            <pubDate>Thu, 10 Dec 2020 21:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Making of “The Godfather” – Sort of a home movie (1971)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25378576">thread link</a>) | @dadt
<br/>
December 10, 2020 | http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/ | <a href="https://web.archive.org/web/*/http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>As was his custom before the drive home from work with his son, the old man walked across the narrow, tenement‐lined street in Manhattan’s Little Italy to buy some fresh fruit. The grocer, who had known him for many years, helped the old man sort out some prize oranges and, as a gift, handed him a perfectly ripened, home‐grown fig. The old man smiled, accepted the backyard offering with a slight nod and started toward his car. It was then that he spotted two gunmen.</p>
<p>He called out to his son and began to sprint toward the safety of his car with surprising speed for a man of his age, but the gunmen were too quick. As they opened fire, the old man seemed caught in a great leap, suspended momentarily in the air, his arms thrown protectively around his head. Loud shots hammered through the street, bright oranges rolled across the gray pavement and the old man crashed onto the fender of his car and collapsed. The people of Mott Street watched in silence from tenement windows, fire escapes and rooftops as the gunmen slipped away. Then, to spontaneous applause, the grim street tableau came to life, and the old man—the godfather, <a href="http://www.thestacksreader.com/brando/">Marlon Brando</a>—lifted himself slowly from the ground, smiled at the cheering crowd and bowed.</p>
<p>At 11 o’clock on April 12, just as Brando was getting shot on Mott Street, Carlo Gambino, one of New York’s real godfathers, sat around the corner in a Grand Street cafe, sipping black coffee from a glass and holding 18th‐century Sicilian court in 20th‐century New York. He had arrived moments earlier in the company of his brother, Paul, and five bodyguards. It was his custom, as well as his duty as head of a Mafia family, to hear at regular intervals the endless woes of racketeers, dishonored fathers and deportable husbands. They were ushered before him, one at a time, from a waiting area in a restaurant across the street. He was the final judge to people still willing to accept his decisions as law.</p>
<hr>
<p>Back on Mott Street, two Mafiosi assigned to observe the movie production were unaware of his arrival. For hours, they had been watching Brando getting shot. They had had innumerable cups of coffee and had adjusted their open‐throat, hand ironed shirts so often that their collars had begun to wilt. Neither of them had been impressed when they heard Brando was to play the godfather, so they watched his performance critically. They volunteered to grips, cameramen and extras that they would have preferred Ernest Borgnine or Anthony Quinn.</p>
<p>“A man of that stature,” one of them said, pointing to Brando, “would never wear a hat like that. They never pinched them in the front like that. Italian block, that’s the way they wore them, Italian block.”</p>
<p>They did not like Brando’s wearing his belt below his trouser loops, either.</p>
<p>“He makes the old man look like an iceman. That’s not right. A man like that had style. He should have a diamond belt buckle. They all had diamond belt buckles. And a diamond ring and tie clasp. Those old bosses loved diamonds. They all wore them. Brando makes the guy look like an iceman.”</p>
<p>In truth, Brando did not look like the traditional double‐breasted, wide lapeled, blue‐serge racketeer. He had accepted the advice of an Italian American friend, rather than the Mafiosi themselves, and made himself look old and bent. He wore a sack shaped suit of an undistinguished brown stripe and an outsize over coat. He wore a cardboard‐stiff white shirt with a collar at least two sizes too large and a striped tie so indifferently knotted that its back, label and all, faced front. The makeup man, who was never very far away, had fixed Brando with an elaborate mouth plate that made his jaw heavy and extended his jowls. Brando’s complexion was sallow, his eyes were made to droop on the side and with his graying temples and mustache many people on Mott Street that day did not recognize him until the filming began.</p>
<h5>There was an aura about the production that was unmistakable, just as there is an aura of real and imagined power around the honored society itself.</h5>
<p>The two Mafiosi did approve the vintage cars and were amused by the streetlamps, pushcarts and prices, circa 1940, tacked up in store windows. But they did not like the way the godfather’s assassins fired their guns.</p>
<p>“They hold pieces like flowers,” one said.</p>
<p>Shortly before noon a third man came up behind the pair and whispered:</p>
<p>“The old man’s around the corner.” The two men were stunned. “You kidding?” one asked. “Believe me, he’s around the corner.”</p>
<p>“Kee‐rist!”</p>
<p>“Shooo!”</p>
<p>Without further hesitation—and with the same pitch of excitement most neighborhood people saved for a peek at Brando—the trio left the movie set. They walked quickly toward the intersection and stopped. One of them darted his head around the corner of the building for a quick peek and shot back to his friends: “He’s there. He’s there. I see his car. I see Paul’s guy.”</p>
<hr>
<p>Mario Puzo’s best seller may have started out to be just another multimillion‐dollar movie for Paramount, but it wasn’t long before its producers realized that to the Mafiosi themselves the making of <em>The Godfather</em> was like the filming of a home movie. Before Puzo’s book, cops‐and‐robbers novels and films about organized crime left the mobsters cold. <em>The Godfather</em> was different. When it was published in 1969 word quickly spread across the country’s most regularly tapped telephone wires about this different book on the “honored society.” It was their <em>Forsyte Saga</em>. It was filled with bits of underworld gossip and its characters could be compared to live dons, singers, movie moguls and hit men. It depicted not only their lives, but the lives of their children, wives, enemies and friends. It emphasized their peculiar code of honor rather than their seedy, greedy little maneuverings. It dealt with their strong sense of family and their passionate loyalties. It romanticized and exaggerated their political power, wealth and influence in legitimate business. But most important, it humanized rather than condemned them.</p>
<p>The godfather himself, for instance, was shot because he refused to deal in the dirty business of narcotics. Sonny Corleone, his impetuous heir, was killed in an ambush because he tried to save his pregnant sister from a brutal husband. Michael Carleone, the godfather’s college educated war‐hero son, assumed his father’s Mafia mantle not out of greed, but from a sense of responsibility to his father, who, for all his illegal activities, was a far more honorable man than all the crooked cops, venal judges, corrupt politicians and perverted businessmen who peppered the plot.</p>
<p>Though certain Italian‐American politicians and organizations condemned Puzo for defaming all Italians, the author heard no such criticism from the society about which he had written. In fact, shortly after his book’s publication, Puzo found that some Mafiosi were anxious to meet him. They wanted to compare notes with the author of <em>The Godfather.</em> They, like other fans, refused to believe that the book was all fiction. In Las Vegas he found that a gambling debt he had run up was somehow marked paid. When Puzo protested he was told, “It’s a certain party’s pleasure.” On other occasions, bottles of champagne would arrive at his table unordered. Multisyllabic names were whispered in his ear by reverential headwaiters, and men with sunglasses and diamond rings waved at him across darkened restaurants.</p>
<hr>
<p>Six weeks before the Mott Street shooting of Brando, Albert Ruddy, the film’s producer, was uncertain whether he would be able to make the movie at all. Paramount had been deluged with letters describing the project as anti‐Italian and threatening demonstrations, boycotts and wildcat strikes by everyone from maintenance men to electricians. Letters had come from Congressmen in New York, New Jersey, Connecticut, Louisiana and Pennsylvania, as well as from dozens of New York State legislators, judges, civic leaders and businessmen.</p>
<p>One of them began: “A book like <em>The Godfather</em> leaves one with the sickening feeling that a great deal of effort and labor to eliminate a false image concerning Americans of Italian descent and also an ethnic connotation to organized crime has been wasted …. There are so many careers and biographies that could be made into constructive and intellient movies, such as the life of Enrico Fermi, the great scientist; Mother Cabrini; Colonel Ceslona, a hero of the Civil War; Garibaldi, the great Italian who unified Italy; William Paca, a signer of the Declaration of Independence; Guglielmo Marconi, and many, many others.”</p>
<p>The letter was signed by “the Grand Venerable of the Grand Council of the Grand Lodge of New York State’s Sons of Italy.” It also informed Paramount that the studio could expect an economic boycott of the film, petitions of protest from all Sons of Italy lodges, regional meetings to plan protests, a complaint filed with the State Human Rights Division and demands that no governmental authorities give the production any cooperation whatever.</p>
<p>And as if this were not enough, there were rumors of union walkouts, work stoppages and boycotts. Ruddy could envision costly delays. He had already run into trouble trying to negotiate with householders in Manhasset, L.I., for a site that looked like a godfather’s compound. The entire community and its bureaucrats had ganged up to sabotage his efforts.</p>
<p>“First, they’d complain that we would bring additional cars into the area and take up parking space,” Ruddy said. “So we’d promise to bus our people to the locations. Then they’d say they didn’t want buses in the area. Some said that if we did use their homes for the mall and the wedding the newspapers couldn’t know about it. How could we guarantee that? We were ready to pay, rent, replant, repaint, replace everything in the area for them. We were ready to make all kinds of concessions, but in the end I realized that they just didn’t want us. They never flat came out and said no, but it amounted to the same thing.</p>
<p>“For …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</a></em></p>]]>
            </description>
            <link>http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378576</guid>
            <pubDate>Thu, 10 Dec 2020 20:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inuttitut, a language shaped by humility, poetry, and the land]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25378558">thread link</a>) | @diaphanous
<br/>
December 10, 2020 | https://beside.media/new-narratives/nuna/ | <a href="https://web.archive.org/web/*/https://beside.media/new-narratives/nuna/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
                          <p>Text — Juliana Léveillé-Trudel<br>
Photos — Alexi Hobbs</p>
                                                


      

                  <div>
        <p>“She’s away on vacation for two weeks,” said Bobby, manager of the village of Quaqtaq.</p>
<p>He was talking about the head of the recreation department, who had all of the keys, most importantly the one for the Isummasarvik School’s storage room. We needed it to get the sports equipment to keep the kids occupied at day camp: balls, badminton racquets, nets, and hockey sticks.</p>
<p>I sighed inwardly. Ever since I’d been working in Nunavik, finding a key had been a recurring nightmare. I had already given up hope.</p>
<p>“Maybe you could ask the caretaker,” Bobby suggested.</p>
<p>Anne, my colleague, nodded and waved me on. We got back into the truck. On the other side of the windows, the June sun was beating down on the frozen bay that it could not crack. We stopped in front of a house near the footbridge spanning the river. The caretaker was out, but her husband exchanged a few words with Anne in Inuttitut, then disappeared and returned with the miraculous key. I pinched myself. It had taken all of five minutes.</p>
<p>That was back in 2015, my fifth summer in Nunavik. If it had happened a few years earlier, I would have probably told the story on my blog, joking about how even a simple task can be so immensely complicated in the North.</p>
<p>But as the old man held out the keys, it hit me: it was my fault that it was complicated. I had begun setting up day camps in the North in 2011. Everything that I had found difficult then was difficult because I was trying to make things work my way: planning activities and appointments in advance, holding daily meetings, requiring long-term commitment from the camp’s employees. There was another problem too: I didn’t know the people or the language well enough. I didn’t know who the caretaker was or where she lived. I wouldn’t have been able to speak with her husband, who spoke only in Inuttitut.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-02.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>I’d learned a few words, of course, especially words useful for working with children: <em>come here, sit down, do you understand, hurry up, are you ready, stop, wait, again, a little, a lot, yesterday, today, tomorrow, yes, no, maybe, what’s your name, and how old are you.</em> We’d played Twister once, so I also knew the names of body parts, colours, left and right. I knew the names of all the animals. It was a start, but not enough to converse with the caretaker’s husband.</p>
<p>Many of the <em>Qallunaat</em> (whites) I met among the Inuit described Inuttitut as “impossible to learn.” It did indeed seem complicated, with all those qs, ks, and js, but I loved its rough sonority. Moreover, I could never feel at ease with this linguistic one-sidedness. Some of my friends were taking online courses with Professor Marc-Antoine Mahieu at INALCO (Institut National des Langues et Civilisations Orientales), affiliated with the Sorbonne in Paris. They all spoke about the class with the same blissful smile. In 2016 I signed up too. I had just quit my job to devote myself to writing. It meant that I would no longer be travelling to Nunavik but that I had more time—and I very much wanted to learn Inuttitut and keep a foot in the North.</p>
<p>In our first class, Marc-Antoine made a point of destroying our hopes. Inuttitut is a highly unfamiliar language, not nearly as easily learned as English or Spanish. Acquiring competence would take years of study and practice, and despite all that effort, we would very likely never be able to really converse.</p>
<p>Strangely, this bleak prospect soon seemed irrelevant. Little by little, I discovered a spectacular language, immensely creative and full of humour. A language that had to invent all sorts of slightly eccentric ways of naming the elements of modern life, but that described the land and hunting techniques with staggering precision. A language that seemed made for poetry with its constructed words and love of repetition; a language that taught me so many things about people that I’d been among for years without ever really knowing.</p>

      </div>
      

            
    
      

            
        

      
    
      

                  <div>
        






<p>Don’t believe everything you’ve heard, however: there are not hundreds of words for snow.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-06.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>Over and over, I’d said what so many others have: that the Inuit have a very liberal concept of time. I learned that it could be as structured as my own; it was just structured around other things. For example, the months are defined by animal behaviours.</p>
<p>September, October, November: <em>amiraijaut, arnalirnguutivik, natjuijarvik.</em></p>
<p>Time when antlers lose their velvet. Time when the males compete for females. Time when caribou shed their antlers.</p>
<p>Places that I had known by their French or English names regained their original appellations: I now dared to utter the word <em>Kangiqsualujjuaq</em>; I no longer needed to say <em>George River</em>. I was unlearning my geography, just as so many Indigenous people have had to unlearn theirs. Even the idea of “the Arctic” once hadn’t existed for the Inuit. They had to invent a word for it that suited a Western geographical perspective: <em>Ukiurtatuq</em>, which translates as “repeated winter.”</p>
<p>I found that the language had a harmonious relationship with the environment—despite the occasionally ruthless climate. In the very first Inuttitut dictionary, written by Taamusi Qumaq in 1991, Nunavik is defined as “a large country occupied by animals.” I admired this humility, this awareness that a place is shared with other species, that one is living, in a way, on <em>their</em>&nbsp; land.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
                      <img src="https://content.beside.media/beside_/app/www/2020/10/AWH_2318.jpg" alt="">
                            </figure>
       </div>

              
    
      

                  <div>
        <p>It’s perhaps precisely because of this humility that one should never speak ill of <em>sila</em>, the weather. This was a blessing for a snow lover like me, tired of the eternal whinging about winter.</p>
<p>All of these words for different kinds of snow and ice, for Northern hunting and fishing techniques, show the extent to which the Inuit were at one with their land. Some people have bandied about the idea that the ancestors of the <em>Nunavimmiut</em>&nbsp; found themselves stuck in the North, blocked from going south by the Cree in the west and Innus in the east, but this is false. Research has concluded that the ancient peoples of the Arctic in fact moved even further north during a period of warming around the year 1000, because they did not know how to survive without the cold. Today, climate change has had particularly devastating consequences for the populations of Nunavik and Nunavut.</p>
<p>In the land that would become Canada, European explorers (<em>tariup akiani</em>, “from across the sea”) saw a vast reservoir of natural resources for exploitation. Our current climate crisis is the direct result of this unbridled exploitation, our stubborn insistence on doing things our way, our belief that we can draw a hermetic border between us and <em>nuna</em>, the great land, when in fact we live in each other.</p>
<p>Our language navigates modern urbanity with much more ease than Inuttitut, but it reflects a far more distant relationship with the environment, often stuck in the idea of fighting against the elements. Could the rich vocabulary of the Inuit inspire us to redefine our relationship with nature? <span>■</span></p>

      </div>
      

            
    
      

                    <div>
          <p>Born in Montréal in 1985, <strong>Juliana Léveillé-Trudel</strong> writes in various genres: fiction (<em>Nirliit</em>, La Peuplade, 2015, translated by Anita Anand, Véhicule Press, 2018), children’s literature (<em>How to Catch a Bear Who Loves to Read</em>, Chouette, 2018, coauthored with Andrew Katz), blogs, and plays. She has presented many of her theatrical and literary creations on stage. In 2018 she founded Productions de Brousse.</p>
        </div>

            
                
        </section>
      </div></div>]]>
            </description>
            <link>https://beside.media/new-narratives/nuna/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378558</guid>
            <pubDate>Thu, 10 Dec 2020 20:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“The tragedy of the commons” in software development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378442">thread link</a>) | @mcrittenden
<br/>
December 10, 2020 | https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4179">

	
<!-- .entry-header -->

	<div>

		<div>

			
<blockquote><p>The&nbsp;<strong>tragedy of the commons</strong>&nbsp;is a situation in a shared-resource system where individual users, acting independently according to their&nbsp;own self-interest, behave contrary to the common good of all users by depleting or spoiling the shared resource through their&nbsp;collective action.&nbsp;</p><cite><a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">Wikipedia</a></cite></blockquote>



<p>Remind you of anything? Toilet paper in 2020, perhaps?</p>



<p>I’m struck by how often this pops up in software development:</p>



<ul><li>Hitting refresh over and over when your test environment won’t load because everyone is overloading the dev server by hitting refresh.</li><li>Teams don’t volunteer to upgrade dependencies because they all have their own milestones to meet, and eventually an upgrade would be a nightmare because they waited too long. </li><li>Disk space, disk space, disk space. “A few extra MB won’t hurt” repeated thousands of times until the drive is chock full.</li><li>One vaguely named variable ain’t no thing, but 5 years of vaguely named variables equals <a href="https://critter.blog/2020/09/08/2-things-ive-learned-from-reading-refactoring-by-martin-fowler/">one unmaintainable codebase</a>. </li></ul>



<p>The classic <a href="https://blog.codinghorror.com/the-broken-window-theory/">broken window theory</a> is a part of this. Once someone sets the precedent, it’s hard to walk it back. Another part is <a href="https://critter.blog/2020/11/06/all-self-help-boils-down-to-choose-long-term-over-short-term/">choosing short term over long term</a>, the enemy of growth.</p>



<p>Those two plus a healthy dose of regular old human greed adds up to <em>the tragedy of the commons</em>. </p>



<p>I have no useful insight here other than to say that it exists, and sometimes naming a thing is enough to prevent it.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378442</guid>
            <pubDate>Thu, 10 Dec 2020 20:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing and Using Docker and Kubernetes on FreeBSD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25378236">thread link</a>) | @mikece
<br/>
December 10, 2020 | https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html | <a href="https://web.archive.org/web/*/https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article role="main"><p><strong>These configuration have been tested only on FreeBSD 12.1-RELEASE.</strong></p><h2 id="1-introduction">1. Introduction</h2><p>Wait… what? FreeBSD does not have Docker! Doesn’t it?</p><p>Well of course not really, but you can still install Docker using FreeBSD, it won’t just be FreeBSD in Docker since FreeBSD is not supported as Docker images.</p><p>In this blog post, I won’t discuss exactly how to install a few things, I will mostly point to blog posts and documentations so that you know what to do to install Docker and Kubernetes <strong>using</strong> FreeBSD.</p><p>I will not be using Minikube or Kind, not that I don’t like it, but my opinion is that Minikube is nice for quick and dirty small tests and it’s using VirtualBox which is like a big problem to me, but also Bhyve + VirtualBox … choice?!. And Kind is also mostly for tests, it’s closer to an installation with kubeadm, but I really prefer to try things as close to production as possible.</p><p>All these have been tested on a PC installed with FreeBSD 12.1-RELEASE. It has a 6 cores cpu, and 32GB of memory.</p><p>Here is a quick summary:</p><ul><li><a href="#1-introduction">1. Introduction</a></li><li><a href="#2-details">2. Details</a><ul><li><a href="#21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</a></li><li><a href="#22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</a></li><li><a href="#23-install-docker">2.3 Install Docker</a></li><li><a href="#24-install-kubernetes">2.4 Install Kubernetes</a></li></ul></li><li><a href="#the-end-is-the-beginning">The end is the beginning…</a></li></ul><h2 id="2-details">2. Details</h2><h3 id="21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</h3><p><a href="https://github.com/churchers/vm-bhyve"><code>sysutils/vm-bhyve</code></a> is a shell based, minimal dependency bhyve manager. And <a href="https://www.freebsd.org/doc/handbook/virtualization-host-bhyve.html">Bhyve</a> is a BSD licenced hypervisor. It’s being heavily developped with FreeBSD, and honestly it’s really well integrated to FreeBSD.</p><p>To install <code>vm-bhyve</code> on FreeBSD, you have to be root ofc for good reasons:</p><div><pre><code data-lang="shell"><span># 'sysrc -f /boot/loader.conf vmm_load="YES"'</span>
<span># Load the 'vmm' kernel module</span>
kldload vmm
<span># 'sysrc -f /boot/loader.conf nmdm_load="YES"'</span>
<span># Load the 'nmdm' kernel module</span>
kldload nmdm
<span># vm on bridge is using tap interface</span>
sysctl net.link.tap.up_on_open<span>=</span><span>1</span>
<span># edit '/etc/sysctl.conf', add 'net.link.tap.up_on_open=1'</span>
pkg install sysutils/vm-bhyve
</code></pre></div><p>I’m inviting you to go to the <code>vm-bhyve</code> GitHub page and to review its README, it has a lot of interesting informations. Just do not forget to create a switch (vm-bhyve term) and also to add your network interface to that switch.</p><p>The next thing is mostly the handling of this package. But one thing about this project is that it’s using bridge. I personaly like to have my bridge free of use, and to use firewall when it’s needed, and to be able to address my VM to my needs, which are generaly to have internet access to ease installations. Which is leading to my next point.</p><h3 id="22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</h3><p>I’m usually using PF for firewall, and to be able to have my best use of the bridge you can create with <code>vm-bhyve</code>. To this goal, I’m deciding not to firewall the bridge in any way, and to tell PF not to care about bridge it’s quite easy, it’s even a configuration I’m using for VNET jails.</p><p>So let’s change the PF behavior with bridge with these sysctls, descriptions:</p><div><pre><code data-lang="text">net.link.bridge.pfil_bridge: Packet filter on the bridge interface
net.link.bridge.pfil_onlyip: Only pass IP packets when pfil is enabled
net.link.bridge.pfil_member: Packet filter on the member interface
</code></pre></div><p>commands:</p><div><pre><code data-lang="shell">sysctl net.link.bridge.pfil_bridge<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_onlyip<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_member<span>=</span><span>0</span>
</code></pre></div><p>You can put these sysctls directly in your <code>/etc/sysctl.conf</code> so that at reboot it’s already configured.</p><p>Now you can only care for what’s important, and if you want to firewall your VM, you can always add one inside the VM itself.</p><h3 id="23-install-docker">2.3 Install Docker</h3><p>Just follow this blog: <a href="https://www.gamsjager.nl/2019/01/11/How-to-run-Docker-on-FreeBSD-12/">How to run Docker on FreeBSD 12</a></p><p>In this blog, the author is telling to get Debian 9 ISO, but you can also get Debian 10, it’s working as well.
Once the debian is installed, just don’t forget to follow these two links, I’ve followed them and it’s working:</p><ul><li><a href="https://docs.docker.com/install/linux/docker-ce/debian/">Install Docker Engine on Debian</a></li><li><a href="https://success.docker.com/article/how-do-i-enable-the-remote-api-for-dockerd">How do I enable the remote API for dockerd</a></li></ul><p>When you are finished with this section, you should be able to use docker inside the VM, and outside, so on your host.</p><h3 id="24-install-kubernetes">2.4 Install Kubernetes</h3><p>Honestly, it should be as simple as search in your favorite Search Engine <code>Install Kubernetes</code>, but the first link you get is this one: <a href="https://kubernetes.io/docs/setup/">Getting started</a>.
So… yes you could follow this link but, this is not the goal!</p><p>Instead we want the <strong>R</strong>eal thing, to get closer to a production environment, even if that’s for testing. So you can get there: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">Installing kubeadm</a>. You can follow everything on this page, it’s not hard at all. But the page only tells you to install <code>kubeadm</code>, <code>kubelet</code> and <code>kubectl</code>.</p><p>The hardest part comes with: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating a single control-plane cluster with kubeadm</a>. And here are my tips:</p><ul><li>When you install docker inside your vm, you installed it with <code>containerd.io</code>. This Kubernetes page tells you about what’s possible, either <code>Containerd.io</code>, or <code>CRI-o</code>, just do not install CRI-o, it’s not needed.</li><li>Do not forget to enable Docker in <code>systemd</code> so it’s launched when you’re VM is started</li><li>Do not forget to disable swap<ul><li><code>swapoff -a</code></li><li>edit your <code>/etc/fstab</code> to comment out the swap line</li></ul></li><li>You have to configure Docker to use the systemd cgroup and restart it, here’s my <code>/etc/docker/daemon.json</code>:</li></ul><div><pre><code data-lang="json"><span>{</span>
        <span>"dns"</span><span>:</span> <span>[</span><span>"8.8.8.8"</span><span>,</span> <span>"8.8.4.4"</span><span>],</span>
        <span>"exec-opts"</span><span>:</span> <span>[</span><span>"native.cgroupdriver=systemd"</span><span>],</span>
        <span>"log-driver"</span><span>:</span> <span>"json-file"</span><span>,</span>
        <span>"log-opts"</span><span>:</span> <span>{</span>
                <span>"max-size"</span><span>:</span> <span>"100m"</span>
        <span>},</span>
        <span>"storage-driver"</span><span>:</span> <span>"overlay2"</span>
<span>}</span>
</code></pre></div><ul><li>You have to reconfigure <code>containerd.io</code> so that it will use systemd cgroup<ul><li>reconfigure <code>containerd.io</code> with defaults, as root:</li></ul></li></ul><div><pre><code data-lang="shell">containerd config default &gt; /etc/containerd/config.toml
</code></pre></div><ul><li>then edit the <code>/etc/containerd/config.toml</code> file and change <code>systemd_cgroup = false</code> to <code>systemd_cgroup = true</code></li><li>restart <code>containerd.io</code>:</li></ul><div><pre><code data-lang="shell">systemctl restart containerd
</code></pre></div><ul><li>You should create a <code>/etc/sysctl.d/k8s.conf</code>, with these values:</li></ul><div><pre><code data-lang="text">net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
</code></pre></div><ul><li>and reload sysctl with:</li></ul><ul><li>If you do not care about default values, you can initialize the control-plane mode with just: <code>sudo kubeadm init</code></li><li>I’ve install Calico as the Network Pod, since I don’t know a thing for now about the pod network, I’ve installed the first one, also it seems to be tested with <code>e2e</code>, which seems to be CNCF standards.</li><li>Skip <code>Joining nodes</code> if you do not plane to install many nodes.</li><li>At this point, you should have a single control-plane cluster installed.</li><li>If you want to <code>kubectl run</code> images, you will need to untaint the master:</li></ul><div><pre><code data-lang="shell">kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div><h2 id="the-end-is-the-beginning">The end is the beginning…</h2><p>So here we are at the end of this post, thank you if you’ve read me up until now. My feelings are that Docker is easy to install, it’s really well integrated with Linux, even if I prefer FreeBSD. Also, Kubernetes is really nice, I’m just peeling the onion slowly.</p><p>At this point, I’ve already tried 2 (3 in fact…) other products installations with Kubernetes:</p><ul><li><a href="https://github.com/kubernetes/dashboard">Kubernetes Dashboard</a>: This one is nice to have a Web UI to watch what’s in your Kubernetes cluser</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-kubernetes-monitoring-stack-with-prometheus-grafana-and-alertmanager-on-digitalocean">How To Set Up a Kubernetes Monitoring Stack with Prometheus, Grafana and Alertmanager on DigitalOcean</a>: And this one, although it’s about DigitalOcean Kubernetes… I’ve managed to install in my Kubernetes cluster, that was a lot of searching and testing because they are using DigitalOcean Kubernetes capabilities such as creating DO Block Storage. To that end, I had to install a <a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">Static provisioner of local volumes</a> (the 3rd product 😋), and a Kubernetes Storage Class that would mimics at least the <code>do-block-storage</code> storage class in a very “simple” way.</li></ul><p>Clearly, that was a lot of time invested, but I’m quite happy since I’ve discovered and learnt quite some informations. I’m really well aware that it’s a lot of informations to handle, but if you’ve got some time to kill, it’s really worth the trip.</p><p>Eye Candy:
<a href="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png"><img src="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png" alt="kubectl get all -A"></a></p></article></div></div></div></div>]]>
            </description>
            <link>https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378236</guid>
            <pubDate>Thu, 10 Dec 2020 20:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploy an Alexa Skill and Get an Echo]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378078">thread link</a>) | @rolldeez
<br/>
December 10, 2020 | https://www.stackery.io/blog/reinvent-alexa-quiz-challenge | <a href="https://web.archive.org/web/*/https://www.stackery.io/blog/reinvent-alexa-quiz-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We are excited to announce that if you <strong>deploy our AWS Trivia Alexa Skill from Stackery</strong>  we will send you $100 AWS credits and an Amazon Echo!</p>
<h2>Details</h2>
<ol>
<li>Build an Alexa Skill (tutorial below)using Stackery to deploy into your AWS account.</li>
<li>You can deploy the code as-is out of Stackery, or modify the content of the quiz.</li>
<li><a href="https://twitter.com/stackeryio">Tweet us</a> a screenshot of your deployed backend. It'll look something like this:</li>
</ol>
<p><img src="https://media.graphcms.com/AB6B8KcTGKPiTL4gqi99" alt="alexa1.png"></p>
<h2>Q&amp;A</h2>
<h4>What is an Alexa Skill?</h4>
<p>A Skill is a voice app that can be opened on an Alexa-enabled device, such as a smart speaker, a smart home device that's Alexa-enabled, a smartwatch.</p>
<h4>What does this Skill do?</h4>
<p>This Skill asks users questions about AWS services, such as Lambda, Cognito or EC2, in a 10-question quiz game. It also gives users facts about certain AWS services.</p>
<h4>Do I need to be an AWS expert to follow this tutorial?</h4>
<p>Nope! Stackery makes it easy for <em>anyone</em> to deploy serverless apps on AWS, and adding infrastructure is as simple as dragging and dropping! You just need an AWS account, a modern browser, and a computer connected to the Internet.</p>
<h4>Do I need a lot of programming experience to follow this tutorial?</h4>
<p>No! If you can copy-paste, you can build and deploy this app. If you want to customize the quiz, you will need to know basic JavaScript.</p>
<h4>Do I need an Alexa-enabled device to test my Skill?</h4>
<p>No. The Alexa developer console includes an in-browser Alexa simulator for testing.</p>
<h4>What does it cost?</h4>
<p>Everything should fit easily within AWS's free tier, and the AWS account and Amazon Developer account are free.</p>
<h4>Can I make Alexa speak in a sarcastic tone?</h4>
<p>Sadly, no (believe me, I tried). But there are some cool things you can do with <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/speech-synthesis-markup-language-ssml-reference.html">SSML</a>, the markup language used to dictate how Alexa generates phrases.</p>
<h4>Resources</h4>
<ul>
<li><a href="https://developer.amazon.com/en-US/docs/alexa/ask-overviews/build-skills-with-the-alexa-skills-kit.html">Alexa Developer docs</a></li>
<li><a href="https://github.com/alexa/skill-sample-nodejs-quiz-game">Skill sample</a></li>
<li><a href="https://github.com/stackery/alexa-reinvent-quiz">Git repo</a></li>
</ul>
<h2>Tutorial</h2>
<h4>Prerequisites:</h4>
<ol>
<li><a href="https://developer.amazon.com/en-US/alexa/alexa-skills-kit">Free Amazon Developer account</a></li>
<li><a href="https://stackery.io/sign-up">Free Stackery Account </a></li>
</ol>
<h3>1. Create an Alexa Skill</h3>
<ol>
<li>Log in to the <a href="https://developer.amazon.com/alexa/console/ask">Alexa Developer Console</a>, and click the <strong>Create Skill</strong> button</li>
<li>Name your skill whatever you'd like</li>
<li>Choose <strong>Custom</strong> as your model</li>
<li>Choose <strong>Provision your own</strong> as the method to host your skill's backend resources</li>
<li>Scroll back up, make sure everything looks right, and click <strong>Create skill</strong></li>
</ol>
<p>You'll now see your newly-created skill in a list of all skills:</p>
<p><img src="https://media.graphcms.com/XNpSqCP6SlGhz2Nq1Yh5" alt="alexa2.png"></p>
<ol start="6">
<li>Click on the skill name, and navigate to <strong>Interaction Model</strong> -&gt; <strong>JSON editor</strong></li>
</ol>
<p>This is where you will paste a JSON file that describes the different forms of interactions your Skill will have with users, as well as the custom data that serves as the allowable answers to quiz questions.</p>
<ol start="7">
<li>Copy the entire contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/models/en-US.json">this JSON file</a> from our <a href="https://github.com/stackery/alexa-reinvent-quiz">alexa-reinvent-quiz repo</a></li>
<li>Paste the copied contents into the Alexa JSON editor, then click <strong>Save Model</strong> at the top, followed by <strong>Build Model</strong></li>
</ol>
<p><img src="https://media.graphcms.com/6AXcts9JREKAOzGB68Ts" alt="alexa3.png"></p>
<p>Once you save, you will see that your Intents were auto-populated. Feel free to poke around and view the sample utterances and <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/slot-type-reference.html">slot types</a> that are there now. When you're done, return to the main console where all of your skills are listed, as you'll need to get your Skill ID in a few moments, so be sure to leave this browser tab open.</p>
<h3>2. Build your backend in Stackery</h3>
<p><em>For this step you'll need a <a href="https://www.stackery.io/sign-up/">free Stackery account</a>, a Git provider, and a code editor. If you're a first-time Stackery user, you'll need to link your Git provider and AWS account the first time you commit and deploy a stack. Don't worry, the process is fairly quick and simple and the app will walk you through it.</em></p>
<ol>
<li>In a new tab, log in to Stackery, and create a new stack with a new repo</li>
</ol>
<p><img src="https://media.graphcms.com/AfJ27NQSjmRwqGjrlWL8" alt="alexa-step1.gif"></p>
<ol start="2">
<li>In the Visual edit mode, add a function and give it the name <code>AlexaHandler</code> and change its code source directory to <code>src/AlexaHandler</code>. Scroll down and hit <strong>Save</strong></li>
</ol>
<p><img src="https://media.graphcms.com/aH74Msn0QDOMZ1AzVGpk" alt="alexa-step2.gif"></p>
<ol start="4">
<li>Flip to the Template edit mode, and add the following YAML as part of the <code>Properties</code> of your <code>AlexaHandler</code> function:
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">   Events:
     AlexaSkillEvent:
       Type: AlexaSkill
       SkillId: [your-skill-id]
</code>
        </deckgo-highlight-code></li>
<li>Replace <code>[your-skill-id]</code> with the <code>Skill ID</code> you noted above<sup>1</sup></li>
</ol>
<p>This is what allows your Lambda function to be accessed by the specific skill you are building, and not any other.</p>
<p>Your template should look now something like this:</p>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  AlexaHandler:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-AlexaHandler
      ...
      Policies:
        - AWSXrayWriteOnlyAccess
      Events:
        AlexaSkillEvent:
          Type: AlexaSkill
          SkillId: amzn1.ask.skill.some-long-numbers-and-letters
Parameters:
  ...
</code>
        </deckgo-highlight-code><p>If you want to double-check your formatting, you can refer to our <a href="https://github.com/stackery/alexa-reinvent-quiz/blob/master/template.yaml">SAM template</a> in the tutorial repo.</p>
<ol start="8">
<li>If everything looks right, click the <strong>Commit...</strong> button to commit your changes to your Git repository</li>
<li>Follow the repo link below the stack name to access your newly-created repository</li>
</ol>
<p><img src="https://media.graphcms.com/p6X5aC2jQcqDDmuQyjcQ" alt="alexa4.png"></p>
<ol start="10">
<li>Clone your repo to your computer and open it in your favorite (or least-favorite, we're not particular) IDE</li>
</ol>
<h3>3. Add function code</h3>
<p>When you created a function in Stackery, it stubbed out some function code for you in the chosen runtime, which is Node 12 in this case. We're going to replace the function code with the Alexa backend from the <a href="https://github.com/stackery/alexa-reinvent-quiz/">tutorial repo</a>, as well as its <code>package.json</code> contents to add the required dependencies.</p>
<ol>
<li>Open <code>your-repo/src/AlexaHandler/index.js</code> and replace its contents with the contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/AlexaHandler/index.js">Stackery's Alexa Skill code</a>. Save the file</li>
<li>Open <code>your-repo/src/AlexaHandler/package.json</code> and replace its contents with the following and save:</li>
</ol>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="javascript">
                    <code slot="code">{
  "name": "alexahandler",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "author": "Stackery",
  "license": "MIT",
  "devDependencies": {
    "aws-sdk": "^2.796.0"
  },
  "dependencies": {
    "ask-sdk-core": "^2.9.0",
    "ask-sdk-model": "^1.34.1"
  }
}
</code>
        </deckgo-highlight-code><ol start="3">
<li>Commit the changes and push to your Git repo</li>
</ol>
<p>If you kept your Stackery tab open, you'll have noticed that it detected the changes you pushed up. Go ahead and hit the refresh link:</p>
<p><img src="https://media.graphcms.com/kV2cc64TQ2XcWfsWT1f6" alt="alexa5.png"></p>
<h3>4. Deploy to AWS</h3>
<ol>
<li>In the Stackery app, navigate to the <strong>Deploy</strong> tab</li>
<li>Select an environment to deploy to (if this is your first time deploying with Stackery, you'll be guided through linking to AWS first). Click <strong>Prepare new deployment</strong> and then <strong>Prepare Deployment</strong> to start your deployment</li>
</ol>
<p><img src="https://media.graphcms.com/rQ8rAzWASfG0eKVF3Fd4" alt="alexa-step3.gif"></p>
<ol start="3">
<li>Once the deployment is prepared (which will take about a minute), click <strong>Deploy</strong>. A tab will open in your AWS Console, where you'll need to click <strong>Execute</strong> to kick off the deployment<sup>2</sup></li>
</ol>
<p><img src="https://media.graphcms.com/GEnQASVcTrqah2nExmAf" alt="alexa-step4.gif"></p>
<p>This will take a few minutes - get yourself a coffee and a pat on the back, because you're 90% done with deploying your first Alexa Skill!</p>
<ol start="4">
<li>You'll get a notification when your stack has deployed. Click the <strong>View</strong> tab to see your live stack</li>
<li>Grab your screenshot for Twitter!</li>
<li>Double-click the <code>AlexaHandler</code> function to pull up some handy data and links.</li>
<li>Copy the function's ARN, as you'll need it for the final step</li>
</ol>
<p><img src="https://media.graphcms.com/N2pitl1jQwe6gs28hxmY" alt="alexa-step5.gif"></p>
<h3>5. Connect your backend to your Skill</h3>
<p>This is it: the final stage, when we connect all the dots and test our Alexa Skill!</p>
<ol>
<li>Back in the Amazon Developer Console, select <strong>Endpoint</strong> from the menu</li>
<li>Enter the ARN you copied in the previous step like so:</li>
</ol>
<p><img src="https://media.graphcms.com/oWHUCWAYQeLTiyXCeFx1" alt="alexa6.png"></p>
<ol start="3">
<li>Click <strong>Save Endpoints</strong></li>
</ol>
<p>Now you're ready to test your Skill! Navigate to <strong>Test</strong>, and say or type "Start Stackery re:Invent Quiz" to kick off the quiz. You can try the quiz yourself, or get some trivia information about specific AWS services. Knock yourself out - this is the fun part!</p>
<p><img src="https://media.graphcms.com/0JO6s23ZRjqStQh6y42u" alt="alexa7.png"></p>
<p>Return to the Stackery Dashboard, notice that your function was successfully invoked while you were testing!</p>
<p><img src="https://media.graphcms.com/Xl8eDGDQRy7TSQCCrxdd" alt="alexa8.png"></p>
<h2>Next steps</h2>
<p>Hopefully, this tutorial piqued your interests in building Alexa Skills. With a Lambda backend, you can build skills in just about any runtime, and Stackery helps you deploy changes quickly (and automatically with our <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>).<br>
I'd love to see what you build - feel free to send your projects <a href="https://twitter.com/annaspies">my way on Twitter</a>, and  don't forget to send your deployed stack to <a href="https://twitter.com/stackeryio">Stackery on Twitter</a>.</p>
<p><em><sup>1</sup> For the sake of this tutorial, we are hard-coding the Skill ID. <strong>If you are saving your Skill ID directly in the template, make sure your repo is private.</strong> Alternatively, you can use Stackery's <a href="https://docs.stackery.io/docs/using-stackery/environments#setting-parameter-store-values">Environments and Parameter Store</a> to follow best practices and store your Skill ID as in AWS's <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html">Systems Manager Parameter Store</a> and reference it at build time.</em></p>
<p><em><sup>2</sup> This tutorial walks you through deploying manually in the browser, but there are other ways to deploy that will likely suit your workflow better. You can deploy with the <a href="https://docs.stackery.io/docs/using-stackery/cli">Stackery CLI</a> with just one command, or completely automate this process upon a merge to the repo's main branch, including automated test runs, with Stackery's <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>.</em></p>
</div></div>]]>
            </description>
            <link>https://www.stackery.io/blog/reinvent-alexa-quiz-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378078</guid>
            <pubDate>Thu, 10 Dec 2020 20:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving River Crossing Puzzles with MiniZinc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378057">thread link</a>) | @rsas
<br/>
December 10, 2020 | https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/ | <a href="https://web.archive.org/web/*/https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>The objective of river crossing puzzles is to bring items from one river bank to the other in the fewest possible steps.
One prominent puzzle is the <strong>wolf, goat and cabbage problem</strong>.
From Wikipedia:</p>
<blockquote>
<p>“Once upon a time a farmer went to a market and purchased a wolf, a goat, and a cabbage.
On his way home, the farmer came to the bank of a river and rented a boat.
But crossing the river by boat, the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage.
If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.</p>
</blockquote>
<blockquote>
<p>The farmer’s challenge was to carry himself and his purchases to the far bank of the river, leaving each purchase intact. How did he do it?”</p>
</blockquote>
<h3 id="minizinc">MiniZinc</h3>
<p><a href="https://www.minizinc.org/">MiniZinc</a> is a high-level constraint modeling language.
It allows you to model optimization and constraint satisfaction problems.
In the backend, one is free to choose from a wide range of solvers.</p>
<h3 id="structure-of-minizinc-models">Structure of MiniZinc Models</h3>
<p>A MiniZinc model consists of <em>parameters</em>, <em>decision variables</em>, <em>constraints</em>, <em>objective</em>, and <em>output</em>.
They all can be specified in any order.</p>
<h4 id="parameters">Parameters</h4>
<p>Parameters define the concrete inputs for the model.
In our river crossing puzzle, the parameters can be defined as follows:</p>
<div><pre><code data-lang="minizinc"><span>enum</span> <span>PASSENGER</span> <span>=</span> <span>{</span><span>Farmer</span><span>,</span> <span>Wolf</span><span>,</span> <span>Goat</span><span>,</span> <span>Cabbage</span><span>};</span>
<span>enum</span> <span>LOC</span> <span>=</span> <span>{</span><span>bankA</span><span>,</span> <span>bankB</span><span>};</span>

<span>int</span><span>:</span> <span>maxstep</span> <span>=</span> <span>10</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP0</span> <span>=</span> <span>0</span><span>..</span><span>maxstep</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP</span> <span>=</span> <span>1</span><span>..</span><span>maxstep</span><span>;</span>
</code></pre></div><p>Apart from the enumerations, the only parameter in this puzzle is <code>maxstep</code>.
It is always a good idea to specify some upper bound for the search space during modeling.
<code>STEP0</code> and <code>STEP1</code> are two helper arrays.
We will need these later.</p>
<h4 id="decision-variables">Decision Variables</h4>
<p>A decision variable represents the unknown solution space.
In our puzzle, we are looking for the farmer’s concrete steps to carry the purchases to the far bank of the river.
In MiniZinc, we can use arrays or <code>var</code> variables to represent the unknown locations at each step:</p>
<div><pre><code data-lang="minizinc"><span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmerLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>wolfLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>goatLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>cabbageLoc</span><span>;</span>

<span>% Helper type: two-dimensional array of the unknown locations.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>loc</span> <span>=</span>
    <span>array2d</span><span>(</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>,</span>
            <span>farmerLoc</span> <span>++</span> <span>wolfLoc</span> <span>++</span> <span>goatLoc</span> <span>++</span> <span>cabbageLoc</span><span>);</span>

<span>var</span> <span>STEP</span><span>:</span> <span>end</span><span>;</span>
</code></pre></div><p>The <code>end</code> variable represents the unknown number of steps to solve the puzzle.</p>
<h4 id="constraints">Constraints</h4>
<p>The constraints define the restrictions on the decision variables:</p>
<blockquote>
<p>“the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage. If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.”</p>
</blockquote>
<p>Modeling constraints is the most challenging (and fun) part of MiniZinc.
Fortunately, you can use established techniques for modeling common problems.
In the following, we will constrain the farmer’s locations and his purchases at each step to represent the boat crossing the river.</p>
<div><pre><code data-lang="minizinc"><span>% The farmer arrives at the river with his purchases.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>)(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>0</span><span>]</span> <span>=</span> <span>bankA</span><span>);</span>
<span>% The farmer crosses the river with his purchases after end steps.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span> <span>where</span> <span>s</span> <span>&gt;=</span> <span>end</span><span>)</span>
                 <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>]</span> <span>=</span> <span>bankB</span><span>);</span>
<span>constraint</span> <span>end</span> <span>&lt;=</span> <span>maxstep</span><span>;</span>
</code></pre></div><p>How should we model the crossing of the river?
We can simply iterate over the <code>loc</code> array and constrain the previous and the next location of the farmer and his items.
To avoid code duplication, we can create a <em>predicate</em>.</p>
<div><pre><code data-lang="minizinc"><span>% If the location of a passenger changes from one river bank
</span><span>% to the other, so should change the location of the farmer too.
</span><span>% Note that STEP is 1..maxtep allowing us to access s-1.
</span><span></span><span>predicate</span> <span>passenger_moves</span><span>(</span><span>var</span> <span>PASSENGER</span><span>:</span> <span>p</span><span>,</span> <span>var</span> <span>STEP</span><span>:</span> <span>s</span><span>)</span> <span>=</span>
    <span>let</span> <span>{</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmer_last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>farmer_new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>];</span> <span>}</span> <span>in</span>
          <span>last_pos</span> <span>!=</span> <span>new_pos</span>
          <span>-&gt;</span>
          <span>farmer_last_pos</span> <span>=</span> <span>last_pos</span> <span>/\</span> <span>farmer_new_pos</span> <span>=</span> <span>new_pos</span><span>;</span>
<span>% Constrain all passengers (farmer and his purchases).
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span><span>)(</span><span>passenger_moves</span><span>(</span><span>p</span><span>,</span> <span>s</span><span>));</span>
</code></pre></div><p>Done!
Let’s finish by adding the two remaining constraints.</p>
<div><pre><code data-lang="minizinc"><span>% Never leave the wolf with the goat or the goat with the cabbage alone.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>wolfLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>\/</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>cabbageLoc</span><span>[</span><span>s</span><span>]</span> 
                  <span>-&gt;</span>
                  <span>farmerLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]);</span>

<span>% The farmer can carry only himself and a single one of his purchases.
</span><span>% If the location of the farmer changes, at most one purchase can
</span><span>% change its location as well.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>farmerLoc</span><span>[</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>farmerLoc</span><span>[</span><span>s</span><span>]</span>
                  <span>-&gt;</span>
                  <span>sum</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>p</span> <span>!=</span> <span>Farmer</span><span>)</span>
                     <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span>
                  <span>&lt;=</span> <span>1</span><span>);</span>
</code></pre></div><h4 id="objective">Objective</h4>
<p>The objective function can be either constraint satisfaction or minimization/maximization of the decision variables.
We are looking for the least number of steps to cross the river.</p>
<h4 id="output">Output</h4>
<p>Printing custom output of the solution is optional and a bit tricky.
There are built-in MiniZinc functions for that, and together with the support of emojis, we can craft the explanation of the solution found by MiniZinc.</p>
<div><pre><code data-lang="minizinc"><span>% Our emojis.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>]</span> <span>of</span> <span>string</span><span>:</span> <span>emoji</span> <span>=</span> <span>[</span><span>"👨‍🌾"</span><span>,</span><span>"🐺"</span><span>,</span><span>"🐐"</span><span>,</span><span>"🥬"</span><span>]</span> <span>::</span><span>output_only</span><span>;</span>

<span>output</span>
<span>[</span> <span>"Step \(s): "</span> <span>++</span> <span>% step prefix
</span><span></span>  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankA</span> <span>])</span> <span>++</span>
  <span>" &lt;-&gt; "</span> <span>++</span>
  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankB</span> <span>])</span> <span>++</span>
  <span>"\n"</span>
  <span>|</span> <span>s</span> <span>in</span> <span>1</span><span>..</span><span>fix</span><span>(</span><span>end</span><span>)</span> <span>];</span> <span>% generator
</span></code></pre></div><p>It’s time to put the pieces together and run our model.
Assuming you have MiniZinc available in your <code>PATH</code>, pass the model file to the executable.</p>
<div><pre><code data-lang="plain">$ minizinc --version
MiniZinc to FlatZinc converter, version 2.5.3, build 220798393
Copyright (C) 2014-2020 Monash University, NICTA, Data61

$ time minizinc farmer-wolf-goat-cabbage.mzn
Step 1: ["🐺", "🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐐"]
Step 2: ["🧑🏻‍🌾", "🐺", "🥬"] &lt;-&gt; ["🐐"]
Step 3: ["🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐"]
Step 4: ["🧑🏻‍🌾", "🐐", "🥬"] &lt;-&gt; ["🐺"]
Step 5: ["🐐"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🥬"]
Step 6: ["🧑🏻‍🌾", "🐐"] &lt;-&gt; ["🐺", "🥬"]
Step 7: [] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐", "🥬"]
----------
==========

real	0m0.850s
user	0m0.072s
sys	0m0.059s
</code></pre></div><p>We need 7 steps to cross the river, and this is provably the minimal solution!
<a href="https://github.com/rsas/minizinc-examples/blob/main/farmer-wolf-goat-cabbage.mzn">Grab the model from GitHub</a> and try it yourself.</p>
<h3 id="conclusion">Conclusion</h3>
<p>This post was inspired by the <a href="https://www.youtube.com/watch?v=kiX1FOw1GUU">MiniZinc tutorial of Lucas DiCioccio</a>.
There are many ways to model this problem.
I used the techniques from the two MiniZinc courses available in Coursera, <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a> and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>, which I highly recommend.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378057</guid>
            <pubDate>Thu, 10 Dec 2020 20:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tee in Haskell using streaming-bytestring]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377939">thread link</a>) | @anardil
<br/>
December 10, 2020 | https://anardil.net/2020/haskell-coreutils-tee.html | <a href="https://web.archive.org/web/*/https://anardil.net/2020/haskell-coreutils-tee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I've implemented some <a href="https://github.com/Gandalf-/coreutils">Unix core utilities in Haskell</a>, and want to start a series of
posts going through the details - starting with simple programs like <code>cat</code>,
<code>seq</code>, and <code>which</code>, and then moving on towards more featureful programs like
<code>uniq</code>, <code>tr</code> and maybe <code>grep</code>.</p>
<p>You can find the full source from this post
<a href="https://github.com/Gandalf-/coreutils/blob/master/Coreutils/Tee.hs">here</a>.
Let's implement <code>tee</code> in Haskell!</p>

<p>What does <code>tee</code> do? From the man page, "read from standard input and write to
standard output and files". Seems simple enough; <code>tee</code> is like <code>cat</code> except
that it additionally writes whatever passes between <code>stdin</code> and <code>stdout</code> to any
number of files along the way. Like the majority of coreutils, this is done in
a streaming fashion for performance and to reduce memory usage. It's
unacceptable, for instance, to read all of stdin, then write it to stdout and
each output file in turn. We need to <em>stream</em> the data to each output, or sink,
as it becomes available.</p>

<p>Let's sketch out the program in types to see what we need. We'll use this as a
reference for each section below:</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ parse arguments with defaults, look for errors, call runTee</span>

<span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>

<span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ read from stdin, write to each provided handle and stdout</span>
</pre></div>
<p>Let's work our way top down, starting with argument parsing, then down to
our runtime, and lastly the business logic.</p>

<p>Our main concern is streaming data, for which Haskell has a couple libraries.
We'll be using <code>streaming</code> and <code>streaming-bytestring</code> which provide
<code>Data.ByteString.Streaming</code>. ByteStrings are the way to go since <code>tee</code> must
behave itself with binary input, and besides we don't need to concern ourselves
with the content of stdin means to move it around. <code>System.Console.GetOpt</code> will
handle argument parsing, while the other <code>System</code> and <code>Control</code> libraries
provide some basics: <code>bracket</code>, <code>unless</code>, <code>die</code>, <code>openBinaryFile</code>, open flags,
and <code>Handle</code>. We'll see how these are each used in the following sections.</p>
<div><pre><span></span><span>module</span> <span>Coreutils.Tee</span> <span>where</span>

<span>import</span>           <span>Control.Exception</span>
<span>import</span>           <span>Control.Monad</span>
<span>import</span> <span>qualified</span> <span>Data.ByteString.Streaming</span> <span>as</span> <span>Q</span>
<span>import</span>           <span>System.Console.GetOpt</span>
<span>import</span>           <span>System.Exit</span>
<span>import</span>           <span>System.IO</span>
</pre></div>

<p>BSD <code>tee</code> has just two options</p>
<ul>
<li><code>-a</code> to append to output files rather than overwriting them</li>
<li><code>-i</code> to ignore SIGINT</li>
</ul>
<p>GNU tee has some more options related to error path behavior, but let's ignore
those and BSD's <code>-i</code> for the time being. This leaves us with three things to do
in our argument parsing:</p>
<ul>
<li>look for help flags to show usage</li>
<li>look for <code>-a</code> or <code>--append</code> to indicate append mode for writing</li>
<li>collect everything else as output file names</li>
</ul>
<p><code>System.Console.GetOpt</code> provides a simple pattern to describe this exactly, we
provide a data type describing our options (in this case, just one), the
defaults, and some help text and it'll figure out the details internally.</p>
<div><pre><span></span><span>newtype</span> <span>Options</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>::</span> <span>IOMode</span> <span>}</span>

<span>defaults</span> <span>::</span> <span>Options</span>
<span>defaults</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>=</span> <span>WriteMode</span> <span>}</span>

<span>options</span> <span>::</span> <span>[</span><span>OptDescr</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>)]</span>
<span>options</span> <span>=</span>
    <span>[</span> <span>Option</span> <span>"a"</span> <span>[</span><span>"append"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>opt</span> <span>-&gt;</span> <span>Right</span> <span>opt</span> <span>{</span> <span>optMode</span> <span>=</span> <span>AppendMode</span> <span>}))</span>
        <span>"append to given files, do not overwrite"</span>

    <span>,</span> <span>Option</span> <span>"h"</span> <span>[</span><span>"help"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>_</span> <span>-&gt;</span> <span>Left</span> <span>$</span> <span>usageInfo</span> <span>"tee"</span> <span>options</span><span>))</span>
        <span>"show this help text"</span>
    <span>]</span>
</pre></div>
<p><code>getOpt</code> automatically tracks which arguments aren't parsed and provides those
separately, perfect for our usecase. Let's plug this all together in our pseudo
main function.</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>teeMain</span> <span>args</span> <span>=</span> <span>do</span>
        <span>unless</span> <span>(</span><span>null</span> <span>errors</span><span>)</span> <span>$</span>
            <span>die</span> <span>$</span> <span>unlines</span> <span>errors</span>

        <span>either</span> <span>die</span> <span>(`</span><span>runTee</span><span>`</span> <span>filenames</span><span>)</span> <span>$</span>
            <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span> <span>opts</span>
    <span>where</span>
        <span>(</span><span>opts</span><span>,</span> <span>filenames</span><span>,</span> <span>errors</span><span>)</span> <span>=</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>args</span>
</pre></div>
<p>The real driver here is:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span>
<span>getOpt</span>
  <span>::</span> <span>ArgOrder</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>OptDescr</span> <span>a</span><span>]</span> <span>-&gt;</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>([</span><span>a</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>someArgs</span> <span>=</span> <span>[</span><span>"-a"</span><span>,</span> <span>"out.txt"</span><span>]</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
<span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
  <span>::</span> <span>([</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>
</pre></div>
<p>where <code>options</code> describes the flags we're looking to parse, and <code>args</code> are the
command line arguments, as per <code>System.Environment.getArgs</code>. Once parsed, we
check for errors, apply defaults with <code>foldM (flip id) defaults opts</code>, and run.
The <code>foldM</code> has a bit going on, let's break that down by specializing the
arguments one at a time.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span>
<span>foldM</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>t</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>m</span> <span>Options</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>Options</span>
</pre></div>
<p>What about <code>opts</code>? We can see the types align with <code>getOpt</code>'s first tuple if
our Foldable is a list and Monad is Either. This makes sense from a higher
level too; we have multiple "combine-able" operations (parsing flags) that can
succeed (provide an <code>Option</code>) or fail (provide a <code>String</code> error message). All
together, this executes the parsing functions <code>opts</code> in turn to build an
<code>Either String Options</code>, filling in the blanks with our defaults as necessary.</p>
<p>When we're all done, we have <code>Options</code> and a list of everything else not parsed
which we can use as the list of output filenames.</p>

<p>Let's take a look back and see what we're supposed to do next.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>
</pre></div>
<p>So we have our options and filenames, and need to convert those into handles to
call the next layer. To properly manage our resources (these handles), we need
to close them too. Breaking these steps out in a <code>do</code> block would work most of
the time, but would leak if we hit an exception. On Linux, this isn't such a
big deal - the process exiting will close all the handles. However on Windows
(which we can support for free thanks to Haskell's IO libraries), not closing
the handles can mean that data doesn't get written. To that point, Haskell uses
exceptions to communicate IO errors, the exact type of errors we're likely to
encounter opening and writing to files. Luckily, <code>bracket</code> is perfect for this
situation; let's check it out.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>bracket</span>
<span>bracket</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>c</span><span>)</span> <span>-&gt;</span> <span>IO</span> <span>c</span>
</pre></div>
<p>Provided some IO computation that produces resources, a function that uses
those resources, and a function that releases those resources, <code>bracket</code> will
run everything together, ensuring that the resources are released even if
there's an exception while they're being used.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>runTee</span> <span>o</span> <span>fs</span> <span>=</span>
        <span>bracket</span> <span>acquire</span> <span>release</span> <span>tee</span>
    <span>where</span>
        <span>acquire</span> <span>=</span> <span>mapM</span> <span>(`</span><span>openBinaryFile</span><span>`</span> <span>optMode</span> <span>o</span><span>)</span> <span>fs</span>
        <span>release</span> <span>=</span> <span>mapM_</span> <span>hClose</span>
</pre></div>
<p>Pretty easy!</p>

<p>So now we have our collection of handles, time to use them to do some real
work. Let's see it all together, then break it down.</p>
<div><pre><span></span><span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- build up n computations that copy the stream and write it a file</span>
<span>tee</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>foldr</span> <span>(</span><span>\</span><span>h</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>toHandle</span> <span>h</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
</pre></div>
<p><code>Data.ByteString.Streaming</code> usage works right to left, where the right side is
the source of the stream, and the left side is the sink, where the data ends
up. The space between is where we can mutate the stream. The simplest <code>tee</code> is
with no files, in which it's just a simplified <code>cat</code> that only reads from
<code>stdin</code>. To describe that with these streams, that'd be:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>m</span> <span>()</span>
</pre></div>
<p>Take everything from stdin and stream it to stdout. For our purposes, <code>m</code> is
<code>IO</code>, nothing else is needed here. We can specialize our types to see this
ourselves, and that we're going to fit into the prototype we sketched out
initially for <code>tee</code>.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span> <span>::</span> <span>IO</span> <span>()</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>IO</span> <span>()</span>
</pre></div>
<p>Now, for writing streams to handles we have <code>Q.toHandle</code>, but this has a
problem - it acts like a sink, consuming all of the input stream. This won't
work, since the input from <code>stdin</code> will never make it to <code>stdout</code>. We can't
read the stream twice either; for a file we could read everything twice, it
would just be wasteful, but for <code>stdin</code> it's not possible - the data only
exists once.</p>
<p>The library has something for us though: <code>Q.copy</code> forks a stream, allowing you
to do two separate, independent computations on it. Internally, this is
essentially sending the chunks that make up the input stream two different
places, creating two streams from one.</p>
<p>Let's build up a <code>cat</code> the preserves the input stream beyond writing to stdout
rather than consuming it.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span>
<span>Q</span><span>.</span><span>copy</span>
  <span>::</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
<span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span>
     <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>()</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
<span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>()</span>
</pre></div>
<p>While we're here thinking about stdout, let's note that <code>Q.stdout</code> isn't doing
anything magical compared to <code>Q.tohandle</code>, just sparing us some typing. This is
useful, because it let's us treat stdout as "just another output", the same as
the handles we're creating.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
<span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>stdout</span>
<span>Q</span><span>.</span><span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>
</pre></div>
<p>With our stream copying ability, we can create a waterfall of streams! stdin to
the first handle + new stream 1, new stream 1 to the second handle + new stream
2, and so on until the last stream, which just goes to stdout.</p>
<p>Good old <code>foldr</code> matches this pattern well; take some initial value, run a
computation on it with the first input to produce an output, then use that as
the new initial value for the second input value, and so on.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>T…</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anardil.net/2020/haskell-coreutils-tee.html">https://anardil.net/2020/haskell-coreutils-tee.html</a></em></p>]]>
            </description>
            <link>https://anardil.net/2020/haskell-coreutils-tee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377939</guid>
            <pubDate>Thu, 10 Dec 2020 20:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick guide to the security features of euro banknotes [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377645">thread link</a>) | @dt3ft
<br/>
December 10, 2020 | https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377645</guid>
            <pubDate>Thu, 10 Dec 2020 19:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Non-Dilutive Funding for SaaS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377563">thread link</a>) | @tacon
<br/>
December 10, 2020 | https://www.trypaper.io/funders | <a href="https://web.archive.org/web/*/https://www.trypaper.io/funders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.trypaper.io/funders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377563</guid>
            <pubDate>Thu, 10 Dec 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning about Elixir's generic server processes with a real-world example]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377107">thread link</a>) | @areichert
<br/>
December 10, 2020 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377107</guid>
            <pubDate>Thu, 10 Dec 2020 19:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Take on RSS]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25376849">thread link</a>) | @jacobobryant
<br/>
December 10, 2020 | https://findka.com/blog/new-take-on-rss/ | <a href="https://web.archive.org/web/*/https://findka.com/blog/new-take-on-rss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Findka now includes an RSS aggregator.</p><p><img src="https://findka.com/img/subscriptions-example.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>If you subscribe to any feeds, then 50% of the articles in your regular Findka
emails will be sampled from those feeds.
I added this because, <a href="https://findka.com/blog/2020-12-05/">as I mentioned</a>,
I'm going to start doing more manual curation to make sure that Findka has a
steady stream of new, great essays. I also think it's a valuable feature for
anyone who wants a little more control over their Findka recommendations.</p><p>How's this different from existing RSS aggregators? For one thing, since this
is built into Findka, any articles that you like will start to be recommended
to other users, too. But there's more.</p><p>Most RSS aggregators keep your feeds separate. Findka instead merges them into
a single feed using a bandit algorithm. If you've subscribed to three
feeds—A, B and C—Findka will start out picking articles from the
feeds uniformly. 1/3 of the articles will come from feed A, etc. As time goes
on, Findka will adjust the distribution based on your usage data. If you never
click on articles from feed A and you always click on articles from feed B,
then Findka will show you fewer articles from A and more articles from B.</p><p>On top of that, the number of articles in your feed is controlled by you, not
by the feeds you subscribe to.</p><p><img src="https://findka.com/img/frequency-setting.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>The result is that using RSS now takes extremely little effort. You get a
single, small feed that improves itself automatically.</p><p>I'm planning to add more RSS-related features—stay tuned.</p></div></div>]]>
            </description>
            <link>https://findka.com/blog/new-take-on-rss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376849</guid>
            <pubDate>Thu, 10 Dec 2020 18:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Blog from Emacs via magit-forge backed by GitHub issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376755">thread link</a>) | @sgrove
<br/>
December 10, 2020 | https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues | <a href="https://web.archive.org/web/*/https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><a href="https://twitter.com/sgrove"><p><img alt="Sean Grove" src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly9hdmF0YXJzMy5naXRodWJ1c2VyY29udGVudC5jb20vdS8zNTI5Nj9zPTk2JnU9OTc1M2U1MmU2NjRkYmEyYWI4M2IyYzA4YjlhNmNjOTBhNWNhYzdiYiZ2PTQ"></p></a></div></div><p><span><p>So @dwwoelfel and I have been working on a powerful blogging system that keeps all of your data inside of GitHub issues - you can see the result (and post yourself) live on <a href="https://essay.dev/">essay.dev</a> - or you can fork the open-source repo and deploy your instance, and all the instructions below will work just fine on your own repo.</p><h4 id="watch-me-create-a-blog-post-from-inside-magit-forge">Watch me create a blog post from inside magit-forge</h4><p><iframe title="https://www.youtube.com/watch?v=VVOd1yOKVqQ" type="text/html" width="100%" height="360" src="https://www.youtube.com/embed/VVOd1yOKVqQ" frameborder="0"></iframe></p><h3 id="github-issue-powered-blogging-and-commenting">GitHub-issue powered blogging and commenting</h3><p>The entire site is powered by GitHub issues and next.js (and hosted on Vercel). Any issue with a <code>Publish</code> tag will be made publicly available immediately (and can be similarly unpublished by removing the <code>Publish</code> label).</p><p>That's pretty fantastic for lots of reasons - your posts are now in an API that's easy to slice and dice so there's no lock-in to your content or comments, it's a familiar place for devs to work, etc.</p><p>There are hundreds of features and polish in essay.dev, but importantly for me, it's compatible with emacs' <code>magit-forge</code>!</p><h3 id="magit-forge-i-choose-you"><code>magit-forge</code>, I choose you!</h3><p><code>magit</code> is the famous git control system for emacs, and it has an equally powerful integration to manage GitHub issues called <code>magit-forge</code>.</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMzI3LTgyNTg3ZDAwLTM1NWQtMTFlYi04MmFiLTQwZTI0MGZlYWY3Ni5wbmc" alt="Preview of reading a rich post on `essay.dev` in `magit-forge`"></span></p><p>You can do all the normal CRUD operations on GitHub issues inside a familiar emacs workflow - which means we can do the same for our posts<sup>1</sup>!</p><h3 id="creating-a-post-on-essaydev">Creating a post on essay.dev</h3><p>First make sure you've installed <a href="https://magit.vc/"><code>magit</code></a> and <a href="https://magit.vc/manual/forge.html"><code>magit-forge</code></a> (or for spacemacs users, just add the <a href="https://develop.spacemacs.org/layers/+source-control/github/README.html"><code>GitHub layer</code></a>).</p><p>Now, let's clone the <code>essay.dev</code> repo:</p><div><pre><code><span>git clone https://github.com/OneGraph/essay.dev.git</span>
<span>cd essay.dev</span>
<span>emacs README.md</span></code></pre></div><p>Next we'll connect <code>forge</code> with our GitHub repository via <code>M-x forge-add-repository</code> - and now we're ready to see a list of all of the posts, so run <code>M-x forge-list-issues</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMDkxLTMxNDg4OTAwLTM1NWQtMTFlYi05MDgyLTMzYzMxYzQ3NmFiMy5wbmc" alt="`magit-forge` listing posts on `essay.dev`"></span></p><p>If we hit <kbd>Enter</kbd> on any of the issues, we'll see the content and the comments:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwNDM2LWE2YjQ1OTgwLTM1NWQtMTFlYi04ZDUzLTQ5Y2JhMTBhMmNlYy5wbmc" alt="Look at this excellent post - we'll have to up our game from now on"></span></p><h4 id="create-a-new-post">Create a new post</h4><p>Running <code>M-x forge-create-issue</code> will create a new buffer pre-filled via the default <code>new-post</code> template:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwODYxLTJhNmU0NjAwLTM1NWUtMTFlYi04YTU0LTczNmE0ZDExOWYyYS5wbmc" alt="We're ready to write our next great post"></span></p><p>Simply fill out the title and the body, and when you're ready, "commit" the new post via <code>C-c C-c</code>. Forge will commit it to a local database first for safe-keeping, and then create an issue on GitHub! Back in the <code>*forge-issue-list...*</code> buffer, hit <kbd>g</kbd> to refresh the lists of posts, with your newest one at the top. Hit <kbd>Enter</kbd> on it to view the contents.</p><h4 id="your-post-is-ready">Your post is ready!</h4><p>A few seconds later, run <code>M-x forge-pull</code> to update your local copy - you should find there's a new comment waiting for you from <code>onegraph-bot</code>:</p><span><blockquote><p>View your post at https://<username></username>.essay.dev/post/<issue-number></issue-number>/<issue-title></issue-title></p></blockquote></span><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwOTE3LTQyZGU2MDgwLTM1NWUtMTFlYi05ODAwLWFmM2M3MTFhYjY5MC5wbmc" alt="Our post is all grown up and ready for the world"></span></p><p>That's it, your post is available to the world.</p><p>You can also leave comments on your posts (and others) with <code>M-x forge-create-post</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMDUwLTY5MDQwMDgwLTM1NWUtMTFlYi04ODU2LTUzNzRkMGE1NjRiOC5wbmc" alt="Why leave emacs to leave a comment?"></span></p><p>It'll show up instantly on your post (both in forge and on the site):</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMTE4LTdmMTFjMTAwLTM1NWUtMTFlYi05M2ZkLWMzMDJiOGYyNGNiZC5wbmc" alt="Thanks to the API-based backend (and some clever engineering), posts and comments show up everywhere seamlessly"></span></p><h3 id="whats-next">What's next?</h3><p>Your content belongs to you, and is easily accessible through the GitHub API - here's an example query that'll pull out the posts for you:</p><div><pre><code><span>query</span><span> MyPostsOnGitHub(</span>
<span>  $owner: String = </span><span>"onegraph"</span>
<span>  $name: String = </span><span>"essay.dev"</span>
<span>  $createdBy: String = </span><span>"sgrove"</span>
<span>) {</span>
<span>  gitHub {</span>
<span>    repository(name: $name, owner: $owner) {</span>
<span>      issues(</span>
<span>        first: </span><span>10</span>
<span>        orderBy: { </span><span>field</span><span>: CREATED_AT, </span><span>direction</span><span>: DESC }</span>
<span>        filterBy: { </span><span>createdBy</span><span>: $createdBy }</span>
<span>      ) {</span>
<span>        edges {</span>
<span>          node {</span>
<span>            body</span>
<span>            number</span>
<span>            title</span>
<span>          }</span>
<span>        }</span>
<span>      }</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre></div><p>Try it out <a href="https://www.onegraph.com/graphiql?shortenedId=R8KXQM&amp;snippetKey=JavaScript%3Areact-apollo">here</a></p><p>And again, note that this setup will work with any repo, so if you want to self-host your content it's as easy as using the <a href="https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext&amp;env=NEXT_PUBLIC_ONEGRAPH_APP_ID,NEXT_PUBLIC_TITLE,OG_GITHUB_TOKEN,OG_DASHBOARD_ACCESS_TOKEN,VERCEL_URL,VERCEL_GITHUB_ORG,VERCEL_GITHUB_REPO&amp;envDescription=Variables%20needed%20to%20build%20your%20OneBlog&amp;envLink=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext%23environment-variables&amp;project-name=oneblog&amp;repo-name=oneblog">deploy on vercel</a> link.</p></span></p></div></div>]]>
            </description>
            <link>https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376755</guid>
            <pubDate>Thu, 10 Dec 2020 18:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Docker to Manage Your Test Database(s)]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376621">thread link</a>) | @craigkerstiens
<br/>
December 10, 2020 | https://www.tonic.ai/post/using-docker-to-manage-your-test-database | <a href="https://web.archive.org/web/*/https://www.tonic.ai/post/using-docker-to-manage-your-test-database">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-b46f52e7cc86-94242d82"><p><img src="https://uploads-ssl.webflow.com/5f0ae1534d32e5a91598eb9c/5fb81ee39c9c19251287e848_Docker%20for%20Test%20DB.png" loading="lazy" alt=""></p></figure><p><em>TL;DR: Docker is a great tool for packaging and distributing test databases among your team and testing environment. We’ve created </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>a starter repository</em></a><em> to show these concepts in PostgreSQL and MySQL </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>on Github</em></a><em> if you’d like to dig in immediately while reviewing our process below.</em></p><p>Containers are a valuable resource for us developers. They give you the ability to package your production code, dependencies, and assets into a standardized unit. Once conveniently packaged, running your application in a variety of environments is a breeze. And yet despite containerization’s immense value, we often see teams overlook containers entirely when it comes to managing test databases. At Tonic, whether we’re helping our customers improve testing with high-quality test databases or building our own testing environments, we rely on Docker as a key part of the pipeline. Our customers are finding a lot of value in the approach, so we thought we’d share our strategy.</p><h2>The Trouble With Test Databases</h2><p>Let’s take a look at the typical growth of a test database for a team:</p><ol role="list"><li>You and your team realize that testing in production is a bad idea. You’ve heard about it or you’ve felt the pain yourself: mistakes that lead to data loss and time spent restoring from backups; poor reliability in production due to increased database load; the security team raising their eyebrows at giving too many people access to sensitive data; and the omnipresent anxiety that testing might take down production.</li><li>You decide you need data that’s similar to your production environment, so you write some scripts to generate some fake data (like<a href="https://www.tonic.ai/post/how-to-generate-simple-test-data-with-faker" target="_blank"> faker</a>), use some free or paid services to generate some random data for you (like<a href="https://www.tonic.ai/post/tonic-mockaroo" target="_blank"> Mockaroo</a>), or extract data from production and attempt to anonymize it later (dealing with the mess of maintaining referential integrity).</li><li>You shove either those scripts or data files into your code repo.</li><li>You write in a README the loader command to get it into your database of choice, and like a rite of passage, everyone on the team struggles through getting it to work during onboarding.</li></ol><p>And struggle you will! Databases are notorious for requiring large installations with a multitude of dependencies, navigating arcane configuration, and the extensive work of establishing the test dataset: creating schemas, creating tables, and finally loading your generated data.</p><p>Many teams will have a separate installation process for each operating system their developers use, each of which usually takes a good bit of trial and error after poring over database documentation. Others will set up a staging or test server for their team to use, but it risks becoming out-dated without a regular rebuild, it means a lot of coordination between team members, and there is rarely a one-size-fits-all test environment. For example, when you want to test the scale of your application, your entire team is saddled with a giant database that slows everyone down; likewise, too small of a database can limit effective testing for certain projects.</p><p>Wouldn’t it be great if there were a tool that made it easy to package a database, its dependencies, loader scripts, and its data for any operating system? That any team member could use to easily test their code against a test environment, be it on their local machine or on a quickly spun-up test server in the cloud?</p><h2>Doing Better with Docker</h2><p>Good news, everyone! There is a better way! The many benefits that Docker provides for shipping your code in production work likewise for testing. You can create a database that is easy to distribute, deploy, and reset so that individuals and teams can work effectively without stepping on each other’s toes. For larger organizations, you can even package multiple test databases that each contain different tables or amounts of data, easily available to everyone in your engineering org. Best of all, you don’t need a different local installation README for each operating system—developers can just use the OS they feel most productive in without the headaches of the past.</p><h3>The Basics</h3><p>The simplest way to get started is to use a vanilla database image for your database of choice. By using docker-compose, you can set up the configuration once, and it’s just a<tt> docker-compose up -d </tt>to start the database. Here’s a basic configuration below:</p><h5>version: '3'<br>services:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testdb_postgres:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image: postgres:12<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: always<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ports:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 5432:5432<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;environment:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_USER: user<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_PASSWORD: password<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_DB: test_data<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;container_name: testdb_postgres<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumes:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- /tmp:/tmp<br></h5><p>This configuration does the following:</p><div><ul role="“list”">
<li>Creates a container named<tt> testdb_postgres </tt>that runs off of a PostgreSQL 12 image</li>
<li>Opens up Postgres’ default port of 5432 to 5432 on your host machine</li>
<li>Attaches the<tt> /tmp </tt>folder to your host machine’s<tt> /tmp </tt>folder</li>
<li>Creates a new user with credentials<tt> user/password</tt>, and a new database called<tt> testdb_postgres</tt>.</li></ul></div><p>Right off the bat, we’ve removed a lot of work from the README, and if you have data or data-generating scripts in your repo, you’ve made it much easier to get up and running quickly by simply pointing them to load into the database via the host part. Many databases have official images, including <a href="https://hub.docker.com/_/postgres/" target="_blank">Postgres</a>, <a href="https://hub.docker.com/_/mysql" target="_blank">MySQL</a>, <a href="https://hub.docker.com/_/microsoft-mssql-server" target="_blank">MS SQL Server</a>, <a href="https://hub.docker.com/_/oraclelinux" target="_blank">Oracle</a>, and <a href="https://hub.docker.com/_/mongo" target="_blank">Mongo</a>, among others.</p><h3>Even Better: Packaging Your Data &amp; Scripts with Docker</h3><p>Instead of just using the available database image and calling it a day, you can easily create a new Docker image based off of your database’s official image. Many official images have an entry point folder that allows you to run scripts upon initialization, enabling the container to be immediately useful as soon as it’s up. To do this, you’ll likely need to add a Dockerfile and a build script, and potentially any data import scripts.</p><h4>Dockerfile</h4><p>Making a basic Dockerfile is not hard at all, in fact it’s only two lines:</p><h5>FROM postgres:12<br>COPY sql/*.sql /docker-entrypoint-initdb.d/</h5><p>Here we did the following:<br></p><div><ol role="list">
<li>We started by defining a<tt> Dockerfile </tt>with a<tt> FROM </tt>declaration pointing to the base image of your database.</li>
<li>We copied over all of our data import scripts (defined in a subdirectory named sql) to the<tt> /docker-entrypoint-initdb.d/ </tt>directory. Postgres <a href="https://hub.docker.com/_/postgres/">defines this folder</a> for SQL scripts to be run during initialization.</li>
</ol></div><p>In our <a href="https://github.com/TonicAI/docker-testdb" target="_blank">code repository</a>, you’ll see we’ve commented out additional options to consider for your use case, such as:</p><ul role="list"><li>Adding any additional dependencies, like database extensions or certificates using typical package manager commands.</li><li>Adding data files to an accessible directory for use with data import scripts.</li><li>Adding custom scripts to import data outside of the container, e.g. via S3 or other data storage.</li></ul><h4>Build Script</h4><p>Here we simply create a shell script to make it easier to build the container. Our build.sh contains the following command which merely tags the new container as<tt> testdb_postgres </tt>and specifies the Dockerfile to use.</p><h5>docker build -f Dockerfile -t testdb_postgres .<br></h5><p>If you were building this in a CI environment, we’d recommend giving the tag a unique version for each build and release as a script argument, such as<tt> testdb_postgres:1.0.4</tt>.</p><h4>SQL Scripts</h4><p>Next, you’ll need to create SQL loader scripts that create your schema and load in your data. Typically the easiest way to do this is by using database dump commands with an existing test database. We recommend three scripts: the first one creates your schema without constraints, the second one loads your data, and the third one adds your constraints to all of your tables. This way, you’re able to load your data without worrying about the order in which it’s loaded (which would matter if foreign key constraints were already in place).</p><p>Some databases will turn off constraints using a data import tool until the import is complete, which means you can just keep your constraints in the schema script. For simplicity, in <a href="https://github.com/TonicAI/docker-testdb" target="_blank">our example code</a> we only use two scripts since our data script loads tables in order and doesn’t break referential integrity.</p><p>Sticking with PostgreSQL as our example, you can run the following command to get a dump of your existing schema and constraints:</p><h5>pg_dump -U user -s -f 1_schema.sql [YOUR DATABASE NAME];</h5><p>Followed by a similar command to get just the data:<br></p><h5>pg_dump -U user -a -f 2_data.sql test_data;<br></h5><p>Notably, we’ve added numbers to the beginning of each filename to ensure that the schema script is run before the data load script. (Postgres runs the scripts in this folder in alphabetical order.)</p><p>Take a look at our code to see the full output of both of these files. Feel free to modify these files as you like or write them from scratch, especially if you plan to load your data using a COPY or LOAD command.</p><h4>Modifying your docker-compose.yml</h4><p>Lastly, update the image you’re using to the name of your newly tagged one: image: testdb_postgres. If you’re versioning your container when you build it, we recommend specifying a stable release tag such as<tt> testdb_postgres:stable </tt>so that users can pull the latest update to that tag with<tt> docker-compose pull</tt>.</p><h4>Setting up CI</h4><p>Now you can check your Dockerfile, scripts, and data files into a code repo, and create a build for the Docker container in your CI service of choice using your build script. Any time the scripts or data files are changed, we recommend triggering a new release build for the container and pushing it to your container repository for use by your entire team (of course, after you’ve checked that nothing new caused the build to break 😉).</p><p>If everything is set up, it should be as simple as distributing the docker-compose.yml file to your team and running a<tt> docker-compose up</tt>.</p><h2>Next Level Test Data Management</h2><p>If you’ve followed the steps thus far, you’ll likely find that your testing setup is much more reliable and useful to your entire team, and it’s a big leap forward in efficiency.</p><p>From here, there are a lot of ways …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tonic.ai/post/using-docker-to-manage-your-test-database">https://www.tonic.ai/post/using-docker-to-manage-your-test-database</a></em></p>]]>
            </description>
            <link>https://www.tonic.ai/post/using-docker-to-manage-your-test-database</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376621</guid>
            <pubDate>Thu, 10 Dec 2020 18:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mystery illness in India found excessive levels of lead, nickel in blood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375917">thread link</a>) | @gmays
<br/>
December 10, 2020 | https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Indian health officials have found traces of nickel and lead in a few of the blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, the state government says.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5834017.1607524630!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/india-mystery-illness.jpg"></p></div><figcaption>Health officials and experts in India are investigating a mysterious illness linked to the death of one person and the hospitalization of 585 others. In this photo, taken Tuesday, a patient is assisted out of an ambulance at the district government hospital in Eluru, Andhra Pradesh state. <!-- --> <!-- -->(The Associated Press)</figcaption></figure><p><span><p>Indian health officials have found traces of nickel and lead in a few of the&nbsp;blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, officials said.</p>  <p>The Andhra Pradesh state government said in a statement Tuesday night that investigations by experts from the All India Institute of Medical Sciences have&nbsp;not been able to determine&nbsp;the source of excessive nickel and lead particles in the patients' blood.</p>  <p>The government was still waiting for results of other tests, including toxicology reports and blood cultures, being conducted by experts at the Indian Institute of Chemical Technology, the statement said&nbsp; &nbsp;</p>  <p>Health officials and experts appeared to be baffled&nbsp;by how the heavy metals got into the patients' blood, and whether those metals&nbsp;caused the mysterious illness linked&nbsp;to the death of one person&nbsp;and the hospitalization of&nbsp;more than 585 others.</p>    <p>The illness was first detected Saturday evening in Eluru, an ancient city famous for its handwoven products.</p>  <p>People with the illness started convulsing without any warning, said Geeta Prasadini, a state health official.</p>  <p>Andhra Pradesh Chief Minister Y.S. Jaganmohan Reddy held a virtual meeting Wednesday with officials who included experts from India's top scientific institutes.</p>  <p>Reddy said 502 of the people who went to hospital were&nbsp;discharged after showing improvement.</p>  <h2>No apparent common link</h2>  <p>The patients showed symptoms ranging from nausea and anxiety to loss of consciousness.</p>  <p>What is confounding experts is that there doesn't seem to be any common link among the hundreds of people who have fallen sick.</p>  <p>All of the patients have tested negative for the coronavirus and other viral diseases such as dengue, chikungunya and herpes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/india-mystery-illness.jpg 300w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/india-mystery-illness.jpg 460w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/india-mystery-illness.jpg 620w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg 780w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/india-mystery-illness.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg"></p></div><figcaption>A man carries a young patient at the district government hospital in Eluru on Monday. About 70 children are among those stricken by the mystery illness.<!-- --> <!-- -->(The Associated Press)</figcaption></figure></span></p>  <p>Those who became ill aren't related to each other and don't all live in the same area. They represent different age groups, including about 70 children, but very few are elderly.</p>  <p>Initially, officials suspected contaminated water. But the chief minister's office confirmed that people who don't use the municipal water supply have also fallen ill, and that initial tests of water samples didn't reveal any harmful chemicals.</p>  <p>A 45-year-old man who goes by the single name Sridhar went to hospital with symptoms resembling epilepsy and died Sunday evening, doctors said. Prasadini said his autopsy didn't shed any light on the cause of death.</p>  <p>Andhra Pradesh state is among those worst-hit by the coronavirus, with over 800,000 detected cases. The health system in the state, like the rest of India, has been frayed by the virus.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375917</guid>
            <pubDate>Thu, 10 Dec 2020 17:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25375637">thread link</a>) | @markmossberg
<br/>
December 10, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind too much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong><strong>Misc items</strong></strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375637</guid>
            <pubDate>Thu, 10 Dec 2020 16:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a tool to visualise pathfinding algorithms (Desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375391">thread link</a>) | @anthonyatp
<br/>
December 10, 2020 | https://anthonyatp.github.io/pathfinder-visualiser/ | <a href="https://web.archive.org/web/*/https://anthonyatp.github.io/pathfinder-visualiser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://anthonyatp.github.io/pathfinder-visualiser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375391</guid>
            <pubDate>Thu, 10 Dec 2020 16:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Relic to open-source Pixie’s eBPF observability platform]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25375170">thread link</a>) | @htroisi
<br/>
December 10, 2020 | https://blog.pixielabs.ai/pixie-new-relic/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/pixie-new-relic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We are excited to announce that we signed a <a href="http://blog.newrelic.com/product-news/pixie-developer-first-observability" target="_blank" rel="noopener noreferrer">definitive agreement</a> to join New Relic -- an outcome we certainly never predicted after only just two years.</p><p>New Relic’s focus on the developer is legendary. When New Relic's Founder/CEO, Lew Cirne, first started tinkering around with Pixie and participating in our community, we noticed an alignment in our visions for the future of observability, as well as echoes of New Relic’s developer-centric roots in Pixie. Joining New Relic will provide us with an unprecedented opportunity to reach millions of developers faster by open-sourcing a self-managed version of Pixie in the upcoming months.</p><p>When we started Pixie in 2018, Kubernetes was rapidly gaining traction. We felt that a new approach to observability was needed due to the new, fundamental challenges in observing distributed, ephemeral systems. We founded Pixie in order to provide instant, flexible observability for developers like ourselves who were building applications on Kubernetes.</p><p>However, we knew that the most developer-friendly version of Pixie must be open-source. In a forward-looking move, New Relic is giving us the opportunity to open-source Pixie and focus on providing world-class observability to all developers. The developer community is a core element of New Relic’s vision, and Pixie’s open-source offering will be a key part of that initiative and the primary area of focus for the Pixie team going forward.</p><p>We are so excited to begin working with New Relic on our shared vision for the future of observability. In the coming months, we’ll be jointly committing our roadmap in the following initiatives:</p><ul><li><p><strong>Pixie Core</strong>: An open-source and self-managed version of Pixie which we will release to the CNCF sandbox early next year. As part of the process, we look forward to speaking with you about this at Kubecon-EU on May’21. Due to Pixie’s and New Relic’s commitment to open standards, we also plan to build out integrations with OpenTelemetry, Prometheus, and Grafana.</p></li><li><p><strong>Pixie By New Relic</strong>: Our current Pixie Community offering will continue as a hosted version of Pixie Core and existing New Relic One customers will soon get instant access to Pixie data with a few clicks. Their existing experiences will be augmented with the metrics, logs, events, and application traces that Pixie automatically provides.</p></li><li><p><strong>Pixie by New Relic, Enterprise Edition</strong>: Industry-specific solutions for sectors such as Media, Telecommunications, and Government that allow enterprise customers to install Pixie entirely inside production clusters while meeting compliance, data security, support, and performance requirements.</p></li></ul><p>Finally, our journey is just beginning. We are a team of 12 people with a huge vision to reach every Kubernetes developer. As we embark on this part of our journey, we encourage anyone passionate about open source, Kubernetes, and observability to apply to join us <a href="https://pixielabs.ai/careers/" target="_blank" rel="noopener noreferrer">here</a>.</p><p>You can try out Pixie <a href="https://work.withpixie.ai/auth/signup?UTM=PXNR" target="_blank" rel="noopener noreferrer">here</a>, learn more about us <a href="https://pixielabs.ai/" target="_blank" rel="noopener noreferrer">here</a> and ping us anytime on our Pixienaut community slack.</p></div></div></div></div>]]>
            </description>
            <link>https://blog.pixielabs.ai/pixie-new-relic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375170</guid>
            <pubDate>Thu, 10 Dec 2020 16:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to product analytics tools for startups]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25375148">thread link</a>) | @Fission
<br/>
December 10, 2020 | https://satchel.com/web-analytics/ | <a href="https://web.archive.org/web/*/https://satchel.com/web-analytics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content"><div><div><p>Last Updated </p><!-- --><p>May 30, 2020</p></div><div><p>Reading Times:</p><p>Summary only: 1 minute</p></div></div><h2 id="introduction">Introduction</h2><p>Every YC batch, Michael Seibel gives a talk about building product. He'll ask: "<a href="https://youtu.be/C27RVio2rOs?t=1677">How many of you are using Google Analytics as your primary source of metrics?</a>" But it's a trick question. When the majority of the audience eventually raises their hands, he'll fake a sigh and tell everyone that they're doing it wrong, and that they should instead by relying on an event-based analytics tool.<span></span><span>The linked video is from Startup School, but the same talk is given at YC Core as well.</span></p><p>It's a perennial favorite, but don't let the humor distract you. Michael's got a
good point. Without using an event-based analytics tool, which tracks the interactions your users have with your product, you won't know <em>how</em> your
users are using your product. This is arguably just as important as actually
building out the product. There are a lot of event-based analytics tools out
there, but we think that if you're an early-stage startup, Heap makes the best tradeoffs.</p><div><p><a target="_blank" href="https://heap.io/"><img src="https://d33wubrfki0l68.cloudfront.net/b6fae69c970dbd3257184ea4d909f5d858810bdc/35c24/logos/heap.svg"></a></p><div><p>Our Recommendation</p><p><a target="_blank" href="https://heap.io/">Heap</a></p><p>Highest benefit-to-effort ratio</p><p>Gave us auto-tracking functionality, which we think is an exceptionally good safety net for an early-stage startup with rapidly-changing features and limited engineering resources, although it lacks some of the extensibility and more advanced analysis capabilities of its competitors. That said, we think this tradeoff best suits an early-stage startup.</p><p><a target="_blank" href="https://heap.io/">heap.io</a></p></div></div><summary><h2 id="summary">Summary</h2><ul><li>"Setting up event-based metrics is something that's super important very early in your company, because it's how you know whether your product is being used or not. And it's the number one source of new product ideas and inspiration." - Michael Seibel</li><li>Google Analytics by itself is insufficient to figure out how your users are using your product, although it is useful to complement an event-based analytics tool.</li><li>Event-based analytics help you figure out what actions a user took on your website.</li><li>We are primarily focused on evaluating the three main event-based analytics tools: Mixpanel, Amplitude, and Heap.</li><li>We found that event-based analytics is a category of SaaS with some of the most feature parity.</li><li>The core analytics functionality of all three tools is more or less equivalent.</li><li>The key considerations for an early-stage startup are the amount of maintenance and discipline required to maintain useful analytics, and the ability to go far without spending a lot of money.</li><li>We found that defining events in code while having auto-track as a safety net is a near-ideal setup for an early stage startup.</li><li>We recommend Heap, because it is the only major analytics tool that offers this capability. The main downside for an early-stage startup is that you can't get as far on a free plan on Heap compared to Mixpanel or Amplitude.</li><li>If pricing is the main consideration, then we recommend Amplitude. Even though its product is oriented towards later-stage companies, Amplitude has the most generous free plan of the major event-based analytics providers.</li></ul></summary><h2 id="ratings-matrix">Ratings Matrix</h2><h2 id="context">Context</h2><h3 id="what-is-event-based-analytics">What is event-based analytics?</h3><p>Pageview-based analytics tools like Google Analytics and event-based analytics tools such as Mixpanel, Amplitude, and Heap are typically grouped together under the heading of analytics tools. However, we think that lumping them all under the same heading is misleading, because they fundamentally do different things. To better understand what event-based analytics are, we need to understand what exactly Google Analytics does, figure out where its gaps are, and then use that context to motivate event-based analytics tools. </p><p>Google Analytics uses a pageview-driven paradigm, a holdover from what was important in the early 2000s. Its focus on pageviews helps answer questions such as how many users came to your website, what pages they visited, and how they found your website. Unfortunately, it isn't able to help you figure out which specific actions a user performed on any given page of your website. For example, it doesn't answer whether a user clicked on a CTA button, if they abandoned their cart, how far they got into signing up, or what part of the page they were looking at before they converted. Answering these kinds of questions can be quite informative to early-stage startups' decision-making, and can be accomplished quite easily by using an event-based analytics tool.</p><p>An event-based tool will provide two things: an interface to collect "events", and an interface to analyze those events. You can define and implement your events (commonly referred to as instrumenting) by calling the API of the event-based analytics tool you're using.</p><p>To illustrate, let's say you run an ecommerce store. You want to figure out what types of items people checkout without hesitation, and what types of items often result in abandoned carts. This isn't something that can be accomplished with pageview-based analytics tools such as Google Analytics. However, this can be performed quite easily with an event-based analytics tool. If you track two events — when someone adds something to their cart, and when someone checks out their cart — you can figure out which SKUs lead to a high checkout rate, and which SKUs lead to abandoned carts. This is implemented by calling two functions: </p><ol><li><p>a function <code>track('add-to-cart', {&lt;metadata&gt;})</code>, including metadata about the item added (e.g. SKU, name, price) in your code that executes when someone adds something to cart, and </p></li><li><p>a similar function <code>track('checkout', {&lt;metadata&gt;})</code> in your code that runs when someone checkouts. Data from these events will be sent to your analytics provider, which will provide an interface to analyze and draw conclusions from your data.</p></li></ol><p>This is a simple example, but is already quite a powerful tool to understand your users, and can be easily extended. The same power generalizes beyond an ecommerce store to any startup's web product, helping one answer essential questions such as: Is your CTA convincing? What are the characteristics of products that customers are the most hesitant about buying? What part of the signup process needs to be improved to prevent potential users from dropping off? Which portion of your product page was the most engaging and persuaded customers to take the next step?</p><h3 id="early-stage-startups-and-their-analytics-dilemma">Early-stage startups and their analytics dilemma</h3><p>If event-based analytics are so important for early-stage startups, one might rightly wonder why so many YC startups, whose founders are quite sharp in aggregate, rely primarily on Google Analytics?</p><p>It turns out that this is a rather illuminating question. The main contributor to this phenomenon is easy to understand and empathize with. Startups are busy and overworked, and analytics are often ostensibly seen as orthogonal to the priorities of understanding their users and building product<span></span><span>The <a href="https://blog.ycombinator.com/ycs-essential-startup-advice/">canonical priorities</a> for early-stage startups.</span>. Therefore, event-based analytics often fall to the wayside as they typically require engineering time and discipline to maintain. If you forget to update an event, or don't have time to implement analytics for a new feature, then you can't get any benefit out of it at all.</p><p>Yet, in reality, event-based analytics are one of the best sources of new product insights and inspiration and are a fantastic way to understand how your users are using your product. This is one of our main motivations for writing this particular guide. Early-stage startups have a unique set of challenges to face, particularly around prioritizing their time and engineering resources. That said, we think that there's an approach that can make event-based analytics require a lot less discipline, and therefore make it a lot more attainable for an early-stage startup.</p><h2 id="methodology">Methodology</h2><p>Based on a few years of first-hand experience using and testing event-based analytics tools, in addition to aggregating feedback from other founders, we have found the following factors matter most for early-stage startups choosing an analytics tool:</p><ul><li><p><strong>Core Analytics Functionality</strong> refers to the standard analytics features that are critical for an early-stage startup to understand their users. These include standard analysis tools, such as funnel analysis (i.e. figuring out when users drop out in each step of a process), retention analysis (i.e. figuring out how many users churn, and when), and cohort analysis (i.e. figuring out how different user segments interact with your product). </p></li><li><p><strong>Robustness / Ease of Maintenance:</strong> Early-stage startups need to use analytics just as much as larger companies, but also have to be a lot more resourceful and focused with their time and energy. What happens if you change a component, and don't update the tracking code? What happens if you're under time pressure from a customer and make the conscious decision to launch a complex product without tracking? While large companies have the ability to implement strict QA processes and are okay with extended deadlines, early-stage startups don't have these options. Therefore, we've kept a close eye out for how each analytics tool performs under less-than-ideal situations.</p></li><li><p><strong>Affordability:</strong> Web analytics tools are somewhat notable/notorious for giving generous free plans, attaining lock-in, and then making things more expensive once your company starts becoming successful <span></span><span>This is one of the reasons why <a href="#consider-using-segment-as-a-wrapper">we suggest using Segment</a>, since it helps you avoid vendor lock-in and gives you more negotiating power.</span>. That said, several analytics tools have generous free tiers or deals that can last you quite a long time without paying. Therefore, we've split this criterion into two subcriteria: <strong>How far you can get without paying</strong>, and <strong>Paid Plan Affordability</strong>. The latter is actually somewhat non-trivial to evaluate, because most analytics providers hide their pricing behind a Contact Us gate, even for early-stage startups. That said, we got our hands on a decent amount of data on the actual cost of each service, and we have also compiled a list of typical discounts and deals that you can reasonably expect to get from each analytics provider.</p></li><li><p><strong>Ease…</strong></p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://satchel.com/web-analytics/">https://satchel.com/web-analytics/</a></em></p>]]>
            </description>
            <link>https://satchel.com/web-analytics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375148</guid>
            <pubDate>Thu, 10 Dec 2020 16:06:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A typical day as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375100">thread link</a>) | @karlhughes
<br/>
December 10, 2020 | https://www.karllhughes.com/posts/engineering-manager | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/engineering-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/engineering-manager-time.png" alt="A Day in the Life of an Engineering Manager">
</p> 

<p>
2020, Nov 01&nbsp;&nbsp;&nbsp;—&nbsp;
7 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>During the eight years I spent as an engineering manager, I regularly tracked how I spent my time. As a startup engineering manager, I was responsible for a wide range of duties, so keeping track of which areas I spent the most time on helped me plan and schedule appropriately.</p>
<p>For example, I knew that I typically spent about 1/3rd of my time helping my team solve technical problems or pairing with teammates. Knowing this, I reserved some free blocks of time for them. If my whole week were full of meetings and big-picture planning, I’d become a blocker for my team who needed my input on specific issues.</p>
<p>Since many prospective software engineering managers ask me about my job and what it entails, I decided to create this detailed look at how I spent my time. While every company and role is different, I hope this post gives you some first-hand insight into a day in the life of an engineering manager.</p>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="what-does-an-engineering-manager-do">What Does an Engineering Manager Do?</h2>
<p>First, a little bit about my roles as an engineering manager: my first management role was at <a href="https://www.packback.co/">Packback</a>, a question and answer platform for college professors.</p>
<p>I joined the team when there were just four people in the company - it was essentially myself and the founders. In the intervening three years, I saw the company raise close to $5 million and grow to almost 30 people. My engineering team was pretty lean - there were five when I left in 2016 - but my role changed quite a bit over my years with the company.</p>
<p>After <a href="https://www.karllhughes.com/posts/joining-the-graide-network">I left Packback to join The Graide Network</a>, I started over as an engineering manager. Initially, my team was just a contractor and me, but over my four years at Graide, I <a href="https://www.karllhughes.com/posts/hiring-process">hired three other engineers</a> and <a href="https://www.karllhughes.com/posts/product-management-process">took on more of the product management duties</a>.</p>
<p>While my day-to-day work changed a lot over the years, <strong>as a software engineering manager, I was ultimately responsible for helping my team ship software that worked as expected on schedule and within budget.</strong></p>
<p>The tricky word there is “helping.” What does that mean exactly? Does it mean that an engineering manager writes code? Or do they just make sure everyone on their team is writing code?</p>
<p>The short answer is: it depends.</p>
<h3 id="engineering-managers-must-be-technical">Engineering Managers Must be Technical</h3>
<p>Generally, engineering managers write less code than the senior developers on their team, but <a href="https://medium.com/swlh/do-engineering-managers-need-to-write-code-d89903d68e8d">they should write some code to keep their skills sharp</a>. They also need to be good at helping their team members get “unstuck.” Sometimes this means answering technical questions, and sometimes it means solving disputes between team members.</p>
<p>They’re likely to play a role in <a href="https://www.karllhughes.com/posts/developing-talent">training new engineers</a> as well as evaluating candidates on a technical and interpersonal basis.</p>
<h3 id="engineering-managers-have-to-be-good-with-people">Engineering Managers Have to be Good with People</h3>
<p>Being “good with people” is a tough label to nail down.</p>
<p><img src="https://i.imgur.com/e7ML5PR.gif" alt="I have people skills! - Office Space"></p>
<p>Many people assume that you have to be an extrovert to be an effective manager, <a href="https://www.inc.com/john-brandon/are-extroverts-the-best-leaders-maybe-not.html">but that’s not necessarily true</a>. Having empathy for your team and helping them through challenges - both technical and personal - is one of an engineering manager’s primary mandates.</p>
<p>But, engineering managers have to “manage up” as well. This means they need to look out for their team’s best interests when their boss asks them for feedback, and it means they might have to let a team member go if they’re not getting the job done.</p>
<h3 id="the-hardest-part-about-engineering-management">The Hardest Part About Engineering Management</h3>
<p>As I moved into my first management role, the most challenging part was adjusting my method for self-evaluation. Nickolas Means says it well in his <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">fantastic piece on meta productivity for managers</a>:</p>
<blockquote>
<p>“Every so often, I have a day where I look up after the last meeting has ended and feel like I’ve gotten absolutely nothing done. I’ve been busy all day long: having conversations, reading documents, and checking in with peers and team members. I’m exhausted, but I’ve accomplished nothing.” - Nickolas Means</p>
</blockquote>
<p>It was <em>relatively</em> easy for me to tell how productive I had been as a software engineer. I usually made progress on shipping a feature or opened up a pull request, but as a manager, I had a really hard time telling whether my day was productive or not.</p>
<p>That’s why I started tracking my time. While time spent on a task is not a perfect measurement of productivity, it helped me make sure I was investing enough time into each area of my job.</p>
<h2 id="how-does-an-engineering-manager-spend-their-time">How Does an Engineering Manager Spend Their Time?</h2>
<p>Engineering managers tend to have a wide range of responsibilities, and these responsibilities vary based on the employer’s size and organizational structure. To help you see how an engineering manager spends their time, I broke my time down into four categories:</p>
<ul>
<li><strong>Technical</strong> (35%)</li>
<li><strong>Managerial</strong> (35%)</li>
<li><strong>Recruiting</strong> (15%)</li>
<li><strong>Administrative</strong> (15%)</li>
</ul>
<p>In this section, you’ll see how I spent my time as an engineering manager. I’ll offer a little bit about the specific tasks encompassed in each area and why it was an important part of my daily work.</p>
<p>While I tracked my time pretty rigidly for periods of my 8-year management career, I decided to round each category to a nice round number for the sake of simplicity. Exact hours spent on each task aren’t the point here, but I found it helpful to know if one area spiked in one week or dropped sharply in another.</p>
<p><img src="https://i.imgur.com/Tx9pTaz.png" alt="engineering-manager-time"></p>
<h3 id="technical">Technical</h3>
<p><em>35% of my time.</em></p>
<p>Technical work includes writing code, code reviews, hunting down bugs, pairing with teammates, and reading software updates and best practices. As my teams grew, the amount of time I devoted to writing and reviewing code dwindled, but I do think it’s important for engineering managers to spend at least <a href="http://www.drdobbs.com/architecture-and-design/engineering-managers-should-code-30-of-t/240165174">some of their time elbows deep in the code</a>.</p>
<h3 id="managerial">Managerial</h3>
<p><em>35% of my time.</em></p>
<p>This includes direct people management, creating timelines, strategic planning, and meetings with technical and non-technical team members. Making sure my team was happy, advocating for them in business meetings, and helping our product team create technical specs were all part of my engineering manager duties at Packback.</p>
<p>At The Graide Network, I took a more strategic role by consulting with the founders on software choices and jumping in on important sales calls. Interestingly, while the tasks I took on were different, the time breakdown was pretty similar.</p>
<h3 id="recruiting">Recruiting</h3>
<p><em>15% of my time.</em></p>
<p>Recruiting time included going to conferences, meetups, and coding bootcamps, writing blog posts, meeting with job candidates, and evaluating technical screenings.</p>
<p>While I spent more of my time on recruiting when I had an open engineering job, smart engineering managers are <em>always</em> hiring. The best candidates are usually the passive ones who rarely look for a job, so I spent a portion of my time getting in front of them each week.</p>
<h3 id="administrative">Administrative</h3>
<p><em>15% of my time.</em></p>
<p>Finally, I spent a few hours per week reading and writing emails, answering questions in Slack, random conversations, and “other” day-to-day things to support my team. As the manager, I tried to keep these kinds of distractions away from my engineering team, but I’d schedule time with team members when necessary.</p>
<p>If an engineering manager’s job is to make their team as productive as possible, it stands to reason that most of the administrative work will fall to them.</p>
<h2 id="what-makes-a-good-engineering-manager">What Makes a Good Engineering Manager?</h2>
<p>I don’t think I can give you <em>everything</em> you need to know about being a good engineering manager in just one blog post (<a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some good books on the topic though</a>), so I’ll just pick the three things that I focus on first.</p>
<h3 id="1-empower-your-team">1. Empower Your Team</h3>
<p>Being a good manager is all about <a href="http://www.jrothman.com/articles/1999/01/successful-engineering-management-7-lessons-learned/">helping others achieve great things</a>.</p>
<p>This means that as a manager, your <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">impact is much less direct</a>, and therefore, you can’t spend all your time heads down in the code. It was frustrating for me to see my weekly accomplishments list shrink, but once I learned to accept that my team was getting more done without my individual contributions, I started to really enjoy the role.</p>
<h3 id="2-overcommunicate">2. Overcommunicate</h3>
<p>Whether your team is working in one room or working <a href="https://www.karllhughes.com/posts/managing-remote-engineering">remotely across the world</a>, communication is one of your most crucial roles as a manager. In marketing, there’s an idea that <a href="https://www.linkedin.com/pulse/its-nagging-repetition-effective-communication-marton-jojarth/">people must hear your message seven times before they internalize it</a>, and I think this applies to team communication as well.</p>
<p>I’m not saying you should repeat everything seven times in the same meeting, but think about reiterating significant changes in one-on-ones, group settings, via email, and in passing. Change is scary, but the more people hear about something, the less scary it tends to be.</p>
<h3 id="3-be-the-source-of-calm">3. Be the Source of Calm</h3>
<p>Finally, as the engineering manager, your role is to “<a href="https://staysaasy.com/management/2020/07/07/dont-create-chaos.html">vacuum up chaos</a>:”</p>
<blockquote>
<p>“Any room that you enter should have more certainty and a firmer plan by the time that you leave it. Good leaders can walk into a situation where people have lost track of their goals and get everyone aligned on a clear path forward.”</p>
</blockquote>
<p>Don’t create or perpetuate drama, divide your team from the rest of the company, or pit team members against each other. Instead, be the one who absorbs uncertainty and stress so your team can get sh** done.</p>
<hr>
<p>If you’re an aspiring engineering manager or you’re just wondering what your boss does all day, I hope this helps you.</p>
<p>Interested in more great reading material? Here are some of the <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">books that helped me on my journey to become an engineering manager</a>.</p>

<section id="mc_embed_signup">

</section>
</div> 
</article> 
</section></div>]]>
            </description>
            <link>https://www.karllhughes.com/posts/engineering-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375100</guid>
            <pubDate>Thu, 10 Dec 2020 16:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Justice Against a Cable Company: Step-by-Step]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375034">thread link</a>) | @KaiserSanchez
<br/>
December 10, 2020 | https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/ | <a href="https://web.archive.org/web/*/https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            <section>
                <div>
                    <p><span><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" alt="" width="500" height="286" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">How many times have you heard someone in your life </span><a href="https://fairshake.com/consumer-news/comcast-customer-service-complaint/"><span>complaining about their cable company</span></a><span>?</span></p>
<p><span>Even worse, how many times have </span><i><span>you</span></i><span> been the one complaining about a cable provider?</span></p>
<p><span>Complaints about cable companies might sound like cliches. But cable providers aren’t like the DMV or the post office —&nbsp;services that draw a lot of consumer ire but ultimately tend to be doing their best to get their jobs done. On the contrary, cable companies have actually been </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash/"><span>caught engaging in a lot of shady behaviors</span></a><span> that fully justify their customers’ complaints.</span></p>
<p><span>But what if you want to take your dispute with your cable company further than your watercooler chat? What do you do if you have a legitimate complaint about your cable company that you need resolved? Where do you go if you need help getting justice against a cable company that’s gone beyond just providing an unpleasant customer service experience —&nbsp;but has actually wronged you?</span></p>
<p><span>These are questions that a lot of consumers have, and we’re here to help. In this article, we’ll discuss some of the common reasons people might want to seek justice against their cable companies. Then, we’ll explain, step-by-step, how to file a complaint against a cable company, and point you toward some resources that will be on your side if you need help getting justice.&nbsp;</span></p>
<h2><span>Why Do So Many People Have Complaints About Their Cable Companies?</span></h2>
<p><span>Let’s start at the beginning: Why do so many people complain about cable companies? And, more importantly, are people complaining about just annoyances, or actual injustices?</span></p>
<p><span>The American Consumer Satisfaction Index </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=148&amp;Itemid=213"><span>surveys consumers</span></a><span> and scores industries based on how well they provide satisfactory services at fair prices. Consistently, year after year, the cable TV industry ranks lowest out of the dozens of industries the ACSI tracks.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" alt="Graph of American Consumer Satisfaction Index Scores for the Cable TV Industry" width="2022" height="1825" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>In 2020, the cable industry has scored </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=149&amp;catid=&amp;Itemid=212&amp;i=Subscription+Television+Service"><span>64 out of 100 points on the ACSI index</span></a><span>, which is actually a 3.2 percent increase over last year. But the industry still has the lowest score in the ACSI rankings, reflecting more dissatisfied customers than ISPs, cell phone providers, online news media, and many other industries that consumers love to complain about. Additionally, this year is the first time since 2016 that the cable industry saw an increase in its ACSI ranking.</span></p>
<p><span>ACSI rankings aren’t even the worst evidence against the cable industry, though.</span></p>
<p><span>News reports reveal that some of what cable companies have been up to goes beyond just bad customer service. For example,</span></p>
<ul>
<li><span>Some AT&amp;T customers found they were </span><a href="https://fairshake.com/consumer-news/att-overcharging-customers-complaints"><span>being charged three times the rate</span></a><span> the company promised them. The situation was so bad, one legal expert called AT&amp;T’s policies “a license to steal.”</span></li>
<li><span>Comcast </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash"><span>wrongly charged a small business owner $1,800 in cancelation fees</span></a><span>, and then spent </span><i><span>two years</span></i><span> fighting against returning that wronged customer’s money.</span></li>
<li><span>Cox employees were found to be </span><a href="https://wjla.com/features/7-on-your-side/cox-communications-complaints-fake-accounts"><span>creating customer accounts without permission</span></a><span> so they could charge users more.</span></li>
<li><span>Optimum got caught advertising a $99 promotion rate, but </span><a href="https://www.thehour.com/business/article/After-profitable-2017-Altice-USA-hikes-Optimum-12885236.php"><span>actually billed users more than $160 for it</span></a><span>.</span></li>
<li><span>DirecTV </span><a href="https://fairshake.com/consumer-news/feds-sue-direct-tv-claim-money"><span>broke its contracts with 33 million customers</span></a><span> by wrongly raising their rates.</span></li>
</ul>
<p><span>These are just some examples of how cable companies have done shady (or even outright illegal) things to their customers. In all these cases (and any others like them), the customers deserve justice. But it can be difficult to figure out how to get it.</span></p>
<h2><span>How to File a Complaint Against a Cable Company</span></h2>
<p><span>The exact process for filing a complaint might vary from one cable company to the next. For more detailed advice about taking on a specific company, visit our consumer guides.</span></p>
<p><span>But no matter what cable company your dispute is with, there are certain steps you can take to file and escalate your complaint. Here’s what you need to know.</span></p>
<h3><span>Step 1: Contact the Cable Company</span></h3>
<p><span>For anyone who’s suffered through an unproductive customer service call, this probably won’t be welcome news. But any time you have a complaint against a company, before taking it to any outside agencies, you need to try to resolve it with the company itself. This is important, because if you end up escalating your complaint to the FTC, FCC, or a local franchising authority, they’ll expect that you’ve already tried to resolve your dispute with the company directly.</span></p>
<p><span>Some best practices to keep in mind here: Try to address the complaint with your cable company in writing, whenever possible. Email is a great option for this. This ensures that you have a record of exactly what’s said by both parties, and you have proof that you attempted to resolve the complaint directly with the cable company, as well as proof of why that didn’t work.</span></p>
<p><span>If you’ve tried this and your cable company was unable or unwilling to help you reach a resolution, it’s time for step two.</span></p>
<h3><span>Step 2: Find the Right Regulatory Agency</span></h3>
<p><span>If your cable company is unable or unwilling to help you, you can escalate your complaint to a regulatory agency. However, finding the right one can be a challenge.</span></p>
<p><span>Cable companies are overseen by a number of entities: The Federal Communications Commission, the Federal Trade Commission, public utility commissions, and local franchising authorities are the ones that are likely to be most relevant to any dispute you might have. Here’s where this gets complicated: Each of them has different jurisdiction and can only help with certain issues.</span></p>
<p><span>Here’s who you should contact, depending on your complaint.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" alt="Where to File a Complaint against Your Cable Company" width="1881" height="2560" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" sizes="(max-width: 1881px) 100vw, 1881px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<h4><span>Local Franchising Authorities</span></h4>
<p><span>Local franchising authorities are government organizations that regulate cable TV service at a municipal, county, or other local level. You can usually find the name of your local franchising authority on your cable bill. If not, you can contact your cable company or your local town or city hall to request that information.</span></p>
<p><span>Local franchising authorities can help you with these issues:</span></p>
<ul>
<li><span>Rates for basic service and equipment, and service charges related to basic cable.</span></li>
<li><span>Rates for cable service tiers, particularly if rates for your cable service have been increased within the past 90 days.</span></li>
<li><span>Customer service problems, like availability of customer service representatives, office hours, timeliness of service visits, and outages.</span></li>
<li><span>Franchise fees.</span></li>
<li><span>Signal quality.</span></li>
<li><span>Use of public or informational channels that are required as part of your cable company’s franchise agreement.</span></li>
</ul>
<h4><span>Public Utility Commissions</span></h4>
<p><span>In some states, public utility commissions oversee certain issues related to cable or satellite TV services.</span></p>
<p><span>To find out more about your state’s public utility commission, check the </span><a href="https://www.naruc.org/about-naruc/regulatory-commissions/"><span>National Association of Regulatory Utility Commissioners</span></a><span>. If your state has one, PUCs can help you with these issues:</span></p>
<ul>
<li><span>Rates and programming for stand-alone satellite TV services.</span></li>
<li><span>Rates and programming for stand-alone cable TV services (not including basic tier plans).</span></li>
<li><span>Installation of cable or satellite TV services that are not bundled with other services.</span></li>
<li><span>Burial of phone or cable TV wires.</span></li>
</ul>
<h4><span>Federal Communications Commission</span></h4>
<p><span>The FCC is a department of the federal government that exists to regulate businesses and prevent them from taking advantage of or unfairly treating consumers.</span></p>
<p><span>There are a number of ways you can contact the FCC if you have a complaint about a cable company that falls under its jurisdiction. You can visit the </span><a href="https://consumercomplaints.fcc.gov/hc/en-us"><span>FCC Complaint Center</span></a><span> to file your complaint online or get the right information to mail it, or you can call 1-888-225-5322 for information and general questions.&nbsp;</span></p>
<p><span>The FCC can help with these kinds of complaints:</span></p>
<ul>
<li><span>Equal Opportunity Employment complaints.</span></li>
<li><span>Signal leakage that might affect other spectrum users.</span></li>
<li><span>Cable companies that violate rules about home cable wiring.</span></li>
<li><span>Cable companies that violate commercial limits during kids’ programming.</span></li>
<li><span>Indecency or obscenity on a cable TV program.</span></li>
</ul>
<h4><span>Federal Trade Commission</span></h4>
<p><span>And finally, the right entity to receive your complaint might be the FTC, which is another department of the federal government. It has similar goals to the FCC, but oversees different things.&nbsp;</span></p>
<p><span>Also similarly to the FCC, you have a few options for contacting the FTC about your complaint. You can use an </span><a href="https://www.ftccomplaintassistant.gov/"><span>online complaint portal</span></a><span>, or you can reach the agency by phone at 1-877-FTC-HELP.&nbsp;</span></p>
<p><span>Here are some of the types of complaints that would fall under the jurisdiction of the FTC:</span></p>
<ul>
<li><a href="https://fairshake.com/consumer-guides/false-advertising-and-misleading-marketing/"><span>False advertising</span></a><span>.</span></li>
<li><span>Deceptive business practices.</span></li>
<li><span>Scams.</span></li>
<li><span>Problems with debt collection.</span></li>
</ul>
<h2><span>What to Expect After Filing a Complaint Against a Cable Company</span></h2>
<p><span>After filing a complaint with any of the entities listed above, you might be wondering what comes next. The answer, unfortunately, is that it depends.</span></p>
<p><span>Regulatory agencies, particularly at the federal level, will typically investigate a company if they receive complaints about it. If they find that the company did, in fact, do something wrong, they may impose fines or other punishments. But typically, a federal agency like the FTC or the FCC </span><a href="https://fairshake.com/consumer-guides/getting-your-refund/"><span>won’t help you get a refund</span></a><span>, get charges reversed, or get justice in any other, similar way. For that, you have other resources.</span></p>
<h2><span>How to Get Justice Against a Cable Company</span></h2>
<p><span>If resolving your dispute means getting a refund, a zero balance, other compensation, or some other form of justice, you might feel like you have a long, uphill road to climb.</span></p>
<p><span>Most cable companies have clauses built into their contracts that say you can’t sue them, unless it’s in small claims court. But what you can do is </span><a href="https://fairshake.com/how-it-works/"><span>take advantage of consumer arbitration</span></a><span>.</span></p>
<p><span>Arbitration works a little bit like small claims: You’ll send a legal demand to your cable company, and then collect any evidence you have and present it to an independent third party, or arbitrator. The arbitrator will hear both sides of the dispute and make a legally binding decision.</span></p>
<p><span>But even that might sound overwhelming. And if you’ve never been through the process of arbitration before, we don’t blame you if you feel intimidated by the paperwork, the process, or just the thought of taking on a big company with major legal resources.</span></p>
<p><span>So let us help. </span><a href="https://fairshake.com/"><span>Fai…</span></a></p></div></section></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</a></em></p>]]>
            </description>
            <link>https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375034</guid>
            <pubDate>Thu, 10 Dec 2020 15:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Corporate Innovation]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375013">thread link</a>) | @nicotesla
<br/>
December 10, 2020 | https://blog.codelitt.com/corporate-innovation/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/corporate-innovation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
      

      
      <section id="Post__Main-Content">
        <div>
          <h2 id="discovering-the-problem">Discovering the Problem</h2><p>Startups are swallowing corporations' markets. This is mainly because corporations struggle with innovation, regardless of how much they use that word in press releases and PPT presentations. About 7 years ago we started <a href="http://www.codelitt.com/">Codelitt</a>, a corporate skunkworks and product incubator company. We build startups for corporations and invest 20% of our time in building products, tools, and <a href="https://github.com/codelittinc">open source projects</a> for the web. </p><p>In the beginning, we didn't set out to discover a specific problem. Put another way, we weren't being purposeful about searching for a problem to solve. This post is half about the problem with corporate innovation and half about our discovery process that led us to where we are today:</p><h2 id="eye-opening">Eye-opening</h2><p>In the beginning of my career I worked for investors in Latin America helping to build and launch startups before later moving to corporate America. Although I'm often critical of corporate culture, it was really eye opening and integral to my career. Really this is one of the best pieces of advice I can give to entrepreneurs looking for problems to solve:</p><blockquote>If you are smart and ambitious but can't find a problem to solve, go work for a large (preferably traditional) corporation. You'll find plenty there.</blockquote><p>Large enterprises succeed <em>in spite</em> of themselves. It really is a wonder that they get anything done at all. I can't speak for every single large company, but I've worked with quite a few. In one way or another they all have systemic issues. This is not to say that startups or more modern tech companies don't have their own issues. We do. But the proof is in the pudding and startups are launching products monthly that will take a huge chunk of traditional companies' markets or even render them completely irrelevant.</p><p>Some large enterprises have realized that their biggest threat isn't another corporate giant, it's some unknown kid building something. In order to compete, they have to create new value, do a little disruption of their own, and start shipping.</p><blockquote>However, traditional companies spend millions in R&amp;D and take several years to come to market.</blockquote><p>So the question is, why are they at such a disadvantage when their seemingly endless budgets should afford them a solid advantage? The answer is that the same tools, systems, and culture that they rely on to manage their large organization don't work for innovation and skunkworks teams.</p><h2 id="decisions-by-consensus">Decisions by Consensus</h2><p>Traditionally the vast majority make decisions by consensus. Note: there is a difference between collaboration and consensus. Collaboration takes different points into account but can still have one decision maker, whereas consensus decision making requires every single person to have input and be onboard. This is crippling to organizations. Teams should have a single decision maker.</p><p>Any startup who has experienced the sales cycle of a large company can attest to this first hand. While many sales people focus on identifying "the decision maker level," this person is rarely the only decision maker and they'll likely have an entire team to convince. When making a sales pitch (even for a $1,000 a month SaaS product) you'll very likely spend time in a room of 12 or so people from different areas of the company. Most of those people will likely have different needs and agendas. The same is true when it comes to developing new products, processes, or strategy. Decision making time is multiplied by an exponential factor.</p><blockquote>In the time it takes a large organization to make a decision just to move forward with something, a startup could have built, launched, and validated a new feature or model.</blockquote><h2 id="corporate-it">Corporate IT</h2><p>There are a number of reasons why normal innovation processes, product prototyping, and building new business models is so costly inside a large organization. Time is a huge factor. A close second is the cost of actual development. As with everything, I'm sure there are reasons for why things are done the way they are done. But from a product development perspective and coming from the startup world, they are nearly impossible to understand.</p><p>Corporate IT departments have a hard time looking at a product as something that develops. They see a project as having a start date, an end date, and a full set of features. There is no iterative development. They plan for every possible scenario and build to the full spec. Version releases begin with 1.0.0 launch and following releases are security patches at best.</p><p>Instead of using open source tools, large IT teams are locked in to Microsoft and Oracle products. I've never been able to understand why this is completely. It could be the fact that they spend a solid chunk of time earning Oracle or Microsoft Certifications. It could be the comfort of having support just a phone call away. Or it could even be an unwillingness to learn something new. </p><p>From a security perspective, it's like looking for a babysitter to watch your kids, asking for her recommendations, and she tells you, "Just trust me. I promise your child is secure. But just so you know, we'll be doing things my way; your house rules don't apply."</p><p>From a time perspective, there are open source technologies that allow you to whip up an MVP in much less time. Even with complaints about Rail's "magic under the hood," you can't deny that it's a powerful tool to quickly build a prototype.</p><p>From a cost perspective, licenses are expensive and they add up quickly. Millions of dollars are spent on IT licensing every year by large orgs. Imagine if that money was spent on employing core devs for the respective clients like we've seen with Red Hat, Bitpay, and Google.</p><blockquote>Developing a new product or business can often cost millions to develop with the traditional IT infrastructure and business processes. Timelines, again, are measured in years, not weeks.</blockquote><h2 id="risk-averse">Risk-averse</h2><p>The final piece to the puzzle which impedes progress and innovation is often a risk-averse nature. Being risk-averse is 'consultant speak' inside a large organization. Entire teams are dedicated to mitigating risk. I've heard a lot of different theories for why this is from insiders and outsiders over the years:</p><p><strong>Job security</strong> is one that gets floated around a lot. The 25 year Rolex, the benefits, and the cushy salary really don't require a whole lot. Don't upset the status quo, don't argue with the wrong people, play the politics, and work well with others. Do those 4 things and you have very little to worry about. Large companies rarely fire people who do those things. It's easy for anyone to become complacent when basic needs are taken care of. Unfortunately for them however, disruption requires risk. There's always the risk of being wrong. Being wrong is rarely celebrated in corporate culture and that stigma can follow someone around for the rest of their career preventing any sort of upward mobility. In our world, many of us have failed a few times, succeeded a couple, and worked for several companies. Our entire attitude towards failure and opportunity is a completely different perspective.</p><p>Another is the <strong>high visibility</strong> that corporations have in the public eye. Because of their size, most things they do are considered <a href="http://www.mediacollege.com/journalism/news/newsworthy.html">newsworthy</a> due to the impact it could have on their customers, employees, or investors. In the startup world, we have the luxury of being able to fail relatively quietly. Our customers and beta users are usually very understanding of certain degrees of failures to the point they even expect them. Remember those corporate departments dedicated to risk management? These often include legal, public relations, and marketing communications teams. They all have the responsibility to keep the public face of the company as free from blemishes as possible.</p><blockquote>Disruption requires risk. No great invention, change, or innovation ever came from doing the same thing over and over. <a href="https://blog.codelitt.com/not-innovating/">You have to be ready to break things along the way</a>.</blockquote><h2 id="their-disadvantage">Their Disadvantage</h2><p>When you begin to understand the issues that are faced by teams tasked with innovation projects, skunkworks programs, or disrupting old models you can see how simple objectives for us turn into difficult ones for them. While many of us perhaps envy their resources, they're actually at a huge disadvantage to us in every other way. They have a massive problem, one that we set out to solve:</p><blockquote>For them innovation, product development, and skunkworks is expensive, slow, regulated, ineffective, and swimming against the current.</blockquote>
        </div>
      </section>


        <div>
  <h3>Stay up to date!</h3>
  <p>
    Get all the latest &amp; greatest information delivered straight to your inbox
  </p>

  
</div>

    </article>
  </div></div>]]>
            </description>
            <link>https://blog.codelitt.com/corporate-innovation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375013</guid>
            <pubDate>Thu, 10 Dec 2020 15:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CentOS Stream, or Debian?]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25374783">thread link</a>) | @pabs3
<br/>
December 10, 2020 | https://jonathancarter.org/2020/12/10/centos-stream-or-debian/ | <a href="https://web.archive.org/web/*/https://jonathancarter.org/2020/12/10/centos-stream-or-debian/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>It’s the end of CentOS as we know it</strong></p><p>Earlier this week, the CentOS project announced the shift <a href="https://blog.centos.org/2020/12/future-is-centos-stream/">to CentOS stream</a>. In a nutshell, this means that they will discontinue being a close clone of RHEL along with security updates, and instead it will serve as a development branch of RHEL.</p><p>As you can probably imagine (or gleam from the comments in that post I referenced), a lot of people are unhappy about this.</p><p>One particular quote got my attention this morning while catching up on this <a href="https://lwn.net/Articles/838889/">week’s edition of Linux Weekly News</a>, under the distributions quotes section:</p><blockquote><p>I have been doing this for 17 years and CentOS is basically my life’s work. This was (for me personally) a heart wrenching decision. However, i see no other decision as a possibility. If there was, it would have been made.</p><cite><a href="https://lwn.net/Articles/839521/">Johnny Hughes</a></cite></blockquote><p>I feel really sorry for this person and can empathize, I’ve been in similar situations in my life before where I’ve poured all my love and energy into something and then due to some corporate or organisational decisions (and usually poor ones), the project got discontinued and all that work that went into it vanishes into the ether. Also, 17 years is really long to be contributing to any one project so I can imagine that this must have been especially gutting.</p><p><strong>Throw me a freakin’ bone here</strong></p><p>I’m also somewhat skeptical of how successful CentOS Stream will really be in any form of a community project. It seems that Red Hat is expecting that volunteers should contribute to their product development for free, and then when these contributors actually want to use that resulting product, they’re expected to pay a corporate subscription fee to do so. This seems like a very lop-sided relationship to me, and I’m not sure it will be sustainable in the long term. In <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat’s announcement of CentOS Stream</a>, they kind of throw the community a bone by saying “In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases”- it seems likely that this will just be for experimental purposes similar to the <a href="https://insider.windows.com/">Windows Insider program</a> and won’t be of much use for production users at all.</p><p>Red Hat does point out that their <a href="https://developers.redhat.com/products/rhel/ubi">Universal Base Image</a> (UBI) is free to use and that users could just use that on any system in a container, but this doesn’t add much comfort to the individuals and organisations who have contributed huge amounts of time and effort to CentOS over the years who rely on a stable, general-purpose Linux system that can be installed on bare metal.</p><p><strong>Way forward for CentOS users</strong></p><p>Where to from here? I suppose CentOS users could start coughing up for RHEL subscriptions. For many CentOS use cases that won’t make much sense. They could move to another distribution, or fork/restart CentOS. The latter is already happening. One of the original founders of the CentOS project, Gregory Kurtzer, is now working on <a href="https://rockylinux.org/" data-type="URL" data-id="https://rockylinux.org/">Rocky Linux</a>, which aims to be a new free system built from the RHEL sources.</p><p>Some people from Red Hat and Canonical are often a bit surprised or skeptical when I point out to them that binary licenses are also important. This whole saga is yet another data point, but it proves that yet again. If Red Hat had from the beginning released RHEL with free sources and unobfuscated patches,  then none of this would’ve been necessary in the first place. And while I wish Rocky Linux all the success it aims to achieve, I do not think that working for free on a system that ultimately supports Red Hat’s selfish eco-system is really productive or helpful.</p><p>The fact is, Debian is already a free enterprise-scale system already used by huge organisations like Google and many others, which has stable releases, LTS support and ELTS offerings from external organisations if someone really needs it. And while RHEL clones have come and gone through the years, Debian’s <a href="https://www.debian.org/social_contract">mission and contract to its users</a> is something that stays consistent and I believe Debian and its ideals will be around for as long as people need Unixy operating systems to run anywhere (i.e.  a very long time).</p><p>While we sometimes fall short of some of our technical goals in Debian, and while we don’t always agree on everything, we do tend to make great long-term progress, and usually in the right direction. We’ve proved that our method of building a system together is sustainable, that we can do so reliably and timely and that we can collectively support it. From there on it can only get even better when we join forces and work together, because when either individuals or organisations contribute to Debian, they can use the end result for both private or commercial purposes without having to pay any fee or be encumbered by legal gotchas.</p><p>Don’t get caught by greedy corporate motivations that will result in you losing years of your life’s work for absolutely no good reason. Make your time and effort count and either contribute to Debian or give your employees time to do so on company time. Many already do and reap the rewards of this, and don’t look back.</p><p>While Debian is a very container and virtualization friendly system, we’ve managed to remain a good general-purpose operating system that manages to span use cases so vast that I’d have to use a blog post longer than this one just to cover them.</p><p>And while learning a whole new set of package build chain, package manager and new organisational culture and so on can be uhm, really rocky at the start, I’d say that it’s a good investment with Debian and unlikely to be time that you’ll ever felt was wasted. As Debian project leader, I’m personally available to help answer any questions that someone might have if they are interested in coming over to Debian. Feel free to mail leader_AT_debian.org (replace _AT_ with @) or find me on the oftc IRC network with the nick <em>highvoltage</em>. I believe that together, we can make Debian the <em>de facto</em> free enterprise system, and that it would be to the benefit of all its corporate users, instead of tilting <em>all</em> the benefit to just one or two corporations who certainly don’t have your best interests in mind.</p></div></div></div>]]>
            </description>
            <link>https://jonathancarter.org/2020/12/10/centos-stream-or-debian/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374783</guid>
            <pubDate>Thu, 10 Dec 2020 15:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-off scripts: DevOps last mile]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374731">thread link</a>) | @andriosr
<br/>
December 10, 2020 | https://andrios.co/articles/oneoffs | <a href="https://web.archive.org/web/*/https://andrios.co/articles/oneoffs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Companies chasing DevOps have an internal team dedicated to automation. Developers use tools built by this team to run and operate their code. They have many names, but let’s call them Platform, which most companies do.</p><p>Platform teams create abstractions on top of the infrastructure. The goal is to increase developer speed and make systems reliable. They increase speed by simplifying infrastructure APIs and reliability by automating manual tasks. <strong>Automation lowers the risk of service disruptions, but companies aren’t automating the highest-risk tasks.</strong></p><p><strong>What should we automate?</strong></p><p>We used to ship software by accessing servers and running commands inside boxes to pull new code. Now code goes from Git to servers without human intervention. Developers define what they need with code. Platform teams build the tools to make code changes become running systems.</p><p>The goal is doing this for everything, from business code to infrastructure like networking, databases, and queues. But this is hard. Platform teams have a lengthy backlog; they focus on items demanded with higher frequency.</p><p>Developers make manual changes for things not yet automated. Some companies have compliance, regulations, and other constraints. <strong>It’s hard to get developers direct access to production. So they have the Platform team running these changes for developers.</strong></p><p>It’s what makes the higher frequency items get priority. Engineers want to write software, not run repetitive manual tasks. But this backlog is never decreasing. The business changes and adopts new technologies. Headcount grows, adding new items to the automation backlog. And this mysterious type of task is always left behind.</p><p><strong>One-offs.</strong></p><p>Sometimes a bug in software messes with a customers' money, time, health, or ego. They won’t wait for three iterations of code reviews, tests, code analysis, and gradual rollouts. It takes time. Someone will access the database and update it. These are one-off scripts. <strong>They solve a problem for one or a few customers before the team creates a definitive fix.</strong></p><p>One-off scripts have a terrible reputation. When this happens too much, it’s a sign that the software is not stable. In the ideal world, it would never happen. Engineers would spot such time-critical problems during the design and code review phases. Production issues should be light and wait for regular software delivery flow.</p><p>Almost every company lives under the illusion that one-offs should not exist. Or that they will stop happening at some point. Yes, one should not do this every day. <strong>But having a few senior engineers run manual scripts in production because it’s an exceptional case is a mistake.</strong></p><blockquote><p>Almost every company lives under the illusion that one-offs should not exist.</p></blockquote><p><strong>Am I doing one-offs?</strong></p><p>Here are some common one-off solutions companies use in production:</p><ul><li>Call Raketasks using Rails console.</li><li>Use IEx to call Elixir functions.</li><li>Exec into servers/containers/pods and make localhost calls to an HTTP API</li><li>Make DML queries against the database.</li><li>Run bash/Python scripts through VPNs.</li></ul><p><strong>A myth.</strong></p><p>One-offs won’t go away, and companies need to embrace it. Avoiding them will drive the company to the wrong path. Centralizing execution with experienced engineers; or creating a team dedicated to analyzing and running them isn’t reasonable. It’s the opposite of DevOps.</p><blockquote><p>One-offs won’t go away, and companies need to embrace it.</p></blockquote><p>Most big companies solve this problem with a slow and manual Change Management workflow. Developers find the problem and add a script to a ticketing system. <strong>Someone from the operations team runs it without all the context</strong> of what she is doing. Avoiding one-offs is the shortest path to this model.</p><p><strong>What about Runbooks?</strong></p><p>Runbooks are great. Tools like <a href="https://www.rundeck.com/" target="_blank" rel="noreferrer noopener">Rundeck</a>
and <a href="https://stackstorm.com/" target="_blank" rel="noreferrer noopener">StackStorm</a>
automate fixing problems you know exist. They remove manual operations for routine tasks. But 1) creating Runbooks takes time, and 2) Runbook tools focus on infrastructure. One-off solutions need a faster track and application layer changes.</p><p>One-offs are the most challenging piece to automate. When you don’t know what problems will happen, it’s hard to build a solution upfront. Few companies I know 1) embrace one-offs, and 2) and try to automate them.</p><p><strong>For unknown unknowns, pre-existing solutions won’t work.</strong> The automation supporting this flow needs to be open-ended. The fastest is using direct access to resources and running ad-hoc solutions manually. But we can do better. It won’t get to the level of regular code, but we can get close.</p><blockquote><p>When you don’t know what problems will happen, it’s hard to build a solution upfront.</p></blockquote><p><strong>Isn’t this a bad incentive?</strong></p><p>A common misconception about one-offs is that formalizing them will increase their usage. They are faster to build than regular code. So it makes sense to think developers will prefer them over traditional pipelines. But this couldn’t be further from the truth. <strong>By making one-offs first-class citizens, you start to measure them. You can only change what you measure.</strong></p><p>One-offs must link to tasks with definitive fixes. Teams running them too much should decrease the number of features in the next sprint. Product prioritization should take into account what types of one-offs happen the most. All this is only possible with measurements. There is no upside in making one-offs hard to build and run.</p><blockquote><p>There is no upside in making one-offs hard to build and run.</p></blockquote><p><strong>One-offs as first-class citizens</strong></p><p>I built automations to support one-off scripts at previous jobs. It took a few months for the team as we had other duties, and the solution was not perfect. But <strong>developers were happy with the autonomy</strong> to build and run all solutions to their problems. Security and compliance were happier with audit trails &amp; logs. SREs were happy with fewer manual interventions in production. It was hard but paid off.</p><p>Today, I’m the founder of <a href="http://runops.io/" target="_blank" rel="noreferrer noopener">RunOps</a>
, a tool that automates one-offs. It lets you run scripts as if you had direct access to resources. Still, transparent controls and reviews make them safe, compliant, and reliable. It takes minutes to set up, our early users are very excited. Feel free to reach out on<a href="https://twitter.com/andriosrobert" target="_blank" rel="noreferrer noopener"> Twitter</a>
or shoot me an <a href="mailto:first@runops.io" target="_blank">e-mail</a>
to learn more.</p><p>I’m writing a few other articles exploring the topic. Subscribe to get the next in your inbox.</p><br></article></div>]]>
            </description>
            <link>https://andrios.co/articles/oneoffs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374731</guid>
            <pubDate>Thu, 10 Dec 2020 15:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building 5G Edge Clouds for Containers with OpenNebula and AWS Wavelength]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374553">thread link</a>) | @amarti
<br/>
December 10, 2020 | https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/ | <a href="https://web.archive.org/web/*/https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-29317">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_df94ee-55"><div>
<div><p>🌎 OpenNebula’s new <a href="https://opennebula.io/true-hybrid/" target="_blank" rel="noopener noreferrer">True Hybrid Cloud Architecture</a> enables true hybrid and edge cloud computing by combining <strong>public and private</strong> cloud operations with <strong>workload portability</strong> and <strong>unified management</strong> of your IT infrastructure and applications.</p></div>



<div><p>Since the release of version 5.8 ‘Edge’ in February 2019, OpenNebula comes with a number of innovative features that provide organizations with a truly simple way to create and manage <strong>highly distributed cloud infrastructures</strong>. Thanks to these tools—developed in the context of our <a href="https://oneedge.io/">ONEedge</a> initiative—companies can easily deploy and manage remote clusters outside their premises in <strong>cloud and edge locations</strong> that are geographically dispersed or in close proximity to their end-users and customers.</p></div>
</div></div></div>



<p>By using <strong>OpenNebula’s new provisioning tools</strong>, cloud admins can now expand their private clouds in an incredibly flexible way using resources offered by <strong>third-party cloud providers like AWS and Equinix Metal</strong>, incorporating when necessary the distributed dedicated infrastructure they need to satisfy their users’ requirements for fault tolerance, capacity or low latency.&nbsp;</p>



<p>OpenNebula users can <strong>automatically allocate resources when needed</strong>, deploying and controlling edge nodes based on the current demand at those specific geographical locations. This approach simplifies significantly the process of <strong>provisioning and managing edge resources</strong>, without the organization that’s using this solution having to provide or own those underlying resources at all.</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg" alt="" width="750" height="263" srcset="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg 1000w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-300x105.jpg 300w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-768x269.jpg 768w" sizes="(max-width: 750px) 100vw, 750px"></figure></div>



<p>OpenNebula also offers a simple, but powerful approach for <a href="https://opennebula.io/mastering-containers/">running containerized applications and workflows</a>—both <strong>on-premises and on cloud or edge locations</strong>—by directly using Docker official images from the <a href="https://support.opennebula.pro/hc/en-us/articles/360046667892-Using-the-Docker-Hub-Marketplace-to-Deploy-Container-based-Applications">Docker Hub</a> and running them as lightweight <a href="https://opennebula.io/firecracker/">Firecracker</a> microVMs. For those cases where Kubernetes is required or is the best fit, OpenNebula also provides a <a href="https://opennebula.io/certified-kubernetes-appliance/">Certified Kubernetes</a> Virtual Appliance available from the OpenNebula Public Marketplace, although for <strong>Kubernetes deployments at the edge</strong> we normally recommend a lighter solution based on <a href="https://k3s.io/">K3s</a> clusters 😉</p>



<h2>The New AWS Wavelength Service</h2>



<p>Recently, Amazon Web Services (AWS), in collaboration with <strong>Verizon, Vodafone and other 5G telecommunication providers</strong>, has presented its new <a href="https://aws.amazon.com/wavelength/">AWS Wavelength</a> service (read <a href="https://aws.amazon.com/blogs/aws/aws-wavelength-zones-are-now-open-in-boston-san-francisco/">here</a> the full announcement by AWS Chief Evangelist Jeff Barr back in August). <strong>Wavelength Zones</strong> bring AWS compute and storage capabilities and services to the edge of existing 5G networks, embedding AWS hardware and software within their data centers. This enables developers to innovate and build a new class of edge applications that can exploit <strong>high bandwidth and ultra-low latencies</strong> as offered by the new 5G networks.</p>



<figure><p>
<iframe title="AWS Wavelength - Edge Computing for 5G Networks" width="640" height="360" src="https://www.youtube.com/embed/EhMqwPqPzcY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Thanks to AWS Wavelength, application traffic from 5G devices can reach the servers running in Wavelength Zones <strong>without leaving the telecommunications network</strong>, thus avoiding having to traverse multiple hops across the Internet to reach their final destination, as it happens with a traditional approach based on a centralized cloud solution. This new service enables both developers and end-users to finally take full advantage of the latency and bandwidth benefits offered by 5G networks 📱</p>



<p>At OpenNebula, we have already started <strong>testing the new AWS Wavelength resources</strong> as part of our <a href="https://oneedge.io/">ONEedge</a> initiative. Eventually, this new service will be incorporated into our <strong>catalogue of cloud and edge providers</strong> available for OpenNebula users. We expect this integration to really simplify the process of provisioning and managing resources close to 5G devices, helping organizations using OpenNebula to <strong>build and quickly deploy edge applications</strong> that can benefit from 5G high bandwidth and ultra-low latency, including machine learning, video streaming, multiplayer gaming, Internet of Things, augmented reality, and real-time analytics.&nbsp;</p>



<h2>OpenNebula’s First 5G Edge Architecture based on AWS Wavelength</h2>



<p>As part of our first tests of this new AWS service, we’ve adapted the scenario described by AWS Senior Developer Mike Coleman in a <a href="https://aws.amazon.com/blogs/compute/deploying-your-first-5g-enabled-application-with-aws-wavelength/">post on AWS Wavelength</a> published in early August. In our case, a company with an OpenNebula private cloud wants to <strong>deploy a multi-container application at the edge</strong> (i.e a Machine Learning solution), closer to the 5G devices of their end-users. The following diagram describes how this would be implemented based on the features provided by OpenNebula and on the new resources made available by AWS Wavelength:</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-300x165.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-768x422.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture.png 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>AWS Wavelength is designed to provide access to services and applications that require low latency, but it’s important to remember that you don’t need to deploy your entire application in a Wavelength Zone. You only need to deploy those<strong> latency-sensitive parts of your application</strong> that are really going to benefit from being deployed at the 5G edge. In our demo scenario, the API server and inference engine are located on the Wavelength Zone because one of the design goals of the application is low-latency processing of the inference requests. On the other hand, given that the web server doesn’t have those latency requirements, it doesn’t really need to be hosted on the Wavelength Zone.</p>



<p>Each Wavelength Zone is <strong>associated with a specific AWS Region, known as the “parent region”</strong>. For our experiment we have picked the Boston area, which is one of the first regions—along with San Francisco—in which the new Wavelength service was made available. Also, Wavelength instances are only accessible from 5G devices on a specific telecom provider network, in this case from those of <strong>Verizon customers in the Boston area</strong> 🧱</p>







<figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-300x55.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-768x142.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal.png 1319w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>For the deployment of a multi-container application that benefits from this approach, we have used a number of <strong>well-known open source technologies</strong>. One of them has been <a href="https://k3s.io/">K3s</a>, a certified Kubernetes distribution originally developed by <strong>Rancher Labs</strong> and now hosted by the <a href="https://rancher.com/press/rancher-labs-k3s-joins-cloud-native-computing-foundation-sandbox-project">Cloud Native Computing Foundation</a> (CNCF). K3s is a lightweight, production-grade distribution designed for organizations looking to run Kubernetes in resource-constrained environments, which makes it ideal for deployments at the edge. We have used a customized K3s image for this demo, but in the near future users will be able to deploy a K3s cluster by simply using its public Docker image 🤩</p>



<p>When <strong>bare-metal resources</strong> are available, OpenNebula users can also benefit from our latest, super-cool integration with <a href="https://opennebula.io/firecracker/">Firecracker</a>. Firecracker is a new open source virtualization technology—widely used by AWS as part of its <strong>Fargate and Lambda</strong> services—especially designed for <strong>serverless deployments</strong>. By running application containers (e.g. the K3s Docker image) as a <strong>Firecracker microVM</strong>, we immediately obtain the enhanced security and workload isolation of a traditional VM, but without undermining the speed and resource efficiency of a container.</p>



<p>Unfortunately, right now, bare-metal instances are not available in the current Wavelength zones, so we cannot use Firecracker for our 5G edge deployment, only at the associated AWS parent region (i.e. us-east-1). Thus, for Wavelength instances, and thanks to another great feature of OpenNebula, we can use <strong>Ubuntu</strong>’s <a href="https://linuxcontainers.org/lxd/getting-started-opennebula/">LXD system containers</a> to deploy K3s agents on the Wavelength resources.</p>



<p>As show in the figure, in order to deploy a containerized application composed of different components, OpenNebula allows to <strong>instantiate a K3s cluster across multiple hosts with mixed hypervisors</strong> and then let the customer deploy the application (e.g. using an helm chart or kubectl) by scheduling the components on the right resources, typically deploying the latency-sensitive components (i.e. the Inference Engine and the API server) on the Wavelength Zone, and the rest of components (i.e. Web Server) on the AWS parent region.</p>



<h2>Integration of AWS Wavelength Resources within OpenNebula</h2>



<p>OK, let’s get into some more detail… 🤓 The first step required to set up AWS Wavelength resources is the deployment of an <strong>AWS Virtual Private Cloud</strong> (VPC) with two zones: one is related to the associated AWS parent region, and one is related to the Wavelength Zone. We have then to associate to the VPC an Internet Gateway that is used to assign public IPs to resources that are deployed within the parent region, plus a Carrier Gateway that is used to assign carrier public IPs to the resources deployed on the Wavelength Zone.</p>



<p>In the VPC we have to define two subnets: one for the resources at the parent region and one for Wavelength Zone resources. The parent region subnet will be associated with the Internet Gateway to get public IPs, whereas the Wavelength subnet will be associated with the Carrier Gateway to get public IPs from the 5G carrier network.</p>



<p>The Carrier Gateway in a Wavelength Zone only allows access from the carrier’s 5G network. So, since the Wavelength zone resources cannot be accessed by using the internet, it is not possible to provision, configure and set up those resources by directly accessing them. In order to integrate Wavelength Zone resources with OpenNebula, we have to <strong>use the parent zone’s servers as “bastion hosts”</strong> to access Wavelength Zone resources via SSH, since they are only reachable through the private VPC subnet. Resources in the parent region can also be used to deploy those parts of our application that are not latency-sensitive or require high-bandwidth.&nbsp;</p>



<p>Provisioning resources on regular AWS zones for deploying application parts that are not latency-sensitive is already possible for OpenNebula and can be performed by using its standard <a href="https://docs.opennebula.io/5.8/advanced_components/ddc/overview.html">OneProvision</a> tool. By using a bastion host and customized SSH configuration files, it is then possible to <strong>provision and configure instances on the Wavelength Zone</strong> and to add them as hosts to the OpenNebula front-end. Since OpenNebula uses SSH to perform any operation on the hosts, once bastion and Wavelength resources are set up, it is possible to <strong>deploy containerized applications</strong> (i.e. a K3s cluster) both on the parent region and on the …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</a></em></p>]]>
            </description>
            <link>https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374553</guid>
            <pubDate>Thu, 10 Dec 2020 15:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Acronyms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374486">thread link</a>) | @thismodernlife
<br/>
December 10, 2020 | https://headey.net/the-problem-with-acronyms | <a href="https://web.archive.org/web/*/https://headey.net/the-problem-with-acronyms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  <p><em>Reducing the use of unnecessary acronyms in your business will increase productivity and employee happiness, and reduce cynicism as you grow. Here's how.<br></em><br>
</p>
<div>
<action-text-attachment sgid="BAh7CEkiCGdpZAY6BkVUSSI1Z2lkOi8vYmxvZ2xpbmUvQWN0aXZlU3RvcmFnZTo6QmxvYi83OT9leHBpcmVzX2luBjsAVEkiDHB1cnBvc2UGOwBUSSIPYXR0YWNoYWJsZQY7AFRJIg9leHBpcmVzX2F0BjsAVDA=--492323e7f82eed9da3abe777946f97eda1fea850" content-type="image/jpeg" url="https://blogline.co/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/choose-your-words.jpg" filename="choose-your-words.jpg" filesize="47482" width="800" height="600" previewable="true" presentation="gallery"><figure>
    <img src="https://headey.net/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDRG9MWm05eWJXRjBTU0lJYW5CbkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFJQUJHa0NBQU02QzJ4dllXUmxjbnNHT2dsd1lXZGxNQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--a716ef5bd361b6dfee383a3ae715134b65b59d48/choose-your-words.jpg">

  <figcaption>
  </figcaption>
</figure></action-text-attachment><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiRlcKCp5jtAhWNQEEAHfPgCOYQFjAAegQIBBAC&amp;url=https%3A%2F%2Fheadey.net%2Fspectacular-vernacular&amp;usg=AOvVaw0rJ08bs82T25D_W2oBjORi">Confusing vernacular</a> isn’t a new thing to me, but I’ve noticed that an acronym[1] population steadily increases as projects, or entire companies, expand. I can sort of understand. When a company is bigger, there are more people and more things going on. More projects, more meetings, more presentations. Typing “Engaged User Growth Hack” becomes tedious the 14th time you write it in your proposal, so someone initialises it (EUGH) the first time and uses the acronym there on in. Once the document is circulated, it’s inevitable that at some point – it might take a few meetings, but eventually – it becomes common parlance. "How is the EUGH rate looking this week, Ted?"</p></div>
<div><p>One of the many problems you’re going to encounter in a growing business is a lack of clarity among staff. A successful business is one where employees understand things, and when they don’t it's okay because they know where to go to find the information required to understand things.&nbsp;</p><p>Whether you’re a new hire reviewing an onboarding guide on your first day, or a seasoned employee reading the latest project proposal, you’re probably going to be faced with a sea of acronyms. The more there are, the more confused you'll be. This is bad for morale and bad for business, so it's your job as a leader in an organisation to spare everyone from this misery by eliminating acronyms as much as possible in your organisation. Here are my top tips.</p></div>


<div><p>Some acronyms are so universally understood and accepted that it would be weird not to use them (HTML, RAM). There are some acronyms where the majority of people know what they mean, even if they don't know specifically what the abbreviation stands for. There are some that are <strong>very dependent on context</strong> so proceed with caution unless they are truly universal or if you really know your specific audience. For instance:</p></div>
<ul>
<li>NHS. Everyone in Britain will know what this means, but many people from other countries might be confused.</li>
<li>FBI. You know what it is, but what does it stand for?&nbsp;</li>
<li>UFO. People of a certain age will know about UFOs, but has anyone talked about them since 1989?&nbsp;</li>
</ul>


<div><p>If we accept the premise that more acronyms means more confusion, why would we add to this? Writing Average Page Load Time is tedious for the author, but creates clarity and removes any confusion about what it means (given the appropriate context). APLT does neither. Adopting universal acronyms into your organisation isn't necessarily a bad thing, but inventing your own probably is.</p><p>One exception to this rule is code names. Calling your new internal app <strong>PERSI</strong> is better than calling it Predictive Enterprise Relationship System Integration, and it's fun to ask the team "How is PERSI doing this morning?". Personality goes a long way.<br>.</p></div>

<div><p>Even if we're not creating any new acronyms, there will always be a heap in common use already. When you’re writing a document, always write the words in full on first use and put the acronym in brackets after it. For example, don't write:</p></div>
<blockquote>In our company, we live and die by OKRs and KPIs.</blockquote>

<blockquote>In our company, we live and die by Objectives and Key Results (OKRs) and Key Performance Indicators (KPIs).&nbsp;</blockquote>
<div>
<p>Given that everything is likely to be in digital form you should also, wherever possible, link to even more information. Context is king. So your document should look more like this:</p></div>
<blockquote>In our company, we live and die by <a href="https://www.youtube.com/watch?v=mJB83EZtAjc">Objectives and Key Results</a> (OKRs) and <a href="https://en.wikipedia.org/wiki/Performance_indicator">Key Performance Indicators</a> (KPIs).&nbsp;</blockquote>
<div>
<p>Do this always. Even if you think it's unnecessary, it's really not. It is helping communication, not hindering.</p></div>


<blockquote><em>To maximize clarity, use abbreviations sparingly<p>— American Psychological Association</p></em></blockquote>
<div>
<p>Just because everyone else does, you don't actually have to use acronyms yourself. You can assume everyone knows what KPI means, and perhaps they do know that it stands for Key Performance Indicator, but do they know what a "performance indicator" actually is? Wouldn't it be better to ditch the acronym entirely and say "measure of success"? You could say the same thing about OKRs (goals), CTR (ad click rate), and CRM (customer database). </p><p><a href="http://www.plainenglish.co.uk/">Plain English</a> is liberating.&nbsp;</p></div>

<div><p>You need to write down all the acronyms being used in your daily business so, at the very least, people can look things up rather than sit there silently and fearfully in ignorance. Doing this is a fun company crowdsourcing exercise where you can talk about the perils of acronyms and get this front and centre so people actually know about it and use it.&nbsp;</p><p>This glossary should be reasonably short. If it's not, you're probably using too many acronyms in your business and you need to go on a diet. You could write an OKR for that.</p></div>
<div>
<p>The intention of this article is to make you think about how acronyms are being used in your business, and for you to keep a sharper eye on new ones appearing. You should feel empowered to question their invention, and you should call it out when a document lands in your inbox that is populated with unreferenced jargon. </p><p>You could even go all Elon Musk, <a href="https://gist.github.com/klaaspieter/12cd68f54bb71a3940eae5cdd4ea1764">berate the entire company</a> and demand sign-off of any new acronyms. Extreme behaviour, perhaps, but it goes to show the negative impact acronyms have on a business and the secret power of that liberating feeling of clarity when they're eliminated from use.</p><p><a href="https://en.wikipedia.org/wiki/TTFN">TTFN</a>.<br><em><br>[1] I only learned this recently but an acronym is a word formed from the first letters of other words and is pronounceable, for example </em><strong><em>laser</em></strong><em> or </em><strong><em>radar</em></strong><em> (🤯 I know, right), whereas an initialism is an abbreviation in which each letter is pronounced separately, such as OMG or NHS. In this article I only use the word acronym because I'm pretty sure no-one ever uses the word initialism.</em></p></div>
</div>

  </div><div data-controller="email-subscribers">
    <p>Subscribe to Email Updates</p>

    

      </div></div>]]>
            </description>
            <link>https://headey.net/the-problem-with-acronyms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374486</guid>
            <pubDate>Thu, 10 Dec 2020 15:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting our first thousand users in one day]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25374319">thread link</a>) | @frankdilo
<br/>
December 10, 2020 | https://francescodilorenzo.com/typefully-launch | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/typefully-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Yesterday we launched <a href="https://typefully.app/">Typefully</a>, a write-only interface for Twitter, after weeks of work and refinement. I documented the whole story on Twitter <a href="https://twitter.com/frankdilo">@frankdilo</a>.</p>
<p>Not much deep work happened on launch day and for good reasons. It was a bigger launch than <a href="https://francescodilorenzo.com/mailbrew-launch-numbers">Mailbrew's</a>.</p>
<p>Here the numbers:</p>
<ul>
<li>16,400 Pageviews </li>
<li>1,432 Signups </li>
<li>1,843 Drafts created</li>
<li>256 Threads published</li>
<li>$155 Revenue (more on this at the end).</li>
</ul>
<p>The traffic breakdown reveals what happened:</p>
<ul>
<li>Hacker News: 6.3k</li>
<li>Twitter: 2.1k</li>
<li>ProductHunt: 1.9k</li>
</ul>
<p>Yeah, we finally managed to hit the <a href="https://news.ycombinator.com/item?id=25358108">Hacker News frontpage</a>. </p>
<p>The perfect formula was:</p>
<ul>
<li>interesting product</li>
<li>no-bullshit title</li>
<li>sparking a controversial discussion in the comments.</li>
</ul>
<p>When it comes to Twitter, we have been building a following there for some time, so it was a matter of publishing the <a href="https://twitter.com/frankdilo/status/1336589322670268416?s=21">right tweet</a>, at the right time, and getting the right people to retweet it.</p>
<p>For Product Hunt, we partnered with our friend <a href="https://twitter.com/chrismessina">Chris</a>. His followers got a notification when he hunted us, but we also did our part and emailed our lists.  That helped to get fast on the front page and to kickstart the discussion.</p>
<p>Once we were in front of enough people, the product did the rest.</p>
<p>Servers did hold up without a sweat. </p>
<p>It's crazy what you can do these days with a couple of well-configured dynos on Heroku and a Django app! We peaked at 8 RPS when we hit the HN frontpage.</p>
<p>Typefully was born as <a href="https://twitter.com/linuz90">Fabrizio</a>'s personal side-project. I jumped in to make the editor crazy-fast, and write the server-side code. When <a href="https://twitter.com/meseali">Ali</a> helped us refine positioning and copy, we knew we had a winner and promoted it to an official <a href="https://mailbrew.com/">Mailbrew</a> project.</p>
<p>Plans for the future? Implement all the great feature requests we got, and monetize this thing. </p>
<p>We launched with a tip-jar system where people could become <em>patrons</em> by tipping us, but with $150 earned after a crazy launch day like this, it's clear that this is not going to pay the bills. </p>
<p>We are thinking of adding some paid features. What's free is gonna stay free though, because this was first and foremost a labor of love.</p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/typefully-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374319</guid>
            <pubDate>Thu, 10 Dec 2020 14:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A list of small teams behind billion dollar start-ups]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374145">thread link</a>) | @maxejennings
<br/>
December 10, 2020 | https://stevepulec.com/posts/small/ | <a href="https://web.archive.org/web/*/https://stevepulec.com/posts/small/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Patrick Collison has a <a href="https://patrickcollison.com/fast">great list</a> of people quickly accomplishing ambitious things. Inspired by that, I created a page of impressive things accomplished by small teams.</p>
<ul>
<li>
<p><strong>Instagram</strong> had 13 employees when they were acquired by Facebook for $1 billion. They had 30 millions users at the time. <a href="https://www.cnbc.com/2019/09/24/facebook-bought-instagram-because-it-was-scared-of-twitter-and-google.html">Source</a></p>
</li>
<li>
<p><strong>Mojang</strong> (the company behind Minecraft) had 37 employees when they were acquired by Microsoft for $2.5 billion. At that time, Mojang had revenue of about $290 million annually with profits of over $100 million. <a href="https://www.ft.com/content/6eb85da4-38f4-11e4-9526-00144feabdc0">Source</a></p>
</li>
<li>
<p><strong>WhatsApp</strong> had 55 employees when they were acquired by Facebook for $19 billion. <a href="https://www.wired.com/2015/09/whatsapp-serves-900-million-users-50-engineers/">Source</a></p>
</li>
<li>
<p><a href="https://www.notion.so/"><strong>Notion</strong></a> has raised money at a $2 billion valuation with under 50 employees. <a href="https://techcrunch.com/2020/04/01/notion-hits-2-billion-valuation-in-new-raise/">Source</a></p>
</li>
<li>
<p><strong>BuiltWith</strong> generates $14 million/year with a single employee. <a href="https://twitter.com/theSamParr/status/1257819248484745216">Source</a> (an investor in the business)</p>
</li>
<li>
<p>The <strong>Gartman Letter</strong> had a single employee and was rumored to be doing $25M/year</p>
</li>
<li>
<p>Kylie Jenner sold a 51% stake in the <strong>Kylie Cosmetics</strong> for $600 million with just seven full-time and five part-time employees. <a href="https://www.forbes.com/sites/forbesdigitalcovers/2018/07/11/how-20-year-old-kylie-jenner-built-a-900-million-fortune-in-less-than-3-years/">Source</a></p>
</li>
<li>
<p><strong>Craigslist</strong> generates around $1 billion/year with about 50 employees. <a href="https://www.cnbc.com/2019/01/24/craigslist-posts-annual-revenue-of-1-billion-study.html">Source</a></p>
</li>
<li>
<p><strong>Plenty of Fish</strong> sold for $575 million with 75 employees. <a href="https://www.businessinsider.com/how-markus-frind-bootstrapped-plentyoffish-and-sold-it-for-575-million-2015-7">Source</a></p>
</li>
<li>
<p><strong>Liberty Media</strong> had 16 employees and was worth multi-billions in the 90s. <a href="https://www.amazon.com/Not-Fade-Away-Short-Lived/dp/006073731X">Source</a></p>
</li>
<li>
<p><strong>Joe Rogan</strong> is making between $30-$50 million/year with a handful of employees. <a href="https://www.forbes.com/sites/arielshapiro/2020/05/19/the-new-howard-stern-podcast-giant-joe-rogan-inks-exclusive-deal-with-spotify/">Source</a></p>
</li>
<li>
<p>The progress that the <strong>Wright brothers</strong> made on powered flight was so unbelievable that they had to spend two years convincing the US and French governments that it was true. <a href="http://wrightbros.org/History_Wing/Wright_Story/Showing_the_World/Prize_Patrol/Prize_Patrol.htm">Source</a></p>
</li>
</ul>
<p>This list is very business heavy right now, but I would love to add some non-business examples too! Have more? Please <a href="https://stevepulec.com/about/">reach out</a>.</p>
<p><em><a href="https://twitter.com/spulec">Follow me</a> on Twitter for more updates</em></p>
<p>Related resources:</p>
<ul>
<li><a href="https://www.theguardian.com/technology/2018/apr/24/the-two-pizza-rule-and-the-secret-of-amazons-success">Two pizza rule</a></li>
<li>Something something Margaret Mead quote something something.</li>
<li><a href="https://en.wikipedia.org/wiki/Ringelmann_effect">Ringelmann effect</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://stevepulec.com/posts/small/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374145</guid>
            <pubDate>Thu, 10 Dec 2020 14:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Data You Give]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374120">thread link</a>) | @henrikwm
<br/>
December 10, 2020 | https://security.christmas/2020/10 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>He sees you when you’re sleeping, he knows when your awake, he knows if you ‘we been bad or good so be good for goodness sake. This is a line of a popular Christmas song. It obviously refers to Santa Claus. However… What if this is true, not only for Santa, but for large companies worldwide. We’ll take a closer look on the data you give and the repercussions.</p>
</section><article><section><p>In today’s modern world, our phones are an integral part of our lives. We carry it everywhere, whether it is at work, when we are out and about or in the hospital. In every situation, our phone is nearby. The phone gives us easy access to information, communication and you might say there is an app for everything. If you need to see the local weather, it is right there in your phone, the same goes for the directions to the cinema or if you want to know what your friends are up to – check your phone. And it is all free of charge. Well, not exactly, nothing is free.</p>
<h2>The payment</h2>
<p>Although you might not spend any money on an app, the app still collect a form of payment from you. Your information is the currency and it is collected through every action you make on the internet and in the apps on your phone. Your device information, your likes and dislikes and your email is just some of the data they might collect. And the hottest commodity is your location data. You might say the phone is a tracking device you wear 24/7.</p>
<p>Some of this data, we give willingly. This can be photos, statuses, interests and in some cases, who your friends are, where you live and so on. It is easy to believe that the information you give to a specific app will be contained within the app. This is often not the case. Selling consumer data is a multi-billion-dollar industry and your data is sold for targeted marketing, to analytics companies and to research. </p>
<p>You might not know what you do online every day, but the 50 apps you have on your phone does and what you do says a lot about you.</p>
<h2>I have nothing to hide</h2>
<p>You might not know why you should care about the fact that your data is collected, you have nothing to hide. A couple of emails with “special offers” in terms of marketing might not be the worst thing. But here is why you should care. </p>
<p>There are no restrictions on who can by this data and more parties are showing interest. In fact, earlier this year the Wall Street Journal found that the <a href="https://www.wsj.com/articles/federal-agencies-use-cellphone-location-data-for-immigration-enforcement-11581078600">U.S government bought commercially available location data</a> and used if for detecting undocumented immigrants or others trying to get across the U.S border. It also played a part in discovering a drug smuggling tunnel beneath the border between USA and Mexico in an abandoned KFC restaurant. </p>
<p>The police usually must acquire warrants to get this kind of information on your phone, but what if they can just buy it commercially? When is it ok to use these data and when is it surveillance? <a href="https://privacy-pc.com/interviews/bruce-schneier-nsa-is-wasteful-and-dangerous.html">Like the comparisons the cryptographer Bruce Sneider draws:</a> If the government said: “Whenever you make a new friend, you must inform the police”. We would laugh, but we willingly tell Facebook and Facebook informs the government. Or if the government says: ”Whenever you send a message or write a letter or send a note to somebody, send us a copy, please”. That would never happen, we would not do that. However, Google does it for you.</p>
<p>Throughout your days of using your phone or computer, you give pieces of information to each application or website, and although this data is supposed to be anonymous, it is not hard to connect the missing pieces. When seeing all the data from different sources together and by adding simple searches on specific information, your name and identity will be found and the data will no longer be anonymous. This was illustrated when <a href="https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html">The New York Times</a> bought commercially sold location data. With this data they could easily find the person to whom the data belonged. Even though the name of the woman they were tracking, was not among the bought information, they deduced a lot about her. They could see that she was at a weight watchers meeting, doing a procedure at the dermatologist and by the amount of time she was spending at a school, she was most likely a teacher. The phone tracked her every two seconds and giving information about her she found disturbing.</p>
<p><a href="https://www.nrk.no/norge/xl/avslort-av-mobilen-1.14911685">NRK</a>, a TV-channel in Norway did the same. By analysing the person’s patterns, they could see where he spent his days and where he spent his nights. By this information alone one can easily find out who lives at the address he slept at and who works at the address he was during the day, to find the name of the person using the phone. They even found that the person was going to interviews with another company, which he had not told anyone. And some time after these interviews he change his place of work.</p>
<p>All your data collected is a foundation for through analysis of you as a person. They can put you in boxes and make assumptions about you. Sometimes they are right, and sometimes they are not. If you are classified as likely to become a gambler, could it get in the way of you getting a loan in the future? Or could marketing pray on your weaknesses to get you to buy something you don’t need? You can easily be manipulated by companies gaining in-depth knowledge about you. This was proven by “Folkeopplysningen”, a show in Norway that informs the public about different topics. In one episode they <a href="https://www.nrk.no/dokumentar/xl/ble-manipulert-etter-nrk-spionering-pa-hans-digitale-liv-1.14759796">manipulate an intelligent man to give up his company, his life’s work, purely based off of information found on him online</a>. By his likes on Facebook, they could perform a personality test. By the pictures on Instagram they could see that he liked to work out, that he loved superheroes and all kind of other information. They staged a day for him to be considered for a super hero-part in a Hollywood production. All he had to do was give up his business. This is something he probably would never do if it wasn't for being manipulated for an entire day based on the information the TV-show could find on his social media and other online accounts.</p>
<h2>What about GDPR</h2>
<p>If you live in Europe, you have probably heard of General Data Protection Regulation or GDPR. <a href="https://www.investopedia.com/terms/g/general-data-protection-regulation-gdpr.asp">GDPR</a>&nbsp;is a legal framework that sets guidelines for the collection and processing of personal information from people who live in the EU. It is there to give consumers of the internet more right as to what data is collected.</p>
<p>As a consumer, you notice it best by having to accept the use of cookies on the web or by giving permissions to the apps of which data they can have access to. However, the government can only do so much if consumers keep accepting the usage. The web or phone applications often make it hard not to accept by writing the terms incomprehensible or too long. In some cases, you must even go to completely different applications to turn it all the way off.&nbsp;<em>As long as it is easier to accept, we will accept.</em>&nbsp;It can also be difficult to investigate where the commercially sold data comes from because not all companies are located in Europe and in some cases the terms does not specify all the different ways your data can be spread. </p>
<h2>Off the grid</h2>
<p>By highlighting some downsides of sharing data, you might feel the need to stop sharing data all together, but it is important to state that data sharing is not all bad. First of all, getting commercials tailored for you can be a good thing as you can get offers based off of previous purchases and get more effective services. Another great thing about sharing your data is that it can benefit scientists. Research on cancer be done studying patient data, why we are the way we are can be explored by looking at data from Facebook and so on. Looking at large sets of data can give us a better understanding of the world today.</p>
<p>The thing to think about is that you do not have to share your data all the time and to every app or website. For instance, a flashlight app does not need permissions to track your location. There are ways of sharing less data by limiting the apps on your phone to only sharing location data when the app is used or turning it completely of when you are not active on your phone.&nbsp;</p>
<p>When it is all said and done it is&nbsp;<em>your</em>&nbsp;data.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374120</guid>
            <pubDate>Thu, 10 Dec 2020 14:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding native integrations to your app with FusionAuth and Xkit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374028">thread link</a>) | @mooreds
<br/>
December 10, 2020 | https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>FusionAuth and Xkit came together for this blog post to share how you can use our services to boost your engineering team’s productivity. If you’re working on growing your SaaS business, you know just how much your engineers have on their plates. At both FusionAuth and Xkit, we believe that outsourcing what you can – like authentication and integration infrastructure – lets your team focus on the products and services that drive your business.</p>

<!--more-->

<p>We’ve written this post to lay out how you can use our services together to simplify your auth and build native integrations into your app faster. No more telling your customers that the integrations they’ve been asking for are “on the roadmap”. Follow the steps below and you can ship them in no time.</p>

<h2 id="what-is-xkit">What is Xkit</h2>

<p>Xkit is a SaaS platform which makes integrating third party systems a snap. Suppose you are writing a recipe management application and are going to sell it for big money to all the cooks of the world. After some market research, you realize that you want to integrate with other services. Your users are clamoring for the ability to export the steps of a recipe to a Trello board for sharing and Dropbox for backups. These are all services with APIs.</p>

<p>End users can give your application access to their accounts with these services, but that takes some coding. There’s also a fair bit of hoop jumping: setting up API keys and OAuth consent screens, among other things.</p>

<p>This is the problem which Xkit solves. Xkit has built connections to many services; <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">here’s a current list</a>. Once configured, your application can connect a user’s account with an external service to your application. I (Dan) was able to connect Trello and my app in about an hour. The user experience of connecting the external application is smooth and far better than something I could whip up in a day, let alone an hour.</p>

<h2 id="xkit-and-fusionauth-integration">Xkit and FusionAuth integration</h2>

<h3 id="install-fusionauth">Install FusionAuth</h3>

<p>FusionAuth offers <a href="https://fusionauth.io/docs/v1/tech/installation-guide/">a number of different methods you can use to install the service</a>. Once you’ve installed it, there’s a Setup Wizard to walk you through the next steps. You’ll need to create your application in the FusionAuth interface and then add a few elements to your application code base to fully implement the FusionAuth login flow. A <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide/">full, detailed setup guide</a> is also available. Feel free to create additional <a href="https://fusionauth.io/docs/v1/tech/core-concepts/users/">users via the FusionAuth administrative user interface</a>.</p>

<p>Once FusionAuth is installed and configured, you have a full featured user management system, ready to go. APIs to control everything, multi factor authentication, consent management, SAML, OIDC, and more, hosted wherever you want. There’s also FusionAuth Cloud, a managed services offering, if you don’t want to host FusionAuth yourself.</p>

<h3 id="install-xkit">Install Xkit</h3>

<p>After you’re set up with FusionAuth you’ll want to head over and <a href="https://app.xkit.co/sign-up">create your Xkit account</a>. Upon sign-up, Xkit will also prompt you with some basic information needed to set up the environment. Fill out those details and you’re good to go there.</p>

<p>To set up Xkit in your code base, you’ll need to add the script tag for <code>xkit.js</code> on your front-end:</p>

<div><div><pre><code><span>&lt;script </span><span>src=</span><span>"https://&lt;your-slug&gt;.xkit.co/xkit.js"</span><span>&gt;&lt;/script&gt;</span>
</code></pre></div></div>

<p>In addition, your users need a place to actually sign in to their apps, such as Dropbox for your cooking recipe sharers. The easiest way to do this is to direct users to the hosted integration catalog Xkit has set up for you:</p>

<div><div><pre><code><span>&lt;a</span> <span>href=</span><span>"https://&lt;your-slug&gt;.xkit.co"</span><span>&gt;</span>Integration Catalog<span>&lt;/a&gt;</span>
</code></pre></div></div>
<p>Alternatively, if you need more customization, you can embed Xkit’s catalog on your site and customize its styling to fit your look and feel (<a href="https://docs.xkit.co/docs/self-hosted-catalog">details here</a>). If you still need more flexibility, you can use the SDK.</p>

<h3 id="connect-fusionauth-with-xkit">Connect FusionAuth with Xkit</h3>

<p>Now that you have both FusionAuth and Xkit set up, you’ll need to connect the two. We do this by collecting some information from your FusionAuth dashboard and inputting it into Xkit.</p>

<p>Specifically, you’ll need to generate an RSA key and then add your “iss” claim, “aud” claim and JWKS URL into your Xkit account. This setup is <a href="https://docs.xkit.co/docs/fusionauth">fully documented</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/rsa-keypair.png" alt="The generated RSA key for use with Xkit."></p>

<p>Once you’ve done that and clicked save, FusionAuth and Xkit will be connected. Huzzah!</p>

<p>You can now have your users log in using FusionAuth’s Login API. You’ll get a JWT from FusionAuth on successful user authentication. This JWT can then be sent to Xkit to authenticate the user in Xkit, and therefore grant them access to integrations you’ve configured.</p>

<p>In your code base you can log your user into Xkit simply by using your FusionAuth ID token:</p>

<div><div><pre><code><span>//...</span>
<span>xkit</span><span>.</span><span>ready</span><span>(()</span> <span>=&gt;</span> <span>{</span>
  <span>xkit</span><span>.</span><span>login</span><span>(</span><span>'</span><span>eyJhbGciOi...</span><span>'</span><span>)</span>
<span>})</span>
<span>//...</span>
</code></pre></div></div>

<p>This easy JWT-based connection saves you the trouble of dealing with API keys and provisioning users for Xkit; you can instead maintain them in FusionAuth. You can also use FusionAuth for all your other applications, providing one view of all your users.</p>

<p>The security minded among you will notice that this JWT is available in the DOM, and therefore exposed to cross site scripting attacks, should any malicious JavaScript be executed on the same page. To minimize the risks, lock the permissions associated with this JWT down and don’t allow its use as a bearer token for any other more sensitive APIs or services.</p>

<h2 id="add-an-integration">Add an integration</h2>

<p>Now to actually set up your first integration! Say you want your users to be able to connect their Trello accounts with your app. To do this, you’ll first need to get an <a href="https://trello.com/app-key">Trello API key</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/xkit-trello-screenshot.png" alt="The Xkit Trello integration screen."></p>

<p>Next you’ll need to add Trello as a connector in your Xkit platform and provide Xkit with the API key. After filling out a bit more information in the Xkit Trello connector page to set the permissions you require and what your users see when they’re connecting the app, you’ll click save.</p>

<p>You’re now ready to retrieve access tokens! You simply make one API call to retrieve a user’s fresh access token:</p>

<div><div><pre><code><span>const</span> <span>trelloToken</span> <span>=</span> <span>await</span> <span>xkit</span><span>.</span><span>getConnectionToken</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>If the token isn’t available, you should send the user to the appropriate place in your integration catalog to connect it.</p>

<div><div><pre><code><span>//...</span>
<span>if</span> <span>(</span><span>!</span><span>trelloToken</span><span>)</span> <span>{</span>
  <span>window</span><span>.</span><span>location</span><span>.</span><span>href</span> <span>=</span> <span>xkit</span><span>.</span><span>connectorUrl</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
<span>}</span>
<span>//...</span>
</code></pre></div></div>

<p>Behind the scenes here, Xkit handles all the complicated parts of managing the access tokens — dealing with each SaaS app’s protocol differences, token expirations, refresh tokens, protection against CSRF attacks, token encryption and more — so that it’s as simple as one API call for you. This setup also makes it easy to retrieve the token anywhere in your stack, be it in Cloud Functions, on the front-end, from your web server, etc. You can then use the token to make calls to the Trello API.</p>

<p>To add integrations to other apps, you follow essentially the same steps and retrieve the token with the same API call. Specific guides for different apps <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">can be found here</a>.</p>

<p>We’re always looking for feedback and suggestions so let us know your thoughts! Thanks for reading.</p>

<p>This post can also be found on the <a href="https://xkit.co/post/adding-native-integrations-to-your-app-with-xkit-and-fusionauth">Xkit blog</a>.</p>

            
          </div></div>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374028</guid>
            <pubDate>Thu, 10 Dec 2020 14:31:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top React libraries you need to know in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373927">thread link</a>) | @oczek
<br/>
December 10, 2020 | https://blog.graphqleditor.com/react-libs-2021/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-libs-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last time we looked a bit at the background and some built-in features of React. As promised it’s now time to look at some optional tools. Just like with Vue and Angular, components play a big role here and as usual you can create your own or use some of those made by the rapidly growing community. Let’s take a look at React libraries you should check before 2020 ends.</p>
<h2>React based frameworks</h2>
<p>If you’re planning on working with React most likely you’re going to have to pick between two starter frameworks, Gatsby.js and Next.js. React by itself works only on the client side and does not provide server side rendering, while those two build on top of React and provide SSR/SSG. Both also follow JAMStack architecture and provide you with a boilerplate which helps speed up and simplify the development process. That’s enough about similarities and let’s look at what the choice boils down to:</p>
<ul>
<li><strong><a href="https://www.gatsbyjs.com/">Gatsby.js</a>:</strong> generates HTML via server side generator during the build time, this means you don’t need a Node.js server to handle rendering and you’ll have HTML files ready right after build.  Data fetching is handled via GraphQL which has its benefits (you only fetch what you need which saves resources and time) but also ties you to GraphQL which not everyone likes or wants to use. Prominent uses of Gatsby.js include Figma.com, React’s official site and State of Javascript.</li>
<li><strong><a href="https://nextjs.org/">Next.js</a>:</strong> renders pages via server side rendering, this requires a Node.js server to run applications and handle dynamic HTML rendering. If you don’t like that Next.js also supports SSG since version 9.3. What you use for data fetching is up to you, hell you can even use GraphQL. Prominent uses of Next.js include TikTok, Hulu and Twitch mobile.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="React based frameworks" title="React based frameworks" src="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png" srcset="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/12f09/base.png 148w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/e4a3f/base.png 295w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png 590w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/efc66/base.png 885w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>State management</h2>
<p>State management is the most crucial part of any modern React app. Most of the time it is the biggest challenge any developer faces while working on their frontend project, especially when it comes to large and complex enterprise-grade commercial apps. Managing state is such a complex task that proper handling requires using external libraries, as at some point React itself will no longer be able to provide a satisfactory solution.</p>
<ul>
<li><strong><a href="https://redux.js.org/">Redux</a>:</strong> a predictable, standalone state container for JavaScript apps which helps you write applications that behave consistently and run in different environments. Being a standalone library means you can use Redux even if you don’t have a UI setup yet. Redux can be used with any UI framework i.e React, where you can describe your UI as a function of your state and make Redux keep track of your components state and update them accordingly in response to UI actions. Redux is definitely the most popular choice when it comes to state management with React with almost 5 million weekly downloads on NPM.</li>
<li><strong><a href="https://mobx.js.org/README.html">MobX</a>:</strong> a simple, scalable state management solution. It’s easier to learn and simpler to use than Redux and focuses on helping develop simpler apps with less boilerplate code. The main focus is reducing the number of bugs by mapping the relations between state and derivatives while maintaining referential integrity. Another plus is that it can be used either client side or server side and, as a JavaScript library, lets you keep the existing utilities of JS.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="State management" title="State management" src="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png" srcset="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/12f09/state.png 148w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/e4a3f/state.png 295w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png 590w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/efc66/state.png 885w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Forms</h2>
<p>Forms are present in most web and mobile apps.  Unlike Angular and Vue, which both give you a way to validate forms out of the box, React requires you to handle them all by yourself. Fortunately there are some libraries rushing to help you out.</p>
<ul>
<li><strong><a href="https://formik.org/">Formik</a>:</strong> is the most popular form library for React (and React Native). Formik is packed with dozens of micro features like different types of validation, handling API errors, auto-saving forms data and many more. It’s the result of the React community’s years of experience in terms of UI, security, accessibility etc. With Formik you can focus on developing your product instead of battling with all aspects of forms. It’s a well-tested and highly optimized solution, using which will leave you with less chances for unexpected errors and edge cases in your forms.</li>
<li><strong><a href="https://react-hook-form.com/">React Hook Forms</a>:</strong>  a light-weight form library for React, allowing you to achieve astonishing results with a minimal amount of code, which makes it very performance oriented. React Hook Forms is optimized to remove any unnecessary re-renders of your components by providing the developer a way to isolate component re-renders, improving performance of your mobile or web application. It is a great way to empower your applications with highly-performant, flexible, easy to use and manage forms.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Forms" title="Forms" src="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png" srcset="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/12f09/forms.png 148w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/e4a3f/forms.png 295w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png 590w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/efc66/forms.png 885w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Testing</h2>
<p>Test-driven development (TDD) is now one of the leading approaches to application development. It’s becoming more and more popular as it reduces the chance of major bugs occurring in the future. An obvious downside of test-driven development is that it usually takes longer to bring a product to market than while using a behavior-driven development approach. Fortunately there are some useful React libraries that can make writing tests a much easier task.</p>
<ul>
<li><strong><a href="https://enzymejs.github.io/enzyme/">Enzyme</a>:</strong> a JS testing utility that makes testing your React components super easy. You can manipulate, traverse and in some ways simulate runtime given the output. Enzyme was created internally at AirBnB and released as an open source project in 2015. The tool aims to be as easy as possible by providing an intuitive API inspired by jQuery’s API for DOM manipulation and traversal.</li>
<li><strong><a href="https://testing-library.com/docs/react-testing-library/intro/">React Testing Library</a>:</strong> a tool that lets you test React components without relying on their implementation details. This approach helps focus on accessibility as it basically puts you in the shoes of the end-user of the React app. The guiding principle here is that the more your tests look like the way your software is supposed to be used, the more confidence running them can give you. It’s much lighter and easier to get started with than Enzyme (which on the other hand has a lot more functions) and is the recommended testing app according to React’s docs.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tests" title="Tests" src="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png" srcset="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/12f09/test.png 148w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/e4a3f/test.png 295w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png 590w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/efc66/test.png 885w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>UI</h2>
<p>If it goes for out of the box React components there’s a bunch of useful libraries made by the community to check out. Using these can help you in a variety of ways by providing practical and reusable solutions, which really impact the time and effort development takes.</p>
<ul>
<li><strong><a href="https://react-bootstrap.github.io/">React Bootstrap</a>:</strong> a UI kit which replaces Bootstrap’s JavaScript with React code. Arguably the best way to quickly start building UI as it has thousands of ready to use themes and resources. No wonder it’s among the most popular component libraries with over 700k weekly downloads on NPM.</li>
<li><strong><a href="https://material-ui.com/">Material UI</a>:</strong> a set of components created by Google based on their famous material design protocols. The components are self-sustaining in nature and only inject the styles they need to display. It also provides a lot of accessible and configurable UI widgets and ready to use site templates. This makes for a pretty significant performance boost especially considering the library is regularly updated and has very strong community support with over 60k stars on GitHub and is probably the most popular component library with over 1,6 mln weekly downloads on NPM.</li>
<li><strong><a href="https://rebassjs.org/">Rebass</a>:</strong> a tiny component library that packs a punch. Rebass contains only 8 components and weighs only 4 KBs but can be used to create a robust set of themable UI elements. It’s based on the Styled System library and focuses on providing a quick start for your development process. It’s really handy if you don’t want to rely too much on community component libraries or you intend to create your own custom UI.</li>
<li><strong><a href="https://react.semantic-ui.com/">Semantic UI React</a>:</strong> the official React integration for Semantic UI. This offers all the extra functions of the jQuery based re-scripted in React code. Comes with tons of prebuilt components designed specifically to make it easier to work with and produce Semantic-friendly code.</li>
<li><strong><a href="https://ant.design/">Ant Design</a>:</strong> a design system for enterprise level products. Based on the Ant Design project it provides you with over 60 high quality components crafted based on a design language developed by the creators. The components are customizable and include support for dozens of languages. The focus is on helping build rich, interactive UIs for internal desktop applications (no worries there’s also Ant Design Mobile for mobile apps)</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="UI" title="UI" src="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png" srcset="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/12f09/ui.png 148w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/e4a3f/ui.png 295w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png 590w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/efc66/ui.png 885w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Join up!</h2>
<p>Obviously that’s just a few popular libraries, there’s a myriad more and everyone will easily find some useful ones. Most of them aren’t complicated and take a short while to get a hang of, which is time well invested considering they usually speed up and simplify the development process by quite a bit. Creating everything yourself has its benefits, but all in all the rapidly growing and already sizable React community is probably the biggest advantage using it provides.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/react-libs-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373927</guid>
            <pubDate>Thu, 10 Dec 2020 14:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A DIY particle detector kit developed at CERN]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25373912">thread link</a>) | @kasbah
<br/>
December 10, 2020 | https://shop.kitspace.org/buy/electron-detector/ | <a href="https://web.archive.org/web/*/https://shop.kitspace.org/buy/electron-detector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A kit to make the electron detector variant of the DIY Particle Detector project.</p><p>This open hardware project is a mobile low-cost detector for measuring ionising radiation like electrons from beta radiation (plus some gamma photons). It's an educational tool and citizen science device made for exploring natural and synthetic sources of radioactivity such as stones, airborne radon, potassium-rich salt or food and every-day objects (Uranium glass, old Radium watches etc.).</p><p>This project is developed by Oliver Keller at CERN, see full project details <a href="https://kitspace.org/boards/github.com/ozel/diy_particle_detector/electron-detector/">here.</a></p><p>This is a kit to make your own electron detector. A required metal enclosure (see the<!-- --> <a href="https://github.com/ozel/DIY_particle_detector/wiki/Enclosures">wiki</a>) and a 9V battery are not included.</p><div><p><span>Worldwide Shipping (estimated delivery by Monday, December 21, 2020)</span></p><p><span>€15.00</span></p></div><p><b>Total: </b><b>€45.00</b></p></div></div>]]>
            </description>
            <link>https://shop.kitspace.org/buy/electron-detector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373912</guid>
            <pubDate>Thu, 10 Dec 2020 14:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting system calls to fix broken software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373860">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://yairchu.github.io/posts/intercept-to-fix | <a href="https://web.archive.org/web/*/https://yairchu.github.io/posts/intercept-to-fix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Apple sure like to change things, so when my new computer shipped with the new macOS 11.0, some things didn't work - specifically the Haskell compiler, GHC, failed linking my programs with OpenGL and other system libraries.</p>
<p><a href="https://gitlab.haskell.org/ghc/ghc/-/issues/18446">The problem</a> is already fixed in the GHC git repository, and I could try building it, but that might send me on new adventures due to more new-version behaviours, so instead I looked into working around the problem by making macOS 11 behave like macOS 10 did in the way that GHC expects!</p>
<h3 id="short-problem-description">Short problem description</h3>
<p>When linking with OpenGL, GHC verifies that the file <code>/System/Library/Frameworks/OpenGL.framework/OpenGL</code> exists, but it no longer does!</p>
<p>We can't add the file there (not even with <code>sudo</code>) because macOS's <code>/System</code> folder is special.</p>
<h3 id="solution">Solution</h3>
<p>We can trick GHC to believe that the file exist, and then everything would work!</p>
<p>This can be done by hijacking its calls to the <a href="https://en.wikipedia.org/wiki/Stat_(system_call)"><code>stat</code></a> system call and returning fake results.</p>
<p>MacOS lets us inject additional code into programs using the <code>DYLD_INSERT_LIBRARIES</code> environment variable, and it also supports special pragmas to tell it to replace library functions (aka "interpose" or "hook").</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>int</span> my_stat (<span>const</span> <span>char</span>* <span>restrict</span> path, <span>struct</span> stat* <span>restrict</span> buf)</span>
<span id="cb1-2">{</span>
<span id="cb1-3">    <span>if</span> (STARTS_WITH (<span>"/System/Library/Frameworks/"</span>, path))</span>
<span id="cb1-4">    {</span>
<span id="cb1-5">        <span>// Pretend that the file exists</span></span>
<span id="cb1-6">        <span>return</span> <span>0</span>;</span>
<span id="cb1-7">    }</span>
<span id="cb1-8">    <span>return</span> stat (path, buf);</span>
<span id="cb1-9">}</span>
<span id="cb1-10"></span>
<span id="cb1-11">DYLD_INTERPOSE (my_stat, stat)</span></code></pre></div>
<p>The above injected code tricks GHC to believe that any file inside <code>/System/Library/Frameworks/</code> exists, and that makes it work!</p>
<p>To work around the problem when executing <code>ghc</code> from a build system, it takes a bit more work to make sure that the injection propagates to it, but my complete solution isn't too long, see: <a href="https://github.com/yairchu/macos11-haskell-workaround/">github.com/yairchu/macos11-haskell-workaround</a></p>
<ul>
<li><img src="https://yairchu.github.io/images/reddit.svg" alt="reddit"> <a href="https://www.reddit.com/r/haskell/comments/k9r2cy/workaround_for_haskell_woes_on_macos_11_big_sur/">r/haskell discussion</a> on this work-around</li>
<li>I want to get this workaround into the Haskell build tool <code>stack</code>, if you want that too then please share your opinion on <a href="https://github.com/commercialhaskell/stack/issues/5456">the issue</a>!</li>
<li>FYI: The Linux equivalent of <code>DYLD_INSERT_LIBRARIES</code> is called <a href="https://tbrindus.ca/correct-ld-preload-hooking-libc/"><code>LD_PRELOAD</code></a>, and it can do similar things on Linux.</li>
<li>Image by <a href="https://pixabay.com/illustrations/vaccine-syringe-antidote-cure-3314164/">LillyCantible</a> from PixaBay.</li>
</ul>

    <!--Share buttons-->
    
</article></div>]]>
            </description>
            <link>https://yairchu.github.io/posts/intercept-to-fix</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373860</guid>
            <pubDate>Thu, 10 Dec 2020 14:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never work as a software engineer in a startup]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25373431">thread link</a>) | @veebuv
<br/>
December 10, 2020 | https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup | <a href="https://web.archive.org/web/*/https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I'm speaking in front of 200 people tomorrow on the topic around software development for startups. There are hundreds of books written on this so I'll try to condense my learnings from most.</p><p>Even though we're a startup company at <a href="#"></a><a href="#"></a><a href="#"></a><a href="#"></a>, I stopped hiring software engineers, hell I tried to unlearn and relearn a few things in the journey as well.</p><p>Confusing I know - I still have to grapple around the entirety of it all but the honest truth is being a software engineer alone will get you easily fired or unvalued in a startup.</p><p>You need to fire yourself from that role and re-hire yourself as a product engineer. I've referenced this point multiple times in my previous articles and I really stand by this.</p><p>I don't think this necessarily applies for larger companies when they're hiring specialists and algo heavy engineers, however in a startup you need to think about the product, the marketing and most important the customer.</p><p>There is a significant disconnect in larger firms from the creator (developer) to the end user, all the way from hierarchy, to Project Managers, to Product Managers, to Marketers, to Execs etc - but in a startup, if you push code up... it's up.</p><p>So whats so special about being a product engineer that a software engineer can't do? A few things:</p><h3>1. They carry a get shit done attitude</h3><p>Sure some engineers carry that too, these statements aren't binary or exclusive but address the vast majority. When you look at github discussions or you look at conference events where people share their discoveries, it's all based around the engineer - not as much around the customer.</p><p>So yes, product engineers have a get shit done attitude, keeping in mind that they need to push good work out, but are quick on their feet to understand how much of debt some technical decisions will be vs others. This will be understood better over time, and even after a decade of programming, I can confirm that there is no right or wrong answer, its extremely situational based.</p><h3>2. Business first, software second</h3><p>You should toughen up and realise that building on the latest and greatest tech will not make you a better engineer. You almost NEVER have as much a good reputation for being the engineer for a bad startup as you may of a good startup, even though your code in the bad startup might be worthy of awards and your code in the good startup might be worthy of firing. It's inherent you see - good code isn't coincidentally in good companies, its because the companies made the smart decision of hiring mini-CTOs, people who understood that their customer mattered as much as their code.</p><p>This doesn't mean you give up all morals and build on PHP(I'M JOKING :p), but it kinda does. Not PHP but any language that is deemed unfit just because it's popular or not. You do a direct risk analysis on what will get me to my next goal ASAP. Whether that's faster iteration, more features or modularised code bases.</p><h3>3. Customer first, business second</h3><p>It should all come down to how you can make the life of the customer as easy as possible when you're solving the problem for them. Sometimes business requirements become business requirements and not customer requirements, and if you're just a software engineer by title, you will be doing what you're told to do because thats the limitation you have, at least the limitation I had a couple of years ago.</p><p>By stepping out of that box and understanding that if the business requirements step outside of the customer requirements, you get to voice your opinion and more importantly add the kicker to your "opinion" by justifying it with your technical abilities, techies are badass, we're the makers, so in the end if we have the knowledge around consumerism AS well as execution, it'll make us bulletproof.</p><p>So yes, if you're in a startup - don't work as a software engineer, work as a product engineer. Your impact will be 10X I kid you not.</p><p>People will take you ALOT more seriously, you'll climb the ranks faster, your code will matter a lot more, and the impact will be at scale. Your work matters and there should be no reason why more people shouldn't experience your genius code, the way you can make that happen is by being product focused and ensuring your customers are having the best time of their life.</p><p>As with any post, I'm always always looking to learn and become better at what I do, so I'd love to hear what you have to say, good or bad 🙌</p><p>If you liked this, definitely follow me on for the similar stuff:</p><p>twitter: twitter.com/<a href="https://dev.to/veebuv">@veebuv</a><br>linkedin: linkedin.com/in/vaibhavnamburi<br>instagram:_veebuv</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373431</guid>
            <pubDate>Thu, 10 Dec 2020 13:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AR with SceneKit and Metal]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25373105">thread link</a>) | @emllnd
<br/>
December 10, 2020 | https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/ | <a href="https://web.archive.org/web/*/https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently I found myself needing to process and visualize both point clouds and meshes in an iOS application utilizing ARKit, with the point cloud being gathered using the 2020 iPad “LiDAR” sensor. To enable maximum performance and content creation convenience I thought it would be nice to have both custom shaders and a regular, easy-to-work-with 3D hierarchy available. The best options available seemed to be Metal and SceneKit, which required some initial setup to get working together. That setup is detailed in this post.</p>
<p><em>If all this sounds unfamiliar see <a href="https://blog.halide.cam/lidar-peek-into-the-future-with-ipad-pro-11d38910e9f8">here</a>, <a href="https://developer.apple.com/metal/">here</a> and <a href="https://www.raywenderlich.com/2243-scene-kit-tutorial-getting-started">here</a> for introductions to these technologies.</em></p>












<a href="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/sceneKitAndPointCloud.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/sceneKitAndPointCloud.jpg">
    </picture>
</a>

<p>To help you recreate what I did, the post is accompanied by a GitHub repository showing the specifics: <a href="https://github.com/emllnd/ar-with-scenekit-and-metal">github.com/emllnd/ar-with-scenekit-and-metal</a>.</p>

<p><em>Note that the repo uses slightly confusing naming. XCode project name is “smTest” (for “SceneKit Metal test”), which leads to combinations such as smTestTest for the auto-generated unit testing project… not the best choice, but bear with me.</em></p>
<p><em>Also note that this is not really beginner level stuff, nor is having both SceneKit and Metal rendering usually required. If you just want to do some 3D+AR on iOS, good tech to start with would likely be either <a href="https://developer.apple.com/documentation/realitykit/">RealityKit</a>+<a href="https://developer.apple.com/documentation/realitykit/creating_3d_content_with_reality_composer">RealityComposer</a>, the more widely applicable tool <a href="https://tutorialsforar.com/creating-an-ar-app-for-ios-using-unity-and-arkit/">Unity</a> or just plain <a href="https://blog.pusher.com/building-an-ar-app-with-arkit-and-scenekit/">SceneKit</a>.</em></p>

<p>RealityKit seems like the future, but I was interested in custom shaping of meshes at runtime with e.g. geometry shaders and there did not (yet?) seem to be hooks for integrating that kind of processing in RealityKit.</p>
<p>Turns out those hooks do exist in SceneKit, which is an older and more mature technology. They can be used to implement custom render steps either before or after regular rendering. A helpful blog post with details that aided me with the ‘<strong>renderer didRenderScene</strong>’ hook can be found here: <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">Custom Metal Drawing in SceneKit</a>. Thanks for the writeup Mr. Ippel!</p>
<p>I chose to get started with combining ARKit, SceneKit and custom Metal rendering by mashing two of Apple’s example applications together:</p>
<ul>
<li>The Scene Depth demo app (<a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">Visualizing a Point Cloud Using Scene Depth</a>)</li>
<li>The default SceneKit AR project created by the XCode project wizard (creation steps depicted below)</li>
</ul>












<a href="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/newSceneKitARProj.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/newSceneKitARProj.jpg">
    </picture>
</a>


<p>The trickiest part was to get the depth blending working correctly. SceneKit and the custom Metal renderer of the Point Cloud demo use different depth buffer conventions, which caused a few moments of initial confusion before realizing I would have to adjust depth settings to make them compatible.</p>
<p>Initial depth buffer ranges <em>(from memory, might be incorrect)</em>:</p>
<ul>
<li>
<p>SceneKit:</p>
<ul>
<li>empty = zero</li>
<li>growing towards camera</li>
<li>range around 0.00-0.05</li>
</ul>
</li>
<li>
<p>SceneDepthPointCloud Metal renderer</p>
<ul>
<li>empty = negative infinity(?)</li>
<li>shrinking towards camera</li>
<li>range around 1.0-9.9995</li>
</ul>
</li>
</ul>
<p>To make the depth blending behave nicely and consistently, it was needed to set the proper depth blending mode (<em>shown as DepthStencilState –&gt; DepthCompareFunction in the XCode Frame Debugger</em>), to find matching value ranges for both depth buffers and to keep the 3D scenes of both renderers in their respective camera frustums (having good values for znear and zfar) so that they would not get culled off by being too near or too far.</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameDebug.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameDebug.jpg">
    </picture>
</a>


<p>If you’re working in a recent Apple dev environment in a fairly empty project, there’s a good chance you can get started with GPU debugging right away. You just need to build and run your app and press the camera icon (and wait a bit):</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameCaptureButton.jpg">
    </picture>
</a>

<p><em>(from here: <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/viewing_your_frame_graph">Viewing Your Frame Graph</a>)</em></p>
<p>If you crave more in-depth GPU debug options or have trouble getting started, more info can be found on the page about <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools">Frame Capture Debugging Tools</a> as well as the guide page for <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/enabling_frame_capture">Enabling Frame Capture</a>.</p>

<p>For more specific details on how I combined the two renderers, see the changes included in the first few commits (Nov 24th &amp; 28th) on the <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commits/main">commits page</a> of the example repository. It shows the history of how I:</p>
<ul>
<li>started with a blank SceneKit AR project using the Project Wizard (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/3d5358507d2824d0d57335d6988ec81d20291b9d">Initial commit</a>)</li>
<li>added custom Metal rendering as per Mr. Ippel’s <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">post</a> (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/75ad32f2012594ba3c09df9f351299d64f0ecb59">draws simple triangle, …</a>)</li>
<li>copied in the <a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">SceneDepthPointCloud</a> demo and made sure the application still builds (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/cbcdaf130a288a7ad68cd2a848ddd671269b93d6">builds with SceneDepthPointCloud …</a>)</li>
<li>fiddled with accumulation settings etc confusedly to get the thing closer to working (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39ba6d28e7f22ae202e20344c503a2136932f3ff">almost works …</a>)</li>
<li>and finally adjusted the depth blending, depth range and camera frustum settings to be able to see both scenes together (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/4a60df6c60b380d72ec740171c3440ffa09ddc23">improved …</a>, <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39c9a0e7a997567ca978e1190b67cd2af9790666">draws both …</a>)</li>
</ul>

<p>The end result of all these steps can be seen in motion below. It is of course merely the starting point for a more interesting application that leverages the ease and speed of regular 3D asset workflows and selectively applies the power of customized GPU processing as needed.</p>



<p><iframe src="https://player.vimeo.com/video/485931370?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>



<p>At the time of first publication of this post (Dec 2020) I’m not sure if the depth buffer is entirely in sync between the two renderers, even though they both do render simultaneously. The point cloud looks alright behind the rocketplane(? 😄), but I’m not sure whether they behave correctly in overlap situations. However, the fix should be just a matter of adjusting camera and depth buffer parameters and possibly scene scale (<em>famous last words…</em>).</p>
<p>If and when time permits, I will update the post and the repository with improved details.</p>
<p>Thanks for reading!</p>


    	</div></div>]]>
            </description>
            <link>https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373105</guid>
            <pubDate>Thu, 10 Dec 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons from Running a Sale That Earned 3 Month's Profit in a Week]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25372636">thread link</a>) | @czue
<br/>
December 10, 2020 | https://www.coryzue.com/writing/black-friday/ | <a href="https://web.archive.org/web/*/https://www.coryzue.com/writing/black-friday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
                <p>A few weeks ago I was in a bad place.</p>

<p>My product Pegasus—a <a href="https://www.saaspegasus.com/">Django boilerplate for SaaS applications</a>—was 
having its worst sales slump in recent history.
Meanwhile, my other product, Place Card Me—an <a href="https://www.placecard.me/">online place card maker</a>—continued
to be hit hard by the pandemic, with sales down almost $10,000 from 2019.
It looked like I was going to fall short on my targets for the month. 
<em>Again</em>.</p>

<p><img src="https://www.coryzue.com/images/black-friday/place-card-me-2020.png" alt="Place Card Me"></p>

<p>The grey line is Place Card Me’s profits in 2019. The purple line is 2020. Thanks, Covid.</p>

<p>And then on a lark I thought, “well maybe I’ll try running a Black Friday sale.”</p>

<p><strong>And my month’s trajectory completely changed.</strong></p>

<p>A few hours of work and a week later, and I had shattered my previous earnings for any month—earning
more than 3 months’ worth of typical profit in a single week.</p>

<p>Through the process, I learned a lot about running sales—lessons I thought I should share.
Because Black Friday <em>is</em> a huge opportunity for online creators and indie hackers. 
One that—if you’re anything like me—you’re probably not taking full advantage of.</p>

<p>Here’s what I did and what I learned along the way.</p>

<h2 id="deciding-to-run-a-sale-by-overcoming-the-ickiness-factor">Deciding to run a sale by overcoming the “ickiness factor”</h2>

<p>If you’re like me, your first reaction to the idea of a Black Friday sale might be something along the lines of 
“ugh, those are so overdone and spammy”.
And it’s true, Black Friday and Cyber Monday sales have become ubiquitous online.</p>

<p><em>But Black Friday sales aren’t inherently bad.</em></p>

<p>Many consumers, including myself, happily take place in Black Friday deals.
They’re a great way to support creators and pick up products you’ve long considered buying.</p>

<p>To get over my fear of “Black Friday ickiness”, I decided to turn to other successful creators who were also running deals.
Adam Wathan and Steve Shoger of <a href="https://tailwindui.com/">Tailwind UI</a> / <a href="https://refactoringui.com/">Refactoring UI</a>;
online educator extraordinaire <a href="https://wesbos.com/">Wes Bos</a>;
fellow solopreneur <a href="https://mtlynch.io/">Mike Lynch</a> for his product <a href="https://tinypilotkvm.com/">TinyPilot</a>.
How were they doing Black Friday and what could I learn from them?</p>

<p>My favorite example came from Wes Bos, which <a href="https://marketingexamples.com/">Harry’s Marketing Examples</a>
did a great job analyzing:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wes-bos-black-friday.jpeg" alt="Wes Bos Black Friday"></p>

<p>Wes Bos’s “masterful” Black Friday email. Image and analysis from <a href="https://twitter.com/GoodMarketingHQ/status/1331573176405536769">Harry’s Marketing Examples</a></p>

<p>This email and the others I looked at all shared similar qualities.
They were <em>genuine</em>, they <em>put the reader first</em>, and they <em>weren’t too pushy</em>.
It was “hey, here’s a great deal in case you’re interested, if not, sorry to bug you.”</p>

<p>Seeing that it was possible to run a deal in a classy way was enough to get me over the “ickiness” factor,
and provided a framework for crafting my own sales communications.</p>

<p><strong>Lesson: Running a sale doesn’t have to be “icky” if you do it right.</strong></p>

<h2 id="choosing-the-right-sale-structure-by-adding-value">Choosing the right sale structure by <em>adding value</em></h2>

<p>People expect Black Friday deals to offer a huge discount from normal prices—particularly 
for online products. Here’s a typical deal I received, with bundle of fonts being offered at 95% off 
the normal price:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wild-ones-black-friday.png" alt="Wild Ones Font Bundle"></p>

<p>A typical Black Friday deal—offering 95%-off a bundle of commercial fonts.</p>

<p>Offering a huge discount is a great way to drive sales, but it comes with a huge cost. 
<em>Literally</em>. A big discount will substantially reduce your revenue-per-customer and 
leave money on the table.</p>

<p>And that’s not the only problem.</p>

<p>In addition to the lost revenue, <em>massive discounts devalue your product</em>.
If your customers know that you sometimes sell your product for 95% off, they’re likely 
to think it’s only worth 5% of it’s price.
<em>You’ve just turned your valuable good into a commodity.</em></p>

<p>So how do you run a sale without reducing your prices? <strong><em>You add value.</em></strong></p>

<p>Take Adam Wathan and Steve Shoger’s deal.
They took their two products, <a href="https://tailwindui.com/">Tailwind UI</a> (normally $249) and 
<a href="https://refactoringui.com/">Refactoring UI</a> (normally $149), and bundled them together for $279.
Their customers are simultaneously <em>saving $120</em> while <em>paying more than the price of either individual product.</em>
This is adding value at its finest.</p>

<p><img src="https://www.coryzue.com/images/black-friday/refactoring-ui.jpg" alt="Refactoring UI Black Friday"></p>

<p>The Tailwind UI / Refactoring UI deal—which used bundling to offer 30% off while simultaneously increasing prices.</p>

<p><em>Bundling</em>—what Adam and Steve did by offering two products together at a discount—is a great way to 
add value while not lowering prices.
A similar approach is to <em>offer increased benefits on a lower pricing tier</em>. 
This is the approach I took with my own product.</p>

<p>My product, <a href="https://www.saaspegasus.com/">SaaS Pegasus</a>, is designed to help people launch new web applications quickly.
Pegasus has two pricing tiers, a <em>single-site</em> version for $295, and an <em>unlimited</em> version for $750.
The product is the same, but the single-site version is only able to be used on—well—a single site,
while the unlimited version can be used on—you guessed it—unlimited sites.
The unlimited version also comes with lifetime updates to Pegasus itself, instead of just a year.</p>

<p>Anyway, the details aren’t important, but what <em>is</em> important is that more than 90% of my customers 
opt—at least initially—for single-site. 
So for my Black Friday deal I decided to offer the unlimited version at price of single-site. 
This allowed me to offer a 60% discount without significantly reducing my revenue per customer
or devaluing my product.</p>

<p>Whether you use bundling, the “increased benefits on a lower tier” approach, or something else, 
adding value is a great way to create a “Black Friday deal” feeling while not incurring 
some of the financial and psychological costs associated with heavy discounting.</p>

<p><strong>Lesson: Don’t lower prices, add value.</strong></p>



<p>Ok, you’ve gotten over the ickiness factor and you’ve chosen a sale structure that adds value.
Now’s the most important part: <em>spreading the word</em>.</p>

<p>When considering how best to get the word out, think of the following breakdown.
Everyone is either <em>interested</em> or <em>not interested</em> in your sale.
Likewise everyone will either <em>find out</em> or <em>not find out</em> about it.
This creates four buckets that any person might fall into:</p>

<p><img src="https://www.coryzue.com/images/black-friday/sale-matrix.png" alt="Sale Categorization Breakdown"></p>

<p>Breakdown of the possible ways people can experience your sale.</p>

<p>The two green boxes are what you’re aiming for. 
Of course, you want everyone who might be interested in the sale to find out about it—these are your potential customers!
Also, you want everyone who <em>isn’t</em> interested in the sale to not get spammed by it—the blissfully unaware.</p>

<p>The tradeoffs and mistakes happen in the red boxes.
What you really want to prevent is <em>lost customers</em>—people who would have been interested in the deal
but never knew it was happening.
You also want to annoy as few people as possible, but <em>it’s generally better to promote the deal to someone who wasn’t interested
than to have someone who was interested miss it</em>. 
The upside of a potential sale clearly outweighs the downside of mildly annoying someone.</p>

<p><strong>Lesson: Default to promoting everywhere that the signal-to-noise ratio isn’t terrible.</strong></p>

<h3 id="where-to-promote-your-sale">Where to promote your sale</h3>

<p>The key avenues for promotion—in order of importance—are your <em>website</em>, your <em>email list</em>, and <em>other online marketing channels</em>.</p>

<p><strong>Your website is your best source of potential customers.</strong></p>

<p>No one is more likely to be interested in your deal than someone who is already browsing your product website,
so you should do everything you can to ensure all website visitors see your deal.</p>

<p>I used the common technique of splashing a big-ass colorful banner on every page of the site.
Here’s what it looked like.</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-sale.png" alt="Pegasus Sale"></p>

<p>Don’t be shy promoting your sale on your website. These are the people most likely to benefit from it.</p>

<p>Your goal is to make it impossible for someone visiting your website to not hear of the sale,
so err on the side of flashy, even if it seems a bit much.</p>

<p><strong>Your email list is your next best source of potential customers.</strong></p>

<p>People on your email list were interested in your product at one point, and so are more likely
than almost anyone else to still be interested, so make sure to let them know!</p>

<p>My email sequence consisted of two mails:</p>

<ol>
  <li>An email at the start of the sale telling people about it.</li>
  <li>An email with 24 hours left in the sale telling people it was about to end.</li>
</ol>

<p>Some people add a third email in the middle—often with 48 hours to go. 
I don’t recommend more than 3 emails as you seriously risk pushing people 
further into the “annoyed” category.</p>

<p>In terms of email copy—you can’t do better than the Wes Bos example above.
But for the sake of transparency, here’s the mail I used:</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-email.png" alt="Pegasus Email"></p>

<p>The first email in my sequence announcing the Pegasus Black Friday deal.</p>

<p>One difference between Wes and I is that my email list is <em>cold</em>—I almost never use it.
So I added a reminder for people who might be wondering what Pegasus even was.
I also included details on some new features to show that I’m still improving the product.</p>

<p><strong>All other channels besides your website and email list are a distant third in terms of usefulness.</strong></p>

<p>For this reason, I severely limited promotion in other places unless they were 
specifically aggregating Black Friday deals—and therefore unlikely to annoy anyone.</p>

<p>Depending on your product and audience, social media can be a good channel, though it’s not for Pegasus
so I didn’t bother promoting there.<sup id="fnref:2"><a href="#fn:2">1</a></sup></p>



<p>It’s important to realize that unless you did something very wrong, 
<strong><em>people will be more likely to purchase your product during a sale than at any other time.</em></strong></p>

<p>Now, if you’ve taken the advice above and are still getting good revenue-per-customer during
the sale, there is an interesting side-effect:
<strong>website traffic <em>during a sale</em> is more valuable than at any other time</strong>.</p>

<p>I’ll show you just how much more valuable it was for me in the next section <em>(preview: it was way more than I expected)</em>.</p>

<p>In practice, this means that any additional effort you can expend to get people to your website—for any reason—will 
have a higher payoff during a sale.</p>

<p>How you leverage this information depends on your marketing strategy.
If you’re running ads, consider increasing your budget while the sale is running;
if you do content marketing, consider publishing your next big article during the sale, etc.
These efforts—while not necessarily directly related to the sale—will have the side-effect of getting
more eyes on your site at the exact moment your …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.coryzue.com/writing/black-friday/">https://www.coryzue.com/writing/black-friday/</a></em></p>]]>
            </description>
            <link>https://www.coryzue.com/writing/black-friday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372636</guid>
            <pubDate>Thu, 10 Dec 2020 11:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eisenhower Matrix – How to Prioritise and Master Tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25372423">thread link</a>) | @rossnoel
<br/>
December 10, 2020 | https://productive.fish/blog/eisenhower-matrix/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/eisenhower-matrix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>30 Oct 2020 • 5 min read</p><p>Throughout his life, President Dwight D. Eisenhower was well known as a man of productivity. Before he was president, he was a five start general of the US Army, being a key strategist for many invasions against the Nazis in World War II. On becoming President, he launched many of the significant projects and departments that are still integral to the USA today, such as the interstate highway system, NASA and DARPA. His productivity became well-renowned and researched, and by far one of the most useful strategies he's credited for devising is the Eisenhower Matrix. A simple method to deploy in our everyday lives, it can help you increase productivity, avoid procrastination, and order your workflow. So, what exactly is it and how does it work?</p><picture><source type="image/webp" media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.webp 2x"><source type="image/webp" media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.webp 2x"><source type="image/webp" media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.webp 2x"><source media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.jpg 2x"><source media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.jpg 2x"><source media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.jpg 2x"><img src="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg" alt="Illustration of person watching on Eisenhower Matrix and thinking"></picture><h2 id="what-is-the-eisenhower-matrix%3F">What is the Eisenhower Matrix?</h2><p>The method begins by creating a 2x2 matrix. On the X axis of our matrix we have Urgent and Not Urgent. On the Y axis, we have Important and Not Important. With these different boxes, we have four quadrants, each with a different value, and as such, each to be handled very differently.</p><p>The four quadrants are essentially divided into the following categories:</p><ul><li>Urgent and important - <strong>do it</strong></li><li>Important, but not urgent - <strong>schedule it</strong></li><li>Urgent, but not important - <strong>delegate i</strong>t</li><li>Neither urgent, nor important - <strong>eliminate it</strong></li></ul><p>The Eisenhower Matrix teaches us to swiftly recognise the importance and urgency of tasks on our to-do lists. By categorising the tasks in the above way we can figure out which ones to prioritise, which to put on the back-burner for later, which to delegate, and which to eliminate. This will both put your to-do list in an order of priority, and shrink it down.</p><p>But how do we distinguish between “urgent and important” and everything in between?</p><h2 id="what-are-%22urgent%22-and-%22important%22-activities%3F">What Are "Urgent" and "Important" Activities?</h2><p>Important things are, well, important.They are the things that move us closer to our defined goals, dreams, and aspirations in life. They have meaning and impact to what actually matters to us in our lives. Running in alignment with your values, important things include, going to the gym, spending time with your family, or coming up with a strategic plan for your business.</p><p>On the other hand, we have urgent things. Urgent things require your immediate attention like a call from an angry customer, or picking up your kid from the nurse's office at school.</p><p>More often than not, things don’t tend to be both important and urgent. A lot of the time we mistake urgent tasks as being inherently important, with their acute timeframe masking the true value of what they actually represent in our lives.</p><p>The Eisenhower Matrix is an amazing tool to combat this frequent “mislabelling” of tasks in our workflow, and by mapping out a matrix of urgency and importance, we get a clearer picture of what’s on our slate.</p><h2 id="how-to-use-the-eisenhower-matrix-effectively">How to Use the Eisenhower Matrix Effectively</h2><p>In order to implement the Eisenhower Matrix effectively, one must identify which of the four quadrants a task or a project sits in, and then give it the appropriate action. So what are the traits that come with each category, and (having filed the task appropriately) what should you do with it?</p><h3 id="quadrant-one%3A-urgent-and-important">Quadrant One: Urgent and Important</h3><p>These are tasks that are not only important, but also time sensitive. These might include taking care of a sick relative, addressing an order-dispute for your biggest customer or fixing a crucial bug on the company website. Hopefully you shouldn’t have too many of these but something landing in this box should be done immediately with everything else put aside to make space for it.</p><h3 id="quadrant-two%3A-important%2C-but-not-urgent">Quadrant Two: Important, But Not Urgent</h3><p>This is where some of the most important things in our lives live, and yet many people will see tasks piling up here. Why? Because these jobs are not urgent we often let them slide or delay into the indefinite. Whilst they might not have the immediacy of Quadrant One tasks, it’s important to recognise they are truly no less important.</p><p>These tasks include long-term strategy and planning meetings with your team, performing regular website maintenance, exercising, spending quality time with your friends and family, meditating, and sleeping enough.</p><p>These things won't pop out at you with red flashing lights, but there's no denying that they are extremely important. Indeed if not taken care of, they could soon turn into a hoard of urgent jobs bashing on the door of Quadrant One.</p><p>When it comes to Quadrant Two tasks, stop procrastinating and make a decision. Ask yourself, “When will I sit down and do these things?”. If you're a business owner or a manager in a company, these tasks are probably the most significant part of your job. It’s tempting to ignore Quadrant Two for the sake of addressing Quadrant Ones and Quadrant Threes, but come under no illusions, these need to be tackled, so schedule them in and stick to those deadlines.</p><h3 id="quadrant-three%3A-urgent%2C-but-not-important">Quadrant Three: Urgent, But Not Important</h3><p>We all hate to admit it, but a lot of the stuff we do, whilst urgent, is actually not important at all. For example, monitoring comments on your website or social media, attending a quarterly business update, or scheduling a Zoom meeting. Of course these are worth doing, but they’re just not important. Certainly not enough for you to actually do them yourself. That's why the answer to Quadrant Three tasks is a simple one: delegate. Find a technological solution, an automation, or a human being who can help you with this task and pass it off to them. Ideally you want to spend as little of your time as possible in Quadrant Three.</p><h3 id="quadrant-four%3A-not-urgent%2C-and-not-important">Quadrant Four: Not Urgent, and Not Important</h3><p>These represent a large category of tasks that aren't worth your time or anyone else’s for that matter (not even that programme or person you got to help you out in Quadrant Three). Some of these may be enjoyable, but they're not moving you towards your desired goals in any way, shape, or form. Things like watching television or scrolling through social media for example. While Quadrant Four tasks inevitably pervade our lives, look to try and eliminate these activities as much as possible.</p><h2 id="how-to-use-the-eisenhower-matrix-to-increase-productivity">How to Use the Eisenhower Matrix To Increase Productivity</h2><p>The Eisenhower Matrix is especially useful if you find yourself dealing with excessive amounts of work. With an overabundance of tasks, taking a bit of time to categorise your jobs into the four quadrants above can restore order to an otherwise chaotic workflow.</p><p>It’s also good to incorporate the overarching philosophy of this time management matrix into your daily workflow. Whether it’s on a daily or weekly basis, the Eisenhower Matrix will help prioritise the items on your to-do list. Look to commit to scheduling or prioritising your tasks as per the above, and you’ll find yourself with a clearer and more effective work-day</p><h2 id="conclusion">Conclusion</h2><p>The nature of our work-environment today, as shaped by email, instant messaging and the like, means we feel constantly in need of prioritising our requests in order of when the message was received. However, this approach often leaves us with a feeling of dissatisfaction with our own productivity, finding that the majority of the day has been spent handling items we could have delegated or just eliminated, and jobs that don’t progress our life-goals or objectives.</p><p>Instead, the Eisenhower Decision Matrix provides an excellent framework to help you cut through the clutter and finish your most important work in record time, whilst making sure you’re not wasting precious hours and minutes on things that can either be done elsewhere or just not at all. By giving you the skill of distinguishing between which tasks truly demand your attention, and those that don’t, the Eisenhower Box will keep you focused on what’s important, and in doing so change not just the output you see in your day or your week, but also your life.</p></article></div>]]>
            </description>
            <link>https://productive.fish/blog/eisenhower-matrix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372423</guid>
            <pubDate>Thu, 10 Dec 2020 11:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnt $72k testing Firebase and Cloud Run and almost went bankrupt]]>
            </title>
            <description>
<![CDATA[
Score 249 | Comments 347 (<a href="https://news.ycombinator.com/item?id=25372336">thread link</a>) | @bharatsb
<br/>
December 10, 2020 | https://blog.tomilkieway.com/72k-1/ | <a href="https://web.archive.org/web/*/https://blog.tomilkieway.com/72k-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>                
			<blockquote>
  <p>This is the story of how close we came to shutting down before even launching our first product, how we survived, and the lessons we learnt.</p>
</blockquote>

<p>In March, 2020, when COVID hit the world, our startup Milkie Way too was hit with a big blow and almost shut down. <strong>We burnt $72,000 while exploring and internally testing Cloud Run with Firebase within a few hours.</strong></p>

<p>In November 2019, after having the idea, I started developing <strong>Announce <a href="https://annc.in/">https://announce.today</a></strong>. The goal was to create an “MVP”, a functional V1 of the  product, and for this reason our code was based on a simple stack. We used JS, Python and deployed our product on Google App engine.</p>

<center>
<em>Announce on Desktop</em>
<img src="https://blog.tomilkieway.com/assets/images/post_images/anc-first-look.png" width="100%"><br>
</center>

<p>Having a very small team, our focus was on writing code, designing the UI and getting product ready. I spent minimal time in Cloud management, just enough to make us go live, and have basic development flow (cicd) going.</p>

<p>In the V1 web application, user experience was not the smoothest, but we just wanted to make a product that some of our users could experiment with, while we built a better version of Announce. With Covid hitting the world, we thought it was the best time to make a difference as Announce could be used by the governments to make announcements world wide.</p>

<p>Wouldn’t it be cool to have some rich data on the platform even if users don’t create content to begin with? This thought that led to another project, called <strong>Announce-AI</strong>. It’s purpose was to create rich content for Announce automatically. Rich data == events, safety warnings like earthquakes, and possibly local relevant news.</p>

<h3 id="some-technical-details">Some Technical Details</h3>
<p>To begin developing Announce-AI, we used Cloud Functions. As our bot scraping the web was fairly young, we believed light weight Cloud functions were the way to go. However, as we decided to scale, we ran into troubles because Cloud Functions have a timeout of ~9 minutes.</p>

<p>At this time we learn about Cloud Run, which then had a big free usage tier! Without understanding it completely, I asked my team to deploy a “test” Announce AI function on Cloud Run, and see it’s performance. The goal was to play around with Cloud Run, so we can learn and explore it really fast.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/cloud-run.jpg" width="80%"><br>
<em>Google Cloud Run</em></center>

<p>To keep it simple, as our experiment was for a very small site, we used Firebase for database, as Cloud Run doesn’t have any storage, and deploying on SQL server, or any other DB for a test run would have been an over kill.</p>

<p>I created a new GCP project ANC-AI Dev, set up $7 Cloud Billing budget, kept Firebase Project on the Free (Spark) plan. The worst case we imagined was exceeding the daily free Firestore limits if we faltered.</p>

<p>After some code modifications, we deployed the code, ran it by making few requests in middle of the day manually and then left it.</p>

<h3 id="nightmare-begins">Nightmare Begins</h3>
<p>Everything went fine on the day of test, and we got back to developing Announce. Next day after working, I went for a quick nap in late afternoon. On waking up I read few emails from Google Cloud, all sent within few minutes of each other.</p>

<center>
<em>First Email: Auto upgrade of our Firebase Project</em>
<img src="https://blog.tomilkieway.com/assets/images/72K/auto-upgrade.jpg" width="80%"><br>
</center>

<center>
<em>Second Email: Budget Exceeded</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/budget.jpg" width="80%"><br>
</center>

<p>Luckily my card had a spending limit of $100 preset. This led to declining the charges, and Google suspending all our accounts with it.</p>

<center>
<em>Third email: Card was declined</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/card-declined.jpg" width="80%"><br>
</center>

<p>I jumped out of the bed, logged into Google Cloud Billing, and saw a bill for ~$5,000. Super stressed, and not sure what happened, I clicked around, trying to figure out what was happening. I also started thinking of what may have happened, and how we could “possibly” pay the $5K bill.</p>

<p>The problem was, every minute the bill kept going up.</p>

<p>After 5 minutes, the bill read $15,000, in 20 mins, it said $25,000. I wasn’t sure where it would stop. Perhaps it won’t stop?</p>

<p>After two hours, it settled at a little short of $72,000.</p>

<p>By this time, my team and I were on a call, I was in a state of complete shock and had absolutely no clue about what we would do next. We disabled billing, closed all services.</p>

<p>Because we used same company card across all our GCP Projects, all our accounts and projects were suspended by Google.</p>

<h3 id="nightmare-continues">Nightmare Continues</h3>
<p>This happened on Friday evening, March 27th, 3 days before we had planned V1 of Announce to go live. Our product development was dead as Google suspended all our projects as they were tied to same credit card. My morale was as low as it could be, and the future of our company was unsure.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/suspended.jpg" width="80%"><br>
<em>All our Cloud Projects were suspended; development stopped</em></center>

<p>Once my mind made peace with this new reality, at midnight I sat down to actually investigate what happened. I started writing a document detailing all the investigations… I called this document: “Chapter 11”.</p>

<p>Two of my team members who were in this experiment also stayed up all night investigating and trying to make sense of what had happened.</p>

<p>The next morning on Saturday, March 28th, I called and emailed over a dozen law firms to book an appointment / have a chat with some attorney. All of them were away, but I was able to get response from one of them over email. Because the details of the incident are so complicated even for engineers, explaining this to an attorney in plain english was a challenge of its own.</p>

<blockquote>
  <p>As a bootstrapped company, there was no way for us to come up with $72K.</p>
</blockquote>

<p>By this time, I was well versed with Chapter 7 and Chapter 11 of Bankruptcy and mentally prepared of what could come next.</p>

<h3 id="some-breather--gcp-loopholes">Some Breather : GCP Loopholes</h3>

<p>On the Saturday after sending emails to lawyers, I started reading more and going through every single page in GCP Documentation. We did make mistakes, but it didn’t make sense that Google let us spend $72K without even making a payment on the project before!</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/firebasegcp.jpg" width="80%"><br>
<em>GCP and Firebase</em></center>

<h4 id="1-automatic-upgrade-of-firebase-account-to-paid-account">1. Automatic Upgrade of Firebase Account to Paid Account</h4>
<p>We never anticipated this, nor was this ever displayed while signing up for Firebase. Our GCP project had billing connected to have Cloud Run execute, but Firebase was under Free plan (Spark). GCP just out of the blue upgraded it, and charged us for the amount it needed to.</p>

<p>It turns out this is their process as “Firebase and GCP are deeply integrated”.</p>

<h4 id="2-billing-limits-dont-exist-budgets-are-at-least-a-day-late">2. Billing “Limits” don’t exist. Budgets are at least a day late.</h4>
<p>GCP Billing is actually delayed by at least a day. In most of their documentation Google suggests using Budgets and auto shut-off cloud function. Well guess what, by the time the cut off function would trigger, or the Cloud Users be notified, the damage would’ve probably been done.</p>

<p>Billing takes about a day to be synced, and that’s why we noticed the charges the next day.</p>

<h4 id="3-google-was-supposed-to-charge-us-100-not-72k">3. Google was supposed to charge us $100, not $72K!</h4>
<p>As our account had not made any payment thus far, GCP should’ve first made charge for $100 as <a href="https://cloud.google.com/billing/docs/how-to/billing-cycle#find-threshold-amount">per billing info</a>, and on non-payment, stopped the services. But it didn’t. I understood the reason later, but it’s still not the user’s fault!</p>

<p>The first billing charge made to our account was of ~ $5,000. The next one for $72,000.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/automatic-payments.jpg" width="100%">
<em>Billing threshold for our account was $100</em>

</center>

<h4 id="4-dont-rely-on-firebase-dashboard">4. Don’t rely on Firebase Dashboard!</h4>
<p>Not just Billing, but even Firebase Dashboard took more than 24 hours to update.</p>

<p>As per Firebase Console documentation, the Firebase console dashboard numbers may differ ‘slightly’ from Billing reports.</p>

<p>In our case, it differed by <strong>86,585,365.85 %</strong>, or 86 million percentage points. Even when the bill was notified to us, Firebase Console dashboard still said 42,000 read+writes for the month (below the daily limit).</p>

<h3 id="new-day-new-challenge">New Day, New Challenge</h3>
<p>Having been a Googler for ~6.5 years and written dozens of project documents, postmortem reports, and what not, I started a document to share with Google outlining the incident, and adding the loopholes from Google’s side in a postmortem. Google team would come back to work in 2 days.</p>

<p>EDIT: Some readers suggested that I used my internal contacts at Google. The truth is that I haven’t been in touch with anyone, and I used the path that any normal developer / company would take. Like any other small developer, I spent countless hours on chat, in consults, lengthy emails, and bugs. In one of my next posts on how to look at incidents, I’d like to share the doc/postmortem I sent to Google during this incident.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/googleplex.jpg" width="40%"><br>
<em>Last day at Google</em></center>

<p>Another task was to understand our mistake, and devise our product development strategy. Not everyone on the team knew what was going on, but it was quite clear that we were in some big trouble.</p>

<p>As a Googler I had experienced teams making mistakes costing Google millions of dollars, but the Google culture saves the employees (except engineers have to write a long incident report). This time, there was no Google. Our own limited capital and our hard work, was at complete stake.</p>

<hr>

<p>This post is already getting long, so I’ll continue the details of how we managed to make this blunder, how we survived, and what did we learn.</p>

<p>See you in <strong><a href="https://blog.tomilkieway.com/72k-2/">Part 2: https://blog.tomilkieway.com/72k-2</a></strong>.</p>
                
			</article></div>]]>
            </description>
            <link>https://blog.tomilkieway.com/72k-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372336</guid>
            <pubDate>Thu, 10 Dec 2020 10:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsche Post to support DIY postal stamps (via handwritten code)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25372252">thread link</a>) | @tosh
<br/>
December 10, 2020 | https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327 | <a href="https://web.archive.org/web/*/https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Kunden sollen früh wissen, welche Briefe für sie unterwegs sind und wo sich Pakete befinden. Das Unternehmen will sich damit auch auf junge Kunden einstellen und sucht einen zeitgemäßen Weg für seine sehr analogen Produkte.</p><div itemprop="articleBody" data-testid="article-body"><p>Zwischen den Managern in schwarzen Anzügen strahlt ein Paketbote in gelb-roter DHL-Montur hervor. Wenn er nicht gerade bei der Vorstellung der neuen Digitalstrategie der Deutschen Post Modell steht, dann fährt Maik Berkholz mit einem 3,5-Tonner durch Berlin-Mitte. Seit zehn Jahren liefert Berkholz Pakete aus. Und neuerdings trägt er neben seinem Unterschriftgerät einen kleinen Drucker am Hosenbund. Denn Berkholz ist nicht mehr nur Paketbote, er frankiert auch Pakete und Briefe und nimmt sie im Lieferwagen mit. "Die Kunden finden das super", sagt er mit abgehacktem Berliner Zungenschlag, "wenn sie mir das mitgeben können und nicht bei der nächsten Filiale anstehen&nbsp;müssen."</p><p>Der kleine Drucker ist eine der vielen Ideen, mit der die Post eine dreifache Herausforderung meistern will: Ihre Kunden versenden von Jahr zu Jahr weniger Briefe, wenngleich die Menge in Deutschland bislang nicht so stark eingebrochen ist wie in anderen Staaten. Zugleich transportiert die Post immer mehr Pakete durchs Land, vor allem wegen des boomenden Onlinehandels. Die Bundesnetzagentur meldet freilich auch, dass sich immer mehr Menschen über die Post&nbsp;beschweren.</p><div><div data-hydration-component-name="ImageAsset"><figure><div><div><picture><source type="image/webp"><img alt="20 Jahre Briefzentrum Gera" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></picture></div></div><figcaption><p>Eine Mitarbeiterin arbeitet an der Briefsortierungsanlage im Briefzentrum in Gera, Thüringen.</p> <small>(Foto: Martin Schutt/dpa)</small></figcaption></figure></div></div><p>"Wir wollen die sichere Zustellung von Paketen und Briefen beibehalten, diese aber mit der Digitalisierung koppeln", sagt Tobias Meyer, der Brief- und Paketchef der Post in&nbsp;Deutschland.</p><p>Dass Kunden Boten wie Berkholz Pakete mitgeben, das ging zwar schon früher. Neu ist aber, dass der Kunde das Adress- und Frankierfeld nicht mehr aufkleben muss. Stattdessen kann Berkholz ein selbstklebendes Adressfeld und eine Marke aus seinem mobilen Drucker ausdrucken. Dafür scannt der Bote einen Code vom Handy des Kunden ein. Der Code wurde erstellt, nachdem der Kunde via Post-App auf seinem Smartphone das Porto bezahlt und die Adresse eingegeben hat. Die "mobile Paketmarke" für die "mobile Retour", so nennt es Manager&nbsp;Meyer.</p><p>Mit der Digitalstrategie will die Post neuen Bedürfnissen der Kunden gerecht werden, aber auch Geld sparen. Das Versenden, das Empfangen, das Nachverfolgen von Sendungen - selbst Vorabbenachrichtigungen, was morgen im heimischen Briefkasten ankommen soll: All das soll effizienter werden. Bei der Vorstellung in Berlin erklären Männer in schwarzen Anzügen und eine Frau die neuen&nbsp;Services.</p><h4>Abfotografierte Briefe</h4><p>Einer der Männer in schwarz zeigt an seiner Station ein E-Mail-Postfach, in dem lauter gelbe Mails von der DHL lagern. Denn vom kommenden Sommer an wird es für Nutzer von GMX und Web.de möglich sein, Fotos von ihren Briefen zu sehen, bevor sie ausgeliefert&nbsp;werden.</p><p>Dazu scannt die Post eintreffende Briefe ein, ohne sie zu öffnen, und der Empfänger bekommt eine Mail mit dem Foto der Umschläge. Damit kennt man zwar beispielsweise noch nicht die Höhe des Bußgeldbescheids, aber weiß, dass ein solcher auf dem Weg&nbsp;ist.</p><p>Kunden müssen sich für dieses Angebot anmelden. Eine weitere Station präsentiert den Prototypen einer künftigen App-Funktion, die es im Laufe dieses Jahres ermöglichen soll, nachzusehen, wo sich ein erwartetes Paket gerade befindet. Damit reagiert die Post nicht nur auf die vielen Beschwerden über verspätete oder verloren gegangene Sendungen. Experten gehen auch davon aus, dass die sogenannte letzte Meile zu den Adressaten etwa die Hälfte der Kosten von Paketdiensten ausmachen. Konzerne wie die Post können also viel Geld sparen, wenn sie erfolglose Zustellversuche verhindern. Das neue Tracking zeigt den Kunden, wie viele Stopps noch zwischen dem Paketboten und der eigenen Haustüre liegen. Außerdem will die Post künftig am Tag vor der Auslieferung ein Zeitfenster von 90 Minuten angeben, in dem der Paketbote vorbei kommt. Empfänger könnten auch kurzfristig noch mitteilen, falls das Paket beim Nachbarn abgegeben werden soll, im Hausflur abgelegt werden soll, oder in der nächsten&nbsp;Packstation.</p><h4>Erweiterte Packstation</h4><p>Zudem führt ein Postvertreter die Packstation der Zukunft vor, die im Videochat mit dem Kunden kommunizieren soll und ebenfalls Adressfelder und Portosticker drucken kann. Die Post möchte die Zahl der Packstationen von 4000 im Laufe des Jahres auf 7000&nbsp;erhöhen.</p><p>Politisch interessant ist diese Ankündigung, da das Bundeswirtschaftsministerium derzeit an einer Reform des alten Postgesetzes von 1997 arbeitet. Ein Streitpunkt dabei: Wie viele Filialen muss die Post künftig noch aufrechterhalten? Sollte der Gesetzgeber die erweiterten Packstationen als Verkaufsstellen auf dem Land akzeptieren, hätte es der Konzern künftig einfacher, die Vorgaben zu&nbsp;erfüllen.</p><h4>Selbstgemachte Briefmarken</h4><p>An der letzten Station führt die Post vor, wie sie das Briefgeschäft auch für sogenannte Digital Natives - also junge Leute, die mit dem Internet großgeworden sind - attraktiv halten will. Über eine App kann der Kunde die Höhe des Portos wählen, diese spuckt dann einen Code aus Zahlen und Buchstaben aus. Der Kunde schreibt den Code auf das Kuvert mit dem Zusatz "#Porto" - und fertig ist die selbstgemalte Briefmarke. Aber Moment, die Handschrift als Teil einer&nbsp;Digitalisierungsoffensive?</p><p>Was paradox anmutet, soll es Kunden von Ende 2020 an ermöglichen, mit ihrem Handy eine Marke zu generieren. Bezahlt wird die "mobile Briefmarke" über die App mittels dem verbreiteten Bezahldienst Paypal. Ist dies das Ende der bunten Bildchen auf randgezackten Briefmarken? "Nein, nein", wiegelt Post-Vorstand Meyer ab. Es würden nach wie vor Briefmarken angeboten. Zudem glaubt er, dass die Code-Briefmarke aus dem Smartphone nur eine Ergänzung sein&nbsp;wird.</p><div><div><p><span>Streetscooter-Aus verstimmt Zulieferer</span></p><div><p>Die Deutsche Post hat mit dem angekündigten Aus ihrer Produktion des Streetscooters offenbar wichtige Vertragspartner überrumpelt. So erfuhr der Zulieferer Neapco nach eigenen Angaben "überraschend aus den Medien von dieser Nachricht". Neapco stellt der Post in Düren Produktionsflächen sowie etwa 120 Beschäftigte für die Montage der batteriebetriebenen Nutzfahrzeuge zur Verfügung. "Geplant war ein Anstieg der Mitarbeiterzahlen auf etwa 200 in den kommenden Monaten", heißt es von dem Dienstleister.</p>
<p>Die Post hat vorige Woche die Suche nach einem Käufer oder Investor für Streetscooter aufgegeben. Der Konzern verweist auf Millionenverluste seiner Autotochter. Er will die mehr als 11 000 bereits hergestellten E-Fahrzeuge zwar weiterbetreiben, doch soll die Produktion in Aachen und Düren in diesem Jahr auslaufen. Streetscooter beschäftigt selbst etwa 500 Menschen; hinzu kommen Mitarbeiter bei Dienstleistern wie Neapco. Die Post erklärt, dass sie das Aus von Streetscooter ad hoc kommunizieren musste, da es auch für den Kapitalmarkt relevant sei. Der Konzern geht davon aus, dass sich die Abschreibungen auf Streetscooter sowie die Kosten für den Personalabbau und die Abwicklung der Verträge auf bis zu 400 Millionen Euro summieren werden.</p>
<p>Unterdessen kritisiert der Streetscooter-Gründer Günther Schuh, die Post habe nach der Übernahme des Start-ups 2014 "Amateure eingesetzt, jegliche Verbesserung verboten und auf eine Gelegenheit gewartet, das Geschäft unter einem Vorwand einzustellen". Die Post habe Streetscooter weder ausreichend finanziert noch einen Zugang zum Kapitalmarkt gewährt, moniert der Aachener Professor in einem Handelsblatt-Gastbeitrag. Schuh war nach der Übernahme bei Streetscooter ausgeschieden. <span>Benedikt Müller</span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372252</guid>
            <pubDate>Thu, 10 Dec 2020 10:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Week in Rust 368]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25371862">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/ | <a href="https://web.archive.org/web/*/https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/rust-lang/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/rust-lang/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/rust-lang/this-week-in-rust/pulls">please submit a PR</a>.</p>

<h3 id="official">Official</h3>
<ul>
<li><a href="https://blog.rust-lang.org/2020/12/07/the-foundation-conversation.html">The Foundation Conversation</a></li>
</ul>
<h3 id="newsletters">Newsletters</h3>
<ul>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-016/">This Month in Rust GameDev #16 - November 2020</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k6cka7/rib_newsletter_18_on_to_the_ribbles/">RiB Newsletter #18 - On to the Ribbles</a></li>
</ul>
<h3 id="tooling">Tooling</h3>
<ul>
<li><a href="https://rust-analyzer.github.io/thisweek/2020/12/07/changelog-54.html">Rust Analyzer Changelog #54</a></li>
<li><a href="https://ferrous-systems.com/blog/knurling-changelog-9/">Knurling-rs Changelog #9</a></li>
<li><a href="https://blog.jetbrains.com/clion/2020/12/intellij-rust-updates-for-2020-3/">IntelliJ Rust: Updates for 2020.3</a></li>
</ul>
<h3 id="observationsthoughts">Observations/Thoughts</h3>
<ul>
<li><a href="https://www.fpcomplete.com/blog/monads-gats-nightly-rust/">Monads and GATs in Nightly Rust</a></li>
<li><a href="https://fanf.dreamwidth.org/134024.html">Vanishing zeroes for geometric algebra in Rust</a></li>
<li><a href="https://blog.thomasheartman.com/posts/on-generics-and-associated-types">On Generics and Associated Types</a></li>
<li><a href="https://vector.dev/blog/adaptive-request-concurrency/">Adaptive Request Concurrency. Resilient observability at scale.</a></li>
<li><a href="https://blog.logrocket.com/rust-compression-libraries/">Rust compression libraries</a></li>
<li><a href="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">Rust makes cross compilation child's play</a></li>
<li><a href="https://jmmv.dev/2020/12/builder-pattern-for-tests.html">Using the builder pattern to define test scenarios</a></li>
<li><a href="https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html">Measuring Memory Usage in Rust</a></li>
<li><a href="https://www.tag1consulting.com/blog/saving-time-switching-users-async-support-goose">Saving time by switching users: Async support in Goose</a></li>
<li><a href="https://evrone.com/rust-vs-c">Why Rust is meant to replace C</a></li>
</ul>
<h3 id="rust-walkthroughs">Rust Walkthroughs</h3>
<ul>
<li><a href="https://subvisual.com/blog/posts/real-time-video-processing-with-rust-ffmpeg-opencv/">Real-time video processing with Rust, FFmpeg and OpenCV</a></li>
<li><a href="https://dev.to/creativcoder/merge-k-sorted-arrays-in-rust-1b2f">Merge k sorted arrays in Rust</a></li>
<li><a href="https://arzg.github.io/lang/13/">Make A Language - Part Thirteen: Whitespace &amp; Events</a></li>
<li><a href="https://jmmv.dev/2020/12/unit-testing-a-console-app.html">Unit-testing a console app (a text editor)</a></li>
<li><a href="https://blog.drogue.io/rust-and-async/">Rust and Async (on embedded devices)</a></li>
<li><a href="https://www.fpcomplete.com/blog/avoiding-duplicating-strings-rust/">Avoiding Duplicating Strings in Rust</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-custom-target-to-build-kernel-for-a-bare-metal-part-3/">OS in Rust: Custom target to build kernel for bare metal: Part-3</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-building-kernel-for-custom-target-part-4/">OS in Rust: Building kernel for custom target: Part-4</a></li>
<li>[video] <a href="https://youtu.be/lLWchWTUFOQ">Introduction to Rust Part 2</a></li>
</ul>
<h3 id="project-updates">Project Updates</h3>
<ul>
<li><a href="https://github.com/EmbarkStudios/rust-gpu/releases/tag/v0.2">rust-gpu v0.2</a></li>
<li><a href="https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell">Interior Mutability in Rust: Understanding The Cell Type</a></li>
</ul>
<h3 id="miscellaneous">Miscellaneous</h3>
<ul>
<li><a href="https://www.infoq.com/news/2020/12/cpp-rust-interop-cxx/">Safe Interoperability between Rust and C++ with CXX</a></li>
<li><a href="https://opensource.googleblog.com/2020/12/expanding-fuchsias-open-source-model.html">Expanding Fuchsia's open source model</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k75tez/miri_can_now_detect_data_races/">Miri can now detect data races</a></li>
</ul>

<p>This week's crate is <a href="https://github.com/not-a-seagull/breadx">breadx</a>, a X-windows protocol implementation in 100% safe and mutex-free Rust.</p>
<p>Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/851">Willi Kappler</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>

<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<ul>
<li><a href="https://github.com/AaronErhardt/Triox/labels/good%20first%20issue">Triox - Good First Issues</a></li>
<li><a href="https://github.com/libssh2/libssh2/pull/517">libssh2 - Pull Request Needs Windows Reviewer</a></li>
</ul>

<p>279 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2020-11-30..2020-12-07">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/78684">add wasm32 support to inline asm</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79509">improve attribute message error spans</a></li>
<li><a href="https://github.com/rust-lang/chalk/pull/659">chalk: always relate with Invariant to non-General inference vars</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79680">fix perf regression caused by match exhaustiveness split</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79623">pass around Symbols instead of Idents in doctree</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79620">tweak diagnostics on shadowing lifetimes/labels</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/78122">avoid panic_bounds_check in <code>fmt::write</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79650">fix incorrect <code>io::Take</code>'s limit resulting from <code>io::copy</code> specialization</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79600"><code>std::io</code>: use sendfile for UnixStream</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8937">cargo: slightly optimize `cargo vendor</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8725">cargo: add "--workspace" to update command</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79539">rustdoc: JSON backend experimental impl</a></li>
</ul>
<h2 id="rust-compiler-performance-triage">Rust Compiler Performance Triage</h2>
<ul>
<li><a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">2020-12-08</a>:
0 Regressions, 2 Improvements, 1 Mixed</li>
</ul>
<p>Triage done by @simulacrum.</p>
<p>See the <a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">full report</a> for more.</p>
<h2 id="approved-rfcs">Approved RFCs</h2>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments) process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>

<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h3 id="rfcs"><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h3>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/3007">RFC: Plan to make core and std's panic identical</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2992">RFC: Add <code>target_abi</code> configuration</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2859">added secret types rfc</a></li>
</ul>
<h3 id="tracking-issues-prs"><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h3>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79642">rustdoc: stabilise --default-theme command line option</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79502">Implement <code>From&lt;char&gt;</code> for u64 and u128.</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79485">Stabilize <code>unsafe_cell_get_mut</code></a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79473">Move <code>{f32,f64}::clamp</code> to core</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79342">Stabilize all stable methods of <code>Ipv4Addr</code>, <code>Ipv6Addr</code> and <code>IpAddr</code> as const</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79270">Acknowledge that <code>[CONST; N]</code> is stable</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79261">Deprecate atomic compare_and_swap method</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79213">Stabilize <code>core::slice::fill</code></a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/79188">Made matches! more useful by adding mapping support</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79073">passes: prohibit invalid attrs on generic params</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79022">stabilize deque_range</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/78367">Apply <code>unused_doc_comments</code> lint to inner items</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78242">Rename <code>overlapping_patterns</code> lint</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78083">Stabilize or_insert_with_key</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/77688">Add built-in implementations of <code>Default</code> for function definition and… </a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74699">Mark <code>-1</code> as an available niche for file descriptors</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74304">Stabilize the Wake trait</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/63514">Tracking issue for map_ok and map_err method for <code>Poll&lt;Option&lt;Result&lt;T, E&gt;&gt;&gt;</code></a></li>
</ul>
<h2 id="new-rfcs">New RFCs</h2>
<p><em>No new RFCs were proposed this week.</em></p>

<h3 id="online">Online</h3>
<ul>
<li><a href="https://www.meetup.com/de-DE/Rust-Community-Stuttgart/events/274892215/">December 10, Stuttgart, DE - Hack &amp; Learn - Directions for 2021 - Rust Community Stuttgart</a></li>
<li><a href="https://www.meetup.com/San-Diego-Rust/events/274757235/">December 10, San Diego, CA, US - San Diego Rust December 2020 Tele-Meetup - San Diego Rust</a></li>
<li><a href="https://www.meetup.com/RustDC/events/274460587">December 10, Washington, DC, US - How oso built a runtime reflection system for Rust—Rust DC</a></li>
<li><a href="https://www.meetup.com/Rust-%D0%B2-%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B5/events/274924961/">December 15, Russia - Russian Rust Online Meetup</a></li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/npqfbsybcqbvb/">December 16, Vancouver, BC, US - Are Results just Checked Exceptions? - Vancouver Rust</a></li>
</ul>
<h3 id="north-america">North America</h3>
<ul>
<li><a href="https://www.meetup.com/utah-rust/events/273530244/">December 10, Provo, UT, US - Mob Programming: Add <code>--tree -d</code> to <code>lsd</code></a></li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>

<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<ul>
<li><a href="https://www.pathai.com/careers/?gh_jid=4983568002">Software Engineer, Systems at PathAI (Boston, MA, US)</a></li>
<li><a href="https://www.welcometothejungle.com/fr/companies/meilisearch/jobs/software-developer-rust_paris">Software Developer (Rust) at MeiliSearch (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4019a818-4a7b-46ef-9225-c53c7a7f238c">Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/fe1e07f4-6d7c-4f65-9a8f-27cf3b3fd2b1">Backend Engineer, Kraken Futures - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/2442ee5c-56b6-4a73-a477-8cdda2b218d5">Rust Engineer, Desktop GUI - Cryptowatch at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4c864c8f-bde6-443d-b521-dd90df0e9105">Senior Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/2863623f-13c9-4f50-992d-7c25736a60f9">Senior Banking Engineer - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4485f672-dc5f-4e49-a10b-2b0399e28a8d">Software Engineer - Trading Technology (Rust) at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://stackoverflow.com/jobs/294502/rust-for-embedded-environments-ockam">Rust for Embedded Environments at Ockam (Remote)</a></li>
<li><a href="https://stackoverflow.com/jobs/400828/messaging-protocol-architect-in-elixir-and-rust-ockam">Messaging protocol architect in Elixir (and Rust) at Ockam (Remote)</a></li>
<li><a href="https://nzxt.bamboohr.com/jobs/view.php?id=259">Senior Software Engineer (Rust &amp; C++) at NZXT (Remote)</a></li>
<li><a href="https://www.notion.so/Embedded-Firmware-Engineer-in-C-Rust-a9c741c539454ee7b8bbb969d8e90da2">Embedded Firmware Engineer in C &amp; Rust at Astropad (Remote, US)</a></li>
</ul>

<blockquote>
<p>Writing rust for me is a gradual process of the compiler patiently guiding me towards the program I should have written in the first place, and at the end I take all the credit.</p>
</blockquote>
<p>– <a href="https://discord.com/channels/442252698964721669/448238009733742612/783395725991084074">@felixwatts on Discord</a></p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/972">Joshua Nelson</a> for the suggestion.</p>
<p><a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit quotes and vote for next week!</a></p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nellshamrell">nellshamrell</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/cdmistman">cdmistman</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/ka8fvg/this_week_in_rust_368/">Discuss on r/rust</a></small></p>
  </article></div>]]>
            </description>
            <link>https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371862</guid>
            <pubDate>Thu, 10 Dec 2020 09:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Web Service to Manage Scientific Simulation Data Using GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371580">thread link</a>) | @felipez
<br/>
December 10, 2020 | https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@f.zapata?source=post_page-----a0bbf1c3f6e9--------------------------------" rel="noopener"><img alt="Felipe" src="https://miro.medium.com/fit/c/96/96/1*f7WZ93VZ5pv2qgIxOhxJUA.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="77c2">Scientific simulations generate large volume of data that needs to be stored and processed by multidisciplinary teams across different geographical locations. Distributing computational expensive simulations among the available resources, avoiding duplication and keeping the data safe are challenges that scientists face every day.</p><p id="8d66">In this post we present our web service <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> and its command line interface <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a>. Insilico solves the problem of <em>computing</em>, <em>storing</em> and <em>securely sharing</em> computationally <em>expensive</em> simulation results. Researchers can save significant time and resources by easily computing new data and reusing existing simulation data to answer their questions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9856/0*bI9DbwobcmYvOYyk" width="4928" height="3280" srcset="https://miro.medium.com/max/552/0*bI9DbwobcmYvOYyk 276w, https://miro.medium.com/max/1104/0*bI9DbwobcmYvOYyk 552w, https://miro.medium.com/max/1280/0*bI9DbwobcmYvOYyk 640w, https://miro.medium.com/max/1400/0*bI9DbwobcmYvOYyk 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bI9DbwobcmYvOYyk?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@publicpowerorg?utm_source=medium&amp;utm_medium=referral" rel="noopener">American Public Power Association</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="71c5">At the <a href="https://www.esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a> we empower academic researchers by building together simulation tools, data pipelines, etc. A common goal among several tools that we develop for projects in different scientific fields, is to reduce the calculation time of computationally expensive physical simulations (e.g. molecular processes) by applying statistical methods to previously simulated data.</p></blockquote><p id="204c">The aforementioned methodology can potentially save us significant human and computational resources by easily generating high value data using previous computations. But before we are ready to apply any statistical method we of course need the data and for doing so, we need to ask ourselves questions like:</p><blockquote><p id="7c69">What input is required?</p><p id="75eb">Who is going to perform the simulation?</p><p id="a35c">What facilities are going to be used?</p><p id="93ec">Where is the resulting data going to be stored?</p><p id="6091">How to access the available data?</p></blockquote><p id="6fb9">Physical simulations usually require intricate input that takes into consideration several aspects and parameters used by different models to approximate the phenomena under consideration. Also, scientific simulations are computationally demanding tasks, so they are usually run in (inter)national supercomputers or very specialized facilities. We also want to maximize the impact of the data in the scientific community, therefore we want other scientists to be able to access the data and even add their own, but we need some security layers to protect such valuable data.</p><p id="bcb8">There is no silver bullet to address all the previous questions, but there are amazing initiatives like the <a href="https://foldingathome.org/" rel="noopener">folding at home project</a> that distributes some computational tasks among volunteers around the world who give away some time in their computers to simulate protein dynamics.</p><p id="6858">It seems that if we want to collaborate on the distribution of computational tasks and the assemblage of the resulting data, we need a central “entity” that (1) allows users to request new tasks, (2) receives the task’s results to be stored and (3) returns some available data when requested. It sounds like we need a web service!</p><blockquote><p id="6a2b">Writing a web service is a nontrivial task, you need to be aware of different technologies, libraries, etc. while making sure that your data is going to be safe and of course you need some infrastructure to host your service. This post goal is to give you some hints about building a web service for scientific applications and it is by no means a complete guide to writing web applications.</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9662/0*HnAn4y-BQGmvGjGZ" width="4831" height="3221" srcset="https://miro.medium.com/max/552/0*HnAn4y-BQGmvGjGZ 276w, https://miro.medium.com/max/1104/0*HnAn4y-BQGmvGjGZ 552w, https://miro.medium.com/max/1280/0*HnAn4y-BQGmvGjGZ 640w, https://miro.medium.com/max/1400/0*HnAn4y-BQGmvGjGZ 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*HnAn4y-BQGmvGjGZ?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@johnschno?utm_source=medium&amp;utm_medium=referral" rel="noopener">John Schnobrich</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Before entering into the web service technical details, let’s explore what its behavior should be.</p><p id="74cc">So, once it has been decided what are the best approximations and models to perform the simulations, we can compile all the simulation metadata into different jobs. For instance, a job can be a single molecular simulation under some specific conditions. We would like to make all these jobs available to the users, in such a way that they can run one or more jobs at a time but avoiding that the same job is run by more than one user.</p><p id="2b33">It would be great that when the simulation is done a user can send the results to the web service or ask for already available results. We also want to be able to call the web service from our local computer, specialized infrastructure or wherever we want to perform the computation, without worrying about where the service is running.</p><p id="be30">It seems, that we want a <a href="https://en.wikipedia.org/wiki/Git" rel="noopener">Git</a>-like behavior where we can pull jobs (or available data) and push results.</p><p id="ba78">With these requirements in mind, I have developed an open source web service called <a href="https://github.com/nlesc-nano/insilico-server" rel="noopener">Insilico-server</a>. Let’s see how it works!</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7296/0*P4hHvh84YZQLPGgi" width="3648" height="2432" srcset="https://miro.medium.com/max/552/0*P4hHvh84YZQLPGgi 276w, https://miro.medium.com/max/1104/0*P4hHvh84YZQLPGgi 552w, https://miro.medium.com/max/1280/0*P4hHvh84YZQLPGgi 640w, https://miro.medium.com/max/1400/0*P4hHvh84YZQLPGgi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P4hHvh84YZQLPGgi?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@andrew_gook?utm_source=medium&amp;utm_medium=referral" rel="noopener">Andrew Gook</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="773a">The web service consists of two parts: a small command line interface (CLI) that communicates with the service and the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico web service</a> that handles all the data.</p><p id="0fa0">Our CLI is called <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> and it offers several actions to interact with the service, like logging in, computing, querying, etc. as shown in the following snippet:</p><pre><span id="4e44">&gt;&gt;&gt; moka --help<br>usage: moka [-h] [--version] {login,compute,report,query,add,manage} ...</span><span id="84c2">positional arguments:<br>  {login,compute,report,query,add,manage}<br>                        Interact with the properties web service<br>    login               Log in to the Insilico web service<br>    compute             Compute available jobs<br>    report              Report the results back to the server<br>    query               Query some properties from the database<br>    add                 Add new jobs to the database<br>    manage              Change jobs status</span><span id="6b00">optional arguments:<br>  -h, --help            show this help message and exit<br>  --version             show program's version number and exit</span></pre><p id="b5c4">Using <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> we can compute some jobs using a command like:</p><pre><span id="f521">moka compute -c collection_name -j number_of_jobs_to_compute</span></pre><p id="8e50">The previous command handles the communication with the web service, fetches the requested jobs from a given collection (or dataset) and runs them directly or invokes a <a href="https://en.wikipedia.org/wiki/Job_scheduler" rel="noopener">job scheduler</a> like <a href="https://slurm.schedmd.com/documentation.html" rel="noopener">Slurm</a>. To communicate with the service, <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> invokes the <a href="https://requests.readthedocs.io/en/master/" rel="noopener">Python Requests library</a> that handles the communication.</p><p id="54f9">Once the jobs are done we can report the computed data like:</p><pre><span id="2183">moka report</span></pre><p id="eafc">You may be wondering how does the client know what data it needs to send/receive. Well, that is the subject of the next section!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8064/0*o_Zzwgbaexr6Fz8y" width="4032" height="3024" srcset="https://miro.medium.com/max/552/0*o_Zzwgbaexr6Fz8y 276w, https://miro.medium.com/max/1104/0*o_Zzwgbaexr6Fz8y 552w, https://miro.medium.com/max/1280/0*o_Zzwgbaexr6Fz8y 640w, https://miro.medium.com/max/1400/0*o_Zzwgbaexr6Fz8y 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*o_Zzwgbaexr6Fz8y?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@tofi?utm_source=medium&amp;utm_medium=referral" rel="noopener">Tobias Fischer</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e270">The main goal of the web service is to minimize the interaction between the users and the data. If the client requests some read-only action you just return the data (if available) and if the client wants to change something, you need to ensure that (1) the client has permissions to mutate the data (2) only the mutations specified by the client are carried out but nothing more. I will skip authentication in this post.</p><p id="2b72">Therefore, the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> web service needs to handle two kinds of requests by the client: read-only queries and mutations on the datasets. These “queries” and “mutations” can be easily describe with <a href="https://graphql.org/" rel="noopener">GraphQL</a>.</p><p id="0dbe">In a nutshell, <a href="https://graphql.org/" rel="noopener">GraphQL</a> defines a contract (known as a schema) between the actions that a client can perform with the web service and the possible outcomes of those actions. More formally, <a href="https://graphql.org/" rel="noopener">GraphQL</a> is a query language that allows you to specify an application Programming interface (API) using different programming languages. If you have previous experience with <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" rel="noopener">RESTful API</a> have a look at a comparison between <a href="https://www.howtographql.com/basics/1-graphql-is-the-better-rest/" rel="noopener">GraphQL and REST</a>.</p><p id="ecf0">But how does GraphQL work? First, you need to define a schema using the <a href="https://graphql.org/" rel="noopener">GraphQL</a> schema language. The following code snippet defines a schema to query a job using its status,</p><figure><div></div><figcaption>Schema definition for job query</figcaption></figure><p id="2045">The <strong>Query</strong> schema specifies that in order to request some <strong><em>jobs</em></strong> you need to provide a <em>Status</em> argument, where <em>Status</em> can be one of four possibilities: <em>AVAILABLE, DONE, FAILED</em> and <em>RUNNING. </em>The exclamation mark (!) indicates that the argument cannot be <em>Null</em> (a.k.a <em>None</em> in Python).</p><p id="5870">The following <strong>Mutation</strong> schema defines the required arguments to update a given job status.</p><figure><div></div><figcaption>Schema definitation for Job status mutation</figcaption></figure><p id="9dd2">The <strong><em>updateJob</em></strong> action specifies that you must provide an <em>id</em> and a <em>new_status</em> in order to be able to update a job. You will receive a <em>Reply</em> specifying whether the update action has succeeded.</p><p id="54d3">Have a look at the Insilico <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Query.graphql" rel="noopener">queries</a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Mutation.graphql" rel="noopener">mutations</a> schemas. They are slightly more complex than the aforementioned schemas but follow the same rationale as the previous examples. You can also have a look at the official <a href="https://graphql.org/learn/" rel="noopener">introduction to GraphQL</a>.</p><p id="33f0">We have just defined the schemas that specify the actions that we want to perform. We still need to implement the actions and for doing so, we need a GraphQL engine: a library that takes the schemas together with the code that implements the actions and generates an API.</p><p id="39ea">We have chosen the <a href="https://tartiflette.io/" rel="noopener">Tartiflette GraphQL engine</a> to implement our web service mostly because it is easy to use and open source. The following snippet shows a possible implementation for querying jobs based on their status using <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a>.</p><figure><div></div></figure><p id="affa">the <strong><em>Resolver</em></strong> decorator indicates that the <strong><em>resolver_query_jobs</em></strong> function corresponds to the implementation of the <strong><em>query jobs</em></strong> schema. The function takes 4 arguments of which I only use <strong><em>args</em></strong> and <strong><em>ctx</em></strong><em> </em>(You can refer to <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a> for further details). <strong><em>args </em></strong>contains the arguments given by the client code, while <strong><em>ctx </em></strong>contains the context for running the current function, for example the handler to access the database that is called <strong><em>mongodb</em></strong> in this code snippet.</p><p id="9242">Notice that the definition of the aforementioned function starts with the <em>async</em> keyword. <a href="https://docs.python.org/3/library/asyncio.html" rel="noopener">Asyncio</a> is a popular built-in Python library to write concurrent code. It is extensively used to write high performance web services.</p><p id="fb0a">In the Insilico web service implementation of the <a href="https://github.com/nlesc-nano/insilico-server/tree/master/provisioning" rel="noopener"><strong>queries</strong></a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/mutation_resolvers.py" rel="noopener"><strong>mutations</strong></a>, there are definitions for all the Python functions that perform the actions specified in the GraphQL schemas. For each query and mutation, there is a corresponding function.</p><p id="632b">We need a database not only for storing the interesting data but also to store the jobs metadata, like what jobs are available. For the Insilico web service we use <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a>.</p><p id="1b90">My personal opinion is that a <a href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener">NoSQL database</a> like <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a> gives a significant advantage over traditional SQL databases on research projects where up-front design of the schemas to store data is unfeasible. The research priorities can change as the project evolves and having dynamic …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</a></em></p>]]>
            </description>
            <link>https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371580</guid>
            <pubDate>Thu, 10 Dec 2020 09:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ProtoPie 5.2: Turn Figma designs into realistic, conditional prototypes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371555">thread link</a>) | @heytmt
<br/>
December 10, 2020 | https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58 | <a href="https://web.archive.org/web/*/https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="72bc">A far better Figma import for ProtoPie. Lightning speed and flexibility at your fingertips.</h2><div><div><div><p><a href="https://medium.com/@fredotan?source=post_page-----5758892c4c58--------------------------------" rel="noopener"><img alt="Fredo Tan" src="https://miro.medium.com/fit/c/96/96/1*6aaH5nx9yHmC7KcdczcZTg@2x.jpeg" width="48" height="48"></a></p></div></div></div><blockquote><p id="e08d">We are on <a href="https://www.producthunt.com/posts/protopie-for-figma" rel="noopener"><strong>Product Hunt</strong></a> today! We’d love to receive your feedback and support there :)</p></blockquote></div></div><div><div><p id="ebd5">We are beyond excited that today we can finally introduce the <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>—a far better Figma import for ProtoPie.</p><p id="7ead">The introduction of this plugin goes hand-in-hand with the <a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>ProtoPie 5.2</strong></a> release.</p><p id="f675">ProtoPie plugins for Adobe XD and Sketch are coming soon.</p><p id="95c4">A lot of you have been using the Figma integration we introduced in early 2019. Many designers, since then, rely on a Figma + ProtoPie workflow on a daily basis—designing, prototyping, iterating, and anything in between.</p><p id="588e">As this workflow became essential for many rapidly, we received tons of feedback on how we could make this particular workflow better.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2616/1*35ZGJ7gZQN-LKqgbRZZj9Q.png" width="1308" height="262" srcset="https://miro.medium.com/max/552/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 276w, https://miro.medium.com/max/1104/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 552w, https://miro.medium.com/max/1280/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 640w, https://miro.medium.com/max/1400/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*35ZGJ7gZQN-LKqgbRZZj9Q.png?q=20"></p></div></div></div><figcaption>A better Figma import was one of the top <a href="https://protopie.canny.io/" rel="noopener">feature requests</a>.</figcaption></figure><p id="2208">Quickly we realized that we needed to provide a better workflow in which designers can merely focus on what they need ProtoPie for: making realistic, highly interactive prototypes.</p><p id="e4fd">So, we decided to build something new, entirely from scratch.</p><p id="1618">The new import experience is completely different from the previous one, which we now call the legacy Figma import.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3840/1*rINB-qGSruwy8te26r1hlA.gif" width="1920" height="1080" srcset="https://miro.medium.com/max/552/1*rINB-qGSruwy8te26r1hlA.gif 276w, https://miro.medium.com/max/1104/1*rINB-qGSruwy8te26r1hlA.gif 552w, https://miro.medium.com/max/1280/1*rINB-qGSruwy8te26r1hlA.gif 640w, https://miro.medium.com/max/1400/1*rINB-qGSruwy8te26r1hlA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*rINB-qGSruwy8te26r1hlA.gif?q=20"></p></div></div></div><figcaption>ProtoPie plugin for Figma: a revamped import experience to boost productivity.</figcaption></figure><p id="ffdc">With the new <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>, you have lightning speed and flexibility at your fingertips. Import your designs from Figma into ProtoPie, all done locally—without any latency.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif" width="640" height="360" srcset="https://miro.medium.com/max/552/1*xLg44E8hgKI01r3ML45Jjg.gif 276w, https://miro.medium.com/max/1104/1*xLg44E8hgKI01r3ML45Jjg.gif 552w, https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif 640w" sizes="640px" data-old-src="https://miro.medium.com/freeze/max/60/1*xLg44E8hgKI01r3ML45Jjg.gif?q=20"></p></div></div><figcaption>Control what you import. At lightning speed.</figcaption></figure><p id="29cc">Control what you import. Import top-level frames as scenes, and objects with the same layer hierarchy, positioning, and constraints as in Figma.</p><p id="9ce9">The ProtoPie plugin for Figma requires ProtoPie 5.2 or higher.</p><h2 id="d98b">Differences with the legacy Figma import?</h2><p id="6d13">Spend less time on bringing your designs from Figma into ProtoPie. With the new plugin, you save time and can spend more time on prototyping.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*P_QobAhiTx_KYU4fFHnwUw.png" width="1600" height="1006" srcset="https://miro.medium.com/max/552/1*P_QobAhiTx_KYU4fFHnwUw.png 276w, https://miro.medium.com/max/1104/1*P_QobAhiTx_KYU4fFHnwUw.png 552w, https://miro.medium.com/max/1280/1*P_QobAhiTx_KYU4fFHnwUw.png 640w, https://miro.medium.com/max/1400/1*P_QobAhiTx_KYU4fFHnwUw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*P_QobAhiTx_KYU4fFHnwUw.png?q=20"></p></div></div></div><figcaption>The legacy Figma import on the left, the new ProtoPie plugin for Figma on the right.</figcaption></figure><ul><li id="b8f3">Import one or multiple frames and objects.</li><li id="9195">Import top-level frames as scenes.</li><li id="5eed">Import what you selected.</li><li id="e346">Import vector layers as SVG.</li><li id="ea4c">Import text layers as SVG that can be converted to text layers.</li><li id="7d1e">Import constraints as constraints.</li></ul><p id="9549"><a href="https://protopie.io/learn/docs/basic-features/import#import?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>Learn more</strong></a> about the ProtoPie plugin for Figma.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg" width="600" height="300" srcset="https://miro.medium.com/max/552/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 276w, https://miro.medium.com/max/1104/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 552w, https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 600w" sizes="600px" data-old-src="https://miro.medium.com/max/60/1*6R6YL9UkyU9bwS3PBqaSag.jpeg?q=20"></p></div></div></figure><p id="f67c">ProtoPie is the tool that helps you to bring your Figma designs come to life, indistinguishable from the end product.</p><p id="feec">It’s simply a matter of adding powerful interactions to your designs. Think of dynamic interactions involving conditions, formulas, and variables. Add another level of realism by including text input, camera, voice, media playback to your prototypes. Or even make prototypes that can communicate with each other. The possibilities are endless.</p><h2 id="9d2a">New to ProtoPie?</h2><p id="45a6">Try the ProtoPie plugin for Figma with this <a href="https://r.protopie.io/en/figma-plugin/marketing-file/" rel="noopener"><strong>example file</strong></a>.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*4kJjwUMw6iXIJVcYmy7Asw.png" width="1080" height="540" srcset="https://miro.medium.com/max/552/1*4kJjwUMw6iXIJVcYmy7Asw.png 276w, https://miro.medium.com/max/1104/1*4kJjwUMw6iXIJVcYmy7Asw.png 552w, https://miro.medium.com/max/1280/1*4kJjwUMw6iXIJVcYmy7Asw.png 640w, https://miro.medium.com/max/1400/1*4kJjwUMw6iXIJVcYmy7Asw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4kJjwUMw6iXIJVcYmy7Asw.png?q=20"></p></div></div></div></figure><p id="0d0d">Join our live event as our Head of Product Design, David Lee shares the journey of how we revamped the Figma import experience.</p><p id="6329">👉 <a href="https://www.eventbrite.com/e/protopies-journey-behind-revamping-the-figma-import-tickets-130748563473" rel="noopener"><strong>Register now</strong></a>.</p><ul><li id="f42c">Single sign-on (SSO) for ProtoPie Enterprise</li><li id="2c31">Auto line height</li><li id="6898">Duplicate with same distance</li><li id="2993">App icon for macOS Big Sur</li><li id="74e3">Trigger &amp; response names for voice prototyping</li></ul><figure><a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3336/0*PwpFUw9I5BCcmPr0.png" width="1668" height="390" srcset="https://miro.medium.com/max/552/0*PwpFUw9I5BCcmPr0.png 276w, https://miro.medium.com/max/1104/0*PwpFUw9I5BCcmPr0.png 552w, https://miro.medium.com/max/1280/0*PwpFUw9I5BCcmPr0.png 640w, https://miro.medium.com/max/1400/0*PwpFUw9I5BCcmPr0.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*PwpFUw9I5BCcmPr0.png?q=20"></p></div></div></a></figure><p id="cdbd"><em>Thanks for reading! :) If you enjoyed this article, hit that clap button below </em>👏<em>. Feel free to </em><a href="https://protopie.io/support" rel="noopener"><em>contact us</em></a><em> with your feedback and/or questions.</em></p></div></div></div>]]>
            </description>
            <link>https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371555</guid>
            <pubDate>Thu, 10 Dec 2020 09:14:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Twins, a Requirement for Industrial AI]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371343">thread link</a>) | @MorganeR
<br/>
December 10, 2020 | https://blog.senx.io/digital-twins-requirement-for-industrial-ai/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/digital-twins-requirement-for-industrial-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Using AI to make industrial assets more efficient and reduce their downtime is on many agendas. Learn how digital twins and time series data play a major role in this plan.</p><article>
      
<p><strong>When interviewed, CEOs across industries all state that AI is part of their top priorities.</strong> But when it comes to actual implementation AI projects are not very glamorous. Past simple proofs of concept and the hiring of a team of data scientists, there is usually no sign of the highly anticipated digital transformation wished by the CEOs.</p>



<p>There are multiple reasons for this disenchantment, far too many to list here. But among those, some are directly related to what we focus on at <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a>, data, and the way industries introduce them in their environment.</p>



<h2>No digital transformation without data</h2>



<p>The willingness to transform is genuine in many organizations, driven by ambitious visions or just the consciousness that the competitive landscape is evolving.</p>



<p>The next step is usually for those businesses to pick some quick wins to prove that the transformation can be initiated and comfort everyone that it does not mean changing teams or radically modifying their way of working.</p>



<p>Those short projects aim at demonstrating the methodology for transforming limited operational perimeters. They often involve solving a problem with approaches to leveraging new technologies. Those technologies, 100% digital, need fuel to work, and that fuel is data. <strong>So the first step is to ensure data are available</strong>.</p>



<p>The firms hired to help in building those quick wins will then wander among departments. They will harvest datasets here and there until they have sufficient matter for implementing their solutions.</p>



<p>This step can sometimes take time if the data is not well identified and distributed across the organization. But it is a mandatory path to follow as without data no digital transformation will happen.</p>



<figure></figure>



<h2>No AI without big data</h2>



<p>Past the simple quick wins done to bootstrap the transformation comes a time when more ambitious projects are brought on the table, and that is when AI (Artificial Intelligence) comes into the conversation. The hype around AI is so strong that projects around AI and ML (Machine Learning) cannot be neglected.</p>



<p>The problem with the current hype is that very few people really understand what AI actually implies. <strong>For many</strong>,<strong> you buy an AI like you buy a Microsoft Office 365 subscription</strong>, this is just not true. The promise of AI is to bring new, automatic, ways to use data to help in or even completely assume the decision process. This promise can only be fulfilled if the actual AI put to work, otherwise called the model, is actually trained on the data in your very own organization, and this requires once again the same digital transformation fuel, data. The difference is that this time you need more of it. You are no longer trying to light a fondue burner but a rocket engine!</p>



<p>Training a model does indeed require a lot of data covering the various aspects of your business operations you want the model to focus on, also covering a long period of time so trend and seasonality can be modeled. </p>



<h4>This has several impacts</h4>



<ul><li>The first is that you cannot expect to train a model and efficiently introduce AI in your operations until you actually have collected enough meaningful data. And if your organization has not done so so far you need to start as soon as possible. </li><li>The second impact is that this data collection process is not a one time job. It does not stop once you have enough data for training a model. It needs to go on and on so you keep on accumulating signals on how your business operates to retrain your models in the future if their performance starts to degrade. This means that prior to your journey into the core of AI you need to plan for big data to be collected, stored and made available to teams across your organization so they can start looking at the data and imagine possible uses and models.</li></ul>



<h2>No industrial AI without Digital Twins</h2>



<p>Among verticals, industrial organizations face the hardest problems of data collection. Industries whose data mainly relates to users using their services are lucky. In the end, their data are not that massive. Sure we have all heard stories of banks or retailers hoarding piles of data. But we are talking about a few thousand interactions per year per user. So even with a billion users, which not that many banks or retailers have, we are talking a few trillion events per year.</p>



<p>In the industrial world, things are different, the assets producing data do not eat or sleep. They work day and night and sometimes produce thousands of measurements per second.</p>



<h3>For example...</h3>



<p>Take for example the CERN experiments at the LHC. They produced 600 million events per second during the campaigns for the quest of the Higgs boson. That is 51 trillion events per day. Luckily for the CERN, not all events needed to be retained. With highly efficient AI-based detectors, which needed to be trained with massive data themselves, they were able to limit the production to 100 000 events per second sent for digital reconstruction and ultimately 200 events persisted per second. </p>



<p>But other sectors need to retain more data. Synchro phasors (or PMUs, phase monitoring units) monitoring electrical grids, for example. They each produce several 1000s measures per second, and there are thousands of those at the scale of a country like France. This means millions of C37.118.2 messages sent every second, not to mention the IEC61850 messages sent to supervise the substations. </p>



<p>Same thing in aeronautics where aircraft typically produce 5 000 to 15 000 data points per second they are operating, or industrial assets whose PLC (Programmable Logic Controllers) track the state of many sensors and actuators.</p>



<p>The use of AI in those verticals requires that those truly massive data be collected and organized. Since they are data related to physical assets, it is wise to use an approach which mimics these assets in a digital form, this approach is called Digital Twins. </p>



<figure></figure>



<h3>What are Digital Twins?</h3>



<p>The Digital Twin of an asset is the set of measures coming from its sensors and actuators. Those measures need to be tracked in time to catch the dynamics of the assets' operations. And the technology of choice to do so is a <a href="https://blog.senx.io/which-time-series-database-suited-to-your-needs/" target="_blank" rel="noreferrer noopener">Time Series Database</a>. Indeed Digital Twins are nothing else than time series, some for the sensors, some for the actuators with their states. And if you want more advanced digital twins, some with the control commands sent to the assets to modify how it behaves.</p>



<p>Once you start collecting the data from your assets in a Time Series Database, you can easily access the state of those assets at any point in time. More importantly, you can start extracting features to train models to detect anomalies and perform predictive maintenance.</p>



<h2>Takeaways</h2>



<p>AI is on every business' agenda, but the importance of data is too often overlooked. <strong>When it comes to industrial AI, the first step towards a successful implementation is the collection of all sensor data to build Digital Twins of the physical assets involved.</strong> This approach needs to leverage a Time Series Database, the kind of database SenX offers with the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10 Time Series Platform</a>.</p>



<p><a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how SenX and its technologies can help you master your industrial AI adventure.</p>








<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/digital-twins-requirement-for-industrial-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371343</guid>
            <pubDate>Thu, 10 Dec 2020 08:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A Rust-Based Fast Static Site Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371125">thread link</a>) | @camsjams
<br/>
December 10, 2020 | https://camsjams.github.io/rust-coal/ | <a href="https://web.archive.org/web/*/https://camsjams.github.io/rust-coal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://camsjams.github.io/rust-coal/assets/images/favicon.png" alt="Coal in a mine cart"></p><div>
<p><strong>Coal</strong> is a command-line interface (CLI) to speed up your ability to create static HTML
websites
without having to setup dependencies or install other libraries.</p><p>

Just install <strong>Coal</strong> once on your machine, and get building!
</p></div>
</div></div>]]>
            </description>
            <link>https://camsjams.github.io/rust-coal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371125</guid>
            <pubDate>Thu, 10 Dec 2020 08:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts about Mapbox GL JS moving to a NON-OS License]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25371037">thread link</a>) | @D_Guidi
<br/>
December 9, 2020 | http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html | <a href="https://web.archive.org/web/*/http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>09 Dec 2020</span></p><p>Yesterday, Mapbox announced that they were moving their <a href="https://github.com/mapbox/mapbox-gl-js">Mapbox GL JS</a> library from a standard BSD license to a new very much <a href="https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt">non-open source license</a>.</p>

<p><a href="https://joemorrison.medium.com/death-of-an-open-source-business-model-62bc227a7e9b">Joe Morrison said</a> the news “shook” him (and also the readers of the Hacker News front page, well done Joe). It did me as well. Although apparently for completely different reasons.</p>

<blockquote>
  <p>Mapbox is the protagonist of a story I’ve told myself and others countless times. It’s a seductive tale about the incredible, counterintuitive concept of the “open core” business model for software companies.
<br>– Joe Morrison</p>
</blockquote>

<p>There’s a couple things wrong with Joe’s encomium to Mapbox and “open core”:</p>

<ul>
  <li>first, Mapbox was <strong>never</strong> an open core business;</li>
  <li>second, open core is a <strong>pretty ugly model</strong> that has very little to do with the open source ethos of shared intellectual pursuit.</li>
</ul>

<p><img src="http://blog.cleverelephant.ca/images//2020/core.jpg" alt="Open Core"></p>

<h2 id="mapbox-was-never-open-core">Mapbox was never Open Core</h2>

<p>From the very start (well, at least from the early middle), Mapbox was built to be a location-based services business. It was to be the Google Maps for people who were unwilling to accept the downsides of Google Maps.</p>

<p>Google Maps will track you. They will take your data exhaust and ruthlessly monetize it. They will take your data and use it to build a better Google Maps that they will then re-sell to others.</p>

<p>If you value your data at all (if you are, say, a major auto maker), you probably don’t want to use Google Maps, because they are going to steal your data while providing you services. Also, Google Maps is increasingly the “only game in town” for location based services, and it seems reasonable to expect price increases (<a href="https://housesigma.com/blog-en/2018/06/07/google-map-price-hike/">it has already happened once</a>).</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/google-location-history.png" alt="Google is Tracking You"></p>

<p>Nobody can compete with Google Maps, can they? Why yes, they can! Mapbox fuses the collaborative goodness of the <a href="https://openstreemap.org/">OpenStreetMap</a> community with clever software that enables the kinds of services that Google sells 
(<a href="https://docs.mapbox.com/api/maps/#raster-tiles">map tiles</a>, 
<a href="https://docs.mapbox.com/#search">geocoding</a>, 
<a href="https://docs.mapbox.com/#navigation">routing</a>, 
<a href="https://docs.mapbox.com/help/troubleshooting/access-elevation-data/">elevation services</a>), and a bunch of services Google doesn’t sell (like <a href="https://www.mapbox.com/mapbox-studio/">custom map authoring</a>) or won’t sell (like <a href="https://www.mapbox.com/vision/">automotive vision</a>).</p>

<p>But like Google, the value proposition Mapbox sells isn’t in the software, so much as the data and the platform underneath. Mapbox has built a unique, scalable platform for handling the huge problem of turning raw OSM data into usable services, and raw location streams into usable services. They sell access to that platform.</p>

<p>Mapbox has never been a software company, they’ve always been a data and services company.</p>

<p>The last company I worked for, <a href="https://carto.com/">CARTO</a>, had a similar model, only moreso. All the parts of their value proposition (PostgreSQL, PostGIS, the CARTO UI, the tile server, the upload, everything) are <a href="https://github.com/cartodb">open source</a>. But they want you to pay them when you load your data into their service and use their software there. How can that be? Well, do you want to assemble all those open source parts into a working system and keep it running? Of course not. You just want to publish a map, or run an analysis, or add a spatial analysis to an existing system. So you pay them money.</p>

<p>Is Mapbox an “open core” company? No, is there a “Mapbox Community Edition” everyone can have, but an “Enterprise Edition” that is only available under a proprietary license? No. Does Mapbox even sell <strong>any software at all</strong>? No. (Yes, some.) They (mostly) sell services.</p>

<p>So what’s with the re-licensing? I’ll come back to that, but first…</p>

<h2 id="open-core-is-a-shitty-model">Open Core is a Shitty Model</h2>

<p>Actually, no, it seems to be a passable <strong>monetization</strong> model, for some businesses. It’s a shitty open source model though.</p>

<ul>
  <li>MongoDB has an open source core, and sells a bunch of proprietary enterprise add-ons. They’ve grown very fast and might even reach sufficient velocity to escape their huge VC valuation (or they may yet be sucked into the singularity).</li>
  <li>Cloudera before them reached huge valuations selling proprietary add-ons around the open Hadoop ecosystem.</li>
  <li>MySQL flirted with an open core model for many years, but mostly stuck to spreading FUD about the GPL in order to get customers to pay them for proprietary licenses.</li>
</ul>

<p>Easily the strangest part of the MySQL model was trash-talking the very open source license <strong>they chose</strong> to place their open source software under.</p>

<p>All those companies have been quite succesful along the axes of “getting users” and “making money”. Let me tell you why open core is nonetheless a shitty model:</p>

<ul>
  <li>Tell me about the MongoDB developer community. Where do they work? Oh right, Mongo.</li>
  <li>Tell me about the Cloudary developer community? Where do they work?</li>
  <li>Tell me about the MySQL developer community? Where to they work? Oh right, <strong>Oracle</strong>. (There’s a whole other blog post to be written about why sole corporate control of open source projects is a <strong>bad idea</strong>.)</li>
</ul>

<p>A good open source model is one that promotes heterogeneity of contributors, a sharing of control, and a rising of all boats when the software succeeds. Open core is all about centralizing gain and control to the sponsoring organization.</p>

<p>This is going to sound precious, but the leaders of open core companies don’t “care” about the ethos of open source. The CEOs of open core companies view open source (correctly, from their point of view) as a “sales channel”. It’s a way for customers to discover their paid offerings, it’s not an end in itself.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/funnel.png" width="75%" alt="Sales Funnel"></p>

<blockquote>
  <p>We didn’t open source it to get help from the community, to make the product better. We open sourced as a freemium strategy; to drive adoption. 
<br>– Dev Ittycheria, CEO, MongoDB</p>
</blockquote>

<p>So, yeah, open core is a way to make money but it doesn’t “do” anything for open source as a shared proposition for building useful tools anyone can use, for anything they find useful, anytime and anywhere they like.</p>

<p>Check out <a href="https://www.youtube.com/watch?v=8q5o-4pnxDQ">Adam Jacob’s take</a> on the current contradictions in the world of open source ethics; there are no hard and fast answers.</p>

<h2 id="mapbox-shook-me-too">Mapbox Shook Me Too</h2>

<p>I too was a little shook to learn of the <a href="https://news.ycombinator.com/item?id=25347310">Mapbox GL JS relicensing</a>, but perhaps not “surprised”. This had happened before, with <a href="https://news.ycombinator.com/item?id=14734589">Tilemill</a> (open) morphing into <a href="https://www.mapbox.com/mapbox-studio/">Mapbox Studio</a> (closed).</p>

<p>The change says nothing about “open source” in the large as a model, and everything about “single vendor projects” and whether you should, strategically, believe their licensing.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/empty-promise.jpg" alt="Empty Promises"></p>

<p>I (and others) took the licensing (incorrectly) of Mapbox GL JS to be a promise, not only for now but the future, and made decisions based on that (incorrect) interpretation. I integrated GL JS into <a href="https://github.com/CrunchyData/pg_tileserv/blob/master/assets/preview-table.html">an open source project</a> and now I have to revisit that decision.</p>

<p>The license change also says something about the business realities Mapbox is facing going forward. The business of selling location based services is a competitive one, and one that is perhaps not panning out as well as their venture capital valuation (<a href="https://blog.mapbox.com/softbank-mapbox-series-c-be207b866b27">billions?</a>) would promise.</p>

<p>No doubt the board meetings are fraught. Managers are casting about for future sources of revenue, for places where more potential customers can be <strong>squeeeeezed</strong> into the sales funnel.</p>

<p>I had high hopes for Mapbox as a counterweight to Google Maps, a behemoth that seems <a href="https://www.justinobeirne.com/google-maps-moat">likely to consume us all</a>. The signs that the financial vice is beginning to close on it, that the promise might not be fulfilled, they shake me.</p>

<p>So, yeah, Joe, this is big news. Shaking news. But it has nothing to do with “open source as a business model”.</p>


</div></div>]]>
            </description>
            <link>http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371037</guid>
            <pubDate>Thu, 10 Dec 2020 07:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Restore pictures for free with deep learning tool]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370708">thread link</a>) | @panabee
<br/>
December 9, 2020 | https://hotpot.ai/restore-picture | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBoxWrapper">
			<div id="controlBox">

				<div>
					<p><img src="https://hotpot.ai/images/site/transparent.gif">
					</p>
				</div>

				<p>Upload</p>

				

				<p><span>Restore</span>
				</p>

			</div>
		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			If the image has scratches, enabling the "Has Scratches" option instructs our AI to remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370708</guid>
            <pubDate>Thu, 10 Dec 2020 07:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring page performance – Learn Puppeteer and Playwright]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370533">thread link</a>) | @kiyanwang
<br/>
December 9, 2020 | https://theheadless.dev/posts/basics-performance/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/basics-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The need for fast and responsive applications has never been greater because of the move from <a href="https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet/worldwide/2019" target="_blank" rel="noopener noreferrer">desktop to mobile</a>. Still, web applications have been increasing in <a href="https://httparchive.org/reports/page-weight" target="_blank" rel="noopener noreferrer">complexity and size</a>, with rising load times. It is therefore clear why the topic of webpage performance is more popular today than it likely ever was.</p> <p>This article aims at giving a practical introduction to the whys and hows of web performance, without getting lost in the depth or breadth of this massive topic.</p> <h2 id="why-performance-matters"><a href="#why-performance-matters">#</a> Why performance matters</h2> <p>The time it takes for a service to become usable, as well as its general responsiveness, bear a lot of weight on the user's perception of that service. Helpful features, great design and other prominent characteristics all become irrelevant when an online service is so slow that users navigate away.</p> <p>You can build the best web application in the world, but be mindful that each user will have a specific amount of time they are willing to invest in your service to solve their problems. Exceed that amount, and you risk losing them to a different, more performant solution. This is even truer for new users, who haven't yet been given proof of the quality of your service, and are essentially investing their time up-front, hoping for a return.</p> <h3 id="a-competitive-differentiator"><a href="#a-competitive-differentiator">#</a> A competitive differentiator</h3> <p>There is a brighter side to the topic: if low performance can sink an online platform, high performance can very well help it rise to the top. Speed and responsiveness can be a differentiating characteristic for a service, prompting users to choose it over the competition. Therefore an investment in this area will almost always pay off. Some notorious real-world examples from known businesses include:</p> <ol><li>Pinterest decreasing wait time for their users, <a href="https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7" target="_blank" rel="noopener noreferrer">increasing both traffic and conversions</a>.</li> <li>Zalando applying small improvements in load time and finding a direct correlation with <a href="https://engineering.zalando.com/posts/2018/06/loading-time-matters.html" target="_blank" rel="noopener noreferrer">increased revenue per session</a>.</li> <li>The BBC discovering that every extra second that a page took to load led to 10% of <a href="https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale" target="_blank" rel="noopener noreferrer">users leaving the page</a>.</li></ol> <h2 id="measuring-performance"><a href="#measuring-performance">#</a> Measuring performance</h2> <p>Given the importance of page performance, it is no coincidence that browsers expose a ton of insights into <a href="https://web.dev/metrics/" target="_blank" rel="noopener noreferrer">performance metrics</a>. Being aware of how your application scores against these <em>across time</em> will provide you the feedback you need to keep it performant for your users. There are several approaches that can be combined to achieve the best results:</p> <ol><li><em>Real user monitoring</em> to understand what performance actual end-users of your service are experiencing.</li> <li><em>Synthetic monitoring</em> to proactively gather intel on service performance, as well as to find issues before users stumble into them.</li> <li><em>Performance testing</em> to avoid releasing performance regression to production in the first place.</li> <li><em>Regular audits</em> to get an overview of your page's performance and suggestions on how to improve it, e.g. with tools such as <a href="https://developers.google.com/web/tools/lighthouse" target="_blank" rel="noopener noreferrer">Google Lighthouse</a>.</li></ol>  <p>As much as we should be striving to build performant applications, we should commit to monitoring and testing performance to enable continuous feedback and rapid intervention in case of degradation. Puppeteer and Playwright give us a great toolkit to power both synthetic monitoring and performance testing.</p> <ol><li>Access to the Web Performance APIs, especially <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceNavigationTiming" target="_blank" rel="noopener noreferrer">PerformanceNavigationTiming</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceResourceTiming" target="_blank" rel="noopener noreferrer">PerformanceResourceTiming</a>.</li> <li>Whenever testing against Chromium, access to the Chrome DevTools Protocol for traffic inspection, network emulation and more.</li> <li>Easy interoperability with performance libraries from the Node.js ecosystem.</li></ol> <h3 id="web-performance-apis"><a href="#web-performance-apis">#</a> Web Performance APIs</h3> <p>The <a href="https://www.w3.org/TR/navigation-timing/" target="_blank" rel="noopener noreferrer">Navigation Timing</a> and the <a href="https://www.w3.org/TR/resource-timing-1/" target="_blank" rel="noopener noreferrer">Resource Timing</a> performance APIs are <a href="https://www.w3.org/" target="_blank" rel="noopener noreferrer">W3C</a> specifications. The <a href="https://developer.mozilla.org/en-US/docs/Web/Performance/Navigation_and_resource_timings" target="_blank" rel="noopener noreferrer">MDN docs</a> very clearly define the scope of both:</p> <blockquote><p>Navigation timings are metrics measuring a browser's document navigation events. Resource timings are detailed network timing measurements regarding the loading of an application's resources. Both provide the same read-only properties, but navigation timing measures the main document's timings whereas the resource timing provides the times for all the assets or resources called in by that main document and the resources' requested resources.</p></blockquote> <p>We can use the Navigation Timing API to retrieve timestamps of key events in the page load timeline.</p>  <p>The Resource Timing API allows us to zoom in to single resources and get accurate information about how quickly they are being loaded. For example, we could specifically look at our website's logo:</p>  <h3 id="chrome-devtools-for-performance"><a href="#chrome-devtools-for-performance">#</a> Chrome DevTools for performance</h3> <p>The Chrome DevTools Protocol offers many great performance tools for us to leverage together with Puppeteer and Playwright.</p> <p>One important example is network throttling, through which we can simulate the experience of users accessing our page with different network conditions.</p>  <p>The DevTools Protocol is quite extensive. We recommend exploring the <a href="https://chromedevtools.github.io/devtools-protocol/" target="_blank" rel="noopener noreferrer">documentation</a> and getting a comprehensive overview of its capabilities.</p> <h3 id="additional-performance-libraries"><a href="#additional-performance-libraries">#</a> Additional performance libraries</h3> <p>Lighthouse can easily be used programmatically with Playwright and Puppeteer to gather values and scores for different metrics, like <a href="https://web.dev/interactive/" target="_blank" rel="noopener noreferrer">Time To Interactive (TTI)</a>:</p>  <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>The comprehensive <a href="https://developer.mozilla.org/en-US/docs/Web/Performance" target="_blank" rel="noopener noreferrer">MDN Web Performance documentation</a></li> <li><a href="https://web.dev/learn/#performance" target="_blank" rel="noopener noreferrer">web.dev's performance section</a></li> <li><a href="https://addyosmani.com/blog/puppeteer-recipes/" target="_blank" rel="noopener noreferrer">Web Performance Recipes With Puppeteer</a> by Addy Osmani</li> <li><a href="https://github.com/aslushnikov/getting-started-with-cdp" target="_blank" rel="noopener noreferrer">Getting started with Chrome DevTools Protocol</a> by Andrey Lushnikov</li> <li><a href="https://developers.google.com/web/tools/lighthouse#get-started" target="_blank" rel="noopener noreferrer">Get Started with Google Lighthouse</a></li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/basics-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370533</guid>
            <pubDate>Thu, 10 Dec 2020 06:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up OBS Studio for Screen Recording – Step-by-Step Procedure]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25369651">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/ | <a href="https://web.archive.org/web/*/https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-2893" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>So, you’ve downloaded and installed <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a> on your computer and you want to start recording your screen, but you’re lost?</p>



<p>Well, simply <strong>follow this step-by-step tutorial and you will be ready to start recording high-quality videos of your screen in no time with OBS Studio</strong>. </p>



<p>Let’s get started.</p>



<hr>



<h2>A Brief Overview of OBS Studio</h2>



<p>Before we go further, let’s get an idea of the GUI layout of OBS Studio. To keep things simple, we will divide OBS Studio into 6 sections.</p>



<div><figure><img width="1024" height="550" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20550'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1"></figure></div>



<h3>1. Scenes</h3>



<p>If OBS is a canvas, <code>Scenes</code> would be a place that stores various pictures you can switch at any time. Each scene is used for different purposes. For example, a streamer would use different ones to signify when he is playing, waiting in a lobby, or taking a break.</p>



<h3>2. Sources</h3>



<p>You can think of <code>Sources</code> like a set of colors, you use to paint a scene. These are all of the elements shown on your screen during a recording. A good example of Sources are your logo, webcam, and chat window.</p>



<h3>3. Audio Mixer</h3>



<p>The mixer is where you will set up everything audio-related. More on that later.</p>



<h3>4. Scene Transitions</h3>



<p>Transitions provide you with animations you can play while switching up the scenes.</p>



<h3>5. Controls</h3>



<p>This houses the most important controls you will use to manipulate your recording.</p>



<h3>6. Preview Window</h3>



<p>Finally, there is a Preview Window. This shows exactly what you will see after you’ve recorded your video.</p>



<p>And don’t forget that OBS Studio is really customizable. You can drag and drop all of these windows and re-organize them to create a unique layout that suits your workflow.</p>



<p>Great, now that you have an idea of what hte OBS Studio layout looks like, let’s get started with setting up OBS Studio for recording.</p>



<hr>



<h2>Setup OBS Studio for Recording Your Screen</h2>



<p>Now let’s follow this step-by-step procedure to setup OBS Studio and start recording! </p>



<h3>1. Add Audio Sources</h3>



<p>Let’s start by setting up the audio. First, go to the <code>Controls &gt; Settings &gt; Audio</code>. Set both <code>Desktop Audio</code> and <code>Mic Audio</code> to <code>default</code>. Everything else should be disabled.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Let’s quickly add some filters to make your voice sound more professional. Click on the gear icon next to <code>Mic/Aux</code> in <code>Audio Mixer</code>.</p>



<div><figure><img width="742" height="431" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 742px) 100vw, 742px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20742%20431'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1"></figure></div>



<p>Here we have 3 options: <code>Noise Suppression</code>, <code>Noise Gate</code>, and <code>Gain</code>.</p>



<div><figure><img width="598" height="257" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" sizes="(max-width: 598px) 100vw, 598px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20598%20257'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1"></figure></div>



<ul><li><strong>Noise Suppression</strong> will remove most of your background noise. Start from -10 dB and drop lower until you can’t hear the noise.</li><li><strong>Noise Gate</strong> will turn off your microphone when the volume drops below the Close Threshold. This way you won’t record your breathing. Settings will vary depending on your type of mic, so play with it until it feels natural.</li><li><strong>Gain</strong> is used for changing the volume of your mic.</li></ul>



<h3>2. Choose Recording Quality</h3>



<p>Go to the <code>Output</code> tab on the left and under <code>Recording</code> choose the path where OBS will save all your videos. By default, it’s set to <code>\Users\OBS\Videos</code>.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Next, click on <code>Recording Quality</code>.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1" alt="Set up OBS Studio for Recording" width="874" height="675" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" sizes="(max-width: 874px) 100vw, 874px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20874%20675'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1"></figure></div>



<p>If you are just beginning to record your videos, we recommend that you choose <code>High Quality</code>. This will provide you with pretty good quality and reasonable file size.</p>



<p>Others should pick <code>Indistinguishable Quality</code>. This will give you a fully professional video that you can later edit in post-processing.</p>



<p>We can’t really recommend <code>Lossless</code> as it will eat up your storage without providing a perceptible difference.</p>



<p>Under <code>Recording Format</code> choose either <code>MKV</code> or <code>FLV</code> as they are very stable container formats. In case your PC or PBS crashes, you will likely be able to save your recording. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1" alt="Set up OBS Studio for Recording" width="864" height="666" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" sizes="(max-width: 864px) 100vw, 864px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20864%20666'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1"></figure></div>



<p>You can easily convert your files later, by going to <code>File &gt; Remux Recording</code>.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1" alt="Set up OBS Studio for Recording" width="942" height="530" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 942px) 100vw, 942px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20942%20530'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1"></figure></div>



<h3>3. Add Scenes</h3>



<p>Now, you will want to create a game scene by clicking on the plus sign in <code>Scenes</code>. A new window will pop up where you can name it.</p>



<div><figure><img width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<h3>4. Capture Your Game</h3>



<p>After creating an in-game scene, keep it selected and click on the <code>+</code> sign in <code>Sources</code>, and select <code>Game Capture</code>. This will open up the properties and let you pick which game you want to record.</p>



<div><figure><img width="562" height="380" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20562%20380'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1"></figure></div>



<p>For <code>Mode</code> make sure it’s set to <code>Capture</code> any fullscreen application. Once you start playing your game, OBS will automatically focus on it.</p>



<p>Nowadays, many games have an anti-cheat system that might affect OBS Studio. For this reason, you should select <code>Use anti-cheat compatibility hook</code>. Don’t worry, you won’t get banned for it.</p>



<p>If you enable 3rd party overlays like Discord or Steam, OBS will try and capture them as well. However, this does not always work, so make sure to check the preview window.</p>



<div><figure><img width="717" height="605" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" sizes="(max-width: 717px) 100vw, 717px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20717%20605'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1"></figure></div>



<p>Once you are done with the setup, click OK and exit. Your game should now be displayed in the OBS.</p>



<h3>5. Add your Webcam</h3>



<p>Go back to the <code>+</code> sign in <code>Sources</code> and select <code>Video Capture Device</code>.</p>



<div><figure><img width="500" height="393" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20500%20393'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1"></figure></div>



<p>That will take you to the <code>Properties</code>. Make sure that you select the right webcam and OBS will set it up. By default, <code>Resolution Type</code> is set to custom. If you want to change it, we recommend choosing either <code>1080p</code> or <code>720p</code>. Hit <code>OK</code> and your webcam will appear under <code>Scenes</code>. Just drag it where you want and resize if needed.</p>



<p>And that’s it! You are now ready to start recording videos in OBS Studio.</p>



<p>Hope you were able to follow this guide and set up your computer to record using <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a>. Have fun recording your screen, or games! Let us know if you have any tips for setting up your OBS Studio installation and we’ll publish it. Thanks! </p>



<hr>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-2892231280" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I’m Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369651</guid>
            <pubDate>Thu, 10 Dec 2020 04:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Crossminds.ai – A knowledge graph indexed AI research video library]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25369075">thread link</a>) | @tecresearch
<br/>
December 9, 2020 | https://crossminds.ai/explore/ | <a href="https://web.archive.org/web/*/https://crossminds.ai/explore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://crossminds.ai/explore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369075</guid>
            <pubDate>Thu, 10 Dec 2020 02:54:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Google Firestore Locally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368698">thread link</a>) | @adrianancona
<br/>
December 9, 2020 | https://ncona.com/2020/12/running-google-firestore-locally/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/12/running-google-firestore-locally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In a previous article, <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">we started playing with Google Firestore</a>. In this article we are going to learn how we can test our applications without the need to talk to Google Cloud.</p>

<p>Note that the local version of Google Firestore is intended for testing only and shouldn’t be used for production systems. It doesn’t provide the reliability or scalability features that the real Firestore does.</p>

<h2 id="firebase-emulator-suite">Firebase emulator suite</h2>

<p>Google provides this suite to help developers test applications without having to use production data or incur cost. The suite doesn’t only emulate the database, but also cloud functions and real-time functionality, to name a couple. In this article we’re only going to focus on the Firestore database.</p>

<!--more-->

<h2 id="firebase-cli">Firebase CLI</h2>

<p>We start by installing the <a href="https://firebase.google.com/docs/cli">Firebase CLI</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl -sL https://firebase.tools | bash
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then start an instance of Firestore:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>firebase emulators:start --only firestore
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As part of the output we will get something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>┌───────────┬────────────────┐
│ Emulator  │ Host:Port      │
├───────────┼────────────────┤
│ Firestore │ localhost:8080 │
└───────────┴────────────────┘
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Port <code>8080</code> is the default for Firestore. When the emulator starts it will look for a file named <code>firebase.json</code> where we can override the port:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>{</span><span>
  </span><span>"emulators"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"firestore"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"port"</span><span>:</span><span> </span><span>"9999"</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>One important thing to keep in mind about the emulator is that the data will be lost every time the emulator is stoped.</p>

<h2 id="connecting-to-the-emulator">Connecting to the emulator</h2>

<p>In <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">Introduction to Google Firestore</a> we learned how to create a firestore client:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre><span>// Constants necessary to create the firestore client</span>
<span>const</span> <span>GcpCredentialsFile</span> <span>=</span> <span>"/tmp/my-key.json"</span>
<span>const</span> <span>ProjectId</span> <span>=</span> <span>"project-12345"</span>

<span>// When done with the client, close it using:</span>
<span>// defer client.Close()</span>
<span>func</span> <span>createClient</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>)</span> <span>*</span><span>firestore</span><span>.</span><span>Client</span> <span>{</span>
  <span>client</span><span>,</span> <span>err</span> <span>:=</span> <span>firestore</span><span>.</span><span>NewClient</span><span>(</span><span>ctx</span><span>,</span> <span>ProjectId</span><span>,</span> <span>option</span><span>.</span><span>WithCredentialsFile</span><span>(</span><span>GcpCredentialsFile</span><span>))</span>

  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"Failed to create client: %v"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>return</span> <span>client</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To tell our app that we want to use the emulator, we need to set an environment variable:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>export </span><span>FIRESTORE_EMULATOR_HOST</span><span>=</span>localhost:8080
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will cause the credentials to be ignored, and the client will connect to the emulator instead.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick article to show how we can easily start a local version of Google Firestore that can be used for testing. The emulator provides a lot of advanced features, but I haven’t had the need for them, so I haven’t dived into them.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/12/running-google-firestore-locally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368698</guid>
            <pubDate>Thu, 10 Dec 2020 02:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming the ATtiny10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368633">thread link</a>) | @taf2
<br/>
December 9, 2020 | http://www.technoblogy.com/show?1YQY | <a href="https://web.archive.org/web/*/http://www.technoblogy.com/show?1YQY">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>11th November 2017</p>
<p>This article describes how to program the ATtiny10, Microchip's diminuitive 6-pin processor, using the Arduino IDE. It's a great chip for building small gadgets and wearables, or designing interface logic for other projects, and it really lives up to its "tiny" name:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10.jpg" alt="ATtiny10.jpg" width="250" height="300"></p>
<p>The following sections explain how to program the ATtiny10 in C, and how to download programs using a low-cost ISP programmer. It also illustrates some simple applications with example programs.</p>
<p>For a couple of projects based on the ATtiny10 see&nbsp;<a href="http://www.technoblogy.com/show?201J">ATtiny10 POV Pendant</a>&nbsp;and&nbsp;<a href="http://www.technoblogy.com/show?2G8A">ATtiny10 Thermometer</a>.</p>
<h3><span>Introduction</span></h3>
<p>If, like me, you like using the simplest possible chip for each application, the ATtiny10 will appeal to you&nbsp;<sup id="cite_ref1"><a href="#cite_note1">[1]</a></sup>; it's a 6-pin processor, about the same size as an 0805 SMD resistor, and it costs about 35p/35¢. It packs in the following features:</p>
<ul>
<li>Internal 8MHz clock, by default prescaled to 1MHz.</li>
<li>Three I/O lines.</li>
<li>Two 16-bit PWM analogue outputs.</li>
<li>Three 8-bit analogue inputs.</li>
<li>An analogue comparator.</li>
<li>A 16-bit timer with input capture and an event counter.</li>
<li>A watchdog timer.</li>
<li>1024 bytes of program memory, 32 bytes of RAM, and no EEPROM.</li>
</ul>
<p>All of these features will be familiar to users of the larger AVR chips. Here's the pinout (using Spence Konde's design conventions):</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10pinout.gif" alt="ATtiny10Pinout.gif" width="701" height="159"></p>
<p>The internal oscillator is accurate to within 10%, but you can calibrate it in software to within 1%. You can configure RESET as a fourth I/O line, which prevents further programming, but I don't cover that in this article.</p>
<p>To work with the ATtiny10 on a breadboard you can mount it on a SOT23 breakout board, such as the one available from Sparkfun <sup id="cite_ref2"><a href="#cite_note2">[2]</a></sup>.</p>
<h3>Programming the ATtiny10</h3>
<p>Unlike the SPI protocol used to program the larger AVR chips, such as the ATmega328 in the Arduino Uno, the ATtiny10 uses a programming protocol called TPI (Tiny Programming Interface) which needs only five wires. Fortunately Thomas Fischl's excellent USBasp programmer supports this protocol&nbsp;<sup id="cite_ref3"><a href="#cite_note3">[3]</a></sup>; you can build your own, order one from his site, or they are widely available on eBay&nbsp;<sup id="cite_ref4"><a href="#cite_note4">[4]</a></sup>, Banggood&nbsp;<sup id="cite_ref5"><a href="#cite_note5">[5]</a></sup>, etc. I recommend getting one with a 10-pin to 6-pin adapter for ISP programming. The current versions of the Arduino IDE support the ATtiny10, so you can program it in C and upload programs as easily as with the other AVR chips. Since an Arduino core would use up almost half of the available program memory the best way to program it is to access the registers directly, and I give an overview of how to do this in the section&nbsp;<a href="#Alternatives">Alternatives to core functions</a>&nbsp;below.</p>
<p>Here are step-by-step instructions for programming the ATtiny10.</p>
<p>NOTE: There is a problem with compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 and higher. If necessary, run version 1.8.8 to do this, or for a workaround see the Disqus comments below.</p>
<ul>
<li>Download the <strong>ATtiny10Core</strong> hardware configuration from my repository on GitHub <a href="https://github.com/technoblogy/attiny10core" target="_blank">ATtiny10Core</a>.</li>
<li>Copy it to the&nbsp;<strong>hardware</strong>&nbsp;folder in your&nbsp;<strong>Arduino</strong>&nbsp;folder in your <strong>Documents</strong> folder. If there isn't already a <strong>hardware</strong> folder there, create one first.</li>
<li>Restart the Arduino IDE.</li>
</ul>
<p>This should add an&nbsp;<strong>ATtiny10Core</strong>&nbsp;heading to the <strong>Board</strong> menu.</p>
<ul>
<li>Enter your program into the Arduino IDE editor.</li>
</ul>
<p>For example, try the&nbsp;<strong>Blink</strong>&nbsp;example program given below.</p>
<ul>
<li>Connect the USBasp to the ATtiny10 as shown in the following diagram:</li>
</ul>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp.gif" alt="ATtiny10USBasp.gif" width="203" height="157"></p>
<p><em>Connecting the USBasp programmer to an ATtiny10.</em></p>
<ul>
<li>Choose&nbsp;<strong>Board</strong>&nbsp;from the&nbsp;<strong>Tools</strong>&nbsp;menu, and select the&nbsp;<strong>ATtiny10/9/5/4</strong>&nbsp;option under the <strong>ATtiny10Core</strong> heading; it's the only option.</li>
<li>Choose the chip you want from the <strong>Chip</strong> menu; for example&nbsp;<strong>ATtiny10</strong>.</li>
<li>Choose <strong>USBasp</strong> from the&nbsp;<strong>Programmer&nbsp;</strong>option on the&nbsp;<strong>Tools</strong>&nbsp;menu.</li>
<li>Choose&nbsp;<strong>Upload</strong>&nbsp;to upload the program.</li>
</ul>
<p>The LED should blink at 0.5Hz.</p>
<p>Here's my test setup on a mini breadboard:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/usbasp.jpg" alt="USBasp.jpg" width="680" height="324"></p>
<p><em>Testing the ATtiny10 Blink program on a mini breadboard, using the USBasp programmer.</em></p>
<h3>Examples</h3>
<p>Here are a couple of examples using the ATtiny10:</p>
<h4>Blink</h4>
<p>This is the ubiquitous Blink program:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  TCCR0A = 1&lt;&lt;COM0A0 | 0&lt;&lt;WGM00;  // Toggle OC0A, CTC mode
  TCCR0B = 1&lt;&lt;WGM02 | 3&lt;&lt;CS00;    // CTC mode; use OCR0A; /64
  OCR0A = 15624;                  // 1 second; ie 0.5Hz
  while (1);
}</pre>
<p>To run it connect an LED to PB0 as follows:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp2.gif" alt="ATtiny10USBasp2.gif" width="157" height="128"></p>
<p><em>Circuit using an ATtiny10 to blink an LED.</em></p>
<p>It uses Timer/Counter0 to divide the 1MHz system clock by a prescaler value of 64, and then by 15625, toggling the output PB0 with a period of 1 second.</p>
<h4>Analogue frequency generator</h4>
<p>The following program reads the voltage from a potentiometer on analogue input ADC1 (PB1), and then uses this to set the compare match register OCR0A of Timer/Counter0, to generate a square wave on PB0 whose frequency you can control with the potentiometer:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  // Set up ADC on PB2
  ADMUX = 1&lt;&lt;MUX0;                // ADC1 (PB1)
  ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;    // Enable ADC, 125kHz clock
  // Set up waveform on PB0
  TCCR0A = 1&lt;&lt;COM0A0 | 3&lt;&lt;WGM00;  // Toggle OC0A, Fast PWM
  TCCR0B = 3&lt;&lt;WGM02 | 4&lt;&lt;CS00;    // Fast PWM with OCR0A as TOP; /256
  // Main loop
  for (;;) {
    ADCSRA = ADCSRA | 1&lt;&lt;ADSC;    // Start
    while (ADCSRA &amp; 1&lt;&lt;ADSC);     // Wait while conversion in progress
    OCR0A = ADCL;                 // Copy result to frequency output
  }
}</pre>
<p>Note that because we're changing the compare match value, we need to use Fast PWM mode in this application, because it double-buffers the compare match value. Here's the circuit:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp3.gif" alt="ATtiny10USBasp3.gif" width="247" height="132"></p>
<p><em>Circuit using a potentiometer to adjust the frequency of a square wave generated by an ATtiny10.</em></p>
<p>It generates a frequency between 1MHz/256/256, or about 15Hz, and 1MHz/256/1, or 3.9kHz.</p>
<h3 id="Alternatives">Alternatives to core functions</h3>
<p>The following sections give some tips on programming the ATtiny10 to achieve some of the things provided by the Arduino core functions.</p>
<h4>includes</h4>
<p>You need to add these includes at the start of your program to include the AVR register definitions and standard C++ routines:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;</pre>
<h4>setup and loop</h4>
<p>Arduino programs are normally written with the initialization in&nbsp;<strong>setup()</strong>&nbsp;and the main program in&nbsp;<strong>loop()</strong>, rather than the standard&nbsp;<strong>int&nbsp;main()</strong>&nbsp;function required by C. If you want to keep to this convention you'll need to add the following definition at the end of your program:</p>
<pre>int main() {
  setup();
  for(;;) loop();
}</pre>
<h4>pinMode</h4>
<p>To specify whether pins are inputs or outputs you set the corresponding bits in the <strong>DDRB</strong> register to 0 or 1 respectively. For example, to define pins 1 and 3 as outputs (and leave the other pins as inputs):</p>
<pre>DDRB = 0b0101; &nbsp; &nbsp;     // Equivalent to pinMode(1, OUTPUT); pinMode(3, OUTPUT);</pre>
<h4>Input pullups</h4>
<p>Unlike the older AVR chips, such as the ATmega328 and ATtiny85, the ATtiny10 enables pullup resistors using a separate pullup register, <strong>PUEB</strong>. To set pullups on input pins you set the corresponding bits in this&nbsp;register. For example, to set a pullup resistor on input pin 2:</p>
<pre>PUEB = 0b0010;         // Equivalent to pinMode(2, INPUT_PULLUP);</pre>
<p>Note that it doesn't make sense to set a pullup on an output.</p>
<h4>digitalWrite</h4>
<p>To set the state of an output you set the corresponding bits in the <strong>PORTB</strong> register. For example, to set bit 1 low and bit 3 high (assuming they have been defined as outputs):</p>
<pre>PORTB = 0b0100;        // Equivalent to&nbsp;digitalWrite(1, LOW);&nbsp;digitalWrite(3, HIGH);</pre>
<p>Changing the state of&nbsp;an input has no effect.</p>
<h4>digitalRead</h4>
<p>To read the state of the I/O pins you read the <strong>PINB</strong> register:</p>
<pre>int temp = PINB;</pre>
<h4>analogWrite</h4>
<p>You can use OC0A (PB0) and OC0B (PB1) for analogue output using PWM. You first need to configure the Timer/Counter into PWM mode for that pin; for example, using PB0:</p>
<pre>TCCR0A = 2&lt;&lt;COM0A0 | 3&lt;&lt;WGM00; // 10-bit PWM on OC0A (PB0), non-inverting mode
TCCR0B = 0&lt;&lt;WGM02 | 1&lt;&lt;CS00;   // Divide clock by 1
DDRB = 0b0001;                 // Make PB0 an output</pre>
<p>To write an analogue value we then need to write the value to the appropriate output compare register, OCR0A:</p>
<pre>OCR0A = 1000;                  // Equivalent to analogWrite(0, 1000)</pre>
<p>With a 5V supply this will set PB0 to 1000/1024 * 5V, or 4.88V.</p>
<h4>analogRead</h4>
<p>To use an I/O pin for analogue input you first need to configure the Analogue-to-Digital Converter. For example, to use ADC0:</p>
<pre>ADMUX = 0&lt;&lt;MUX0;               // ADC0 (PB0)
ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;   // Enable ADC, 125kHz clock</pre>
<p>To read an analogue value from the pin we then need to start a conversion, and when the conversion is ready read the ADC register:</p>
<pre>ADCSRA = ADCSRA | 1&lt;&lt;ADSC;     // Start
while (ADCSRA &amp; 1&lt;&lt;ADSC);      // Wait while conversion in progress
int temp = ADCL;               // Copy result to temp
</pre>
<h4>delay</h4>
<p>For a simple substitute for&nbsp;<strong>delay()</strong>&nbsp;you can use a loop adjusted to give roughly the right timing:</p>
<pre>void delay (int millis) {
  for (volatile unsigned int i = 34*millis; i&gt;0; i--);
}</pre>
<p>This would provide an alternative way of writing the Blink program. Note that the counter variable&nbsp;<strong>i</strong>&nbsp;must be defined as&nbsp;<strong>volatile</strong>&nbsp;or the compiler will optimise it out of the loop, eliminating the delay.</p>
<p>For more accurate delays, and to implement timers like&nbsp;<strong>millis()</strong>, you could set up Timer/Counter0 as a timer, or use the Watchdog Timer.</p>
<h3>Update</h3>
<p>30th December 2019: Added a note about problems compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 or later. Use 1.8 to 1.8.8.</p><hr>
<ol>
<li id="cite_note1"><a href="#cite_ref1">^</a> <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-8127-AVR-8-bit-Microcontroller-ATtiny4-ATtiny5-ATtiny9-ATtiny10_Datasheet.pdf">ATtiny10 Datasheet</a> on Microchip.</li>
<li id="cite_note2"><a href="#cite_ref2">^</a> <a href="https://www.sparkfun.com/products/717" target="_blank">Sparkfun SOT23 to DIP Adapter</a> on Sparkfun.</li>
<li id="cite_note3"><a href="#cite_ref3">^</a> <a href="http://www.fischl.de/usbasp/" target="_blank">USBasp - USP programmer for Atmel AVE controllers</a>&nbsp;on www.fischl.de.</li>
<li id="cite_note4"><a href="#cite_ref4">^</a> <a href="https://www.ebay.co.uk/itm/USBASP-USBISP-ISP-Programmer-Cable-Adapter-KK2-0-KK2-1-Atmel-AVR-ATMega-ARDUINO/131241223483" target="_blank">USBASP ISP Programmer Cable Adapter</a>&nbsp;from Boos Bits on eBay.</li>
<li id="cite_note5"><a href="#cite_ref5">^</a> <a href="https://www.banggood.com/USBASP-USBISP-3_3-5V-AVR-Downloader-Programmer-With-ATMEGA8-ATMEGA128-p-934425.html" target="_blank">USBASP 3.3 5V AVR Downloader Programmer</a>&nbsp;on Banggood.</li>
</ol>

<hr>


<p><a href="http://disqus.com/">blog comments powered by </a></p></div></div>]]>
            </description>
            <link>http://www.technoblogy.com/show?1YQY</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368633</guid>
            <pubDate>Thu, 10 Dec 2020 02:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the scenes photos of YC S20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368499">thread link</a>) | @cheeseblubber
<br/>
December 9, 2020 | https://papercups.io/blog/what-remote-demo-day-looked-like | <a href="https://web.archive.org/web/*/https://papercups.io/blog/what-remote-demo-day-looked-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/what-remote-demo-day-looked-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368499</guid>
            <pubDate>Thu, 10 Dec 2020 01:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How eBPF Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367728">thread link</a>) | @gk1
<br/>
December 9, 2020 | https://goteleport.com/blog/what-is-ebpf/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/what-is-ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-header.png" width="100%" alt="what is ebpf"></p>

<p>About a year ago, a friend of mine decided to build an <a href="https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e">EVM</a> (Ethereum Virtual Machine) assembler in Rust. After some prodding from him, I began to help by writing unit tests. At the time, I knew very little about operating systems and started to read about lexical and symbolical analyzers. I was quickly in way over my head. What I did retain, however, was a newfound appreciation for the OS as a whole. So, when he started raving about eBPF, I knew I was in for a treat.</p>

<p>The bar for understanding what eBPF is and what it can do is high. Finding a good foothold to start was difficult for me. On the spectrum of basic 500-word mini-blogs to <a href="https://cilium.io/">Cilium’s</a> overwhelming documentation, material certainly skews towards documentation. My goal here is to provide a thorough entrypoint into this nascent technology, preparing you for progressively technical deep dives, like <a href="https://lwn.net/Articles/740157/">Linux Weekly News</a>, <a href="http://www.brendangregg.com/index.html">Brendan Gregg’s</a> website, and Cilium’s <a href="https://docs.cilium.io/en/stable/bpf/">documentation</a>. Together, we will explore:</p>

<ul>
<li>What eBPF does</li>
<li>How eBPF works</li>
<li>An example of eBPF in use</li>
<li>How to start using eBPF</li>
</ul>

<h2 id="what-does-ebpf-do">What Does eBPF Do?</h2>

<p>eBPF lets programmers execute custom bytecode within the kernel <em>without</em> having to change the kernel or load kernel modules. Exciting? Maybe not yet. eBPF is closely intertwined with the Linux kernel. For context, let’s briefly review some fundamental concepts.</p>

<p>Linux divides its OS into two distinct areas: kernel space and user space. Kernel space is where the core of the operating system resides. It has full and unrestricted access to all hardware - memory, storage, CPU, etc. Due to the privileged nature of kernel access, the space is protected and allowed to run only the most trusted code. User space is where anything that is not a kernel process runs - I/O, file system manipulation, etc. These programs have limited access to hardware and must make syscalls through an API exposed by the kernel. In other words, user space programs must be filtered through the kernel space.</p>

<p>While the system call interface was sufficient in most cases, developers need more flexibility to add support for new hardware, filesystems, network protocols, or even custom system calls. There had to be a way for custom programs to access hardware directly, a way to extend the base kernel without adding directly to the kernel source code. <a href="https://tldp.org/LDP/lkmpg/2.6/html/lkmpg.html">Linux Kernel Modules</a> (LKMs) serve this function. Unlike system calls, whereby requests traverse from the user space to kernel space, LKMs are loaded directly into the kernel, making them a part of it. Perhaps the most valuable feature of LKMs is that it can be loaded at runtime, removing the need to recompile the entire kernel and reboot the machine.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-1.png" width="60%" alt="LKMs in kernel space"></p>

<p>Figure 1 - LKMs can be dynamically loaded and unloaded as part of kernel space (<a href="http://derekmolloy.ie/writing-a-linux-kernel-module-part-1-introduction/">Source</a>)</p>

<p>As helpful as LKMs are, they do introduce a lot of risk to the system. The division of kernel and user spaces added a number of security measures to the OS. The kernel space is meant to run only a privileged OS kernel. The layer between, connected by the system call interface, separated user space programs that could mess with finely tuned hardware. In other words, LKMs could certainly crash the kernel. Aside from the wide blast radius of security vulnerabilities, modules incur a large overhead maintenance cost in that kernel version upgrades could break the module.</p>

<h4 id="what-is-ebpf">What is eBPF</h4>

<p>eBPF programs are a more recent invention for accessing services and hardware from the Linux kernel space. Already these programs have been used for networking, debugging, tracing, firewalls, and more.</p>

<p>Born out of a need for better Linux tracing tools, eBPF drew inspiration from <code>dtrace</code>, a dynamic tracing tool available primarily for Solaris and BSD operating systems. Unlike <code>dtrace</code>, Linux could not get a global overview of running systems, it was limited to specific frameworks for system calls, library calls, and functions. Building on the Berkeley Packet Filter (BPF), a tool for writing packer-filtering code using an in-kernel VM, a small group of engineers began to extend the BPF backend to provide a similar set of features as <code>dtrace</code>. First released in limited capacity in 2014 with Linux 3.18, making full use of eBPF requires at least Linux 4.4 or above.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-2.png" width="100%" alt="simplified visualization of eBPF architecture"></p>

<p>Figure 2</p>

<p>In Figure 2, we see a simplified visualization of eBPF architecture. Before being loaded into the kernel, the eBPF program must pass a certain set of requirements. Verification involves executing the eBPF program within the virtual machine. Doing so allows the <a href="https://github.com/torvalds/linux/blob/master/kernel/bpf/verifier.c">verifier</a>, with 10,000+ lines of code, to perform a series of checks. The verifier will traverse the potential paths the eBPF program may take when executed in the kernel, making sure the program does indeed run to completion without any looping that would cause a kernel lockup. Other checks, from valid register state, program size, to out of bound jumps, must also be met. Almost immediately, eBPF sets itself apart from LKMs with important safety controls in place.</p>

<p>If all checks are passed, the eBPFprogram is loaded and compiled into the kernel at a point in a code path and listens for the right signal. That signal comes in the form of an event that passes where the program is loaded in the code path. Once triggered, the bytecode executes and collects information as per its instructions.</p>

<p>So what does eBPF do? It lets programmers safely execute custom bytecode within the Linux kernel without modifying or adding to kernel source code. While still a far cry from replacing LKMs as a whole, eBPF programs introduce custom code to interact with protected hardware resources with minimal threat to the kernel.</p>

<h2 id="how-ebpf-works">How eBPF Works</h2>

<p>So far, I’ve reduced eBPF to its bare architecture. But, there are more components working together, each of which has layers of complexity of their own.</p>

<h3 id="anatomy-of-an-ebpf-program">Anatomy of an eBPF Program</h3>

<h4 id="events-and-hooking">Events and Hooking</h4>

<p>eBPF programs are triggered by events that pass a particular location in the kernel. These events are captured at hooks when a specific set of instructions are executed in a single run. When triggered, these hooks will execute an eBPF program, letting us capture or manipulate data. The diversity of hook locations is one of the many aspects that makes eBPF so useful. A quick sampling of these locations include:</p>

<ul>
<li>System Calls - Inserted when user space functions transfer execution to the kernel</li>
<li>Function Entry and Exit - Intercepts calls to pre-existing functions</li>
<li>Network Events - Executes when packets are received</li>
<li>Kprobes and uprobes - Attach to probes for kernel or user functions</li>
</ul>

<h4 id="helper-calls">Helper Calls</h4>

<p>When eBPF programs are triggered at their hook points, they make calls to helper functions. These special functions are what makes eBPF feature-rich in accessing memory. For example, helpers can perform a wide variety of tasks:</p>

<ul>
<li>Search, update, and delete key-value pairs in tables</li>
<li>Generate a pseudo-random number</li>
<li>Collect and flag tunnel metadata</li>
<li>Chain eBPF programs together, known as tail calls</li>
<li>Perform tasks with sockets, like binding, retrieve cookies, redirect packets, etc.</li>
</ul>

<p>These helper functions must be defined by the kernel, meaning there is a whitelist of calls eBPF programs can make. But the <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">number</a> is large and continues to grow.</p>

<h4 id="maps">Maps</h4>

<p>To store and share data between the program and kernel or user spaces, eBPF makes use of maps. As implied by the name, maps are key-value pairs. Supporting a number of different data structures, like hash tables, arrays, and tries, programs are able to send and receive data in maps using helper functions.</p>

<h3 id="executing-an-ebpf-program">Executing an eBPF Program</h3>

<h4 id="loading-and-verifying">Loading and Verifying</h4>

<p>The kernel expects all eBPF programs to be loaded as bytecode, so unless bytecode is being written, we need a way to compile higher level languages. To build out this compiler, eBPF uses <a href="https://llvm.org/">LLVM</a> as its back-end infrastructure on which a front-end for any programming language can be built. Because eBPF programs are written in C, that language front end is <a href="https://clang.llvm.org/">Clang</a>. But before compiled bytecode can be hooked anywhere, it must pass a series of checks. By simulating the program in a VM-like construct, an <a href="https://elixir.bootlin.com/linux/latest/source/kernel/bpf/verifier.c">in-kernel verifier</a> can prevent programs that loop, do not have the right permissions, or crash the kernel. If the program passes all checks, program bytecode will be loaded onto the hook point using a <code>bpf()</code> system call</p>

<h4 id="just-in-time-jit-compiler">Just-In-Time (JIT) Compiler</h4>

<p>After verification, eBPF bytecode is JIT’d into native machine code. eBPF has a modern design, meaning it has been upgraded to be 64-bit encoded with 11 total registers. This closely maps eBPF to hardware for x86_64, ARM, and arm64 architecture, amongst others. Fast compilation at runtime makes it possible for eBPF to remain performant even as it must first pass through a VM.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-3.png" width="100%" alt="eBPF architecture"></p>

<p>eBPF Architecture (<a href="https://lucid.app/invitations/accept/0096e31e-14f9-47d4-a1a0-57e82b3bc6f5">Raw LucidChart</a>)</p>

<h3 id="summary">Summary</h3>

<p>Putting this conceptual jigsaw together, eBPF programs are inserted into a hook point after passing a number of safety checks. When they are triggered by an event, programs execute immediately, using a combination of helper functions and maps to manipulate and store data. We’ll take a closer look at how these components work together in the next section</p>

<h2 id="example-ebpf-in-action">Example: eBPF in Action</h2>

<p>At Teleport, we’ve used a few eBPF programs in one of our open source projects, Teleport, for tracing and networking. For some necessary context: <a href="https://goteleport.com/teleport">Teleport</a> gives developers secure server access via SSH. Because organizations want to know what happens during a session, Teleport records user actions. Yet there are ways to bypass session recording entirely by obfuscating behavior within encoded commands, commands run in shell scripts, or even terminal commands like disabling <code>echo</code>.</p>

<p>Earlier this year with our <a href="https://goteleport.com/blog/teleport-release-4-2">Teleport 4.2 release</a>, we introduced <em>enhanced</em> session recording, which uses three eBPF programs (for now!) to take unstructured SSH sessions and transform them into a stream of structured events.</p>

<p>Consider <code>echo Y3VybCBodHRwOi8vd3d3LmV4YW1wbGUuY29tCg== | base64 --decode | sh</code>. Though we can capture this command printed in the terminal, it means nothing to us as the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/what-is-ebpf/">https://goteleport.com/blog/what-is-ebpf/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/what-is-ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367728</guid>
            <pubDate>Thu, 10 Dec 2020 00:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOSBox-X 0.83.8 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367662">thread link</a>) | @fm77
<br/>
December 9, 2020 | https://dosbox-x.com/release-0.83.8.html | <a href="https://web.archive.org/web/*/https://dosbox-x.com/release-0.83.8.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
            <tbody><tr>
            <td></td>
            <td>
            <p>1. Notable New Features</p>
<ul>
<li><p>Scalable TrueType font (TTF) output for DOS applications</p>With the new TrueType font (TTF) output, you will get nice high resolution DOS screen rendered using a TrueType font (either the built-in one or a TTF font of your choice), and the window can be set to almost any usable number of lines and columns. This feature greatly improved DOSBox-X's support for DOS applications. Set "output=ttf" (or from the "Video" menu) to enable this output.</li>

<li><p>On-screen text styles for DOS applications</p>With the TrueType font output, DOSBox-X now supports on-screen text styles for DOS applications including WordPerfect, WordStar, and XyWrite. With this feature you will visually see fonts in bold for bold text, and fonts in italics for italicized text, and so on. Set a DOS word processor (WP/WS/XY) to enable this feature.</li>

<li><p>Support for Apple M1 Mac and macOS Big Sur</p>DOSBox-X now supports the new Apple ARM-based M1 MacBooks! The dynamic core now works on the new ARM-based macOS systems. The audio also works once again when compiled and run on macOS 11 Big Sur.</li>

<li><p>Pasting clipboard text in macOS SDL1 builds</p>Pasting text from the host system clipboard is now supported in the macOS SDL1 build, similar to the Linux SDL1 build. On all other platforms (Windows SDL1/SDL2, Linux SDL2, and macOS SDL2) both copying to and pasting from the clipboard are supported.</li>

<li><p>System menu in Windows SDL2 builds</p>The system menu that was available in Windows SDL1 builds is now also
available for Windows SDL2 builds, which includes a few common menu options such as the configuration tool and the mapper editor.</li>

<li><p>Select common host keys from the menu</p>You can now select a host key from the "Main" menu, which now includes common key combinations such as Ctrl+Alt, Ctrl+Shift, and Alt+Shift, or you may just use the mapper-defined host key (which default to F11 on Windows and F12
otherwise). The default shortcuts for a few items are changed to use the host key style.</li>

<li><p>Switch OpenGL (GLSL) shaders at run-time</p>With the OpenGL outputs (opengl/opengnb/openghq), you can now select and switch to a different GLSL shader at the run-time by selecting the menu item "Select OpenGL (GLSL) shader..." from the "Video" menu, similar to the function for Direct3D pixel shaders for the Direct3D output.</li>

<li><p>Display IDE disk or CD status</p>There is now a menu option under "DOS" menu which allows you to see the current assignments (disk or CD image) of the IDE controllers.</li>

<li><p>Support for mounting MAME CHD CD images</p>Mounting the MAME CHD images is now supported in DOSBox-X! You can mount CHD files as CD images with IMGMOUNT command, or from the "Drive" menu.</li>

<li><p>Support for saving your files for the save-state feature</p>There is a now a FLAGSAVE command which allows you to mark files to be saved and loaded by the save-state feature. Type "FLAGSAVE /?" at the DOSBox-X shell for more usage information.</li>

<li><p>Enhanced MODE command to change screen dimensions</p>You can now change the number of columns and lines on the screen with the
MODE command, similar to real DOS systems. Alternatively, this can be done from the "Video" menu (within "Text-mode" menu group).</li>

<li><p>Improved LOADFIX command to auto-allocate memory</p>The LOADFIX command now has an -a option which will automatically allocate enough memory to fill lowest 64KB memory instead of using exactly 64KB memory. This will let some memory-demanding DOS programs or games to run with this command.</li>

<li><p>Improved automatic fix for the "Packed file corrupt" error</p>The handler for the "Packed file corrupt" error has been greatly improved so that it will likely automatically handle the error more efficiently. There is now also an option to silence the messages during the automatic fix.</li>

</ul>

            <p>2. Notable Usability Improvements</p>
<ul>
<li><p>Improved mapper editor interface</p>The mapper editor interface has been enhanced! The texts for the shortcut functions are now longer and clearer, and there are now multiple pages in the mapper, navigable with the "Previous Page" and "Next Page" buttons.</li>

<li><p>Load DOSBox-X mapper files from menu</p>You can now select and load DOSBox-X mapper files at run-time from the "Main" menu. Previously it was possible to load a mapper file dynmically from the command line, but now you can do so from the menu too.</li>

<li><p>List network interfaces from menu</p>There is now a "List network interfaces" menu option under the "Help" menu that will list the current network interfaces for the NE2000 networking feature. Previously you can only see the network interface list from the log file.</li>

<li><p>Display DOS command help from menu</p>You can now find a "DOS commands" menu group under the "Help" menu, which allows you to select a DOS shell command (DIR, CD, etc) to see its help messages. Alternatively you can type "[COMMAND] /?" (e.g. "DIR /?") for help information for the command.</li>

<li><p>Searching for config file and mapper file in DOSBox-X executable path</p>DOSBox-X will now look for the config file (e.g.
dosbox-x.conf) and the mapper file in the directory containing the DOSBox-X executable too if they cannot be found in the DOSBox-X working directory. This makes DOSBox-X even more portable.</li>

<li><p>More saving options for the built-in configuration tool</p>The graphical configuration tool now provides the option to save
to the primary or user config files, not just the dosbox-x.conf file.</li>

<li><p>New config options for save state options</p>The config options "saveremark" and "forceloadstate" are added to [dosbox]
section which can be used to control the save state-related options from the config file. In the previous section these can only be done from the "Capture" menu.</li>

</ul>

            <p>3. Bugfixes and Other Improvements</p>
There are also many bugfixes and other improvements, such as fixing the CD audio issue with the game "The Secret of Monkey Island" when talking to the pirate in Scumm Bar. Please see the full changelogs below for more information.
<p>4. Full Changelog In This Version</p>
<ul>
<li>
Added support for scalable TrueType font (TTF)
output for text-mode programs. Set "output=ttf"
and optionally a monospaced TTF font (such as
consola) with config option "ttf.font" to use it.
Lines and columns can be specified with config
options "ttf.lins" and "ttf.cols", and the cursor
can be made blinking with the option "ttf.blinkc".
The config options "ttf.ptsize" and "ttf.winperc"
can be used to set the TTF font size and window
percentage respectively. If you specify a TTF font
size with "ttf.ptsize" then "ttf.winperc" will be
ignored. You can also specify a word processor
(WP=WordPerfect, WS=WordStar, XY=XyWrite) for the
on-screen text-style and 512-character font (WP)
features. When using the TTF output DOSBox-X will
temporarily switch to a different output when a
graphical mode is requested (or when trying to take
a screenshot); the TTF output will be auto-switched
back later), which can be customized via config
option "ttf.outputswitch" (which defaults to auto).
Menu items in the "Text-mode" menu group (under
"Video" menu) have been expanded to support TTF
options such as increasing/decreasing the TTF font
sizes and on-screen text style toggling (including
bold, italics, underline and strikeout). You can
also select a TTF font to use at run-time with the
"Select TrueType font (TTF)" menu option. (Wengier)
</li><li>
Added the "Load mapper file..." menu option (under
"Main") to select and load a DOSBox-X mapper file
at run-time. Be sure to select a SDL1 mapper file
for SDL1 builds, and similar for SDL2. (Wengier)
</li><li>
You can now select a host key from the menu (under
"Main") including Ctrl+Alt, Ctrl+Shift, Alt+Shift,
or use the mapper-defined host key as in previous
versions (which default to F11 on Windows and F12
otherwise). A config option "hostkey" is added so
that you can specify it from config file. (Wengier)
</li><li>
Pasting text from the clipboard on macOS SDL1 build
is now supported like Linux SDL1 build. (Wengier)
</li><li>
Added support for ARM-based Apple M1 MacBook. The
dynamic core now works on ARM-based macOS systems.
SDL1 builds updated to use newer audio APIs on the
macOS platform so that the audio works once again
when compiled and run on macOS 11 (Big Sur). Prior
to the change, ancient versions of the API dating
back to the mid 2000s were used which no longer
work on Big Sur.
</li><li>
DOSBox-X will now look for the config file (i.e.
dosbox-x.conf/dosbox.conf) and the mapper file in
the directory containing the DOSBox-X executable
too if the config or mapper file cannot be found
in the DOSBox-X working directory. (Wengier)
</li><li>
The system menu in Windows SDL1 builds is now also
available for Windows SDL2 builds, and menu items
"Reset font size", "Increase TTF font size" and
"Decrease TTF font size" are added. (Wengier)
</li><li>
Enhanced the mapper editor interface to allow more
keyboard shortcuts to be added, shown in multiple
pages in the mapper, navigable with the "Previous
Page" and "Next Page" buttons. The text in the
grids are now longer and clearer too. The default
shortcuts for a few items are changed to use the
Host key style (e.g. Host+S and Host+L for saving
and loading states respectively). (Wengier)
</li><li>
Added menu item "List network interfaces" under
"Help" menu to list network interfaces in the host
system for the NE2000 feature. (Wengier)
</li><li>
Added menu group "DOS commands" under "Help" menu
to display the help content for the selected DOS
shell command (DIR, CD, etc). (Wengier)
</li><li>
Configuration Tool now provides the option to save
to the primary or user config files. (Wengier)
</li><li>
Certain config options (e.g. doublescan) that were
marked as advanced options are now general config
options and will appear in dosbox-x.reference.conf
apart from dosbox-x.reference.full.conf. (Wengier)
</li><li>
Added config options "saveremark" (default: true)
and "forceloadstate" (default: false) in [dosbox]
section which can be used to control if DOSBox-X
should ask users to enter remarks when saving a
state or show warnings when loading a saved state
if there is a mismatch found. (Wengier)
</li><li>
The config option "pixelshader" is moved from the
section [gui] to [render] …</li></ul></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dosbox-x.com/release-0.83.8.html">https://dosbox-x.com/release-0.83.8.html</a></em></p>]]>
            </description>
            <link>https://dosbox-x.com/release-0.83.8.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367662</guid>
            <pubDate>Thu, 10 Dec 2020 00:22:12 GMT</pubDate>
        </item>
    </channel>
</rss>
