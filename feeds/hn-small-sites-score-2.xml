<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 01 Mar 2021 12:40:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 01 Mar 2021 12:40:56 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Bupstash Garbage Collector]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26282771">thread link</a>) | @andrewchambers
<br/>
February 26, 2021 | https://acha.ninja/blog/the_bupstash_garbage_collector/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/the_bupstash_garbage_collector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h2 id="overview">Overview</h2>
<p>My backup tool <a href="https://github.com/andrewchambers/bupstash">bupstash</a> stores backups in a repository as an evergrowing set of
encrypted data trees which use content addressing and structural sharing
to deduplicate data. In order to delete unused backups we need to do something very similar to how
many programming languages free unreferenced memory - garbage collection. This post will
explain the evolution and implementation of the garbage collector in bupstash for the curious.</p>
<h2 id="stop-mark-and-sweep">Stop, mark and sweep.</h2>
<p>The initial version of the bupstash garbage collector was a naive stop-the-world
garbage collector. It walks all backup data trees creating a set of reachable data chunks
by address and then deletes unreachable data.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Stop the world.</li>
<li>Mark.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>lock_repository()
reachable_addresses = empty_set()

for data_tree in all_backups():
  
  work_list = new_work_list_from_backup(data_tree.root_address)
  
  until work_list.is_empty():
    
    node_height, node_address = work_list.pop()
    reachable_addresses.add(node_address)
    
    if node_height != 0:
      add_child_nodes_to_worklist(work_list, node_address)

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>This algorithm is short and sweet, but if the repository is very large our repository becomes unavailable
for a potentially long time. The next version shortens the downtime of the repository significantly.</p>
<h2 id="mark-stop-mark-and-sweep">Mark, stop, mark and sweep.</h2>
<p>The bupstash v0.6.4 garbage collector takes advantage of two facts:</p>
<ul>
<li>Because many backups share data with each other, we can memoize the walk phase to skip work.</li>
<li>Because backups are immutable while the repository is unlocked, we can walk most of them without
stopping the world.</li>
</ul>
<p>This time we walk the repository without the repository locked, then lock it and walk
the repository again using our memoization to quickly complete the job. If any new backups
appeared during our first walk, we are guaranteed to mark them now that the repository lock is held. Doing the majority of the slow mark phase without locking the repository greatly increases
the repository availability for other operations.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark repository.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
reachable_addresses = empty_set()

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = reachable_addresses.has(node_address)
      reachable_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><h2 id="mark-stop-mark-bloom-adjust-and-sweep">Mark, stop, mark, bloom adjust, and sweep</h2>
<p>The next version of the garbage collector is a WIP unreleased version.</p>
<p>In bupstash each data chunk address is 32 bytes, which means we need at least 32 bytes of RAM per chunk in the repository to successfully perform a garbage collection. For a repository containing a 100 million chunks or
more this could easily exhaust memory on a busy or small system.</p>
<p>If we are willing to accept a very low probability of retaining some extra data, we can reduce this down
to a few <em>bits</em> per chunk reducing memory usage by 64x or more.
To do this we use a probabilistic data structure called a <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to track reachable addresses.</p>
<p>Bloom filters have two downsides:</p>
<ul>
<li>They can have false positives. For us this means we might keep a data chunk by accident we could have actually freed.</li>
<li>We must presize them. They cannot grow if we got the size wrong.</li>
</ul>
<p>Luckily for us these downsides are not bad:</p>
<ul>
<li>Because memory use is so low per address, we can generously size our bloom filter reducing false positives to less than one percent, even for large repositories.</li>
<li>We can easily detect when a bloom filter gets overly full and produces many false positives, and thus adjust it’s size for future garbage collections.</li>
</ul>
<p>As a bonus, the bupstash implementation of a bloom filter is actually simpler than a hash table, with the implemenation
weighing in at around 30 lines of code plus tests and helpers.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark the repository.</li>
<li>Adjust bloom filter size.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
walked_addresses = empty_cache()
reachable_addresses = empty_bloom_filter(repository_bloom_size())

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = walked_addresses.has(node_address)
      reachable_addresses.add(node_address)
      walked_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

if bloom_filter_overutilized(reachable_addresses):
  increase_bloom_filter_size_for_next_gc()
else if bloom_filter_underutilized(reachable_addresses):
  decrease_bloom_filter_size_for_next_gc()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>One thing to note about this implementation is that because the bloom filter has false positives we can not use it to skip processing addresses, instead
we must introduce a new cache for this purpose. A cache also lets us put a fixed upper bound on memory usage for large repositories.</p>
<p>Overall for large repositories, the addition of a bloom filter reduces ram requirements from the gigabyte range down to tens of megabytes while increasing the repository size by only a fraction of a percent.</p>

<p>The bupstash garbage collector tries hard to keep the repository avaliable as long
as possible while also providing excellent performance with a small memory profile. If you are implementing
a content addressed storage system, this post will hopefully provide you with some new ideas.</p>
<p>In the future bupstash could follow the same path as programming language garbage collectors to find more improvements:</p>
<ul>
<li>Parallelism in the mark phase.</li>
<li>Parallelism in the sweep phase.</li>
<li>Incremental collection.</li>
<li>Object generations.</li>
<li>Write barriers</li>
<li>Yet to be invented techniques…</li>
</ul>
<p>As always, thanks for reading and please feel free to give <a href="https://github.com/andrewchambers/bupstash">bupstash</a> a try.</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/the_bupstash_garbage_collector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282771</guid>
            <pubDate>Sat, 27 Feb 2021 04:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do farmers have the right to repair their own equipment?]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26282642">thread link</a>) | @curmudgeon22
<br/>
February 26, 2021 | https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/ | <a href="https://web.archive.org/web/*/https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span><span>Reading Time: </span> <span>5</span> <span>minutes</span></span></p><p>It’s a story that’s becoming more and more common.</p>
<p>You’re smack dab in the middle of harvest and an error code appears on your combine’s monitor. A call to the dealership results in a long wait for a technician to come out, with anxiety rising with every passing hour because priceless harvesting time is being lost or, worse, nasty weather is moving in.</p>
<p>Then when the technician gets to your farm, he determines what is needed is to reset (or ‘flash’) the onboard computer.</p>
<p>That happened to Cole Siegle last fall when he was harvesting canola, leaving the Fairview-area producer to wonder why he can’t have access to the same diagnostic tools.</p>
<div id="attachment_133445"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>Cole Siegle.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>“If I could have done that myself or been able to use a mechanic or a technician who’s closer to me, our downtime could have gone from six hours to two hours,” he said. “That four hours could have been the difference between getting&nbsp;a crop off before the snow or not.”</p>
<p>But these days it’s dealerships — via sales and service agreements with manufacturers — that have legal access to these diagnostic tools. So when an error message pops up, farmers and independent mechanics are out in the cold, sometimes literally.</p>

<ul>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/connectivity-grey-under-new-trade-agreement/">Connectivity ‘grey’ under new trade agreement</a></strong></li>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/remote-diagnostics-blocked-by-poor-internet-on-farms/">Remote diagnostics blocked by poor internet on farms</a></strong></li>

</ul>
<p>“As a producer I think we need access to these diagnostic tools,” said Siegle. “If (manufacturers) want to continue to build equipment like this that’s fine, but we need access to the laptops with the programs that we can plug into our equipment so we can buy whatever part we need.”</p>
<p>Equipment manufacturers make a lot of repair information public, including what codes mean, but giving access to proprietary tools raises several issues, said John Schmeiser, CEO of the Western Equipment Dealers Association.</p>
<p>The hardware and software Siegle and other farmers wish to acquire for repair purposes can also be used to modify equipment to the detriment of machinery, warranties, the lawfulness of their operations and even their own safety, he said.</p>
<p>“I applaud the manufacturers that put a lot of stuff online&nbsp;like parts, service manuals and operational guides. But it’s a slippery slope,” said Schmeiser.</p>
<p>“When you provide special tools to somebody outside a controlled environment like the manufacturer/dealer&nbsp;relationship, that opens the door for illegal modification. They lose that control when they provide&nbsp;diagnostic or special tools to a third-party retailer with whom they don’t have the same sales and services agreement.”</p>
<h2>Repair versus modify</h2>
<p>‘Right to repair’ is a term being thrown around a lot in ag circles today, but it means different things to different people.</p>
<p>For Siegle and other like-minded producers, it means the right to either repair equipment themselves or hire an unaffiliated local mechanic — just as farmers have done throughout the history of mechanized agriculture.</p>
<div id="attachment_133446"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>John Schmeiser.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>But Schmeiser argues that farmers’ right to repair is already entrenched in law in many jurisdictions (including Alberta) as long as the owner is using the equipment for its intended purpose and doesn’t violate manufacturer standards.</p>
<p>The right to repair (R2R) movement (which started in the tech sphere but expanded to other areas, such as ag equipment) is actually a front for promoting the ‘right to modify,’ he said.</p>
<p>Often that means making modifications to bypass environmental controls in order to boost vehicle horsepower.</p>

<p>“There are over 25 states that had R2R bills introduced — every one impacting farm equipment has been defeated,” said Schmeiser. “They haven’t passed&nbsp;because as the state representatives were hearing the rationale coming from R2R advocates, they were finding out that what they were really looking for is to modify the equipment in a manner where&nbsp;it can get around emission standards and violate U.S. Environmental Protection Agency laws and regulations.”</p>
<h2>DEF delete and chipping</h2>
<p>There are two specific actions that concern Schmeiser’s association (a Missouri-based advocacy group for equipment dealerships with a Canadian headquarters in Calgary).</p>
<p>One is circumventing Diesel Exhaust Fluid (or DEF) emissions systems using grey-market ‘DEF delete’ kits to boost horsepower on tractors and combines. Another is ‘chipping’ or ‘tuning,’ which usually refers to adding a specific chip to increase horsepower.</p>
<p>Bypassing emissions control systems contravenes the Canadian Environmental Protection Act, leaving producers open to fines, said Schmeiser, adding he was unsure of the Canadian penalties but breaches of similar U.S. laws have produced fines in excess of $300,000.</p>
<p>Part of the problem is that not everyone knows this practice is illegal. Another is it comes with a host of potential risks including damaged equipment, voided warranties, reduced trade-in value, insurance cancellation and even safety, he said.</p>
<p>“We have seen an unusual number of combine fires this (past) year,” said Schmeiser.</p>
<p>“Now, we have had some dry conditions but in some of those cases the combines were running hotter (due to alterations).</p>

<p>“The insurance company will look at it from the standpoint that you have altered your combine away from the manufacturer’s original standards and you are going to be denied insurance coverage in a situation like that.”</p>
<p>But Siegle isn’t convinced.</p>
<p>He said he has no interest in making such modifications to his equipment and suggested it’s a straw man argument from manufacturing and dealership interests seeking exclusive control over the diagnostic tools.</p>
<p>The kind of modification Siegle is concerned about losing is the legal ability to place, for example, a third-party manufacturer’s custom header on a John Deere combine. Specifically, he worries about big manufacturers denying third-party companies the codes required for an implement to interact with a tractor or combine.</p>
<p>Schmeiser said this isn’t considered modification but rather interoperability or connectivity: A third party designing an implement to attach to another manufacturer’s product. This is a long-standing tradition in the manufacturing and dealership industries that few if anyone has any interest in ceasing, he said (see accompanying story).</p>
<h2>The business aspect</h2>
<p>All of this still does not answer Siegle’s fundamental question: Why can’t I — or mechanics unaffiliated with specific manufacturers — have all the tools required to diagnose and fix a mechanical problem?</p>
<p>In the past it was relatively easy for mechanically minded producers and unaffiliated mechanics to repair machinery because it ran on tried-and-traditional engineering principles. This is still by and large the case, said Schmeiser, adding 95 per cent of equipment issues can still be fixed mechanically.</p>
<p>He said he understands the frustration farmers feel by not having diagnostic tools at their fingertips. But at the same time dealerships have rights as well, especially when one considers the considerable training and expense needed to obtain service contracts with manufacturers.</p>
<p>“What the farmer is speaking to is the frustration of being down. He wants to get up and running as quickly as possible. We get that,” said Schmeiser.</p>
<p>“But the moment the manufacturers start providing special tools or diagnostics&nbsp;equipment to businesses that are outside of their dealer contracts, doesn’t that diminish the value of the contract in the dealer’s eyes as well?… So what’s the incentive for the manufacturer&nbsp;to provide special tools or even service manuals to a third party that would be competing with somebody they have a contractual relationship with&nbsp;(and) who is also making a substantial financial investment to be the representative for the manufacturer?”</p> </div>
</div></div>]]>
            </description>
            <link>https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282642</guid>
            <pubDate>Sat, 27 Feb 2021 04:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Assembly Language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26282634">thread link</a>) | @swolchok
<br/>
February 26, 2021 | https://wolchok.org/posts/how-to-read-assembly-language/ | <a href="https://web.archive.org/web/*/https://wolchok.org/posts/how-to-read-assembly-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why, in 2021, does anyone need to learn about assembly language?
First, reading assembly language is the way to know <em>exactly</em> what
your program is doing. Why, <em>exactly</em>, is that C++ program 1 MiB (say)
instead of 100 KiB? Is it possible to squeeze some more performance
out of that function that gets called all the time?</p><p>For C++ in particular, it is easy to forget or just not notice some
operation (e.g., an implicit conversion or a call to a copy
constructor or destructor) that is implied by the source code and
language semantics, but not spelled out explicitly. Looking at the
assembly generated by the compiler puts everything in plain sight.</p><p>Second, the more practical reason: so far, posts on this blog haven’t
required an understanding of assembly language, despite constant
links to <a href="https://godbolt.org/">Compiler Explorer</a>. By <a href="https://twitter.com/ScottWolchok/status/1361022423399755776">popular
demand</a>,
however, our next topic will be parameter passing, and for that, we
will need a basic understanding of assembly language. We will focus
only on <em>reading</em> assembly language, not writing it.</p><p>The basic unit of assembly language is the <strong>instruction</strong>. Each
machine instruction is a small operation, like adding two numbers,
loading some data from memory, jumping to another memory location
(like the dreaded <a href="https://en.wikipedia.org/wiki/Goto">goto</a>
statement), or calling or returning from a function. (The x86
architecture has <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">lots of not-so-small
instructions</a>
as well. Some of these are <a href="https://stackoverflow.com/questions/5959890/enter-vs-push-ebp-mov-ebp-esp-sub-esp-imm-and-leave-vs-mov-esp-ebp">legacy
cruft</a>
built up over the 40-odd years of the architecture’s existence, and
others are <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">newfangled
additions</a>. )</p><p>Our first toy example will get us acquainted with simple
instructions. It just calculates the square of the
<a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a>
of a 2D vector:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
    <span>int64_t</span> z;
};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and here is the resulting x86_64 assembly from clang 11, <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAGYADKS3oAMnlqYAcsYBGmYiADspAA6oFQnVaPUMTcyt/QLU6e0cXI3dPHyUVGNoGAmZiAlDjU0tFZUxVYMzsgjjnNw9vRSycvPDChQbKh2rE2q8ASkVUA2JkDgByKTMHZEMsAGpxMx1kVvx6eexxCwBBDc3W4gNVGYA1Esk5r1ktmeuZhwIANm4AfQIZgA95y82b2/pHl5mAE9PuIvAAREFbHZ3f6vWgkIwMACOBmymHQEBOyDOADceucvj9iJgCINaDMcQA6N4zABUFOpcxkDMBdJZkO24JGfVYIBGAFYRqRTCMLELUHydHI5DMFAMhpgmWZOEKCHyxT0%2BgBrcxmSlmA2Go1G%2B5CPncIUisWkCUjIUKEBWNWi7mkOCwJBoIy%2BPDsMgUCBen1%2BlDCUScTgWTikKi%2BggeB0QVzqoWuBzZQF8lWkL1GLQEADytFYmZdpCwRhEwHYKfLeGJpRxmAdZcwbxKBnjWaFd2U3aEeFcxAzeiw/YIxDwRm7fRo9CYbA4PH4gjDYmlMgHrgdkD6qF86RbAFoC2YZkflvMwRIZHJJNbUiV0pptE1TNGbFUEklBFEgnQ31/AJ/1oL8ak8aNH1KOhykafR8kEKD0lg9p4nAxC2kAyC2jAroIL6OVBmGLgeT5QVhVrW03gADnuI9HhmKYqxmCNKQsSlOBmCBcEIEglWjGY9G9X0PH4/EpVvGRVRTTVSB1A19WNJSDVNXkRgtCiy1te1HVIZ0NTdGBEBQVBhL9chKCDETPCY8NI2jWNWHjYhE2TMs01oDN%2B1zfMixLWsKyrGsy3wBs1CbFtrTbDsuxGbNezU61WEHYdiEBUdRmtCcpxnGM6EYFga2XARJCEKsUA3eRku3eA9wPYJj1Pc9LzMa9Kvve1img0wIBsLDrG0XCf2jP90n60bgiG2pIK65DMPg8IZrSMocI6b9pvqCp%2BtaCopvw/oiKXUiBUtSi%2BRouiGNs4AWM4NiOK4niiGIfjSEE0zg1E8ZJHEyrpJdWT5L1ZTlLNdTTq0vkdKdGTjskCHrW0vTYdIJsXOCEBuCAA%3D%3D">via Compiler Explorer</a>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><div><pre><code data-lang="asm">        <span>imulq</span>   %rdi, %rdi
        <span>imulq</span>   %rsi, %rsi
        <span>leaq</span>    (%rsi,%rdi), %rax
        <span>retq</span>
</code></pre></div><p>Let’s talk about that first instruction: <code>imulq %rdi, %rdi</code>. This
instruction <a href="https://www.felixcloutier.com/x86/imul">performs signed integer
multiplication</a>. The <code>q</code>
suffix tells us that it is operating on 64-bit quantities. (In
contrast, <code>l</code>, <code>w</code>, and <code>b</code> would denote 32-bit, 16-bit, and 8-bit,
respectively.) It multiplies the value in the first given register
(<code>rdi</code>; register names are prefixed with a <code>%</code> sign) by the value in
the second register and stores the result in that second
register. This is squaring <code>v.x</code> in our example C++ code.</p><p>The second instruction does the same with the value in <code>%rsi</code>, which
squares <code>v.y</code>.</p><p>Next, we have an odd instruction: <code>leaq (%rsi,%rdi), %rax</code>. <code>lea</code>
stands for “load effective address”, and it stores the address of the
first operand into the second operand. <code>(%rsi, %rdi)</code> means “the
memory location pointed to by <code>%rsi + %rdi</code>”, so this is just adding
<code>%rsi</code> and <code>%rdi</code> and storing the result in <code>%rax</code>. <code>lea</code> is a quirky
x86-specific instruction; on a more
<a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a>-y
architecture like ARM64, we would expect to see a plain old <code>add</code>
instruction.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>Finally, <code>retq</code> returns from the <code>normSquared</code> function.</p><p>Let’s take a brief detour to explain what the registers we saw in our
example are. Registers are the “variables” of assembly
langauge. Unlike your favorite programming language (probably), there
are a finite number of them, they have standardized names, and the
ones we’ll be talking about are at most 64 bits in size. Some of them
have specific uses that we’ll see later. I wouldn’t be able to rattle
this off from memory, but <a href="https://en.wikipedia.org/wiki/X86-64#Architectural_features">per
Wikipedia</a>,
the full list<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of 16 registers on x86_64 is <code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rbx</code>,
<code>rsp</code>, <code>rbp</code>, <code>rsi</code>, <code>rdi</code>, <code>r8</code>, <code>r9</code>, <code>r10</code>, <code>r11</code>, <code>r12</code>, <code>r13</code>,
<code>r14</code>, and <code>r15</code>.</p><p>Now, let’s extend our example to debug print the <code>Vec2</code> in <code>normSquared</code>:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
<span>    <span>void</span> <span>debugPrint</span>() <span>const</span>;
</span>};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
<span>    v.debugPrint();
</span>    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and, again, let’s see <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEJICcpLegAyeWpgByxgEaZiIAGykADqgWE6rR6hiaCfgFqdHYOzkZuHt5KKlG0DATMxAQhxqYWisqYqkHpmQQxTq7uXooZWTlhnLVlFXEJXgCUiqgGxMgcAORSAMz2yIZYANTiwzrICgT49DPY4gAMAILrGwvEBqqTAGpFktMA7LKbk9eT9gSe3AD6BJMAHjOXGze39A/PkwBPD7bb4AN1QeHQkywLgMwAACsQ7hAOpM0LQFsDNuIzgARLFbTZ3P4vWgkIwMACOBkymHQEGOyFOoNROM%2BYIAdDC4YjkR0Cd9iJgCL1aJNQRzXpMAFTiyXTGRygEypUEnG4gZdVggAYAVgGpFMAzWBtQOp0cjkkwUPT6mAVw04BoIOpNHS6AGsQMNhhyff6A4HvNqBtwDUaTaQzQMDQoQGtSC7jZrSHBYEg0EYfHh2GQKBBM9ncyhhKJOJw1k0qDmCO44xAXK6DS57JkATqnaRM0YtAQAPK0Vjt5OkLBGETAdhN0d4IXFUGYOMjzCvIoGWsdg13ZSboR4FzENt6LC7ghIoybro0ehMNgcHj8QSlsSWmR7lxxyBdVA%2BVJLgC0fbDJM/4LOgMy4hIMhyJIkbJEUqSaNoDSmE01itFUHhNBEgR0Ch4T%2BLhtAYfE1RNPBxR0KU9T6LkggUak1HlPYlSkVhzQ0aEqEccxsSYVwXQ2r0/QCUIOr6oa07Rq8AAcnj/g8aLPpM5YcmsHKcJMEC4IQJAOk0kx6FmObuPpqIWtBMjOk27qkF6Pp%2BoGTk%2BsGOphpJI7RrG8aJjZqYwIgKCoMZubkJQhYmR44wTuWlakNWrC1sQ9aNiOLa0G2u7dr2A5DtOY4TlOI74HOagLkukYrmuG4DJ224hpGrD7oexAAsegyRmeeAXrVKbXowLBTg%2BAiSEIE4oK%2B8hNR%2B8Dfr%2BQQAUBIFgRBUGyDIsGxoUlGmBA1j4Zwo3oSxbRkcMviEakB2jThqQke0nDnQxJR1NktGNKNz1Ua991nTx108b9WHDIJtoiZwWrieGUk6rJ8mKdFogqZwakaVpOlEMQ%2BmkIZwVFqZIySOZk3Wcmtn2b6znOWJobQ55OreQmSZupDAySHTkZeb5ZNdAuyVBCA3BAA">the generated assembly</a>:</p><div><pre><code data-lang="asm">        <span>subq</span>    <span>$24</span>, %rsp
        <span>movq</span>    %rdi, <span>8</span>(%rsp)
        <span>movq</span>    %rsi, <span>16</span>(%rsp)
        <span>leaq</span>    <span>8</span>(%rsp), %rdi
        <span>callq</span>   <span>Vec2</span>::<span>debugPrint</span>() <span>const</span>
        <span>movq</span>    <span>8</span>(%rsp), %rcx
        <span>movq</span>    <span>16</span>(%rsp), %rax
        <span>imulq</span>   %rcx, %rcx
        <span>imulq</span>   %rax, %rax
        <span>addq</span>    %rcx, %rax
        <span>addq</span>    <span>$24</span>, %rsp
        <span>retq</span>
</code></pre></div><p>In addition to the obvious call to <code>Vec2::debugPrint() const</code>, we have
some other new instructions and registers! <code>%rsp</code> is special: it is
the “stack pointer”, used to maintain the <a href="https://en.wikipedia.org/wiki/Call_stack">function call
stack</a>. It points to the
bottom of the stack, which grows “down” (toward lower addresses) on
x86. So, our <code>subq $24, %rsp</code> instruction is making space for three
64-bit integers on the stack. (In general, setting up the stack and
registers at the start of your function is called the <a href="https://en.wikipedia.org/wiki/Function_prologue">function
prologue</a>.) Then, the
following two <code>mov</code> instructions store the first and second arguments
to <code>normSquared</code>, which are <code>v.x</code> and <code>v.y</code> (more about how parameter
passing words in the next blog post!) to the stack, effectively
creating a copy of <code>v</code> in memory at the address <code>%rsp + 8</code>. Next, we
load the address of our copy of <code>v</code> into <code>%rdi</code> with <code>leaq 8(%rsp), %rdi</code> and then call <code>Vec2::debugPrint() const</code>.</p><p>After <code>debugPrint</code> has returned, we load <code>v.x</code> and <code>v.y</code> back into
<code>%rcx</code> and <code>%rax</code>. We have the same <code>imulq</code> and <code>addq</code> instructions as
before. Finally, we <code>addq $24, %rsp</code> to clean up the 24
bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of stack space we allocated at the start of
our function (called the <a href="https://en.wikipedia.org/wiki/Function_prologue#Epilogue">function
epilogue</a>),
and then return to our caller with <code>retq</code>.</p><p>Now, let’s look at a different example. Suppose that we want to print
an uppercased C string and we’d like to avoid heap allocations for
smallish strings.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> We might write something like
the following:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdio&gt;</span><span>
</span><span>#include</span> <span>&lt;cstring&gt;</span><span>
</span><span>#include</span> <span>&lt;memory&gt;</span><span>
</span><span></span>
<span>void</span> <span>copyUppercase</span>(<span>char</span> <span>*</span>dest, <span>const</span> <span>char</span> <span>*</span>src);

<span>constexpr</span> size_t MAX_STACK_ARRAY_SIZE <span>=</span> <span>1024</span>;

<span>void</span> <span>printUpperCase</span>(<span>const</span> <span>char</span> <span>*</span>s) {
    <span>auto</span> sSize <span>=</span> strlen(s);
    <span>if</span> (sSize <span>&lt;=</span> MAX_STACK_ARRAY_SIZE) {
        <span>char</span> temp[sSize <span>+</span> <span>1</span>];
        copyUppercase(temp, s);
        puts(temp);
    } <span>else</span> {
        <span>// std::make_unique_for_overwrite is missing on Godbolt.
</span><span></span>        std<span>::</span>unique_ptr<span>&lt;</span><span>char</span>[]<span>&gt;</span> temp(<span>new</span> <span>char</span>[sSize <span>+</span> <span>1</span>]);
        copyUppercase(temp.get(), s);
        puts(temp.get());
    }
}
</code></pre></div><p>Here is <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAHZeW9ABk8tTADljAI0zEuANlIAHVAsLqtHqGJua8vv5qdLb2Tkau7pxeSipRtAwEzMQEwcamForKmKqBGVkEMY4ubp6Kmdm5oQUK9RV2VfE1SQCUiqgGxMgcAORSAMx2yIZYANTiYzrILfio89jiAAwAguOT05hzC0sExHbAa5s7khO0Uwaz8zpGmEYkAJ4X25cAbqh46DM0N43gBVbzeNwsJQQZAILIzABUWBapEBdBagLhxERCkG3Xmsi%2B2zQtBamAAHt5sf4AF6YAD6BBmAFktgANekMAAqWx0AGl6VsAEpCrYATU5AEkAFrYQ4AERmnA2km4BMuPz%2BAKpdgIYIhxB0zGhJIxsPhCIU3TmZkJWxmDpmzAMRBmCgYeDpCrdJ3YtAgVvV20dMzwVBmAY9Xse80VrI53N5AuFoolDBl2Gt4ltlxDIfN2IIL284gArNJ3Z6DnIlWX5UH7XmHUDQeDIcbMBAi0ZvKjA2M7U2Hd4XQou8X8QPc47s4rlEobYOhwB6Zc%2B9AgEBGZgAawZBloeAAjgYGTRiPTUN83AB3U5F0MKGZGPAKfyiGZ0GZ6Ht4djY7BKVYEg3AAOmnJtlk3A9j1PelvBOR4CzLWRS3rMY5W7bwIHsG9MSyFDK2jGRazQyclybFt9XbaEsNA4BMAICBejdciILzEcCDHOiGKY7o2ODGczHrL5hOGXpWBAYZS2GUhTGGDZZNQKSdDkGsFH6QZq2uThZIIKTFP40gdxAbgxlAsZlTGABOMxS1LMZSySAAOSQhCk7hZPkxTSGU4ZZIUEANlIfSFPE0g4FgJA0F/f9yEoGLvD/GophEYBOGVThSCoP8i2IQKIGcAzZOcOwsjeKTdNIGLnnoAB5WhWAqsLSCwbdRHYYrWrwYhijUa9ApailihdEYqt1ZRKtk1g8GcYhyr0LAppC04jCm3oaHoJg2A4Hh%2BEEYRRBQNSZCEWbAsgXpUAQwJBoAWjqsYZju5ZYwkGQ5EkDZnqoWhUDu69VBIKsfr%2Bu6D2IfRWDu4DrqfO7fv%2Bikhhu9EAqKEoNAgKxGlMLKrEqOIEkECIAjoXGSb8MnaEJ6pEkKVJSlaCmspSPqmfKWnOnplpyhZupOfaImul6DSBiGLgJKkmS5K6vzyWcjw7o8bhAUO4AlU4UCNlAzgI1wQgSDmHTUR/JL/2NyzrVUj6ZD04qjJMsZzMkUszNLMxrI2MxnIc653OGTzZZavyAqCkKHYimBEBQVBYrceKYTj82UvVjKNiynLWDygqipa0raHK5aaq0AgGqarq2rSzqWvwXqSgGrrhuQUblomySWpmuaFowEYfJOPA1uGXSNroRgWE6vaBDc9Xjtt%2BQu4u5jfNR0kpIep6XoIdA3pO6QvtB/7AaIU4vQRsGIahmHUDhw%2B7uRzBV4UdHGaxnH9DyQQCaFunKciQJ%2BakzSFzYmrMMZpDKA0D%2BoQwGv3SK0EBXQBZQJCHjZBbRYi/04KLTSEtsEBxlt5JSUkFZKxVmrNKmtta631vgE%2BlssrfmTslbE4xJDWz3vbMKjsQDXFAu7VU3AHKK0kNZaypYZ4eS8nLKSYdgqhUMlLYYkhpEh1kRHbhvRrz5UCKZIAA%3D">the generated assembly</a>:<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre><code data-lang="asm"><span>printUpperCase</span>(<span>char</span> <span>const</span>*):                  <span># @printUpperCase(char const*)
</span><span></span>        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
        <span>callq</span>   <span>strlen</span>
        <span>leaq</span>    <span>1</span>(%rax), %rdi
        <span>cmpq</span>    <span>$1024</span>, %rax                     <span># imm = 0x400
</span><span></span>        <span>ja</span>      <span>.LBB0_2</span>
        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
.LBB0_2:
        <span>callq</span>   <span>operator</span> <span>new</span>[](<span>unsigned</span> <span>long</span>)
        <span>movq</span>    %rax, %rbx
        <span>movq</span>    %rax, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %rbx, %rdi
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>jmp</span>     <span>operator</span> <span>delete</span>[](<span>void</span>*)                          <span># TAILCALL
</span></code></pre></div><p>Our function prologue has gotten a lot longer, and we have some new
control flow instructions as well. Let’s take a closer look at the
prologue:</p><div><pre><code data-lang="asm">        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
</code></pre></div><p>The <code>pushq %rbp; movq %rsp, %rbp</code> sequence is very common: it pushes
the <a href="https://en.wikipedia.org/wiki/Call_stack#FRAME-POINTER">frame
pointer</a>
stored in <code>%rbp</code> to the stack and saves the old stack pointer
(which is the new frame pointer) in <code>%rbp</code>. The following four
<code>pushq</code> instructions store registers that <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI">we need to save before
using</a>.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>
Finally, we save our first argument (<code>%rdi</code>) in <code>%r14</code>.</p><p>On to the function body. We call <code>strlen(s)</code> with <code>callq strlen</code> and
store <code>sSize + 1</code> in <code>%rdi</code> with <code>lea 1(%rax), %rdi</code>.</p><p>Next, we finally see our first <code>if</code> statement! <code>cmpq $1024, %rax</code> sets
the <a href="https://en.wikipedia.org/wiki/FLAGS_register">flags register</a>
according to the result of <code>%rax - $1024</code>, and then <code>ja .LBB0_2</code>
(“jump if above”) transfers control to the location labeled <code>.LBB0_2</code>
if the flags indicate that <code>%rax &gt; 1024</code>. In general, higher-level
control-flow primitives like <code>if</code>/<code>else</code> statements and loops are
implemented in assembly using conditional jump instructions.</p><p>Let’s first look at the path where <code>%rax &lt;= 1024</code> and thus the branch
to <code>.LBB0_2</code> was not taken. We have a blob of instructions to create
<code>char temp[sSize + 1]</code> on the stack:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
</code></pre></div><p>We save <code>%rsp</code> to <code>%r15</code> and <code>%rbx</code> for later
use.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> Then, we add 15 to <code>%rdi</code> (which,
remember, contains the size of our array), mask off the lower 4 bits
with <code>andq $-16, %rdi</code>, and subtract the result from <code>%rbx</code>, which we
then put back into <code>%rsp</code>. In short, this rounds the array size up to
the next multiple of 16 bytes and makes space for it on the stack.</p><p>The following block simply calls <code>copyUppercase</code> and <code>puts</code> as written in the code:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
</code></pre></div><p>Finally, we have our function epilogue:</p><div><pre><code data-lang="asm">        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
</code></pre></div><p>We restore the stack pointer to deallocate our variable-length array
using <code>leaq</code>. Then, we <code>popq</code> the registers we saved during the
function prologue and return control to our caller, and we are done.</p><p>Next, let’s look at the path when <code>%rax &gt; 1024</code> and we branch to
<code>.LBB0_2</code>. This …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolchok.org/posts/how-to-read-assembly-language/">https://wolchok.org/posts/how-to-read-assembly-language/</a></em></p>]]>
            </description>
            <link>https://wolchok.org/posts/how-to-read-assembly-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282634</guid>
            <pubDate>Sat, 27 Feb 2021 04:40:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Greenwashing? Learn to Spot Truly Sustainable Brands]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26282619">thread link</a>) | @jradhughes
<br/>
February 26, 2021 | https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands | <a href="https://web.archive.org/web/*/https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><span>Greenwashing is when a company pretends to be </span><b>eco-friendly</b><span> despite using toxic ingredients and unsustainable practices to manufacture their product.&nbsp;</span></p>
<p><span>When a company engages in </span><i><span>greenwashing</span></i><span>, they effectively influence consumers to believe that they’re working towards saving the environment when they’re not. In fact, companies that go to great lengths to create a </span><b>greenwashed marketing strategy</b><span> are sometimes covering up their lack of </span>environmentally friendly products or processes<span>. They are interested only in improving their sales and making more money, and they do so by projecting a green image and deceiving </span><b>conscious consumers</b><span>.&nbsp;</span></p>
<p>It should be noted that some companies greenwash their products accidentally. Misinformation surrounding sustainability is so widespread that companies can get the wrong idea about what's sustainable and what's not. Although there's no excuse for large corporations with hefty research budgets, smaller companies sometimes think they're being eco-friendly when they're not.&nbsp;</p>
<h2><b>Why do companies use this marketing strategy?</b></h2>
<p><span>The short answer is that companies who deliberately use this strategy do so to attract more customers and increase revenue.</span><span><br></span><span><br></span><span>Over the past couple of decades, there has been a shift toward holding companies accountable for their carbon footprint and environmental impact. At the same time, consumers have become more conscious of their impact on the environment. Naturally, conscious customers try their best to buy </span><b>environmentally friendly products</b><span> when possible.&nbsp;</span></p>
<p><span>There isn’t currently a lot of regulation around sustainable terms such as: natural, green, eco-friendly, and environmentally friendly. Any company can include green colors and imagery on their products and use terms such as </span><i><span>natural</span></i><span>. Therefore, it’s usually easy for brands to attract well-meaning consumers and improve their sales. </span><span><br></span><span><br></span><span>Another reason for companies using this marketing strategy is to stand out from their competitors in the market. They promise the consumers that their product is more efficient, saves more power, or is </span><b>sustainable</b><span>. In response, many people start purchasing from them believing that they are helping the environment.&nbsp;</span></p>
<p><span>Many companies see this </span><i><span>green agenda</span></i><span> as an opportunity to gain a competitive advantage, especially because “natural products” are usually priced higher.&nbsp;Particularly when shopping on-the-go at the grocery store or mall, consumers don’t have time to research every single product they put into their cart. And with good reason! Unless you only buy from trusted brands, it’s hard to distinguish between the truly sustainable products and the fake ones.&nbsp;</span></p>
<p><b>Examples of Greenwashing</b><b><br></b><span><br></span><span>A very common example of greenwashing is when a company rebrands as natural or eco-friendly. If a company changes their name, logo, or slogan to appear greener without actually changing their business to be environmentally friendly, then chances are it's an attempt to greenwash. Food companies, cosmetic companies, and household product manufacturers are often seen involved in greenwashing. &nbsp;</span><span><br></span><span><br></span><span>Another example of greenwashing is when a company labels its products with buzz-words and meaningless statistics.&nbsp;</span></p>
<p><span>Have you ever seen one or more of the the following descriptions on a product?<br></span></p>
<ul>
<li><span>"99% naturally derived"&nbsp;</span></li>
<li><span><span>"100% recyclable"</span></span></li>
<li><span><span><span>"Made with natural ingredients"&nbsp;&nbsp;</span></span></span></li>
<li><span><span><span><span>"Biodegradable"&nbsp;</span></span></span></span></li>
</ul>
<p>While these things all sound great to the conscious consumer, these phrases don't mean anything.</p>
<p>Single-use plastic can be 100% recyclable, but it isn't sustainable or eco-friendly. Many chemicals are naturally-derived, yet are still harmful to the environment. Food, cosmetics, textiles, and more can all be made with "natural" ingredients, but that doesn't necessarily mean they're inherently healthy or environmentally friendly. Lastly, most things are biodegradable, but that doesn't mean it's okay to dump them in a landfill.</p>

<h2><b>Impact of Greenwashing</b></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/pexels-catherine-sheila-2409025_480x480.jpg?v=1613572719" alt="false green claims"></p>
<p><b></b><span>Greenwashing is unethical.&nbsp;False green claims have&nbsp;a negative impact not only on consumers but also on the environment. Let’s look at some of the problems that arise because of greenwashing.&nbsp;</span></p>
<p><b>Encourages Uninformed Decisions</b> <b><br></b><b><br></b><span>The most important danger of greenwashing is that it misinforms people, leading them to make wrong decisions and contribute to unintended environmental harm. Customers, without knowing if a company’s eco-friendly claims are genuine or not, act unsustainably, and make an uninformed decision. </span><span><br></span><span><br></span><b>Harms the Environment</b></p>
<p><a href="https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.118-a246"><span>Greenwashing harms the environment and public health</span></a><span>. When consumers are unable to understand the false practices of a company and they decide to buy from a greenwashing company, they contribute to the growth of that company.</span></p>
<p><span>Their support gives such companies more revenue and they continue with their greenwashed marketing and non-environmentally friendly products. Many companies that use greenwashing are often found to be using toxic ingredients in their products or using unsustainable practices such as excess water usage, causing unnecessary air pollution,&nbsp;or producing toxic run-off. To stop this, consumers should look into what they are buying and support the company only if they are genuinely working towards protecting the environment.&nbsp;&nbsp;</span></p>
<p><b>Harms Genuine Brands</b><b><br></b><b><br></b><span>Apart from harming the environment, greenwashing also causes trouble for companies that are genuinely working towards saving the environment. This happens because greenwashing breaks consumer trust and consumers start suspecting </span><i><span>all</span></i><span> brands</span><b>, </b><span>even those that are working hard to produce </span><b>environmentally friendly products</b><span>. The reputation of true eco-friendly companies are hindered, making it difficult for them to gain significant market share.&nbsp;</span></p>

<h2><b>How to Identify Greenwashing&nbsp;</b></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/Webp.net-resizeimage_3_480x480.jpg?v=1613572793" alt="greenwashed" width="480x480" height="480x480"></p>
<p><span>Unfortunately, it can be hard to know if a company is greenwashing or not.&nbsp;It is important for consumers to be educated and aware about which companies and products are truly green and which are not, but this takes time and a lot of effort.&nbsp;</span></p>
<p><span>However, there are some things you can look out for that might help you make more informed decisions. Here are a few tips:</span></p>
<ul>
<li><span>Many companies use specific phrases like natural, sustainable, organic, healthy, vegan, etc. to attract consumers. The use of such words gives the impression that they are eco-friendly and green. However, be skeptical. You should read the information provided by the company on the packaging material, label, and website. The only way to know about the product is to read the label carefully.&nbsp;</span></li>
<ul>
<li>
<span>You should know what common products are inherently not eco-friendly: PVC, triclosan, microbeads, aerosols, phosphates, and chlorine bleach are just a few toxic materials that companies use while still marketing themselves as safe and natural. </span><span></span>
</li>
</ul>
<li>
<span>Product imagery that depicts natural scenery is also a tool used by many companies to deceive potential buyers. Consumers should be aware not to be fooled by pictures of fruit, nuts, farms, or any other natural-looking imagery on the labels of the product. Using a particular image does not represent the true sustainability of a company’s products.</span><span></span>
</li>
<li>
<span>Besides using earth-centered imagery, companies also using earthy tones to promote a natural vibe. They use greens, browns, and blues instead of bright and flashy colors while packaging their products. This is to lure the consumers who are drawn to earth-friendly products. However, consumers should remember that greens and browns don’t necessarily imply that the product is earth-friendly.</span><span><br></span><span>&nbsp;&nbsp;</span>
</li>
</ul>

<h2><b>Ways to Verify Sustainable Brands&nbsp;</b></h2>
<p><b><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/MG_1114_copy_480x480.jpg?v=1613568843" alt="what is greenwashing"></b></p>
<p><span>These days, the number of environmentally-conscious buyers is growing.&nbsp;</span></p>
<p><span>If you find it hard to obtain information about a company’s factory or production details, there's a chance&nbsp;that the company is greenwashing or it has something to hide.To verify the sustainability of a brand,&nbsp;you&nbsp;should try to find out more and more about the way a company operates. <p>Here are some things you can look out for:</p></span></p>
<ul>
<li><span>Don't trust everything that a company shares or says if they don't have evidence to back it up. There is a possibility that the company is sugar-coating their information or spinning the truth.&nbsp;</span></li>
<li><span>Try to find out about the company’s supply chain, their production facilities, the employees, working conditions, contractors, etc.&nbsp;</span></li>
<li><span>Evaluate the logistics of the product. If a company is claiming they're sustainable, but they're still using single-use plastics...you know something is off.&nbsp;Look for the trademarks of true sustainability such as zero waste practices and/or materials.</span></li>
<li><span>For textiles and household goods, check the material and quality of the product. For food and cosmetic products, check the ingredients and learn more about the production processes of common ingredients. For example, "palm oil" sounds relatively unproblematic, but is actually one of the <a href="https://www.wwf.org.uk/updates/8-things-know-about-palm-oil">greatest&nbsp;drivers of deforestation</a>.&nbsp;</span></li>
<li>Ask tough questions! Even true eco-friendly companies are not perfect, but they'll be happy to answer your questions and show you how they're willing to improve.</li>
</ul>
<p><span>If you really want to avoid giving business to companies who are&nbsp;intentionally greenwashing, you'll need to screen your purchases carefully. Keep an eye out for harmful ingredients, materials, and production practices. When you're informed, you can spot fake eco-friendly companies much more easily.&nbsp;<br></span></p>
<p><span>Continue to read labels and always think about the entire product lifecycle - all the way from the sourcing of materials all the way down to&nbsp;discarding, recycling, or reusing the product.</span></p>
<p><span>Greenwashing needs to be stopped and we need to hold companies accountable. Let’s continue to do our part by becoming conscious consumers and buying environment friendly products.</span></p>
<p><span>To learn more about our sustainability efforts here at&nbsp;</span><b>LaFlore Paris</b><span>, please read our <a href="https://lafloreparis.com/pages/our-promise-to-you-eco-friendly-purses">Eco-Friendly Promise</a>. Please feel free to contact us at any time if you have more questions. We'd be happy to hear from you!&nbsp;</span></p>
<p><strong><br><a href="https://lafloreparis.com/products/convertible-backpack-purse"><span>Shop Our Eco-Friendly Convertible Backpack Purse</span></a></strong></p>
    </div></div>]]>
            </description>
            <link>https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282619</guid>
            <pubDate>Sat, 27 Feb 2021 04:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining Ethereum on M1 Mac GPU]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281864">thread link</a>) | @gyf304
<br/>
February 26, 2021 | https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/ | <a href="https://web.archive.org/web/*/https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-444">

	

	
	<div>
		
<p>TL;DR: It’s possible to mine Ethereum on a M1 Mac GPU. Hashrate is about 2Mh/s.</p>



<figure><img data-attachment-id="452" data-permalink="https://blog.yifangu.com/image-1-5/" data-orig-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png" data-orig-size="1338,754" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300" data-large-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=750" src="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024" alt="" srcset="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024 1024w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=150 150w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300 300w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=768 768w, https://yifangucom.files.wordpress.com/2021/02/image-1.png 1338w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Mining on a M1 Mac</figcaption></figure>



<p>I’ve had my M1 MacBook Air for a bit of time now, and I also recently started mining Ethereum. I can’t help asking myself: What’s Ethereum mining performance like on a M1 Mac?</p>



<p>The obvious thing to do first is to run the off-the-shelf <code>ethminer</code>, which gives the following error:</p>



<pre><code>ethminer 0.19.0-alpha.0
Build: darwin/release/appleclang

Unrecognized platform Apple
Error: No usable mining devices found</code></pre>



<p>Not good. Apparently Apple GPUs are not whitelisted in ethminer. That should be easy to fix. Relevant lines are in <code>libethash-cl/CLMiner.cpp</code>, and I added Apple GPUs to the whitelist, pretending it’s an Intel GPU.</p>



<p>Then <code>boost</code> won’t compile since it’s trying to compile with a <code>-fcoalesce-templates</code> argument, which doesn’t exist in recent clang versions. So I have to update <code>boost</code> to the latest version, and fix relevant <code>asio</code> code since <code>ethminer</code> was using deprecated <code>asio</code> APIs.</p>



<p>I also need to upgrade OpenSSL to the latest version to have it support darwin + arm64.</p>



<p>After getting everything to compile. Here’s the result:</p>



<pre><code>ethminer 0.19.0-17+commit.ce52c740.dirty
Build: darwin/release/appleclang

 i 19:51:36          Configured pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Selected pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Connection remotely closed by eth-us-east1.nanopool.org
 i 19:51:36          Stratum mode : EthereumStratum/1.0.0 (NiceHash)
 i 19:51:36          Established connection to eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:51:36          Spinning up miners...
cl 19:51:36 cl-0     Using Device : Intel GPU 0.0 Apple M1 OpenCL 1.2  Memory : 10.67 GB (11453251584 B)
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Authorized worker [REDACTED]
 i 19:51:36          Epoch : 397 Difficulty : 10.00 Gh
 i 19:51:36          Job: c7fc5311… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     Generating split DAG + Light (total): 4.10 GB
 i 19:51:38          Job: 40a57756… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     OpenCL kernel
cl 19:51:38 cl-0     Creating DAG buffer, size: 4.10 GB, free: 6.57 GB
cl 19:51:38 cl-0     Creating light cache buffer, size: 65.62 MB
cl 19:51:38 cl-0     Loading kernels
cl 19:51:38 cl-0     Creating buffer for header.
cl 19:51:38 cl-0     Creating mining buffer
 m 19:51:41          0:00 A0 0.00 h - cl0 0.00
 i 19:51:42          Job: 077b62f6… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:46          0:00 A0 0.00 h - cl0 0.00
 i 19:51:46          Job: 2835839e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:51          0:00 A0 0.00 h - cl0 0.00
 m 19:51:56          0:00 A0 0.00 h - cl0 0.00
 i 19:51:57          Job: 97f724e7… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:01          0:00 A0 0.00 h - cl0 0.00
 m 19:52:06          0:00 A0 0.00 h - cl0 0.00
 m 19:52:11          0:00 A0 0.00 h - cl0 0.00
 m 19:52:16          0:00 A0 0.00 h - cl0 0.00
 i 19:52:16          Job: 54df0504… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:21          0:00 A0 0.00 h - cl0 0.00
cl 19:52:22 cl-0     4.10 GB of DAG data generated in 44,060 ms.
 m 19:52:26          0:00 A0 184.16 Kh - cl0 184.16
 m 19:52:31          0:00 A0 1.96 Mh - cl0 1.96
 m 19:52:36          0:01 A0 1.98 Mh - cl0 1.98
 i 19:52:39          Job: d3b1da5e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:41          0:01 A0 1.99 Mh - cl0 1.99
cl 19:52:43 cl-0     Job: 54df0504… Sol: 0x778d000001d14c71
 i 19:52:43          **Accepted 150 ms. eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:46          0:01 A1 1.95 Mh - cl0 1.95
 m 19:52:51          0:01 A1 2.07 Mh - cl0 2.07
 m 19:52:56          0:01 A1 2.00 Mh - cl0 2.00
 m 19:53:01          0:01 A1 1.98 Mh - cl0 1.98
 i 19:53:01          Job: ccc2b97f… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:53:06          0:01 A1 1.97 Mh - cl0 1.97
 i 19:53:07          Job: 23919d82… eth-us-east1.nanopool.org [144.217.14.139:9999]
^C i 19:53:10 main     Got interrupt ...
 i 19:53:10 main     Disconnected from eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:53:10 main     Shutting down miners...
 i 19:53:16 main     Terminated!</code></pre>



<p>Code is available at <a rel="noreferrer noopener" href="https://github.com/gyf304/ethminer-m1" target="_blank">https://github.com/gyf304/ethminer-m1</a></p>



<h2>Is it worth it?</h2>



<p>Um. Not really. At current Ethereum prices (2021-02-26), it generates $0.14 of profit per day. It’s still a profit, but very miniscule.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281864</guid>
            <pubDate>Sat, 27 Feb 2021 01:32:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RepoDash: Performance Metrics for GitHub Repositories]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281676">thread link</a>) | @gilad
<br/>
February 26, 2021 | https://laurencemolloy.github.io/RepoDash/ | <a href="https://web.archive.org/web/*/https://laurencemolloy.github.io/RepoDash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
          <p>Performance metrics for Github repositories</p>
        
        <p><a href="https://github.com/LaurenceMolloy/RepoDash">View the Project on GitHub <small></small></a></p>
        <ul>
        
          <li><a href="https://github.com/LaurenceMolloy/RepoDash"><strong>View On GitHub</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash"><strong>About</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash/docs/userguide"><strong>User<br>Guide</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash/docs/technical"><strong>Technical<br>Docs</strong></a></li>
        </ul>
      </header>
      <section>

      <p><img src="https://laurencemolloy.github.io/RepoDash/docs/images/RepoDash_screenshot.png" alt="Screenshot"></p>

<p>See our <a href="https://laurencemolloy.github.io/RepoDash/"><strong>github.io pages</strong></a> 
for detailed instructions on how to use RepoDash.</p>



<p>Do you maintain a project codebase on Github? Would you like to be able to collate statistics 
that summarise historic monthly activity on that codebase and see, at a glance, how that impacts 
the project issues list over time? Would you like to be able to perform this analysis for any 
given time period of your choosing?</p>

<p>RepoDash can do just this. It uses the Github API to collect repository data and generate a 
data visualisation of a range of historic metrics of the project issues list over a user-specified 
period of time. For each calendar month in the time period of interest, it displays the following 
metrics:</p>

<ul>
<li>The number of new issues created</li>
<li>How many of these issues are still open at the time of generating the dashboard</li>
<li>How many of these issues still require triage (labelling) at the time of generating the dashboard</li>
<li>The number of existing issues resolved</li>
<li>The percentage split between opened / closed issues</li>
<li>The aggregate number of open issues in the issues list (month start &amp; month end)</li>
<li>The aggregate number of open issues in the issues list requiring triage (month start &amp; month end)</li>
<li>The change in total number of open issues over the month</li>
<li>The average age and age spread of open issues in the isssues list</li>
</ul>


<p>It also displays aggregate counts for the most frequently used labels for all issues that remained open
at the end of the displayed time period.</p>

<h3>Typical Use Cases</h3>

<p>Perhaps you are managing an open source project, the maintenance of which you'd like to keep on top 
of. Or perhaps you manage a software product at work where you are required to provide your boss with 
exective summary updates of your support team's progress on an ongoing monthly basis. Either way, if 
your codebase is managed via Github, RepoDash could be just what you need.</p>

<h3>Demo Mode</h3>

<p>For demo purposes, this code processes the first 10 pages of the matplotlib<sup>1</sup> project and 
displays the most recent 12 months of metrics by default. Command line arguments allow you to set your
own project repository and analysis timeframe. It couldn't be simpler.</p>

<p><sup>1</sup> <em><a href="https://matplotlib.org/"><strong>matplotlib</strong></a> is a popular open science 
plotting library for python which is utilised by RepoDash to generate its data visualisations</em></p>

<h3>Future Development</h3>

<p>This project is a work in progress. The current version of RepoDash has only been tested with open 
source (public) projects. However, there are plans to ensure that it works with private ones as well. 
Over time, we also plan to build on the range of metrics offered and make it easy for the user to select 
which metrics to display... watch this space!</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://laurencemolloy.github.io/RepoDash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281676</guid>
            <pubDate>Sat, 27 Feb 2021 01:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting brain activity with Neural Nets and TensorFlow is easy(-ish)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281492">thread link</a>) | @pizza
<br/>
February 26, 2021 | https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html | <a href="https://web.archive.org/web/*/https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        
        <time datetime="2020-12-13T02:28:37+00:00">December 13, 2020</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
          
        
        <p>Over-fitting is a lie.</p>

<h2 id="backgroud">Backgroud</h2>

<p>I <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/2020/07/31/decoding_visual_experience.html">previously talked about</a> predicting and decoding brain activity as recorded using fMRI. In that post I followed the tried and true approach of (1) extracting some features from the stimulus and (2) fitting a regularised linear regression from the features to brain activity. It works really well.</p>

<p>One of the reasons we use linear regression in these type of “encoding” studies is that there is not much data. For example in that study the training set had only about 7200 samples (which is quite a lot by fMRI community standards). The traditional thinking is that very rich models, such as deep neural nets (NNs) with millions of parameters, will disastrously over-fit in this type of situation, resulting in low performance. However, this traditional thinking may be out of date.</p>

<p>A <a href="https://www.biorxiv.org/content/10.1101/2020.09.11.293878v1">recent paper uploaded to bioarxiv</a> generated some discussion in our lab. It is a very thorough study looking at predicting brain activity using deep NNs with many interesting results. Among these results, the authors show that replacing the linear regression with a NN provides a substantial improvement over linear regression (see also <a href="https://www.frontiersin.org/articles/10.3389/fncom.2019.00021/full">here</a>).</p>

<p>I think is pretty likely that with some effort and a lot of NN know-how an expert can improve on the performance of a linear model. But I figured that avoiding over-fitting in this situation is going to be really hard, and that an out of the box implementation would perform disastrously. So I thought I’d give it a go.</p>

<p>In this post I go through fitting a simple NN, though still with millions of parameters, to predict brain activity. I’ll use a vanilla NN paired with the same data I analyzed in my previous post. This way we will have a direct comparison with the linear model. A full notebook to reproduce this is up on my <a href="https://github.com/drorcohengithub/Prediciting_BOLD_with_TensorFlow">github</a>.</p>

<h2 id="preparations">Preparations</h2>

<p>We will use the same data from last time. For convenience I put everything you’ll need <a href="https://figshare.com/s/9803543b6736009e7a83">here</a>.</p>

<div><div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>"font.size"</span><span>]</span> <span>=</span> <span>"20"</span>

<span>import</span> <span>tensorflow</span> <span>as</span> <span>tf</span>
<span>from</span> <span>tensorflow</span> <span>import</span> <span>keras</span>
<span>from</span> <span>tensorflow.keras</span> <span>import</span> <span>layers</span>
<span>from</span> <span>tensorflow.keras.callbacks</span> <span>import</span> <span>Callback</span>
<span>from</span> <span>tensorflow.keras</span> <span>import</span> <span>backend</span> <span>as</span> <span>K</span>
</code></pre></div></div>

<div><div><pre><code><span>#load the preproc data from before
</span><span>with</span> <span>np</span><span>.</span><span>load</span><span>(</span><span>"./data.npz"</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>print</span><span>(</span><span>f</span><span>.</span><span>files</span><span>)</span>
    <span>voxel_test_data</span> <span>=</span> <span>f</span><span>[</span><span>"voxel_test_data"</span><span>]</span>
    <span>voxel_train_data</span> <span>=</span> <span>f</span><span>[</span><span>"voxel_train_data"</span><span>]</span>
    <span>ME_features_train_data</span> <span>=</span> <span>f</span><span>[</span><span>"ME_features_train_data"</span><span>]</span>
    <span>ME_features_test_data</span> <span>=</span> <span>f</span><span>[</span><span>"ME_features_test_data"</span><span>]</span>
    <span>linear_model_acc</span> <span>=</span> <span>f</span><span>[</span><span>"linear_model_acc"</span><span>]</span>
</code></pre></div></div>

<ul>
  <li><strong>voxel_train_data</strong> this is the brain activity data we will use to train the model</li>
  <li><strong>voxel_test_data</strong> this is the brain activity data we will use in the final test of the model</li>
  <li><strong>ME_features_train_data</strong> this is the ME feature data we will use to train the model. The feature vector consists of stacking together four consecutive delays (t-3 to t-6, see the <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/2020/07/31/decoding_visual_experience.html">original post</a> for details)</li>
  <li><strong>ME_features_test_data</strong> this is the ME feature data we will use in the final test of the model</li>
  <li><strong>linear_model_acc</strong> this is the accuracy data for the linear model. This is calculated as the pearsons correlation between the model predictions and the test data (i.e. voxel_test_data)</li>
</ul>

<p>I restrict the analysis to the 2000 voxels that were best predicted using the linear model. This is a bit harsh on our NN here because it is possible that the NN improves on voxels that the linear model was poor at predicting, so keep that in mind.</p>

<div><div><pre><code><span>feature_dim</span> <span>=</span> <span>ME_features_train_data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
<span>num_voxels</span> <span>=</span> <span>voxel_train_data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
</code></pre></div></div>

<h2 id="the-network">The network</h2>

<p>We first need to decide on the structure of the network. There is now a whole zoo of network architectures and I think it is pretty likely that many of them are superior to the linear model. However, the point here to see how well an “out of the box” NN works. Nothing is more vanilla than a tutorial, so I will use the architecture from the <a href="https://www.tensorflow.org/tutorials/keras/regression">TensorFlow regression tutorial</a>. The architecture has two hidden, densely connected layers with relu activations. We will be fitting a mere 1,812,304 parameters.</p>

<p>There really is no reason to think that this architecture is suited to our specific problem. But if something like this <em>does</em> work, then it may not be so difficult to come up with a NN that is superior to the linear model.</p>

<p>To the model.</p>

<div><div><pre><code><span># repeatable intialization of the weights
</span><span>initializer</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>initializers</span><span>.</span><span>GlorotNormal</span><span>(</span><span>seed</span><span>=</span><span>1</span><span>)</span>

<span>vanilla</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span>
    <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Input</span><span>(</span><span>shape</span><span>=</span><span>[</span><span>feature_dim</span><span>]),</span>
    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span><span>kernel_initializer</span><span>=</span><span>initializer</span><span>),</span> <span># set the initial weights
</span>    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span><span>kernel_initializer</span><span>=</span><span>initializer</span><span>),</span>
    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>num_voxels</span><span>)</span>
<span>])</span>
<span>vanilla</span><span>.</span><span>summary</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 64)                1678144   
_________________________________________________________________
dense_7 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_8 (Dense)              (None, 2000)              130000    
=================================================================
Total params: 1,812,304
Trainable params: 1,812,304
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div><div><pre><code><span>keras</span><span>.</span><span>utils</span><span>.</span><span>plot_model</span><span>(</span><span>vanilla</span><span>,</span> <span>show_shapes</span><span>=</span><span>True</span><span>,</span><span>to_file</span><span>=</span><span>'vanilla.png'</span><span>)</span>
</code></pre></div></div>

<figure>
  <img src="https://drorcohengithub.github.io/website/assets/images/vanilla.png" alt=""><figcaption>
      Model structure

    </figcaption></figure>

<h3 id="the-optimizer">The optimizer</h3>

<p>The next thing is to choose an optimizer for the network. The tutorial used ADAM with a hardwired learning rate, but I went with a simple weight decay approach. Standard stuff, though I did manually tweak it a bit. A more principled approach is to optimize this using cross validation or something but for simplicity I’ll keep this as is.</p>

<div><div><pre><code><span># initial learning rate
</span><span>initial_learning_rate</span> <span>=</span> <span>0.0001</span>
<span>#expontential decay
</span><span>lr_schedule</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>schedules</span><span>.</span><span>ExponentialDecay</span><span>(</span>
<span>initial_learning_rate</span><span>,</span>
<span>decay_steps</span><span>=</span><span>1000</span><span>,</span>
<span>decay_rate</span><span>=</span><span>0.8</span><span>)</span>
</code></pre></div></div>

<h3 id="compile">Compile</h3>
<p>Put it all together</p>

<div><div><pre><code><span># optimize mean squared error
</span><span>vanilla</span><span>.</span><span>compile</span><span>(</span>
    <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr_schedule</span><span>),</span><span>#
</span>    <span>loss</span><span>=</span><span>'mean_squared_error'</span><span>,</span>
    <span>metrics</span><span>=</span><span>[</span><span>"mean_squared_error"</span><span>])</span>
</code></pre></div></div>

<h3 id="custom-callback-to-monitor-things">Custom callback to monitor things</h3>

<p>As I mentioned, the performance of the model is assess as the correlation between the predicted and actual response (more on this later). This will quickly evaluate our model performance</p>

<div><div><pre><code><span>zs</span> <span>=</span> <span>lambda</span> <span>v</span><span>,</span><span>dim</span><span>=</span><span>0</span><span>:</span> <span>(</span><span>v</span><span>-</span><span>v</span><span>.</span><span>mean</span><span>(</span><span>dim</span><span>,</span><span>keepdims</span><span>=</span><span>True</span><span>))</span><span>/</span><span>v</span><span>.</span><span>std</span><span>(</span><span>dim</span><span>,</span><span>keepdims</span><span>=</span><span>True</span><span>)</span>

<span>def</span> <span>respective_correlation</span><span>(</span><span>x</span><span>,</span><span>y</span><span>,</span><span>dim</span><span>=</span><span>0</span><span>):</span>

    <span>"""
        shape is samps by vars/featurs   
    """</span>  

    <span>num_samps</span> <span>=</span> <span>x</span><span>.</span><span>shape</span><span>[</span><span>dim</span><span>]</span>
    <span>if</span> <span>not</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>x</span><span>.</span><span>shape</span><span>,</span> <span>y</span><span>.</span><span>shape</span><span>):</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'x and y must have same shape'</span><span>)</span>

    <span>corrs</span> <span>=</span> <span>(</span><span>zs</span><span>(</span><span>x</span><span>,</span><span>dim</span><span>)</span> <span>*</span> <span>zs</span><span>(</span><span>y</span><span>,</span><span>dim</span><span>)).</span><span>mean</span><span>(</span><span>dim</span><span>)</span>

    <span>return</span> <span>corrs</span>
</code></pre></div></div>

<div><div><pre><code><span># We create a custom call back to report on how things are progressing in the end of each epoch
</span><span>class</span> <span>CustomCallback</span><span>(</span><span>Callback</span><span>):</span>

    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>val_data</span><span>):</span> <span># this gives us access to the validation data (see https://github.com/keras-team/keras/issues/10472 )
</span>        <span>super</span><span>().</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>validation_data</span> <span>=</span> <span>val_data</span>

    <span>def</span> <span>on_epoch_end</span><span>(</span><span>self</span><span>,</span> <span>epoch</span><span>,</span> <span>logs</span><span>=</span><span>{}):</span> <span># on the end of each training epoch get
</span>
        <span># the current learning rate
</span>        <span>current_lr</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>optimizer</span><span>.</span><span>_decayed_lr</span><span>(</span><span>'float32'</span><span>).</span><span>numpy</span><span>()</span>

        <span># the correlation between the predicted and actual response
</span>        <span>for</span> <span>val</span> <span>in</span> <span>val_dataset</span><span>:</span> <span># calculate correlation on the validation data
</span>            <span>mdl_pred</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>predict</span><span>(</span><span>val</span><span>[</span><span>0</span><span>])</span>        
            <span>val_corr</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>respective_correlation</span><span>(</span><span>mdl_pred</span><span>,</span> <span>val</span><span>[</span><span>1</span><span>].</span><span>numpy</span><span>()))</span>

        <span># add it to the logs (not sure if this is the correct way to do it but it works)
</span>        <span>logs</span><span>[</span><span>"val_corr"</span><span>]</span> <span>=</span> <span>val_corr</span>
        <span>print</span><span>(</span><span>f</span><span>"current lr </span><span>{</span><span>current_lr</span><span>:.</span><span>2</span><span>E</span><span>}</span><span> corr </span><span>{</span><span>val_corr</span><span>:.</span><span>03</span><span>f</span><span>}</span><span>,</span><span>\
</span><span>        MSE </span><span>{</span><span>logs</span><span>[</span><span>'val_mean_squared_error'</span><span>]:.</span><span>06</span><span>f</span><span>}</span><span>"</span><span>)</span> <span>#, loss {logs['val_loss']:.06f}
</span></code></pre></div></div>

<h2 id="prepare-the-training-and-validation-data">Prepare the training and validation data</h2>

<p>I will keep some data aside for validation as we train the model. The key thing to remember here is that we are using time series data. This means that the data is not iid. If we just grabbed samples randomly for validation then there is a good chance that dependent samples will be in the training set. For example, we may end up with sample at t=n in the val set but t=n-1 in the training set. These are dependent, and in fact likely to be quite similar. In this case performance on the validation test will reflect something of double dipping and probably be much higher than what we get on the final test set.</p>

<p>I will very crudely grab three chunks of 200 samples at intervals of 2000, 4000 and 6000 samples. This is completely arbitrary and pretty poor practice. We did much better on the ridge regression in the previous post, but I think it is good enough for illustration. Note that we might have a bit of leakage (since the samples around these chunks are still in the training set), but I think it is not too much of a worry.</p>

<div><div><pre><code><span>all_data_inds</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>ME_features_train_data</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span>
<span>#keep the first, take three, chunk_len samples long chunks for validation
</span><span>chunk_len</span> <span>=</span> <span>200</span>
<span>chunk_starts</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>2</span><span>,</span><span>4</span><span>,</span><span>6</span><span>])</span><span>*</span><span>1000</span>
<span>chunk_ends</span> <span>=</span> <span>chunk_starts</span><span>+</span><span>chunk_len</span>
<span>val_inds</span> <span>=</span> <span>np</span><span>.</span><span>concatenate</span><span>([</span><span>np</span><span>.</span><span>arange</span><span>(</span><span>strt</span><span>,</span><span>stp</span><span>)</span> <span>for</span> <span>strt</span><span>,</span><span>stp</span> <span>in</span> <span>zip</span><span>(</span><span>chunk_starts</span><span>,</span><span>chunk_ends</span><span>)])</span>
<span>trn_inds</span> <span>=</span> <span>np</span><span>.</span><span>delete</span><span>(</span><span>all_data_inds</span><span>,</span><span>val_inds</span><span>)</span>
</code></pre></div></div>

<p>TensorFlow likes its data in a particular way. This is <em>really</em> irritating to me.</p>

<div><div><pre><code><span>train_dataset</span> <span>=</span> <span>tf</span><span>.</span><span>data</span><span>.</span><span>Dataset</span><span>.</span><span>from_tensor_slices</span><span>((</span><span>ME_features_train_data</span><span>[</span><span>trn_inds</span><span>,:],</span> <span>voxel_train_data</span><span>[</span><span>trn_inds</span><span>,:]))</span>
<span># organized in batches ofo 32 to update the gradients (I think this is default)
</span><span>train_dataset</span> <span>=</span> <span>train_dataset</span><span>.</span><span>batch</span><span>(</span><span>32</span><span>)</span>

<span># Prepare the validation dataset
</span><span>val_dataset</span> <span>=</span> <span>tf</span><span>.</span><span>data</span><span>.</span><span>Dataset</span><span>.</span><span>from_tensor_slices</span><span>((</span>…</code></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html">https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html</a></em></p>]]>
            </description>
            <link>https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281492</guid>
            <pubDate>Sat, 27 Feb 2021 00:31:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatcat is a new robot for your home]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281376">thread link</a>) | @zdw
<br/>
February 26, 2021 | https://jetpack.cl/your-next-robot-is-a-pet/ | <a href="https://web.archive.org/web/*/https://jetpack.cl/your-next-robot-is-a-pet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-764" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			
<p><strong>flatcat is a new robot</strong> <strong>for your home</strong></p>



<p>Jetpack Cognition Lab, a Berlin-based AI and robotics startup, today announced flatcat, a new consumer robot, to be launched in March 2021. flatcat is a firm and fluffy AI pet for the living room, that responds to touch and gravity, and has a playful life of its own.</p>



<figure><img loading="lazy" width="1800" height="1000" src="https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo.jpg" alt="" srcset="https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo.jpg 1800w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1000x556.jpg 1000w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-768x427.jpg 768w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1536x853.jpg 1536w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-500x278.jpg 500w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-800x444.jpg 800w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1280x711.jpg 1280w" sizes="(max-width: 1800px) 100vw, 1800px"></figure>



<p>flatcat invites to experience a new dimension of touch and motion. Cuddle with it, have a gentle romp, or just watch it do weird things on its own, to caress your soul. The robot feels everything exactly with cognitive sensorimotor loops based on ten years of developmental robotics research. flatcat has no face, no app, no cloud, full privacy. It is built around a 3D printed skeleton and is powered by Jetpack Cognition Lab‘s own electrical motor design.</p>



<p>The new product will be available on Kickstarter and selected outlets beginning March 3, 2021. Visit https://flatcat.berlin for more information.</p>



<p><strong>Links</strong><br><a href="https://flatcat.berlin/" target="_blank" rel="noreferrer noopener">https://flatcat.berlin</a></p>



<p><strong>About Jetpack Cognition Lab</strong><br>Established in 2019, Jetpack Cognition Lab is a Berlin-based AI and Robotics startup and innovation hub. Founded by Oswald Berthold and Matthias Kubisch, it specializes in science transfer and product research. The company’s bioinspired hardware and software design is built on the neuroscience and psychology of developmental learning.</p>








		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://jetpack.cl/your-next-robot-is-a-pet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281376</guid>
            <pubDate>Sat, 27 Feb 2021 00:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every thought about personal finance I've ever had, as concisely as possible]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281108">thread link</a>) | @aadillpickle
<br/>
February 26, 2021 | https://blog.aadilali.com/posts/personal-finance.html | <a href="https://web.archive.org/web/*/https://blog.aadilali.com/posts/personal-finance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav id="63540a58-887b-43a8-802f-008032cf227a"></nav><p id="96dbe6a8-0b25-43a2-88b6-ca4688f23134"><em>NOTE: LITERALLY ZERO OF THIS IS FINANCIAL ADVICE!!! DO YOUR OWN RESEARCH!!!</em></p><h3 id="f7ffa1c1-d40e-4aac-9101-563cb5c43efd">1. Before you even think about investing, start with the personal finance fundamentals</h3><ol id="636ca7eb-6ddd-4d2a-96ee-02cfda1b58ac" start="1"><li>Pay down any debts greater than 7% per year (7% is the average yearly return for the stock market)<ul id="a08592f8-ef0a-4b25-ae93-4cb5bd4f0e54"><li>Don't even think about investing until you do this, not being charged 15% a year in interest and penalties on credit card debt gives you a 2x higher return than the average investor</li></ul></li></ol><ol id="338f55be-2d71-474c-9360-54ee494b18e1" start="2"><li>If you have the space, buy products you're guaranteed to use in bulk on sale<ul id="3b530a5d-4653-4853-983a-ccb62d628437"><li>Buying years supply of toilet paper on sale at $100 instead of $200 means a 100% rate of return - 14x the average investor</li></ul></li></ol><ol id="d22a6401-3bc3-4754-be17-d40a2fba6213" start="3"><li>Reconsider your spending habits (i.e. cut up your credit cards, return things you don't need, uninstall the amazon app and <a href="https://getcoldturkey.com/">block all the online shopping websites</a>)<ul id="e74e9c24-39de-43cf-878a-e8fb7716f238"><li>The reason you don't have money might not be because you're losing it to inflation, it's because you're losing it to $4 cups of coffee <ul id="844e56f6-5a8c-40a2-b980-b06ece4f69c4"><li>In fact, you're probably losing ~$1000 a year - if you invested that, you could have ~$650K in 40 years:<figure id="4f73cb39-38e2-423e-9c4e-714ef03e4350"><a href="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"><img src="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"></a></figure></li></ul></li></ul></li></ol><h3 id="7c5be926-1109-48eb-8caf-7d8768f42a8e">2. When you should (and shouldn't) buy things</h3><p id="0c7ad9de-777a-444b-a703-e2fd64c6a748">Buy things if they:</p><ol id="fb66b42a-e007-4f54-92ee-0125704a9790" start="1"><li>Spark joy, especially when buying for someone else — the emotional ROI of gift-giving is off the charts.</li></ol><ol id="61953c5a-f373-460a-8c86-a1df20760a17" start="2"><li>Get used everyday (Ex. Nice pants, laptop and phone).</li></ol><ol id="38edd8a2-4d00-455e-90c4-351dfb0e2b8b" start="3"><li>Come in between you and the ground (Ex. Mattresses, chairs, winter tires).</li></ol><ol id="dce98e87-6a65-4304-994a-fbaf12c1e596" start="4"><li>Make your life &gt;1% easier (Ex. Good cookware/knives, tools, software).</li></ol><ol id="d6357926-602c-4450-aad9-c53bee4d4845" start="5"><li>Make you better (Ex. Education, gym memberships, travel).</li></ol><p id="dccfbf19-9ddc-4278-b1e6-b8dfa92d77b8">Don't buy things if:</p><ol id="2bb2a4df-bd52-4d81-bb3d-4f34d2a515fd" start="1"><li>You pretty much already own them (Ex. The newest iPhone if you have the last gen already, anything limited edition that won't appreciate in value, cars unless somethings wrong with them).</li></ol><ol id="e14026b6-6d57-439c-baef-b19bf5115bc9" start="2"><li>They're "on sale" — by all means try to get a good deal but sometimes products "on sale" were the same price last month and you just didn't see it, use a price tracker like <a href="https://camelcamelcamel.com/">camelcamelcamel.com</a> to avoid this and make sure you're actually getting a good deal for something you will actually use. Marketing people get paid millions to make you buy things you don't need with money you don't have - outsmart them.</li></ol><ol id="2a9c7b05-6a47-4be0-a8ff-e642252f11d6" start="3"><li>They're cheap — inexpensive and cheap mean 2 different things here but generally look for quality items with lifetime warranties, 1 coat that costs $1000 but lasts 30 years has better ROI than buying a $100 coat every other year. Plus it's less mental strain since you don't have to think about replacing it and you'll get to use something you actually like.</li></ol><ol id="37763a48-4232-460c-86f0-87dcb651fea1" start="4"><li>They're heavily advertised to you — more money spent on marketing means a higher price for you since you're not just paying for the product but the salaries of the people hired to sell/advertise it to you.</li></ol><ol id="f7b4a249-f8bd-4ae4-8fb2-2329bd1b01b6" start="5"><li>You can't afford it! Treat your credit card like a debit card and even then make sure it doesn't dip below an uncomfortable balance.</li></ol><h3 id="2e2f2deb-32bc-4e8d-be04-8a43469e6060">3. Legal tax evasion strategies</h3><p id="31a30907-dbb4-4d92-a98f-4adcdc753115">There are a few ways to legally pay less taxes that the average joe usually isn't aware of. </p><p id="0dff2cad-cfef-4b44-9f44-8577b867fd68">If you have a company, incorporated or not, you can write off lots of things as business expenses like transportation, buying new equipment or rent for co-working spaces. It's also not that hard to start a company — if you're a freelancer, call yourself a consultant and start a "consulting firm" or start an e-commerce store and call yourself a sole-proprieter. Then you can hire a family member, deduct home office expenses and even if you lose money operating the business, you'll save money on taxes. </p><p id="3b719889-6616-4458-94ca-655d168fe3d5">Investing in your government's version of a retirement savings plan is tax deductible against your personal income. So are losses from the stock market. So is charitable giving!</p><p id="62423246-e396-4a48-a5de-a2435a7b19e6">Always try to max out tax free investment accounts/retirement accounts — even if you think it's not worth it the taxes breaks alone mean you come out ahead, even better if your employer matches your contributions. And at the very least, not being able to withdraw for a few decades means you'll be in it for the long run and the market always goes up in the long run.</p><h3 id="93a74cf1-8c77-4182-9946-e91424039ed0">4. <strong>Investing the 80/20 way</strong></h3><p id="05897fe9-4a0e-47d4-8df2-cd910fe40f75">For traditional investing, I try to maximize output and minimize effort. I only use 1 app: Wealthsimple Trade. </p><p id="919727c6-9844-4e45-9aaf-173cb2c3689c">Wealthsimple Trade is like a broker — they let you buy stocks, ETFs, mutual funds, etc., all with $0 fees. They make money from charging a 1.5% currency conversion fee — you can only hold CAD in your account but have to buy US equities with USD and when you sell holdings in USD your balance is credited with CAD. $0 fees are not typical for a brokerage but the currency exchange fees are a killer so I try to only buy Canadian equities. Sometimes I can't resist and I'll run a YOLO on GME - this is more common than I'd like to admit.</p><p id="6dc5cb83-3b1e-410c-b972-d95b9797fc56">Since I'm young, have a job, live at home and can take lots of financial risk, my net worth is divided up roughly as follows (in order of volatility):</p><ul id="467c8446-9ec7-43ad-8b1f-1791cdd43b52"><li>35.5% virtual NBA trading cards</li></ul><ul id="bf81caae-aa42-4c95-a52c-5b3ddf5d07f8"><li>1% Cryptocurrency</li></ul><ul id="8b770356-e3fd-4fb1-ad38-bc3c816dc0d9"><li>33.3% individual stocks I picked (mostly tech companies, this is basically gambling)</li></ul><ul id="5cdbf0f9-7f1d-472a-92ce-9b2b01f7f923"><li>7.1% tech ETFS (ZQQ, ARKK)</li></ul><ul id="4ce7e8fa-3420-4f06-be9d-3418a842c2fd"><li>21.6% whole market ETFs (VSP.TO, VTI, EEMV)</li></ul><ul id="12e4ffe2-10d1-409e-b40a-cf0726ac9eb5"><li>1.5% cash</li></ul><p id="b48787d4-7850-4d49-9104-2819465bd622">This portfolio was made when I was young and stupid. I do not recommend this for anyone and am slowly selling off my more risky positions and buying more into whole market ETFs. It also makes no sense that I'm so heavily invested in the tech sector while working in tech - if that industry goes to shit I'll be doubly ruined. I'm just sharing this for full disclosure since you should know who you're in business with while reading this. Do as I say, not as I do. </p><p id="ddde7cc2-1ab0-4ced-8353-1fe79f450c38">For most investors under 30 who have a similar financial and risk profile as me but aren't as insane, I'd recommend the following steps:</p><ul id="ecc17c23-5127-4155-99d6-30a736287057"><li>Open up a $0 fee trading account - likely Wealthsimple Trade or QuestTrade in Canada, Robinhood in the States</li></ul><ul id="05d79173-10cf-4145-9713-6bb38ced3c08"><li>Deposit a certain % of your paycheque every time you get it and try to maintain a certain ratio of risky investments to safe ones - consistently depositing $500 every month is way better than $10 000 at one time, <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp#:~:text=Dollar%2Dcost%20averaging%20(DCA)%20is%20an%20investment%20strategy%20in,volatility%20on%20the%20overall%20purchase.&amp;text=Dollar%2Dcost%20averaging%20is%20also%20known%20as%20the%20constant%20dollar%20plan.">trust me</a></li></ul><ul id="4df5cac9-c4f4-42ae-8c3e-711a751152fd"><li>I believe inflation is worse than market volatility and the market has always gone up and likely will continue to. For that reason, I recommend the following allocation for your investing money:<ul id="4d3ce485-0523-4605-afe5-c97bacc99497"><li>40% in a whole market fund - something that tracks a lot of high quality stocks and moves in the direction of the entire stock market every day (ex. VRGO, SPY)</li></ul><p id="36533864-3c86-44f4-8bbe-144d15b97ab3">The rest is based on your risk tolerance:</p><ul id="2599b8be-90db-47ad-8ea9-151e9b7b538d"><li><details open=""><summary>Risky (in order of ascending risk): </summary><ul id="6a974d7a-0e47-4fa1-ad6f-226fd0949462"><li>20-30% in a tech sector ETF (I like QQQ/ZQQ, ARKK and ARKW)</li></ul><ul id="24e9d83b-a18d-489a-a7dd-9a8450856b2f"><li>15-20% in individual stocks (this is basically blackjack)</li></ul><ul id="5f3b11bd-9b9f-4ebb-9293-724fea03a1a7"><li>5-10% in cryptocurrency (this is basically roulette)</li></ul><ul id="d8860df2-13af-47d9-816c-dcbe43ecb54e"><li>10-20% in cash</li></ul></details></li></ul><ul id="b9d7004e-e41f-4eda-a330-dbc5d5d13da4"><li><details open=""><summary>Conservative:</summary><ul id="6338a2a9-ded0-4731-ac23-9de34ba326ba"><li>Another 20-40% in in a whole market fund</li></ul><ul id="3d919383-87af-4291-86b0-1e4a6cb790ba"><li> 10-20% in a tech ETF (or pick a more stable industry like banking/energy)</li></ul><ul id="6db6640c-7c77-446b-bd0a-a67883caa04f"><li>10-20% in an ETF tracking bonds</li></ul><ul id="8dc7967e-2184-4ccb-a303-f9f0bf0be1c7"><li>10-20% cash</li></ul><ul id="2e285b82-ee2e-40d1-a547-46ae9a3c3dad"><li>0-5% gold</li></ul></details></li></ul></li></ul><p id="7ca5d98c-014c-4654-8ccc-6e333334b9b8">Some other things to remember:</p><ul id="9225f5e9-eb42-4d81-945f-39e312b14045"><li>Wherever you're investing, keep it consistent and comfortable — it's better to invest 20% of your salary every month and never withdraw than depositing $10000 sporadically when "you see an opportunity"<ul id="ab8e384c-f4a5-4b48-8075-9041ce3ed137"><li>You'll have cash when you need it — if something happens and all your money is tied up in investments, you have to withdraw no matter what → the stock market may always go up in the long run but it fluctuates in the short run, if you need money immediately you may need to sell while you're at a loss.</li></ul></li></ul><ul id="1321b660-f49d-4127-9920-56410f7d3fa5"><li>Keep your personal wellbeing above all<ul id="6e47ce6d-42d0-4836-8a06-ab17b09af564"><li>I have a low appetite for risk when it comes to things I don't understand — that's why I'll never trade on margin, trade options or invest more than 40% of my portfolio in one equity, the possibility of losing all my money would keep me up at night and wouldn't be worth the potential financial upside.</li></ul><ul id="32700e60-6458-4a6a-a801-8318377ba405"><li>I keep less cash on hand because I don't need to buy things very often - you may the opposite in that case your asset allocation will look different from mine - the most important thing is just beating inflation by getting at least 2-4% return (ideally more).</li></ul></li></ul><ul id="6f4d5ce0-26bb-480e-b466-30deb7b0ff0d"><li>Don't over-optimize<ul id="29ad34f1-b279-4417-971b-b2c6e3be98e8"><li>The average person doesn't need to spend hours researching trading strategies or comparing fees for different investment platforms. Spend that time making more money to invest.</li></ul><ul id="56117fd6-92da-4ee1-91ee-228fd20c3118"><li>Just get your money into an investment account. It's literally losing value to inflation by sitting in your 0.00001% annual return savings account or in your mattress.</li></ul></li></ul><ul id="07c2820c-b3c4-4316-b808-4b5f64405b35"><li>Investing is actually 90% saving and 10% all of the sexy things people normally associate with "investing". Always make more than you spend.</li></ul><h3 id="bb0a9476-8011-49e8-9941-25daf83f7d51">5. <strong>My tech stack (aka the section with my referral codes)</strong></h3><ol id="368ae0b9-15f6-488c-92ae-093d7beda66e" start="1"><li>Wealthsimple Trade: I use this everyday and it powers most of my investments — <a href="https://my.wealthsimple.com/app/public/trade-referral-signup?code=OJCS_A">my referral gives you $10 to invest</a> (after investing $100).</li></ol><ol id="add28728-e360-4118-8ac7-bc60741f1f61" start="2"><li>Newton: This is where I buy crypto, best app in Canada - <a href="https://web.newton.co/r/66UJ16">my referral gives you $25</a> (after investing $100).</li></ol><p id="a7125418-57fa-4791-8e37-29dd0fbbb3dc">-AA</p><hr id="c2406a8a-6a85-4d4f-85c5-9e057b0c749b"><p id="ce82f288-c85b-4d43-a343-a6065ffdd874"><em>Thanks for reading! Let me know if you have any questions via twitter </em><em><a href="https://twitter.com/aadillpickle">@aadillpickle</a></em><em> - I'd be happy to help!</em></p><p id="3a2e7255-b50a-4bb6-a39e-e2de8b1da195"><em>And if you found this tutorial particularly useful, consider </em><em><a href="https://www.buymeacoffee.com/aadillpickle">buying me a coffee</a></em><em> ☕️.</em></p></div></div>]]>
            </description>
            <link>https://blog.aadilali.com/posts/personal-finance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281108</guid>
            <pubDate>Fri, 26 Feb 2021 23:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Land – Living Off Grid With No Money]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26281103">thread link</a>) | @SQL2219
<br/>
February 26, 2021 | https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html | <a href="https://web.archive.org/web/*/https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>If you are like me, the biggest obstacle to the dream of living off grid is money. Today, I thought I would help out wannabe homesteaders by gathering together tips for living off grid without money, some you probably haven’t seen before.</p><p>How to live off grid with no money:</p><ul><li><strong>Get yourself a piece of free or low-cost land (4 methods below)</strong></li><li><strong>Build a free home</strong></li><li><strong>Gather and grow naturally abundant foods</strong></li><li><strong>Purify available water for free — no wells to dig</strong></li><li><strong>Set up dirt cheap (free) waste disposal</strong></li><li><strong>Bonus: Find a free living community</strong></li></ul><p>Despite what advertisers, builders, and real estate agents might want you to believe, there are actually many ways to get off grid with out much cost. It all depends on how much work you are willing to put in, and being able to think outside the box.</p><h2 id="getting-land-for-no-money">Getting Land for No Money</h2><p>Free land is still out there and still available. Right now there are many out of the way towns and villages offering plots free or basically free if you are willing to live there. Out in the country, there also opportunities for farm caretakers or land contract deals that will not be advertised online. You have to know where to look. Lastly, there are many tracks of land sitting, unused, that could be yours for <strong>free</strong>, using the unknown law called “adverse possession” that exists in some form in all 50 states!</p><div><div><h5>Free Off Grid Guide</h5><p>Thinking about going off grid? Receive the 30+ page PDF that helps you get there! My gift to you.</p><p><small>You will receive your free guide, exclusive discounts, and occasional announcements</small></p></div></div><h3 id="free-land-in-the-us">Free Land in the US</h3><p>While the original homesteading act is no longer on the books, there are many remote cities in the US that are offering free and, usually in exchange for building a home and living in that city for a set period of time. Here is a list of all the towns in the US offering free land for living there:</p><ul><li><a href="http://www.beatrice.ne.gov/dept/city/attorney/homestead.php">Beatrice, Nebraska</a></li><li><a href="https://www.buffalony.gov/306/Urban-Homestead-Program">Buffalo, New York</a></li><li><a href="https://www.curtisnebraska.com/copy-of-medicine-valley-economic-de">Curtis, Nebraska</a></li><li><a href="http://www.elwoodnebraska.com/Wheatfield1.pdf">Elwood, Nebraska</a></li><li><a href="http://www.lincolnks.org/Housing.html">Lincoln, Kansas</a></li><li><a href="http://www.loupcity.com/business/housing/john-subdivision/">Loup City, Nebraska</a></li><li><a href="https://www.mankatoks.com/free-land">Mankato, Kansas</a></li><li><a href="https://www.manillaia.com/">Manilla, Iowa</a></li><li><a href="https://www.marneiowa.com/marne-free-lots/">Marne, Iowa</a></li><li><a href="http://www.marquettekansas.com/land.html">Marquette, Kansas</a></li><li><a href="https://www.cityofnewrichlandmn.com/index.asp?SEC=E4182CA2-FBE7-4271-89BD-2907B9067956&amp;Type=B_BASIC">New Richland, Minnesota</a></li><li><a href="http://www.discoverosborne.com/ECONOMICDEVELOPMENT/BusinessIncentives.aspx">Osborne, Kansas</a></li><li><a href="http://rookscounty.net/free_homesites">Plainnville, Kansas</a></li></ul><h3 id="free-land-in-canada">Free Land in Canada</h3><p>Being the world’s second largest country yet with only 37 million people (just over 1/10th the United State’s population), Canada is interested in getting more people to live in their many underpopulated rural regions. Right now, there are countless small towns looking for people to move in, in exchange for free or practically free (eg $10/acre) land.</p><p>Many of these deals stipulate that you build a home within a set amount of time, in order to get the free land. But read the section on low cost housing below to see how you might be able to get that done on your own for free.</p><p>Here are some towns and regions in Canada offering free land:</p><ul><li><a href="https://www.cbc.ca/news/canada/new-brunswick/new-brunswick-straw-house-community-offers-free-land-1.2765195">New Brunswick Strawhouse Community</a></li><li><a href="https://www.albertafarmexpress.ca/2016/12/05/the-lure-of-free-land-is-drawing-in-a-new-type-of-homesteader/">St-Louis-de-Blandford, Quebec</a></li><li><a href="http://rmofpipestone.com/main.aspx?CategoryCode=BE0B3259-5572-4DEA-9D08-6072C1F49D90&amp;pageCode=2DB56BC7-F94C-4DE9-A71C-C7E5E9EE352A&amp;subPageCode=6EC9A94F-F258-4746-8369-FECB852B7AEA">Pipestone, Manitoba</a></li><li><a href="https://www.cbc.ca/news/canada/manitoba/manitoba-rm-looks-to-sell-ghost-town-lots-for-10-1.2086700">Scarth, Manitoba</a></li><li><a href="http://www.back2land.ca/">South Knowlesville Community Land Trust, New Brunswick</a></li><li><a href="https://www.mundare.ca/Business-Opportunity">Mundare, Alberta</a></li><li><a href="https://www.thefarmersdaughtercountrymarket.ca/employment">Free Land for Working in Wycocomagh, Cape Breton</a></li><li><a href="https://yukon.ca/en/apply-agriculture-land#getting-public-land-for-agriculture">Free Land in the Yukon</a></li><li><a href="http://www.greenenergyfutures.ca/episode/craik-eco-village">Craik Eco-Village , Saskatchewan</a> (ecovillage website not up at time of writing, but community may still be in operation)</li></ul><p>Also, crown land in Canada (land owned by the government) allows people to live there free for 6 weeks at a time, after which time you would have to move on. This could be a perfect free way for a yurt, RV, or portable tiny home dweller to live free of rent.</p><h3 id="cheap-land-and-free-money-in-alaska">Cheap Land and Free Money in Alaska</h3><p>Long one of the last bastions of truly untouched wilderness, Alaska is still one of the freest states in the Union and one of the most beautiful places in the world. While not free up front, <a href="https://dnr.alaska.gov/mlw/landsales">the Alaskan government routinely sells cheap land</a> over the counter as well as through periodic auctions.</p><h4 id="free-money-for-living-in-alaska">Free Money for Living in Alaska</h4><p>While not initially free, establishing residency in Alaska makes you eligible to receive the annual <a href="https://pfd.alaska.gov/">Permanent Fund Dividend</a>. Last year’s dividend was <a href="https://www.adn.com/alaska-news/2019/09/27/this-years-alaska-permanent-fund-dividend-1606/">$1,606 per person</a> including dependents and children. <strong>So a household of five would have seen a $8030 payment this year.</strong> The amount paid depends on how much money Alaska is making, and thus the economy, but the dividend payout has been between about $1,000 – $2,000 per person in recent memory.</p><p>For a family who lives frugally and attempts to produce most of their food off grid through hunting would be able to pay of their off grid land purchase in only a few years.</p><figure><img alt="Subsistence Fishing in Alaska" height="393" src="https://offgridpermaculture.com/img/subsistence_fishing_alaska_salmon.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/subsistence_fishing_alaska_salmon.jpg"></figure><h4 id="subsistence-hunting-and-fishing-licenses">Subsistence Hunting and Fishing Licenses</h4><p>Residents of Alaska also get <a href="https://www.adfg.alaska.gov/index.cfm?adfg=residentfishing.main">special privileges concerning hunting and fishing rights</a>. This includes practices such as net fishing for Salmon and subsistence hunting that are not possible in other states. When I lived in Alaska, it was rare to find a home without a chest freezer packed with salmon and moose meat caught for free.</p><p>For those of you haven’t spent time in Alaska the remoteness of the land and ferocity of the cold weather may astonish you. Likewise, the cost of necessities such as gas and food is well above most regions of United States. So be careful if you decide to go up there. However, for many of my readers, Alaska might just be the perfect spot.</p><h3 id="usda-farm-grant-and-loan-program">USDA Farm Grant and Loan Program</h3><p>No money, but interested in opening a functioning off grid farm? <a href="https://www.usda.gov/topics/farming/grants-and-loans">USDA Grants &amp; Loans</a> has programs to provide money for family size farms as well as a program specifically for new farms.</p><p>In exchange for accepting these funds you will be obligated to attempt to start a farm that conforms to the USDA’s standards of farming. But, for looking to get started with their own off grid agriculture business, these programs could be perfect for you.</p><h3 id="farm-caretaker">Farm Caretaker</h3><p>One way to get started off grid for no money is to become a <a href="https://www.motherearthnews.com/homesteading-and-livestock/farm-caretaker-zmaz76mjztak">Farm Caretaker</a>. Farm care taking is a free rent situation where you work in exchange for free rent. And, can often be a longer term arrangement, lasting years if you choose.</p><p>With labor in rural farm lands at an all time low, and children of farming families moving to the city, there are many farms out there that are looking for people to watch over them. Depending on the situation, some owners may ask you to work part time on the farm — tending livestock and the like — while others may just want someone around to keep an eye on the place and do occasional maintenance work.</p><p>You will not find offers for farm care taker advertised online or on job sites. and will have to search for your own opportunities. Try posting an add on Craigslist, Facebook local forums, or in regional newspapers with good rural distribution. Explain clearly and quickly what you are looking for and what you plan to offer in return.</p><h3 id="land-contract">Land Contract</h3><p>Undeveloped land is not easily financed or mortgaged by banks, which makes land contracts, also known as owner carry, very common practice for purchasing off grid land. A land contract is an agreement between the buyer and seller that you will pay off the purchase over time at a set rate, and at the end of the contract you become the full owner of the land.</p><p>Essentially, the seller becomes the bank.</p><h4 id="finding-no-down-land-contracts">Finding No Down Land Contracts</h4><p>While land contracts typically require a 10% – 20% down payment, finding a motivated owner through direct contact gives you the opportunity to negotiate for a zero down or work exchange situation. See my article <a href="https://offgridpermaculture.com/Finding_Land/How_to_Find_Off_Grid_Land_Ways_You_Havent_Heard_Of.html">“How to Find Off Grid Land - Ways You Haven’t Heard Of”</a> for details on how to find and contact motivated sellers not yet on the market.</p><h4 id="local-businesses-that-sell-land">Local Businesses that Sell Land</h4><p>Another no down option would be to contact <a href="https://www.classiccountryland.com/blog/become-a-land-owner-with-no-down-payment-or-fees">small companies that specialize in off grid properties</a>. Some have special deals for no down payment parcels, while others might be amenable to negotiating special terms. Also, if you are in a lumber producing area, search for local timber investment firms. I have found firms that sell off grid “timber land” with land contracts, and may be willing to provide good terms on parcels of land that they consider unproductive.</p><p>Land contracts are well established legally, generally safe for both parties. However, be wary if you sign one, because failure to pay timely payments or follow through with the contract usually results in the buyer losing the property and anything they paid up to that point.</p><figure><img alt="Map of Adverse Possession Laws in the US" height="450" src="https://offgridpermaculture.com/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg"></figure><h3 id="adverse-possession">Adverse Possession</h3><p>One legal concept for acquiring land that you probably haven’t heard of before is <a href="https://en.wikipedia.org/wiki/Adverse_possession#United_States">adverse possession</a> or “squatter’s rights”. What they are is the right to claim ownership of a piece of land that you have been openly living on it for a certain amount of time (see above map), between 5 – 30 years depending on your state.</p><p>The idea of these laws are that vacant pieces of land where, the owner is completely absent, should go to someone who is putting it to good use. What that means in practice varies form state to state. Every state in the US has some form of adverse possession.</p><p>Adverse possession does not mean you have the right to live on a piece of property if you have been asked to leave. The legal owner can ask you to leave at any time. Ultimately, it can be a gamble, since you <strong>must live on the land without the owner’s permission in order to claim adverse possession.</strong></p><p>EDIT: More info on adverse possession and squatters rights, including a state by state breakdown of the laws, can be found here —</p><ul><li><a href="https://offgridpermaculture.com/Finding_Land/How_to_Homestead_on_Abandoned_Property_Is_It_Legal.html">How to Homestead on Abandoned Property | Is It Legal?</a></li></ul><h2 id="low-cost-or-no-cost-off-grid-housing">Low Cost or No Cost Off Grid Housing</h2><p>The next big hurdle to get started living off grid is housing. While some of the options provided above may come with a living arrangement, there are may free or low cost ways to live comfortably off the grid.</p><p>Homes are usually the mainstream family’s biggest expense, but if you are willing to work and to live conservatively, a dept free or even plain free home is within your grasp. Building a tiny home is well within the skills of most people with minimal training. And, they can be built quickly and cheap or free depending on your building material foraging skills. There are also may natural building styles like cob building, light straw clay, earth bag, and straw bale that can be build largely from earth already on site, and can last for generations.</p><figure><img alt="Tiny Home Living for Free" height="400" src="https://offgridpermaculture.com/img/tiny_home_living_off_grid.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/tiny_home_living_off_grid.jpg"></figure><h3 id="tiny-home-from-recycled-materials">Tiny Home from Recycled Materials</h3><p>With the tiny home craze growing every year, there are many places to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</a></em></p>]]>
            </description>
            <link>https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281103</guid>
            <pubDate>Fri, 26 Feb 2021 23:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Molecules that remodel the gut microbiota reverse narrowing of arteries]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280993">thread link</a>) | @voisin
<br/>
February 26, 2021 | https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/ | <a href="https://web.archive.org/web/*/https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="#1">• Clotting activation</a><br>
<a href="#2">• Therapeutic approach</a></p>
<blockquote>
<p><strong>What is already known on this topic</strong><br>
Cardiovascular diseases, which include stroke and heart attack, are one of the leading cause of death worldwide. Most heart attacks result from the formation of a blood clot that obstructs one or more coronary arteries, the blood vessels that carry oxygen and nutrients to the heart. Low levels of microbial molecules called endotoxins have been found in the blood of people whose coronary arteries are obstructed by blood clots, but the role of endotoxins in the formation of blood clots is still unclear.</p>
<p><strong>What this research adds</strong><br>
Researchers have analyzed blood samples from 150 people, including 50 individuals affected by heart attack, from whom the researchers also obtained samples of coronary blood clots. The analysis showed that endotoxins derived from Escherichia coli, a bacterium commonly found in the gut, could enter the blood circulation and trigger the formation of blood clots in coronary arteries. The team also found that, compared to the gut of healthy people, the intestine of individuals who suffered a heart attack is more permeable — a condition that could allow endotoxins to enter the blood circulation. Mice injected with E. coli or treated with endotoxins developed more blood clots than untreated mice. But these detrimental effects disappeared when mice were given an inhibitor of TLR4 — the cellular receptor to which E. coli binds to trigger the formation of blood clots.</p>
<p><strong>Conclusion</strong><br>
The findings suggest a new mechanism that could favor heart attacks and could open up therapeutic avenues that rely on TLR4 inhibition to counteract the formation of coronary clots in people with cardiovascular disease, the researchers say.</p>
</blockquote>
<p>Cardiovascular diseases, which include stroke and heart attack, are one of the leading cause of death worldwide, but the mechanisms behind these disorders are unknown. Now, researchers have found that <strong>a bacterium commonly found in the gut could enter the blood circulation, triggering the formation of blood clots in vessels that carry oxygen and nutrients to the heart</strong>.</p>
<p><a href="https://doi.org/10.1093/eurheartj/ehz893" target="_blank" rel="noopener noreferrer">The findings</a>, published in the <i>European Heart Journal</i>, suggest a new mechanism that could favor heart attacks. They also open up therapeutic avenues to treat this condition, the researchers say.</p>
<p>Most heart attacks result from the formation of a blood clot that obstructs one or more coronary arteries. <strong>Low levels of</strong> microbial molecules called <strong>endotoxins have been found in the blood of people whose coronary arteries are obstructed by blood clots</strong>, but the role of endotoxins in the formation of blood clots is still unclear.</p>
<p>To address this question, <strong>Francesco Violi</strong> at Umberto I University Hospital in Rome and his colleagues analyzed blood samples from 150 people, including 50 individuals affected by heart attack. From these individuals, the researchers also obtained samples of coronary blood clots.</p>
<h2 id="1">Clotting activation</h2>
<p>The analysis showed that <strong>endotoxins derived from </strong><strong><i>Escherichia coli</i></strong>, a bacterium commonly found in the gut, <strong>circulate in the blood of people with heart attack</strong>. <strong>That’s likely because</strong> <strong>the intestine of these individuals is more permeable that the gut of healthy people</strong>, the researchers found.&nbsp;</p>
<p>The increased gut permeability observed in people with heart attacks could allow endotoxins as well as gut bacteria to enter the blood circulation. Indeed, the researchers found that 34% of samples from people with a heart attack contained <i>E. coli</i> DNA, compared to 4% of samples from healthy people.</p>
<p><strong>The presence of low levels of endotoxins in the blood appears to trigger the formation of coronary blood clots through several mechanisms</strong>, the researchers found. These include the activation, adhesion, and aggregation of small cell fragments known as platelets, which help to turn blood from a liquid into a gel.&nbsp;</p>
<h2 id="2">Therapeutic approach</h2>
<p><strong>To trigger the formation of blood clots, <i>E. coli</i></strong><strong> appears to bind to a specific cell-surface receptor called TLR4</strong>. The team also identified <strong>a molecule that inhibits the TLR4 receptor, hindering the formation of blood clots</strong>.&nbsp;</p>
<p>Mice injected with <i>E. coli</i> or treated with endotoxins developed more blood clots than untreated mice. But the detrimental effect of endotoxins disappeared when mice were given the TLR4 inhibitor.</p>
<p>The results could help to develop <strong>new therapeutic strategies that rely on TLR4 inhibition to counteract the formation of coronary clots in people with cardiovascular disease</strong>, the researchers say.</p><div>
<p><a href="https://microbiomepost.com/register/?utm_source=banner_article_bottom"><img src="https://microbiomepost.com/wp-content/uploads/2018/12/Banner-sign-up.jpg"></a></p></div> </div></div>]]>
            </description>
            <link>https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280993</guid>
            <pubDate>Fri, 26 Feb 2021 23:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The four requirements under the Declarative Theory of Statehood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280279">thread link</a>) | @valkrieco
<br/>
February 26, 2021 | https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/ | <a href="https://web.archive.org/web/*/https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-253">

	
		<!-- .entry-header -->

		<div>
			
<p>On 16<sup>th</sup> June 2014, Jeremiah Heaton declared 2,060km<sup>2</sup> of arid land in Africa as the <a rel="noreferrer noopener" href="https://www.kingdomsudan.org/" target="_blank">Kingdom of North Sudan</a>, after promising his daughter that one day she would become a Princess.</p>



<p>Heaton, a farmer from the US state of Virginia, had been looking for unclaimed territory around the world and after some research settled on an area known as Bir Tawil, an uninhabited piece of land between Egypt and Sudan.</p>



<p>Due to two conflicting treaties drawn up by the British, both Egypt and Sudan interpreted the treaties as they saw fit. A claim on a piece of land close to Bir Tawil would disqualify the party from claiming Bir Tawil itself, and since the former enjoyed prospective mineral wealth, both sides claim this land as their own. Bir Tawil ended up a ‘terra nullius’ – land that belongs to no one until this was claimed by Heaton himself.</p>



<div><figure><img loading="lazy" width="640" height="488" src="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=640%2C488&amp;ssl=1" alt="" srcset="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?w=941&amp;ssl=1 941w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=768%2C586&amp;ssl=1 768w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure></div>



<h3>Rose Island</h3>



<p>Like many others, I have recently watched ‘<a rel="noreferrer noopener" href="https://www.netflix.com/title/81116948" target="_blank">Rose Island</a>‘ on Netflix and started to think about how countries we know today came to be. In the film, Giorgio Rosa, the real-life founder of the former ‘<a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Republic_of_Rose_Island" target="_blank">Republic of Rose Island</a>‘, tried, in vain, to convince the United Nations, the Council of Europe and the Italian Government that since his artificial island was outside Italy’s territorial waters, it should be considered an independent state. While Rose Island and North Sudan are <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Micronation" target="_blank">micronations</a> – which are usually small in size, lack recognition from other states and are generally the creation of a single individual – their founding stories can tell us a lot about the challenges that <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Proto-state" target="_blank">proto-states</a> meet with, and how countries are indeed volatile entities that can be created and destroyed.</p>



<p>When one thinks of countries like the United States, Russia, China, Japan or Germany for example, we usually consider these as permanent entities, however even these same countries had different borders, governments and cultures throughout their existence. While micronations cannot be compared to these countries, they do have one thing in common – they all are trying to find or maintain their place on the world stage.</p>



<p>So, how do you create a country?  First of all – what exactly is a country?</p>



<p>While there is no single definition of what constitutes a ‘country’, there are some <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Sovereign_state" target="_blank">international guidelines</a> that this entity must follow, for it to be recognised as such. The two main competing schools of thought are the <a href="https://en.wikipedia.org/wiki/Sovereign_state#Constitutive_theory">constitutive theory of statehood</a> and the <a href="https://en.wikipedia.org/wiki/Sovereign_state#Declarative_theory">declarative theory of statehood</a>. </p>



<p>Big words, however, the main difference is that the first one only affords recognition to states that have been recognised by other states, while the second allows for an entity to declare sovereignty without having to be explicitly recognised as such by other states.</p>



<p>The declarative theory was codified in 1933 in the Montevideo Convention on the Rights and Duties of States and is used by many proto-states, including micronations to help prove their cause, as its the easier way of declaring sovereignty. This does not guarantee that someone following this theory is automatically considered a country. Let’s take a look at each one of the qualifications under this theory and see how they affect the aspirations of proto-countries, not only micronations but also regions and people fighting for their sovereignty. </p>



<p>The Convention states that “the state as a person of international law should possess the following qualifications”:</p>



<ol><li><strong>Permanent Population;</strong></li><li><strong>Defined</strong> <strong>Territory;</strong></li><li><strong>A Government;</strong></li><li><strong>The ability to enter into agreements with other states.</strong></li></ol>



<hr>



<h3>1. Permanent Population</h3>



<p>The first qualification under this Convention is for the proto-state to have a permanent population belonging to the land one is claiming as a country.  </p>



<p>The Sahrawi people in <a href="https://en.wikipedia.org/wiki/Western_Sahara">Western Sahara</a> have been roaming the lands for hundreds of years. The area was governed by the Spanish until 1975 when Morocco, Mauritania and <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Polisario_Front" target="_blank">Polisario</a> all claimed the land as their own. </p>



<p>In a dispute between the latter two, the International Court of Justice (ICJ) <a href="https://www.economist.com/the-economist-explains/2021/01/13/who-should-control-western-sahara" target="_blank" rel="noreferrer noopener">declared</a> that Western Sahara was not <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Terra_nullius" data-type="URL" data-id="https://en.wikipedia.org/wiki/Terra_nullius" target="_blank">terra nullius</a>, as in the case of Bir Tawil, and before the Spanish conquered the area, there were tribes connected to Morocco, who were already living off the land. Morocco took this as a sign that it has historical precedent to control Western Sahara, even if the ICJ did not reach that explicit conclusion.</p>



<p>Earlier, the United Nations General Assembly adopted <a rel="noreferrer noopener" href="https://www.ohchr.org/EN/ProfessionalInterest/Pages/Independence.aspx" target="_blank">Resolution 1514 (XV)</a> on 14 December 1960, which declared that non-self-governing territories have to “transfer all powers to the peoples of those territories, without any conditions or reservations, …. in order to enable them to enjoy complete independence and freedom.”</p>



<div><figure><img src="https://i0.wp.com/morningstaronline.co.uk/sites/default/files/styles/article_full/public/11sahrawiprotesters.jpg?w=640&amp;ssl=1" alt="" data-recalc-dims="1"><figcaption>Sahrawi women protesting against the Moroccan occupation, 2005 Photo: Western Sahara / Creative Commons</figcaption></figure></div>



<p>This is were Morocco and Polisario, which is recognised as the representative of the Sahrawi people by the United Nations, disagree. Polisario has been fighting for control of the land ever since, and after 1991 when a war between the Front and Morocco ended, the former only controlled a strip of land to the east of Western Sahara with the border of Mauritania.</p>



<p>The Sahrawis are banking that having a permanent population on the land would make it easier for them to declare independence of Western Sahara. However, even this hope is fading as Morocco has been increasingly moving Moroccans on the land, making sure that any future referendum, if it takes place, confirms its control on Western Sahara. Without outside pressure, especially from major players in the region and around the world, Polisario supporters and Sahrawis see little hope that someday they would control the area, despite their people having lived there for hundreds of years.</p>



<p>The case of Western Sahara contrasts with the tens of colonies that after World War II started gaining independence on account of their different cultures, languages and customs compared to the coloniser – and also as a result of the UN Security Council Resolution mentioned above. Even today, pro-independence parties and supporters in Catalonia and Scotland, for example, who have occupied their lands for hundreds of years, built institutions around their customs and passed on their language from generation to generation, claim their right to govern themselves as they see fit. The call for the sovereignty of these regions is, in fact, stronger than that of the people in <a href="https://en.wikipedia.org/wiki/Northern_Cyprus">Northern </a><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Northern_Cyprus" target="_blank">Cyprus</a>, for example, whose claim for independence is the result of a military incursion in 1974. Article 11 of the same Convention even claims that states will not recognise territorial acquisitions claimed by force.</p>



<h3>2. Defined Territory</h3>



<p>Several proto-countries often start with this specification – finding or occupying a piece of land or estate – something tangible that can give the claim of a state a real feel. Some, like Heaton, go to great lengths to find land unclaimed by official states, while others declare regions or parts of their country as a separate entity. Rosa, in ‘Rose Island’, even built the artificial island himself.</p>



<p>On the night of 2<sup>nd</sup> May 2020, a number of slogans such as ‘<a rel="noreferrer noopener" href="https://www.nationalia.info/brief/11308/away-from-rome-independence-slogans-written-with-fire-on-mountains-in-south-tyrol" target="_blank">Away from Rome</a>‘ were written with fire on the side of the mountains in South Tyrol in what seems to be criticism by right-wing separatist supporters, against the centralisation of COVID-19 regulations by the Italian government.</p>



<div><figure><img loading="lazy" width="640" height="320" src="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?resize=640%2C320&amp;ssl=1" alt="" srcset="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?w=750&amp;ssl=1 750w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption><em>Author: Schützenkompanie Johann-Jaeger Niederdorf Süd Tirol</em></figcaption></figure></div>



<p>The geographic position and history of South Tyrol with its neighbours and Rome, has led some movements to argue for the region to cede from Italy and join Austria. Pro-separatist South Tyrolean parties highlight their historical borders and their cultural and language differences with other parts of Italy as the reason why they cannot form part of the country. </p>



<p>Many regions around the world have promoted territorial separatism as a way to reduce tension, sometimes even violence, between people of different backgrounds and different cultures. This is not usually the case in most independence movements in Europe, such as in South Tyrol or Corsica. However, violence has sometimes been used by separatist movements who believe that this will accelerate their cause, and even by the Government of the country who believes it will keep these movements in check.</p>



<p>Even so, cases like South Tyrol, Corsica, West Papua (Indonesia) or New Caledonia (France), where there is an existing natural or man-made border separating people with similar backgrounds from other parts of the country tend to be more successful in making their case for independence accepted, or at least understood, within that same community and with the mainland. Compare this with people who have the same cultural background but are found in different regions/countries. One example is the case of the Kurds who are concentrated in parts of Turkey, Syria, Iran and Iraq. Without a single place to call home, Kurds have had to take up their quest for sovereignty with several regional powers, which has made it harder for them to claim territory. The Syrian civil war did provide hope for Kurds, after the setting up of Rojava or the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Autonomous_Administration_of_North_and_East_Syria" target="_blank">Autonomous Administration of North and East Syria</a>,  which created a de facto proto-state controlled by Syrian Kurds. However, as soon as Turkey realised the danger of having an entity controlled by the Kurds right outside their borders, they invaded and re-took part of the lands aligned with Rojava.</p>



<p>Take also the example of Cyprus and the Turkish invasion in 1974, which de facto divided the country into two. Whereas before the invasion Greek-Cypriots and Turkish-Cypriots lived amongst each other all over the country, the invasion and subsequent building of borders, led to the separation of these two cultures. The now defined territory of the Turkish Republic of Northern Cyprus made it possible for some Cypriot-Turks to try and claim independence.</p>



<h3>3. A Government</h3>



<p>After identifying the borders of their territory, the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/">https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/</a></em></p>]]>
            </description>
            <link>https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280279</guid>
            <pubDate>Fri, 26 Feb 2021 21:52:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoCAD: A tiny modeller made in PICO-8]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26280141">thread link</a>) | @leafo
<br/>
February 26, 2021 | https://johanpeitz.itch.io/picocad | <a href="https://web.archive.org/web/*/https://johanpeitz.itch.io/picocad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>A tiny modeller for tiny models</h3>
<p>picoCAD is a program to build and texture lowpoly 3D models. Where many programs for modelling and texturing are&nbsp;bloated and overly complicated, picoCAD aims to make it fun, easy, and accessible by focusing on the&nbsp;bare essentials.&nbsp;It is built on the PICO-8 platform and comes rich with constraints.&nbsp;Experiment to find your own workflow and anything is possible!</p>
<h3>Features</h3>
<ul><li>Streamlined and easy to use editor</li><li>Place and modify&nbsp;meshes to create amazing things</li><li>Live manipulation of textures and UV coordinates&nbsp;</li><li>A unique look with picoCAD's dithered shading</li><li>Render in wireframe, solid fill, or textured</li><li>All save files in easy to read text format</li><li>Exports&nbsp;Twitter friendly GIFs</li><li>Ships with a manual that is worth reading</li></ul>
<h3>Get involved</h3>
<p>Check out our&nbsp;<a href="https://discord.gg/hjXMammbPB" rel="nofollow noopener">discord</a> for help, as well as&nbsp;cool stuff built by the community.</p>
<p>The&nbsp;<a href="https://twitter.com/search?q=%23picoCAD" rel="nofollow noopener">#picoCAD</a>&nbsp;on Twitter is also a good place to browse the latest and greatest.</p>
<h3>Have fun</h3>
<p>I&nbsp;hope you'll have a good time using picoCAD! If you find it useful, please consider donating - thanks! &lt;3&nbsp;</p></div></div>]]>
            </description>
            <link>https://johanpeitz.itch.io/picocad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280141</guid>
            <pubDate>Fri, 26 Feb 2021 21:39:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Nym Network – Next Generation of Privacy Infrastructure [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279779">thread link</a>) | @octabond
<br/>
February 26, 2021 | https://nymtech.net/nym-whitepaper.pdf | <a href="https://web.archive.org/web/*/https://nymtech.net/nym-whitepaper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nymtech.net/nym-whitepaper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279779</guid>
            <pubDate>Fri, 26 Feb 2021 20:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Riddle of the Square]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279712">thread link</a>) | @chrbutler
<br/>
February 26, 2021 | https://www.chrbutler.com/square | <a href="https://web.archive.org/web/*/https://www.chrbutler.com/square">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<br>

<h6>← <a href="https://www.chrbutler.com/essays">See All Articles</a></h6>
        <p>
<img src="https://blot.im/cdn/blog_a7eb7cf1ab024efcb17c380ef69c53f4/_image_cache/55ab3c90-d28f-475f-8262-87a25e72b88f.jpg" width="1000" height="500" data-action="zoom">
</p>

<p>
Shapes are mysterious. They are basic, rudimentary forms — simple ideas upon which we build more complex systems of understanding. They are also vast landscapes of information and meaning — doorways into mental worlds of thought, unhindered by physical limitations.
</p>
<p>
You can look at the simplest of forms — a square, a circle, a triangle — and its edges will accommodate your curiosity; they will stretch; they will become porous; their liminality will beckon you to enter and to hold them. Like the Sphinx, they may be all their edges tell you, or they may be anything else. They are riddles for the eye.
</p>
<p>
Ellsworth Kelly put it much more simply when he said that “a shape contains personality.”
</p>
<p>
Kelly was talking about just one of his Blue Panels when he said this, though his entire body of work exemplifies the idea. He is best known for painting fields of color. His contribution to modern art was, in part, a vast collection of shaped canvasses, painted in single, flat colors. Beginning his career at a time when abstract expressionism was the idea carrying modern art forward, Kelly’s work was universally iconoclastic. For many onlookers at the time, it simply wasn’t art. And though many of them had their complaints about the expressionist work of his peers, they could at least still see the artist’s <i>hand</i> in the work, be swept up in its motion, or even lose themselves in the physical beauty of the material itself. Kelly’s objects were made precisely to do the opposite: not to engage the viewer in the object or its maker, but to draw them in to everything beyond it. To be a riddle and an invitation.
</p>
<p>
Kelly once <a href="https://www.metmuseum.org/metmedia/video/collections/modern/ellsworth-kelly-blue-panel" target="_blank">told a story</a> about a man he met on an airplane. They got to talking about painting. The man shared that he often visits The Metropolitan Museum of Art to look at the paintings. “One painting really throws me,” he said. “It’s a large blue painting with nothing on it.” Kelly replied, “That’s mine. Go look at it again.” Rather than a correction, Kelly offers another riddle.
</p>
<p>
I love this story because I can tell the same one. When I was seventeen, I went with my senior art class to the same museum, and saw the same painting. We had come to tour the modern art gallery in general, but Kelly’s <a href="https://www.metmuseum.org/art/collection/search/484636" target="_blank">Blue Panel <span>II</span></a>, which is still on view in <a href="https://maps.metmuseum.org/galleries/fifth-ave/2/922" target="_blank">Gallery 922</a>, became our fixation. We gathered in front of it and stared; it silently divided us. Some said it was art. Others said it was not. Its name further provoked the angst of the naysayers: “Blue Panel number <i>two</i>? So there are more of these things?”
</p>
<p>
The debate continued as we left the museum. It went on as we explored the city. And on still, all way home on the bus. Someone suggested we keep this going — that we get together once a week to talk about art outside of class. We named our little group <i>The Wedge</i>. It was a nod to Kelly’s panel and the way it had cleaved our assumed intellectual unity. The group, as far as I know, remained a fixture at my high school for a few years after we were gone but eventually faded away. But I have remained transfixed by <i>the wedge</i>.
</p>
<p>
As I said, Kelly made more than one Blue Panel. In what feels like an almost supernatural coincidence, one of them just happens to hang in a gallery near me at the North Carolina Museum of Art. I remember the first time I strode into the room and saw it. I stopped, dead in my tracks, as if I’d seen a ghost of my past returned in tremendous glory. The <span>NCMA</span>’s <a href="https://ncartmuseum.org/art/detail/blue_panel" target="_blank">Blue Panel</a> is not the same Blue Panel as the one I’d seen as a teenager at The Met. It’s bigger. It’s brighter. Its movement is less of a subtle lean to the side and more of an explosive twist. It’s my favorite of Ellsworth Kelly’s <i>Blue Panels</i>, and a perfect example of what is so magical about his work. I stare at his shapes and am in awe of their endless capacity. In them I see all of geometry, all of math, all surfaces, all spaces, all movement.
</p>
<p><span>
■□
</span></p>
<p>
In no other shape is there greater mystery than the square. I wonder if that is why one of the very few single, square images that Ellsworth Kelly produced is just black. He even titled it that way: “Black,” without reference to shape or surface, leaving us all to decide what it is, or where it is, or where we are within it.
</p>
<p>
A square is a plane with four equal sides set at four right angles. Such a thing hardly exists in the world. Everything we call <i>a square</i> is an example that falls considerably short of the definition, provided you look closely enough. That’s because the precision of numbers doesn’t really exist in the natural world.
</p>
<p>
Plato considered numbers to be <i>abstract</i>. For him, they were ideas that lack physical form necessarily, because to take any form would be to lose their perfection. He also considered numbers to be <i>eternal</i> — perpetually existing — and therefore more real than the world in which we live. His reverence for the perfection of the abstract was almost religious. In fact, he believed that things like numbers and shapes actually existed in another space, often called now, after him, <i>The Platonic Realm</i>. Aristotle, his student, was more pragmatic. He considered numbers to be nothing more than an invention of the mind to aid in our understanding of nature, providing measures of amount, or distance, or duration. One can imagine the debate: One side might say, “If numbers are just a construct, then why do they describe the universe so well?” To which the other might reply, “So would anything else, if that’s what we decided to use to describe the universe!”
</p>
<p>
Nevertheless, both a Platonist and an Aristotelian can agree that there is quite some distance between the perfection of geometry and the plasticity of nature. The square, again, makes for an ideal symbol. It is too perfect for nature. Observing both where we <i>find</i> squares and how we <i>use</i> them bears that out. Of all the geometric shapes, the square may be the least commonly occurring in nature. This is because most things in the natural world are molecularly asymmetrical. Mineral structures, for instance, are quite varied in their geometric correspondence. The few that are square are pyrite, galena (the mineral form of lead sulfide), and halite (rock salt). Most everywhere you look for structure in nature, though, you will find far less rigid forms. While there are a few scant natural squares — lobster eyes comprise millions of micron-length square channels; wombat poop is, oddly, cubic — circles, triangles, rhombuses, and all sorts of polygons are far more common. And most of them are warped.
</p>
<p>
When we make squares and when we don’t follows nature’s lead. I often think about how infrequently we use squares when creating spaces and structures. Our bodies, of course, determine this. A square door, for example, would be interesting to look at but impractical to use. We are taller than we are wide. A square door tall enough to give us passage would be wider and intrude upon the space in which it opened more than necessary. So doors, like many other things created by nature, for nature, in nature, are rarely square. Perfect symmetry, as it turns out, is inefficient.
</p>
<p>
I often think about that principle when, as a designer, I consider aspect ratios of imagery. Why is everything a rectangle? There is a reason why cinema screens, televisions, and monitors are wider than they are tall. A rectangular plane in landscape orientation fits our biology. Our two eyes, spaced apart on our head as they are, create a wider periphery. We can see more horizontally than vertically without moving our heads. A square screen, large enough to be absorbingly “cinematic,” would have us literally moving our heads up and down continually in order to take in the visual information it displayed. The ergonomics of wide screens are obviously superior. The visual economy of the rectangle works its way inward, from the edges of the form to its contents. As many a web designer will lament, another day, another rectangle. But it’s worth pointing out that the complaint would be the same and certainly louder, if it were another day, another square. Symmetry of form is beautiful, but it isn’t always functional.
</p>
<p>
Symmetry of system, on the other hand, can be extremely efficient, even when it doesn’t correspond to nature. Because a square is perfectly symmetrical, it can be duplicated into infinity, creating a reliably consistent structure — a grid — in all directions. Grids help us to work within and upon nature, even when within nature no grids can be found.
</p>
<p>
As a child — and to this day — I was fascinated by maps and pages of text and easily transfixed by them. I often find myself drawn to pages and screens, for instance, not by their contents but by their form. By how the information is arranged. As a child, I didn’t realize that what I was actually looking at was <i>the grid</i>. The form of the page became a puzzle; I was in search of the system beneath it. The grid becomes another riddle for the eye. Most things we make we do so upon a grid, though the precision of their form can never match the abstract system beneath them. There’s a tension in that, one which provides endless provocation to anyone who looks.
</p>
<p>
Ellsworth Kelly understood that. He created an <a href="https://ellsworthkelly.org/work/the-boston-panels-the-john-j-moakley-federal-courthouse-boston/" target="_blank">installation in Boston</a> which is an ideal illustration of the tension between the perfect symmetry and eternality of the abstract and the asymmetry and limits of nature. Within a large, open column of space within the John J. Moakley Federal Courthouse building, Kelly hung a set of colored panels. From a mezzanine, you can look out and up into the column to a point at which the arc’ed ceiling above you cuts off your view, creating the illusion that the grid of shapes goes on and up forever. When you stand in front of it, you can easily imagine them encircling you, too. It’s as if <i>The Boston Panels</i> were as close as Kelly could get to merging our world with The Platonic Realm.
</p>
<p>
▱
</p>
<p>
It’s not lost on me that this has been more about forms that are <i>not</i> squares than those that are. For me, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrbutler.com/square">https://www.chrbutler.com/square</a></em></p>]]>
            </description>
            <link>https://www.chrbutler.com/square</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279712</guid>
            <pubDate>Fri, 26 Feb 2021 20:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Road to Common Lisp (2018)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279468">thread link</a>) | @Tomte
<br/>
February 26, 2021 | https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/ | <a href="https://web.archive.org/web/*/https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on August 27th, 2018.</p><p>I've gotten a bunch of emails asking for advice on how to learn Common Lisp in
the present day.  I decided to write down all the advice I've been giving
through email and social media posts in the hopes that someone might find it
useful.</p>

<p>One disclaimer up front: this is <em>a</em> road to Common Lisp, not <em>the</em> road to
Common Lisp.  It's what I followed (without some of the dead ends) and has
a <em>lot</em> of my personal opinions baked in, but it is by no means the only way to
learn the language.</p>

<p>This post has been translated into
<a href="https://gist.github.com/y2q-actionman/49d7587912b2786eb68643afde6ca192">Japanese</a>.
I can't vouch for the accuracy of any translations.</p>

<ol><li><a href="#s1-context">Context</a><ol><li><a href="#s2-history">History</a></li><li><a href="#s3-consequences">Consequences</a><ol><li><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></li><li><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></li><li><a href="#s6-extensibility">Extensibility</a></li><li><a href="#s7-power">Power</a></li><li><a href="#s8-ugliness">Ugliness</a></li></ol></li></ol></li><li><a href="#s9-a-road-to-learning-common-lisp">A Road to Learning Common Lisp</a><ol><li><a href="#s10-get-a-lisp">Get a Lisp</a></li><li><a href="#s11-pick-an-editor">Pick an Editor</a></li><li><a href="#s12-hello-lisp">Hello, Lisp</a></li><li><a href="#s13-a-gentle-introduction">A Gentle Introduction</a></li><li><a href="#s14-getting-practical">Getting Practical</a></li><li><a href="#s15-make-something">Make Something</a></li><li><a href="#s16-lisp-as-a-system">Lisp as a System</a></li><li><a href="#s17-learning-paradigms">Learning Paradigms</a></li><li><a href="#s18-switch-things-up">Switch Things Up</a></li><li><a href="#s19-recipes-for-success">Recipes for Success</a></li><li><a href="#s20-final-patterns">Final Patterns</a></li></ol></li><li><a href="#s21-where-to-go-from-here">Where to Go From Here</a><ol><li><a href="#s22-macros">Macros</a></li><li><a href="#s23-object-oriented-programming-with-clos">Object-Oriented Programming with CLOS</a></li><li><a href="#s24-low-level-programming">Low-Level Programming</a></li><li><a href="#s25-web-development">Web Development</a></li><li><a href="#s26-game-development">Game Development</a></li><li><a href="#s27-window-management">Window Management</a></li><li><a href="#s28-unit-testing">Unit Testing</a></li><li><a href="#s29-more-implementations">More Implementations</a></li></ol></li><li><a href="#s30-modern-common-lisp">Modern Common Lisp</a><ol><li><a href="#s31-structure">Structure</a><ol><li><a href="#s32-packages">Packages</a></li><li><a href="#s33-systems">Systems</a></li><li><a href="#s34-projects">Projects</a></li><li><a href="#s35-recap">Recap</a></li></ol></li><li><a href="#s36-common-libraries">Common Libraries</a><ol><li><a href="#s37-alexandria">Alexandria</a></li><li><a href="#s38-bordeaux-threads">Bordeaux Threads</a></li><li><a href="#s39-cffi">CFFI</a></li><li><a href="#s40-cl-ppcre">CL-PPCRE</a></li><li><a href="#s41-drakma">Drakma</a></li><li><a href="#s42-iterate">Iterate</a></li><li><a href="#s43-local-time">local-time</a></li><li><a href="#s44-lparallel">lparallel</a></li><li><a href="#s45-named-readtables">Named Readtables</a></li><li><a href="#s46-roswell">Roswell</a></li><li><a href="#s47-series">SERIES</a></li><li><a href="#s48-st-json">st-json</a></li><li><a href="#s49-usocket">usocket</a></li></ol></li></ol></li><li><a href="#s50-good-luck">Good Luck!</a></li></ol>

<h2 id="s1-context"><a href="#s1-context">Context</a></h2>

<p>I think it's important to have a sense of where Common Lisp came from and what
kind of a language it is before you start learning it.  There are some things
that will seem very strange if you're coming straight from modern languages,
but will make more sense if you've got a bit of background context.</p>

<h3 id="s2-history"><a href="#s2-history">History</a></h3>

<p>Common Lisp has a long, deep history.  I'm not going to try to cover it all here
— if you're interested you should check out some of the following (in roughly
increasing order of detail):</p>

<ul>
<li>Wikipedia's <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)#History">History of Lisp</a> and <a href="https://en.wikipedia.org/wiki/Common_Lisp#History">History of Common Lisp</a>.</li>
<li>The <a href="http://www.gigamonkeys.com/book/introduction-why-lisp.html#where-it-began">Where it Began section in Practical Common Lisp</a>.</li>
<li>The <a href="https://www.cs.cmu.edu/Groups//AI/lang/lisp/faq/lisp_2.faq">History: Where did Lisp come from?</a> section of the comp.lang.lisp FAQ.</li>
<li><a href="http://www.nhplace.com/kent/Papers/cl-untold-story.html">Common Lisp: the Untold Story</a> by Kent Pitman.</li>
<li><a href="https://www.dreamsongs.com/Files/HOPL2-Uncut.pdf">The Evolution of Lisp</a> by Guy Steele and Richard Gabriel.</li>
</ul>

<p>I realize you probably won't want to read all of the links above immediately, so
here's a whirlwind tour of sixty years of Lisp.</p>

<p>Lisp began in the late 1950's.  It was invented by John McCarthy at MIT.</p>

<p>Over the next twenty or so years various versions and dialects of Lisp grew and
flourished.  Some of the more notable dialects were Maclisp, BBN Lisp/Interlisp,
Franz Lisp, Spice Lisp, and Lisp Machine Lisp.  There were others too.  The
point is that there were a <em>lot</em> of different implementations, all growing,
changing, and trying out different things.</p>

<p>(Scheme also originated in this time frame, but took a very different route and
diverged from the path we're looking at.  I won't cover Scheme in this post.)</p>

<p>In the early 1980s people decided that having a whole slew of
mutually-incompatible dialects of Lisp might be not be ideal.  An effort was
made to take these different languages that had grown organically and produce
one common language that would satisfy the needs of everyone (or at least
a reasonable subset of "everyone").  In 1984 the first edition of Guy Steele's
<a href="https://www.cs.cmu.edu/Groups/AI/html/cltl/cltl2.html">Common Lisp: the Language</a> was published.</p>

<p>If you do some math you'll see that at the time the book was published Lisp had
around twenty-five years of real-world use, experimentation, experience, and
history to draw upon.  Even so, the book alone didn't quite satisfy everyone and
in 1986 a committee (X3J13) was formed to produce an ANSI specification for
Common Lisp.</p>

<p>While the committee worked on the standardization process, in 1990 the second
edition of Common Lisp: the Language was published.  This was more
comprehensive and contained some of the things the committee was working on
(see the comp.lang.lisp FAQ linked above for more on this).  At this point the
Lisp family of languages had over thirty years of experience and history to
draw upon.  For comparison: Python (a "modern" language many people think of as
also being "kind of old") <a href="https://en.wikipedia.org/wiki/History_of_Python#Early_history">was released</a> for the first time the
following year.</p>

<p>In 1992 the X3J13 committee published the first draft of the new Common Lisp
ANSI standard for public review (see Pitman's paper).  The draft was approved in
1994 and the approved specification was finally published in 1995.  At this
point Lisp was over thirty-five years old.  The first version of Ruby <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)#First_publication">was
released</a> in December of that year.</p>

<p>That's the end of the history lesson.  There has not been another revision of
the ANSI specification of Common Lisp.  The version published in 1995 is the one
that is still used today — if you see something calling itself "an
implementation of Common Lisp" today, that is the specification it's referring
to.</p>

<h3 id="s3-consequences"><a href="#s3-consequences">Consequences</a></h3>

<p>I wanted to give you a quick overview of the history of Common Lisp because I
want you to know what you're getting yourself into.  I want you to realize that
Common Lisp is a stable, large, practical, extensible, ugly language.
Understanding these characteristics will make a lot of things make more sense
as you learn the language, and I want to talk a little bit more about each of
them before I start offering recommendations.</p>

<h4 id="s4-escaping-the-hamster-wheel-of-backwards-incompatibility"><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></h4>

<p>If you're coming from other languages, you're probably used to things breaking
when you "upgrade" your language implementation and/or libraries.  If you want
to run Ruby code you wrote ten years ago on the latest version of Ruby, it's
probably going to take some effort to update it.  My current day job is in Scala,
and if a library's last activity is more than 2 or 3 years old on Github I just
assume it won't work without a significant amount of screwing around on my part.
The Hamster Wheel of Backwards Incompatibility we deal with every day is a fact
of life in most modern languages, though some are certainly better than others.</p>

<p>If you learn Common Lisp, this is usually not the case.  In the next section of
this post I'll be recommending a book written in 1990.  You can run its code,
unchanged, in a Common Lisp implementation released last month.  After years of
jogging on the Hamster Wheel of Backwards Incompatibility I cannot tell you how
much of a <em>relief</em> it is to be able to write code and reasonably expect it to
still work in twenty years.</p>

<p>Of course, this is only the case for the language itself — if you depend on any
libraries there's always the chance they might break when you update them.  But
I've found the stability of the core language is contagious, and overall the
Common Lisp community seems fairly good about maintaining backwards
compatibility.</p>

<p>I'll be honest though: there are exceptions.  As you learn the language and
start using libraries you'll start noticing some library authors who don't
bother to document and preserve stable APIs for their libraries, and if
staying off the Hamster Wheel is important to you you'll learn to avoid relying
on code written by those people as much as possible.</p>

<h4 id="s5-practicality-begets-purity"><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></h4>

<p>Another thing to understand about Common Lisp is that it's a large, practical
language.  The second edition of Common Lisp: the Language (usually abbreviated
as "CLtL2" by Common Lisp programmers) is 971 pages long, not including the
preface, references, or index.  You can get a surprising amount done by writing
pure Common Lisp without much extra support.</p>

<p>When programming applications in Common Lisp people will often depend on
a small(ish) number of stable libraries, and library writers often try to
minimize dependencies by utilizing as much of the core language as possible.
I try to stick to fewer than ten or so dependencies for my applications and no
more than two or three for my libraries (preferably zero, if possible), but I'm
probably a bit more conservative than most folks.  I <em>really</em> don't like the
Hamster Wheel.</p>

<p>It's also worth noting that since Common Lisp has been around and stable for so
long, it has <em>libraries</em> older and more stable than many programming languages.
For example: Bordeaux Threads (the de-facto threading library for Common Lisp)
was first proposed in 2004 and released soon after (2006 at the latest but
possibly earlier, it's hard to tell because so many links are dead now), which
makes it about fourteen years old.  So yes, threading is handled by a library,
but I'm not worried about it breaking my code in the next decade or two.</p>

<p>My advice is this: as you learn Common Lisp and look for libraries, try to
suppress the voice in the back of your head that says "This project was last
updated six years ago?  That's probably abandoned and broken."  The stability of
Common Lisp means that sometimes libraries can just be <em>done</em>, not <em>abandoned</em>,
so don't dismiss them out of hand.</p>

<h4 id="s6-extensibility"><a href="#s6-extensibility">Extensibility</a></h4>

<p>Part of Common Lisp's practicality comes from its extensibility.  No one has
been clamoring for a new version of the specification that adds features
because Common Lisp's extensibility allows users to add new features to the
language as plain old libraries, without having to alter the core language.
Macros are what might come to mind when you hear "Lisp extensibility", and of
course that's part of it.  Macros allow users to write libraries that would
need to be core language features in other languages.</p>

<p>Common Lisp doesn't include string interpolation.  You want it?  No problem, you
don't have to wait for <a href="https://docs.scala-lang.org/overviews/core/string-interpolation.html">Scala
2.10</a> or
<a href="https://www.python.org/dev/peps/pep-0498/">Python 3.6</a>, just <a href="https://edicl.github.io/cl-interpol/">use
a library</a>.</p>

<p>Want to try some nondeterministic programming without any boilerplate?  <a href="https://nikodemus.github.io/screamer/">Grab
a library</a>.</p>

<p>Pattern matching syntax can make for some really beautiful, readable code.
Common Lisp doesn't include it, but of course <a href="https://github.com/guicho271828/trivia/wiki/What-is-pattern-matching%3F-Benefits%3F">there's a library</a>.</p>

<p>Enjoying algebraic data types in Haskell or Scala?  Here's your
<a href="https://github.com/tarballs-are-good/cl-algebraic-data-type">library</a>.</p>

<p>All of these libraries rely on macros to make using them feel seamless.  Of
course you could <em>do</em> all of that without macros, but you've have to add a layer
of boilerplate to manage evaluation.  This:</p>

<pre><code>(match foo
  '(list x y z) (lambda (x y z) (+ x y z))
  '(vector x y) (lambda …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</a></em></p>]]>
            </description>
            <link>https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279468</guid>
            <pubDate>Fri, 26 Feb 2021 20:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming SQL: What is it, why is it useful?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279109">thread link</a>) | @cptroot
<br/>
February 26, 2021 | https://materialize.com/streaming-sql-intro/ | <a href="https://web.archive.org/web/*/https://materialize.com/streaming-sql-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Summary</h3>
<p><strong>Streaming SQL</strong> is about taking the same declarative SQL used to write database queries, and instead <strong>running it on streams of fast-changing data</strong>.</p>
<p>This is useful because:</p>
<ol>
<li>Data is often more valuable when you can act on it quickly</li>
<li>The existing tools for deriving real-time insights from streams are too complex.</li>
</ol>
<p>The “declarative” nature of SQL plays an important role in addressing the second point because it allows the user to focus on <strong>WHAT</strong> they want, and lets the underlying engine worry about <strong>HOW</strong> it gets done.</p>
<p>In the real world, Streaming SQL is used to:</p>
<ul>
<li>Enable new internal and customer-facing insights, automation, and applications</li>
<li>Increase value of business intelligence data by providing a single up-to-date source of truth for key metrics</li>
<li>Simplify microservices by replacing code doing data coordination and transformation</li>
</ul>
<h2>What is streaming SQL?</h2>
<p>Let’s start by being specific about what we mean when we say <strong>streaming</strong> and <strong>SQL</strong>.</p>
<h3>Streaming (event streams)</h3>
<p>Streaming refers to message brokers like Kafka, Kinesis, or Pulsar that handle data as a <strong>continuous stream of events or messages</strong>.</p>
<p>Event streams handle everything from transactions to user actions on sites or mobile apps, IoT sensor data, metrics from servers, even activity on traditional databases via <a href="https://materialize.com/change-data-capture-part-1/">change data capture</a>.</p>
<h3>SQL</h3>
<p>In the context of streams, SQL gives users a declarative language for:</p>
<ul>
<li>Creating <strong>views</strong> that join, filter, and group the raw data from the stream into more useful outputs (<a href="https://materialize.com/docs/sql/create-materialized-view/"><code>CREATE MATERIALIZED VIEW</code></a>)</li>
<li>Selecting data from sources and views (<a href="https://materialize.com/docs/sql/select/"><code>SELECT</code></a>)</li>
</ul>
<p>
<strong>NOTE:</strong> The CREATE MATERIALIZED VIEW command is the core concept in streaming SQL. It comes from <a href="https://www.postgresql.org/docs/9.3/sql-creatematerializedview.html">databases</a>, where it’s used to precompute the VIEW ahead of time in case the data changes. In streaming, the data is changing all the time, so queries are often more useful when maintained as materialized views.
</p>
<p>Other common SQL verbs like INSERT, UPDATE, and DELETE have roles in streaming SQL, but for this article we’ll focus on the core concepts of <strong>reading</strong> from streams, joining/filtering/transforming these streams, and making their outputs queryable or <a href="https://materialize.com/docs/sql/create-sink/">writing out to a new stream</a>.</p>
<h3>Differences between SQL on streams and databases</h3>
<p>A soon as you try using SQL on streams, a few key differences become apparent:</p>
<h4>Point-in-time vs continuous queries</h4>
<p>Running a SQL query on a traditional database returns a static set of results from a single point in time.</p>
<p>Take this query:</p>
<pre><code>SELECT SUM(amount) as total_amount FROM invoices;
</code></pre>
<p>When you run it, the database engine scans all invoices that existed <em>at the time of</em> the query and returns the sum of their amounts.</p>
<p>With streaming SQL, you <em>could</em> run the exact query above and get a point-in-time answer. But you’re querying a stream of fast-changing data, and as soon as you’ve gotten the results back they’re probably out-dated. In many cases a <strong>query that continually updates itself</strong> (a materialized view) is much more useful in a few ways we’ll describe below.</p>
<p>To turn the query above into a materialized view, you’d write:</p>
<pre><code>CREATE MATERIALIZED VIEW invoice_summary AS
  SELECT SUM(amount) as total_amount FROM invoices;
</code></pre>
<p>When you first create it, the SQL engine will process the entire history of invoice events it has access to up to the present, <strong><em>and then continue to update as new invoice events come through.</em></strong></p>
<h4>Response time vs lag</h4>
<p>Traditional databases have the concept of query response times: you run a query, some time elapses while the engine computes the results, and you get the response.</p>
<p>In streams the initial response time is only a factor when you first materialize a view. But there has to be some kind of time penalty in streaming results if we get a sudden surge of input events. That penalty is <strong>time lag</strong>: <em>by how much time is the output trailing the input?</em></p>
<p>Like response times in traditional databases, most end-users won’t need to think about time-lag in streaming systems, but knowing it exists helps to write and use streaming SQL in ways that avoid issues.</p>
<h4>Different actions create work for the underlying engine</h4>
<p>On the READ side, a traditional database engine idles until it receives a query, then it plans and optimizes it and gets to work providing the results. Once it responds with the results it idles again until it gets another query.  <strong>The sending of queries is what creates work for the engine.</strong></p>
<p>If you go back to the materialized view from above, <strong>new data from the stream creates the work</strong> for the engine. In Materialize, this approach is made possible by incremental computation: the work done to update the view is proportionate to the data coming in not the complexity of the query. We don’t need to do a full re-scan of data to update the results.</p>
<p>This paradigm shift makes streaming SQL best for queries that ask the same question over and over again (e.g. dashboards, reports, automation, most application code) and not ad-hoc queries.</p>
<h2>Why is streaming SQL useful?</h2>
<h3>1. Data is often most valuable when it first appears</h3>
<p>There are two reasons for this, one obvious and one less so:</p>
<ol>
<li><strong>Faster data = faster decisions</strong> — The stock market is a clear example of this idea taken to an extreme. <img src="https://user-images.githubusercontent.com/11527560/108846387-81f3df00-75ac-11eb-8caa-f293b48bf54c.png" data-src="https://user-images.githubusercontent.com/11527560/108846387-81f3df00-75ac-11eb-8caa-f293b48bf54c.png" alt="Chart showing higher value for newer data"> But it also applies to SaaS businesses, verticals like Marketplaces, Travel, Events that need to make fast decisions about rates and inventory, retail and logistics where faster decisions can reduce inefficiency, etc…
</li>
<li>
<p><strong>Data closer to its origin has fewer opportunities to be misinterpreted</strong> — Every step that data takes between where it’s created and where it’s used adds more potential for errors of the type where the end-user (person or machine) thinks the data represents something it does not. Time plays a role in this by forcing coordination around order of operations and alignment of work. In this case, switching to streaming data isn’t better because it’s faster, it’s better because you no longer have to think about timing.</p>
</li>
</ol>
<h3>2. SQL is a great means of deriving insights from streaming data</h3>
<p>Here is another example of a materialized view on streaming events:</p>
<pre><code>  CREATE MATERIALIZED VIEW experiments AS
   SELECT
     experiment_views.name,
     experiment_views.variant,
     COUNT(DISTINCT(experiment_views.user_id)) as unique_users,
     COUNT(DISTINCT(conversions.user_id)) as unique_conversions
   FROM experiment_views
   LEFT JOIN conversions ON
     conversions.user_id = experiment_views.user_id 
     AND conversions.created_at &gt; experiment_views.created_at
   GROUP BY experiment_views.name, experiment_views.variant;
</code></pre>
<ul>
<li><strong>The SQL is not unique to streaming</strong> — The meaning of data doesn’t change when it moves from a stream to a database, so the way we query it shouldn’t change either.</li>
<li><strong>The declarative nature of it increases productivity</strong> — There are little or no optimization decisions for the developer to make, especially in comparison to the same task in code.</li>
</ul>
<p>SQL has the added benefit of being a mature language built over three decades with an ecosystem of tooling and education around it. This means a much larger group of developers can work with streaming data and easily integrate it into the rest of their stack.</p>
<h2>Example use cases for Streaming SQL</h2>
<p>Today, anyone already working with a message broker like Kafka can start using streaming SQL without significant effort. In the future as CDC software matures, that criteria will expand to “anyone with a database.” Here are some examples of how streaming SQL is used:</p>
<h3>Business Intelligence and Analytics</h3>
<p>When deciding “what is the best way to empower our internal teams to make intelligent decisions from data”, Streaming SQL is one option to consider, with trade-offs that make it better for some cases than others.</p>
<p>In many cases, a materialized view on primary source data done in streaming SQL is a simpler <a href="https://nchammas.com/writing/data-pipeline-materialized-view">data pipeline</a>. In addition to the benefit of real-time data, businesses use this approach to side-step issues of:</p>
<ul>
<li>Coordination of time intervals and order of operations in batch processing</li>
<li>Extended outages caused by bugs that are not fixable or testable until next batch run</li>
<li>Slow-loading dashboards</li>
<li>Inconsistency issues caused by caching, denormalization</li>
</ul>
<p>See this walkthrough on <a href="https://materialize.com/docs/demos/business-intelligence/">streaming SQL to a business intelligence dashboard</a> with Materialize for an example.</p>
<h3>Microservices</h3>
<p>Streaming SQL is used to replace code doing complex data coordination and transformation in microservices.</p>
<p>An event stream like kafka is typically already a first-class citizen in microservice architectures. Engineers often find themselves building and maintaining complex applications consuming from kafka. For example: applications that read from an event log to produce insights and measurements on API usage for a SaaS application.</p>
<p>Any component of a microservice that looks like a query might be replaceable with streaming SQL.</p>
<p>This <a href="https://materialize.com/docs/demos/microservice/">Streaming SQL on Microservices example</a> walks through a working demo using Materialize to produce billing data based on product events from a stream.</p>
<h3>Real-Time Applications</h3>
<p>If the value of your application depends on your ability to deliver updates and data in real time, Streaming SQL may be an alternative to building an expensive or complex multi-component stack.</p>
<p>See <a href="https://materialize.com/a-simple-and-efficient-real-time-application-powered-by-materializes-tail-command/">a simple and efficient real-time application</a> post for an example.</p>
<h3>New capabilities</h3>
<ol>
<li><strong>User-facing real-time analytics</strong> – Previously, only tech behemoths like LinkedIn and Google had the scale and engineering teams to build user-facing real-time analytics (like LinkedIn’s “Who has viewed your profile” page or Google Analytics’ Real-time dashboard.) By lowering the complexity, streaming SQL opens magical real-time user analytics features up to more companies.</li>
<li><strong>Business Automation</strong> – Once you have streaming SQL powering real-time dashboards, a natural progression is to begin making automated decisions on the same data. (For example: If your e-commerce site gets a spike in traffic from a particular source, add a promotion to the homepage.)</li>
</ol>
<h2>Conclusion</h2>
<p>Materialize provides a streaming SQL implementation that’s unique in two important ways:</p>
<ol>
<li>In Materialize, you write queries in postgres-compatible SQL. <em>We think it’s worth going through the …</em></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.com/streaming-sql-intro/">https://materialize.com/streaming-sql-intro/</a></em></p>]]>
            </description>
            <link>https://materialize.com/streaming-sql-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279109</guid>
            <pubDate>Fri, 26 Feb 2021 19:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Cybercafe to Rocketship: My First Month at Orbit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277988">thread link</a>) | @sorich87
<br/>
February 26, 2021 | https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/ | <a href="https://web.archive.org/web/*/https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My journey at Orbit started with this funny tweet by Josh.</p><p>I wasn't looking for a new job but his tweet caught my attention.</p><p>The mission of Orbit, right there on the careers page, made me curious to learn more about the company. Building thriving communities and developer tools was very much aligned with my past career path and current interests. That ultimately led me to join the team.</p><h2>My background</h2><p>I started my career as a self-taught software developer who didn’t own a computer. I worked from a cybercafé in a small African country with a very bad internet connexion. I quickly gained plenty of technical experience and contributed to products used by millions of people across the world. I even wrote <a href="https://www.packtpub.com/product/learning-bootstrap/9781782161844">a technical book</a> and had <a href="https://www.flyerco.com/">a small startup exit</a>! I attribute a large part of that growth to being involved in gaming and developer communities where I made friends, met mentors, and found clients.</p><p>After about ten years of basically 100% online life, I spent the past five building up the tech community in my country of origin, Benin, by serving as vice-president and CTO of <a href="https://etrilabs.com/">the leading tech innovation hub</a>, and co-founding <a href="http://www.tekxl.com/">a small product studio</a> over there. It was awesome contributing to projects with real-world impact on tens of thousands of people. Over time, my involvement decreased as we were able to build a talented team that could continue moving the mission forward.</p><p>So, when COVID hit, I knew the next step of my professional career was due, and it was about the online-first life again. I spent the best part of 2020 helping <a href="https://irawotalents.com/">Irawo</a>, a community of more than 50.000 talents and creators in francophone Africa, launch new programs and develop a sustainable business model.</p><h2>Meeting Orbit</h2><p>When I saw Orbit's homepage and model, something clicked. The <a href="https://github.com/orbit-love/orbit-model">Orbit Model</a> was in line with my own experience of contributing and growing communities. I’d also long dreamed of building a CRM-like solution that’s centered around each customer’s experience as an individual. I think the Orbit Model captures the multi-dimensional aspect of how people interact in a community, or with organization products or services. It’s a refreshing break from the linear view of traditional sales and marketing funnels.</p><p>Needless to say, I was drawn to Orbit and decided to email the founders right away. I wasn’t looking for a full-time job, but they were looking for part-time consultants to help with integrations and other stuff.</p><p>Josh, the co-founder and CTO, replied a couple of days later, and, about a week after my email, we were on a call. The call was awesome! That’s when I knew I wanted to join the team instead of just contributing some integrations. Talking with Josh sold me on the vision. It also helped that the team was great at execution. They had made enormous progress in terms of traction and product development. And they were backed by some of the top VCs in Silicon Valley.</p><p>The opportunity to join this rocket ship about to take off was amazing. For me, this is the ideal time to join a startup in its growth trajectory, and I am very confident that Orbit is going to grow even faster and be successful. It was the best learning opportunity I could have at this step of my career.</p><h2>The Interviews</h2><p>After the call with Josh, he introduced me to Nicolas, who is a software engineer and the first non-founder team member. We scheduled a technical interview for the next day. It was not your typical algorithmic coding interview. It was a pair programming session where we worked together on actual production code to implement a new fun feature in the product. We had a great time together! Nicolas was happy to have another French-speaking programmer in the team so we spoke French. I learned a lot about the team culture, how technical decisions are made, etc. I could get a taste of what it would be like to work together.</p><p>After the interview with Nicolas, I went into my last interview with Patrick, 100% convinced Orbit was the next step in my journey. Patrick is the other co-founder and CEO of Orbit. He's a very high-energy guy. We talked about the company vision and the plans for the next months. I could feel his enthusiasm and how he was dedicated to reaching the goals. After our chat, he told me right away that I would receive an offer in the next few days. The offer came a couple of days later and, after a short negotiation, I signed it. It took less than a week from the first call to signing the offer, and I was starting the next Monday!</p><h2>The First Days</h2><p>Onboarding remote employees can be difficult but, for a young company, Orbit onboarding is pretty solid. A few days before I started, Josh had shared access to all the communication and collaboration tools: Miro, Slack, GitHub, Airtable, Trello, and more. I went through basically everything and learned so much about the company, what product and strategic decisions were made in the past, why they had been made, most major events, the company values, the processes, and many more key points.</p><p>Being an early riser, I was even able to submit a small pull request before anyone in the Paris or San Francisco timezone was up on the first day! I got a handful of pull requests merged in my first week overall. This is how fast a team member can onboard when there are great asynchronous communication processes in place. It was like someone had onboarded me on the basics before actually talking with anyone in person. The calls with team members on the next few days were mostly around getting to know each other and getting help on my tasks.</p><h2>The Hard Parts</h2><p>The technical aspects of my new role are going very smoothly, and I haven’t had any difficulties with them so far. The hard parts were mostly around some emotional aspects of stepping into new shoes. Working with Orbit is my first full-time role not being in a founder or executive position, so it came with its challenges. Around the middle of the month, I was hit by a bunch of insecurities and, for 2-3 days, I wasn’t as productive as I would have loved. Would I be able to adjust to a different culture? Would I be able to perform at my full potential? Would my integration into the team go smoothly? Would I be given the kind of responsibilities I’m looking for?</p><p>I think it’s normal to have such interrogations when joining a new role. They would differ from one person to another, but they are frequently addressed with good communication with other team members, and some amount of self-reflection. The team has been handling the communication aspect very well so far. I have 1:1s with Josh every two weeks where I’m able to openly discuss all I have in mind. It also helped that Josh, Nicolas, and I were able to meet in person once for lunch.</p><h2>Conclusion</h2><p>Overall, my first month at Orbit has been an awesome experience. The team is made of caring and driven people with great product and business chops. I learned a lot in just a few weeks and I look forward to learning, growing and contributing more over the next months.</p><p>We're looking for more awesome people to join the Orbit team! <a href="https://orbit.love/careers/">See our open positions.</a></p></div></div>]]>
            </description>
            <link>https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277988</guid>
            <pubDate>Fri, 26 Feb 2021 18:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hummingbard – decentralized communities built on Matrix]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26277602">thread link</a>) | @SubGenius
<br/>
February 26, 2021 | https://hummingbard.com/hummingbard/introducing-hummingbard | <a href="https://web.archive.org/web/*/https://hummingbard.com/hummingbard/introducing-hummingbard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>Hummingbard is an experiment in building communities on top of <a href="https://matrix.org/" rel="nofollow">Matrix</a>. Hummingbard has social elements like user profiles, posts, communities, sharing and so on. It is intended to be more than just a decentralized link aggregator or a microblogging platform.</p>

<h3>Spaces</h3>

<p>The main centre of interest in Hummingbard is a space, which is an ordinary <a href="https://github.com/matrix-org/matrix-doc/blob/kegan/spaces-summary/proposals/2946-spaces-summary.md" rel="nofollow">Matrix space</a>. A space is similar to a forum board, subreddit or an FB group. The posts in a space are ordinary Matrix events, with additional metadata for rendering social-like posts. Posts can include images, attachments and links. This should be extendable to add polls, reviews etc. in the future. Hummingbard posts can be blog posts too, like <em>this one youâ€™re reading right now</em>.</p>

<p>Spaces can be rendered in various ways, which makes it possible to use them as user profiles like <a href="https://hummingbard.com/@david" rel="nofollow">@david</a>, or communities like <a href="https://hummingbard.com/art" rel="nofollow">art</a>. Spaces can be arbitrarily nested, allowing sub-spaces like <a href="https://hummingbard.com/music/classical" rel="nofollow">music/classical</a> or <a href="https://hummingbard.com/music/jazz/fusion" rel="nofollow">music/jazz/fusion</a>. Spaces can also have sub-spaces that render as wiki pages like <a href="https://hummingbard.com/hummingbard/about" rel="nofollow">hummingbard/about</a>.</p>

<p>It is possible to have different types of spaces. A gallery type renders a space in Instagram-like fashion, like the <a href="https://hummingbard.com/pics" rel="nofollow">pics</a> space. Any type of space can be nested under any other type of space. This allows normal boards to have sub-spaces which are galleries, or vice versa. In the future, a space could be rendered to be a business page, and e-commerce page etc.</p>

<p>Hummingbard spaces are very limited in options right now, but basic info like title, description, header-image can be changed. Spaces support custom CSS too.</p>

<h3>Social</h3>

<p>Hummingbard has very basic social-like features. Users can follow other users and join spaces. A user feed shows posts chronologically. Posts can be shared from one user/community to another user/community. Posts can be replied to. Replies can be nested like in this <a href="https://hummingbard.com/test/$kXWe3pG7N53PIWl33KnW_zA0GYGTRDWy2d5jj6rE0G8" rel="nofollow">thread</a>.</p>

<h3>Federation</h3>

<p>Hummingbard works with federated Matrix servers too. Users can create Matrix accounts on remote servers, or log in with an existing account. Logging in with an existing account creates a user profile automatically, unless one already exists. Hummingbard spaces on federated servers work just the same as local spaces. Here are a few examples:</p>

<ul>
<li><p><a href="https://hummingbard.com/rhythm:matrix.org" rel="nofollow">rhythm:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/food:tchncs.de" rel="nofollow">food:tchncs.de</a></p></li>

<li><p><a href="https://hummingbard.com/ask:matrix.org" rel="nofollow">ask:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/@ahq:matrix.org" rel="nofollow">ahq:matrix.org</a></p></li>
</ul>

<p>Federated spaces can also have nested spaces like <a href="https://hummingbard.com/ebooks:matrix.org/fantasy" rel="nofollow">ebooks:matrix.org/fantasy</a> or pages <a href="https://hummingbard.com/rhythm:matrix.org/about" rel="nofollow">rhythm:matrix.org/about</a>.</p>

<p>In an ideal world, owners of Matrix servers would be hosting their own instance of Hummingbard, instead of going through one popular instance.</p>

<h3>Dendrite</h3>

<p>Hummingbard is dependent on <a href="https://github.com/hummingbard/dendrite/tree/thread_pagination" rel="nofollow">Dendrite</a>, the second-generation Matrix homeserver written in Go. Features like spaces and threading have only been implemented on Dendrite. Note that it is a forked repo with a temporary patch for paginating threads.</p>

<h3>Code</h3>

<p>Hummingbardâ€™s code will be available as soon as I am able to decide which license works best for us.</p>

<h3>Whatâ€™s Coming</h3>

<p>Hummingbard is very bare-bones at the moment. Iâ€™m actively working on the following:</p>

<ul>
<li><p>Private spaces</p></li>

<li><p>Power levels for admins/mods</p></li>

<li><p>Dark mode and various UI changes</p></li>
</ul>

<p>Aside from that, Hummingbard has a lot of bugs, and will likely crash randomly. If you do want to check out the site, either create a local Hummingbard account, or use an existing throwaway Matrix account. Iâ€™d advice against using your main Matrix account, as the authentication code may have bugs. Please try to avoid any rooms that are too large. My tiny VPS running dendrite will not be able to handle it.</p>

<h3>Contact/Feedback</h3>

<p>Weâ€™re using <a href="https://matrix.to/#/%23hummingbard:matrix.org" rel="nofollow">#hummingbard:matrix.org</a> as a meeting place to discuss Hummingbard development. You can also leave bug reports on a Hummingbard space itself - <a href="https://hummingbard.com/hummingbard/bugs" rel="nofollow">hummingbard/bugs</a></p>

<p>Lastly, if youâ€™d like to leave a reply on this blog post itself, you can log into Hummingbard with an existing Matrix account, join the <a href="https://hummingbard.com/hummingbard" rel="nofollow">hummingbard</a> space, and come back here to write your reply.</p>

<p>Many thanks.</p>

<p><strong>PS</strong>: If this post has a typo, I wonâ€™t be able to fix it because Hummingbard has not implemented editing posts yet.</p>

<p><strong>PPS</strong>: Thanks to <a href="https://hummingbard.com/@david" rel="nofollow">@david</a> for reviewing this post.</p>

                </div></div>]]>
            </description>
            <link>https://hummingbard.com/hummingbard/introducing-hummingbard</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277602</guid>
            <pubDate>Fri, 26 Feb 2021 17:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: your build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26277521">thread link</a>) | @moonlighter
<br/>
February 26, 2021 | https://justine.lol/cosmopolitan/ | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>your build-once run-anywhere c library</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/tutorials.html">Tutorials</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» justine's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
printf %s <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc \
  -o hello.com.dbg hello.c -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
objcopy -SO binary hello.com.dbg hello.com

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, OpenBSD, and NetBSD too. For details on how this works,
  please read the <a title="Actually Portable Executable" aria-label="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> blog post. This novel binary format is also
  optional, since <code>hello.com.dbg</code> is executable too, only on
  your local system since it's an ELF binary.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277521</guid>
            <pubDate>Fri, 26 Feb 2021 17:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Did Texas Lose Power?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277437">thread link</a>) | @amoorthy
<br/>
February 26, 2021 | https://blog.thefactual.com/why-did-texas-lose-power | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/why-did-texas-lose-power">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>On February 16, as many as <a href="https://www.usatoday.com/story/news/nation/2021/02/17/texas-power-grid-why-state-has-its-own-operated-ercot/6782380002/" rel="noopener" target="_blank"><span>4.5 million Texans</span></a>, or about 1 in 6, were without power as the state plunged into record sub-freezing temperatures. For a state that prides itself on energy production and <a href="https://www.foxnews.com/politics/texas-power-outtage-rick-perry-keep-feds-out-of-their-business" rel="noopener" target="_blank"><span>independence</span></a>, the sudden inability to supply enough energy represents a catastrophic failure: people froze, water infrastructure was incapacitated, and <a href="https://www.wsj.com/articles/full-death-toll-from-texas-storm-could-take-months-to-determine-11614107708#:~:text=So%20far%2C%20nearly%2080%20people,according%20to%20the%20Associated%20Press." rel="noopener" target="_blank"><span>at least 80 people</span></a> died. In the aftermath, millions faced <a href="https://www.smithsonianmag.com/smart-news/how-winter-storm-uri-has-impacted-us-180977055/" rel="noopener" target="_blank"><span>water-boil advisories</span></a>, and some Texans have received power bills <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>equivalent</span></a> to what they “would normally pay over three or four years.”</p>
<!--more-->
<p>Finger pointing started almost immediately, with conservative voices <a href="https://abcnews.go.com/Politics/republicans-texas-power-outages-spread-false-claims-green/story?id=75947664" rel="noopener" target="_blank"><span>blaming renewable energy</span></a>, especially wind, and left-leaning voices clarifying that natural gas, the state’s dominant energy source, had <a href="https://www.businessinsider.com/texas-a-majority-of-lost-power-generation-has-been-from-fossil-fuels-2021-2" rel="noopener" target="_blank"><span>lost far more capacity</span></a> than any of the other power sources. Others cast doubt upon ERCOT — the organization that runs the state’s power grid — for a seeming inability to meet demand and protect Texas’s consumers both from the cold and unprecedented prices.&nbsp;</p>
<div><p>What actually happened in Texas? This week, The Factual uses 27 articles from 18 sources across the political spectrum to look for an answer. In the end, the organization of the state’s power resources and grid, rather than the merits of any particular energy source, seem to bear the majority of responsibility.</p></div>
<p><img src="https://lh6.googleusercontent.com/zlayEqnt73ZL31G0fANICz68V9RNU7F1H6CUHpIeoRDlCiv3bOVqUZtJi22V2tO8LcFV5VPRBAyoIrluEeEtyYXLm0JvXwbiqTtwghCq4PvfE5sie3J0k-D9cgSSXEq7HZqs6Q7H" width="726" loading="lazy"></p>

<h4><strong>Was Renewable Energy Responsible?</strong></h4>
<p>The rapid transformation of a climatic crisis into a political battleground began with a <a href="https://www.vox.com/2021/2/17/22287469/fox-news-winter-storm-uri-windmills-ercot-greg-abbott-hannity-carlson" rel="noopener" target="_blank"><span>salvo of accusations</span></a> that renewable energy sources were responsible for the power grid’s collapse. Frozen wind turbines, plastered across some news sites, supposedly bore responsibility.&nbsp;</p>
<p>To be sure, many of the wind turbines in Texas are not winterized, meaning they lack heated or protected elements that permit continued operation in freezing temperatures. As a result, some wind facilities slowed or stopped their production of electricity entirely. Critics missed, however, that wind was only expected to account for less than 10%, or <a href="https://www.statesman.com/story/news/politics/politifact/2021/02/18/texas-power-outages-greg-abbott-dan-crenshaw-fact-check/6791469002/" rel="noopener" target="_blank"><span>6,000 megawatts</span></a> (MW), during winter production, when Texas relies mostly on natural gas. At its lowest point, it looks like about <a href="https://oilprice.com/Energy/Energy-General/Whos-To-Blame-For-The-Texas-Power-Crisis.html" rel="noopener" target="_blank"><span>2,000 MW</span></a> of that went offline, while up to 29,000 MW from natural gas, coal, and nuclear went missing — <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>a third</span></a> of ERCOT’s total production capacity. They also missed that wind’s shortfall was only intermittent, with offshore turbines causing wind generation to <a href="https://www.statesman.com/story/news/politics/politifact/2021/02/19/texas-power-outage-energy-grid-wind-renewable-energy-greg-abbott-fact-check/4500251001/" rel="noopener" target="_blank"><span>exceed expectations</span></a> during periods of the storm.</p>
<p>In short, the missing wind energy only accounted for a small portion of the overall missing capacity that led to Texas’s power outages. Natural gas, coal, and nuclear were to account for 80% of wintertime production and were experiencing similar or greater levels of failure. Afterwards <a href="https://www.forbes.com/sites/joewalsh/2021/02/16/wind-power-isnt-to-blame-for-texas-electricity-crisis/?sh=749255ef21b3" rel="noopener" target="_blank"><span>ERCOT noted</span></a>, for example, that “wind turbine outages have been responsible for less than 13% of Texas’ total power shortages.”&nbsp;</p>
<p>As critics used the incident to ridicule wind technology, and renewables at large, they neglected to mention that wind turbines in other parts of the world, like the <a href="https://www.factcheck.org/2021/02/wind-turbines-didnt-cause-texas-energy-crisis/" rel="noopener" target="_blank"><span>North Sea</span></a>, are designed to function at freezing temperatures and regularly do so without issue. The lack of winterization in Texas represents a choice by Texas’s energy producers, not the type of energy itself, and ERCOT was <a href="https://reason.com/2021/02/22/the-texas-blackout-blame-game/" rel="noopener" target="_blank"><span>well aware</span></a> that only a fraction of wind capacity would be available in winter months.</p>
<div><p>This combination of factors shows that the responsibility for the bulk of Texas’s power outages, instead, lies elsewhere.</p></div>
<h4><strong>Does Blame Fall on Natural Gas, Coal, or Nuclear?</strong></h4>
<p>It’s easy to turn around and then heap blame on <a href="https://www.vox.com/2021/2/20/22292926/texas-high-electric-bills-winter-storm-griddy" rel="noopener" target="_blank"><span>failures in thermal energy sources</span></a>, and especially natural gas, which nominally accounts for <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>around half</span></a> of all power generation in the state. Just as frigid temperatures were negatively impacting wind turbines, they were causing major failures for natural gas, coal, and nuclear energy. Given Texas’s abundance of energy resources, natural gas is pumped up from the ground as needed, but these <a href="https://www.factcheck.org/2021/02/wind-turbines-didnt-cause-texas-energy-crisis/" rel="noopener" target="_blank"><span>pumps failed</span></a>, as did a whole range of equipment needed to keep the system moving. Likewise, coal plants saw their production capacity fall, and a nuclear reactor <a href="https://www.washingtonexaminer.com/policy/energy/how-and-why-a-nuclear-reactor-shut-down-in-texas-cold-snap-when-energy-was-needed-most" rel="noopener" target="_blank"><span>shut down entirely</span></a>.&nbsp;</p>
<p>In a sense, natural gas, as the state’s largest energy provider and experiencing the greatest <a href="https://www.texastribune.org/2021/02/17/abbott-republicans-green-energy/" rel="noopener" target="_blank"><span>reduction in capacity</span></a>, bears more responsibility than any other energy source. But blaming a reliance on fossil fuels for Texas’s troubles is just as short-sighted as blaming renewable energy. During normal times, natural gas is lauded as a reliable, cheap, and abundant energy source, and it is the cornerstone of the state’s ability to supply electricity to nearly 30 million people. Shortcomings of natural gas in terms of contributions to greenhouse gas emissions are clear, as with other fossil fuels, but nothing inherent to fossil fuels made them more or less likely to fail during the record cold temperatures.&nbsp;</p>
<div><p>The failure, rather, seems to be systematic and organizational, not specific to a singular energy source.</p></div>
<h4><strong>The Need for Winterization</strong></h4>
<div><p>The more likely culprit is a lack of winterization standards in Texas's power grid as a whole. Texans are well-known to value independence and freedom from regulation, so much so that their power grid is <a href="https://www.nbcnews.com/news/us-news/texas-set-stage-its-energy-crisis-more-80-years-ago-n1258341" rel="noopener" target="_blank"><span>disconnected from the rest of the U.S</span></a>. The laissez-faire approach has purported benefits, like lower prices, but also limitations.</p></div>
<p><img src="https://lh6.googleusercontent.com/UjEf_OrUCpcjv9od8SzUYcCcE2B2aDKX_Fj-SDKzkr3oqvGM4A6qwzjNgsFsqWQsqsdZSvXWJ2mdNwX4KvD9TxCFWepIbYXLWuRME2MRyDe1pWK-udM1h0YxybN26Xl_E_t-Hyka" width="576" height="288" loading="lazy"></p>
<div><p>Note: Because Texas has its own electrical grid and does not transmit power across state lines, it can avoid regulations like those from the FERC.</p></div>
<p>National bodies, like the Federal Energy Regulatory Commission (FERC), can only make recommendations for how the state should deal with energy issues, including winter preparedness. In the aftermath of cold temperatures in 2011 that caused similar but less severe outages, FERC undertook an investigation of what went wrong, eventually highlighting a <a href="https://www.usatoday.com/story/news/nation/2021/02/18/state-energy-winter-protections-lacking-reports-have-suggested/4490501001/" rel="noopener" target="_blank"><span>lack of winterization and emergency storage</span></a> in natural gas plants as the primary cause. It then provided plans for mitigation strategies to Texas energy producers.</p>
<p>Fast forward 10 years to 2021, and Texas’s energy producers can produce affidavits of winterization, but that concept doesn’t contain specific, enforceable steps at the state level as <span>they do elsewhere</span>. <a href="https://www.dallasnews.com/news/investigations/2021/02/20/texas-tells-power-plants-to-be-winter-ready-but-it-lets-them-decide-how-to-prepare/" rel="noopener" target="_blank">Without such standards</a>, “state utility regulators have issued only three fines ever related to inadequate weather planning by power generators.” This means the natural gas network once again found itself unable to cope with cold temperatures — sufficient gas couldn’t be pumped from the ground due to failing equipment, emergency above-ground reserves were scarce, and <a href="https://oilprice.com/Energy/Energy-General/Whos-To-Blame-For-The-Texas-Power-Crisis.html" rel="noopener" target="_blank"><span>gas distribution</span></a> networks stopped working. The same goes for wind turbines, which <a href="https://www.texastribune.org/2021/02/20/texas-power-grid-winterize/" rel="noopener" target="_blank"><span>weren’t prepared</span></a> to operate in such low temperatures.&nbsp;</p>
<p>In Texas’s open and unregulated market, the desire to produce energy when it is in greater demand, like during the winter, when there are fewer sources of supply, is intended to <a href="https://www.wsj.com/articles/texas-freeze-power-grid-failure-electricity-market-incentives-11613777856" rel="noopener" target="_blank"><span>incentivize winterization</span></a> — producers that continue operation in winter are rewarded by higher prices. Yet as energy producers sought greater profits, the extra cost of winterization precautions was deemed prohibitive, especially given the infrequency of extreme cold weather. In this way, the <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>incentive for profit</span></a>, not something specific to any energy source, seems to be the key to the grid’s lack of preparedness.&nbsp;</p>
<div><p>While there’s no guarantee that improved winterization standards would have forestalled all power outages, they would have at a minimum enabled better outcomes, with less lost capacity, shortened power outages, and probably fewer dead.</p></div>
<h4><strong>A System Meant to Benefit Texans Ended Up Hurting Them</strong></h4>
<p>Adding insult to injury, many Texans now face sky-high energy bills in the aftermath of insufficient and intermittent power, courtesy of the energy market's design. The ERCOT grid allows consumers to choose between <a href="https://www.vox.com/2021/2/20/22292926/texas-high-electric-bills-winter-storm-griddy" rel="noopener" target="_blank"><span>variable and fixed rates</span></a> for energy consumption. A variable rate allows the cost of electricity to follow supply, while a fixed rate means customers pay the same amount regardless of how much electricity is available.&nbsp;</p>
<div><p>The variable-rate system, which can lead to prices as low as <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>2 cents</span></a> per kWh, gave way to unprecedented prices as supply dwindled. This led customers, including single households, to pay as much as <a href="https://theconversation.com/whats-behind-15-000-electricity-bills-in-texas-155822" rel="noopener" target="_blank"><span>$9 per kWh</span></a>, an arbitrary cap imposed by ERCOT. For context, the average retail cost per kWh varies by state but is generally around <a href="https://www.statista.com/statistics/183700/us-average-retail-electricity-price-since-1990/" rel="noopener" target="_blank"><span>11 cents</span></a> and averaged <a href="https://www.eia.gov/electricity/state/" rel="noopener" target="_blank"><span>8.6 cents</span></a> in Texas in 2019, and the average home consumes just under <a href="https://www.eia.gov/tools/faqs/faq.php?id=97&amp;t=3#:~:text=How%20much%20electricity%20does%20an,about%20877%20kWh%20per%20month." rel="noopener" target="_blank"><span>900 kWh per month</span></a>. Had the cap not existed, customers could have paid even higher prices. Energy retailers, such as <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>Griddy</span></a>, warned customers that higher than normal prices were anticipated, but switching companies before the storm proved impossible for most. This led to headlines like “<a href="https://www.businessinsider.com/texas-army-veteran-faces-16000-bill-due-to-rocketing-energy-prices-2021-2" rel="noopener" target="_blank"><span>Texas: Army veteran faces $16,000 bill due to rocketing energy prices</span></a>.”</p></div>
<p><img src="https://lh6.googleusercontent.com/QZt0csXKhNchYumakXv3lGoYYHPaNjVvsmYUdMZUcFbKYnW-eEyGH61Ld-eduvNlf8e0AZA-lBG049GQTloiovIBzAYMlgC8xwedWkMsIodQvkctTJR_1eWvkYIhrRTMIGphwd5E" width="652" loading="lazy"></p>

<p>For some, this failure represents the duplicity of leaving a critical utility up to market forces. In seeking to protect the freedom of energy producers from federal regulation, Texas ultimately ended up <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>curtailing the freedom of everyday Texans</span></a> — for some by making electricity unaffordable, for others by effectively taking away that access, and the freedom to power and heat one’s home, entirely. It’s easy to see overregulation as a burden, but in this instance, there’s a clear rationale for how an absence of regulation made an extreme weather event worse. Indeed, it likely cost some Texans their lives.</p>
<div><p>Now, amid the scrutiny on the system’s lack of regulation, Texans may also be reconsidering the merits of deregulation. An <a href="https://www.wsj.com/articles/texas-electric-bills-were-28-billion-higher-under-deregulation-11614162780" rel="noopener" target="_blank"><span>analysis</span></a> from the <em>Wall Street Journal </em>in the aftermath of the crisis even casts doubt on the purported low costs of such a system, finding that “deregulated Texas residential consumers paid $28 billion more for their power since 2004 than they would have paid at the rates charged to the customers of the state’s traditional utilities.”&nbsp;</p></div>
<h4><strong>Conclusion</strong></h4>
<p>The rapid politicization of Texas’s weather troubles seems on par with the partisan tensions that epitomize the beginning to 2021, …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/why-did-texas-lose-power">https://blog.thefactual.com/why-did-texas-lose-power</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/why-did-texas-lose-power</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277437</guid>
            <pubDate>Fri, 26 Feb 2021 17:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Judge in Google case disturbed that 'incognito' users are tracked]]>
            </title>
            <description>
<![CDATA[
Score 864 | Comments 337 (<a href="https://news.ycombinator.com/item?id=26277396">thread link</a>) | @johncena33
<br/>
February 26, 2021 | https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When Google users browse in â€œIncognitoâ€� mode, just how hidden is their activity? The Alphabet Inc. unit says activating the stealth mode in Chrome, or â€œprivate browsingâ€� in other browsers, means the company wonâ€™t â€œremember your activity.â€� But a judge with a history of taking Silicon Valley giants to task about their data collection raised doubts Thursday about whether Google is being as forthright as it needs to be about the personal information itâ€™s collecting from users.</p>

<p>At a hearing Thursday in San Jose, California, U.S. District Judge Lucy Koh said sheâ€™s â€œdisturbedâ€� by Googleâ€™s data collection practices in a class-action lawsuit that describes the companyâ€™s private browsing promises as a â€œruseâ€� and seeks US$5,000 in damages for each of the millions of people whose privacy has been compromised since June of 2016.</p>

<p>Weighing Googleâ€™s attempt to get the suit dismissed, Koh said she finds it â€œunusualâ€� that the company would make the â€œextra effortâ€� of data collection if it doesnâ€™t use the information to build user profiles or targeted advertising. Google has become a target of antitrust complaints in the last year filed by state and federal officials -- as well as businesses -- accusing it of abusing its dominance in digital advertising and online search. Koh has a deeper history with the company as a vocal critic of its privacy policies. She forced Google in one notable case to disclose its scanning of emails to build profiles and target advertising.</p>

<p>In this case, Google is accused of relying on pieces of its code within websites that use its analytics and advertising services to scrape usersâ€™ supposedly private browsing history and send copies of it to Googleâ€™s servers. Google makes it seem like private browsing mode gives users more control of their data, Amanda Bonn, a lawyer representing users, told Koh. In reality, â€œGoogle is saying thereâ€™s basically very little you can do to prevent us from collecting your data, and thatâ€™s what you should assume weâ€™re doing,â€� Bonn said.</p>

<p>Andrew Schapiro, a lawyer for Google, argued the companyâ€™s privacy policy â€œexpressly disclosesâ€� its practices. â€œThe data collection at issue is disclosed,â€� he said.Another lawyer for Google, Stephen Broome, said website owners who contract with the company to use its analytics or other services are well aware of the data collection described in the suit.</p>

<p>Broomeâ€™s attempt to downplay the privacy concerns by pointing out that the federal court systemâ€™s own website uses Google services ended up backfiring.</p>

<p>The judge demanded an explanation â€œabout what exactly Google does,â€� while voicing concern that visitors to the courtâ€™s website are unwittingly disclosing information to the company. â€œI want a declaration from Google on what information theyâ€™re collecting on users to the courtâ€™s website, and what thatâ€™s used for,â€� Koh told the companyâ€™s lawyers. The case is Brown v. Google, 20-cv-03664, U.S. District Court, Northern District of California (San Jose).</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277396</guid>
            <pubDate>Fri, 26 Feb 2021 17:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto exchange sells Bitcoin for 90% discount, threatens to sue buyers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277252">thread link</a>) | @CoinPM
<br/>
February 26, 2021 | https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/ | <a href="https://web.archive.org/web/*/https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>One of Southeast Asia’s <strong>biggest crypto exchanges</strong> is bracing itself for legal fallout after it suspended thousands of accounts in the wake of a <a href="https://bitpinas.com/cryptocurrency/pdax-suffers-outage-what-happened/" target="_blank" rel="noreferrer noopener">major outage</a> earlier this month.</p>
<p>PDAX users thought they’d hit the jackpot when the platform started selling <a href="https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/" target="_blank" rel="noreferrer noopener">Bitcoin</a> for just $6,000 — <strong>nearly 90% below</strong> its value at the time.</p>
<p>Sadly, it turns out the sale of the century was actually down to a glitch in PDAX’s system. Within 24 hours, the exchange started to lock users out of their accounts.</p>
<p>It even demanded some give the Bitcoin back, <strong>threatening those who refused</strong> with legal action.</p>
<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I also bought some in that glitch but unfortunately pdax demand me to return the withdrawn btc otherwise they will file me a criminal case 😢</p>— Drakeee (@Drakeee31101625) <a href="https://twitter.com/Drakeee31101625/status/1365282105056366592?ref_src=twsrc%5Etfw">February 26, 2021</a></blockquote>
</div></figure>
<p><em>[Read more: <a href="https://protos.com/bitcoin-ethereum-cryptcurrency-exchange-thefts-academic/" target="_blank" rel="noreferrer noopener">Academic proves Bitcoin exchange thefts affect Ethereum — 5 days later</a>]</em></p>
<p>But now PDAX users are meeting legal fire with fire. They say they did nothing wrong, and by losing access to their accounts <strong>the exchange denied customers</strong> the opportunity to <a href="https://www.philstar.com/business/2021/02/25/2080142/pdax-ready-face-lawsuits" target="_blank" rel="noreferrer noopener">make the most</a> of Bitcoin’s latest price surge.</p>
<p>Legal experts working on behalf of affected users reportedly say they <a href="https://www.benzinga.com/markets/cryptocurrency/21/02/19845820/crypto-exchange-asks-customers-to-return-bitcoin-after-selling-it-at-88-discount#bz-campaign-text-middle:~:text=Rafael%20Padilla%2C%20an%20attorney%20representing%20the,it%20cannot%20unilaterally%20reverse%20the%20transactions." target="_blank" rel="noreferrer noopener">have a case</a>.</p>
<p>On the other hand, PDAX argues it’s well within its rights to lock accounts and reverse the transactions, which related to some 2,800 users — as it supposedly <strong>never actually had the crypto</strong> to sell.</p>
<blockquote><p>It’s very understandable that a lot of users will feel upset they were able to buy what they thought an order was there for Bitcoin at very low prices. But unfortunately, the underlying Bitcoins were never in the possession of the exchange, so there’s never really anything there to be bought or sold.</p><cite><em>PDAX CEO Nichel Gaba</em></cite></blockquote>
<p>While the case is strange, there <em>is</em> something of a precedent in this area. Crypto exchange Quoine was <a href="https://www.coindesk.com/singapores-court-of-appeals-rules-quoine-exchange-in-breach-of-contract-in-landmark-crypto-case?fbclid=IwAR2YUxMj3oPpY2w57018DOtfBx_OqkJuUA-L16RQ_ldApaTXwmtlFBRTw9g" target="_blank" rel="noreferrer noopener">found to be in breach of contract</a> when it <strong>reversed seven trades </strong>from 2017 that it claimed were authorised by mistake.</p>
</div>
</div></div>]]>
            </description>
            <link>https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277252</guid>
            <pubDate>Fri, 26 Feb 2021 17:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Application-Wide Panic Handling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277143">thread link</a>) | @lukastyrychtr
<br/>
February 26, 2021 | https://domwillia.ms/panik/ | <a href="https://web.archive.org/web/*/https://domwillia.ms/panik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <nav id="toc">
            <strong>Table of Contents</strong>
            

        </nav>

        <p>A <a href="https://doc.rust-lang.org/std/macro.panic.html">panic</a> in Rust is the final resort when the code reaches an erroneous or impossible state. The stack of the thread it occurred on is unwound, every value that falls out of scope <a href="https://doc.rust-lang.org/reference/destructors.html">dropped</a>, and the thread terminated. This is isolated to that specific thread<sup id="fnref:1"><a href="#fn:1">1</a></sup>, which allows other threads to detect and gracefully handle the error condition by e.g. spawning a new thread to replace it, or logging and exiting cleanly.</p>
<p>In most programs this is pretty useful, but I've been tripped up enough by this behaviour in my <a href="https://github.com/DomWilliams0/name-needed">game engine</a> to warrant implementing an alternate method of panic handling.</p>
<h2 id="all-panics-are-terminal">All panics are terminal</h2>
<p>Ideally, no panics should ever occur. Clearly this isn't possible, so I'm striving for the next best thing - <strong>immediate detection and graceful shutdown</strong>. Any panic on any thread should be treated as a hard error, and the main thread should attempt to save all game data and exit as soon as possible. </p>
<p>This provides the benefit of increased confidence in finding error conditions during testing, especially automated end-to-end tests where the game is run headless with debug asserts enabled. I've been bitten by this many times, when a worker thread panics but the main thread continues on oblivious, exiting cleanly and marking the test as a "success". It can be frustrating to hunt down bugs like these where the error is swallowed and silently breaks things<sup id="fnref:2"><a href="#fn:2">2</a></sup>, as I describe in the section below.</p>
<h2 id="the-pain-of-silent-panics">The pain of silent panics</h2>
<p>My game engine makes heavy use of thread pools to process expensive workloads over several ticks without affecting the frame rate - examples include generating chunks of terrain, or calculating paths for <a href="https://domwillia.ms/devlog3">navigation</a>. The main thread will post work to the thread pool via a <a href="https://doc.rust-lang.org/std/sync/mpsc/">channel</a>, then consume available results each tick, all without blocking. A pseudo-code example:</p>
<div><pre><span></span><code><span>// set up channels</span>
<span>let</span><span> </span><span>(</span><span>request_tx</span><span>,</span><span> </span><span>request_rx</span><span>)</span><span> </span><span>=</span><span> </span><span>channel</span><span>();</span><span></span>
<span>let</span><span> </span><span>(</span><span>result_tx</span><span>,</span><span> </span><span>result_rx</span><span>)</span><span> </span><span>=</span><span> </span><span>channel</span><span>();</span><span></span>

<span>// spawn worker thread</span>
<span>std</span>::<span>thread</span>::<span>spawn</span><span>(</span><span>move</span><span> </span><span>||</span><span> </span><span>{</span><span></span>
<span>    </span><span>while</span><span> </span><span>let</span><span> </span><span>Ok</span><span>(</span><span>req</span><span>)</span><span> </span><span>=</span><span> </span><span>request_rx</span><span>.</span><span>recv</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>// process request (potentially taking a long time)</span>
<span>        </span><span>// and post response back</span>
<span>        </span><span>let</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>do_work</span><span>(</span><span>req</span><span>);</span><span></span>
<span>        </span><span>result_tx</span><span>.</span><span>send</span><span>(</span><span>result</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>}</span><span></span>
<span>});</span><span></span>

<span>// core game loop</span>
<span>loop</span><span> </span><span>{</span><span></span>
<span>    </span><span>// submit work to worker threads</span>
<span>    </span><span>for</span><span> </span><span>chunk</span><span> </span><span>in</span><span> </span><span>required_chunks</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>request_tx</span><span>.</span><span>send</span><span>(</span><span>chunk</span><span>).</span><span>unwrap</span><span>();</span><span> </span><span>// does not block</span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>// consume completed results, again without blocking</span>
<span>    </span><span>while</span><span> </span><span>let</span><span> </span><span>Ok</span><span>(</span><span>res</span><span>)</span><span> </span><span>=</span><span> </span><span>result_rx</span><span>.</span><span>try_recv</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>// ... use result ...</span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>// ...</span>
<span>}</span><span>   </span>
</code></pre></div>


<p>This works swimmingly until something causes a panic in the worker thread. Depending on the exact setup, one or more of the following could happen:</p>
<ul>
<li>✅ The panic causes the <a href="https://doc.rust-lang.org/std/sync/mpsc/struct.Receiver.html">receiving end</a> of the requests channel to disconnect, meaning <code>request_tx.send</code> now returns <code>Err</code> on the main thread<sup id="fnref:3"><a href="#fn:3">3</a></sup>. Panic detected!</li>
<li>✅ The panic causes the sending end of the results channel to disconnect, meaning <code>result_rx.try_recv</code> now returns <code>Err</code> on the main thread. Panic also detected!</li>
<li>✅ Any mutex held by the worker thread is now <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html#poisoning">poisoned</a>, and attempts to lock it from any other thread will fail. Panic still detected!</li>
<li>😧 The panic happens before any channel or mutex is in scope, so the thread dies and takes the request to its grave.</li>
<li>😌 The thread pool notices a worker thread died and spawns a new one in its place.</li>
<li>😩 The panic is unconditional (e.g. a <code>todo!()</code>) and we're now stuck in an infinite loop of thread killing and spawning.</li>
<li>🤬 The IDE locks up from the strain of resolving so many stack traces.</li>
</ul>
<p>I've seen all of these happen, and any of the last 4 are a real pain to either notice or track down. The most amusing is #4; the main thread has requested a chunk of terrain and now waits forever for it, leaving a gaping hole in the world where that terrain should be<sup id="fnref:4"><a href="#fn:4">4</a></sup>.</p>
<p><span><img alt="Screenshot of single missing chunk" src="https://domwilliams0.github.io/images/panik-missing-chunk.png" title="A panic killed the thread before it could finish processing that chunk, so I guess they'll just have to learn to live without it."><span>A panic killed the thread before it could finish processing that chunk, so I guess they'll just have to learn to live without it.</span></span></p>
<p>I've written a small crate to avoid this happening again, which is the whole point of this post.</p>
<p><span><img alt="panik-rs logo" src="https://raw.githubusercontent.com/DomWilliams0/panik-rs/master/panik.jpg" title="I refuse to apologise for this."><span>I refuse to apologise for this.</span></span></p>
<h2 id="panik-rs-to-the-rescue">panik-rs to the rescue</h2>
<p><a href="https://crates.io/crates/panik">panik</a> is a simple wrapper around the standard panic functionality, and does the following:</p>
<ul>
<li>Wraps the application in <code>catch_unwind</code> to handle panics on the main thread</li>
<li>Registers a custom panic hook to keep track of all panics</li>
<li>Exposes functions to query all panics (<a href="https://docs.rs/panik/0.1.1/panik/fn.panics.html"><code>panik::panics</code></a>) and check if a panic has occurred on any thread (<a href="https://docs.rs/panik/0.1.1/panik/fn.has_panicked.html"><code>panik::has_panicked</code></a>)</li>
</ul>
<p>The <a href="https://docs.rs/panik/">docs</a> include some basic examples, but I want to show here how the API fits into the code base it was designed for.</p>
<h3 id="example-in-context">Example in context</h3>
<p>Below is a cut-down snippet from the game engine's <code>main</code>. The game spends its whole runtime inside the context of <code>panik::run_and_handle_panics</code>, which boils down to installing a custom panic hook and a <code>catch_unwind</code>, which catches any panics on the main thread and prevents them from bubbling up to kill the program too soon.</p>
<div><pre><span></span><code><span>// ... initialize game state ....</span>

<span>// run the game inside panik's handler</span>
<span>let</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>panik</span>::<span>run_and_handle_panics</span><span>(</span><span>||</span><span> </span><span>{</span><span> </span><span>do_main</span><span>()</span><span> </span><span>});</span><span></span>

<span>let</span><span> </span><span>exit_code</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>result</span><span> </span><span>{</span><span></span>
<span>    </span><span>None</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span>
<span>        </span><span>// 1 or more panics occurred which have already been</span>
<span>        </span><span>// logged, nothing more to do</span>
<span>        </span><span>1</span><span></span>
<span>    </span><span>}</span><span></span>
<span>    </span><span>Some</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>0</span><span>,</span><span> </span><span>// no panics occurred</span>
<span>};</span><span></span>

<span>// ... optionally use panik::panics() to programatically access</span>
<span>//     panic messages, backtraces etc ...</span>

<span>// ... attempt to save any game data ...</span>

<span>std</span>::<span>process</span>::<span>exit</span><span>(</span><span>exit_code</span><span>);</span><span></span>
</code></pre></div>


<p>Now that panics will be detected by the custom panic handler, we need a way to interrupt the main thread if a panic occurred on different thread, in order to gracefully exit. This is done in two places:</p>
<ul>
<li>During startup, while waiting for the world to be loaded/generated by worker threads</li>
<li>Every tick during gameplay</li>
</ul>
<p>The first was an early cause of annoyance; the game initially requests a radius of terrain around the player's position, then blocks with a timeout until the world is available. While the game is in an early state, there isn't much to do and world generation finishes quite quickly, but if something panics it will sit there and wait until the timeout has elapsed<sup id="fnref:5"><a href="#fn:5">5</a></sup>. That code now looks like this:</p>
<div><pre><span></span><code><span>pub</span><span> </span><span>fn</span> <span>block_until_world_loaded</span><span>(</span><span></span>
<span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span></span>
<span>    </span><span>timeout</span>: <span>Duration</span><span>,</span><span></span>
<span><span>    </span><span>bail</span>: <span>&amp;</span><span>impl</span><span> </span><span>Fn</span><span>()</span><span> </span>-&gt; <span>bool</span><span>,</span><span></span>
</span><span>)</span><span> </span>-&gt; <span>Result</span><span>&lt;</span><span>SlabLocation</span><span>,</span><span> </span><span>TerrainSourceError</span><span>&gt;</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>end_time</span><span> </span><span>=</span><span> </span><span>Instant</span>::<span>now</span><span>()</span><span> </span><span>+</span><span> </span><span>timeout</span><span>;</span><span></span>
<span>    </span><span>loop</span><span> </span><span>{</span><span></span>
<span><span>        </span><span>if</span><span> </span><span>bail</span><span>()</span><span> </span><span>{</span><span></span>
</span><span><span>            </span><span>break</span><span> </span><span>Err</span><span>(</span><span>TerrainSourceError</span>::<span>Bailed</span><span>);</span><span></span>
</span><span><span>        </span><span>}</span><span></span>
</span>
<span>        </span><span>let</span><span> </span><span>this_timeout</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>            </span><span>let</span><span> </span><span>now</span><span> </span><span>=</span><span> </span><span>Instant</span>::<span>now</span><span>();</span><span></span>
<span>            </span><span>if</span><span> </span><span>now</span><span> </span><span>&gt;=</span><span> </span><span>end_time</span><span> </span><span>{</span><span></span>
<span>                </span><span>break</span><span> </span><span>Err</span><span>(</span><span>TerrainSourceError</span>::<span>TimedOut</span><span>);</span><span></span>
<span>            </span><span>}</span><span></span>
<span>            </span><span>let</span><span> </span><span>left</span><span> </span><span>=</span><span> </span><span>end_time</span><span> </span><span>-</span><span> </span><span>now</span><span>;</span><span></span>
<span>            </span><span>left</span><span>.</span><span>min</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>1</span><span>)).</span><span>max</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>3</span><span>))</span><span></span>
<span>        </span><span>};</span><span></span>

<span>        </span><span>// ... block for `this_timeout` and return `Ok(res)`</span>
<span>        </span><span>//     if a result is returned ...</span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</code></pre></div>


<p>The lines of interest are highlighted - a function pointer is passed in which triggers an early exit if it returns true when called with no arguments. The limit on the timeout and the <code>loop</code> mean that <code>bail()</code> will be called periodically. As you've probably guessed, a function that fits that function signature is <code>panik::has_panicked</code>! </p>
<p>The other place this is checked is every tick in the game loop. As soon as a panic is detected the loop is broken with an error:</p>
<div><pre><span></span><code><span>// core game loop</span>
<span>loop</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>panik</span>::<span>has_panicked</span><span>()</span><span> </span><span>{</span><span></span>
<span>            </span><span>debug</span><span>!</span><span>(</span><span>"breaking out of loop due to panics"</span><span>);</span><span></span>
<span>            </span><span>break</span><span> </span><span>Exit</span>::<span>Stop</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>

<span>        </span><span>// ... tick and render ...</span>
<span>}</span><span></span>
</code></pre></div>


<p>That's it! The API is pretty simple and easy enough to integrate into a code base. </p>
<h3 id="before-after-comparison">Before/after comparison</h3>
<p>This is what a panic in a worker thread during world initialisation looked like before. The panic and backtrace is mixed in with other logs, and the game window was unresponsive for 30 seconds before dying.</p>
<div><pre><span></span><code><span>...</span>
<span>  000000 DEBG populating chunk with slabs</span>
<span><span>  00000thread '0wrld-worker-0' panicked at 'intentional panic!!11!', /home/.../name-needed/game/world/src/loader/finalizer.rs:84: 21</span>
</span><span>stack backtrace:</span>
<span><span>DEBG removed 0 nodes in slab range, upper: SlabIndex(4), lower: SlabIndex(-1), removed: 0</span>
</span><span><span>  000000 DEBG added 960 edges and 256 nodes, area: ChunkArea { slab: SlabIndex(1), area: SlabAreaIndex(1) }, nodes: 256, edges: 960</span>
</span><span>   0: std::panicking::begin_panic</span>
<span>   1: world::loader::finalizer::SlabFinalizer&lt;C&gt;::finalize::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>   2: &lt;core::future::from_generator::GenFuture&lt;T&gt; as core::future::future::Future&gt;::poll</span>
<span>   ... lots of frames omitted ...</span>
<span>  45: tokio::runtime::blocking::pool::Spawner::spawn_thread::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.</span>
<span>... 30 seconds later ...</span>
<span>000000 CRIT critical error, error: Timed out</span>
<span>000000 CRIT more detail, error: TimedOut</span>
<span>000000 INFO waiting 2 seconds to allow other threads to finish logging, seconds: 2</span>
<span>000000 INFO exiting cleanly, code: 1</span>
</code></pre></div>


<p>But now, with the power of <code>panik</code>:</p>
<div><pre><span></span><code><span>  000000 DEBG populating chunk with slabs</span>
<span>000000 ERRO handling panic on thread ThreadId(9) (wrld-worker-3): 'intentional panic!!11!'</span>
<span><span>000000 WARN panic occurred in another thread, swallowing unpanicked result: Err(Error(Bailed))</span>
</span><span><span>000000 ERRO 1 threads panicked, count: 1</span>
</span><span>000000 CRIT panic on thread "ThreadId(9) (wrld-worker-3)": "intentional panic!!11!"</span>
<span>   0: panik::register_panic</span>
<span>   1: panik::GlobalStateGuard::init::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>   ... lots of frames omitted ...</span>
<span>  62: __GI___clone</span>
<span>000000 INFO waiting 2 seconds to allow other threads to finish logging, seconds: 2</span>
<span>000000 INFO exiting cleanly, code: 1</span>
</code></pre></div>


<p>The logs are clear and not intermingled, and the game exited immediately. Much better!</p>
<h2 id="watch-out-for-async-runtimes">Watch out for async runtimes</h2>
<p>Since moving my manual thread pools to <a href="https://crates.io/crates/tokio">tokio</a>, panics have become more of a pain, especially unconditional panics when I forget to remove a <code>todo!()</code>. The runtime's behaviour of auto-spawning new threads to replace the dead ones doesn't lead to pretty results, and I'm sure the following log speaks for itself:</p>
<div><pre><span></span><code><span>...</span>
<span>000000 ERRO handling panic on thread ThreadId(7) (wrld-worker-1): …</span></code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://domwillia.ms/panik/">https://domwillia.ms/panik/</a></em></p>]]>
            </description>
            <link>https://domwillia.ms/panik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277143</guid>
            <pubDate>Fri, 26 Feb 2021 17:17:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Documentation Improvements in KDE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277094">thread link</a>) | @ognarb
<br/>
February 26, 2021 | https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/ | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>There was many changes over the last few months in KDE developer
documentation tooling. The hope is to make KDE development easier
to both newcomers but also long-time KDE contributors to use
KDE technologies to build cool stuff.</p><h2 id="api-documentation">Api documentation</h2><p>The tooling for our generated documentation tooling improved. First
of all, KApiDox got a new theme with a cleaner appearance and a
better dark theme. But the improvement goes beyond just theming.</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api.png" data-size="1908x891"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api_hu75ec079396b4d1e999137d12765b0477_152990_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api_hu75ec079396b4d1e999137d12765b0477_152990_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api.png" width="1908" height="891" loading="lazy" alt="API.kde.org new look"></a><figcaption>API.kde.org new look</figcaption></figure><p><a href="https://invent.kde.org/sdk/doxyqml" target="_blank" rel="noopener">Doxyqml</a>, our documentation
bridge between QML and doxygen, got various improvements, thanks
to Olaf Mandel and Lasse Lopperi. Now QML enums are supported and
the lexer/parser got various bug fixes.</p><p>Speaking of QML documentation, the Kirigami API documentation was
improved and now uses more correctly <code>@inherit</code> tags and
<code>@property</code> tags. There is still room for improvements, but the
current state is already a lot better. Most Components are now
showing all their properties correctly and the type of the
property is correct. (<a href="https://invent.kde.org/frameworks/kirigami/-/commit/6ce80224a9fe46216cf47d29458e16f3519ec693" target="_blank" rel="noopener">kirigami!239</a>)</p><p>Another improvement is that the generated Kirigami documentation
now shows more accurate names: e.g. <code>Kirigami.Page</code> instead of
<code>org::kde::kirigami::Page</code>. This makes it easier to read and
navigate the documentation.</p><p>There was also a bit of background work inside KApiDox, Jannet
added support for QDoc, allowing to use QDoc as an alternative
to Doxygen. This might be a better solution for generating
documentation for projects with a lot of QML.</p><h2 id="high-level-documentation">High level documentation</h2><p>Since <a href="https://develop.kde.org/" target="_blank" rel="noopener">develop.kde.org</a> was announced
back in September 2020 just before Akademy, it received a steady
stream of updates. In terms of visuals, Jannet replaced the left
sidebar with a better-looking one.</p><p>A Doxygen integration was also added in the Hugo based website,
allowing to link to the API documentation in an easy way (e.g.
<code>[Kirigami.Page](docs:kirigami2;Page)</code>).</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi.png" data-size="438x211"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi_hu1dd9834c8070fdaaebb60963fde23a42_20357_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi_hu1dd9834c8070fdaaebb60963fde23a42_20357_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi.png" width="438" height="211" loading="lazy" alt="Link to API documentation"></a><figcaption>Link to API documentation</figcaption></figure><p>The Plasma documentation was massively improved. Zren moved his
excellent tutorial about creating Plasma Widgets to
<a href="https://develop.kde.org/docs/plasma/widget/" target="_blank" rel="noopener">/docs/plasma/widget</a>.
I also moved the <a href="https://develop.kde.org/docs/plasma/scripting/" target="_blank" rel="noopener">Plasma Desktop Scripting tutorial</a>
and the <a href="https://develop.kde.org/docs/plasma/theme/" target="_blank" rel="noopener">Plasma Theme Tutorial</a>
from techbase to develop. This was a good occasion to update them to a
more recent version of Plasma since some parts were from the early
days of Plasma 5 and a few bits from KDE4 remained.</p><p>Concerning the Framework documentation, most of the tutorials from
the Framework book, that was written a few years ago to develop.
Same as the Plasma documentation, I used this opportunity to update
the documentation and remove any mentions of deprecated APIS. I
also did the same for most of the old tutorials from <a href="https://techbase.kde.org/" target="_blank" rel="noopener">techbase</a>.</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features.png" data-size="1239x831"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features_huf04e7f133efae172b4c5dc22c5d6a5ed_66521_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features_huf04e7f133efae172b4c5dc22c5d6a5ed_66521_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features.png" width="1239" height="831" loading="lazy" alt="List of features oriented tutorials"></a><figcaption>List of features oriented tutorials</figcaption></figure><p>Tobias Fella imported the old <a href="https://develop.kde.org/docs/d-bus/" target="_blank" rel="noopener">DBus tutorial</a>
from techbase and David Redondo wrote a tutorial about how to
<a href="https://develop.kde.org/docs/sensor-faces/" target="_blank" rel="noopener">create sensor faces</a>
for the new Plasma Monitor.</p><p><img src="https://develop.kde.org/docs/sensor-faces/images/config.png" alt="Custom sensor faces"></p><p>Finally, Clau Cambra wrote a tutorial for getting started in
<a href="https://develop.kde.org/docs/kirigami/" target="_blank" rel="noopener">Kirigami</a>. The tutorial
will guide you into creating a countdown counter using Kirigami
and QML. This work is part of its Season of KDE project.</p><p>If you enjoy my work, you can sponsor me on <a href="https://liberapay.com/Carl" target="_blank" rel="noopener">Liberapay</a>.</p></section><div><h2>Comments</h2><p>You can use your Mastodon account to reply to this <a href="https://linuxrocks.online/@carl/105798477266183469">post</a>.</p><p><a href="https://linuxrocks.online/interact/105798477266183469?type=reply">Reply</a></p></div></div>]]>
            </description>
            <link>https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277094</guid>
            <pubDate>Fri, 26 Feb 2021 17:12:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grouparoo: Declarative Data Sync]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26276917">thread link</a>) | @bleonard
<br/>
February 26, 2021 | https://www.grouparoo.com/blog/declarative-data-sync | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/declarative-data-sync">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent"><div><p>Developers have been using the <a href="https://www.grouparoo.com/" target="_blank" rel="nofollow noopener noreferrer">Grouparoo</a> UI to set up automated data movement from their databases to Mailchimp, Marketo, Salesforce, and <a href="https://www.grouparoo.com/integrations" target="_blank" rel="nofollow noopener noreferrer">more</a>. While having these integrations already written for them saved plenty of time, there was something they missed: their normal developer workflow.</p><p>Grouparoo now supports declarative data models and integrations to continuously sync your data to all of your cloud-based tools. You manage data sync just like you would any other part of your stack. You test the configuration, check it into git, run it on CI, review, merge, and deploy.</p><p>Using the declarative configuration, Grouparoo does the heavy lifting of building profiles from your customer data sources, segmenting them into groups, and syncing the results to destination tools. Everyone wins when engineers can move faster and with more confidence.</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/kQ789gMXJB8?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>Here is the <a href="https://github.com/grouparoo/app-example-config" target="_blank" rel="nofollow noopener noreferrer">example app</a> from the video.</p><h2 id="data-sync-framework"><a href="#data-sync-framework">Data Sync Framework</a></h2><p>If you have developed Node apps before, you will have a pipeline up and running in minutes. The whole app is just a <code>package.json</code> file and the declarative configuration. If you are new to Node, we have lots of helpers to get you going.</p><p>Here is how you declare your pipeline:</p><ul><li><a href="https://www.grouparoo.com/docs/installation#step-2-pick-an-installation-method" target="_blank" rel="nofollow noopener noreferrer">Get</a> our <code>grouparoo</code> command line tool via npm and <code>init</code> a new Grouparoo project</li><li><a href="https://www.grouparoo.com/docs/installation/plugins#installing-a-plugin" target="_blank" rel="nofollow noopener noreferrer">Install</a> plugins for the connections you need (Postgres, Mailchimp, Salesforce, etc.).</li><li>Generate an <a href="https://www.grouparoo.com/docs/config/apps/community" target="_blank" rel="nofollow noopener noreferrer">App</a> with connection information (Postgres database, etc).</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/sources/community" target="_blank" rel="nofollow noopener noreferrer">Source</a> with <a href="https://www.grouparoo.com/docs/config/properties/community" target="_blank" rel="nofollow noopener noreferrer">Properties</a> (id, email, first_name from users table) to create Profiles.</li><li>Generate calculated <a href="https://www.grouparoo.com/docs/config/groups/community" target="_blank" rel="nofollow noopener noreferrer">Groups</a> of Profiles (High Value Users) based on Profile Property values.</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/destinations/community" target="_blank" rel="nofollow noopener noreferrer">Destination</a> and map the data to it (sync email, first_name, and group membership to Mailchimp)</li></ul><p>Now, you can call <code>grouparoo run</code> to test the data <a href="https://www.grouparoo.com/docs/running" target="_blank" rel="nofollow noopener noreferrer">sync</a>, make expectation or snapshot <a href="https://www.grouparoo.com/docs/running/testing" target="_blank" rel="nofollow noopener noreferrer">tests</a>, and <a href="https://www.grouparoo.com/docs/deployment" target="_blank" rel="nofollow noopener noreferrer">deploy</a> your application so it’s always running and looking for new data to sync.</p><h2 id="zooming-out"><a href="#zooming-out">Zooming Out</a></h2><p>Businesses need data in their tools to be effective because success in marketing, sales, and support is data-driven with personalization, segmentation, and timeliness. We want these teams to be empowered to create great customer experiences.</p><p>Unfortunately, integrations are not fun to build and are tricky to get right. There are edge cases around rate limiting and data formatting. Engineers don’t tend to use the tools being integrated, so it’s hard to know what “right” even looks like. There are no clear patterns to follow. Consequently, data sync infrastructure is often brittle and unloved.</p><p>Open source is great because it tends to take hard problems and solve them for everyone. Grouparoo solves the data sync problem by making it 10x easier to build and maintain by allowing developers to stop worrying about the data pipes and focus on declaring the right definition of what is valuable.</p><div><p><img alt="Declaratively sync data to Mailchimp" src="https://www.grouparoo.com/posts/declarative-data-sync/declarative-sync.png" width="600" height="315"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/declarative-data-sync</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276917</guid>
            <pubDate>Fri, 26 Feb 2021 17:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why northern Europe is so indebted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276869">thread link</a>) | @kome
<br/>
February 26, 2021 | https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/ | <a href="https://web.archive.org/web/*/https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="section-5-61"><div><div id="new_columns-6-61"><div id="div_block-7-61"><p><span id="span-26-61">
<p>You might think the US would be world champion of household debt, yet the highest private indebtment has always been in the Nordic countries. Debt, however, takes different forms, writes <strong>Martino Comelli</strong>. In Scandinavia, inclusive welfare systems make debt into an investment. Elsewhere, gerontocratic welfare and consumer credit can become a burden</p>
<h2>Debt and welfare: a trade-off?</h2>
<p>The economic crisis of 2007–2008 put household debt in the spotlight. <strong><a href="https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008">A common narrative</a></strong> was that cheap credit fuelled a house price bubble in the US. The financial industry sold derivatives based on those debts and many European banks who bought those products went belly up, allowing the crisis to spread across the Atlantic.</p>
<p>Debt, and in particular, household debt, has been regarded with suspicion ever since. Many scholars argue that the rise of household debt was caused by welfare retrenchment, suggesting a trade-off between welfare and debt. A lack of welfare was compensated by private leveraging. Other scholars pointed out that many governments were pushing for asset-based welfare – like buying housing as a form of private welfare – encouraged by steadily rising house prices in the years preceding the crash.</p>
<figure><img loading="lazy" width="683" height="776" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png" alt="" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png 683w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1-264x300.png 264w" sizes="(max-width: 683px) 100vw, 683px"><figcaption>Figure 1: Quantity of household debt in OECD countries</figcaption></figure>
<p>Yet empirical data suggests that the welfare-debt trade-off may be mistaken. Curiously, the highest indebtment ratio in the OECD was, and is, in northern European countries such as Denmark, Norway, Sweden and the Netherlands. These are the countries with the most far-reaching welfare programmes, and known to be fiscally responsible. Clearly, the welfare-debt trade-off theory needs a rethink.</p>
<h2>Private debt, public virtues: on the age-orientation of welfare</h2>
<p>Is it, then, a complementary relationship? Generous welfare provides security, encouraging people to borrow more. But this interpretation does not fly either. Many European countries have generous welfare – France for example, has higher social spending than Denmark – but nowhere near the level of household debt of the Nordic countries.</p>
<p><strong><a href="https://doi.org/10.1080/02732173.2021.1875088">My research on the relations between welfare and household debt</a> </strong>offers a novel explanation of the welfare-debt conundrum. There is no trade-off between private debt and welfare, nor is there a complementary relation. What matters is where the welfare money is spent and how. It isn’t necessarily about the quantity of spending, but about its direction.</p>
<blockquote><p>While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need</p></blockquote>
<p>Most welfare spending is concentrated on older generations, particularly retired people. According to <strong><a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">Franco Modigliani</a>'s life-cycle <a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">hypothesis</a></strong>, debt is linked to one's stage in life. People take on debt when young because their income is low but their expenses (housing, children, leisure) high – and they pay this debt off as they age.</p>
<p>Countries that not only provide social help for the elderly, but counterbalance that with spending and services for the young and economically active, tend to have higher private debt (see Figure 2). In particular, countries that spend on education and active labour market policies, and those which offer better protection for people in precarious jobs, have the highest levels of private debt.</p>
<p>Household debt is an unintended consequence of assuring a smoother transition to adulthood. In conservative continental European countries, however, despite high welfare spending, welfare is concentrated mostly on the elderly and on people with stable jobs. This discourages younger generations from taking risks, including mortgage debt.</p>
<figure><img loading="lazy" width="980" height="714" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png" alt="Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png 980w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-300x219.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-768x560.png 768w" sizes="(max-width: 980px) 100vw, 980px"><figcaption>Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries.</figcaption></figure>
<p>Note: Figure 2 illustrates an inverse relationship between the elderly orientation of social spending (EBiSS, on the x axis), and the quantity of household debt as % of net disposable income (on the y axis). The EBiSS is a rate between social spending for the economically active (at the numerator) versus spending oriented toward the elderly (at the denominator). A higher value on the EBiSS index means that a greater share of social spending is going to the elderly.</p>
<h2>Consumer credit? The three worlds of debtfare capitalism</h2>
<p>Most of the debt in OECD countries is mortgage debt. While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need.</p>
<p>If we consider consumer credit, the welfare-debt theory makes sense again. While consumer credit is more the exception than the norm in Europe, and almost absent in the Nordic countries, it is common in Anglo-liberal countries (UK, US and Canada) where it is used by families as a substitute for poor welfare provision.</p>
<figure><img loading="lazy" width="895" height="531" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png" alt="Figure 3. Clusters measures" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png 895w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-300x178.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-768x456.png 768w" sizes="(max-width: 895px) 100vw, 895px"><figcaption>Figure 3. Clusters measures</figcaption></figure>
<p>Figure 3 shows three main patterns of private debt/welfare configurations; what we call debtfare:</p>
<ol>
<li>In the Nordic / youth-oriented model, household debt is high, consumer credit is low, and the rate of young people Not in Education, Employment, or Training (NEET) is very low.</li>
<li>
<p>In conservative European countries such as Germany and Italy, there are a lot of NEETs, welfare is orientated toward the elderly, and there is little household debt or consumer credit.</p>
</li>
<li>
<p>In Anglo-liberal countries such as the UK, US and Canada, consumer credit is high, and so is overall debt. But it is not as high as in the Nordic countries, where the share of NEETs is remarkably high, and most welfare is oriented toward the elderly.</p>
</li>
</ol>
<p>Household financialisation, then, follows different paths and patterns. Both liberal and conservative welfare is gerontocratic, and they have a high level of NEETs, but while the former is oriented toward a market solution to inequality (more debt), the latter discourages any form of risk taking.</p>
<p>So, while paying attention to debt is important, it shouldn’t be the only lesson of the 2008 crisis. Further attention should be paid to the macro-sociological conditions that give debt different meanings: inclusive welfare can make debt into an investment, but gerontocratic welfare can make debt a burden.</p>
</span></p><p>This article presents the views of the author(s) and not necessarily those of the ECPR or the Editors of <i>The Loop</i>.</p><div id="div_block-246-61"><p><img id="image-247-61" alt="" src="https://theloop.ecpr.eu/wp-content/uploads/2020/09/ECPR-tag-icon.svg" loading="lazy"></p></div></div></div></div></section></div>]]>
            </description>
            <link>https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276869</guid>
            <pubDate>Fri, 26 Feb 2021 16:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Integrating Rust and C++ in Firefox]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276846">thread link</a>) | @ibraheemdev
<br/>
February 26, 2021 | https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/ | <a href="https://web.archive.org/web/*/https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication.</em></p>

<p>In 2017 I worked on the <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">Stylo</a> project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine
(“Gecko”). This involved a <em>lot</em> of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a
lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences.</p>

<p>If you’re interested in Rust integrations, you may find <a href="https://www.youtube.com/watch?v=x9acx2zgx4Q">this talk by Katharina on Rust - C++ FFI</a>, and <a href="https://hsivonen.fi/modern-cpp-in-rust/">this blog post by Henri on integrating encoding-rs into Firefox</a> useful as well.</p>

<h2 id="who-is-this-post-for">Who is this post for?</h2>

<p>So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you
want to <em>avoid</em> having integrations as tight as Stylo. Don’t do what we did; make your Rust
component mostly self-contained so that you just have to maintain something like ten FFI functions
for interacting with it. If this is possible to do, you should do it and your life will be <em>much</em> easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go.</p>

<p>That said, sometimes you <em>have</em> to have gnarly integrations, and this blog post is for those use cases.
These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it.</p>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> is probably a better tool for many of the use cases here, though many of the techniques still transfer.</em></p>

<h2 id="what-was-involved-in-stylos-ffi">What was involved in Stylo’s FFI?</h2>

<p>So, what made Stylo’s FFI so complicated?</p>

<p>It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but
these components are still tightly integrated. If you intend to replace a component, you may need to
make a jagged edge of an integration surface.</p>

<p>The style system is more self-contained than other parts, but it’s still quite tightly integrated.</p>

<p>The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like
the following:</p>

<div><div><pre><code><span>&lt;style </span><span>type=</span><span>"text/css"</span><span>&gt;</span>
    <span>body</span> <span>{</span>
        <span>font-size</span><span>:</span> <span>12px</span><span>;</span>
    <span>}</span>
    <span>div</span> <span>{</span>
        <span>height</span><span>:</span> <span>2em</span><span>;</span>
    <span>}</span>
<span>&lt;/style&gt;</span>
<span>&lt;body&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"foo"</span><span>&gt;&lt;/div&gt;</span>

<span>&lt;/body&gt;</span>
</code></pre></div></div>

<p>and turn it into something like:</p>

<ul>
  <li><code>&lt;body&gt;</code> has a <code>font-size</code> of <code>12px</code>, everything else is the default</li>
  <li>the <code>div</code> <code>#foo</code> has a computed <code>height</code> of <code>24px</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">2</a></sup>, everything else is the default. It “inherits” the <code>font-size</code> from <code>&lt;body&gt;</code> as <code>12px</code></li>
</ul>

<p>From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS,
and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read
very cheaply.</p>

<p>Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system
is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to
deal with this impedence mismatch.</p>

<p>Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++
abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re
dealing with persistent state that is accessed by both sides.</p>

<p>To sum up, we have:</p>

<ul>
  <li>Lots and lots of back-and-forth FFI</li>
  <li>Thread safety concerns</li>
  <li>Rust code regularly dealing with nontrivial C++ abstractions</li>
  <li>A need for nontrivial abstractions to be passed over FFI</li>
</ul>

<p>All of this conspires to make for some really complicated FFI code.</p>



<p>I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post.</p>

<h2 id="the-basics-of-bindgen">The basics of bindgen</h2>

<p><a href="https://github.com/rust-lang-nursery/rust-bindgen/">Bindgen</a> is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well.</p>

<p>To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and <a href="https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html">run bindgen on it</a>. For some codebases, doing this once and
checking in the generate file suffices, but if your C++ code is going to change a lot, <a href="https://rust-lang-nursery.github.io/rust-bindgen/tutorial-1.html">run it as a build dependency instead</a>. Beware that this can adversely impact build times, since your Rust build now has a partial
C++ compilation step.</p>

<p>For large C++ codebases, pulling in a single header will likely pull in a <em>lot</em> of stuff. You should <a href="https://rust-lang.github.io/rust-bindgen/allowlisting.html">allowlist</a>, <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklist</a>, and/or mark things as <a href="https://rust-lang.github.io/rust-bindgen/opaque.html">opaque</a> to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further.</p>

<p>Bindgen <a href="https://rust-lang-nursery.github.io/rust-bindgen/cpp.html"><em>does</em> support some C++ features</a> (you may need to pass <code>-x c++</code>). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support <em>all</em> C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens.</p>

<p>Bindgen is <em>quite</em> configurable. Stylo has a <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">script</a> that consumes a <a href="https://searchfox.org/mozilla-central/source/layout/style/ServoBindings.toml">large toml file</a> containing all of the configuration.</p>

<h2 id="cbindgen">cbindgen</h2>

<p>We don’t use <a href="https://github.com/eqrion/cbindgen">cbindgen</a> in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public <code>extern "C"</code> API. It’s also quite configurable.</p>

<h2 id="cxx">cxx</h2>

<p><a href="https://github.com/dtolnay/cxx">cxx</a> is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between <code>&amp;T</code> and <code>T*</code> across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other.</p>

<h2 id="bindgen-aided-c-calling-rust">Bindgen-aided C++ calling Rust</h2>

<p>So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have <em>both</em> bindgen and cbindgen operating near each other on the same codebase.</p>

<p>In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">one file</a>, and are all named <code>Gecko_*</code>. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with.</p>

<p>We also declare the FFI functions defined in Rust that C++ calls in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">another file</a>, named <code>Servo_*</code>. They’re also all <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/glue.rs">defined in one place</a>.</p>

<p>However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/build.rs">autogenerated</a> <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/servo_function_signatures.rs">unit test</a> to ensure the validity of the signatures.</p>

<p>This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us.</p>

<h2 id="type-replacing-for-fun-and-profit">Type replacing for fun and profit</h2>

<p>Using <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklisting</a> in conjunction with the <code>--raw-line</code>/<code>raw_line()</code> flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings <em>referring</em> to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). <code>--raw-line</code> lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types.</p>

<p>Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn).</p>

<p>There are various ways this can be used:</p>

<h3 id="safe-references-across-ffi">Safe references across FFI</h3>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> does this automatically</em></p>

<p>Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it –  could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it.</p>

<p>In Stylo, we have lots of functions like the following:</p>

<div><div><pre><code><span>RawGeckoNodeBorrowedOrNull</span> <span>Gecko_GetLastChild</span><span>(</span><span>RawGeckoNodeBorrowed</span> <span>node</span><span>);</span>
</code></pre></div></div>

<p>which bindgen translates to:</p>

<div><div><pre><code><span>extern</span> <span>"C"</span> <span>{</span>
    <span>fn</span> <span>Gecko_GetLastChild</span><span>(</span><span>x</span><span>:</span> <span>&amp;</span><span>RawGeckoNode</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;&amp;</span><span>RawGeckoNode</span><span>&gt;</span><span>;</span>   
<span>}</span>
</code></pre></div></div>

<p>Using the <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">bindgen build script</a> on a provided <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindings.toml#648-671">list of borrow-able types</a>, we’ve told bindgen that:</p>

<ul>
  <li><code>FooBorrowedOrNull</code> is actually <code>Option&lt;&amp;Foo&gt;</code></li>
  <li><code>FooBorrowed</code> is actually <code>&amp;Foo</code></li>
</ul>

<p><code>Option&lt;&amp;Foo&gt;</code> <a href="https://doc.rust-lang.org/nomicon/repr-rust.html">is represented …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/</a></em></p>]]>
            </description>
            <link>https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276846</guid>
            <pubDate>Fri, 26 Feb 2021 16:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Game Quotes – The best Quotes from your favorite Video Games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26276805">thread link</a>) | @Kovah
<br/>
February 26, 2021 | https://game-quotes.com/en | <a href="https://web.archive.org/web/*/https://game-quotes.com/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                        <div>
                    <div data-is-blurred=""><div>
        <p>V about a Cyberpsycho:</p>
        <p>Guess even pneumatic arms can't lift morale in a toxic workplace.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Takemura:</p>
        <p>Sushi in Night City...? Sounds like suicide. And somehow disrespectful.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V, Ozob:</p>
        <p>V: Doesn'T it bother you?<br>Ozob: Waht?<br>V: The grenade. You know, the one on your face?<br>Ozob: Eh, you get used to it. I just gotta be carefull not to pull the pin when I wanna pick my nose.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Takemura:</p>
        <p>The wider the smile, the bigger the lies.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Both Sides, now Quest Description:</p>
        <p>You ever hear the saying "No good deed goes unpunished"? You hold your hand out to someone, you get bitten. You help a poor soul in need, you get fleeced for all you're worth. Save someone's life? Fill in the blank.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>A tech corporation acting unethically? Sounds out of character, but let's investigate anyway.</p>
            </div>
    </div>
                            <div><p>Get rid of password stress. Forever. <a href="https://www.tkqlhce.com/click-100347502-13868703">With NordPass</a>.</p>
    <p>Store passwords in a single place and log in to your favorite websites with a click. With NordPass, access your login credentials on any device, even when you’re offline.</p></div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>I'll give you the bad news first: One of your operatives has been kidnapped. Also, there's no good news.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>There it is. Time to do your "destroying-other-people's-property" thing.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Player, Bagley:</p>
        <p>Player: You're telling me that a gambling addict turned down free money? It doesn't sum up.<br>Bagley: You're right. A gambling addict making a bad life choice? Ooh, the mystery! You had better talk to the friend if you want to crack this one.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>So he tried to take on a criminal organization with his bare hands, and got himself in trouble?<br>My, who could have seen that coming.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>You lived! But you will die someday. Best to make peace with that now.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny to Alt:</p>
        <p>What, smoking after sex not Zen enough for you? We gotta rewrite "The Art of War", too?</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>The Hard Reset Approacheth:</p>
        <p>The boys have prepared everything and found me a lamb. Blood will course through the fiberoptics, swirling and blending with the digital, opening the gates of the abyss. Death within arm's reach, the metallic taste of his scythe on my tongue, I will tug at the tangled cables of Fate. A hard reset, a blue screen, a brain reformatted... I'm ready. Luck be with me.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny:</p>
        <p>Corpo or not, without chrome we all look like the same idiotic, bullet-riddled sacks of meat.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V:</p>
        <p>Didn't go through hell and back just to stand in front of a door.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Meredith Stout:</p>
        <p>Sometimes two people find themselves at the wrong place at the right time.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Review "Bloody Bout VII" - What went wrong:</p>
        <p>Just when we thought Macroware was done putting out unfinished games, we get this piping hot plate of spaghetti code. Frankly, I don't even know where to start. From the "story mode" which feels like it was cobbled together from the half-baked ideas of six writers working in different time zones, to the non-intuitive tutorials, to the ridiculous lag that had me up making a fresh cup of coffee between each punch, and finally to the head-scratching localization foul-ups. (Honestly, the dialogues make no sense in any language. What the hell were they originally written in? Swiss?)</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>01110100 01100101 01110011 01110100 - test:</p>
        <div>
            <p>11000101 10000001 01100001 01110011 01101001 01100011 01100101 00100000 01110000 01101111 01111010 01100100 01110010 01100001 01110111 01101001 01100001 01101010 11000100 10000101 00100000 01110111 01101001 01101100 01101011 01101001</p>
<p>Łasice pozdrawiają wilki</p>
<p>Weasels salute the wolves</p>

        </div>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Max Payne:</p>
        <p>The sun went down with practiced bravado. Twilight crawled across the sky, laden with foreboding. I didn’t like the way the show started. But they had given me the best seat in the house. Front row center.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Max Payne:</p>
        <p>They were all dead. The final gunshot was an exclamation mark to everything that had led to this point. I released my finger from the trigger. And then it was over.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny to V:</p>
        <p>Not the brightest bulb on stage, are ya?</p>
            </div>
    </div>
                                <div data-is-blurred="1"><div>
        <p>V, Padre:</p>
        <p>V: So, Padre. You think Jackie's looking don upon us... from up there?<br>Padre: I believe he has met God, stood before him.<br>V: That's it?<br>Padre: I don't know if God left the meeting happy, but I'm pretty certain Jackie did.</p>
                    </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V citing Ernest Hemingway:</p>
        <p>"When you go to war as a boy, you have a great illusion of immortality. Other people get killed, not you... Then, when you are badly wounded the first time, you lose that illusion."</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Saburo Arasaka:</p>
        <p>I have found that people lie, most often deceiving themselves. Not so the dead...<br>The dead are so very, very loud. And yet, lying is not in their nature.<br>It its so... humbling - to listen to the dead speak.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Rogue, Johnny:</p>
        <p>Rogue: Johnny, remember the plan?<br>Johnny: Get the payload on the elevator, arm it, let gravity do its thing. Explosion rocks the foundation, tower crumbles - chaos, screaming, roll credits.</p>
            </div>
    </div>
                            <nav role="navigation" aria-label="Pagination Navigation">
        

        <div>
            <p>
                    Showing
                    <span>1</span>
                    to
                    <span>25</span>
                    of
                    <span>471</span>
                    results
                </p>

            
        </div>
    </nav>

    </div>
                </div></div>]]>
            </description>
            <link>https://game-quotes.com/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276805</guid>
            <pubDate>Fri, 26 Feb 2021 16:52:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[American Sign Language as a medium for poetry]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276773">thread link</a>) | @throw_away
<br/>
February 26, 2021 | https://jacket2.org/commentary/american-sign-language-medium-poetry | <a href="https://web.archive.org/web/*/https://jacket2.org/commentary/american-sign-language-medium-poetry">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
 <div>
    <div>
            <div>
                    <figure><img src="https://jacket2.org/sites/jacket2.org/files/imagecache/wide_main_column/asl.jpg" alt=" Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (" title=" Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (Jessica Munyon)"><figcaption> Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (Jessica Munyon)</figcaption></figure>        </div>
        </div>
</div>
<div><p><em>for Joseph Castronovo &amp; Edward S. Klima, in memoriam</em></p><p>  [The great breakthrough resulting from a new signing poetry in Deaf Culture has been to call into question a poetics in which orality &amp; sounding are assumed to be the foundational bases of <em>all</em> poetic expression. That revelation goes back three decades &amp; more, recently &amp; notably presented in <em><a href="http://www.ucpress.edu/books/pages/9424.php">Signing the Body Poetic: Essays on American Sign Language Literature</a></em>, ed. by Dirksen L. Bauman, Jennifer L. Nelson, &amp; Heidi M. Rose (University of California   Press, 2006).&nbsp;Still closer to the present is an ASL-oriented web site, <em><a href="http://deafjam.org/links.html">Deaf Jam</a></em>, dedicated to a documentary film of that name, from which the first of the comments, below, is taken. The other two notes presented here represent my own early attempts to bring the poetry of sign into the ethnopoetics that I was promoting in the 1970s &amp; 1980s. They also coincide in a startling way with the exploration of an outsider poetry that has been one of the themes of <em>Poems &amp; Poetics </em>– a poetry distanced enough from the mainstream as to effect substantially our ideas about the nature of poetry itself. (J.R.)]</p></div>

<div><p><strong>THE SILENT LANGUAGE</strong><strong><br> </strong>“Pain” <em>for Joe Castronovo</em></p><p>  two fingers,<br> pointing,<br> nearly touch</p><p>  matching the pulse inside<br> the skull<br> a figure “8” explodes</p><p>  over the temples,<br> gentle movements of the mind<br> of words in air</p><p>  in silence:<br> do I learn to speak you?<br> can you <em>hear</em><em><br> </em><br> the way the lines weave,<br> barely<br> moving from the touch</p><p>  to vanish<br> as sounds do<br> writing frees itself</p><p>  from object-<br> hood<br> at last</p><p>  (1) ASL POETRY is a performance art form utilizing body language, rhythm and movement to create a three dimensional pictorial equivalent to oral poetry. The similarity of hand-shapes can act as alliteration, and using the same hand-shape repetitively works as rhyme. Visual Vernacular (a term and technique originated by Bernard Bragg) involves cinematic concepts. The technique involves references to close-ups, wide shots, images dissolving into other images as well as "cutting" back and forth between characters to show different points of view on a scene.</p><p>  <strong>HISTORY: From 1880 to 1960, American Sign Language Was Suppressed In The Schools And Went Underground, Until Statistics Showed That The Suppression Of Sign Language Was Detrimental To Learning For The Deaf.</strong><strong><br> </strong><br> Signed poetry grew out of a tradition of playing with the language in Deaf clubs throughout the country, where deaf individuals and their families and friends would congregate for entertainment and to socialize.</p><p>  ASL poetry has been described "as a kind of writing in space... a language in motion, and, like oral poetry, truly inseparable from its realization in performance." (Edward S. Klima and Ursula Bellugi, "Poetry Without Sound,” 1983)</p><p>  *******</p><p>  Translation for ASL poetry into a written or oral form involves crossing modalities. In ASL poetry the body is the text. It exists in performance or through a video recording, not on paper. Rhyming schemes are based on visual elements such as facial expression, movement, locations of the signs, and hand shapes. Therefore an oral or written translation of an ASL poem can only be an approximation of what is being expressed.</p><p>  (2) Regarding Ameslan [American Sign Language] poetry, you might check the<br> anthology <em>Symposium of the Whole</em> (edited by myself &amp; Diane Rothenberg) for the article "Poetry without Sound" by Edward S. Klima and Ursula Bellugi. Bellugi has done terrific work in this area &amp; early contacted me on the relation of signing poetry to the way in which I and others had been approaching oral poetry in the course of doing (so called) "total translation." I then published this piece in my magazine, <em>New Wilderness Letter</em> (a successor to the earlier <em>Alcheringa Ethnopoetics</em>) with my very strong sense that what was involved touched on a dimension of poetry that made pure oralism inadequate, however much we had then been (or continued to be) committed to a speech model. I made an attempt (around 1976/77) to work out an experimental approach to a total translation from Ameslan, collaborating with the deaf poet Joe Castronovo, who was himself a native signer. But circumstances got in the way &amp; we never followed through on it, although since then I've come on the work of performance poets like Peter Cook &amp; Kenny Learner composing &amp; performing in ASL &amp; have been hoping to see how much further it would go.</p></div>

<div><p>(3) POETRY WITHOUT SOUND. Even in its early, tentative stages, the signing poetry emerging as an aspect of the "culture of the deaf" challenges some of our cherished preconceptions about poetry and its relation to human speech. Ameslan (American Sign Language) represents, literally, a poetry without sound and, for its practitioners, a poetry without access to that experience of sound as voice that we've so often taken as the bedrock of all poetics and all language. In the real world of the deaf, then, language exists as a kind of writing in space and as a primary form of communication without reference to any more primary form of language for its validation. It is in this sense a realization of the ideogrammatic vision of a Fenollosa -- "a splendid flash of concrete poetry" -- but an ideogrammatic language truly in motion and, like oral poetry, truly inseparable from its realization in performance. (Ethnopoetic analogues -- for those who would care to check them out -- include Hindu and Tantric mudras, Plains Indian and Australian Aborigine sign languages, and Ejagham [southeastern Nigerian] "action writing": a history of human gesture languages that would enrich our sense of poetry and language, should we set our minds to it.) // The reader may also want to relate this piece to recent discourse about "written-oral dichotomies, etc., but the revelation of Ameslan, in that sense, isn't a denial of the powers of oral poetry but the creation of its possible and equally impermanent companion in performance. (J.R., from <em>Symposium of the Whole</em>, 1983)</p><p>  [See also the entry “<a href="http://poemsandpoetics.blogspot.com/2008/08/uncollected-poems-3-silent-language.html">Uncollected Poems (3): ‘The Silent Language’ with a note on poetry &amp; signing</a>” in <em>Poems &amp; Poetics</em>, August 30, 2008. And for those who want to pursue this further, a relevant online resource is <em><a href="http://dsdj.gallaudet.edu/">The Deaf Studies Digital Journal</a></em>, edited by Ben Bahan and Dirksen Bauman, with postings primarily in American Sign Language.]</p></div>
<p><span>July 20, 2015</span>
        </p> <!-- end of older_and_newer -->
    
        
  </div></div>]]>
            </description>
            <link>https://jacket2.org/commentary/american-sign-language-medium-poetry</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276773</guid>
            <pubDate>Fri, 26 Feb 2021 16:50:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real Items Turns Physical Shirts into Digital Clothing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276519">thread link</a>) | @expherience
<br/>
February 26, 2021 | https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing | <a href="https://web.archive.org/web/*/https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span>Have you ever wanted to wear your game character's clothes? Maybe you cosplay and enjoy looking like your favorite character.</span></p>
<p><span>I know you've tried looking like your Roblox character in real life. Don't deny it.&nbsp;</span></p>
<p><span>Well, what if you can stop copying your avatar's clothes and have it match YOU instead?</span></p>
<p><span>This merger between the physical and digital world creates what is known as "Phygitals." This is exactly what Real Items is working towards. Our team of dedicated developers and designers has integrated the digital universe and fashion into one platform.&nbsp;</span></p>
<p><span>That's right, you can easily access the Roblox version of your new fashion haul using the Real Items platform. All you have to do is scan the QR code on the clothes to collect the NFT. <a href="https://realitems.shop/collections/100-authentic-marketplace/products/the-future-is-phygital-roblox-avatar">Check out this Phygital shirt in our shop.</a></span></p>

<p><span><img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/phygital_scan_480x480.jpg?v=1614178842" alt=""></span></p>
<p><span><i><span><span>Phygital shirt powered by Real Items technology. Simply scan the QR code on the physical shirt to acquire your digital Roblox clothing.</span></span></i></span></p>




<p><b>What is Phygital?</b></p>
<p><span>Phygital is about creating a new dimension of ecosystems between the brand and consumer. It is a convergence of technologies that bridge the digital and physical worlds with the purpose of unlocking unique business capabilities and creating engaging interactive experiences for enterprises and consumers. Introducing a physical t-shirt that can be worn digitally is one of many aspects of the phygital experience.</span></p>
<p><span>The phygital experience also extends to the gaming industry. A great example of this is Nintendo’s Amiibo products. Amiibos are wireless communication figurines. These collectible toys are shaped like Nintendo characters and can interact and transfer data in and out of their supported game software. By simply tapping the Amiibo to the game, players can immediately enjoy new characters, modes, and other in-game perks.</span></p>
<p><b>Uniquely secure</b></p>
<p><span>Real Items takes the phygital experience a step further by ensuring the security of information. In a recent speech by Homeland Security Secretary Alejandro Mayorkas, he stated that federal agents had seized over 11 million fake N95 masks intended for frontline healthcare workers throughout the nation. Such threats of counterfeit PPEs have motivated Real Items to trace the origin and prove Tricol Clean KN95 masks' authenticity.</span></p>

<p><img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/real_items_mask_480x480.jpg?v=1614015789" alt="Real Items verified KN95 mask with smart label"></p>
<p><span><i><span><span><a href="https://realitems.shop/collections/100-authentic-marketplace/products/vechain-kn95-masks">Real Items verified mask</a> comes with a smart label and a one-time pin for two-factor authentication.</span></span></i></span></p>
<p><span>&nbsp;</span><span><br>Aside from KN95 masks, Real Items technology also traces<a href="https://tastebluemountaincoffee.com/"> JACRA certified Jamaican Blue Mountain (JBM) coffee,</a> the Queen of England's favorite and one of the most expensive coffee in the world. Each pack of authentic JBM coffee comes with a <a href="https://realitems.shop/blogs/news/what-are-industry-4-0-smart-labels">Real Items smart label</a> in the form of a QR code. The Real Items smart label is tracked using Industry 4.0 technology, so it can never be counterfeited or tampered with.</span></p>

<p>&nbsp;<img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/JBM_coffee_8a47b0ca-ab05-4786-836d-4cc18fbe9e43_480x480.jpg?v=1614016266" alt="Real Items verified Jamaican Blue Mountain Coffee"></p>
<p><span><i><span><span><a href="https://tastebluemountaincoffee.com/collections/100-jamaica-blue-mountain-no-1-coffee">Authentic JBM coffee</a>&nbsp;secured with Real Items technology. Use promo code "realitems" to get 15% off every purchase.</span></span></i></span></p>

<p><span>With a proven and secure technology in place, Real Items hopes to see this contribute to improving various industries. The Phygital shirt on Roblox is just our first step towards bringing fashion's phygital experience to the gaming scene. Who knows, there might come a time when your Fortnite character gets to wear your favorite pajamas while you're beating noobs left and right. </span><i><span>Winner winner, chicken dinner.&nbsp;&nbsp;</span></i></p>
<p><span>If you create or sell unique clothes and would like to see them on your Roblox character, connect with our dedicated team </span><a href="https://realitems.io/contact-blockchain-company.html"><span>here</span></a><span>. Or you can join in the community conversation in </span><a href="https://discord.com/invite/9yANdjcVYA"><span>Discord</span></a><span>.</span></p>
<p><span>Cheers to the future of gaming, cosplay, fashion, and mixed reality.</span></p>
      </div></div>]]>
            </description>
            <link>https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276519</guid>
            <pubDate>Fri, 26 Feb 2021 16:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke: The extensible editor for structured binary data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26276516">thread link</a>) | @mnabipoor
<br/>
February 26, 2021 | http://jemarch.net/poke.html | <a href="https://web.archive.org/web/*/http://jemarch.net/poke.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jemarch.net/poke.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276516</guid>
            <pubDate>Fri, 26 Feb 2021 16:30:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid career change – from cruise ship cleaner to developer]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26276390">thread link</a>) | @Pete-Codes
<br/>
February 26, 2021 | https://www.nocsdegree.com/cleaner-developer-covid-career-change/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/cleaner-developer-covid-career-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Aldhair made a career change due to Covid. He became a web developer by learning to code with <a href="https://scrimba.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=nocsdegree_email#join">Scrimba</a>, an online learning platform. Before, Aldhair was working as a cleaner on cruise ships. This interview tells you how Aldhair learned to code, his tips for self-taught web developers and how he got his first job. Enjoy!</p><h2 id="hey-so-can-you-introduce-yourself">Hey, so can you introduce yourself?</h2><p>Hi, I’m Aldhair Escobar, I’m from Mexico and currently living in Veracruz, MX. Currently, I’m working as a Developer for Client Solutions at Scalero, My main duty is building HTML Email Templates for clients, apart from that there are some “inside” projects where I’m using Node JS and even Electron JS to try things out. The company is based on San Francisco so it’s a remote position and I’m loving it a lot. Previously, I have worked as a Tax advisor for almost 4 years, and as a cleaner at a cruise ship.</p><h2 id="why-did-you-learn-to-code">Why did you learn to code?</h2><p>Well, as I said before, I was working as a Tax advisor and spending a lot of time and energy without getting paid enough so I decided to start learning English (You can see that I am still learning it), this language opened some doors so I submitted an application to Royal Caribbean International as a cleaner on a cruise ship (which got me a better salary than my last job).</p><p>The idea to work as a cleaner was to have some experience in that industry and improve my English skills, at the same time I was saving some money.</p><p>When I was on the ship, I applied to some jobs but they didn’t allow me to have an interview (you need a second contract in the company so you can apply to another position), and I was thinking on return to the ship and apply to a better position with a better salary and then COVID happened…</p><p>Fortunately while on the ship I thought about learning some new skills after finishing my contract (e.g English for business, code, or maybe to buy a franchise).</p><p>I decided to start learning to code because I was curious about it and had some business ideas that required it.</p><h2 id="how-did-you-start-learning-to-code">How did you start learning to code?</h2><p>I started with some courses in my native language for around 1 month but I did not like them. I realized I was able to understand English resources so I began with FreeCodeCamp and did the first web development certification module, along with that I found an Udemy course called “The Complete Web Development Bootcamp” by Angela Yu ($10) and things started to make sense.</p><p>So if I can make a timeline could be like this:</p><p>April – FreeCodeCamp (Free), “The Complete Web Development Bootcamp” by Angela Yu ($10).</p><p>May – Full Academy Intro (Free), Full Academy prep (It was Free)</p><p>June – Continued with the courses above, building some projects. (I also tried some new courses that did not like)</p><p>July – Building projects in Frontendmentor, youtube video courses (JS, CSS), Started in Scrimba with a <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">React Course</a> (Free).</p><p>August – “<a href="https://scrimba.com/learn/frontend?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Frontend Developer Career Path</a> Scrimba ($19 Monthly), “21 Days Challenge “Conquering Responsive Layouts” by Kevin Powell (Free), Frontendmentor projects.</p><p>September – <a href="https://scrimba.com/learn/responsive?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Responsive Web Design Bootcamp</a> (Scrimba), Building projects for my portfolio.</p><p>October – <a href="https://scrimba.com/learn/designbootcamp?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">UI Design Bootcamp</a> (Scrimba), Building Projects and continuing with the Frontend Career Path (Scrimba).</p><p>November – FullStackOpen Part 0 and Part 1 (Free), (Finished Frontend Career Path), Started Practicing about Interviews (Scrimba has <a href="https://scrimba.com/learn/reactinterview?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">a module about it</a>), Applied for jobs, I got an interview.</p><h2 id="what-made-you-decide-to-learn-to-code-with-scrimba">What made you decide to learn to code with Scrimba?</h2><p>I was curious about the platform because of this option to modify the code directly on the screen and the mini browser so I decided to take the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a> and I just loved it.</p><p>It is so interactive! They have amazing teachers! , you are writing code the whole course and that is something that I like about their courses, there are many challenges and repetition is the key! (And I love the “spaced repetition” system).</p><p>Apart from that, I like to hear someone explaining a concept and I like when they use images or diagrams to show something, so I realized that Scrimba was created for me 😀</p><h2 id="what-courses-did-you-do-with-scrimba">What courses did you do with Scrimba?</h2><p>I started with the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a>, and then I decided to get the subscription because I wanted to take some Bootcamps and the Frontend Developer Career Path, so I paid $19 per month until finishing the Path.</p><p>The advantage is that you have access to everything with the subscription and maybe in the FrontendCareerPath there’s a module that is also part of a Bootcamp so then you can finish the Bootcamp and get the individual certificate while you continue with the “main” (FrontendCareerPath) course.</p><p>I loved the Path because they are putting together all the things that are going to help you to get hired.</p><p>With Scrimba I learned a lot of JavaScript and CSS and also improved my &nbsp;ReactJS knowledge, the challenges and projects helped me to build my projects that I was going to use in my portfolio.</p><h2 id="how-did-you-get-your-first-entry-level-developer-job">How did you get your first entry level developer job?</h2><p>I always had this idea to have my GitHub profile with everything I was building, together with a “nice” CV because you know… without any experience or degree, you need to show something…</p><p>For that reason, I had my GitHub profile with almost every project I was building, a CV, and a simple portfolio website and started applying for jobs that I was interested in; I sent four applications and then got the opportunity to have an interview from one of those submissions.</p><p>Scrimba has a module dedicated to interviews and some challenges about it so it helped me with my confidence.</p><p>I was nervous because I was so interested to get the job in that company and I got some questions like “What did you learn in that course (Frontend Developer Career Path - Scrimba)?” “Why did you change careers?” Why did you go to the ship (my last job)? “The best characteristic a leader can have...” The best attitude of an employee”, Am I willing to relocate?”.</p><p>After that interview, I had three more interviews (same company), did a test (Wonscore), and built a small project with HTML, CSS and Jinja Template Engine (I learned a little bit of python to get this done).</p><p>So after 812 hours of learning and this interview process I got an offer!!</p><h2 id="what-does-a-typical-day-as-a-software-developer-look-like-for-you">What does a typical day as a software developer look like for you? </h2><p>My main duty is building Email Templates, so I get my ticket with its handoff and I start building the template with old HTML and CSS, apart from that, for instance, last week I was testing some stuff with Selenium WebDriver and Selenium IDE, and this week I am building a small desktop app with ElectronJS.</p><p>So it depends on the day, if there are a lot of templates or not then I do something else. I love what I am doing and everything is better than I was expecting.</p><h2 id="do-you-have-tips-for-people-who-want-to-learn-to-code-without-doing-a-degree">Do you have tips for people who want to learn to code without doing a degree?</h2><p>If I needed to start again, I would do things slightly different, for instance, I would start with 2 weeks of watching a lot of YouTube videos about web development, frontend, backend, stacks, languages, and also some videos that gave you the “roadmap” and all that kind of things.</p><p>After that, you will know what you don’t know and what you want to do, maybe you want to build websites or desktop apps, so you will see exactly the language that you need to learn.</p><p>Then, the most important thing, in my opinion, is to learn how you like to acquire information. Do you prefer books, video or audio? Or just the exercises without video or audio like FreeCodeCamp? It’s really important to know this because you need to search for resources that will work for you (because you prefer it).</p><p>I realized I was spending time on some resources that I didn’t like a lot so that was the main reason I decided to test Scrimba (and it worked!!)</p><p>Only with those first steps, you are going to save you a lot of time so now you can focus on the resources that you chose.</p><p>Always build stuff, it’s going to be a disaster, It won’t look good and that’s great! You can always return and fix it 😉.</p><p>I encourage you to use a “Pomodoro app” (I used “forest”) so you can keep track of your journey and see how much time you are spending, this is going to help you to push yourself and gives you extra motivation.</p><h2 id="what-are-your-career-goals-for-the-future">What are your career goals for the future?</h2><p>The idea is to get familiar with my new job, this is my first time working remotely, in tech, in a startup so it is taking time, and after a few months I want to return to build personal projects, I have some ideas and maybe I will try to build a SaaS product. In short, I want to get used to working in this field and keep pushing myself.</p>
            </div></div>]]>
            </description>
            <link>https://www.nocsdegree.com/cleaner-developer-covid-career-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276390</guid>
            <pubDate>Fri, 26 Feb 2021 16:20:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI/ML needs a key-value store, and Redis is not up to it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276177">thread link</a>) | @LexSiga
<br/>
February 26, 2021 | https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div id="ron_db"><h2>‍<strong>The rise of key-value stores as online feature stores.&nbsp;</strong></h2><p>Online feature stores are the data layer for operational machine learning models - the models that make online shopping recommendations for you and help identify financial fraud. When you train a machine learning model, you feed it with high signal-to-noise data called features. When the model is used in operation, it needs the same types of features that it was trained on (e.g., how many times you used your credit card during the previous week), but the online feature store should have low latency to keep the end-to-end latency of using a model low. Using a model requires both retrieving the features from the online feature store and then sending them to the model for prediction.&nbsp;</p><p>Hopsworks has been using NDB Cluster as our online feature store from its first release. It has the unique combination of low latency, high availability, high throughput, and scalable storage that we call LATS. However, we knew we could make it even better as an online feature store in the cloud, so we asked one of the world’s leading database developers to do it - the person who invented NDB, Mikael Ronström. Together we have made RonDB, a key-value store with SQL capabilities, that is the world’s most advanced and performant online feature store. Although NDB Cluster is open-source, its adoption has been hampered by an undeserved reputation of being challenging to configure and operate. With <a href="https://www.rondb.com/?utm_source=rondb" target="_blank">RonDB</a>, we overcome this limitation by providing it as a managed service in the cloud on AWS and Azure.<strong>‍</strong></p><h3><strong>Requirements for an Online Feature Store</strong>‍</h3><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/60364af8c8f5d47b1f1f70ce_graph_white.png" loading="lazy" alt=""></p></figure><p>The main requirements from a database used as an online feature store are: low latency, high throughput for mixed read/write operations, high availability and the ability to store large data sets (larger than fit on a single host). We unified these properties in a single muscular term <strong>LATS</strong>:</p><p><a href="https://www.rondb.com/?utm_source=rondb" target="_blank">‍<strong>LATS</strong>: low <strong>L</strong>atency, high <strong>A</strong>vailability, high <strong>T</strong>hroughput, scalable <strong>S</strong>torage.&nbsp;</a></p><p>RonDB is not without competition as the premier choice as an online feature store. To quote Khan and Hassan from DoorDash, it should be a low latency database:&nbsp;</p><p><a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/?utm_source=rondb" target="_blank">“latency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower.”&nbsp;</a></p><p>To that end, Redis fits this requirement as it is an in-memory key-value store (without SQL capabilities). Redis is open source (BSD Licence), and it enjoys popularity as an online feature store. Doordash even invested significant resources in increasing Redis’ storage capacity as an online feature store, by adding custom serialization and compression schemes. Significantly, similar to RonDB, it provides sub-millisecond latency for single key-value store operations. There are other databases that have been proposed as online feature stores, but they were not considered in this post as they have significantly higher latency (over one order-of-magnitude!), such as DynamoDB, BigTable, and SpliceMachine.</p><p>As such, we thought it would be informative to compare the performance of RonDB and Redis as an online feature store. <strong>The comparison was between Redis open-source and RonDB open-source</strong> (the commercial version of Redis does not allow any benchmarks). In addition to our benchmark, we compare the innards of RonDB’s multithreading architecture to the commercial Redis products (since our benchmark identifies CPU scalability bottlenecks in Redis that commercial products claim to overcome).<br></p><h2>Benchmark: RonDB vs Redis</h2><p>In this simple benchmark, I wanted to compare apples with apples, so I compared open-source RonDB to the open-source version of Redis, since the commercial versions disallow reporting any benchmarks. In the benchmark, I deliberately hobble the performance of RonDB by configuring it with only a single database thread, as Redis is <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“a single-threaded server from the POV of command execution”</a>. I then proceed to describe the historical evolution of RonDB’s multithreaded architecture, consisting of three different generations, and how open-source Redis is still at the first generation, while commercial Redis products are now at generation two.</p><p>Firstly, for our single-threaded database benchmark, we performed our experiments on a 32-core Lenovo P620 workstation with 64 GB of RAM. We performed key-value lookups. Our experiments show that a single-threaded RonDB instance reached around 1.1M reads per second, while Redis reached more than 800k reads per second - both with a mean latency of around 25 microseconds. The throughput benchmark performed batch reads with 50 reads per batch and had 16 threads issuing batch requests in parallel. Batching reads/writes improves throughput at the cost of increased latency.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6037dae7ff678a83e8eaf1a8_performance.jpg" loading="lazy" alt=""></p></figure><p>On the same 32-core server, both RonDB and Redis reached around 600k writes per second when performing SET for Redis and INSERT, UPDATE or DELETE operations for RonDB. For high availability, both of those tests were done with a setup using two replicas in both RonDB and in Redis.<br></p><h3><strong>Low latency</strong></h3><p>We expected that the read latency and throughput of RonDB and Redis would be similar since both require two network jumps to read data. In case of updates (and writes/deletes), Redis should have lower latency since an update is only performed on the main replica before returning. That is, Redis only supports asynchronous replication from the main replica to a backup replica, which can result in data loss on failure of the main node. In contrast, RonDB performs an update using a synchronous replication protocol that requires 6 messages (<a href="https://www.amazon.com/MySQL-Cluster-7-5-Inside-Out/dp/9176998142/utm_source=rondb" target="_blank">a non-blocking version of two-phase commit</a>). Thus, the expected latency is 3 times higher for RonDB for writes.&nbsp;<br></p><h3><strong>High Throughput</strong></h3><p>A comparison of latency and throughput shows that RonDB already has a slight advantage in a single-threaded architecture, but with its third-generation multithreaded architecture, described below, RonDB has an even bigger performance advantage compared to Redis commercial or open-source. RonDB can be scaled up by adding more CPUs and memory or scaled out, by automatically sharding the database.&nbsp; As early as 2013, we developed a benchmark with NDB Cluster (RonDB’s predecessor) that showed how <a href="http://mikaelronstrom.blogspot.com/2015/03/200m-reads-per-second-in-mysql-cluster.html?utm_source=rondb" target="_blank">NDB could handle 200M Reads per second</a> in a large cluster of 30 data nodes with 28 cores each.&nbsp;<br></p><h3><strong>High Availability</strong></h3><p>The story on high availability is different. A write in Redis is only written to one replica. The replication to other replicas is then done asynchronously, thus consistency can be seriously affected by failures and data can be lost. An online feature store must accept writes that change the online features constantly in parallel with all the batched key reads. Thus handling node failures in an online feature store must be very smooth.<br></p><p>Given that an online feature store may need to scale to millions of writes per second as part of a normal operation, this means that a failed node can cause millions of writes to be lost, affecting the correctness and quality of any models that it is feeding with data. RonDB has transactional capabilities that ensure that transactions can be retried in the event of such partial failures. Thus, as long as the database cluster is not fully down, no transactions will be lost.<br></p><p>In many cases the data comes from external data sources into the online Feature Store, so a replay of the data is possible, but an inconsistent state of the database can easily lead to extra unavailability in failure situations. Since an online feature store is often used in mission-critical services, this is clearly not desirable.<br></p><p>RonDB updates all replicas synchronously as part of writes. Thus, if a node running the transaction coordinator or a participant fails, the cluster will automatically fail over to the surviving nodes, a new transaction coordinator will be elected (non-blocking), and no committed transactions will be lost. This is a key feature of RonDB and has been tested in the most demanding applications for more than 15 years and tested thousands of times on a daily basis.<br></p><p>Additionally it can be mentioned that in a highly available setup, in a cloud environment RonDB can read any replica and still see the latest changes whereas Redis will have to read the main replica to get a consistent view of the data and this will, in this case, require communicating across availability zones which can easily add milliseconds to latency for reads. RonDB will automatically setup the cluster such that applications using the <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud?utm_source=rondb" target="_blank">APIs will read replicas that are located in the same availability zone</a>. Thus in those setups RonDB will always be able to read the latest version of the data and still deliver data at the lowest possible latency. <strong>Redis setups will have to choose between delivering consistent data with higher latency or inconsistent data with low latency in this setup.</strong><br></p><h3><strong>Scalable Storage</strong></h3><p>Redis only supports in-memory data - this means that Redis will not be able to support online Feature Stores that store lots of data. In contrast, RonDB can store data both in-memory and on-disk, and with support for up to 144 database nodes in a cluster, it can scale to clusters of up to 1PB in size.<br></p><h3><strong>Analysis: Three Generations of Multithread Architectures</strong></h3><p>For our single-threaded benchmark, we did not expect there to be, nor were there, any major differences in throughput or latency for either read or write operations. The purpose of the benchmark was to show that both databases are similar in how efficiently they use a single CPU. RonDB and Redis are both in-memory databases, but the implementation details of their multithreaded architectures matters for scalability (how efficiently they handle increased resources), as we will see.&nbsp;<br></p><p>Firstly, <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“Redis is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed.”</a> For our use-case of online feature stores, it is decidedly non-trivial to partition a feature store across multiple redis instances. Therefore, commercial …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276177</guid>
            <pubDate>Fri, 26 Feb 2021 16:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke 1.0 released: an interactive, extensible editor for binary data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26275860">thread link</a>) | @matt_d
<br/>
February 26, 2021 | http://www.jemarch.net/poke | <a href="https://web.archive.org/web/*/http://www.jemarch.net/poke">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jemarch.net/poke</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275860</guid>
            <pubDate>Fri, 26 Feb 2021 15:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Catalog of resources related with Oberon programming language]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26275553">thread link</a>) | @lproven
<br/>
February 26, 2021 | https://oberon.org/en | <a href="https://web.archive.org/web/*/https://oberon.org/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><a href="https://oberon.org/ru"><img src="https://oberon.org/ru.png" alt="ru"></a>
<a href="https://oberon.org/uk"><img src="https://oberon.org/uk.png" alt="uk"></a>
<a href="https://oberon.org/en"><img src="https://oberon.org/en.png" alt="en"></a>
<a href="https://oberon.org/de"><img src="https://oberon.org/de.png" alt="de"></a>
</p>

<div><p><img src="https://oberon.org/oberon.png" alt="OBERON.ORG"></p><p><img src="https://oberon.org/title.png"></p></div>



<p>
OBERON.ORG project unites projects related to programming languages Oberon, Oberon-2, Active Oberon, Modula-2/3, Oberon-07 and Component Pascal (Blackbox Oberon).


</p>





<p><h2 id="history">
Historical materials
</h2></p>

<div>
<h3>
Niklaus Wirth website
</h3>
<p><a href="https://inf.ethz.ch/personal/wirth">inf.ethz.ch/personal/wirth</a></p><p>
Niklaus Wirth is the author of the Oberon programming language. Together with Jürg Gutknecht, he developed the Oberon operating system, giving rise to the technological direction of Oberon languages and tools.
</p>
</div>

<div>
<h3>
One of the first pages about Oberon in Russian
</h3>
<p><a href="http://www.uni-vologda.ac.ru/oberon">www.uni-vologda.ac.ru/oberon</a></p><p>
Sergey Zalmanovich Sverdlov about the main features of Oberon and its application for education.
</p>
</div>

<div>
<h3>
Educational portal about N. Wirth's visit to Russia
</h3>
<p><a href="http://oberon2005.oberoncore.ru/">oberon2005.oberoncore.ru</a></p><p>
The site was created after Niklaus Wirth's visit to Russia in 2005. The core of the site is work on the history and development of programming languages of its authorship.
</p>
</div>

<div>
<h3>
Project Оberon 2013
</h3>
<p><a href="http://www.projectoberon.com/">www.projectoberon.com</a></p><p>
Repeating by Niklaus Wirth, Jürg Gutknecht and Paul Reed of the Oberon project for FPGA
</p>
</div>

<div>
<h3>
Oberon Day in Russia
</h3>
<p><a href="https://oberoncore.ru/oberonday">oberoncore.ru/oberonday</a></p><p>
The event brings together developers who use Oberon-family systems in their practice, and interested listeners. Every year, experts representing fundamental science (high energy physics, biophysics), strategic industries (Rosatom), the industry of control systems (APCS, unmanned aerial vehicles), small innovative business (development of software systems for various purposes) make reports. Also in the center of attention are the problems of IT education, from grade 5 to specialized higher, and the key to their solution, developed by the Informatics-21 project. The mission of the seminar, besides the exchange of experience between the participants, is the broadcast of IT education in the industry and in the field of education.
</p>
</div>

<p><h2 id="education">
Educational materials
</h2></p>

<div>
<h3>
Educational project "Informatics-21"
</h3>
<p><a href="http://www.inr.ac.ru/~info21">www.inr.ac.ru/~info21</a></p><p>
Under the leadership of Fyodor Tkachev, the project coordinates the efforts of specialists in science, education, the aerospace industry and the IT industry to streamline the teaching of programming and computer science based on the achievements of Science.
</p>
</div>

<div>
<h3>
Component Pascal in School Computer Science Course
</h3>
<p><a href="https://inf.1sept.ru/article.php?ID=200800100">inf.1sept.ru/article.php?ID=200800100</a></p><p>
Article by A.S. Ilyina and A.I. Popokov in the magazine "September First". “Teaching programming based on Component Pascal / Blackbox started experimentally in Russia in 2002. The most positive experience accumulated to date, both personal and colleagues, allows us to recommend this environment for mass use in schools and universities."
</p>
</div>

<div>
<h3>
Open wikipedia on languages and projects in the Oberon language
</h3>
<p><a href="http://wiki.oberon.org/">wiki.oberon.org</a></p>
</div>





<div>
<h3>
The site is dedicated to the Oberon family of programming languages
</h3>
<p><a href="https://way.oberon.org/">way.oberon.org</a></p>
</div>





<div>
<h3>
BlackBox Component Builder for Windows
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
Blackbox is a free and open source programming environment for the Component Pascal language, developed by the Swiss company Oberon Microsystems. The environment supports dynamic loading of modules (compiled into machine code) and garbage collection, i.e. provides its own component object model. Writing, compiling, executing, testing can be done inside an integrated environment, which greatly increases the productivity of the programmer. Blackbox is an operating environment (a kind of micro-OS) that runs on top of a regular OS. This operating environment can be included in whole or in part in the final application (along with the compiler), allowing this application to be easily extended and rebuilt on the fly.
</p>
</div>

<div>
<h3>
Cross Platform Blackbox
</h3>
<p><a href="https://blackbox.oberon.org/download">blackbox.oberon.org/download</a></p><p>
A cross-platform version of Blackbox for Windows, GNU / Linux, OpenBSD and FreeBSD is published on the site. A system of open publishing of extensions is also being developed.
</p>
</div>

<div>
<h3>
O7 compiler for microcontrollers with ARMv{6,7E}-M architecture
</h3>
<p><a href="https://github.com/aixp/O7">github.com/aixp/O7</a></p><p>
The compiler is distributed in open source, along with a set of useful modules, which are combined into a Micro subsystem. These modules store register addresses, controller initialization procedures, templates for transferring data via the UART protocol, and much more. The Mobx subsystem contains sample programs for several microcontrollers.
</p>
</div>





<div>
<h3>
MultiOberon
</h3>
<p><a href="https://github.com/dvdagaev/Mob">github.com/dvdagaev/Mob</a></p><p>
Oberon compiler with syntax constraint support. Supports three backends: BlackBox x86, Ofront for C translation, and LLVM. Can be used from Blackbox or command line.
</p>
</div>



<div>
<h3>
"Visual" or Online Oberon
</h3>
<p><a href="https://online.oberon.org/">online.oberon.org</a></p><p>
Visual is a tool for creating interactive educational and scientific models. The project aims to disseminate knowledge and teach programming.
</p>
</div>

<div>
<h3>Free Oberon</h3>
<p><a href="https://free.oberon.org/">free.oberon.org</a></p><p>
Turpo Pascal style IDE for Windows and GNU/Linux.
</p>
</div>









<div>
<h3>Astrobe</h3>
<p><a href="http://astrobe.com/">astrobe.com</a></p><p>
Oberon-07 compiler for microcontrollers
</p>
</div>





<div>
<h3>
Herschel
</h3>
<p><a href="https://herschel.oberon.org/">herschel.oberon.org</a></p><p>
Direct Component Pascal compiler for x86-64 architecture and Blackbox framework.
</p>
</div>


<div>
<h3>
YaOS — Russian translation of the A2 operating system (in development)
</h3>
<p><a href="https://gitlab.com/budden/ja-o-s">https://gitlab.com/budden/ja-o-s</a></p><p>
The YaOS project is a copy (fork) of the A2 operating system, written in the "ETH Oberon" language. The project started in 2019 and managed to make progress in the following areas: translation of source texts into Russian, expanding Unicode support, expanding documentation, improving developer tools, changing the language to improve reliability.
</p>
</div>










<p><h2 id="communities">
Communities
</h2></p>

<div>
<h3>
OberonCore Project
</h3>
<p><a href="https://oberoncore.ru/">oberoncore.ru</a></p><p>
The project brings together users and developers of oberon systems and languages.
</p>
</div>

<div>
<h3>
BlackBox Framework Center
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
The international volunteer organization "Blackbox Component Frame Development Center" was created after the official announcement of Oberon microsystems inc. about publishing Blackbox under BSD 2-clause license and ending official support for Blackbox environment. The center took over the correction of known and newly discovered defects, the addition of innovations, the release and publication of new versions of Blackbox for OS Windows.
</p>
</div>






<p><h2 id="boards">
Forums
</h2></p>







<div>
<h3>
Chat with thematic channels
</h3>
<p><a href="https://chat.oberon.org/">chat.oberon.org</a></p><p>
Thematic communication on the RocketChat software platform.
</p>
</div>






<!--
<div class='item'>
<h3>

</h3>
<a href=http://oberspace.org>oberspace.org</a>
<p>

</p>
</div>
-->

<p><h2 id="video">
Video about Oberon
</h2></p>











<p><h2 id="repos">
Repositories
</h2></p>

<div>
<h3>
Component Pascal Collection
</h3>
<p><a href="http://www.zinnamturm.eu/">www.zinnamturm.eu</a></p><p>
A collection of different subsystems for Blackbox that contains source code examples, tools, utilities, math and graphics libraries, and many other applications. There are also helpful simple examples for tutorials. Here you will find algorithms and solutions for common computer programming problems.
</p>
</div>






<p>
end of catalog
</p><p>

For information on updating and supplementing the information in the directory, as well as if you need a third-level domain for the project, — <a href="mailto:iadenisov %D0%90%D0%A2 oberon.org" onmouseover="this.href = 'mailto:Иван Денисов '+base64_decode('PGlhZGVuaXNvdkBvYmVyb24ub3JnPj9zdWJqZWN0PQ==')+'About oberon.org'">write a letter</a>.

</p><p>
The site runs on an http server developed by Blackbox.
</p>

</div></div>]]>
            </description>
            <link>https://oberon.org/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275553</guid>
            <pubDate>Fri, 26 Feb 2021 15:15:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lam: An actor-model VM for WebAssembly and native]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26275408">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----d7939362e1b8--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div></div><p id="3d04">An interview with its creator, Leandro Ostera.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3040/1*ZA5-hKa-yYGz8FX-kmZh9g.png" width="1520" height="450" srcset="https://miro.medium.com/max/552/1*ZA5-hKa-yYGz8FX-kmZh9g.png 276w, https://miro.medium.com/max/1104/1*ZA5-hKa-yYGz8FX-kmZh9g.png 552w, https://miro.medium.com/max/1280/1*ZA5-hKa-yYGz8FX-kmZh9g.png 640w, https://miro.medium.com/max/1400/1*ZA5-hKa-yYGz8FX-kmZh9g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ZA5-hKa-yYGz8FX-kmZh9g.png?q=20"></p></div></div></div><figcaption>Source: <a href="https://abstractmachines.dev/" rel="noopener">https://abstractmachines.dev/</a></figcaption></figure><p id="a84d">Here, at NAMT, we are in love with the Actor Model.<br> Within this paradigm, the basic units of computation are called actors. There is no shared state between them, instead, they interact via message passing. This has the advantage that actors become trivial to paralellize (in Erlang, an actor is called a <em>process</em>) and errors became easier to handle.</p><p id="3a04">The actor model is a concurrency p<span id="rmm">a</span>radigm created by Carl Hewitt in 1973 with the goal of making the task of writing concurrent programs simpler. It is based on the idea of actors, entities that can only send, receive and process messages. By reducing the amount of shared state it reduces the need of locks for synchronization. There exists several battle-tested implementations of the Actor Model such as Erlang/OTP, Akka (Scala/Java) and Orleans (C#).</p><p id="b028">In this interview, we chat with Leandro Ostera, the founder of Abstract Machines. Ostera is working on LAM, The Little Actor Machine, an embeddable virtual machine for the actor model that runs native or compiles to WebAssembly.</p><p id="32e1"><em>The questions for this interview were thought by Juan Pablo Amoroso, Javier Chatruc &amp; Federico Carrone. Joaquín Centeno and Juan Bono wrote the introduction and edited the article.</em></p></div></div></section><section><div><div><p id="d09c"><strong>Tell us a bit about your project lab, Abstract Machines. What kind of work do you do?</strong></p><p id="22fa">I started Abstract Machines with a single goal in mind: build tools that would help me think more clearly.</p><p id="9e03">Right now what I do think about the most is writing software. I think typed languages help me think clearly, so I’m building Caramel, an OCaml for the BEAM. I also think that understanding the program that runs your programs is fundamental to thinking clearly about the quality of what you build, so I’m building LAM, an actor-model VM.</p><p id="c436"><strong>LAM’s tagline is “A Little Actor Machine that runs on Native and WebAssembly”. Could you give us a brief overview of the actor system?</strong></p><p id="dca4">The original name was Leandro’s Abstract Machine. Like Prolog’s WAM was named after Warren, Warren’s Abstract Machine, and the early Erlang VM was JAM after Joe’s Abstract Machine. But Little I think it’s a much better name overall: LAM should be small, tiny even.</p><p id="6bf0">The actor system it implements is in spirit very close to Erlang’s take on the actor model — processes with mailboxes, message passing across them, fair scheduling through reduction counting. There’s a few more things in the roadmap, like process linking and monitoring. Overall, if you have worked with Erlang or Elixir before, you should feel right at home with LAM.</p><p id="e673"><strong>What is the motivation behind LAM? Why build a BEAM alternative?</strong></p><p id="05cb">LAM’s mission is to make Actor concurrency available everywhere by providing a specified, lightweight runtime. Think LuaVM meets the Actor Model. I’ve always liked the LuaVM, there’s a certain elegance to it that I find very appealing.</p><p id="f192">One of the reasons to build an alternative is that the BEAM is rather large, and the implementation is the only real spec. [Erik Stenmans’ Beam Book] or [kvavks Beam Wisdoms] have tried to document it, but without an official effort to produce a JVM style spec (like the one you can get in a bookshelf), it’s unlikely we will have a reliable drop-in alternative any time soon.</p><p id="ec18">So I thought I could instead make a new thing that could learn from both the LuaVM and the BEAM. At 35 instructions, LAM can run an interesting amount of Erlang programs, in fact I’d like most code that runs on the BEAM to be bytecode-translatable to run on LAM. Not all of it tho, and we’ll see what doesn’t make the cut.</p><p id="a6a3"><strong>One of LAM’s targets is WebAssembly. Is there any alternative actor system for the web? How do they compare with LAM?</strong></p><p id="3b25">Yes, there are plenty! A most promising one these days is Lunatic, but on the Erlang side of things, there’s the up-and-coming Lumen.</p><p id="871a">Most of the rest are libraries for building actor applications in other languages, like how Actix lets you use Actors in Rust. Lumen in particular is more of a compiler + runtime that brings Erlang down to LLVM and gives you this single optimized executable.</p><p id="7414">LAM by contrast is a higher level VM: you feed it bytecode (spawn, send, receive, call, make list, etc), and as it runs it, side-effects happen through FFI/Bindings depending on the platform.</p><p id="a15e">Around LAM there’s a tiny compilation toolchain that takes that bytecode, lowers it to something that can be run a little faster, and packs it <em>with the VM</em> in a single binary that is optimized for a specific platform.</p><p id="3bf4">Because the VM is tiny, and the FFIs are pluggable, it’s straightforward to compile it to WebAssembly and run your bytecode there.</p><p id="e3b3"><strong>The documentation mentions that one of the goals is to support Erlang/OTP’s supervision tree structure. Would this allow more reliable/resilient web UIs, capable of gracefully recovering from errors?</strong></p><p id="848e">Absolutely! I expect it to let you build even more natural and flexible UIs. After all the “event” model fits perfectly: when process Button receives message Click, do this/that.</p><p id="b621">The main problem is that preemptive scheduling makes it impossible to guarantee certain processes will have enough time to make stuff like animations run smoothly. But I’m borrowing the idea of dirty schedulers and considering introducing Greedy Processes instead, that can either request upfront how much time they need, or just run to completion. Definitely interesting to experiment with hard-real time scheduling as well.</p><p id="69ed"><strong>What are some interesting use cases for LAM?</strong></p><p id="0aac">Off the top of my head, there’s 2. The first one is perhaps why I want it the most these days: fast cli tools. Write ’em in Erlang/Elixir/Caramel, ships as a single binary.</p><p id="1e96">The second one will have the largest impact on how we build for the BEAM: actually writing full-stack applications in a single BEAM Language.</p><p id="df52">Write your backend in Elixir and run it on the BEAM, write your frontend in Elixir too but run it on LAM. And it doesn’t have to be a web-based app, it could be an actual native GUI application too.</p><p id="0045"><strong>Why write it in Rust? Is the Rust-WASM toolchain mature enough to target WASM reliably with LAM?</strong></p><p id="aa48">I love Rust. It’s a good language and the learning curve has certainly taught me a lot about how to build software. I think the Rust-wasm toolchain is pretty mature these days too.</p><p id="9104"><strong>Besides performance (LAM compiles AOT), what will be the advantages of LAM over the BEAM?</strong></p><p id="479e">Really the AOT stuff I can’t consider an advantage — I don’t expect LAM to be fundamentally faster than the BEAM, especially after the BeamJIT work. Nor do I expect it to compete in speed with Lumen.</p><p id="fc63">What I see as an advantage is that LAM is being built to have a Specification and to be Embeddable.</p><p id="2cd6"><strong>WebAssembly lacks a garbage collector and the BEAM is a GC environment. How does LAM tackle this?</strong></p><p id="059d">There is a wasm-gc spec in the works, and some other folks are waiting on it as well (like the OCaml-wasm efforts).</p><p id="52f6">But since WebAssembly isn’t the only LAM target, we’ll have to embed a GC anyway. I expect it to work very closely to the BEAMs (per process collections, ref counted binary strings, etc). I haven’t looked so deeply into this, but I have a chunky book waiting for me (The Garbage Collection Handbook).</p><p id="26bf"><strong>Is this a solo project or are you looking for contributors? If you are looking for contributors, how should they get started (first issues, roadmap, etc)?</strong></p><p id="48d2">So far it is just me, but I’d love to build a friendly and welcoming community around it. At the moment I’ve been focused on getting this vertical slice of the project up and running so it becomes easier to do some horizontal scoping: how far along are we with the specification, or how much of the BEAM bytecode can we support via translation.</p><p id="2ea9">There’s tons of work to do starting at the design level. From figuring out how to build the right layers to FFIs across platforms (native, wasi, web), to how to optimize the main emulator loop to crunch the bytecode as fast as possible, to GC and bundling the final binaries, to writing the spec and the manual.</p><p id="967a">Formalizing the spec is a big topic where I hope I can get some interest from the TLA+ community to guide me into doing justice to both TLA+ and LAM.</p><p id="e341">LAM could use help across the board, so if you’re reading this please tweet at me (<a href="https://twitter.com/leostera/" rel="noopener">@leostera</a>)!</p><p id="ee97"><strong>For our last question, in general, what are your favorite books, articles or resources for programmers?</strong></p><p id="889c">I think that if you asked me this a year ago I would have regurgitated a bunch of books that I should list here, but that didn’t really further my understanding. There’s a lot of reference material that is just terrible for learning, because its meant to be a compendium of information rather than a pedagogically written introduction to a subject.</p><p id="8aa0">For example, Types and Programming Languages by Benjamin Pierce is deemed <em>the ultimate</em> reference for type stuff. But I learned more about the nature of typing by reading The Little Typer. After that it was a lot easier to get into the right headspace to understand what Pierce wanted me to get out of the book.</p><p id="b1fa">So if you’re getting into a subject, don’t rush for the ultimate reference, and find something written to teach you <em>the core</em> of the subject. Then the rest becomes a little easier.</p><p id="35f0">Virtual Machines by Iain D. Craig, and Formal Development of a Network-Centric RTOS have been very useful in working with LAM. Hillel Wayne’s Practical TLA+, and Alloy’s Software Abstraction books have been really good to get a better grip on how to specify systems as well. Of course <a href="http://lamport.azurewebsites.net/tla/book.html" rel="noopener">“Specifying Systems” by Lamport</a> has been a good reference as well.</p><p id="17c4">Some books that have had a massive impact in how I think and communicate have (unsurprisingly) nothing to do with computers. Like Umberto Eco’s “6 Walks in the Fictional Woods” (focused on how to create narratives and rhetoric) or Mandelbrot’s “The (Mis)Behavior of Markets” (a historical account of how fractal geometry describes better the financial markets). Nonetheless, they’ve helped shape the way I think and I’ve come out a better programmer.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2/0*nPPWbd4-7dJavk5P.gif" width="1" height="1" data-old-src="https://miro.medium.com/freeze/max/60/0*nPPWbd4-7dJavk5P.gif?q=20"></p></div></div></figure></div></div></section></div>]]>
            </description>
            <link>https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275408</guid>
            <pubDate>Fri, 26 Feb 2021 15:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steampipe v0.2.0 New AWS Multi-Region Queries and Query Caching]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26275128">thread link</a>) | @51stpage
<br/>
February 26, 2021 | https://steampipe.io/blog/release-0-2-0 | <a href="https://web.archive.org/web/*/https://steampipe.io/blog/release-0-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>What is Steampipe?</h2><p>SQL is an expressive and powerful language for asking questions of structured data. Steampipe, an open-source project from <a href="https://turbot.com/">Turbot</a>, enables cloud pros (e.g. software developers, operations engineers and security teams) to query their favorite cloud services with SQL.</p><p>The heart of Steampipe is an intuitive command line interface (CLI) that solves the challenges encountered when asking questions of cloud resources and services. Traditional tools and custom scripts that provide visibility into these services are cumbersome, inconsistent across providers and painful to maintain. Steampipe provides a consistent, explorable and interactive approach across IaaS, PaaS and SaaS services.</p></div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  region</span><span>,</span><span> </span></p><p><span>  instance_state </span><span>as</span><span> state</span><span>,</span><span> </span></p><p><span>  instance_type </span><span>as</span><span> </span><span>type</span><span></span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------+-----------+
| region    | state   | type      |
+-----------+---------+-----------+
| eu-west-1 | running | t3.medium |
| eu-west-2 | running | m5a.large |
| us-east-1 | running | t3.large  |
+-----------+---------+-----------+
    </pre></div></div></div></div></div><p>From the moment you have a question about your cloud, Steampipe is already at work giving you structured tables to formulate that question as SQL and execute it against your live cloud APIs. Steampipe v0.2.0 delivers an even faster response to those questions with our preview of <a href="https://steampipe.io/#blazing-fast-query-response-with-new-query-caching">query caching</a>, and enables you to do more work in each query with our new <a href="https://steampipe.io/#aws-multi-region-queries-with-steampipe">multi-region</a> and <a href="https://steampipe.io/#connection-configuration-management-in-steampipe">connection configuration</a> features.</p><h2 id="aws-multi-region-queries-with-steampipe">AWS multi-region queries with Steampipe</h2><p>Starting with version <code>0.2.0</code> of the Steampipe CLI and version <code>0.5.0</code> of the <a href="https://hub.steampipe.io/plugins/turbot/aws">Steampipe AWS Plugin</a> you can perform multi-region queries that execute in parallel against all AWS regions within your account (see below for multi-account too).</p><br><div><div><div><div><p>&gt;</p><div><pre><code><p><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>select</span><span></span></p><p><span>  region</span><span>,</span><span></span></p><p><span>  instance_id</span><span>,</span><span></span></p><p><span>  instance_state</span><span>,</span><span></span></p><p><span>  instance_type</span><span>,</span><span></span></p><p><span>  title</span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code><span></span></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 244.685827ms
    </pre></div></div></div><h3 id="how-can-it-be-so-fast">How can it be so fast?</h3><p>Steampipe is smart! When you execute a query it fans out concurrent connections to the configured regions, aggregates the results and then presents them to you as one result set. The speed of the query is just limited to the speed of the slowest regional response.</p><h2 id="blazing-fast-query-response-with-new-query-caching">Blazing fast query response with new query caching</h2><p>Believe it or not, we can go even faster. Once you enable the new query caching feature, subsequent queries to the same data source will operate out of the in-memory cache, and return result sets in the blink of an eye.</p><h3 id="fast-1-second">Fast (1 Second)</h3><p>The first time you query a connection, Steampipe needs to create and authenticate API connections, in this case it took a little over 1 second to establish connections across 16 AWS regions and return results.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 1.045864439s
    </pre></div></div></div><h3 id="real-fast-Â¼-second">Real Fast (Â¼ Second)</h3><p>With the connections now cached, the same query returns in less than Â¼ second.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 243.693268ms
    </pre></div></div></div><h3 id="blazing-fast---1-microsecond">Blazing Fast ( &lt; 1 Microsecond)</h3><p>With query caching enabled, subsequent queries to the same table are more than 1000x faster!</p><div><div><div><div><div><pre><code><p><span>$ export STEAMPIPE_CACHE</span><span>=</span><span>true</span><span></span></p><p><span>$ steampipe query</span></p><p><span></span><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 653.39Âµs
    </pre></div></div></div><h2 id="connection-configuration-management-in-steampipe">Connection configuration management in Steampipe</h2><p>Regardless of what cloud you are working with, you are likely to need connections to more than one environment.  Everyone has multiple Slack channels and Github repositories that we work with and most cloud pros have multiple AWS accounts that they work with on a daily basis.</p><p>The latest Steampipe release now makes it even easier to work with (and across multiple api connections). This example shows how to configure multiple AWS accounts in a single Steampipe configuration:</p><div><div><div><div><div><div><div><pre><code><p><span>connection </span><span>"dmi_scranton"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"scranton"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-2"</span><span>]</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span>connection </span><span>"dmi_albany"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"albany"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-1"</span><span>]</span><span></span></p><p><span></span><span>}</span><span> </span></p><p><span>connection </span><span>"dmi_global"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"dmi_corp"</span><span></span></p><p><span>  regions     = </span><span>[</span><span></span></p><p><span>    </span><span>"eu-west-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"eu-west-2"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-2"</span><span></span></p><p><span>  </span><span>]</span><span></span></p><p><span></span><span>}</span></p></code></pre></div></div></div></div></div></div></div><p>In the example above, I chose different <code>[profiles]</code> from my <code>~/.aws/config</code> configuration for the connection credentials. You can optionally configure Steampipe to use <code>access key/secret key</code> pairs instead of your AWS profile if desired. After changing any .spc configuration, restart Steampipe. </p><p>Each account configuration creates a separate <code>namespace</code> in the Steampipe embedded Postgres DB; this allows us to query different accounts using standard <code>schema.table_name</code> syntax:</p><div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_albany</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>2</span><span>     </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_scranton</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>34</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_global</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>15</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span></p></code></pre></div></div></div></div></div></div></div><p>Aggregating results across accounts can be as simple as an SQL <code>union</code> statement:</p><div><div><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_scranton</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_albany</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_global</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span><span>;</span></p></code></pre></div></div></div><div><pre>
   +--------------+-------+
   | account_id   | count |
   +--------------+-------+
   | 111222333444 | 2     |
   | 444555666777 | 15    |
   | 888899990000 | 34    |
   +--------------+-------+
    </pre></div></div></div></div></div><h2 id="yes-we-think-that-is-super-cool-too--get-started-today">Yes, we think that is super cool too!  Get started today.</h2><p>Seeing Steampipeâ€™s multi-region and multi-account queries definitely put a smile on our product teamâ€™s face, we hope it is both delightful and a huge time saver for you in your day-to-day cloud work.  For even more good stuff, checkout the <a href="https://github.com/turbot/steampipe/blob/main/CHANGELOG.md">full release notes on Steampipe v0.2.0</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://steampipe.io/blog/release-0-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275128</guid>
            <pubDate>Fri, 26 Feb 2021 14:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose the Browser Carefully]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26275103">thread link</a>) | @axiomdata316
<br/>
February 26, 2021 | https://unixsheikh.com/articles/choose-your-browser-carefully.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/choose-your-browser-carefully.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-20</span>. Updated on <span id="moddate">2020-10-26</span></p>
<p><a href="https://en.wikipedia.org/wiki/Internet_privacy">Privacy on the Internet</a> is important because privacy risks range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults). Many companies, such as Google, track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. Sometimes prices on products are changed on the same website, depending on tracking information, and two people may view the exact same product on the exact same website yet be presented with very different prices.</p>

<h3>Table of contents</h3>
<ul>
<li><a href="#privacy-compromising">Introduction</a></li>
<li><a href="#third-party-clones">Third party clones</a></li>
<li><a href="#privacy-compromising">Privacy compromising browsers</a>
    <ul>
    <li><a href="#firefox">Mozilla Firefox</a></li>
    <li><a href="#chrome">Google Chrome and Chromium</a></li>
    <li><a href="#brave">Brave</a></li>
    <li><a href="#palemoon">Palemoon</a></li>
    <li><a href="#waterfox">Waterfox</a></li>
    <li><a href="#librewolf">Librewolf</a></li>
    <li><a href="#epiphany">GNOME Web (Epiphany) and Eolie</a></li>
    <li><a href="#midori">Midori</a></li>
    <li><a href="#other-problematic-browsers">Other problematic browsers</a></li>
    </ul>
</li>
<li><a href="#alternatives">Privacy respecting browsers</a></li>
<ul>
<li><a href="#tweaking-firefox">Tweaking Firefox - the best solution</a>
    <ul>
    <li><a href="#control">Controlling Firefox's DNS over HTTPS</a></li>
    <li><a href="#blocking">Blocking DoH via a firewall</a></li>
    </ul>
</li>
<li><a href="#falkon">Falkon</a></li>
<li><a href="#qutebrowser">qutebrowser</a></li>
<li><a href="#icecat">GNU IceCat</a></li>
<li><a href="#ungoogled-chromium">ungoogled-chromium</a></li>
<li><a href="#tor">Tor browser</a></li>
<li><a href="#other-okay-browsers">Other okay browsers</a></li>
</ul>
<li><a href="#recommended-extensions">Recommended extensions</a></li>
    <ul>
    <li><a href="#noscript">NoScript</a></li>
    <li><a href="#ublock-origin">uBlock Origin</a></li>
    <li><a href="#https-everywhere">HTTPS Everywhere</a></li>
    </ul>
<li><a href="#conclusions">Conclusions</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>This article isn't specifically about privacy issues only, it's about promises that are being broken, which might be about privacy. It is also about the lack of user freedom, as in the choice to enable or disable features, such as automatic updates, or forced usage of third party services, or software that the user generally is unaware of or don't have a say about.</p>

<p>Privacy as a subject regarding the usage of services on the Internet is a very difficult subject to deal with. Not only can it be difficult to actually define privacy, but it also requires a balance between freedom of choice by the users, security and usability. Naturally you need to be able to use the browser on the Internet and as such you will always leave some kind of trail behind, and this article is not about how you can hide your tracks. What I am addressing in this article are browsers that are either promoted as "privacy-respecting" by the developers, or in general are considered to be so (mostly due to misunderstanding or misinformation), while it is very clear they are not.</p>

<p>Some browsers either directly violate users by collecting telemetric data without consent, or you have to opt-out rather than opt-in, or they bounce around the Internet visiting places in the background without you knowing (using dns-prefetch or automatic updates etc.), using third party services that operates with a privacy policy you either cannot trust, or that are directly violating your privacy, or they have integrated third party software that do some of these things.</p>

<p>I will try to keep this article updated with relevant information as much as possible. I know several other browsers exist, but if they are not mentioned on this list I have either not had a change to investigate them, they are closed source and completely irrelevant (such as Microsoft Edge or Opera), or they are not actively maintained, or they cannot perhaps be trusted for some reason or another.</p>

<p>I will also <b>not</b> be looking at browsers that only work on Microsoft Windows or macOS, even if they are Open Source. Both Microsoft Windows and macOS are highly controversial and completely untrustworthy operating systems.</p>

<p>Also please note that just because the developers of a browser are promising that their browser is privacy-respecting doesn't mean that you can trust the information. As you will see with the examples of some of the browsers below even developers some times compromise user privacy perhaps without even thinking about it.</p>

<p>I also want to make a strong advice to people recommending browsers to other people without investigation or knowledge. The <a href="https://old.reddit.com/r/privacy/">privacy related channel on Reddit</a> is filled with wrong recommendations regarding privacy-respecting browsers and many people are merely guessing or blindly trusting the information the browser producers are publishing. Neither Mozilla Firefox, Google Chrome or Chromium, Brave, Waterfox, or several of the other recommended browsers truly respect privacy. They all do some form of telemetry and/or privacy-compromising actions without the user consenting to it or even knowing about it.</p>

<p>Also, privacy doesn't mean that you simply pull out telemetry from Firefox, rebrand it, and then ship it. Privacy is more than that. Unless the browser is automatically checking for an updated version, and the website isn't logging that request, it cannot be considered truly private if the browser starts bouncing around on the Internet visiting all kinds of places without the user has done anything more than open the browser up! Every time the browser makes a DNS request, that DNS request is in most cases logged unless the user actively does something to mitigate that - such as using a trusted VPN or non-logging DNS service etc. Furthermore, the Mozilla add-on CDN is logging user activity, as is <a href="https://en.wikipedia.org/wiki/Amazon_CloudFront">Amazon Cloudfront</a>, so if the browser visits these places without the user explicitly pushes a "check for updates" option, the browser is compromising user privacy. The point I'm trying to make is that the user needs to have the choice and that nothing happens until the user actively do something.</p>

<p>Last, but not least, if you discover any mistakes on my part, feel free to email me about it so that I can correct the information.</p>

<h2 id="privacy-compromising">Privacy compromising browsers</h2>

<h3 id="firefox">Mozilla Firefox</h3>
<p>In the past I have always supported Mozilla and promoted <a href="https://en.wikipedia.org/wiki/Firefox">Firefox</a>, but Mozilla has made some pretty controversial decisions as of late and I no longer feel that Mozilla is an organization that deserves any support. Not unless they change the way they conduct their business.</p>
<p>Firefox is promoted by Mozilla as a privacy-respecting browser, but this is highly misleading. Firefox "phones home" every time you start it up even when you have disabled telemetry and automatic updates of extensions. Domains such as mozilla.org, cloudfront.net, firefox.settings.services.mozilla.com (see: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12">https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12</a>), autopush.prod.mozaws.net, detectportal.firefox.com and location.services.mozilla.com are visited each time you start Firefox.</p>
<p>In 2017 Mozilla made a <a href="https://en.wikipedia.org/wiki/Cliqz#Integration_with_Firefox">deal with Cliqz</a> where approximately 1% of users downloading Firefox in Germany would receive a version with Cliqz software included. And in 2018 Mozilla revealed that they had no data on the number of Firefox installations with disabled Telemetry.</p>
<p>Mozilla then developed the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1487578">Telemetry Coverage</a> system and distributed it to 1% of the Firefox installations. The system is automatically installed and designed to inform Mozilla whether telemetry is enabled in the browser.</p>
<p>Mozilla also <a href="https://support.mozilla.org/en-US/kb/telemetry-collection-windows-default-browser-trend">developed a Windows-only scheduled task</a> which runs in the background once a day for each installation of Firefox installed on a computer running Microsoft Windows. The task collects information related to the system's current and previous default browser setting and the operating system locale and version.</p>
<p>This is a list of some of the things that Mozilla collects: <a href="https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content">https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content</a>.</p>
<p>On the <a href="https://www.mozilla.org/en-US/about/">Mozilla website</a> we can read (when I originally started writing this article) that <q>We put people over profit</q>, and <q>a product to support user privacy</q>. We can also read in the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla manifesto</a>, in the fourth principle, that <q>Individuals' security and privacy on the internet are fundamental and must not be treated as optional.</q> However, with their decision to make Cloudflare the default DNS provider for DNS over HTTPS, they are definitely not supporting user privacy or putting people over profit!</p>
<p>DNS over HTTPS is by itself <a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU">bad enough</a>, and <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism">highly criticized</a> with <a href="https://www.zdnet.com/article/dns-over-https-causes-more-problems-than-it-solves-experts-say/">very good reason</a>, but combining it with a US based company like Cloudflare makes it even worse. Cloudflare <a href="https://old.reddit.com/r/privacy/comments/d52kop/eli5_why_cloudflare_is_depicted_as_evil_and_whats/f0jrxox/">cannot be trusted</a> with DNS requests.</p>
<p>Cloudflare has made an <a href="https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/firefox/">agreement</a> with Mozilla that when it acts as a DNS resolver for Firefox, that:</p>
<ul>
<li>DNS requests will be stored as part of Cloudflare's "temporary" logs which are permanently deleted within 24 hours.</li>
<li>Cloudflare will also collect and store the following information as part of its permanent logs:
<ul>
<li>Total number of requests processed by each Cloudflare co-location facility.</li>
<li>Aggregate list of all domain names requested.</li>
<li>Samples of domain names queried along with the times of such queries.</li>
</ul>
</li>
<li>Information stored in Cloudflare's permanent logs will be anonymized and may be held indefinitely by Cloudflare for its own internal research and development purposes.</li>
</ul>
<p>Anyone who has worked with DNS servers knows what goes into such logs and in order for Cloudflare to keep their promise they need to: Delete the DNS requests information, but at the same time somehow still keep "anonymized" logs of the total number of requests, a list of all domain names requested, a so-called "sample" of complete DNS queries along with date and time.</p>
<p>This means that even if Cloudflare could be trusted and they have the best of intentions, they will still log everything the first 24 hours. If Cloudflare is ever compromised all these logs could be copied and distributed over a period of time.</p>
<p>Furthermore, the actual wording of the agreement is such that the technical procedure for how they actually do this can only be guessed at. How do they plan to anonymize the data? Is the "sample" 99.9% of all the queries, or is it 1%?</p>
<p>Last, but not least, Cloudflare is an American company subject to American law, a law that pretty much undermines the foundation of any kind of privacy.</p>
<blockquote>
<p>Cloudflare will not retain or sell or transfer to any third party (except as may be required by law) any personal information, IP addresses or other user identifiers from the DNS queries sent from the Firefox browser to the Cloudflare Resolver for Firefox;</p>
</blockquote>
<p>Real privacy means:</p>
<ul>
<li><b>No logging</b></li>
<li><b>No data retention</b></li>
<li><b>No phoning home without consent before doing so</b></li>
<li><b>No user opt-out telemetry, it has to be opt-in</b></li>
<li><b>Real and 100% transparency regarding …</b></li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/articles/choose-your-browser-carefully.html">https://unixsheikh.com/articles/choose-your-browser-carefully.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/articles/choose-your-browser-carefully.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275103</guid>
            <pubDate>Fri, 26 Feb 2021 14:30:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cuboid: A DIY air purifier that's better than a box fan]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 121 (<a href="https://news.ycombinator.com/item?id=26275091">thread link</a>) | @dynm
<br/>
February 26, 2021 | https://dynomight.net/better-DIY-air-purifier.html | <a href="https://web.archive.org/web/*/https://dynomight.net/better-DIY-air-purifier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            <p>
            
            <strong>Feb 26, 2021</strong> &nbsp; (Updated Feb 7, 2021)
            
            </p>

            <p>I love box-fan based air purifiers. They are cheap, trivial to build, and people around the world have done experiments to show they <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">actually work</a>.</p>

<p>Still, box-fan purifiers have two downsides: They create a lot of noise, and they consume a fair amount of electricity.</p>

<p>I wanted a new design that preserves the best aspects of using a box-fan:</p>

<ol>
  <li>Cheap.</li>
  <li>Easily built with no tools.</li>
  <li>No proprietary parts.</li>
  <li>Good at purifying the air.</li>
</ol>

<p>The design should also fix the worst parts of using a box fan:</p>

<ol>
  <li>Make less noise.</li>
  <li>Use less electricity.</li>
</ol>

<p>I think I’ve found such a design. Behold, the Cuboid:</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/cuboid.jpg" alt="Cuboid DIY purifier">
</p>

<h2 id="performance-summary">Performance summary</h2>

<p>I’ve done some experiments comparing this to a <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">box-fan based purifier</a>, using the same filters.  Here’s a summary.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>Cost to build</td>
    <td colspan="3">$71.50</td>
    <td colspan="3">$100</td>
</tr>
<tr>
    <td>Time to build</td>
    <td colspan="3">30 s</td>
    <td colspan="3">5 min</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>Sound level (dB)</td>
    <td>43</td>
    <td>48</td>
    <td>55</td>
    <td>16</td>
    <td>39</td>
    <td>51</td>
</tr>
<tr>
    <td>Power usage (W)</td>
    <td>65.4</td>
    <td>76.4</td>
    <td>96.0</td>
    <td>22.6</td>
    <td>40.3</td>
    <td>51.3</td>
</tr>
<tr>
    <td>Power cost/year ($)</td>
    <td>74.4</td>
    <td>87.0</td>
    <td>109.3</td>
    <td>25.73</td>
    <td>45.9</td>
    <td>58.4</td>
</tr>
<tr>
    <td>Resembles IED</td>
    <td colspan="3">★☆☆☆</td>
    <td colspan="3">★★★☆</td>
</tr>
</tbody>
</table>
</div>

<p>Less is better for everything except the clean air delivery rate (CADR). The half-life is calculated in a 31 m³ room. Electricity costs assume operation 24 hours/day at 1 kWh = $0.13.</p>

<p>As you can see, the cuboid gives major improvements in noise and electricity consumption, with small regressions in cost, difficulty of construction, and IED resemblance. Particularly on low, the cuboid is very quiet and energy-efficient. Somewhat accidentally, it’s also better at removing particles.</p>

<h2 id="contents">Contents</h2>

<ul id="markdown-toc">
  <li><a href="#performance-summary" id="markdown-toc-performance-summary">Performance summary</a></li>
  <li><a href="#contents" id="markdown-toc-contents">Contents</a></li>
  <li><a href="#the-fanfilter-tradeoff" id="markdown-toc-the-fanfilter-tradeoff">The fan/filter tradeoff</a></li>
  <li><a href="#how-to-build-it" id="markdown-toc-how-to-build-it">How to build it</a>    <ul>
      <li><a href="#materials-used" id="markdown-toc-materials-used">Materials used</a></li>
      <li><a href="#step-1-form-a-column-out-of-the-filters" id="markdown-toc-step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</a></li>
      <li><a href="#step-2-cut-out-a-base-for-the-column" id="markdown-toc-step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</a></li>
      <li><a href="#step-3-cut-out-a-base-for-the-fan" id="markdown-toc-step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</a></li>
      <li><a href="#step-4-set-the-fan-on-the-filter-column" id="markdown-toc-step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</a></li>
    </ul>
  </li>
  <li><a href="#cost" id="markdown-toc-cost">Cost</a></li>
  <li><a href="#measuring-filtering-performance" id="markdown-toc-measuring-filtering-performance">Measuring filtering performance</a>    <ul>
      <li><a href="#experimental-setup" id="markdown-toc-experimental-setup">Experimental setup</a></li>
      <li><a href="#results" id="markdown-toc-results">Results</a></li>
      <li><a href="#fitting-exponential-curves" id="markdown-toc-fitting-exponential-curves">Fitting exponential curves</a></li>
      <li><a href="#clean-air-delivery-rate-calculations" id="markdown-toc-clean-air-delivery-rate-calculations">Clean air delivery rate calculations</a></li>
    </ul>
  </li>
  <li><a href="#measuring-noise" id="markdown-toc-measuring-noise">Measuring noise</a></li>
  <li><a href="#measuring-energy-usage" id="markdown-toc-measuring-energy-usage">Measuring energy usage</a></li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a>    <ul>
      <li><a href="#the-upper-limit" id="markdown-toc-the-upper-limit">The upper limit</a></li>
      <li><a href="#should-you-bother-building-a-cuboid" id="markdown-toc-should-you-bother-building-a-cuboid">Should you bother building a Cuboid?</a></li>
      <li><a href="#when-is-airflow-helpful" id="markdown-toc-when-is-airflow-helpful">When is airflow helpful?</a></li>
      <li><a href="#the-competition" id="markdown-toc-the-competition">The competition</a></li>
      <li><a href="#advice" id="markdown-toc-advice">Advice</a></li>
      <li><a href="#you-might-ask" id="markdown-toc-you-might-ask">You might ask</a></li>
    </ul>
  </li>
</ul>

<h2 id="the-fanfilter-tradeoff">The fan/filter tradeoff</h2>

<p>Air purifiers push air through filters. If you’ve ever built a box-fan-based air purifier, you noticed that once you attach HEPA filters, throughput decreases dramatically. If you use a weak fan, it will barely push any air at all.</p>

<p>Fundamentally, if you want to increase purification, you have two options:</p>
<ul>
  <li><strong>Big fan</strong>: Keep the same amount of filter, but run a bigger/faster motor to push air through it faster.</li>
  <li><strong>Big filter</strong>: Keep the same fan, but install more filters in parallel. This will decrease the pressure on each of them, meaning more total airflow.</li>
</ul>

<p>If we want to be quiet and energy-efficient, the choice is clear: Use a relatively weak fan, but with a large a filter surface area.</p>

<p>Using more filters has a higher upfront cost — filters aren’t free. However, that extra cost disappears over time. If each filter can remove a fixed amount of particulates before it needs to be replaced, then doubling the number of filters means also doubling the replacement interval.</p>

<h2 id="how-to-build-it">How to build it</h2>

<p>(Contact me if you want the exact products I used.)</p>

<h3 id="materials-used">Materials used</h3>

<ul>
  <li>An 8inch (20.32cm) diameter inline duct booster fan ($30).</li>
  <li>Four HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick ($70 for all).</li>
  <li>Two bungee cords (free).</li>
  <li>Tape (free).</li>
  <li>Two pieces of packaging foam (free).</li>
</ul>

<p>Inline duct <em>booster</em> fans are fairly weak fans often used to help with grow rooms or range hoods. An <em>inline duct fan</em> would probably perform even better (see the <a href="#discussion">discussion</a>) but at a higher cost. The one I bought is rated to push around 12 m³ of air per minute.</p>

<p>You can use filters and fans of different sizes if you want. All that matters is that the fan has a smaller diameter than the filters (20.32 cm &lt; 22 cm). The pieces of foam also need to be at least as large as the matching dimension of the filter. I just used the foam that my fan was shipped in.</p>

<h3 id="step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</h3>

<p>Take the four filters, and assemble them into a vertical structure. Be careful to align the edges as you see in the middle, with two sides slightly “inside” of the other sides.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step1.jpg" alt="Step 1 of construction" loading="lazy">
</p>

<p>This column is somewhat unstable, but we’ll deal with that.</p>

<h3 id="step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</h3>

<p>Cut one piece of foam to the size of the square at the bottom of the filter column (I taped over a hole in the foam I used.) Place it at the bottom.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step2.jpg" alt="Step 2 of construction" loading="lazy">
</p>

<p>I did this by setting the filters on top of the foam, tracing out the shape with a pencil, and then cutting the foam with scissors. You probably want to err on the side of making it larger and trim if necessary. It should fit firmly so that it’s held in place by the filters.</p>

<p>Strictly speaking, you could also probably skip this step. I did that in an early version and it was OK. However, this adds a lot of stability allows the purifier to work even if it isn’t on top of a flat surface. You could also substitute some other material for the foam.</p>

<h3 id="step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</h3>

<p>Cut another piece of foam so that it supports the fan from below while holding the fan in place. This should be large enough so that that the piece will sit on top of the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step3.jpg" alt="Step 3 of construction" loading="lazy">
</p>

<p>As you can see, the foam was missing a corner, which I solved inelegantly by gluing on a piece of cardboard.</p>

<h3 id="step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</h3>

<p>Set the fan+foam on top of the filters, oriented so it will blow air <em>upward</em>, and pull air through the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step4.jpg" alt="Step 4 of construction" loading="lazy">
</p>

<p>That’s it, you’re done. The top is only held on by gravity, plus pressure if it’s on. You could obviously make this more stable or beautiful, but I wanted to focus on a design that’s <em>really</em> easy to build.</p>

<h2 id="cost">Cost</h2>

<p>The only significant cost is the fan ($30) and the filters ($70 for 4). This is more expensive than a box fan design, where the fan costs $19 and you only need 2 or 3 filters. However, as mentioned <a href="#the-fanfilter-tradeoff">above</a>, the cost of extra filters evens out in the long run since they need to be replaced half as often.</p>

<h2 id="measuring-filtering-performance">Measuring filtering performance</h2>

<h3 id="experimental-setup">Experimental setup</h3>

<p>I did experiments in a room with a volume of around 31 m³. To generate smoke, I cut 5 credit-card length sticks of incense and placed them on one end of a table. On the other end of the table, I placed a tablet that took a time-lapse video of a particle counter and a stopwatch. I then manually transcribed the measurements from this video.</p>

<p>The purifier (box fan or cuboid) was on the ground around a meter from the particle counter.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/setup.jpg" alt="setup for measuring air purification performance" loading="lazy">
</p>

<h3 id="results">Results</h3>

<p>As a comparison, I attached three of the same filters to a box fan (Literally the <em>same</em> filters).</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan.jpg" alt="DIY box fan compared to">
</p>


<p>Here are the results with the cuboid. Note that the y-axis is logarithmic. The straight lines indicate that particulates are decreasing at an exponential rate.</p>

<p><a href="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg">
<img src="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg" alt="performance of the cuboid on different fan speeds">
</a>
</p>

<p><br>
Here are the results of the box fan.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan_performance_cropped.svg" alt="performance of the box fan on different fan speeds" loading="lazy">
</p>



<p>You’ll notice two things. First and most importantly, the slopes for the cuboid graphs are steeper. This indicates better performance.</p>

<p>Second, the particles peak at higher values with the cuboid. I believe this is because the incense was near the particle counter on a table, while the purifiers were sitting on the floor 2m away. If the air isn’t disturbed, it takes a while before smoke drifts over the purifier and it actually starts doing anything. However, the box fan creates so much wind that the smoke immediately diffuses around the room and the box-fan purifier essentially gets a “head start”.</p>

<p>While wind seems to help here, it could be harmful in other cases. I discuss this more <a href="#when-is-airflow-helpful">below</a>.</p>

<h3 id="fitting-exponential-curves">Fitting exponential curves</h3>

<p>The y-axes in the plots above are logarithmic. As you can see from the dotted lines, these are well-fit by straight lines. This is what we’d expect if a fixed fraction of the air were being cleaned per minute.</p>

<p>The dotted lines for each curve show a fit of the form <strong>y=a×bᵐ</strong>, where <strong>y</strong> is the level of particulates, <strong>m</strong> is the number of minutes, and <strong>a</strong> and <strong>b</strong> are constants.</p>

<p>We can convert a fit of this type to a half-life: The number of minutes the purifier needs to eliminate half the particles from the air when running in a 31 m³ room.  That would be the number of minutes <strong>m</strong> such that <strong>bᵐ = .5</strong>. We can solve this equation as <strong>b = log(.5) / log(b)</strong>.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>90×.963ᵐ</td>
    <td>90×.949ᵐ</td>
    <td>65×.93ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
</tr>
</tbody>
</table>
</div>



<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>300×.955ᵐ</td>
    <td>280×.935ᵐ</td>
    <td>180×.905ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
</tbody>
</table>
</div>

<h3 id="clean-air-delivery-rate-calculations">Clean air delivery rate calculations</h3>

<p>One common way of estimating the performance of purifiers is the clean air delivery rate (CADR). If the air that came out of the purifier had zero particulates, this would just be the volume of air per unit of time.</p>

<p>The fits above were of the form <strong>y=a×bᵐ</strong>. This means that the number of particulates drops by a factor of <strong>b</strong> each minute.</p>

<p>Here’s how I calculated the CADR. Note that that if the purifier delivered <strong>(cleaned air) m³</strong> of clean air in a single minute in a room with a total volume of <strong>(all air) m³</strong>, then the particulates in a room would drop by a factor of</p>

<p><b>b=(uncleaned air)/(all air)= 1 - (cleaned air) / (all air)</b>
</p>
<p><br>
per minute. We can solve this to find that equation to get that</p>

<p><b>(cleaned air) = (all air)×(1-b).</b>
</p>


<p>I measured the dimensions of the room where I did these measurements. I estimated it was 31m³. From this, I computed the CADR for each purifier and speed as <strong>CADR = 31×(1-b)</strong>. This gives the following table of CADR rates.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>PM 2.5 CADR (ft³/min)</td>
    <td>40.5</td>
    <td>55.8</td>
    <td>76.6</td>
    <td>49.2</td>
    <td>71.1</td>
    <td>104</td>
</tr>
</tbody>
</table>
</div>


<p>A recent <a href="https://www.cbc.ca/1.5900782">study</a> from the University of Toronto also measured the CADR of a similar box-fan purifier. They measure around 92 ft³/min. (They don’t give numbers, but there’s a <a href="https://i.cbc.ca/1.5902727.1612545406!/fileImage/httpImage/image.png_gen/derivatives/original_1180/air-purifiers-graph.png">graph</a> CADR=100 is 130 pixels high and the box fan is 100 pixels high.) This is reassuringly close to my estimate of 76.6. I’d put a confidence band of around 20% on my numbers …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dynomight.net/better-DIY-air-purifier.html">https://dynomight.net/better-DIY-air-purifier.html</a></em></p>]]>
            </description>
            <link>https://dynomight.net/better-DIY-air-purifier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275091</guid>
            <pubDate>Fri, 26 Feb 2021 14:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Text Summarization in PDF Documents with Faster R-CNN and PEGASUS]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26275071">thread link</a>) | @konfuzio
<br/>
February 26, 2021 | https://konfuzio.com/de/automatic-text-summarization-in-pdf-files | <a href="https://web.archive.org/web/*/https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Today, rising amounts of documents and the contained information have to be processed by enterprises to be able to use the hidden content. This is either done by time-expensive manual text summarization or by using an automatization solution. Automatic text summarization helps humans to efficiently process the growing volume of information.&nbsp;</p><h4>What exactly is automatic text summarization?</h4><p>The Oxford English dictionary defines automatic text summarization as “the creation of a shortened version of a text by a computer program. The product of this procedure still contains the most important points of the original text.” [1]</p><p>A good example where summarization can be useful is the annual reports of companies. Those documents contain a lot of facts that can be crucial for investors since they include information on many factors such as sustainability or environmental policies which can help for the investors‘ decision. However, the annual reports are normally very long documents with hundreds of pages, which makes their analysis a time consuming process that could be facilitated by an automatic workflow.&nbsp;</p><h2>How can we summarize text in PDF files?</h2><p>We divide the process in three main parts. For each of those steps we go more into detail in the following sections of this article. Feel free to jump right into the details or let us first walk you through the main outcomes of each step.</p><h3>1. Use Object Detection for Page Segmentation</h3><p>In the first step, we need to select those parts of the document that have to be focused on. While we can get a lot of already summarized information from images, graphs, and headlines, it is the text that is the most complete source of information. A possible way to split the document in different components is to use a computer vision approach. A model for multiclass object detection can automatically differentiate between different elements in the annual report. All content can be split into five categories: title, text, table, list, and figure. Only the found locations of the category text are used for the following steps of the summarization process.</p><h3>2. Use OCR to convert the image to text</h3><p>The next step is to convert the selected bounding boxes of the document into text. This part can be defined as an optical character recognition (OCR) problem, which was resolved using estabilished tools.&nbsp;</p><h3>3. Text Summarization of any paragraph</h3><p>The final step is the summarization of the selected content. So-called Transformers, which lately have proven to be powerful models, come to play. We used the tailored BERT model PEGASUS which is especially designed for automatic summarization. The outcome shows us a summarized version of the paragraph which we detected and extracted from the report in the first steps. The original length of 910 characters was reduced to 193 characters, leading to a time saving of almost 80%. Still, all the relevant information to understand the paragraph is included.</p><h4>This approach shrinks paragraphs in a PDF by 80 %</h4><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/summarize_annual_report.gif" alt=""><figcaption>The result of the automatic text summarization with the PEGASUS model of one paragraph extracted from the annual report shows us a good result. Let’s step through it to check what kind of aspects are included: name of company, likelyhood of an event, amount of the fine, name of the comission.</figcaption></figure><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png" alt="" srcset="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png 650w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-300x199.png 300w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-150x100.png 150w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-768x510.png 768w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-1536x1019.png 1536w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-16x12.png 16w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924.png 1611w" sizes="(max-width: 650px) 100vw, 650px"></figure><h4>Join our Meetup talk on the 3rd of March 2021 from 5:00 pm to 6:00 pm GMT+1.</h4><h2>Do you want to learn more right now?</h2><h3>How to use object detection for page segmentation?</h3><p>Object detection is a task where objects of a known class are identified in the image and information about its location is provided. A very known architecture for this task is the Faster R-CNN. This architecture has two outputs for each object: a class label and a bounding-box. It consists of two modules: one deep fully convolutional network to propose regions and a Fast R-CNN that detects objects in those regions.</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg" alt="Faster R-CNN has two outputs for each object: a class label and a bounding-box. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg 600w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-277x300.jpg 277w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-139x150.jpg 139w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-768x832.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-11x12.jpg 11w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection.jpg 1229w" sizes="(max-width: 600px) 100vw, 600px"></figure><p>The way that works is that an input image is fed to a convolutional network that provides a feature map of that image. Then, a separated network (the region proposal network) takes that feature map and predicts possible regions for the objects (region proposals). Those region proposals are fed to a ROI pooling layer that reshapes them into a predefined size. Finally, the output vector from the pooling layer is used to classify the proposed regions and to refine the bounding boxes.&nbsp;</p><p>More recently, Mask R-CNN, which is an extension of the Faster R-CNN, added a third output that allows to have the mask of the object. This results in having the classification, bounding box and the mask of the object.The mask prediction is done in parallel with predicting the class and the bounding box [2].</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg" alt=" By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg 542w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-250x300.jpg 250w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-125x150.jpg 125w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-768x920.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-10x12.jpg 10w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs.jpg 1049w" sizes="(max-width: 542px) 100vw, 542px"></figure><p>The goal is to select only the relevant parts of the report, in our case the text paragraphs. Other parts that already include summaries, like headlines or tables, are not relevant. So the first thing we need is an annotated dataset with the different document elements. PubLayNet is a dataset with annotations of text, figures, titles, lists and tables on more than 360 k pages of scientific papers [3]. By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. The model that we used is available in the Detectron2 platform, which is a platform from Facebook AI Research that allows fast tests of state of art algorithms [4]. In the figure we can see the bounding boxes and the classification shown with a different color for each class, which was the result without any finetuning. For our problem we are not interested in the mask of the text, just the bounding box highlighted in blue.&nbsp;</p><p>Register for free and try out the page segmentation API with your own documents. <a href="https://app.konfuzio.com/v2/swagger/">Register to access our API documentation.</a> Using our document labeling tool you can create a dataset and fine-tune the PubLayNet model on your own documents.</p><figure><img src="https://lh4.googleusercontent.com/VqjsXgNjS9Na36xmpvqcFjgMbYWtyC4g_Xg0T0lDkggpol3mu1akQpHNWjj6P2T6oNBAPSpKpldVep3liFeX_egvwh2AuaZkbUBHM9wHEZcj_NnuBJ3so110A8g9Ynp45_rCTq9a" alt="Konfuzio API to segment pages via Faster R-CNN."></figure><h3>Wich is the best OCR engine?</h3><p>After having found the portion of the images that we are interested in, the next step is to extract the text from them with the use of optical character recognition (OCR). OCR can be done by computer vision approaches that can include detection, segmentation and recognition of characters but most recent approaches include a combination of CNNs and Recurrent Neural Networks.</p><p>An example of a OCR pipeline can be:</p><ul><li>Text detection – detects where the characters are located</li><li>Pre-processing – the text is normalized</li><li>Feature extraction – the output is the feature map of the image</li><li>Post processing – errors can be corrected by comparing with more common sequences of words, for example.&nbsp;</li></ul><p><a href="https://github.com/kba/awesome-ocr">Several OCR tools can be used.</a> We found the best approach to select the OCR per project. So at <a href="https://konfuzio.com/en/">Konfuzio </a>we integrate different OCR engines. In this video you can see how our API detects handwriting.</p><figure><p> <iframe title="Versteht Konfuzio Handschrift?" width="1170" height="878" src="https://www.youtube.com/embed/zbZgTYflpWk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><h3>How does text summarization work?</h3><p>Summarization is now commonly performed using Transformer models. Transformers are a type of neural network architecture introduced in 2017. They were initially designed for machine translation, but are now used for almost all modern NLP applications, such as: entity recognition, natural language inference, question answering and summarization. Transformers are able to process all incoming data in parallel, in comparison to the previous state-of-the-art models, LSTMs, which processed data sequentially. This ability for parallelization makes them easier to scale up with an exponentially growing amount of compute and data.</p><p>The main novel concept introduced in the Transformer architecture is the use of “multi-head attention”. In the Transformer each element in the input sequence is split into three vectors: Q, K, and V. Attention calculated as a weighted sum of these vectors, where the weights are both learned and are context dependent. In other words, the data input into the model decides where the model should focus its attention. Multi-headed attention implies that we split each vector into multiple “heads” and calculate attention across each head in parallel. Therefore, we perform multiple attention calculations at once, all in parallel, before combining the results together at the output. [5]</p><p>The most commonly used Transformer variant is called BERT. BERT only uses the encoder from the original Transformer with very small architecture changes. The main novelty of BERT is that it was trained as a “masked language model” on a large amount of unlabelled text. Masked language models are tasked with “filling in the blanks” of a given sentence, i.e. given a sentence replace a few of the words with a [MASK] token and then try and predict what the actual word was. It turns out that this task teaches the model a lot about natural language, so much so that it is now common to take a pre-trained BERT model and then fine-tune it your desired task. This is usually a good starting point when trying out neural networks for NLP and most NLP research is now focused on how to improve Transformer models and their variants by either tweaking the architecture or inventing a new pre-training objective.&nbsp;</p><p>PEGASUS is a model designed for automatic summarization. The architecture is similar to the original Transformer, with the decoder, but it is pre-trained on two tasks simultaneously. The first task is the masked language modeling task introduced by BERT. The second task involves predicting an entire sentence that has been masked out in the input. PEGASUS is first pre-trained trained on a huge amount of text, consisting of 1.5 billion news articles and then fine-tuned on the target dataset. It achieved state-of-the-art performance across twelve commonly used summarization datasets. [6].</p><h4>Sources:</h4><p>[1] <a href="https://research.fb.com/publications/mask-r-cnn/" target="_blank" rel="noreferrer noopener">He, K. et al. (2017). Mask R-CNN. Facebook AI Research (FAIR).</a></p><p>[2] <a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noreferrer noopener">Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks.&nbsp;</a></p><p>[3] <a href="https://github.com/ibm-aur-nlp/PubLayNet" target="_blank" rel="noreferrer noopener">Zhong, X., Tang, J., &amp; Yepes, A. (2019). PubLayNet: largest dataset ever for document layout analysis. In 2019 International Conference on Document …</a></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</a></em></p>]]>
            </description>
            <link>https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275071</guid>
            <pubDate>Fri, 26 Feb 2021 14:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NFTs Became Stores of Value]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26274634">thread link</a>) | @smalera
<br/>
February 26, 2021 | https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>You’ve heard of Bitcoin, and probably Ethereum. But what are non-fungible tokens, or NFTs, which people like <a href="https://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/">Gary Vaynerchuk, Chamath and Mark Cuban are so besotted with</a>?</p>
<p>Here’s an explainer, with help from two guides to the NFT world: The art and technology writer Jason Bailey, who also makes art as Artnome; and Priyanka Desai who is vice president of operations at OpenLaw, a research organization that helps set up and run new types of blockchain-specific funding vehicles that collect NFTs.&nbsp;</p>
<h2>What’s an NFT anyway?</h2>
<p>The key word in NFT is fungibility. Whereas Bitcoin is fungible, meaning each unit of bitcoin is interchangeable with another, NFTs do not have this property. Instead, NFTs are unique digital tokens.&nbsp;</p>
<p>NFTs are really just a type of computer program that runs on a blockchain. Some NFTs are programmed as items in a game, giving them certain properties that players can use. An example of this is CryptoKitties, where players collect different NFTs, representing digital cats, which they ‘breed’ with one another to create cats with new properties.&nbsp;</p>
<p>Other NFTs are more like digital art, and they’re linked to a specific image or sound file. They might also have certain rules programmed into them that allow the artist to collect a cut of future sales of the work, much like a royalty.&nbsp;</p>
<p>Many blockchains have their own NFTs. Some popular blockchains for NFTs are Ethereum, which hosts CryptoKitties and top crypto artists like Beeple; Flow, which hosts the NBA Top Shot collectible game; and Wax, which hosts crypto versions of Topps cards.&nbsp;</p>
<h2>How does it work?</h2>
<p>Generally, an artist uses a platform to “mint,” or create, an NFT. In theory, anyone can mint an NFT, but you’d need to write your own code.&nbsp;</p>
<p>The newly minted NFT usually doesn’t contain the graphic file or other data that make up an artwork. That data is usually stored somewhere else, off-chain. It could be stored on a centralized server.&nbsp;</p>
<p>An increasingly common option is to store the artwork on something called the Interplanetary File System (IPFS), a peer-to-peer network that replicates a file across many machines, acting as a form of decentralized storage, says Bailey, the artist and critic. The NFT will contain a unique signature that points to that file’s location on IPFS.</p>
<p><a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://opensea.io/blog/guides/non-fungible-tokens/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229656000%26amp;usg%3DAOvVaw0V_mZDO1yfF9QFqOIIC52U&amp;sa=D&amp;source=editors&amp;ust=1614230229670000&amp;usg=AOvVaw0XhDgxg8419--QzsxQrEvS" target="_blank">The Non-Fungible Token Bible</a>&nbsp;is a good resource to go deeper on the tech.&nbsp;&nbsp;</p>
<h2>Why do NFTs have value?</h2>
<p>Why shouldn’t they? NFT investors like Mark Cuban say you should think of them as forms of digital property.&nbsp;</p>
<p>Just as fine wines, paintings or rare trading cards can hold value, so should their digital versions. But instead of physical scarcity, crypto tokens have digital scarcity. That’s why,&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://blogmaverick.com/2021/01/31/the-store-of-value-generation-is-kicking-your-ass-and-you-dont-even-know-it/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229656000%26amp;usg%3DAOvVaw2UpaXEikYmokoVHXMWQgM6&amp;sa=D&amp;source=editors&amp;ust=1614230229671000&amp;usg=AOvVaw3yC_ORIj1fWrTQ_LmPwuXx" target="_blank">according to Cuban</a>, “blockchain driven assets have now legitimately become stores of value.”</p>
<p>Priyanka Desai, of OpenLaw, agrees with Cuban’s take. Digital property is important when we increasingly spend our lives online. She puts it this way: “The whole psychological nature of feeling that your taste and general outlook is signaled through a digital property. Whether that be audio or [crypto] collectibles or anything else&nbsp;—&nbsp;it's flexing wealth or taste. It's not dissimilar to how people behave in the real world.”</p>
<p>Finally, Bailey offers an analogy to the art world: “Art has no [inherent financial] value. A Rothko painting might be worth $40 million one minute and is worthless the next if an authenticator says, hey that’s not by Mark Rothko. Nothing changes about that painting. Art’s value comes from the social agreement that it’s from this artist. When you buy [NFTs], what you are buying is a token, and the artwork is what that token looks like.”</p>
<h2>Who’s Buying These Things?</h2>
<p>Lots of big names from the tech world. There’s Mark Cuban, who’s gotten deep in the weeds and is now collecting generative&nbsp;audio-art NFTs called Eulerbeats (“<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://twitter.com/BanklessHQ/status/1364255520857731072?s%253D20%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229657000%26amp;usg%3DAOvVaw2vPED03Wd15b8mnRi77B1M&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw1kOffqT7INM4UPbm5x-LcU" target="_blank">the most genius idea ever</a>”); billionaire investor Chamath Palihapitiya who says he’s building a “sizable collection” of tokens; and wine merchant turned tech investor Gary Vaynerchuk who seems to tweet almost exclusively about NFTs these days.&nbsp;</p>
<h2>What Are NFTs Going For?</h2>
<p><a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.one37pm.com/grind/money/most-expensive-nfts%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229658000%26amp;usg%3DAOvVaw2VVCgzRxCYBK82HPHABVvF&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw2CeuxZRvX7_OHq6iHKjhSx" target="_blank">Lots of money</a>. The street artist Beeple sold a collection of his works for $3.5 million in December. Now Christie’s is auctioning&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229658000%26amp;usg%3DAOvVaw3dDu9c2x1giehOS1kdX2ZV&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw0cesMH_Wh8-PWgst-aum96" target="_blank">one of his pieces</a>&nbsp;in a first for the storied auction house.&nbsp;</p>
<p>The pixelated portraits&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.businessofbusiness.com/articles/cryptopunks-pixelated-portraits-are-changing-hands-for-760000/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229659000%26amp;usg%3DAOvVaw0JvTTtqeALPgrDki0UrIUn&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw1petCI_5OdZJDW4pzEceym" target="_blank">known as CryptoPunks</a>&nbsp;are changing hands for $1.6 million or so, while a digital cat shooting&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.coindesk.com/nyan-cat-nft-ethereum-meme%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229660000%26amp;usg%3DAOvVaw3fzXkJP74DaMvrAtk_tNN_&amp;sa=D&amp;source=editors&amp;ust=1614230229673000&amp;usg=AOvVaw1IVzdqu5IlhqY3yl7LV5zA" target="_blank">a rainbow from its posterior</a>&nbsp;went for half a million.&nbsp;</p>
<p>According to data site NonFungible.com and L’Atelier, a unit of BNP Paribas, NFT sales hit $250 million in 2020, an increase of some 300% from a year earlier.&nbsp;</p>
<h2>Types of NFTs</h2>
<p>The three biggest categories for NFTs are tokens used in games; artwork and items used in “metaverses” or virtual worlds, according to data from NonFungible.com. NFT sales are pretty evenly split among them at about 25% of the market each. Sports and other collectibles make up the remainder.&nbsp;</p>
<h2>Platforms</h2>
<p>NFTs can be bought on a variety of platforms. Some of these platforms lend themselves to certain types of tokens.&nbsp;</p>
<p>According to Desai:&nbsp;</p>
<ul>
<li>Nifty Gateway, the marketplace backed by the Winklevoss twins, is a “bridge for newbies” because they can wire dollars to their accounts there.</li>
<li>Rarible and Opensea have “wide swaths” of NFTs, everything from collectibles to digital land.</li>
<li>Foundation and Zora are “more curated” with a focus on getting “edgy and interesting” artists into NFTs.</li>
<li>Superrare is “the OG” as far as crypto curated platforms go. Cryptoartists selling works for lots of coins today got their start here.&nbsp;</li>
</ul>
<h2>Displaying Your NFTs</h2>
<p>After spending so much money on a unique digital object how do you show it off? You can show off your crypto art by hanging them on your wall with an&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://infiniteobjects.com%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229662000%26amp;usg%3DAOvVaw1kHb_sBgCuBMKviXMwKP2j&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw10rwU8fNdTzJexp7hOJvqH" target="_blank">Infinite Objects Video Print</a>, Desai says.&nbsp;</p>
<p>You can also use a crypto wallet that’s designed to display your collection, like&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://rainbow.me%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229662000%26amp;usg%3DAOvVaw11i8wxyt5_GKl8Vkz5HgN3&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw1bCEZLCSI66E6ZBUyE2xvR" target="_blank">Rainbow.me</a>. Platforms like Showtime let collectors show off their works in&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://tryshowtime.com%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229663000%26amp;usg%3DAOvVaw0s2jnq8J9ZZYeKLXDfQH1-&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw38Po9J5FW01X8MbYV2VRbq" target="_blank">an Instagram-like format</a>.&nbsp;</p>
<p>If you want to get really fancy, you can build an entire museum or gallery in a metaverse like Decentraland or Cryptovoxels and show off there. “A lot of this art might just end up living virtually,” Desai says.&nbsp;</p>
<p>Lastly, because NFTs are cryptoassets, there’s an increasing array of financial tools that let you borrow against them, fractionalize them, delegate them to a decentralized fund, or just sell them to anyone you like —&nbsp;which is more than you can say for a painting hanging on your wall.&nbsp;</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274634</guid>
            <pubDate>Fri, 26 Feb 2021 13:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Allowing Big Tech to Form “Techno-Governments” to Be Announced Today]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 89 (<a href="https://news.ycombinator.com/item?id=26274611">thread link</a>) | @TheWellerman
<br/>
February 26, 2021 | https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">Nevada Governor Steve Sisolak will be announcing legislation today that will allow major technology companies to effectively form techno-governments.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Gov. Sisolak first mentioned the proposal of creating “Innovation Zones” in Nevada during his&nbsp;</span><a href="https://thenevadaindependent.com/article/full-transcript-annotations-of-sisolaks-2021-state-of-the-state-address" target="_blank" rel="noopener"><span data-preserver-spaces="true">State-of-the-State address</span></a><span data-preserver-spaces="true">&nbsp;on January 19. “New companies creating groundbreaking technologies can come to Nevada to develop their industries. This will be done without tax abatements or public financing.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the legislation wouldn’t provide subsidiaries or public funding, according to a draft of the Bill obtained by the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, major technology firms would be granted authority to form their independent techno-governments within Nevada. “[They] would carry the same authority as a county, including the ability to impose taxes, form school districts and justice courts and provide government services, to name a few duties,” Las Vegas Review-Journal reports.&nbsp;</span></p>
<figure id="attachment_3641" aria-describedby="caption-attachment-3641"><img src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" alt="techno-governments " width="653" height="440" srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w,https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" sizes="(max-width: 653px) 100vw, 653px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w, https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3641">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">During his remarks in January, Gov. Sisolak specifically mentioned the company Blockchains, LLC as already being committed to creating a techno-government in the state that would “fully run on blockchain technology.” Gov. Sisolak said the move would make Nevada “the epicenter of this emerging industry and creating the high paying jobs and revenue that go with it.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the simplest terms, blockchain is a type of database system that stores computational information in groups, known as “blocks.” Though not entirely unalterable, blockchain technology is considered secure by design because data transactions between parties are recorded efficiently and in an open, verifiable, and permanent manner. Financial services, particularly cryptocurrencies, widely use blockchain technology.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The company mentioned explicitly by Gov. Sisolak, Blockchains, LLC, was founded in 2014 by consumer protection attorney and cryptocurrency millionaire <a href="https://www.blockchains.com/our-people/jeffrey-berns/" target="_blank" rel="noopener">Jeffrey Berns</a>.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to their&nbsp;</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">website</span></a><span data-preserver-spaces="true">, Blockchains, LLC currently owns over 67,000 acres in Storey County, Nevada. The company says they aim to convert this land into “the most advanced ‘high-tech’ community and society for business and residents in the country.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Calling it “a new way to live,” Blockchains says they “believe the integration of our product suite is where the full potential of a smart community, digital economy, and connected society can be realized.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">“Blockchains aims to showcase how business development, residential living, and commerce can flourish alongside world-changing technologies. To do that, we have to start with a blank slate – otherwise, we’d merely be trying to insert smart technologies into devices that aren’t, well, ‘smart,'” reads the company’s “</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Road to Development</span></a><span data-preserver-spaces="true">” plan.</span></p>
<p><span data-preserver-spaces="true">According to state records, in 2018, Blockchains purchased 67,125 acres of uninhabited land at the Tahoe Reno Industrial Center for $170 million. At the time, the company’s website did not list any executive, a phone number, or a clear explanation of what it’s software did, leading some local media outlets to label the company as “mysterious.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Since the land grab, Blockchains has been lobbying hard to get legislation passed that would allow the company to form its own techno-government.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Las Vegas Review-Journal reports Blockchains, LLC gave $50,000 to a political action committee, Home Means Nevada, which managed Sisolak’s transition into office in January 2019. Campaign&nbsp;</span><a href="https://www.followthemoney.org/entity-details?eid=48060485" target="_blank" rel="noopener"><span data-preserver-spaces="true">finance records</span></a><span data-preserver-spaces="true">&nbsp;also show the company donated $10,000 to Sisolak and his Republican opponent Adam Laxalt’s campaign in 2018.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Records also show the company’s owner, Jeffrey Berns, personally gave $50,000 to the Nevada Democratic Party in 2019 and various donations ranging from $1,000 to $5,000 to various state lawmakers from both parties.&nbsp;</span></p>
<p>Over a week ago,<em><span data-preserver-spaces="true"> The Debrief&nbsp;</span></em><span data-preserver-spaces="true">reached out to Blockchains, LLC for comment; however, the company did not respond to this request.&nbsp;</span></p>

<figure id="attachment_3640" aria-describedby="caption-attachment-3640"><img src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" alt="techno-governments" width="760" height="428" data-src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3640">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">In an email to&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">, Communications Director for the Governor’s office, Meghin Delaney, said Gov. Sisolack will formally unveil the proposed “Innovation Zones” legislation during a virtual press conference today, Friday, February 26, at 4:30 pm (EST).&nbsp;</span></p>
<p><span data-preserver-spaces="true">Joining Gov. Sisolack at today’s conference will be Michael Brown, Executive Director of the Governor’s Office of Economic Development, and Jeremy Aguero, principal analyst at Applied Analysis.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, the draft language in the proposal said the traditional local government model was “inadequate alone to provide the flexibility and resources conducive to making the State a leader in attracting and retaining new forms and types of businesses and fostering economic development in emerging technologies and innovative industries.”</span></p>
<p><span data-preserver-spaces="true">The draft proposal also reportedly said the creation of techno-governments or “alternative forms of local government” were needed to aid economic development within the state.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development is slated to handle applications for the Innovation Zones, which would be limited to specific “innovative technologies,” including “blockchain, autonomous technology, the internet of things, artificial intelligence, wireless technology, biometrics, and renewable resource technology.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development redirected <em>The Debrief’s</em> questions on the legislation backing techno-governments to the Governor’s communications staff; since the Bill had not been formally proposed, much less passed.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The draft proposal laid out the requirements for companies to create their own techno-government, including an applicant owning at least 50,000 acres of undeveloped and uninhabited land, all within a single county but separate from any city, town or tax increment area.</span></p>
<p><span data-preserver-spaces="true">Big Tech companies would also have to pledge at least $250 million toward initial development, with a plan to invest an additional $1 billion over ten years in the zone.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Major technology companies would function as their own independent governmental body, with a three-member board of supervisors that would carry the same authority as a board of county commissioners. The Bill’s proposed draft suggests technology companies would have a significant say over who would sit on techno-government’s board.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the draft proposal provides insight into some of the details behind the concept, some aspects could be changed when the Bill is formally introduced.&nbsp;</span></p>
<figure id="attachment_3639" aria-describedby="caption-attachment-3639"><img src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" alt="techno-governments" width="640" height="441" srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w,https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" sizes="(max-width: 640px) 100vw, 640px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w, https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3639">Las Vegas, Nevada (Image Source: Pixabay)</figcaption></figure>
<div><div id="block-wrap-54099" data-id="54099"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/the-fermi-paradox-where-are-all-the-aliens/">
				<img width="120" height="120" src="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg" alt="fermi paradox" srcset="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-125x125.jpg 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-125x125.jpg 125w" data-src="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span data-preserver-spaces="true">Aside from lobbying by companies such as Blockchains, the primary motivation for proposing the allowance of techno-governments would be the hope that the move would significantly boost Nevada’s beleaguered economy.&nbsp;</span></p>
<p><span data-preserver-spaces="true">With tourism indirectly or directly accounting for&nbsp;</span><a href="https://www.travelnevada.biz/wp-content/uploads/Nevada-Visitor-Economic-Impact-2018.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">almost 25%</span></a><span data-preserver-spaces="true">&nbsp;of the state’s economy, Nevada has been devastated by the COVID-19 pandemic. Las Vegas, the United States’ second-largest municipal tourism industry, accounted for over $19 billion of Nevada’s GDP before the pandemic. According to the&nbsp;</span><a href="http://nevadaresorts.org/cv19/Nevada%20NRA%20Corona%20Virus%20Assessment%20Fact%20Sheet%20%20FINAL.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">Nevada Resort Association</span></a><span data-preserver-spaces="true">, tourism and leisure services account for one out of every three jobs in Nevada.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The&nbsp;</span><a href="https://www.brookings.edu/research/explaining-the-economic-impact-of-covid-19-core-industries-and-the-hispanic-workforce/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Brookings Institute</span></a><span data-preserver-spaces="true">&nbsp;found two Nevada cities, Las Vegas and Reno, were among the top three metro economies hardest-hit by the pandemic. In December 2020, the U.S. Bureau of Labor Statistics reported Nevada’s unemployment rate of 9.2% was the second-highest in the United States. Hawaii, which came in dead last, was only a tenth of a percentage point below Nevada at 9.3%.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Conversely, metropolitan hubs specializing in technology, such as Seattle and San Francisco, have thrived and benefited from COVID-19. Sales at non-store retailers (i.e., online shopping) increased by 15% from November 2019 to November 2020. Online retail giant Amazon, headquartered in Seattle,&nbsp;</span><a href="https://www.washingtonpost.com/technology/2020/10/29/amazon-hiring-pandemic-holidays/" target="_blank" rel="noopener"><span data-preserver-spaces="true">nearly doubled its workforce</span></a><span data-preserver-spaces="true">, adding 400,000 jobs in 2020. Social media monolith Facebook&nbsp;</span><a href="https://variety.com/2020/digital/news/facebook-hiring-10000-workers-small-business-grants-1234570018/" target="_blank" rel="noopener"><span data-preserver-spaces="true">announced</span></a><span data-preserver-spaces="true">&nbsp;plans to hire an additional 10,000 workers in April 2020.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The adage that “the most secure job is a federal government job” has held during the COVID-19 pandemic, and the U.S. Government grew by over 50,000 jobs in 2020. The metropolitan seat of America’s power, Washington D.C., saw a government employment rate increase over 2% last year.&nbsp;</span></p>
<p><span data-preserver-spaces="true">By allowing major technology corporations to form their techno-governments, Nevada will be trying to capture lightning in a bottle by enticing a mix of the most benefited industries during these economically downtrodden times.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While economic benefits seem enticing, almost assuredly, there will be some public concerns over the idea of Big Tech being allowed to form its own sovereign governance.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In a&nbsp;</span><a href="https://ideas.ted.com/heres-the-real-danger-that-facebook-google-and-the-other-tech-monopolies-pose-to-our-society/" target="_blank" rel="noopener"><span data-preserver-spaces="true">2018 essay</span></a><span data-preserver-spaces="true">, technology analyst Jamie Bartlett warned technology monopolies posed a real threat to democracies. “Tech is just the latest vehicle for very rich people to use well-tested techniques of buying political influence, monopolistic behavior and avoiding regulation,” wrote Bartlett.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Fear over the power Big Tech companies wield has only increased in the past two years. The public and politicians alike have expressed concerns over Big Tech companies’ potential to be a cultural hegemony, dominating public ideas and beliefs.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The jury is still out as to the ultimate impact of allowing Big Tech to form techno-governments, provided that the proposed legislation passes.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the area Blockchains plans to build their “better way to live,” Storey County Commissioner Lance Gilman was a little hesitant toward the proposed legislation during an interview with the Las Vegas Journal Review. “[It’s] going to have an impact on Storey County, and the jury is still out on whether that will be positive or negative.”</span></p>
<p><b>Join us on</b><a href="https://twitter.com/Debriefmedia"> <b>Twitter</b></a><b> or</b><a href="https://www.facebook.com/thedebriefnews"> <b>Facebook</b></a><b> to weigh in and share your thoughts on Big Tech …</b></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274611</guid>
            <pubDate>Fri, 26 Feb 2021 13:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke 1.0]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26274466">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | http://www.jemarch.net/poke-1.0-relnotes.html | <a href="https://web.archive.org/web/*/http://www.jemarch.net/poke-1.0-relnotes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jemarch.net/poke-1.0-relnotes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274466</guid>
            <pubDate>Fri, 26 Feb 2021 13:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: The Power of Habit by Charles Duhigg]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26274358">thread link</a>) | @chegra
<br/>
February 26, 2021 | https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg | <a href="https://web.archive.org/web/*/https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1658851">
    
      <div><center>        <div id="posthaven_gallery[1682788]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/medium_The_Power_of_Habit.jpg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/medium_The_Power_of_Habit.jpg" data-medium-width="324" data-medium-height="499" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/large_The_Power_of_Habit.jpg" data-large-width="324" data-large-height="499" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/thumb_The_Power_of_Habit.jpg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/xlarge_The_Power_of_Habit.jpg" data-xlarge-width="324" data-xlarge-height="499" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/The_Power_of_Habit.jpg" data-orig-width="324" data-orig-height="499" data-posthaven-id="2584577">
        </p>
          
        </div>
</center><p>1. <b>One paper published by a Duke University researcher in 2006 found that more than 40 percent of the actions people performed each day werenâ€™t actual decisions, but habits.</b></p><p>2. Habits, scientists say, emerge because the brain is constantly looking for ways to save effort. Left to its own devices, the brain will try to make almost any routine into a habit, because habits allow our minds to ramp down more often. This effort-saving instinct is a huge advantage. An efficient brain requires less room, which makes for a smaller head, which makes childbirth easier and therefore causes fewer infant and mother deaths. An efficient brain also allows us to stop thinking constantly about basic behaviors, such as walking and choosing what to eat, so we can devote mental energy to inventing spears, irrigation systems, and, eventually, airplanes and video games.</p><p><b>3. This process within our brains is a three-step loop. First, there is a cue, a trigger that tells your brain to go into automatic mode and which habit to use. Then there is the routine, which can be physical or mental or emotional. Finally, there is a reward, which helps your brain figure out if this particular loop is worth remembering for the future:</b></p><p>4. By learning to observe the cues and rewards, though, we can change the routines.</p><p>5. This is how new habits are created: by putting together a cue, a routine, and a reward, and then cultivating a craving that drives the loop.</p><p>6. But to overpower the habit, we must recognize which craving is driving the behavior.</p><p>7. But countless studies have shown that a cue and a reward, on their own, arenâ€™t enough for a new habit to last. Only when your brain starts expecting the rewardâ€”craving the endorphins or sense of accomplishmentâ€”will it become automatic to lace up your jogging shoes each morning.</p><p>8. Cravings are what drive habits. And figuring out how to spark a craving makes creating a new habit easier.</p><p>9. Rather, to change a habit, you must keep the old cue, and deliver the old reward, but insert a new routine.</p><p>10. Belief was the ingredient that made a reworked habit loop into a permanent behavior.</p><p>11. â€œEven if you give people better habits, it doesnâ€™t repair why they started drinking in the first place. Eventually theyâ€™ll have a bad day, and no new routine is going to make everything seem okay. What can make a difference is believing that they can cope with that stress without alcohol.â€�</p><p>12. â€œAt some point, people in AA look around the room and think, if it worked for that guy, I guess it can work for me,â€� said Lee Ann Kaskutas, a senior scientist at the Alcohol Research Group. â€œThereâ€™s something really powerful about groups and shared experiences. People might be skeptical about their ability to change if theyâ€™re by themselves, but a group will convince them to suspend disbelief. A community creates belief.â€�</p><p>13. But we do know that for habits to permanently change, people must believe that change is feasible. The same process that makes AA so effectiveâ€”the power of a group to teach individuals how to believeâ€”happens whenever people come together to help one another change. Belief is easier when it occurs within a community.</p><p><b>14. How do habits change? There is, unfortunately, no specific set of steps guaranteed to work for every person. We know that a habit cannot be eradicatedâ€”it must, instead, be replaced. And we know that habits are most malleable when the Golden Rule of habit change is applied: If we keep the same cue and the same reward, a new routine can be inserted. But thatâ€™s not enough. For a habit to stay changed, people must believe change is possible. And most often, that belief only emerges with the help of a group.</b></p><p>15. Some habits have the power to start a chain reaction, changing other habits as they move through an organization. Some habits, in other words, matter more than others in remaking businesses and lives. These are â€œkeystone habits,â€�</p><p>16. Researchers have found similar dynamics in dozens of other settings, including individualsâ€™ lives. Take, for instance, studies from the past decade examining the impacts of exercise on daily routines.10 When people start habitually exercising, even as infrequently as once a week, they start changing other, unrelated patterns in their lives, often unknowingly. Typically, people who exercise start eating better and becoming more productive at work. They smoke less and show more patience with colleagues and family.</p><p>17. Small wins are exactly what they sound like, and are part of how keystone habits create widespread changes. A huge body of research has shown that small wins have enormous power, an influence disproportionate to the accomplishments of the victories themselves.<br></p><p>18. Small wins fuel transformative changes by leveraging tiny advantages into patterns that convince people that bigger achievements are within reach.</p><p>19. The second way that keystone habits encourage change: by creating structures that help other habits to flourish.</p><p>20. At the core of that education is an intense focus on an all-important habit: willpower. Dozens of studies show that willpower is the single most important keystone habit for individual success.</p><p>21. â€œSelf-discipline predicted academic performance more robustly than did IQ. Self-discipline also predicted which students would improve their grades over the course of the school year, whereas IQ did not.â€¦ Self-discipline has a bigger effect on academic performance than does intellectual talent.â€�</p><p>22. And the best way to strengthen willpower and give students a leg up, studies indicate, is to make it into a habit.</p><p>23. Scientists began conducting related experiments, trying to figure out how to help kids increase their self-regulatory skills. They learned that teaching them simple tricksâ€”such as distracting themselves by drawing a picture, or imagining a frame around the marshmallow, so it seemed more like a photo and less like a real temptationâ€”helped them learn self-control.</p><p>24. By the 1980s, a theory emerged that became generally accepted: Willpower is a learnable skill, something that can be taught the same way kids learn to do math and say â€œthank you.â€�</p><p><b>25. â€œThatâ€™s why signing kids up for piano lessons or sports is so important. It has nothing to do with creating a good musician or a five-year-old soccer star,â€� said Heatherton. â€œWhen you learn to force yourself to practice for an hour or run fifteen laps, you start building self-regulatory strength. A five-year-old who can follow the ball for ten minutes becomes a sixth grader who can start his homework on time.â€�</b></p><p>26. Simply giving employees a sense of agencyâ€”a feeling that they are in control, that they have genuine decision-making authorityâ€”can radically increase how much energy and focus they bring to their jobs.</p><p><b>27. A company with dysfunctional habits canâ€™t turn around simply because a leader orders it. Rather, wise executives seek out moments of crisisâ€”or create the perception of crisisâ€”and cultivate the sense that something must change, until everyone is finally ready to overhaul the patterns they live with each day.</b></p><p>28. â€œThis crisis provides the opportunity for us to do things that you could not do before.â€�</p><p>29. Andreasen wanted to know why these people had deviated from their usual patterns. What he discovered has become a pillar of modern marketing theory: Peopleâ€™s buying habits are more likely to change when they go through a major life event. When someone gets married, for example, theyâ€™re more likely to start buying a new type of coffee. When they move into a new house, theyâ€™re more apt to purchase a different kind of cereal.</p><p>30.If a member made a friend at the YMCA, they were much more likely to show up for workout sessions. In other words, people who join the YMCA have certain social habits.</p><p>31. Itâ€™s a variation of the lesson learned by Target and radio DJs: to sell a new habitâ€”in this case exerciseâ€”wrap it in something that people already know and like, such as the instinct to go places where itâ€™s easy to make friends.</p><p>32. To market a new habitâ€”be it groceries or aerobicsâ€”you must understand how to make the novel seem familiar.</p><p>33. In general, sociologists say, most of us have friends who are like us. We might have a few close acquaintances who are richer, a few who are poorer, and a few of different racesâ€”but, on the whole, our deepest relationships tend to be with people who look like us, earn about the same amount of money, and come from similar backgrounds.</p><p>34. For Aristotle, habits reigned supreme. The behaviors that occur unthinkingly are the evidence of our truest selves, he said. So â€œjust as a piece of land has to be prepared beforehand if it is to nourish the seed, so the mind of the pupil has to be prepared in its habits if it is to enjoy and dislike the right things.â€�</p><p>35. THE DIFFICULT THING about studying the science of habits is that most people, when they hear about this field of research, want to know the secret formula for quickly changing any habit. If scientists have discovered how these patterns work, then it stands to reason that they must have also found a recipe for rapid change, right? If only it were that easy. Itâ€™s not that formulas donâ€™t exist. The problem is that there isnâ€™t one formula for changing habits. There are thousands.</p><p><b>36. THE FRAMEWORK: </b><br><b>â€¢ Identify the routine </b><br><b>â€¢ Experiment with rewards </b><br><b>â€¢ Isolate the cue </b><br><b>â€¢ Have a plan</b></p><p>37. STEP ONE: IDENTIFY THE ROUTINE</p><p>38. To understand your own habits, you need to identify the components of your loops. Once you have diagnosed the habit loop of a particular behavior, you can look for ways to supplant old vices with new routines. As an example, letâ€™s say you have a bad habit, like I did when I started researching this book, of going to the cafeteria and buying a chocolate chip cookie every afternoon. Letâ€™s say this habit has caused you to gain a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg">https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg</a></em></p>]]>
            </description>
            <link>https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274358</guid>
            <pubDate>Fri, 26 Feb 2021 13:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executable]]>
            </title>
            <description>
<![CDATA[
Score 613 | Comments 151 (<a href="https://news.ycombinator.com/item?id=26273960">thread link</a>) | @NilsIRL
<br/>
February 26, 2021 | https://justine.lol/ape.html | <a href="https://web.archive.org/web/*/https://justine.lol/ape.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
24 aug 2020 @ <a href="https://justine.lol/index.html"> justine's web page</a>

</p>

<p>
One day, while studying old code, I found out that it's possible to
encode Windows Portable Executable files as a UNIX Sixth Edition shell
script, due to the fact that the Thompson Shell didn't use a shebang
line. Once I realized it's possible to create a synthesis of the binary
formats being used by Unix, Windows, and MacOS, I couldn't resist the
temptation of making it a reality, since it means that high-performance
native code can be almost as pain-free as web apps. Here's how it works:

</p><pre>MZqFpD='
BIOS BOOT SECTOR'
exec 7&lt;&gt; $(command -v $0)
printf '\177ELF...LINKER-ENCODED-FREEBSD-HEADER' &gt;&amp;7
exec "$0" "$@"
exec qemu-x86_64 "$0" "$@"
exit 1
REAL MODE...
ELF SEGMENTS...
OPENBSD NOTE...
NETBSD NOTE...
MACHO HEADERS...
CODE AND DATA...
ZIP DIRECTORY...
</pre>

<p>
I started a project called
<a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> which
implements
the <a aria-label="Actually Portable Executable" href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/ape/ape.S">αcτµαlly
pδrταblε εxεcµταblε</a> format. I chose the name because I like the idea
of having the freedom to write software without restrictions that
transcends traditional boundaries. My goal has been helping C become a
build-once run-anywhere language, suitable for greenfield development,
while avoiding any assumptions that would prevent software from being
shared between tech communities. Here's how simple it is to get started:

</p><pre>gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
</pre>

<p>
In the above one-liner, we've basically reconfigured the stock compiler
on Linux so it outputs binaries that'll run on MacOS, Windows, FreeBSD,
OpenBSD, and NetBSD too. They also boot from the BIOS. Please note this
is intended for people who don't care about desktop GUIs, and just want
stdio and sockets without devops toil.

</p><h3>Platform Agnostic C / C++ / FORTRAN Tooling</h3>

<p>
Who could have predicted that cross-platform native builds would be this
easy? As it turns out, they're surprisingly cheap too. Even with all the
magic numbers, win32 utf-8 polyfills, and bios bootloader code, exes
still end up being roughly 100x smaller than Go Hello World:

</p><p>
  <a href="https://justine.lol/life.com">life.com</a> is 12kb (<a href="https://justine.lol/life.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello.com">hello.com</a> is 16kb (<a href="https://justine.lol/hello.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Please note that zsh has a minor backwards compatibility glitch with
Thompson Shell [update
2021-02-15: <a href="https://github.com/zsh-users/zsh/commit/326d9c203b3980c0f841bc62b06e37134c6e51ea">zsh
has now been patched</a>] so try <code>sh hello.com</code> rather
than <code>./hello.com</code>. That one thing aside, if it's this easy,
why has no one done this before? The best answer I can tell is it
requires an minor ABI change, where C preprocessor macros relating to
system interfaces need to be symbolic. This is barely an issue, except
in cases like <code>switch(errno){case EINVAL:...}</code>. If we feel
comfortable bending the rules, then the GNU Linker can easily be
configured to generate at linktime all the PE/Darwin data structures we
need, without any special toolchains.

</p><h3>PKZIP Executables Make Pretty Good Containers</h3>

<p>
Single-file executables are nice to have. There are a few cases where
static executables depending on system files makes sense, e.g. zoneinfo.
However we can't make that assumption if we're building binaries
intended to run on multiple distros with Windows support too.

</p><p>
As it turns out, PKZIP was designed to place its magic marker at the end
of file, rather than the beginning, so we can synthesize ELF/PE/MachO
binaries with ZIP too! I was able to implement this efficiently in the
Cosmopolitan codebase using a few lines of linker script, along with a
program for incrementally compressing sections.

</p><p>
It's possible to run <code>unzip -vl executable.com</code> to view its
contents. It's also possible on Windows 10 to change the file extension
to .zip and then open it in Microsoft's bundled ZIP GUI. Having that
flexibility of being able to easily edit assets post-compilation means
we can also do things like create an easily distributable JavaScript
interpreter that reflectively loads interpreted sources via zip.

</p><p>
  <a href="https://justine.lol/hellojs.com">hellojs.com</a> is 300kb (<a href="https://justine.lol/hellojs.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hellojs.c">source</a>)

</p><p>
Cosmopolitan also uses the ZIP format to automate compliance with the
GPLv2 [update 2020-12-28: APE is now licensed ISC]. The non-commercial
libre build is configured, by default, to embed any source file linked
from within the hermetic make mono-repo. That makes binaries roughly 10x
larger. For example:

</p><p>
  <a href="https://justine.lol/life2.com">life2.com</a> is 216kb (<a href="https://justine.lol/life2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello2.com">hello2.com</a> is 256kb (<a href="https://justine.lol/hello2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Rock musicians have a love-hate relationship with dynamic range
compression, since it removes a dimension of complexity from their
music, but is necessary in order to sound professional. Bloat might work
by the same principles, in which case, zip source file embedding could
be a more socially conscious way of wasting resources in order to gain
appeal with the non-classical software consumer.

</p><h3>x86-64 Linux ABI Makes a Pretty Good Lingua Franca</h3>

<p>
It wasn't until very recently in computing history that a clear shakeout
occurred with hardware architectures, which is best evidenced by the
<a rel="nofollow" href="https://en.wikipedia.org/w/index.php?title=TOP500&amp;oldid=966847096#Architecture_and_operating_systems">TOP
500 list</a>. Outside phones routers mainframes and cars, the consensus
surrounding x86 is so strong, that I'd compare it to the Tower of Babel.
Thanks to Linus Torvalds, we not only have a consensus on architecture,
but we've come pretty close to having a consensus on the input output
mechanism by which programs communicate with their host machines, via
the SYSCALL instruction. He accomplished that by sitting at home in a
bathrobe sending emails to huge corporations, getting them to agree to
devote their resources to creating something beautifully opposite to
tragedy of the commons.

</p><p>
So I think it's really the best of times to be optimistic about systems
engineering. We agree more on sharing things in common than we ever
have. There are still outliers like the plans coming out of Apple and
Microsoft we hear about in the news, where they've sought to pivot PCs
towards ARM. I'm not sure why we need a C-Class Macintosh, since the
x86_64 patents should expire this year. Apple could have probably made
their own x86 chip without paying royalties. The free/open architecture
that we've always dreamed of, might turn out to be the one we're already
using.

</p><p>
If a microprocessor architecture consensus finally exists, then I
believe we should be focusing on building better tools that help
software developers benefit from it. One of the ways I've been focusing
on making a contribution in that area, is by building a friendlier way
to visualize the impact that x86-64 execution has on memory. It should
should hopefully clarify how <span aria-label="Actually Portable
Executable">αcτµαlly pδrταblε εxεcµταblε</span> works.

</p><center>
    <video id="video" width="960" height="540" controls="" autoplay="" muted="" loop="">
      <source src="https://storage.googleapis.com/justine/emulator2.mp4" type="video/mp4">
    </video>
    
  </center>

<p>
You'll notice that execution starts off by treating the Windows PE
header as though it were code. For example, the ASCII string <code>"MZqFpD"</code>
decodes as <code>pop %r10 ; jno 0x4a ; jo 0x4a</code> and the string
<code>"\177ELF"</code> decodes as <code>jg 0x47</code>. It then hops
through a mov statement which tells us the program is being run from
userspace rather than being booted, and then hops to the entrypoint.

</p><p>
Magic numbers are then 
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/systemfive.S">easily
unpacked</a> for the host operating system using decentralized sections
and the GNU Assembler <code>.sleb128</code> directive. Low entropy data
like UNICODE bit lookup tables will generally be decoded using either
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/str/lz4cpy.c">103
byte LZ4 decompressor</a> or
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/nexgen32e/rldecode.S">17
byte run-length decoder</a>, and runtime code morphing can easily be
done using
Intel's <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/third_party/xed/x86ild.greg.c">3kb
x86 decoder</a>.

</p><p>
Please note that this emulator isn't a
requirement. <span aria-label="Actually Portable Executables">αcτµαlly
pδrταblε εxεcµταblεs</span> work fine if you just run them on the shell,
the NT command prompt, or boot them from the BIOS. This isn't a JVM. You
only use the emulator if you need it. For example, it's helpful to be
able to have cool visualizations of how program execution impacts
memory.

</p><p>
It'll be nice to know that any normal PC program we write will "just
work" on Raspberry Pi and Apple ARM. All we have to do embed an ARM
build of the emulator above within our x86 executables, and have them
morph and re-exec appropriately, similar to how Cosmopolitan is already
doing doing with qemu-x86_64, except that this wouldn't need to be
installed beforehand. The tradeoff is that, if we do this, binaries will
only be 10x smaller than Go's Hello World, instead of 100x smaller. The
other tradeoff is the GCC Runtime Exception forbids code morphing, but I
already took care of that for you, by rewriting the GNU runtimes.

</p><p>
The most compelling use case for making x86-64-linux-gnu as tiny as
possible, with the availability of full emulation, is that it enables
normal simple native programs to run everywhere including web browsers
by default. Many of the solutions built in this area tend to focus too
much on the interfaces that haven't achieved consensus, like GUIs and
threads, otherwise they'll just emulate the entire operating system,
like Docker or Fabrice Bellard running Windows in browsers. I think we
need compatibility glue that just runs programs, ignores the systems,
and treats x86_64-linux-gnu as a canonical software encoding.

</p><h3>Long Lifetime Without Maintenance</h3>

<p>
One of the reasons why I love working with a lot of these old unsexy
technologies, is that I want any software work I'm involved in to stand
the test of time with minimal toil. Similar to how the Super Mario Bros
ROM has managed to survive all these years without needing a GitHub
issue tracker.

</p><p>
I believe the best chance we have of doing that, is by gluing together
the binary interfaces that've already achieved a decades-long consensus,
and ignoring the APIs. For example, here are the
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/consts.sh">magic
numbers</a> used by Mac, Linux, BSD, and Windows distros. They're worth
seeing at least once in your life, since these numbers underpin the
internals of nearly all the computers, servers, and phones you've used.

</p><p>
If we focus on the subset of numbers all systems share in common, and
compare it to their common ancestor, Bell System Five, we can see that
few things about systems engineering have changed in the last 40 years
at the binary level. Magnums are boring. Platforms can't …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justine.lol/ape.html">https://justine.lol/ape.html</a></em></p>]]>
            </description>
            <link>https://justine.lol/ape.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273960</guid>
            <pubDate>Fri, 26 Feb 2021 12:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Montevideo Convention on the Rights and Duties of States (1933)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273859">thread link</a>) | @simonebrunozzi
<br/>
February 26, 2021 | https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml | <a href="https://web.archive.org/web/*/https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-main">
       

       

           
            

       <!--startindex-->
       


<p>Done at: Montevideo</p>
<p>Date enacted: 1933-12-26</p>
<p>In force: 1934-12-26</p>
<div>
<p>The Governments represented in the Seventh International Conference of American States:
</p>
<p>Wishing to conclude a Convention on Rights and Duties of States, have appointed the following
Plenipotentiaries:</p>
<p>[List of plenipotentiaries omitted]</p>
<p>Who, after having exhibited their Full Powers, which were found to be in good and due order, have
agreed upon the following:</p>
</div>
<div>
<h3 id="article-header-1">Article 1</h3>
<p>The state as a person of international law should possess the following qualifications:</p>
<table>
<tbody><tr>
<td nowrap="">a.</td><td>
<p>a permanent population;</p>
</td>
</tr>
<tr>
<td nowrap="">b.</td><td>
<p>a defined territory;</p>
</td>
</tr>
<tr>
<td nowrap="">c.</td><td>
<p>government; and</p>
</td>
</tr>
<tr>
<td nowrap="">d.</td><td>
<p>capacity to enter into relations with the other states.</p>
</td>
</tr>
</tbody></table>
</div>
<div>
<h3 id="article-header-2">Article 2</h3>
<p>The federal state shall constitute a sole person in the eyes of international law.</p>
</div>
<div>
<h3 id="article-header-3">Article 3</h3>
<p>The political existence of the state is independent of recognition by the other states. Even before recognition the state has the right to defend its integrity and independence, to provide for its conservation and prosperity, and consequently to organize itself as it sees fit, to legislate upon its interests, administer its services, and to define the jurisdiction and competence of its courts. The exercise of these rights has no other limitation than the exercise of the rights of other states according to international law.</p>
</div>
<div>
<h3 id="article-header-4">Article 4</h3>
<p>States are juridically equal, enjoy the same rights, and have equal capacity in their exercise. The rights of each one do not depend upon the power which it possesses to assure its exercise, but upon the simple fact of its existence as a person under international law.</p>
</div>
<div>
<h3 id="article-header-5">Article 5</h3>
<p>The fundamental rights of states are not susceptible of being affected in any manner whatsoever.</p>
</div>
<div>
<h3 id="article-header-6">Article 6</h3>
<p>The recognition of a state merely signifies that the state which recognizes it accepts the personality of the other with all the rights and duties determined by international law. Recognition is unconditional and irrevocable.</p>
</div>
<div>
<h3 id="article-header-7">Article 7</h3>
<p>The recognition of a state may be express or tacit. The latter results from any act which implies the intention of recognizing the new state.</p>
</div>
<div>
<h3 id="article-header-8">Article 8</h3>
<p>No state has the right to intervene in the internal or external affairs of another.</p>
</div>
<div>
<h3 id="article-header-9">Article 9</h3>
<p>The jurisdiction of states within the limits of national territory applies to all the inhabitants. Nationals and foreigners are under the same protection of the law and the national authorities and the foreigners may not claim rights other or more extensive than those of the nationals.</p>
</div>
<div>
<h3 id="article-header-10">Article 10</h3>
<p>The primary interest of states is the conservation of peace. Differences of any nature which arise between them should be settled by recognized pacific methods.</p>
</div>
<div>
<h3 id="article-header-11">Article 11</h3>
<p>The contracting states definitely establish as the rule of their conduct the precise obligation not to recognize territorial acquisitions or special advantages which have been obtained by force whether this consists in the employment of arms, in threatening diplomatic representations, or in any other effective coercive measure. The territory of a state is inviolable and may not be the object of military occupation nor of other measures of force imposed by another state directly or indirectly or for any motive whatever even temporarily.</p>
</div>
<div>
<h3 id="article-header-12">Article 12</h3>
<p>The present Convention shall not affect obligations previously entered into by the High Contracting Parties by virtue of international agreements.</p>
</div>
<div>
<h3 id="article-header-13">Article 13</h3>
<p>The present Convention shall be ratified by the High Contracting Parties in conformity with their respective constitutional procedures. The Minister of Foreign Affairs of the Republic of Uruguay shall transmit authentic certified copies to the governments for the aforementioned purpose of ratification. The instrument of ratification shall be deposited in the archives of the Pan American Union in Washington, which shall notify the signatory governments of said deposit. Such notification shall be considered as an exchange of ratifications.</p>
</div>
<div>
<h3 id="article-header-14">Article 14</h3>
<p>The present Convention will enter into force between the High Contracting Parties in the order in which they deposit their respective ratifications.</p>
</div>
<div>
<h3 id="article-header-15">Article 15</h3>
<p>The present Convention shall remain in force indefinitely but may be denounced by means of one year's notice given to the Pan American Union, which shall transmit it to the other signatory governments. After the expiration of this period the Convention shall cease in its effects as regards the party which denounces but shall remain in effect for the remaining High Contracting Parties.</p>
</div>
<div>
<h3 id="article-header-16">Article 16</h3>
<p>The present Convention shall be open for the adherence and accession of the States which are not signatories. The corresponding instruments shall be deposited in the archives of the Pan American Union which shall communicate them to the other High Contracting Parties.</p>
</div>
<div>

<p>In witness whereof, the following Plenipotentiaries have signed this Convention in Spanish, English, Portuguese and French and hereunto affix their respective seals in the city of Montevideo, Republic of Uruguay, this 26th day of December, 1933.</p>
</div>
<div>

<p>Number of ratifications: 16</p>
<p>Brazil, Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Ecuador, El Salvador, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Panama, United States of America, Venezuela</p>
</div>

       <!--stopindex-->
     </div></div>]]>
            </description>
            <link>https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273859</guid>
            <pubDate>Fri, 26 Feb 2021 11:51:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Reading More Effectively and Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 162 (<a href="https://news.ycombinator.com/item?id=26273735">thread link</a>) | @ingve
<br/>
February 26, 2021 | https://aliabdaal.com/read-more-effectively/ | <a href="https://web.archive.org/web/*/https://aliabdaal.com/read-more-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>It might seem odd to have a blog post devoted entirely to reading. After all, if you’re reading this, chances are you can read. But reading effectively and efficiently is its own skill - one that we’re never really taught how to do.</p><p>Throughout our academic life, we’re programmed to believe that effective reading is measured by speed and breadth. The more we can read, the smarter we look. And the more broadly we can read, the more intelligent we seem.</p><p>In fact, I’ve fallen prey to this myself, making a clickbait video called <em><a href="https://www.youtube.com/watch?v=8tKuviI68Ss">How I Read 100 Books a Year</a></em>. Full disclosure: I don’t actually. It’s closer to 50. But that makes for a less clickable video (sorry, not sorry).</p><p>Because of this obsession we have with reading more, we miss out on a lot of valuable insights. Wisdom from across the ages, the lessons mastered by people who've overcome extraordinary challenges, and the chance to gain knowledge that challenges our beliefs. All because we're never taught the ultimate meta-skill: the art of reading.</p><p>Reading more effectively and efficiently means developing a watertight process to <strong>capture ideas</strong>, <strong>analyse arguments</strong>, and <strong>ask the right questions</strong>. It means identifying the <strong>right books to read</strong>, understanding the <strong>different reading goals</strong>, and using evidence-based techniques to <strong>increase reading productivity</strong>.</p><p>In many ways, improving the way we read is the number one skill that can change our lives for the better.</p><h2 id="the-importance-of-effective-efficient-reading">The Importance of Effective &amp; Efficient Reading</h2><blockquote>“A person who won’t read has no advantage over one who can’t read" - Mark Twain</blockquote><p>Books have had an enormous impact on my own life. They’ve acted as a personal mentor, and as a vehicle for compounding knowledge.</p><h3 id="-books-have-been-my-personal-mentors">🤓 Books have been my Personal Mentors</h3><p>If someone asked me to name the most influential people in shaping my life (outside of my immediate family), I wouldn't find it too hard to identify a group of people who've transformed my thinking through their incredible actions, ideas, and journeys. But the number one influence in my life wouldn't be people at all. It would be books.</p><p>By reading lots of books (and by trying to read effectively), I've managed to accumulate decades worth of knowledge and experience from the world's most incredible minds, with minimal personal effort. I've learned from mistakes without having to fail, I've learned from successes without having to take huge risks, and I've travelled thousands of miles without leaving the comfort of my bed in Cambridge.</p><p>Reading is the mentor without the cost, the pain, and the discomfort. I honestly wouldn't have started <a href="https://6med.co.uk/">6med</a>, my <a href="https://www.youtube.com/channel/UCoOae5nYA7VqaXzerajD0lg">YouTube channel</a>, or decided to <a href="https://book.aliabdaal.com/">write a book</a> without the encouragement, motivation, inspiration, and boundless insights offered by my paper friends. Seriously. My only regret is that I didn't learn to read properly sooner.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/hv1gOEY3cs4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>3 Books That Changed My Life</figcaption></figure><h3 id="-books-help-us-compound-knowledge">🧠 Books help us Compound Knowledge</h3><blockquote>"Compound interest is the 8th Wonder of the World" - Albert Einstein</blockquote><p>Just as money accumulates exponentially, so too does personal knowledge as it snowballs and branches out over time. In other words, the more we read and the better our reading processes are, the more our ideas, beliefs, and opinions begin to develop at an ever-increasing rate.</p><p>Not only does our brain begin effortlessly creating connections between seemingly disparate pieces of information, but cohesive and creative solutions to some of our most puzzling and perplexing problems gradually emerge. It's a personal superpower that all of us have the opportunity to discover.</p><blockquote>“To develop a complete mind: Study the science of art; Study the art of science. Learn how to see. Realise that everything connects to everything else” - Da Vinci</blockquote><h2 id="the-reading-objective">The Reading Objective</h2><p>Increasing our ability to read more effectively, as a means to unlock our own personal potential, begins by deciding on a reading goal. After all, we’re probably going to have a different objective and experience reading <em>Paradise Lost</em> compared to our favourite <em>Harry Potter</em> book.</p><p>Many brilliant authors talk about books as having a rather loose objective of success, happiness, and personal fulfilment. Roald Dahl, for instance, said that "if you are going to get anywhere in life, you have to read a lot of books". And J. K. Rowling once said that "something very magical can happen when you read a good book".</p><p>But I’d agree, these opinions are abstract, subjective, and largely unhelpful in guiding the way in which we should read. Instead, it's easier and more useful for our purposes to segment reading objectives into three distinct categories, as identified by Mortimer Adler in <em><a href="https://geni.us/HkStXXO">How to Read a Book</a></em>.</p><h3 id="-category-1-reading-to-entertain">🤪 Category 1: Reading to Entertain</h3><p>In this category, we read books purely for enjoyment. It’s how we spend the majority of our time as readers. There are no rules and there's no need to think too deeply or critically about what we’re reading. The goal is simple: we can relax and immerse ourselves in the story.</p><p>There’s nothing inherently wrong with reading to entertain ourselves.</p><p>It's a healthy way to escape from everyday stress and, if you're anything like me, a perfect way to finish <a href="https://www.youtube.com/watch?v=KMskdqtR1yA">a productive day of work</a>. In particular, I enjoy reading (or listening to) fantasy novels (with the <a href="https://brandonsanderson.com/">Brandon Sanderson</a> books being a personal favourite). I even created a video on <em><a href="https://www.youtube.com/watch?v=i7awefFU_Hg">My Favourite Fantasy Books</a></em>, which you can check out if you're interested.</p><h3 id="-category-2-reading-to-inform">🗞 Category 2: Reading to Inform</h3><p>In this second category, we read books to learn specific facts or information about something. These books are typically easy to navigate and simple in their layout and structure. This lets us consume them effortlessly and jump around to relevant sections without losing the gist of what's being said. The goal is to <strong>learn without judgement</strong>.</p><p>For example, we'd read the newspaper, a tourist guide, or the <em>Guinness World Records, </em>all to inform. Although we may find aspects of each of them entertaining, we primarily read these things to develop a factual picture of current affairs, a particular location, or some other snippet of knowledge.</p><p>Again, for most of us, reading to inform isn't too problematic.</p><h3 id="-category-3-reading-to-understand">📖 Category 3: Reading to Understand</h3><p>It's the final category of reading - reading to understand - that most of us (including me) tend to struggle with. It therefore deserves most of our attention when it comes to improving the efficiency and effectiveness of our reading.</p><p>The problem is that out of the three reading categories, reading to understand requires the greatest cognitive effort. It forces us to challenge our preconceptions, critically analyse the status quo, and directly confront ideas that we may not be immediately comfortable with. This is hard. It can be uncomfortable. But it’s the only way for us to level-up our thinking and personal growth.</p><p>Ultimately, this is a skill that few of us have mastered. But it's at the very heart of meaningful productivity and improving the way we read. Therefore, we need a method that takes us from reading at an elementary level (like when we’re reading to entertain and inform) to reading at an analytical or syntopical level.</p><p>Let's dive into how we can do this.</p><h2 id="the-four-levels-of-reading">The Four Levels of Reading</h2><figure><img src="https://aliabdaal.com/content/images/2021/02/GW-Article.png" alt="" srcset="https://aliabdaal.com/content/images/size/w600/2021/02/GW-Article.png 600w, https://aliabdaal.com/content/images/size/w1000/2021/02/GW-Article.png 1000w, https://aliabdaal.com/content/images/size/w1600/2021/02/GW-Article.png 1600w, https://aliabdaal.com/content/images/2021/02/GW-Article.png 2000w" sizes="(min-width: 720px) 720px"></figure><p>While the three categories of reading help guide our reading goal, the four cumulative levels of reading help guide our reading style. These levels were again devised by Mortimer Adler and operate to help us understand a book at a far deeper level than what most of us are used to. As we move up the levels we'll not only find ourselves more capable of grasping the author's perspectives and forge deeper insights, but we'll have a process that works with every single book we decide to read.</p><p>This is great stuff.</p><h3 id="-level-1-elementary-reading">👶 Level 1: Elementary Reading</h3><p>The first level of reading is the style of reading that everyone knows how to do, as it's what we're taught in school. As an elementary reader we can easily understand the words on the page, follow the plot, and have a solid grasp of what the book is trying to say.</p><p>However, even at this elementary level, it's easy to screw it up by trying to read too quickly.</p><p>As you know, I'm all about <a href="https://aliabdaal.com/productivity/">increasing productivity</a>, but trying to improve reading speed before understanding the fundamentals of effective reading is only going to hinder our capacity to learn new information.</p><p>My advice - we should try and first improve our reading level. Then, once we've mastered the art of reading analytically, we can worry about reading faster (and we'll talk more about this later).</p><blockquote>"Every book should be read no more slowly than it deserves, and no more quickly than you can read it with satisfaction and comprehension” - Adler</blockquote><h3 id="-level-2-inspectional-reading">🔎 Level 2: Inspectional Reading</h3><p>This second level of reading requires marginally more skill than at the elementary reading level. As an inspectional reader we're tasked with unearthing the overall framework of the book and mapping out the general picture the author is trying to paint. The idea is that we're making some preliminary calculations about the book's content and worth before delving into it properly.</p><p>There are two aspects to inspectional reading: systematic skimming and superficial reading.</p><p><strong>Systematic Skimming</strong></p><p>With systematic skimming our aim is to decide whether or not this is a book we actually want to spend the time reading. I like to ask myself "is this one of the greats that I'd happily spend the next few hours of my life looking at?". If the answer is anything less than "hell yes!" then I won't bother reading it.</p><p>To help me answer this question, I first look at the title, the blurb, and the contents page to determine what the book is about and understand its high-level structure. I then flip through the book concentrating on each chapter's introduction, conclusion, and any sub-headings that interest me. In other words, I do a surface level examination of the book before writing a couple of sentences that neatly summarises everything.</p><p>Another way to systematically skim a book is by reading a book summary. My favourite way of doing this is with the service <a href="https://go.aliabdaal.com/shortform">Shortform</a>. If a book’s available on <a href="https://go.aliabdaal.com/shortform">Shortform</a> (they’re always adding …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aliabdaal.com/read-more-effectively/">https://aliabdaal.com/read-more-effectively/</a></em></p>]]>
            </description>
            <link>https://aliabdaal.com/read-more-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273735</guid>
            <pubDate>Fri, 26 Feb 2021 11:36:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of Wittgenstein's Tractatus logico-philosophicus]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273670">thread link</a>) | @martinlaz
<br/>
February 26, 2021 | https://pbellon.github.io/tractatus-tree/ | <a href="https://web.archive.org/web/*/https://pbellon.github.io/tractatus-tree/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pbellon.github.io/tractatus-tree/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273670</guid>
            <pubDate>Fri, 26 Feb 2021 11:25:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and most alternatives share the same problem]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 179 (<a href="https://news.ycombinator.com/item?id=26273594">thread link</a>) | @sysoleg
<br/>
February 26, 2021 | https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/ | <a href="https://web.archive.org/web/*/https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
            
            
<p>Shall I migrate to Signal, Threema or Telegram? No, because they all have — WhatsApp included — the same problem: They are walled gardens. Imagine a world where for each mail recipient using a separate domain, I would need separate mail client? Or in other words: Gmail users can only communicate with Gmail users.</p>



<h5>Let’s start with mail first.</h5>



<p>The origin of mail were a couple of geeks who wanted to exchange messages on ARPANET (the internets great grandmother). At the time they solved two challenges. Invent a packet-switching network with distributed control that was intended to survive a nuclear attack. And hook up different types of computers types that were not interoperable at the time: A DEC PDP-10, a SDS Sigma 7, an IBM 360/75 and SDS 940. The second topic is our primary issue here.</p>



<figure><img loading="lazy" width="622" height="749" src="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg 622w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-249x300.jpg 249w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-580x698.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-320x385.jpg 320w" sizes="(max-width: 622px) 100vw, 622px"></figure>



<p>To achieve this they agreed on a common terminology and on common standards to exchange messages in a collaborative way. Layering on existing definitions (such as TCP/IP) they created:</p>



<ul><li>RFC 524: <a href="https://tools.ietf.org/html/rfc524">A Proposed Mail Protocol</a></li><li>RFC 561: <a href="https://tools.ietf.org/html/rfc561">Standardizing Network Mail Headers</a></li><li>RFC 680: <a href="https://tools.ietf.org/html/rfc680">Message Transmission Protocol</a></li><li>RFC 724: <a href="https://tools.ietf.org/html/rfc724">Proposed Official Standard for the Format of ARPA Network Messages</a></li></ul>



<p>That summed up later in the document RFC 733: <a href="https://tools.ietf.org/html/rfc733">STANDARD FOR THE FORMAT OF ARPA NETWORK TEXT MESSAGES</a> . And many of the aspects solved back then still live in today’s mail infrastructure. Including an address scheme using “@”.</p>



<figure><img loading="lazy" width="1024" height="655" src="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg 1024w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-300x192.jpg 300w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-768x492.jpg 768w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1536x983.jpg 1536w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-720x461.jpg 720w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-580x371.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-320x205.jpg 320w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson.jpg 1656w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raymond&nbsp;Tomlinson who implemented the first&nbsp;email&nbsp;program on the&nbsp;ARPANET</figcaption></figure>



<p>Later the transport of the messages (originally they used multiple protocols such as CPYNET, UUCP or FTP) transitioned in 1981 to SMTP which is still todays way to transport mail. All of this allows that any mail client (MUA = Mail User Agent) can talk via any mail server (MTA = Mail Transfer Agent). An open, collaborative process defining an interoperable system.</p>



<h5>And now come the instant messengers.</h5>



<p>As I already said Signal, Threema, Telegram AND WhatsApp are broken. Why does everybody wanting to exchange messages need the same client? Before digging into more technical detail or rant about companies earning money with closed gardens let come to a possible solution: <a href="https://matrix.org/">The Matrix-Protocol</a>. In short it’s about the same deal as mail (building on HTTP and WebRTC) but for chat-messaging (including IP-telephony and video-telephony) initiated by a non-profit foundation based in the UK. After XMPP or IRC it’s not the only approach to solve the issue, but so far the most successful.</p>



<p>Their reference implementation of the client is called <a href="https://matrix.org/docs/projects/client/element">Element (former Riot)</a> and a server called <a href="https://github.com/matrix-org/synapse/">Synapse</a>. So in theory there could be any chat client communicating over any chat server to any chat client. Sadly it’s not really used yet. Although the <a href="https://www.heise.de/security/meldung/Tchap-Frankreichs-nicht-so-exklusiver-Regierungschat-4403961.html">French Government</a> is supporting it with a client implementation named Tchap and <a href="https://www.golem.de/news/messenger-bundeswehr-will-komplett-auf-matrix-chat-wechseln-2005-148407.html">German Bundeswehr</a> plans to do alike.</p>



<h5>So what?</h5>



<p>Well no real cheering news and in case don’t want to be alone on Matrix you can write to @juerg:matrix.org.</p>



<p>And will it work? No, because there is already too much money in the game (and telcos try to <a href="https://stuker.com/2018/die-sms-nachfolge-heisst-rcs-rich-communication-services/">reanimate the SMS Eldorado</a> too, without success).</p>



<p>But it would be the right thing. And me? I don’t’ switch, I use them all!</p>



<p>PS: The post was inspired by the very nice article <a href="https://www.republik.ch/2021/02/24/kill-the-messenger">“Kill the Messenger”</a>.</p>

                        
            
        </div></div>]]>
            </description>
            <link>https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273594</guid>
            <pubDate>Fri, 26 Feb 2021 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jq is a lightweight and flexible command-line JSON processor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273534">thread link</a>) | @Gedxx
<br/>
February 26, 2021 | https://stedolan.github.io/jq/ | <a href="https://web.archive.org/web/*/https://stedolan.github.io/jq/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="multiblurb">
        <p>jq is like <code>sed</code> for JSON data - you can use it to slice and filter
and map and transform structured data with the same ease that <code>sed</code>,
<code>awk</code>, <code>grep</code> and friends let you play with text.</p>
        <p>jq is written in portable C, and it has zero runtime
dependencies. You can download a single binary, <code>scp</code> it to a far away
machine of the same type, and expect it to work.</p>
        <p>jq can mangle the data format that you have into the one that you
want with very little effort, and the program to do so is often
shorter and simpler than you'd expect.</p>
      </div></div>]]>
            </description>
            <link>https://stedolan.github.io/jq/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273534</guid>
            <pubDate>Fri, 26 Feb 2021 11:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Dumb TVs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26273169">thread link</a>) | @rbanffy
<br/>
February 26, 2021 | https://frame.work/blog/in-defense-of-dumb-tvs | <a href="https://web.archive.org/web/*/https://frame.work/blog/in-defense-of-dumb-tvs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Smart TV was once a term reserved for high end televisions with built-in streaming capabilities.&nbsp; The combination of massive reductions in panel costs, decreasing costs for embedded compute, and the ready availability of content platforms from Google, Roku, and others has made the term irrelevant.&nbsp; Almost every TV you can buy today has smarts built-in.&nbsp; There have been some fantastic outcomes of that, like breaking up the traditional channel bundle and increasing access to more personalized and niche content.</p>
<p>There have been some serious negatives too.&nbsp; Decreasing prices and decreasing margins on TVs combined with long replacement cycles have driven companies to take advantage of built-in smarts to enable a new revenue source: user data and advertising.&nbsp; As of Q2 2020, Vizio and HiSense are the <a href="https://www.rtings.com/tv/tests/ads-in-smart-tv" target="_blank" rel="noopener">only major brands</a> making TVs that ship without advertising enabled in their UIs.&nbsp; Sony, Samsung, LG, and others have ads enabled by default, most of which can’t be disabled.&nbsp; All of the above brands have built capability to aggregate data on what content is being viewed, and again, not all of them have the option to disable that.&nbsp; TVs smart enough to help you are also smart enough to harm you.&nbsp; Incredibly, Samsung even <a href="https://www.samsung.com/us/support/tip/TIP00083197/" target="_blank" rel="noopener">recommends</a> that you run virus and malware checking on your TV regularly.</p>
<p>An obvious way out of this as a consumer is to buy a TV without smarts built in (a “dumb TV”) and then add your own content source that is privacy focused like <a href="https://www.google.com/url?sa=j&amp;url=https%3A%2F%2Ffoundation.mozilla.org%2Fen%2Fprivacynotincluded%2Fproducts%2Fapple-tv-4k%2F&amp;uct=1603511873&amp;usg=vKN2pgP52PToUDpxmZ4Qm04kwj0.&amp;source=chat" target="_blank" rel="noopener">Apple TV</a> or that you have full control over like <a href="https://kodi.tv/" target="_blank" rel="noopener">Kodi</a>.&nbsp; This is something we personally looked for when we were buying a display for the conference room at Framework’s headquarters.&nbsp; Amazingly enough though, we found that none of the major consumer TV brands make basic “dumb” displays anymore.&nbsp; There are options in the commercial space like <a href="https://www.sharpnecdisplays.us/solutions/corporate/3" target="_blank" rel="noopener">NEC’s commercial displays</a>, but they cost substantially more than the consumer-focused alternatives.</p>
<p>We nearly gave in and bought a typical smart TV, and then we stumbled on <a href="https://www.sceptre.com/TV/4K-UHD-TV-category1category73.html?sort=tbt.parent_pdtype&amp;order=DESC" target="_blank" rel="noopener">Sceptre’s TV lineup</a>.&nbsp; You’ll notice that they have a range of extremely similar looking sets that have minor specification and weight differences.&nbsp; Our best guess is that they source LCDs from panel manufacturers that are either excess stock or fail the quality specifications set by other brands and build extremely minimal TVs around them.&nbsp; We haven’t noticed any quality issues on our Sceptre set, but for our use case of showing slides and spreadsheets, it wouldn’t have mattered anyway.&nbsp; The product was perfect for us: a dumb TV that as an added bonus reduces e-waste by using panels that would otherwise be scrapped.</p>
<p>It’s an interesting business model, and one that is consumer friendly, environmentally considerate, and economically sound.&nbsp; That is a powerful combination that we need to see across all of consumer electronics.</p>

</div>
</div></div>]]>
            </description>
            <link>https://frame.work/blog/in-defense-of-dumb-tvs</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273169</guid>
            <pubDate>Fri, 26 Feb 2021 10:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do I need to add on top of Kubernetes?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273013">thread link</a>) | @anticristi
<br/>
February 26, 2021 | https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/ | <a href="https://web.archive.org/web/*/https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="10763" data-elementor-settings="[]"><div><div><section data-id="d9f7755" data-element_type="section"><div><div><div data-id="0c2b078" data-element_type="column"><div><div><div data-id="53500f0" data-element_type="widget" data-widget_type="text-editor.default"><div><p><h5>So you recently decided to increase development speed by adopting Kubernetes. Suddenly you face a lot of questions: Is Kubernetes sufficient by itself? What are all these projects around Kubernetes? What is vanilla Kubernetes? Do I need a Kubernetes distribution? Which one?</h5><h5>This post will highlight all the features that a DevOps team typically needs to add on top of a vanilla Kubernetes cluster to obtain a secure, production-ready Kubernetes cluster. Adding these features takes time and effort, hence, starting from a production-ready, battle-tested Kubernetes distribution can accelerate an organization’s adoption of Kubernetes.</h5></p></div></div><div data-id="fb2f93a" data-element_type="widget" data-widget_type="heading.default"><p><h2>What is vanilla Kubernetes?</h2></p></div><div data-id="f0e6f8e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>“Vanilla Kubernetes” is a term used to describe a Kubernetes setup which is as small as it can get. This is the kind of Kubernetes cluster one gets from managed Kubernetes offers, such as AWS EKS, Azure AKS or Google GKE, and Kubernetes installation tools, such as kops or kubespray.</span></p><p><span>Vanilla is as plain as it gets, and comes with no bells and whistles included. So it’s like buying the most basic car in the lot: It has steering wheel and seat belts, but no additional safety features. So it can be driven immediately, but it won’t help keep you safe with lane departure warnings or auto-breaking.</span></p><p><span>How minimal vanilla Kubernetes is, is subject to some debate. At the very least, Kubernetes needs the following components:</span></p><ul><li aria-level="1"><span>On the control-plane nodes: etcd, apiserver, scheduler and controller-manager.</span></li><li aria-level="1"><span>On the worker nodes: some container runtime and kubelet.</span></li></ul><p><span>(Without these, can anyone really call the system “a Kubernetes cluster”?)</span></p></div></div></div><div data-id="cd8cf58" data-element_type="widget" data-widget_type="heading.default"><p><h2>How vanilla is a vanilla Kubernetes really?</h2></p></div><div data-id="e486cdb" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>So far, you have a car without fuel. The above Kubernetes setup cannot really run anything yet: Kubernetes does not know how to make Pods, i.e., a collection of one-or-more containers, talk to each other. To this end, even the “most vanilla” Kubernetes comes with a Container Network Interface (CNI) addon, such as </span><a href="https://www.projectcalico.org/"><span>Calico</span></a><span>. Now Kubernetes needs to know how to bring traffic to your Pods and how to store their data, a function fulfilled by the so-called cloud controller.</span></p><p><span>Knowing what is happening inside your Kubernetes cluster — also called “observability” — is essential to avoid unplanned downtime and customer disappointment. Therefore, most managed Kubernetes offers also include a few more integrations with the underlying cloud provider. For example, Google GKE sends logs, metrics and traces to Google StackDriver.</span></p><p><span>Great! Now you can run your application, you can direct traffic within the cluster and you can get traffic from end users into the cluster and to your application. Furthermore, logs and metrics are collected. What would I need more than vanilla Kubernetes?</span></p></div></div></div><div data-id="78a210a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Add Secure Ingress Controller</h2></p></div><div data-id="bb5af44" data-element_type="widget" data-widget_type="text-editor.default"><div><p><span>Data privacy regulations — such as HIPAA and GDPR — require you to encrypt public Internet traffic. Even without regulatory pressure, it is a good idea to encrypt public Internet traffic, unless you are a fan of bad PR. </span><a href="https://en.wikipedia.org/wiki/TLS_termination_proxy"><span>TLS termination</span></a><span> — i.e., the “wall” that separates “encrypted traffic outside” from “unencrypted traffic inside” — could be performed by your cloud provider or your application. However, if you want to stay cloud agnostic and keep your application code focused on business logic, you can do TLS termination in the Kubernetes cluster. Projects, such as </span><a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/"><span>Ingress controller</span></a><span> and </span><a href="https://cert-manager.io/docs/"><span>cert-manager</span></a><span>, will not only provision TLS certificates for you, but will also rotate them before expiry. Rotating certificates is a best practice, but also a chore that sometimes gets forgotten if it is a manual process.&nbsp; Users would get a scary “</span><a href="https://www.ssl.com/guide/troubleshooting-ssl-tls-browser-errors-and-warnings/"><span>Warning: Potential Security Risk Ahead</span></a><span>” message and flock to your competitors.</span></p></div></div><div data-id="c682772" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Kubernetes is </span><a href="https://searchitoperations.techtarget.com/news/252487963/Kubernetes-security-defaults-prompt-upstream-dilemma"><span>not secure by default, nor by itself</span></a><span>. You should further improve your security posture, to minimize the risk of breaches. Why? If you handle personal data, GDPR requires you to </span><a href="https://edpb.europa.eu/our-work-tools/our-documents/guideline/personal-data-breach-notifications_en"><span>notify the data protection authority and/or your users of any breach</span></a><span>. Definitely not what your board wants to read in the newspaper.</span></p><p><span>Therefore, you should regularly scan for vulnerable container images with projects such as </span><a href="https://github.com/aquasecurity/trivy"><span>Trivy</span></a><span>. You should also consider adding intrusion detection via </span><a href="https://falco.org/"><span>Falco</span></a><span>. And don’t forget about disaster recovery! Projects, such as </span><a href="https://velero.io/"><span>Velero</span></a><span>, can backup your Kubernetes cluster and the application data hosted within. As they say: “Hope for the best, prepare for the worst.”</span></p></div></div></div><div data-id="5aaea15" data-element_type="widget" data-widget_type="shortcode.default"><div><div><div data-elementor-type="wp-post" data-elementor-id="8990" data-elementor-settings="[]"><div><div><section data-id="31e2d16" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="247a263" data-element_type="column"><div><div><div data-id="0b295df" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Want to keep up with the latest in cloud and Kubernetes?</p><p>Let us deliver it straight to your inbox!</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></div><div data-id="7781368" data-element_type="widget" data-widget_type="heading.default"><p><h2>Add Multi-Cloud Observability and Authentication</h2></p></div><div data-id="bbfbfa1" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Observability is an <a href="https://elastisys.com/what-was-observability-again/">essential feature of a platform</a>, to ensure that “2am events” are converted into daily checks. Many cloud providers come with great observability stacks included, such as AWS’s CloudWatch, GCP’s StackDriver, and Azure’s Monitor.</span></p><p><span>However, a multi-cloud strategy is seen as essential to cope with various risks </span><a href="https://elastisys.com/solving-privacy-shield-and-gdpr-with-kubernetes/"><span>associated with data privacy</span></a><span>, but also with contractual requirements, such as “data should stay within my jurisdiction”. Needless to say, integration with the underlying cloud provider provides a great productivity boost. However, it does not cater well to a multi-cloud strategy.</span></p><p><span>Fortunately, there are cloud agnostic alternatives:</span></p><ul><li aria-level="1"><a href="https://github.com/dexidp/dex"><span>Dex</span></a><span>, for cloud-agnostic authentication against the Kubernetes cluster (and yes, it can work with your current identity provider, such as Active Directory, LDAP, or Google accounts);</span></li><li aria-level="1"><a href="https://prometheus.io/"><span>Prometheus</span></a><span> and </span><a href="https://grafana.com/"><span>Grafana</span></a><span>, for metrics collection, analysis, visualization and alerting;</span></li><li aria-level="1"><a href="https://opendistro.github.io/for-elasticsearch/"><span>Elasticsearch</span></a><span> and </span><a href="https://www.elastic.co/kibana"><span>Kibana</span></a><span>, for log collection, analysis, visualization and alerting.</span></li></ul><p><span>With all these addons, your Kubernetes cluster should be ready to host your application, in a manner that is secure and observable.</span></p></div></div></div><div data-id="875e2e9" data-element_type="widget" data-widget_type="heading.default"><p><h2>Kubernetes Distributions: a One-Stop Shop</h2></p></div><div data-id="4496ccf" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>While adding all of the above components on top of a vanilla Kubernetes cluster is not rocket science, it does require careful configuration to make sure they work as a whole. Coming back to the car analogy, you can certainly buy an aftermarket lane departure warning system, but finding the right one and fitting it reliably still takes time. Wouldn’t it be great if it came pre-installed? And if you ever need support, wouldn’t you like it all to come from a single vendor that takes full responsibility for making it all work correctly?</span></p><p><span>Kubernetes distributions fill this gap: They enhance a vanilla Kubernetes cluster with carefully chosen and configured components to allow you and your team to focus on what is most important to your customers: Rapidly adding features to your application, without worrying about the hosting platform.</span></p></div></div></div><div data-id="2e281f0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h5>Are you looking for an open-source Kubernetes distribution with focus on observability and security? Check out&nbsp;<a href="https://compliantkubernetes.io/">Compliant Kubernetes</a>! Consider giving us a star at GitHub or contributing to the project.</h5></div></div></div></div></div></div></div></div></section><section data-id="4993597" data-element_type="section"></section></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273013</guid>
            <pubDate>Fri, 26 Feb 2021 09:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive real-time chemistry and fluids: water electrolysis]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26272642">thread link</a>) | @pkarnakov
<br/>
February 26, 2021 | https://cselab.github.io/aphros/wasm/electrochem.html | <a href="https://web.archive.org/web/*/https://cselab.github.io/aphros/wasm/electrochem.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cselab.github.io/aphros/wasm/electrochem.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272642</guid>
            <pubDate>Fri, 26 Feb 2021 08:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being on Call]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 124 (<a href="https://news.ycombinator.com/item?id=26272170">thread link</a>) | @colluder
<br/>
February 25, 2021 | https://tyler.kim/being-on-call | <a href="https://web.archive.org/web/*/https://tyler.kim/being-on-call">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

        <p>
          April 21, 2020

            ☼ <a href="https://tyler.kim/tagged/life">life</a>
            ☼ <a href="https://tyler.kim/tagged/roka">roka</a>
        </p>

        
<p>I’m an occasional on-call operator for my battalion, assisting the on-call commander and staffing the control room from 16:00 in the afternoon until 08:30 the next morning on weekdays. Most of the work is answering and making calls, updating documents, and making sure that nothing is out of the ordinary. It’s not that difficult, just tiring as there is a lot of stuff to follow and pay attention to through the night.&nbsp;</p>
<p>I was on-call on Friday, the 10th, and for 24 hours last Wednesday (not the usual shift), starting from 08:30 to the next 08:30 since it was the legislative election day in Korea. I wrote most of this post over those two shifts to share how I personally am being on-call.</p>

<hr>

<p>A little past 2300 is when I try to find some peace. I usually make myself a cup of coffee, and it doesn’t take long to feel the caffeine flowing through my bloodstream. I’m exhausted. It’s been many hours since I started my shift, and I have nine hours to go. No shift goes without a hectic evening with lots of random situations to handle, and they are usually followed by a series of paperwork.</p>
<p>I sit in front of a bunch of monitors and tactical comms equipment in bad posture, and the chair predates the concept of ergonomics. Meanwhile my feet are trapped in my airtight combat boots and they are begging to take a breath. In addition, no matter how much water I drink, my mouth is dry the whole time. It’s probably from all the sugar-intakes from snacking. It’s a similar feeling to a tiring second day at a college hackathon - constant snack intakes and sleep deprivation.</p>
<p>Around midnight, after I’m finished with all the paperwork that needs to be done by the morning, is a good time to seek solace in a cup ramen. It’s hard to convey the exact late-night-cup-ramen sentiment, but the hot soup warms you up in a way no others can console you in this late time.&nbsp;</p>
<p>I also have books with me so that I can read whenever I can. Late in the night especially after a ramen session is usually a good time to read. Every time I try to read in the evening or during the day, I either get a disruptive phone call or a situation, and they make me re-read the same page multiple times. It gets annoying after a couple of tries.</p>
<p>When I tried to read on the past few shifts, I faced some sad ironies. I brought <em>Why We Sleep</em> to my first shift. Reading about the importance of sleep while not being able to sleep was quite saddening, so I stopped after a few pages in. At least I learned why I feel wide awake towards the end of my shift (in the morning), and why I have difficulties sleeping after my shift despite being tired as hell. Now I’m reading <em>the Utopia of Rules</em>, a book filled with social commentaries on bureaucracy and filling out paper forms. Reading that in between the processing and filling out a ton of paperwork was yet another sad irony I encountered. Inevitably and unfortunately, as the night passes, my ability to focus gets decimated. I wish I could accomplish more reading on the job.&nbsp;</p>
<p>Around 0300~0400, a little after 12 hours (or 20) into the shift, I’m usually passed out on my desk. In a zombie-like state, I get half-woken up by periodic phone calls but I occasionally sleep through the ringings. Sometimes I answer the phone and pretend to handle whatever they tell me, and then go right back to sleep, forgetting everything I heard. I also get woken up when I have to unlock a small safe with ammunition for those going to a guard shift at night. Even then, my body isn’t fully awake sometimes.&nbsp;</p>
<p>By dawn, I can feel my internal organs are rotting. With that, my body starts to produce an uncomfortable amount of gas. A little past 0600, with my internal rhythm resetting, my body spontaneously wakes me up. It’s when I start to get busy again. Meanwhile my body goes through this illusion of feeling refreshed, but soon enough it feels like it has aged about six months over the past six hours. It’s obviously not a great feeling and it takes me about two full days to recover. Five more on-call shifts will age me by two years.&nbsp;</p>
<p>Despite such horribleness, the one positive aspect about doing the on-call shifts is that I get to sleep in and rest for the entirety of the next day, getting exempt from pretty much everything. Then, after one shift, two days have gone by just like that. Time flies and a week passes by only after a few days. And I get to rest over the weekend. That’s a good feeling to have in here, the sense of getting closer to the discharge date quicker than how I would feel it otherwise. Just gotta rinse and repeat till I’m out. It’s like Stockholm syndrome - despite how shitty I feel during and after the shift, I’m a bit disappointed that I don’t have a shift this week.</p>

        <br>

  

</div></div>]]>
            </description>
            <link>https://tyler.kim/being-on-call</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272170</guid>
            <pubDate>Fri, 26 Feb 2021 07:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ISO 8601: a better date format]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 394 (<a href="https://news.ycombinator.com/item?id=26272084">thread link</a>) | @kirbykevinson
<br/>
February 25, 2021 | https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/ | <a href="https://web.archive.org/web/*/https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

				
				
	<p>If you haven’t been living under a rock, you’ve probably heard that
there are different date formats in the world such as the American one
(mm/dd/yyyy) and the European one (dd.mm.yyyy). If you’re smart
enough, you’ve probably also noticed that the American one makes no
sense and is just awful. A simple conclusion that many people draw out
of this is that the European format is the best one, however I don’t
think this is true. If you’re one of these people who think so, I’m
here to (hopefully) change your mind by introducing you to a
lesser-known date format called ISO 8601.</p>
<h2 id="basics">Basics</h2>
<p>As you can see by the “ISO” part in the format’s name, it’s an actual
standard written by the International Organization for
Standardization. It defines many cool things like a way to write time
intervals, which can be useful for writing portable software, and a
calendar where the year is separated not by months but by weeks, which
is used in finances, but here we’re only interested in the basics.
Simplified, the core date format looks like this:</p>
<pre><code>yyyy-mm-dd hh:mm:ss
</code></pre><p>Yup, that’s about it. You write the year, the month, the day, and then
the time exactly like it’s done in other date formats. There’s nothing
extraordinary, so you can learn it in 2 minutes.</p>
<h2 id="why-its-better">Why it’s better</h2>
<h3 id="its-unambigous">It’s unambigous</h3>
<p>This is the main reason the standard was written and why people still
use it. Other date formats can be diffucult to tell apart. For
example, consider this date:</p>
<pre><code>02-03-04
</code></pre><p>When you read it out of context, you have absolutely no idea what’s
going on there. Is <code>02</code> here the day or the month? You just can’t know
unless the day in the date is greater than 12, in which case it just
can’t be a month:</p>
<pre><code>30-03-04
</code></pre><p>This day-month ambiguity is a really common problem, which often
occurs online. People just write down their dates in whatever date
format they know without even thinking that other people can interpret
it in different ways.</p>
<p>ISO 8601 doesn’t have this problem as it’s always obvious which part
is the day and which is the month because of the uniqueness of the
format:</p>
<pre><code>2004-03-02
</code></pre><h3 id="its-more-strict">It’s more strict</h3>
<p>While other date formats usually don’t provide strict requirements on
how to write something, ISO 8601 is an exception. Here there’s only
one correct way to write a date, which is not only useful for
computers to parse, but also helpful for humans to avoid confusion
with other formats and improve readability. Here are some of the
restrictions:</p>
<ul>
<li>The elements in the date are always separated by a hyphen. Not many
date formats use this delimiter, and this also can be useful when
using dates inside filenames as slashes are usually not accepted in
them.</li>
<li>The elements are always padded to the maximum number of digits. This
not only makes all of the dates look equally nice, but also, coupled
with other quirks of this format, allows the files with the date in
the name to be sorted just by the filename.</li>
<li>The year is always written in the full form. This makes the format
unique when written down and  eliminates <a href="https://en.wikipedia.org/wiki/Year_2000_problem">the year 2000 problem</a> in
any forms that it can take. For example, when writing down
birthdays, it always makes it obvious which century we’re talking
about.</li>
<li>The time is always written in the 24 hour format, so there can be no
confusion about what half of the day something happened in.</li>
</ul>
<h3 id="it-makes-more-sense">It makes more sense</h3>
<p>On the first glance, it seems like the European format is about as
logical as it can get - days go into months and months go into years:</p>
<pre><code>18.12.2002
---------&gt; Elements
</code></pre><p>However, this ignores a very important characteristic of numbers -
endianness. Consider a regular number, for example:</p>
<pre><code>69420
&lt;---- Digits
</code></pre><p>As you can see the digits here do the opposite of what elements do in
the European format. When the leftmost element of something is the
most valuable, we call it big endian.</p>
<p>Thus, the European format is little endian while the numbers in it are
big endian:</p>
<pre><code>18.12.2002
&lt;- &lt;- &lt;--- Digits
---------&gt; Elements
</code></pre><p>And the American format just makes no sense:</p>
<pre><code>12/18/2002
&lt;- &lt;- &lt;--- Digits
?????????? Elements
</code></pre><p>And, as you can see, ISO 8601 is completely consistent in this regard
as everything is big endian:</p>
<pre><code>2002-12-18
&lt;--- &lt;- &lt;- Digits
&lt;--------- Elements
</code></pre><p>The situation becomes even worse if you consider time because it is
big endian, like ISO 8601, thus doesn’t work with any other date
format:</p>
<pre><code>18.12.2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
---------&gt; &lt;------- Elements

12/18/2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
?????????? &lt;------- Elements

2002-12-18 23:03:59
&lt;--- &lt;- &lt;- &lt;- &lt;- &lt;- Digits
&lt;--------- &lt;------- Elements
</code></pre><p>If you’re still having trouble visualizing all of this in your head,
look at <a href="https://www.reddit.com/r/ISO8601/comments/ln33j2/datetime_format_by_region_visualised_v3_thanks/">this Reddit post</a>.</p>
<h3 id="its-standardized-and-actively-used">It’s standardized and actively used</h3>
<p>If you think that ISO 8601 is a silly thing that someone in their
basement made up and no one actually uses, think again because that
can’t be further from the truth:</p>
<ul>
<li>The fact that it’s standardized says at least something. Does your
favorite format has a neat several hundred page document where it’s
described in extreme detail and that is internationally recognized?
Also the standard is quite far from being dead - after being
published in 1988 it was updated in 1991, 2000, 2004, and 2019.</li>
<li>As I already mentioned, the standard is actively used in IT.
Almost everything that is used by software and somehow involves a
written numerical date format already speaks ISO 8601.</li>
<li>yyyy-mm-dd has been adapted or used since the beginning as a
national date format by many countries such as Canada, Sweden, and
Japan. See <a href="https://en.wikipedia.org/wiki/Date_format_by_country">this article</a> for more details.</li>
</ul>
<h2 id="frequently-asked-questions">Frequently asked questions</h2>
<h3 id="why-not-use-a-format-like-01-jan-2020">Why not use a format like 01-Jan-2020?</h3>
<p>It doesn’t have any of the nice features ISO 8601 has and doesn’t work
well internationally (i.e. assumes the person you’re communicating
with knows knows English). If you think the latter is not a problem,
imagine how you would feel feel if you had to read a date someone
wrote in their native language that you don’t understand:</p>
<pre><code>01-Янв-2020
</code></pre><h3 id="yyyy-mm-dd-looks-weird">yyyy-mm-dd looks weird</h3>
<p>The only reason why it does to you is because you’re not used to it.
After a little bit of practice, it’ll be even less weird than your
favorite date format.</p>
<h3 id="maybe-the-european-date-format-is-better-because-the-elements-are-in-the--order-of-relevance">Maybe the European date format is better because the elements are in the  order of relevance?</h3>
<p>First of all, the claim that the order of relevance is little endian
is quite questionable. The only situation when you can say that for
certain is when we’re talking about events occuring on a day-to-day
basis, however I can think of numerous cases when the year and the
month are more relevant:</p>
<ul>
<li>Article publication date</li>
<li>Historical event</li>
<li>Personal event that happened a long time ago</li>
<li>Someone’s birthday</li>
<li>Random database entry</li>
</ul>
<p>Second, the order of relevance is actually irrelevant. Even if the
order of relevance was this way, you’re not reading the dates out
loud, so there’s no need for them to be ordered a certain way. If
you’re not interested in the year, you just skip it and read the end
of the date just like you would do when reading time while not being
interested in the hour.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In my opinion, ISO 8601 seems clearly superior to other date formats
when it comes to international communication (such as posting things
online), and as you can see, I have enough reasons to say so. While
the format certainly has an audience, it’s unfortunate that it’s not
as big as it could be. By writing this article, I hope I made you at
least think about different date formats and be more careful when it
comes to making people understand what date you’re talking about.</p>


			</div></div>]]>
            </description>
            <link>https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272084</guid>
            <pubDate>Fri, 26 Feb 2021 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PureScript and Haskell]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26271851">thread link</a>) | @allenleein
<br/>
February 25, 2021 | https://blog.drewolson.org/purescript-and-haskell | <a href="https://web.archive.org/web/*/https://blog.drewolson.org/purescript-and-haskell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><time datetime="2021-02-24 00:00:00 -0600">February 24, 2021</time>
  </p>

  
  

  <p>Two years ago, I starting learning <a href="https://www.purescript.org/">PureScript</a>.  I
had been intrigued by purely functional programming for some time but had failed
to learn <a href="https://www.haskell.org/">Haskell</a> once or twice. PureScript seemed to
be a kinder, gentler introduction to this world while retaining the fundamental
properties of pureness that made Haskell intriguing to me. As part of my
learning process, I rebuilt a slack bot<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> I had previously written in go.</p>

<p>Once I had learned PureScript and become more comfortable with purely functional
idioms, the next logical step seemed to be learning Haskell. I was surprised to
discover how much Haskell I already knew from learning PureScript, but core
features like laziness (PureScript is a strict language) took some getting used
to.</p>

<p>I decided to finish my Haskell learning experience by rewriting my slack bot<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>
once again, this time in Haskell. In this post I’ll compare and contrast my
experiences writing the same program in Haskell and PureScript. The application
I built was “real” enough to have some interesting design challenges. They
included:</p>

<ul>
  <li>Exposing an HTTP endpoint</li>
  <li>Parsing and generating JSON</li>
  <li>Full-text search</li>
</ul>

<p>On to the comparison!</p>



<p>Haskell is a lazy language while PureScript is a strict one. I expected this
core difference to manifest itself constantly when writing these applications,
but in reality it rarely came up. I had predicted a lot of banging my head
against the wall dealing with laziness bugs but it just didn’t happen.</p>

<p>I will say that I generally prefer PureScript being a strict-by-default
language. When laziness is required, there are plenty of ways to <a href="https://blog.drewolson.org/laziness-in-purescript">get
it</a>, but it is always explicit.</p>

<p>While not directly related to strictness, a pain point on the PureScript side
that I didn’t experience in Haskell was stack safety<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. In PureScript, it can
often be confusing to determine if the operation you’re using is stack safe.
When these operations <em>aren’t</em> stack safe, the errors that are produced can be
confusing and hard to track down. I found myself struggling with stack safety in
PureScript far more than I struggled with laziness in Haskell.</p>



<p>A year or two ago, I would have simply said that PureScript has incredible
tooling and Haskell does not. Thanks to the amazing work on the <a href="https://github.com/haskell/haskell-language-server">Haskell
Language Server</a> project,
this gap is starting to close.</p>

<p>Regardless, PureScript still has far better tooling.
<a href="https://github.com/purescript/spago">Spago</a> is an incredible build tool that
offers many of the same features as
<a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> while remaining far
more user friendly and PureScript’s <a href="https://github.com/nwolverson/purescript-language-server">language
server</a> is excellent
and easy to install.</p>

<p>However, PureScript is currently struggling on a few fronts. First, the package
ecosystem is moving from bower to a
<a href="https://github.com/purescript/registry">registry</a> hosted on Github. The
resulting registry seems to be moving along nicely and I believe the result will
be incredible for the language, but the current in-between state is unfortunate.
I am glad the core maintainers are taking their time to design this registry
well and I firmly believe that this will be a strong positive for the PureScript
community in 6-12 months.</p>

<p>Second, PureScript doesn’t have a great option for a formatter. While
<a href="https://gitlab.com/joneshf/purty">purty</a> does exist, it seems to be mostly in
maintenance mode and many of the formatting choices are frustrating for me.
Specifically, the automatic removal of blank lines within functions and the
addition of newlines for <code>let</code> assignments in <code>do</code> blocks both hamper
readability and author intent. On the Haskell side,
<a href="https://hackage.haskell.org/package/ormolu">ormolu</a> was easy to install and
“just worked”.</p>



<p>It’s not a controversial statement to say that Haskell has far more language
features than PureScript. It’s also not a new observation to say that it is
challenging to determine which of these features one should be using and what
extensions one should enable to use them. Here’s the list of default extensions
I have enabled for my project:</p>

<ul>
  <li>DataKinds</li>
  <li>DeriveGeneric</li>
  <li>FlexibleContexts</li>
  <li>FlexibleInstances</li>
  <li>GeneralizedNewtypeDeriving</li>
  <li>InstanceSigs</li>
  <li>LambdaCase</li>
  <li>MultiParamTypeClasses</li>
  <li>NamedFieldPuns</li>
  <li>OverloadedStrings</li>
  <li>ScopedTypeVariables</li>
  <li>TypeApplications</li>
  <li>TypeOperators</li>
</ul>

<p>I found Haskell’s deriving capabilities to be more powerful than PureScript and
led to reduced boilerplate, especially when creating my application monad. I
also like that Haskell’s type class instances do not require names. The names
required by PureScript add very little in terms of readability or author intent.</p>

<p>By far the biggest difference I felt between the two languages is the way they
deal with records. Again, this isn’t a new observation, but it can not be
overstated how much better PureScript’s records are than Haskell’s. Records
based on row polymorphism are a joy to work with, as is having a dedicated
syntax for creating, updating, and accessing records. GHC does have an <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0282-record-dot-syntax.rst">accepted
proposal</a>
for adding record dot syntax which will solve many of these problems, but I
think the underlying implementation based on row polymorphism will continue to
give PureScript the edge here.</p>



<p>When I first learned PureScript I compared its compile times to other statically
typed languages like Rust, Go, and Java. I found it much slower than these other
languages, though incremental rebuilds were generally quite fast. I assumed upon
moving to Haskell that the situation would be comparable or better. I was very
wrong.</p>

<p>Compilation times in Haskell are significantly worse than PureScript, often by
an order or two of magnitude when compiling a project’s dependencies. I say this
less to rag on Haskell (this seems like a challenging problem to tackle), but
more to applaud the PureScript community for the work they’ve already done on
this front.</p>



<p>Haskell has a far larger ecosystem of packages than PureScript – kind of. In
terms of Haskell and PureScript in isolation, Haskell has a vastly superior
collection of packages and the quality of these packages is generally very high.
However, PureScript has done a great job of porting over many of the best
Haskell packages.</p>

<p>Additionally, PureScript gives you access to the entire ecosystem of JavaScript
packages via FFI. While many in the community find this to be something of a
disadvantage, from a practical perspective it is fantastic. As an example, when
building full-text search for Haskell, I ended up using the full-text-search
package. It was fully featured and comprehensive, but required <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Data/Index/SearchEngine.hs">quite a
bit</a>
of code to get working.</p>

<p>On the PureScript side, I built a <a href="https://github.com/drewolson/epicbot/blob/e7e93d2e2642ae135c92c6ff5b73b733685b550e/src/Epicbot/Index.js">simple FFI
wrapper</a>
around elasticlunr. While I understand that the JavaScript ecosystem has
packages of variable quality, it does have <em>lots</em> of package solving <em>many</em>
problems and PureScript’s FFI makes it extremely easy to leverage this giant
ecosystem in a safe way.</p>



<p>For my PureScript application I chose the
<a href="https://github.com/cprussin/purescript-httpure">HTTPure</a>. It was light-weight
and easy to use while feeling idiomatic. This was a relatively simple choice
because there are few options for server-side frameworks within the PureScript
ecosystem that included the features I needed (specifically middleware).</p>

<p>On the Haskell side, the choice of web framework was more complicated. I wanted
something small and light-weight, but with the ability work within my custom
monad stack for my application. I ended up using <a href="">scotty</a>, but the default
middleware solution doesn’t operate within your application’s monad stack, so I
needed to explicitly provide middleware-like-functions for <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Web/Router.hs#L33-L34">each
endpoint</a>
in my router.</p>

<p>At the end of the day, this was mostly a wash between languages, but I expected
the Haskell ecosystem to be far more mature in the backend HTTP service space.</p>



<p>To deploy my PureScript application, I used
<a href="https://github.com/vercel/ncc">ncc</a>. While this required that I had <code>node</code>
available in my deployment environment, it made everything else easy. The <code>ncc</code>
tool produced a single, self-contained JavaScript file that included all of the
application code along with required dependencies. I then simply <code>scp</code>‘d this to
my deployment environment and ran it with <code>node</code>.</p>

<p>On the Haskell side, I used stack’s docker support to build my application’s
executable within a container that matches my deployment environment (debian),
and then shipped the resulting executable via <code>scp</code> as well. The executable was
completely self-contained.</p>

<p>Overall, both approaches felt equivalent in terms of ease. On the PureScript
side, it is a bit frustrating to need <code>node</code> within the deployment environment.
On the Haskell side, there was the added complication of having to use docker
for cross-compilation. Overall, though, both experiences were reasonably nice.</p>



<p>In reading over this post, I worry that it feels like I’m picking on Haskell –
I’m absolutely not. I’m very aware that PureScript is <em>heavily</em> influenced by
Haskell and is standing the shoulders of giants. PureScript was able to learn
from some of the mistakes of Haskell and make choices about intentional
departures from the Haskell ecosystem that better fit the intended use cases of
PureScript.</p>

<p>I found the experiences of learning and using both Haskell and PureScript very
rewarding. I will admit to being surprised at how well PureScript compared to
Haskell in the server-side HTTP space, given that its primary focus is currently
on the front end. I think both languages have a bright future and I’m excited to
follow their continued development.</p>



</div>



    </div></div>]]>
            </description>
            <link>https://blog.drewolson.org/purescript-and-haskell</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271851</guid>
            <pubDate>Fri, 26 Feb 2021 06:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercal, YAML, and Other Horrible Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 164 (<a href="https://news.ycombinator.com/item?id=26271582">thread link</a>) | @sidcool
<br/>
February 25, 2021 | https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/ | <a href="https://web.archive.org/web/*/https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><h2 id="programrejectedformentalhealthreasons">PROGRAM REJECTED FOR MENTAL HEALTH REASONS</h2>
<p>In 1972, two students learning FORTRAN came up with a fantastic new programming language called INTERCAL.  INTERCAL is a bit unusual. For example, single quotes are called <em>sparks</em>, and double quotes are called <em>rabbit ears</em>, less than (&lt;) is an <em>angle</em>, and a dash (-) is a <em>worm</em>.  This makes the manual read like a word puzzle combined with an extended in-joke:</p>
<blockquote>
<p>One final comment about sparks and rabbit-ears; if the next character in the program is a spot, as often happens because onespot variables are common choices for operands, a spark and the following spot can be combined into a wow (!). - <a href="http://www.catb.org/~esr/intercal/ick.htm">INTERCAL Manual</a>.</p>
</blockquote>
<p>The compiler errors are where the authors got genuinely creative. Errors include <code>VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</code> for accessing an array incorrectly, <code>IT CAME FROM BEYOND SPACE</code> for invalid control flow, <code>PROGRAM REJECTED FOR MENTAL HEALTH REASONS</code> for threading issues, <code>I HAVE NO FILE AND I MUST SCREAM</code> for file not found, and <a href="http://www.catb.org/~esr/intercal/ick.htm#Errors">many many more</a>.</p>
<p>Yes, this is a parody language, and reading the manual, you get the sense that no one has yet had as much fun writing technical documentation as Lyon and Woods did writing this.</p>
<p>The language itself looks less fun.  Here is <a href="http://www.rosettacode.org/wiki/Category:Intercal">Hello World</a>:</p>
<pre><code>       NOTE THIS IS INTERCAL
       PLEASE ,1 &lt;- #5
       DO ,1 SUB #1 &lt;- #54
       DO ,1 SUB #2 &lt;- #192
       DO ,1 SUB #3 &lt;- #136
       PLEASE ,1 SUB #4 &lt;- #208
       DO ,1 SUB #5 &lt;- #98
       DO COME FROM (1)
       DO READ OUT ,1
(2)    DO ,1 SUB #1 &lt;- #134
(1)    PLEASE ABSTAIN FROM (2)
</code></pre>
<p>One of the exciting innovations of INTERCAL is the <code>COMEFROM</code> <a href="https://en.wikipedia.org/wiki/COMEFROM#Examples">instruction</a>, seen here in a variant of BASIC.<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<pre><code>10 COMEFROM 40
20 INPUT "WHAT IS YOUR NAME? "; A$
30 PRINT "HELLO, "; A$
40 REM
</code></pre>
<p>A <code>COMEFROM</code> anywhere in a program can grab control flow from the line you are reading. And in some implementations, if many <code>COMEFROM</code>'s reference the same line, execution splits off in each direction.</p>
<p>A <code>COMEFROM</code> is the inverse of a <code>GOTO</code> statement with multi-threading thrown in. It breaks the mental model of imperative execution where each line's evaluation leads to the next line. The idea that you can simulate its execution in your head, line by line, is fundamental to imperative programming and <code>COMEFROM</code> attempts to break that model.</p>
<h2 id="variablesmaynotbestoredinwesthyperspace">VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</h2>
<p>At Twitter, they have a giant monorepo with lots of services in it.  And somebody at Twitter wanted to know which language was most prevalent.  Which language does Twitter use the most?</p>
<p>Java came in 3rd, and Scala came in 2nd. But 1st was a surprise.  The number one programming language used at Twitter was YAML.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>YAML usually doesn't feel like a programming language to me.  The file I'm currently writing in is in markdown with some YAML at the top to set the title and associated fields:</p>
<pre><code>title: INTERCAL, YAML, And Other Horrible Programming Languages
author: Adam
</code></pre>
<p>Nothing executes this YAML. It only offers some information to the blogging platform. But I don't think that is the type of YAML that made up the bulk of config at Twitter.</p>
<p>I suspect a lot of it was build and deployment scripts in the form of YAML. It was the type of configuration that encoded the control flow of some external system.  YAML like that lives in this grey zone between declarative configuration and a full-blown programming language.</p>
<p>I'll show you what I mean. Let's look at an example from <a href="https://github.com/koalaman/shellcheck/blob/master/.travis.yml">shellcheck</a>'s build script:</p>
<pre><code>language: shell
os: linux

services:
  - docker
</code></pre>
<p>That seems like straight-forward config.</p>
<pre><code>jobs:
  include:
    - stage: Build
      env: BUILD=linux
      workspaces:
        create:
          name: ws-linux
          paths: deploy
</code></pre>
<p><code>create</code>, in the above, is starting to seem a bit more like execution. Let's continue.</p>
<pre><code>      script:
        - ls -la ${CASHER_DIR}/ || true
        - tar -xvf ${CASHER_DIR}/ws-osx-fetch.tgz --strip-components=5
        - ls -la deploy
        - ./.github_deploy
</code></pre>
<p>Now the YAML has just devolved into specifying how to execute a grab bag of commands.  We haven't seen control-flow yet, but it's coming.</p>
<pre><code>      if: type = push
      script:
        - source ./.multi_arch_docker
        - set -ex; multi_arch_docker::main; set +x
</code></pre>
<p>There we go, branching. It's an if statement in a YAML file!</p>
<p>That was for TravisCI but this isn't TravisCI, or CI specific.  Here is a simple example from Ansible:</p>
<pre><code>- hosts: all
  tasks:
    - include: foo.yml
      when: something == "foo"
    
    - include: bar.yml
      when: something == "bar"
</code></pre>
<p>Here is GitHub Actions:</p>
<pre><code>steps:
 - name: Step 7
   if: ${{ github.event_name == 'pull_request' &amp;&amp; github.event.action == 'unassigned' }}
   run: echo This event is a pull request that had an assignee removed.
</code></pre>
<p>Here is part of a Grafana <a href="https://github.com/grafana/helm-charts/blob/main/charts/grafana/templates/deployment.yaml">Helm Chart</a>:</p>
<pre><code>
{{ if (or (not .Values.persistence.enabled) (eq .Values.persistence.type "pvc")) }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "grafana.fullname" . }}
  namespace: {{ template "grafana.namespace" . }}
  labels:
    {{- include "grafana.labels" . | nindent 4 }}
{{- if .Values.labels }}
{{ toYaml .Values.labels | indent 4 }}
{{- end }}
{{- with .Values.annotations }}
  annotations:
{{ toYaml . | indent 4 }}
{{- end }}
</code></pre>
<p>I think this is a problem. Writing control flow in a config file is like hammering in a screw. It's a useful tool being used for the wrong job<sup><a href="#fn3" id="fnref3">[3]</a></sup>.</p>
<p>How did we get to this world of little programming languages embedded into YAML? Is calling something configuration just less scary? And if so, is a c++ program just config you give to gcc?</p>
<p>Did things ever get this complicated in XML times?</p>
<p>It turns out they did:</p>
<pre><code>&lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
  &lt;xsl:output method="text" omit-xml-declaration="yes" /&gt;

  &lt;xsl:template match="/"&gt;
    &lt;xsl:call-template name="FizzBuzz"&gt;
      &lt;xsl:with-param name="i" select="1" /&gt;
    &lt;/xsl:call-template&gt;
  &lt;/xsl:template&gt;

  &lt;xsl:template name="FizzBuzz"&gt;
    &lt;xsl:param name="i" /&gt;
    &lt;xsl:choose&gt;
      &lt;xsl:when test="($i mod 3) = 0 and ($i mod 5) = 0"&gt;FizzBuzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 3 = 0"&gt;Fizz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 5 = 0"&gt;Buzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:otherwise&gt;&lt;xsl:value-of select="$i" /&gt;&lt;xsl:text&gt;&amp;#xa;&lt;/xsl:text&gt;&lt;/xsl:otherwise&gt;
    &lt;/xsl:choose&gt;
    &lt;xsl:if test="$i &amp;lt; 100"&gt;
      &lt;xsl:call-template name="FizzBuzz"&gt;
        &lt;xsl:with-param name="i" select="$i + 1" /&gt;
      &lt;/xsl:call-template&gt;
    &lt;/xsl:if&gt;
  &lt;/xsl:template&gt;
&lt;/xsl:stylesheet&gt;
</code></pre>
<p>That is <code>FizzBuzz</code> in <a href="https://gist.github.com/JustinPealing/6f619a23729720a9c14d9917201028c8">XSLT</a>. I assume it was written in jest, but in many ways, XML and XSLT are better than an ad-hoc YAML based scripting language. XSLT is a documented and standardized thing, not just some ad-hoc format for specifying execution.</p>
<p>It burns my eyes to look at it, but at least XSLT was intended to be used as a programming language. That is something we can't say about YAML or INTERCAL.</p>
<p>The problem with these languages embedded into YAML is they are all one-off implementations.  TravisCI conditionals have a TravisCI specific syntax, usage, and features. You can't use Travis's <code>concat</code> function or conditional regex in the YAML configuration for your ansible playbooks.</p>
<p>In a vague way, this YAML problem is like the <code>COMEFROM</code> problem. If you know yaml, you can't just open a .yml file and start reading file line by line.  You need to understand how the configuration controls the execution of the specific system it's for.  And that is hard.</p>
<h2 id="ihavenofileandimustscream">I HAVE NO FILE AND I MUST SCREAM</h2>
<p>The line between configuration and programming languages is not some bright dividing line. It's easy to slowly drift into adding programming language constructs to a config file. Before you know it, you have a full unspecified programming language embedded in the interpretation of your config file.</p>
<p>That is the worst of both worlds, and so much YAML seems to drift into this area.</p>
<p>I like YAML more than XML, but for control flow, you know what would be better than YAML? Anything else!  Maybe even INTERCAL? I mean, how bad could a joke programming language be?</p>
<pre><code>(100)  PLEASE NOTE THIS IS THE FIZZBUZZ FUNCTION	

	PLEASE NOTE: IS THE INPUT DIVISIBLE BY #15?
	DO .1 &lt;- .100	
	DO .2 &lt;- #15
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (130) NEXT
	
	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #15 =&gt; CHECK IF DIVISIBLE BY #3
	DO .2 &lt;- #3
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (110) NEXT

	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #3 =&gt; CHECK IF DIVISIBLE BY #5
	DO .2 &lt;- #5
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (120) NEXT
	
	PLEASE NOTE NUMBER IS REGULAR =&gt; RETURN THE INPUT
	DO .101 &lt;- .100
	DO (199) NEXT

(110)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #3 =&gt; RETURN FIZZ
	DO .101 &lt;- #61440
	DO (199) NEXT


(120)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #5 =&gt; RETURN BUZZ
	DO .101 &lt;- #45056
	DO (199) NEXT

(130)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #15 =&gt; RETURN FIZZ-BUZZ
	DO .101 &lt;- #64256
	DO (199) NEXT

(111)	DO RESUME .4
	
(199)	DO FORGET #1
	DO RESUME #1
</code></pre>
<p>Oh God.</p>
<p>Well, ok, maybe not INTERCAL but anything else. <sup><a href="#fn4" id="fnref4">[4]</a></sup><sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<hr>
<section>
<ol>
<li id="fn1"><p><code>COME FROM</code> was introduced in INTERCAL-90 and not part of the orginal implementation (INTERCAL-72). <code>I HAVE NO FILE AND I MUST SCREAM</code> was also introduced in INTERCAL-90. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>See my interview with <a href="https://www.se-radio.net/2019/08/episode-375-gabriel-gonzalez-on-configuration/">Gabriel Gonzalez on Configuration</a> at Software Engineering Radio. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Ansible and Helm use templating languages built on top of YAML, which is better than embedded control flow, but I think the point still stands. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p>Practically, you may have to use tools that encode a DSL into config, but you can use them while recognizing that we can do better.  I think something like <a href="https://dhall-lang.org/#">Dhall</a> for complicated config and something like <a href="https://www.pulumi.com/">pulumi</a> for complex configuration as code should be where we aim for as an industry. <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>The …</p></li></ol></section></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</a></em></p>]]>
            </description>
            <link>https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271582</guid>
            <pubDate>Fri, 26 Feb 2021 05:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Redbean – Single-file distributable web server]]>
            </title>
            <description>
<![CDATA[
Score 1624 | Comments 207 (<a href="https://news.ycombinator.com/item?id=26271117">thread link</a>) | @jart
<br/>
February 25, 2021 | https://justine.lol/redbean/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/redbean/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://storage.googleapis.com/justine/redbean/redbean.png" width="84" height="84">
<h2>
  <big>redbean</big><br>
  <small>single-file distributable web server</small>
</h2>

<p>
  redbean makes it possible to share web applications that run offline
  as a
  single-file <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> zip archive which contains your assets. All
  you need to do is download the <code>redbean.com</code> program below,
  change the filename to .zip, add your content in a zip tool like
  Windows 10 or InfoZIP, and change the extension back to .com.

</p><p>
  redbean can serve 1 million+ gzip encoded responses per second on a
  cheap personal computer. That performance is thanks to zip and gzip
  using the same compression format, which enables kernelspace copies.
  Another reason redbean goes fast is that it's a tiny static binary,
  which makes fork memory paging nearly free.

</p><p>
  redbean is also easy to modify to suit your own needs. The program
  itself is written as a single .c file.

</p><p>
  <strong>
    download
    &nbsp;
    <img src="https://storage.googleapis.com/justine/redbean/linux.png" title="Linux" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/windows10.png" title="Windows" width="32" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/macos.png" title="MacOS" width="26" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/freebsd.png" title="FreeBSD" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/openbsd.png" title="OpenBSD" width="34" height="32">
    <img src="https://justine.lol/redbean/NetBSD.png" title="NetBSD" width="30" height="30">
  </strong>
  <br>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com">redbean-2021-02-27.com</a><br>
  <small>200kb - PE+ELF+MachO+ZIP+SH</small>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com.dbg">redbean-2021-02-27.com.dbg</a><br>
  <small>2.2m - ELF debugger data (optional)</small>

</p><p>
  <a href="https://github.com/jart/cosmopolitan/blob/master/tool/net/redbean.c">redbean.c</a><br>
  <small>source code</small>

</p><p>
  <strong>
    features
  </strong>
  </p><ul>
    <li>HTTP v1.1
    </li><li>Content-Encoding
    </li><li>Range / Content-Range
    </li><li>Last-Modified / If-Modified-Since
  </li></ul>

<p>
  <strong>
    installation
  </strong>
  </p><pre>curl https://justine.lol/redbean/redbean-latest.com &gt;redbean.com
chmod +x redbean.com
bash -c './redbean.com -vv'
</pre>

<p>
  <strong>
    usage
  </strong>
  </p><pre>echo '&lt;b&gt;hello&lt;/b&gt;' &gt;index.html
zip redbean.com index.html
./redbean.com -vv
curl -v http://127.0.0.1:8080/index.html
</pre>

<p>
  <strong>
    details
  </strong>

</p><p>
  Assets can be listed by running the following command:

</p><pre>unzip -vl redbean.com        # lists files
</pre>

<p>
  Assets can be added to the zip archive as follows:

</p><pre>zip redbean.com index.html   # adds file
</pre>

<p>
  By default, anything you add to the archive gets compressed. Sometimes
  you don't want that to happen. A good example is video files. The web
  browser will want to send HTTP range requests to seek in the video, in
  which case redbean requires that the asset be uncompressed.

</p><pre>zip -0 redbean.com video.mp4  # adds file without compression
</pre>

<p>
  Each connection uses a point in time snapshot of your ZIP file.
  If your ZIP is deleted then serving continues. If it's replaced
  then issuing SIGUSR1 (or SIGHUP if daemon) will reindex the zip
  for subsequent connections without interrupting active ones. If
  SIGINT or SIGTERM is issued then a graceful shutdown is started
  but if it's issued a second time, active connections are reset.

</p><p>
  <strong>
    flags
  </strong>

</p><table>
  <tbody><tr><th>  -h        </th><td>help
  </td></tr><tr><th>  -v        </th><td>verbosity
  </td></tr><tr><th>  -d        </th><td>daemonize
  </td></tr><tr><th>  -s        </th><td>uniprocess
  </td></tr><tr><th>  -m        </th><td>log messages
  </td></tr><tr><th>  -c INT    </th><td>cache seconds
  </td></tr><tr><th>  -r /X=/Y  </th><td>redirect X to Y
  </td></tr><tr><th>  -l ADDR   </th><td>listen ip [default 0.0.0.0]
  </td></tr><tr><th>  -p PORT   </th><td>listen port [default 8080]
  </td></tr><tr><th>  -L PATH   </th><td>log file location
  </td></tr><tr><th>  -P PATH   </th><td>pid file location
  </td></tr><tr><th>  -U INT    </th><td>daemon set user id
  </td></tr><tr><th>  -G INT    </th><td>daemon set group id
  </td></tr><tr><th>  -B STR    </th><td>changes server header
</td></tr></tbody></table>

<p>
  <strong>benchmark</strong>

</p><pre>$ <a href="https://github.com/wg/wrk">wrk</a> -H 'Accept-Encoding: gzip' -t 12 -c 120 \
  http://127.0.0.1:8080/tool/net/redbean.html
Running 10s test @ http://127.0.0.1:8080/tool/net/redbean.html
  12 threads and 120 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   745.49us    8.79ms 406.77ms   99.54%
    Req/Sec    96.60k     6.10k  123.66k    77.36%
  11631210 requests in 10.10s, 7.96GB read
Requests/sec: 1151621.71
Transfer/sec:    807.23MB
</pre>

<p>
  <strong>
    see also
  </strong>

</p><p>
  <a href="https://justine.lol/index.html">justine's web page</a><br>
  <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly pδrταblε εxεcµταblε</a>

</p>
</div>]]>
            </description>
            <link>https://justine.lol/redbean/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271117</guid>
            <pubDate>Fri, 26 Feb 2021 03:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dasung Paperlike HD-FT Teardown]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26270995">thread link</a>) | @alex-a-soto
<br/>
February 25, 2021 | https://alexsoto.dev/dasung-paperlike-hdft-teardown.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/dasung-paperlike-hdft-teardown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A series where I’m documenting my process of designing and building an eink laptop.</p><ul><li><span><span title="2021-02-17T22:13"><a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a><span data-nosnippet="" title="Folgezettel">#</span></span></span></li></ul><p>In my first post, <a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a>, I went over some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>This post in the series will be a teardown of the Dasung HD-FT, inspired from Kev Zettler’s work on the, <a href="https://kevzettler.com/2018/02/11/dasung-paperlike-pro-teardown/">Dasung Paperlike Pro Teardown</a>. Thank you, <a href="https://kevzettler.com/">Kev Zettler</a>, for showing your work on the Dasung Paperlike Pro and making all of this possible. I will later create an accompanying video to go over the Dasung HD-FT teardown process.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="overview-of-the-dasung-hd-ft">Overview of the Dasung HD-FT</h2><p>The Dasung HD-FT is a third-generation e-ink monitor with a display of 13.3“, a screen resolution of 2200x1650, a touchscreen, and an adjustable backlight. The monitor connects via a proprietary Y cable, with connections for USB and HDMI; additionally, the Dasung HD-FT can be powered by the micro-usb connection on the left side.</p><p>Once connected to a computer, it acts as a second monitor or, for our purposes, a primary monitor for our e-ink laptop. The monitor’s physical buttons allow you to adjust the contrast, brightness, clear the screen, and change modes.</p><p>The modes (M1, M2, M3, Fast, Fast++, Black, Black+, Black++) correspond to how the monitor displays what’s rendered in the screen using different shades of grey or black/white.</p><p>Let’s take a closer look and dismantle the Dasung HD-FT and look at its components.</p><h2 id="opening-the-dasung-paperlike-hd-ft">Opening the Dasung Paperlike HD-FT</h2><p>Similar to Zettler’s observations and approach, the Dasung HD-FT is made of one piece of construction. I first began with a knife, carefully prying the outer edges of the Dasung Monitor where it’s all glued and making my way slowly through all of the sides.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194558.jpg"></p><p>Once I finished prying through all of the sides, what became visible were the screws that were holding everything together.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194714.jpg"></p><p>After removing all of the screws, I was able to gain access to the panel!</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="the-e-ink-display-module-and-control-board">The E-ink display module and control board</h2><p>Like Zettler discovered, the Dasung HD-FT chip components upon closer inspection were also chemically peeled off to prevent reverse engineering of the e-ink display and control board.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201821.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201158.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201211.jpg"></p><h2 id="es133tt3-display-module">ES133TT3 Display Module</h2><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201921.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202037.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202009.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202020.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202024.jpg"></p><p>The e-ink display module model number for the Dasung HD-FT is the: <span><strong>ES133TT3</strong></span></p><p>beck-elektronik<span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span> describes it as “<em>reflective electrophoretic E Ink technology display module based on active matrix TFT and plastic substrate. The plastic substrate is protected by an outer covering.</em>”</p><p>Specification:</p><ul><li>Size: 13.3 inch</li><li>Resolution (HxV): 2200 * 1650</li><li>Active Area: 270.60 * 202.95 mm</li><li>Outline Dimensions: 287.00 * 215.50 mm</li><li>Dpi: 206</li><li>E Ink Film: Carta 1.2</li><li>Refresh Time: 450 ms</li><li>Backplane: Flexible</li><li>Total Thickness: 0.65 mm</li><li>Total Weight: 68 g</li><li>Grey Level: 16</li><li>Surface Treatment: Anti-Glare</li><li>Partial Update: yes</li></ul><p>Their website also lists an EPD driver kit that’s compatible with it, the ES133TT3.<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span></p><h2 id="next-steps">Next Steps</h2><p>This second post provided an overview of the Dasung HD-FT, a teardown of the Dasung HD-FT and its internal components, and identifying the display module used, the ES133TT3.</p><p>The following post in the series will be a teardown of the Thinkpad T480 that we will be using to build our e-ink laptop.</p><p><img id="avatar" src="https://alexsoto.dev/static/profile.jpeg"></p><p>Hi, I’m Alexander Soto.</p><p>I’m a community organizer, educator, software engineer, hacktivist, and agent of social change. My interests are in exploring community-building, social justice, education, and leveraging technology to address social problems.</p><p>In the past, I’ve worked as a labor rights organizer, a teacher, and I’m currently an Expert In Residence at <a href="https://www.resilientcoders.org/">Resilient Coders.</a></p><p>I enjoy tinkering/playing/breaking things, 3D printing, painting, playing piano, swimming, and writing in my spare time.</p><p>This site is the <a href="https://alexsoto.dev/impulse.html">scattered and unfinished version of my thoughts</a> while documenting what I’m currently learning and exploring.</p><p>If a post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, an <a href="mailto:contact@alexsoto.dev">email</a>, or subscribe to the <a href="https://buttondown.email/alexsotodev">mailing list</a> and we can talk. Also, ping if you’d like to know the updates of a post or if you have suggestions, comments, questions, or would like to collaborate.</p>



</div></div>]]>
            </description>
            <link>https://alexsoto.dev/dasung-paperlike-hdft-teardown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270995</guid>
            <pubDate>Fri, 26 Feb 2021 03:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Craziest Drinks Sold in Japan]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26270957">thread link</a>) | @rmason
<br/>
February 25, 2021 | https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/ | <a href="https://web.archive.org/web/*/https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Oh come on!  Don’t play it safe and only go just go for a Coke or Pepsi.  You’re in Japan now.  It’s time to try something more adventurous.</p>



<p>Vending machines mainly for carbonated drinks started appearing across the country in 1960.&nbsp; Now there are an estimated 2,470,000 of them throughout Japan or 1 for approximately every 50 people.&nbsp; Thus, it is easy to grab either a cold or hot drink virtually anywhere in the country on a 24/7 basis.</p>



<p>While the same global players such as Coca-Cola and national powerhouses in the beverage industry like Suntory do, in fact, dominate distribution via vending machines and other channels, relatively obscure minor entrants have still managed to carve out a niche with several unique offerings.&nbsp; Even the big boys have become used to granting a creative license to their marketers to go well beyond normal colas.</p>



<div><figure><img loading="lazy" src="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg" alt="" width="512" height="320" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg 1024w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-300x188.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea.jpg 1280w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Some of the more unusual selections from Ryoko Shimizu’s Top 50, Image sourced from Crea</figcaption></figure></div>



<p>The sheer variety of beverages—<em>both non-alcoholic and alcoholic</em>—available in Japan is staggering. &nbsp;To make sense of it all is soft drink critic Ryoko Shimizu (aside–<em>now that’s a cool job!</em>).&nbsp; She has been reviewing the world of non-alcoholic Japanese beverages since the 1980s.&nbsp; Shimizu recently published a <a href="https://news.nifty.com/article/entame/etc/12113-930661/">Top 50 list of her all-time favorites</a> (the original article in Japanese only).</p>



<p>…but wait!  First you need to know this.</p>



<h3><strong>What’s a <em>supodo</em>?</strong></h3>



<p><em>Supodo</em> (スポド) is an abbreviation for the made-up English term “sports drink” in Japanese.&nbsp; This category is a type of soft drink that replenishes the water and minerals lost from the body due to perspiration, especially during exercise. &nbsp;It supposedly helps to prevent dehydration and the potential for heatstroke while playing sports under the scorching sun.</p>



<h3><strong>Top Fifty</strong></h3>



<p>Okay, now that this term has been defined, let’s get to Shimizu’s extensive list which includes plenty of <em>supodo</em> as well as other types of drinks!</p>



<p>Not all of her favorites are still around, but, despite humble beginnings in some cases, a surprising number have since gone mainstream.&nbsp; Scroll down to see how Shimizu ranked them by counting backward from 50 down to 1:</p>



<h4>#50 Sports Mugicha</h4>



<p><strong>Sports Mugicha</strong> sold in the 1990s by Kanebo:&nbsp; Shimizu wrote, “When I first heard the name of this drink, my first impression was that it must be a blend of traditional barley tea and a ‘sports drink.’&nbsp; It consists, in fact, of a combination of an appropriate amount of salt mixed with regular barley tea to enhance its absorption into the body. &nbsp;The can was decorated with a theme from the professional baseball team Yokohama BayStars.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Sports Mugicha (barley tea), Image sourced from Crea</figcaption></figure></div>



<h4>#49 Mountain Dew</h4>



<p><strong>Mountain Dew</strong> launched in 1981 by Pepsi Co:&nbsp; This long-seller, which is still popular today, is marketed in Japan with the tag line “new citrus beverage.”&nbsp; The package has changed little over the years.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Mountain Dew (written in Japanese), Image sourced from Crea</figcaption></figure></div>



<h4>#48 Tab Clear</h4>



<p><strong>Tab Clear</strong> launched in 1993 by Coca-Cola:&nbsp; Shimizu commented, “It became a hot topic because it was a transparent cola, but I remember that it was subtle in terms of taste. Kotaro Tawara, a popular newscaster at the time, appeared in a commercial.”</p>



<div><figure><img loading="lazy" width="245" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg 245w, https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea-230x300.jpg 230w" sizes="(max-width: 245px) 100vw, 245px"><figcaption>Tab Clear, Image sourced from Crea</figcaption></figure></div>



<h4>#47 Tsubu-Tsubu Orange</h4>



<p><strong>Tsubu-Tsubu Orange</strong> was sold in the 1990s by Yamato:&nbsp; This orange drink was conceived based upon the trend of mashed fruit drinks in the 1980s.&nbsp; “Tsubu” means “bead” or “drop” in Japanese.&nbsp; When it was launched, Tsubu-Tsubu Orange lacked national distribution.&nbsp; It was only marketed locally in Nagoya, near where it was made.</p>



<div><figure><img loading="lazy" width="208" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg 208w, https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea-195x300.jpg 195w" sizes="(max-width: 208px) 100vw, 208px"><figcaption>Tsubu Tsubu Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#46 Post Water</h4>



<p><strong>Post Water</strong> launched in 1990 by Kirin:&nbsp; Made from lychees, this <em>supodo</em>  or “sports drink” made quite a scene when it debuted in an unusually-shaped flask.</p>



<div><figure><img loading="lazy" width="554" height="554" src="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg 554w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-300x300.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-150x150.jpg 150w" sizes="(max-width: 554px) 100vw, 554px"><figcaption>Post Water, Image sourced from Twitter</figcaption></figure></div>



<h4>#45 Cheerio Grape</h4>



<p><strong>Cheerio Grape</strong> launched in 1965 by Cheerio:&nbsp; Shimizu fondly recalls Cheerio’s Grape drink as being for sale at the candy store near her childhood home.</p>



<div><figure><img loading="lazy" width="204" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg 204w, https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea-191x300.jpg 191w" sizes="(max-width: 204px) 100vw, 204px"><figcaption>Cheerio Grape, Image sourced from Crea</figcaption></figure></div>



<h4>#44 J Water</h4>



<p><strong>J Water</strong> launched in 1993 by Suntory:&nbsp; This drink made its debut as an officially licensed beverage of the J League or Japan Professional Football (soccer) League back when J League was new.&nbsp; This “sports drink” did not have a particularly distinctive taste, but the taste was secondary to packaging in any case.&nbsp; There are also team-specific variants.</p>



<div><figure><img loading="lazy" width="195" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg 195w, https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online-183x300.jpg 183w" sizes="(max-width: 195px) 100vw, 195px"><figcaption>J. Water, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#43 Ambasa</h4>



<p><strong>Ambasa</strong> launched in 1982 by Coca-Cola:&nbsp; Shimizu commented, “I felt a little &nbsp;uncomfortable with the unfamiliar word ‘Ambasa’ at first, but I quickly got used to it because it was put into virtually every Coca-Cola vending machine.” &nbsp;This carbonated beverage looks milky and tastes lighter than Calpis Soda. &nbsp;There were also melon and pine flavors for a while.</p>



<div><figure><img loading="lazy" width="240" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg 240w, https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea-225x300.jpg 225w" sizes="(max-width: 240px) 100vw, 240px"><figcaption>Ambasa, Image sourced from Crea</figcaption></figure></div>



<h4>#42 Apple Oolong Soda</h4>



<p><strong>Apple Oolong Soda</strong> launched in 1988 by Kirin:&nbsp; This is another drink that relies primarily upon packaging to drum up sales.&nbsp; It features characters from the anime Modern Children (いまどきのこども), which attracted a lot of attention when launched.  It is still fairly popular.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Apple Oolong Soda, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#41 Sweet Kiss</h4>



<p><strong>Sweet Kiss</strong> launched in 1982 by Cheerio:&nbsp; Sweet Kiss is sort of a variant of Mountain Dew (#49) and features a distinctive graphic design.&nbsp; It is, however, still relatively difficult to find this drink even in Tokyo.</p>



<div><figure><img loading="lazy" width="590" height="442" src="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg 590w, https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net-300x225.jpg 300w" sizes="(max-width: 590px) 100vw, 590px"><figcaption>Sweet  Kiss, Image sourced from J Town Net</figcaption></figure></div>



<h4>#40 Saruo Monkey King</h4>



<p><strong>Saruo Monkey King</strong> launched in 1994 by Lotte:&nbsp; The name Saruo literally means “monkey king” in Japanese.&nbsp; It was originally marketed as an exclusive type of oolong tea made from tea leaves grown on cliffs where monkeys like to forage food.&nbsp; There is, naturally, some question about whether monkeys actually harvest tea leaves.&nbsp; One of the respondents reportedly remarked in a taste test, “It sort of smells like a monkey.”&nbsp; Luckily for the brand, there are, however, plenty of other people who disagree!</p>



<div><figure><img loading="lazy" width="216" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg 216w, https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea-203x300.jpg 203w" sizes="(max-width: 216px) 100vw, 216px"><figcaption>Saruo or “monkey king” in Japanese, Image sourced from Crea</figcaption></figure></div>



<h4>#39 Afternoon Tea</h4>



<p><strong>Afternoon Tea</strong> launched in sold in 1986 by Kirin:&nbsp; This drink is a best selling long-runner.&nbsp; It is fairly sweet and was the first black tea sold in a 1.5 liter PET bottle.</p>



<div><figure><img loading="lazy" width="194" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg 194w, https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea-182x300.jpg 182w" sizes="(max-width: 194px) 100vw, 194px"><figcaption>Afternoon Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#38 Bireley’s Orange</h4>



<p><strong>Bireley’s Orange</strong> launched in 1951 by Asahi:&nbsp; The name of this ultra-long-runner, “Birely’s,” used to be synonymous orange juice. Since the 1970s, when restrictions were introduced that limited marketers’ ability to label a drink as juice unless it was 100% juice, Birely’s had to drop the reference to juice.&nbsp; This minor setback did, however,  not make a major dent in its market share.  The brand is still sold today.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Bireley’s Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#37 Hokuriku Soda Godzilla Matsui Can</h4>



<p><strong>Hokuriku Soda Godzilla Matsui Can</strong> launched in 1997 by Soka Komatsuen:&nbsp; This is a locally produced drink made to help immortalize the famous baseball player Hideki Matsui who was also a “favorite son” of Ishikawa Prefecture.&nbsp; Matsui, whose nickname was “Godzilla,” was a home run king who went on to play for the New York Yankees.</p>



<div><figure><img loading="lazy" width="214" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg 214w, https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea-201x300.jpg 201w" sizes="(max-width: 214px) 100vw, 214px"><figcaption>Hokuriku Soda Godzilla Matsui Can, Image sourced from Crea</figcaption></figure></div>



<h4>#36 Honey Lemon</h4>



<p><strong>Honey Lemon</strong> launched in 1986 by Suntory:&nbsp; This fruit drink experienced explosive sales upon its release.&nbsp; Suntory had a problem, though.&nbsp; As they could not register a trademark for “honey lemon” or even its nickname in Japanese <em>hachi-lemo</em>, this particular name essentially became its own category because several other manufacturers flooded the market with similar drinks by the same name.&nbsp; It is a classic example of just how cut-throat the non-alcoholic drink industry can be in Japan.</p>



<div><figure><img loading="lazy" width="225" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg 225w, https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea-211x300.jpg 211w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>Honey Lemon, Image sourced from Crea</figcaption></figure></div>



<h4>#35 McCOL</h4>



<p><strong>McCOL</strong> launched in 1982 by MMC:&nbsp; This collector’s item has long since been taken off the market.&nbsp; It was, apparently, relatively hard to find even when it was available through the mid-1990s.&nbsp; McCOL was marketed as “barley cola,” but it looked just like any other cola.&nbsp; The taste was a combination of barley tea and cider.</p>



<div><figure><img loading="lazy" width="197" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg 197w, https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea-185x300.jpg 185w" sizes="(max-width: 197px) 100vw, 197px"><figcaption>McCOL, Image sourced from Crea</figcaption></figure></div>



<h4>#34 TESS Milk Tea</h4>



<p><strong>TESS Milk Tea</strong> sold in the late 1980s by Suntory:&nbsp; TESS had a relatively short lifetime as a semi-sweet type of milk tea.</p>



<div><figure><img loading="lazy" width="238" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg 238w, https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea-223x300.jpg 223w" sizes="(max-width: 238px) 100vw, 238px"><figcaption>TESS Milk Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#33 NCAA</h4>



<p><strong>NCAA</strong> launched in 1981 by Suntory:&nbsp; Named for the National College Athletic Association (NCAA), this classic sports drink was introduced as “the brand new thirst quencher for those who love sports.”</p>



<div><figure><img loading="lazy" width="193" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg 193w, https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea-181x300.jpg 181w" sizes="(max-width: 193px) 100vw, 193px"><figcaption>NCAA, Image sourced from Crea</figcaption></figure></div>



<h4>#32 Atamaruko</h4>



<p><strong>Atamaruko</strong> launched in 1990 by Suntory:&nbsp; This citrus mixture of kumquats and calamansi (aka “Philippine lime”) was actually sold hot in the heated section of vending machines. Its name means, in fact, “A Child to Warm You Up.”&nbsp; The cute package design proved effective at attracting customers. &nbsp;It actually led to a second-generation character called “Nacchan” that became even more famous than Atamaruko, who was relegated to the status of “the unknown older sister.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Atamaruko, Image sourced from Suntory</figcaption></figure></div>



<h4>#31 Gatorade</h4>



<p><strong>Gatorade</strong> sold in the 1980s by Yukijirushi:&nbsp; Having been replaced by homegrown rival Pocari Sweat, American uber-brand Gatorade is no longer sold in cans in Japan. It was, though, the first “sports drink” to appear in Japan.&nbsp; At that point, Gatorade was only available as a powder.</p>



<div><figure><img loading="lazy" width="198" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg 198w, https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea-186x300.jpg 186w" sizes="(max-width: 198px) 100vw, 198px"><figcaption>Gatorade, Image sourced from Crea</figcaption></figure></div>



<h4>#30 Dr. Nakamatsu’s Head Tea</h4>



<p><strong>Dr. Nakamatsu’s Head Tea</strong> launched in 1994 by Cheerio:&nbsp; Now we’re entering the realm of the truly odd.&nbsp; Named for Dr. Yoshiro Nakamatsu, a leading researcher of “smart foods” at the time of launch, this strong blended tea was somehow supposed to enhance cognitive capability.&nbsp; Years later, the same Dr. Nakamatsu gained additional notoriety outside Japan by winning the “Ig Noble …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</a></em></p>]]>
            </description>
            <link>https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270957</guid>
            <pubDate>Fri, 26 Feb 2021 02:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EdgeDB in Beta]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270576">thread link</a>) | @avador
<br/>
February 25, 2021 | https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/ | <a href="https://web.archive.org/web/*/https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="---post-root---"><section><div><p><img src="https://www.edgedb.com/static/beta1-937a02b3aacf5f4c5a6f10540333cf02.jpg" width="100%" height="100%"></p></div></section>
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<section id="edgedb-1-0-beta-1-sirius">
<!-- -->
<p>Nearly two years after releasing 1.0 Alpha 1, and after seven alpha releases,
            we are ready to bring EdgeDB to the public beta phase!</p>
<p>This means that as of now, we will make every effort to keep the public-facing
            APIs backwards compatible.  This includes EdgeQL, our standard library,
            schema definition language, official database clients’ APIs, even CLI
            commands and their options.  Most importantly, EdgeDB’s dumps made today
            will be restorable in future versions of the database.</p>
<p>This release completes a set of features we feel are crucial for
            a well-rounded 1.0 product, and we invite early adopters to try it out.
            On our end, we’re spending the next few months on getting EdgeDB ready
            for the first stable release.  Entering Beta means we won’t be adding
            new features until the release of 1.0 final.</p>
<p>You can <a href="https://www.edgedb.com/download">download</a> 1.0b1 in a number of ways or try it out
            in our <a href="https://tutorial.edgedb.com/">interactive tutorial</a> without the need to install
            anything.</p>

<h4>What’s EdgeDB</h4>
<p>EdgeDB is an advanced <a href="https://github.com/edgedb/edgedb">open source</a> relational database built
            on top of PostgreSQL which aims to <a href="https://www.edgedb.com/blog/a-path-to-a-10x-database">change the game</a> in terms
            of data layer usability and performance.</p>
<p>It combines an expressive object-oriented data model with a composable
            query language based on set logic, making complex data schemas easy to
            express, populate, and query.  The query system’s explicit goal is to
            address <a href="https://www.edgedb.com/blog/we-can-do-better-than-sql">shortcomings of SQL</a>.</p>
<p>As a database designed for the long haul, EdgeDB allows for your data
            to evolve along with changing business needs, by providing built-in
            support for schema migrations.  It’s also developed in the open and
            under the permissive Apache license.</p>
<p>EdgeDB’s performance focus is embodied in its carefully designed
            first-party database clients (currently available for JavaScript, Go,
            and Python.)  The database server itself compiles EdgeQL queries to
            efficient SQL in ways that outperform many manually written queries.</p>
<p>As a modern database, EdgeDB also provides interoperability with your
            other services via built-in support for GraphQL, REST, and easy <a href="https://www.edgedb.com/docs/clients/01_js/api/connection#Connection.queryJSON">casting
                from and to JSON</a> while keeping your data strictly typed.</p>
<div id="built-in-database-migrations-in-use">

<p>We believe that managing the evolution of your data models is a crucial
                feature in a modern database product.  The alternatives would be either
                weakly typed schemas or a third-party product.  We’re not satisfied with
                either.  The former unnecessarily moves some of the responsibilities of
                the database into your application code, making data consistency harder
                and development more error-prone.  The latter on the other hand usually
                ties you to a particular database connection framework in a particular
                programming language, putting that language in a privileged position.
                This is suboptimal in today’s environment where very often mobile
                applications are written in multiple programming languages, a Web
                front-end can be another, and back-end processing using yet another.</p>
<p>With Beta 1, the migrations functionality we envisioned for EdgeDB
                is fully realized.  While you could <a href="https://www.edgedb.com/docs/edgeql/ddl/migrations">start, populate, and commit
                    migrations</a> from EdgeQL directly for a few releases
                already, now you can fully manage migrations from the CLI, making the
                workflow even more high-level.</p>
<p>The idea here is to be able to version your schema alongside your
                source code, possibly as a separate repository that you can link
                as a submodule in multiple applications that your system consists of.
                That repository would hold schema files describing migrations between
                different states of your data model.</p>
<p>As an example, let’s say we start with the following schema for a simple
                chat app:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }
    }
};</span></span></pre>
<p>The migration CLI looks for <code>.esdl</code> files in the <code>dbschema</code> directory
                by default, so let’s create one and write the above into a
                <code>dbschema/default.esdl</code> file inside it.  Let’s
                <a href="https://www.edgedb.com/docs/tutorial/install/">install</a> EdgeDB server and then create a new
                database instance for our chat app:</p>
<pre><span><span>$ edgedb server init chatapp</span></span></pre>
<p>Now, we can create the initial migration to the schema we’ve written above:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>This is new, what do all those possible actions mean?  Let’s find out:</p>
<pre><span><span>?

y - confirm the prompt, use the DDL statements
n - reject the prompt
l - list the DDL statements associated with prompt
c - list already confirmed EdgeQL statements
b - revert back to previous save point, perhaps previous question
s - stop and save changes (splits migration into multiple)
q - quit without saving changes
h or ? - print help
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>That’s clear, we did in fact create <code>User</code>. Let’s confirm:</p>
<pre><span><span>y
did you create object type 'default::Message'? [y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00001.edgeql, id:
m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q</span></span></pre>
<p>This creates the first migration file
                <code>dbschema/migrations/00001.edgeql</code>. After reviewing it to make
                sure everything is in order, we can apply the migration with the
                following command:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q
(00001.edgeql)</span></span></pre>
<p>In the course of implementing our app we decide to add more features,
                such as a friends list and multiple chat channels, so we alter our
                schema to be:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;

        <span>multi</span> <span>link</span> friends <span>-&gt;</span> User;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }

        <span>link</span> channel <span>-&gt;</span> Channel;
    }

    <span>type</span> Channel {
        <span>required</span> <span>property</span> title <span>-&gt;</span> <span>str</span> {
            <span>constraint</span> <span>exclusive</span>;
        };
        <span>property</span> description <span>-&gt;</span> <span>str</span>;
    }
};</span></span></pre>
<p>And we apply the changes by using <code>create-migration</code> and <code>migrate</code>
                commands again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::Channel'? [y,n,l,c,b,s,q,?]
y
did you create link 'channel' of object type 'default::Message'?
[y,n,l,c,b,s,q,?]
y
did you create link 'friends' of object type 'default::User'?
[y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00002.edgeql, id:
m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
$ edgedb -I chatapp migrate
Applied m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
(00002.edgeql)</span></span></pre>
<p>At this point we may want to actually create a default channel “Main”
                and make the <code>channel</code> link required. So we alter the schema to make
                the link required and run <code>create-migration</code> again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>Indeed we did but for the sake of curiosity let’s list the DDL that
                the tool is producing for us here:</p>
<pre><span><span>l

Following DDL statements will be applied:
ALTER TYPE default::Message {
    ALTER LINK channel {
        SET REQUIRED USING (\(fill_expr));
    };
};</span></span></pre>
<p>Interestingly the DDL statement specifies that some expression will
                have to be provided to backfill data in the database.  Let’s see how
                it deals with this:</p>
<pre><span><span>did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]
y
Please specify an expression to populate existing objects in
order to make link 'channel' required:
fill_expr&gt; SELECT Channel FILTER .title = 'Main'
Created dbschema/migrations/00003.edgeql, id:
m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q</span></span></pre>
<p>However, before applying this migration we also add the line <code>INSERT
default::Channel {title := 'Main'};</code> at the beginning of the
                migration block in the <code>dbschema/migrations/00003.edgeql</code> file
                to ensure the <code>SELECT</code> above finds the default channel.
                Now we can actually apply the changes:</p>
<pre><span><span>$ edgedb -I chatapp migrate
edgedb error: could not read migrations in dbschema/migrations:
could not read migration file dbschema/migrations/00003.edgeql:
migration name should be
`m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba` but
`m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q` is used
instead.
Migration names are computed from the hash of the migration
contents. To proceed you must fix the statement to read as:
  CREATE MIGRATION
  m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.</span></span></pre>
<p>Uh-oh! The migration failed, but the error message actually explains
                what happened: the tool discovered we made manual changes to the file.
                Since this is deliberate, we just need to adjust the migration hash in
                order to proceed.  The tool even supplies us with the new hash. After
                adjusting the migration file, we can now apply it:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba</span></span></pre></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</a></em></p>]]>
            </description>
            <link>https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270576</guid>
            <pubDate>Fri, 26 Feb 2021 01:35:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lexical File Names in Plan 9 or Getting Dot-Dot Right]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270428">thread link</a>) | @silasdb
<br/>
February 25, 2021 | https://plan9.io/sys/doc/lexnames.html | <a href="https://web.archive.org/web/*/https://plan9.io/sys/doc/lexnames.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>
<span><b>Lexical File Names in Plan 9</b></span></p>
<p>
<span><b>or</b></span></p>
<p>
<span><b>Getting Dot-Dot Right</b></span></p>



<p>
<span><i>Rob&nbsp;Pike</i></span></p>
<p>
<span><i></i></span><span><tt>rob@plan9.bell-labs.com</tt></span><span><i></i></span></p>



<p>
<span>Bell&nbsp;Laboratories</span></p>
<p>
<span>Murray&nbsp;Hill,&nbsp;New&nbsp;Jersey&nbsp;07974</span></p>



<p>
<span><i>ABSTRACT</i></span></p>


<p>
<span>Symbolic links make the Unix file system non-hierarchical, resulting in
multiple valid path names for a given file.
This ambiguity is a source of confusion, especially since some shells
work overtime to present a consistent view from programs such as
</span><span><tt>pwd</tt></span><span>,
while other programs and
the kernel itself do nothing about the problem.
</span></p>
<p>
<span>Plan 9 has no symbolic links but it does have other mechanisms that produce the same difficulty.
Moreover, Plan 9 is founded on the ability to control a program’s environment
by manipulating its name space.
Ambiguous names muddle the result of operations such as copying a name space across
the network.
</span></p>
<p>
<span>To address these problems,
the Plan 9 kernel has been modified to maintain an accurate path name for every active
file (open file, working directory, mount table entry) in the system.
The definition of ‘accurate’ is that the path name for a file is guaranteed to be the rooted,
absolute name
the program used to acquire it.
These names are maintained by an efficient method that combines lexical processing—such as
evaluating
</span><span><tt>..</tt></span><span>
by just removing the last path name element of a directory—with
local operations within the file system to maintain a consistently, easily understood view
of the name system.
Ambiguous situations are resolved by examining the lexically maintained names themselves.
</span></p>
<p>
<span>A new kernel call,
</span><span><tt>fd2path</tt></span><span>,
returns the file name associated with an open file,
permitting the use of reliable names to improve system
services ranging from
</span><span><tt>pwd</tt></span><span>
to debugging.
Although this work was done in Plan 9,
Unix systems could also benefit from the addition of
a method to recover the accurate name of an
open file or the current directory.
</span></p>




<p>
<span><b>Motivation
</b></span></p>
<p>
<span>Consider the following unedited transcript of a session running the Bourne shell on a modern
Unix system:
</span></p>
<p>
<span><tt>%&nbsp;echo&nbsp;$HOME</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;$HOME</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;../rob</tt></span></p>
<p>
<span><tt>../rob:&nbsp;bad&nbsp;directory</tt></span></p>
<p>
<span><tt>%&nbsp;</tt></span></p>



<p>
<span>(The same output results from running
</span><span><tt>tcsh</tt></span><span>;
we’ll discuss
</span><span><tt>ksh</tt></span><span>
in a moment.)
To a neophyte being schooled in the delights of a hierarchical file name space,
this behavior must be baffling.
It is, of course, the consequence of a series of symbolic links intended to give users
the illusion they share a disk, when in fact their files are scattered over several devices:
</span></p>
<p>
<span><tt>%&nbsp;ls&nbsp;-ld&nbsp;/home/rob&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>lrwxr-xr-x&nbsp;&nbsp;1&nbsp;root&nbsp;&nbsp;sys&nbsp;&nbsp;&nbsp;14&nbsp;Dec&nbsp;26&nbsp;&nbsp;1998&nbsp;/home/ken&nbsp;-&gt;&nbsp;/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>lrwxr-xr-x&nbsp;&nbsp;1&nbsp;root&nbsp;&nbsp;sys&nbsp;&nbsp;&nbsp;14&nbsp;Dec&nbsp;23&nbsp;&nbsp;1998&nbsp;/home/rob&nbsp;-&gt;&nbsp;/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;</tt></span></p>



<p>
<span>The introduction of symbolic links has changed the Unix file system from a true
hierarchy into a directed graph, rendering
</span><span><tt>..</tt></span><span>
ambiguous and sowing confusion.
</span></p>
<p>
<span>Unix popularized hierarchical naming, but the introduction of symbolic links
made its naming irregular.
Worse, the
</span><span><tt>pwd</tt></span><span>
command, through the underlying
</span><span><tt>getwd</tt></span><span>
library routine,
uses a tricky, expensive algorithm that often delivers the wrong answer.
Starting from the current directory,
</span><span><tt>getwd</tt></span><span>
opens the parent,
</span><span><tt>..</tt></span><span>,
and searches it for an entry whose i-number matches the current directory;
the matching entry is the final path element of the ultimate result.
Applying this process iteratively,
</span><span><tt>getwd</tt></span><span>
works back towards the root.
Since
</span><span><tt>getwd</tt></span><span>
knows nothing about symbolic links, it will recover surprising names for
directories reached by them,
as illustrated by the example;
the backward paths
</span><span><tt>getwd</tt></span><span>
traverses will not backtrack across the links.
</span></p>
<p>
<span>Partly for efficiency and partly to make
</span><span><tt>cd</tt></span><span>
and
</span><span><tt>pwd</tt></span><span>
more predictable, the Korn shell
</span><span><tt>ksh</tt></span><span>
[Korn94]
implements
</span><span><tt>pwd</tt></span><span>
as a builtin.
(The
</span><span><tt>cd</tt></span><span>
command must be a builtin in any shell, since the current directory is unique to each process.)
</span><span><tt>Ksh</tt></span><span>
maintains its own private view of the file system to try to disguise symbolic links;
in particular,
</span><span><tt>cd</tt></span><span>
and
</span><span><tt>pwd</tt></span><span>
involve some lexical processing (somewhat like the
</span><span><tt>cleanname</tt></span><span>
function discussed later
in this paper), augmented by heuristics such as examining the environment
for names like
</span><span><tt>$HOME</tt></span><span>
and
</span><span><tt>$PWD</tt></span><span>
to assist initialization of the state of the private view. [Korn00]
</span></p>
<p>
<span>This transcript begins with a Bourne shell running:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>$&nbsp;</tt></span></p>



<p>
<span>This result is encouraging.  Another example, again starting from a Bourne shell:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;../ken</tt></span></p>
<p>
<span><tt>../ken:&nbsp;bad&nbsp;directory</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>$&nbsp;cd&nbsp;../ken</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/ken</tt></span></p>
<p>
<span><tt>$</tt></span></p>



<p>
<span>By doing extra work,
the Korn shell is providing more sensible behavior,
but it is easy to defeat:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;bin</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob/bin</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob/bin</tt></span></p>
<p>
<span><tt>$&nbsp;exit</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>$&nbsp;</tt></span></p>



<p>
<span>In these examples,
</span><span><tt>ksh</tt></span><span>’s
built-in
</span><span><tt>pwd</tt></span><span>
failed to produce the results
(</span><span><tt>/home/rob/bin</tt></span><span>
and
</span><span><tt>/home/ken</tt></span><span>)
that the previous example might have led us to expect.
The Korn shell is hiding the problem, not solving it, and in fact is not even hiding it very well.
</span></p>
<p>
<span>A deeper question is whether the shell should even be trying to make
</span><span><tt>pwd</tt></span><span>
and
</span><span><tt>cd</tt></span><span>
do a better job.
If it does, then the
</span><span><tt>getwd</tt></span><span>
library call and every program that uses it will behave differently from the shell,
a situation that is sure to confuse.
Moreover, the ability to change directory to
</span><span><tt>../ken</tt></span><span>
with the Korn shell’s
</span><span><tt>cd</tt></span><span>
command but not with the
</span><span><tt>chdir</tt></span><span>
system call is a symptom of a diseased system, not a healthy shell.
</span></p>
<p>
<span>The operating system should provide names that work and make sense.
Symbolic links, though, are here to stay, so we need a way to provide
sensible, unambiguous names in the face of a non-hierarchical name space.
This paper shows how the challenge was met on Plan 9, an operating system
with Unix-like naming.
</span></p>
<p>
<span><b>Names in Plan 9
</b></span></p>
<p>
<span>Except for some details involved with bootstrapping, file names in Plan 9 have the same syntax as in Unix.
Plan 9 has no symbolic links, but its name space construction operators,
</span><span><tt>bind</tt></span><span>
and
</span><span><tt>mount</tt></span><span>,
make it possible to build the same sort of non-hierarchical structures created
by symbolically linking directories on Unix.
</span></p>
<p>
<span>Plan 9’s
</span><span><tt>mount</tt></span><span>
system call takes a file descriptor
and attaches to the local name space the file system service it represents:
</span></p>
<p>
<span><tt>mount(fd,&nbsp;"/dir",&nbsp;flags)</tt></span></p>



<p>
<span>Here
</span><span><tt>fd</tt></span><span>
is a file descriptor to a communications port such as a pipe or network connection;
at the other end of the port is a service, such as file server, that talks 9P, the Plan 9 file
system protocol.
After the call succeeds, the root directory of the service will be visible at the
</span><span><i>mount point</i></span><span>
</span><span><tt>/dir</tt></span><span>,
much as with the
</span><span><tt>mount</tt></span><span>
call of Unix.
The
</span><span><tt>flag</tt></span><span>
argument specifies the nature of the attachment:
</span><span><tt>MREPL</tt></span><span>
says that the contents of the root directory (appear to) replace the current contents of
</span><span><tt>/dir</tt></span><span>;
</span><span><tt>MAFTER</tt></span><span>
says that the current contents of
</span><span><tt>dir</tt></span><span>
remain visible, with the mounted directory’s contents appearing
</span><span><i>after</i></span><span>
any existing files;
and
</span><span><tt>MBEFORE</tt></span><span>
says that the contents remain visible, with
the mounted directory’s contents appearing
</span><span><i>before</i></span><span>
any existing files.
These multicomponent directories are called
</span><span><i>union directories</i></span><span>
and are somewhat different from union directories in 4.4BSD-Lite [PeMc95], because
only the top-level directory itself is unioned, not its descendents, recursively.
(Plan 9’s union directories are used differently from 4.4BSD-Lite’s, as will become apparent.)
</span></p>
<p>
<span>For example, to bootstrap a diskless computer the system builds a local name space containing
only the root directory,
</span><span><tt>/</tt></span><span>,
then uses the network to open a connection
to the main file server.
It then executes
</span></p>
<p>
<span><tt>mount(rootfd,&nbsp;"/",&nbsp;MREPL);</tt></span></p>



<p>
<span>After this call, the entire file server’s tree is visible, starting from the root of the local machine.
</span></p>
<p>
<span>While
</span><span><tt>mount</tt></span><span>
connects a new service to the local name space,
</span><span><tt>bind</tt></span><span>
rearranges the existing name space:
</span></p>
<p>
<span><tt>bind("tofile",&nbsp;"fromfile",&nbsp;flags)</tt></span></p>



<p>
<span>causes subsequent mention of the
</span><span><tt>fromfile</tt></span><span>
(which may be a plain file or a directory)
to behave as though
</span><span><tt>tofile</tt></span><span>
had been mentioned instead, somewhat like a symbolic link.
(Note, however, that the arguments are in the opposite order
compared to
</span><span><tt>ln</tt></span><span>
</span><span><tt>-s</tt></span><span>).
The
</span><span><tt>flags</tt></span><span>
argument is the same as with
</span><span><tt>mount</tt></span><span>.
</span></p>
<p>
<span>As an example, a sequence something like the following is done at bootstrap time to
assemble, under the single directory
</span><span><tt>/bin</tt></span><span>,
all of the binaries suitable for this architecture, represented by (say) the string
</span><span><tt>sparc</tt></span><span>:
</span></p>
<p>
<span><tt>bind("/sparc/bin",&nbsp;"/bin",&nbsp;MREPL);</tt></span></p>
<p>
<span><tt>bind("/usr/rob/sparc/bin",&nbsp;"/bin",&nbsp;MAFTER);</tt></span></p>



<p>
<span>This sequence of
</span><span><tt>binds</tt></span><span>
causes
</span><span><tt>/bin</tt></span><span>
to contain first the standard binaries, then the contents of
</span><span><tt>rob</tt></span><span>’s
private SPARC binaries.
The ability to build such union directories
obviates the need for a shell
</span><span><tt>$PATH</tt></span><span>
variable
while providing opportunities for managing heterogeneity.
If the system were a Power PC, the same sequence would be run with
</span><span><tt>power</tt></span><span>
textually substituted for
</span><span><tt>sparc</tt></span><span>
to place the Power PC binaries in
</span><span><tt>/bin</tt></span><span>
rather than the SPARC binaries.
</span></p>
<p>
<span>Trouble is already brewing.  After these bindings are set up,
where does
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/bin</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;..</tt></span></p>



<p>
<span>set the current working directory, to
</span><span><tt>/</tt></span><span>
or
</span><span><tt>/sparc</tt></span><span>
or
</span><span><tt>/usr/rob/sparc</tt></span><span>?
We will return to this issue.
</span></p>
<p>
<span>There are some important differences between
</span><span><tt>binds</tt></span><span>
and symbolic links.
First,
symbolic links are a static part of the file system, while
Plan 9 bindings are created at run time, are stored in the kernel,
and endure only as long as the system maintains them;
they are temporary.
Since they are known to the kernel but not the file system, they must
be set up each time the kernel boots or a user logs in;
permanent bindings are created by editing system initialization scripts
and user profiles rather than by building them in the file system itself.
</span></p>
<p>
<span>The Plan 9 kernel records what bindings are active for a process,
whereas symbolic links, being held on the Unix file server, may strike whenever the process evaluates
a file name.
Also, symbolic links apply to all processes that evaluate the affected file, whereas
</span><span><tt>bind</tt></span><span>
has a local scope, applying only to the process that executes it and …</span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://plan9.io/sys/doc/lexnames.html">https://plan9.io/sys/doc/lexnames.html</a></em></p>]]>
            </description>
            <link>https://plan9.io/sys/doc/lexnames.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270428</guid>
            <pubDate>Fri, 26 Feb 2021 01:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zine machine: a compact 3D-printed block printing press]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 63 (<a href="https://news.ycombinator.com/item?id=26270251">thread link</a>) | @hownottowrite
<br/>
February 25, 2021 | https://hibred.pmvabf.org/zine-machine | <a href="https://web.archive.org/web/*/https://hibred.pmvabf.org/zine-machine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div><p>
            Zine Machine is a compact 3D-printed block printing press. Convert images into blocks, try friends' blocks, or use the supplied type to set a page.
    </p><p>
    All files and instructions necessary to print and use a zine machine are open to the public and available on this website. Designed and released by <a href="https://gestalte.design/" target="_blank">Gestalte Design</a>, 
    Zine Machine is an experiment in guerilla digital fabrication. 
        </p></div>
    </div></div>]]>
            </description>
            <link>https://hibred.pmvabf.org/zine-machine</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270251</guid>
            <pubDate>Fri, 26 Feb 2021 00:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EFF's Atlas of Surveillance: Documenting Police Tech with Open Source Research]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26270166">thread link</a>) | @Bluestein
<br/>
February 25, 2021 | https://atlasofsurveillance.org/real-time-crime-centers | <a href="https://web.archive.org/web/*/https://atlasofsurveillance.org/real-time-crime-centers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  

<center>
<p dir="ltr"><img alt="A crime analysts sits at a workstation in front of a wall of video monitors. " src="https://atlasofsurveillance.org/files/pictures/10/content_CHINO_RTCC.jpg"></p>

<p dir="ltr"><em><a href="https://www.facebook.com/chinopdsimmons/photos/crime-analyst-green-at-the-helm-of-our-real-time-crime-center/125426665468061/">Source: Chino Chief of Police</a></em></p>
</center>

<p dir="ltr">Over the last two decades, law enforcement agencies across the United States have been obtaining more and more sophisticated surveillance technologies to collect data. Technologies such as networked cameras, automated license plate readers, and gunshot detection are deployed around the clock, as are the tools to process this data, such as predictive policing software and AI-enhanced video analytics. The last five years have seen a distinct trend in which police have begun deploying all of this technology in conjunction with one another. The technologies, working in concert, are being consolidated and fed into physical locations called Real-Time Crime Centers (RTCCs). These high-tech hubs, filled with walls of TV monitors and computer workstations for sworn officers and civilian analysts, not only exploit huge amounts of data, but also are used to justify an increase in surveillance technology through new "data-driven" or "intelligence-led" policing strategies.&nbsp;</p>

<p dir="ltr">As part of the Atlas of Surveillance project, the Electronic Frontier Foundation and students from the Reynolds School of Journalism at the University of Nevada, Reno have identified more than 80 RTCCs across the United States, with heavy concentrations in the South and the Northeast. In this report, we highlight the capabilities and controversies surrounding 7 of these facilities. As this trend expands, it is crucial that the public understands how the technologies are combined to collect data about people as they move through their day-to-day lives.&nbsp;</p>

<p dir="ltr">RTCCs are similar to <a href="https://www.eff.org/deeplinks/2014/04/why-fusion-centers-matter-faq#:~:text=about%20fusion%20centers%3F-,What%20are%20fusion%20centers%3F,who%20analyze%20and%20share%20intelligence.">Fusion Centers</a>, to the extent the terms are sometimes used interchangeably. We distinguish between the two: fusion centers are technology command centers that function on a larger regional level, are typically controlled by a state-level organization, and are formally part of the U.S. Department of Homeland Security's fusion center network. They also focus on distributing information about national security "threats," which are often broadly interpreted. RTCCs are generally focused on municipal or county level activities and focus on a general spectrum of public safety issues, from car thefts to gun crime to situational awareness at public events.&nbsp;</p>

<p dir="ltr">The term “real-time” is also somewhat misleading: while there is often a focus on accessing data in real-time to communicate to first responders, many law enforcement agencies use RTCC to mine historical data to make decisions about the future through "predictive policing," a controversial and largely unproven strategy to identify places where crime could occur or people who might commit crimes.&nbsp;</p>

<center>
<p dir="ltr"><img alt="A map of the United States with small, orange circles representing real-time crime centers." src="https://atlasofsurveillance.org/files/pictures/12/content_RTCC_MAP.png"></p>
</center>

<p dir="ltr">So far, the Atlas of Surveillance project has identified RTCCs in 29 states, with the highest number in Florida (14) and New York (11); however, Mississippi also stood out with four RTCCs despite being a significantly smaller state. While RTCCs are commonly found in large metropolitan areas, even smaller cities such as Ogden, Utah and Hampton, Virginia have established their own RTCCs. There may be more RTCCs yet to be discovered. In Denver, local officials and news organizations were unaware the Denver Police Department had <a href="https://www.9news.com/article/news/local/denver-police-quietly-expand-surveillance-camera-network/73-80b180c4-2456-4a28-b106-feb1831ea61f">launched an RTCC </a>and expanded its camera network until Atlas of Surveillance researchers uncovered a job advertisement outlining its capabilities. The Honolulu Police Department has added a RTCC to its <a href="http://206.195.188.21/downloads/HPD_Moving_Forward.pdf">2020-2022 strategic plan</a>.&nbsp;</p>

<p dir="ltr">RTCCs tend to share common defining technological features, the most prominent being access to a <a href="https://www.eff.org/pages/surveillance-cameras">surveillance camera network</a> with feeds that are broadcast live onto a wall of TV monitors within a centralized headquarters. The number of cameras can range from just a few hundred, as in Albuquerque, New Mexico, to more than 12,000, as in Atlanta, Georgia, but in all cases the number of cameras have been steadily growing.</p>

<p dir="ltr">RTCCs also go hand-in-hand with <a href="https://www.eff.org/pages/gunshot-detection">gunshot detection technology</a>, especially ShotSpotter, a company that installs sensors throughout neighborhoods in order to listen for and locate suspected gunfire. The majority of RTCCs also tap into <a href="https://www.eff.org/pages/automated-license-plate-readers-alpr">automated license plate readers</a> (ALPRs) to track and get real-time alerts on the locations of vehicles. In addition, RTCC staff typically have access to a variety of criminal justice databases and monitor social media feeds.&nbsp;</p>

<p dir="ltr">The starting cost of these RTCCs can range dramatically, from just a few hundred thousand dollars to as much as $11 million, as in New York City. This funding can come from a number of sources, including city budgets, voter-approved bonds, state and federal grants, private institutions, and wealthy individual donors. For example, the Atlanta Loudermilk Operation Shield Video Integration Center started with a $1-million donation from the Loudermilk family, who are real-estate developers, as well as $350,000 from the city. The price tag proved too high for the Fresno Police Department in California, which let go of its <a href="https://gvwire.com/2020/07/09/conservative-appointee-lasts-just-15-hours-on-fresno-immigrant-rights-committee/">part-time RTCC staff in 2019</a> and <a href="https://www.fresno.gov/finance/wp-content/uploads/sites/11/2020/06/TRAY-MEMO-Response-to-Council-Direction-No.-41-Request-Audit-of-Video-Policing-Surveillance-Unit-6.18.20.pdf">ceased all real-time operations</a> at the RTCC in 2020 (although police can still access stored footage from previously installed cameras after crimes occur).&nbsp;</p>

<p dir="ltr">Yet the cost barrier for these systems is steadily dropping. Based at the University of New Orleans, a private organization called <a href="https://www.projectnola.org/">Project NOLA</a> provides subsidized cameras and other technologies to cities and provides virtual RTCC software to municipalities through its NOLA National Real-Time Crime Center. So far, Project NOLA has partnered with police departments in Louisiana, Mississippi, New Jersey, Alabama, and Pennsylvania.&nbsp;</p>

<center>
<p dir="ltr"><img alt="A map of Newark with icons marking the location of cameras. " src="https://atlasofsurveillance.org/files/pictures/13/content_NEWARK_CVP.png"></p>

<p dir="ltr">Source: <a href="https://cvp.newarkpublicsafety.org/">New Jersey "Citizens Virtual Patrol"</a></p>
</center>

<p dir="ltr">Funding isn't the only way that RTCCs blur the line between public and private surveillance. The Newark, New Jersey RTCC encourages citizens to view live video feeds from cameras across the city through its "<a href="https://cvp.newarkpublicsafety.org/">Citizen Virtual Patrol</a>" program. Meanwhile, police in Jackson, Mississippi began testing a new system to link doorbell cameras, including Amazon’s Ring, to their RTCC. Similar camera sharing programs are being promoted in <a href="https://www.wtxl.com/news/lcso-unveils-new-real-time-crime-center/article_af42e61c-f35a-11e8-a32d-2bd5dc910bb2.html">Leon County, Florida</a> and <a href="https://www.safecamnola.com/">New Orleans</a>.</p>

<p dir="ltr">Here are the first seven RTCC case studies:&nbsp;</p>

<ul>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/albuquerque-real-time-crime-center">Albuquerque Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/atlanta-loudermilk-operation-shield-video-integration-center">Atlanta Loudermilk Video Integration Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/detroit-real-time-crime-center">Detroit Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/miami-gardens-real-time-crime-center">Miami Gardens Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/new-orleans-real-time-crime-center">New Orleans Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/ogden-rtcc">Ogden Area Tactical Analysis Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/sacramento-rtcc">Sacramento Real-Time Crime Center</a></li>
</ul>

<p>We have also included <a href="https://atlasofsurveillance.org/real-time-crime-centers/fresno-real-time-crime-center-suspended">a profile of the Fresno Real-Time Crime Center,</a> which was temporarily shut down prior to publication.&nbsp;</p>

<p dir="ltr">More profiles are planned in the coming weeks and months. For more information on the technologies used by police, browse the rest of the <a href="https://atlasofsurveillance.org/">Atlas of Surveillance site</a> or visit EFF's <a href="https://www.eff.org/sls">Street-Level Surveillance hub</a>.&nbsp;</p>

<p dir="ltr">If you know of an RTCC that isn't in our data, email <a href="mailto:aos@eff.org">aos@eff.org</a> or fill out <a href="https://forms.gle/XqFHYndfsWA2GTNj6">our online Google form</a>.&nbsp;</p>

<p dir="ltr" role="presentation">- Dave Maass, Electronic Frontier Foundation, and Hailey Rodis, Reynolds School of Journalism, University of Nevada, Reno.</p>

<h2>Credits</h2>

<p>This project is based on original research conducted by Prof. Gi Yun’s Cybersecurity, Privacy and Society class at the University of Nevada, Reno, Reynolds School of Journalism:&nbsp;Hunter Drost, Kirk Geller, D. Llaneza, Hailey Rodis, Stone Seuss, Cooper Venzon, Madison Vialpando, Javier Hernandez, and Matthew Hinrichs.&nbsp;</p>

<p>Additional writing and editing: Matthew King, Taylor Johnson, Hailey Rodis, Javier Hernandez, and Madison Vialpando</p>

<p dir="ltr" role="presentation"><em>Published Nov. 13, 2020</em></p>

<p dir="ltr" role="presentation"><em>Updated Nov. 24, 2020 to include information about the Honolulu Police Department.</em></p>



  
</div></div>]]>
            </description>
            <link>https://atlasofsurveillance.org/real-time-crime-centers</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270166</guid>
            <pubDate>Fri, 26 Feb 2021 00:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IsometricBlocks]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26270042">thread link</a>) | @autoditype
<br/>
February 25, 2021 | http://shaunlebron.github.io/IsometricBlocks/ | <a href="https://web.archive.org/web/*/http://shaunlebron.github.io/IsometricBlocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://github.com/shaunew/IsometricBlocks"><img src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>


	

	<p>
In an <a href="http://en.wikipedia.org/wiki/Isometric_projection">isometric</a>
display, it can be tricky to draw boxes of various sizes in the correct order
to keep them appropriately in front of or behind one another.  The figure below
shows an example.  The blue box should be drawn first, then green, then red.
	</p>

	<figure>
		<canvas id="figure1a" width="350" height="200"></canvas>
		<canvas id="figure1b" width="350" height="200"></canvas>
		<figcaption>
Figure 1: The boxes on the left are <u>not</u> drawn in the correct order, whereas the
boxes on the right are drawn correctly.
		</figcaption>
		
	</figure>

	<p>
We will explore a simple solution for determining the correct order to draw a
given set of boxes.  But first, we must define what we mean by <em>boxes</em>.
	</p>

	<h3>What do we mean by <em>boxes</em>?</h3>

	<p>
We define boxes as <em>axis-aligned</em> and <em>non-intersecting</em>
rectangular prisms. Take a look at the above Figure 1 again.  Each box is
parallel to the <em>x</em>, <em>y</em>, and <em>z</em> axis (i.e.
axis-aligned).  Also, note that the boxes are next to each other but do not
intersect.
	</p>

	<h3>Determine if boxes overlap on screen.</h3>

	<p>
First of all, if two boxes do not overlap on the screen, then we do not have to
worry about which one is drawn first.  This is the first test we must perform,
which we explore in this section.
	</p>

	<figure>
		<canvas id="figure2a" width="350" height="200"></canvas>
		<canvas id="figure2b" width="350" height="200"></canvas>
		<figcaption>
Figure 2: No overlap on the left; overlap on the right.  (Note: we are talking
about overlap on screen, not intersection in space.)
		</figcaption>
		
	</figure>

	<p>
The silhouettes of the 3D boxes become 2D hexagons in the isometric view, as seen below.  We use the
outline of these silhouettes to test for overlap.
	</p>

	<figure>
		<canvas id="figure3a" width="350" height="200"></canvas>
		<canvas id="figure3b" width="350" height="200"></canvas>
		<figcaption>
Figure 3: The box silhouettes in an isometric view are simple hexagons.  Note
that their sides are always parallel to the vertical and two diagonal axes.
		</figcaption>
		
	</figure>

	<p>
We take advantage of the fact that the hexagon sides are always parallel to
some axis.  This allows us to easily determine if the hexagons overlap by
checking for intersection of their regions on each axis.  We add an <em>h</em>
(horizontal) axis to help.
	</p>

	<figure>
		<canvas id="figure4a" width="350" height="200"></canvas>
		<canvas id="figure4b" width="350" height="200"></canvas>
		<figcaption>
The red and blue boxes do not overlap on the h axis, therefore they do not overlap.
The green and blue boxes do overlap since their region on every axis overlap.
		</figcaption>
		
	</figure>

	<p>
Now that we have outlined our concept for <em>determining if two boxes overlap
on the screen</em>, we will fill in the details necessary for implementing it.
	</p>

	<p>
The act of flattening the 3D box into a 2D hexagon involves getting rid of the
Z coordinate.  Notice that increasing a point's Z coordinate by 1 is the same
as incrementing both X and Y coordinates by 1.  Thus, we can add Z to both X
and Y and drop Z completely.  Shown below is the source code for a function
that performs this conversion.
	</p>

<code>
<span>function</span> spaceToIso(spacePos) <span>{</span>

    
    <span>var</span> isoX = spacePos.x + spacePos.z;
    <span>var</span> isoY = spacePos.y + spacePos.z;

    <span>return</span> <span>{</span>
        x: isoX,
        y: isoY,

        
        h: (isoX - isoY) * Math.cos(Math.PI/6),

        
        v: (isoX + isoY) / 2;
    <span>}</span>;
<span>}</span></code>

	<p>
And finally, after determining the bounds of each hexagon, we can determine if
they overlap by using the source code below.
	</p>

<code><span>function</span> doHexagonsOverlap(hex1, hex2) <span>{</span>
    
    <span>return</span> (

        
        !(hex1.xmin &gt;= hex2.xmax || hex2.xmin &gt;= hex1.xmax) &amp;&amp;

        
        !(hex1.ymin &gt;= hex2.ymax || hex2.ymin &gt;= hex1.ymax) &amp;&amp;

        
        !(hex1.hmin &gt;= hex2.hmax || hex2.hmin &gt;= hex1.hmax));
<span>}</span></code>

	<p>
Now that we have determined if two boxes overlap on the screen, we can begin exploring how to determine which box is in front of the other.
	</p>

	<h3>Determine which box is in front.</h3>

	<p>
Recall that our boxes do not intersect each other. we can visualize their separation
as a thin plane between them (see Figure 5 below).  After identifying this
plane, we can determine which box is in front by selecting the one on the
correct side of this plane.
	</p>

	<figure>
		<canvas id="figure5a" width="230" height="200"></canvas>
		<canvas id="figure5b" width="230" height="200"></canvas>
		<canvas id="figure5c" width="230" height="200"></canvas>
		<figcaption>
Figure 5: A pair of blocks can be separated in one of three ways shown here.
The dark glass illustrates this separation.
		</figcaption>
		
	</figure>

	<p>
We can find this plane of separation by looking at each axis individually.  In
particular, we look for an axis which has non-intersecting box ranges (see
Figure 6 below).
	</p>

	<figure>
		<canvas id="figure6a" width="350" height="200"></canvas>
		<canvas id="figure6b" width="350" height="200"></canvas>
		<figcaption>
Figure 6: On the left, the blocks are separated on the y-axis.  On the right,
the blocks are separated on the x-axis. (The z-axis is omitted for simplicity.)
		</figcaption>
		
	</figure>

	<p>
In Figure 6 above, we have chosen a coordinate system which make lesser values
of <em>x</em> and <em>y</em> to be closer to the camera.  Though not shown, the
<em>z</em> axis is positive in the up direction, so a greater value makes it
closer to the camera.
	</p>

	<p>
The following is a javascript function for determining if the first block is in
front of the second:
	</p>

	<code><span>function</span> isBoxInFront(box1, box2) <span>{</span>

    
    
    <span>if</span> (box1.xmin &gt;= box2.xmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.xmin &gt;= box1.xmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.ymin &gt;= box2.ymax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.ymin &gt;= box1.ymax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.zmin &gt;= box2.zmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.zmin &gt;= box1.zmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>

<span>}</span></code>

	<h3>Draw boxes in the correct order.</h3>

	<p>
In general, <u>a box should not be drawn until all the ones behind it are
drawn</u>.  Thus, we begin by drawing the boxes that have nothing behind them.
Then, we can draw the boxes that are only in front of those that are already
drawn. This process continues until all boxes are drawn. (See Figure 4 below
for an example.)
	</p>

	<figure>
		<canvas id="figure7" width="650" height="200"></canvas>
		<figcaption>
Figure 4: (1) Nothing is behind blue, so draw it first. (2) Draw green next
since blue was the only one behind it and is already drawn.  (3) Then draw red,
since both blocks that were behind it have been drawn.
		</figcaption>
		
	</figure>

	<p>
To implement this algorithm, each box must know exactly which boxes are behind
it.  We have already determined how to do this in the last section.  A search
must be implemented so that each box has a list of boxes behind it.
	</p>

	<p>
You are now armed with everything you need to know to render isometric boxes in
the correct order.
	</p>

	<h3>A conundrum</h3>

	<p>
It is possible to have a situation seen in the figure below.  The aforementioned drawing
methods dictate that we first draw the box with nothing behind it, but this example illustrates
a case where this cannot be done.
	</p>

	<figure>
		<canvas id="figure8" width="650" height="200"></canvas>
		<figcaption>
Here are three boxes intertwined in a way such that one is always behind
another.  This prevents us from drawing a first box.
		</figcaption>
		
	</figure>

	<p>
The figure above cheats by segmenting the orange box into two.
This is one method of breaking this type of cycle.
	</p>

	<p>
There are formal methods used for detecting
such cycles mentioned in the appendix.  After detection of a cycle, the blocks in that cycle
could be drawn with special clipping regions to respect front boxes or to segment a block or blocks
that will break the cycle.  These are solutions that I will be exploring and updating this article as
my experiments progress.
	</p>

	<hr>
	<h2>Appendix</h2>

	<h4>A formal description of the solution</h4>

	<p>
This is a special case of the <a href="https://en.wikipedia.org/wiki/Painter%27s_algorithm">Painter's Algorithm</a>,
which handles occlusion by drawing back-to-front.
	</p>

	<p>
For those who are interested, our method for determining if hexagons and boxes
are overlapping is a result of the <a href="http://en.wikipedia.org/wiki/Hyperplane_separation_theorem">hyperplane separation theorem</a>.
	</p>

	<p>
Also, the way in which we determined the drawing order of the boxes is known in graph theory as a <a href="http://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>,
which is essentially a depth-first search of a directed graph.
	</p>

	<p>
You can build a directed graph of the <em>boxes</em>, with directed edges to
the boxes that are behind it.  Topologically sorting this graph will produce an
ordered list of boxes that can be drawn in that exact order.
	</p>

	<p>
Mathematicians will recognize this directed graph as a <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partially ordered
set</a>.
	</p>

	<p>
Finally, to prevent the aforementioned cycle conundrum, we can use <a href="">Tarjan's
strongly connection components</a> algorithm.  After computing these cycles,
one could either split a block to prevent a cycle, or to use a clipping region
to prevent drawing over any blocks that are supposed to be in front of it.
	</p>

	<h4>Alternative Solutions</h4>

	<p>
You may be able to just use <a href="https://en.wikipedia.org/wiki/Z-buffering">Z-buffering</a>,
though drawing order is still important for transparent sprites.  Also, if all
bounding boxes are unit cubes, sorting is much simpler.
	</p>

	<h4>Full example of working code</h4>

	<p>
All the diagrams above were created using a simple isometric box renderer
written in Javascript, which applies all the techniques described in this
article.  You can study the fully annotated source code on <a href="https://github.com/shaunew/IsometricBlocks">IsometricBlocks project on
GitHub</a>.
	</p>

	<h4>Real game examples</h4>

	<ul>
		<li><a href="http://andrewrussell.net/2016/06/how-2-5d-sorting-works-in-river-city-ransom-underground/">How 2.5D Sorting works in River City Ransom: Underground</a> - allowing bounding boxes to intersect by specifying heightmaps within them (<a href="https://news.ycombinator.com/item?id=12313271">summary</a>)</li>
		<li><a href="http://bannalia.blogspot.co.uk/2008/02/filmation-math.html">Filmation engine on the ZX Spectrum</a></li>
	</ul>
	

	<h4>Thanks</h4>

	<p>
Thanks to Ted Suzman at <a href="http://playbuildy.com/">buildy</a> for
introducing this problem and solution to me.  And thanks to adamhayek for <a href="http://www.reddit.com/r/gamedev/comments/18222r/how_to_determine_the_draw_order_for_an_isometric/c8ayzby">further
insight</a> on a general solution. And thanks to <a href="http://www.reddit.com/r/gamedev/comments/18bg95/tutorial_how_to_render_isometric_blocks_correctly/c8dfx51">Slime0 at reddit</a> for pointing out errors in this article by illustrating the cycle example shown in this article, and for illustrating why we cannot deduce relative drawing order between two non-overlapping boxes.
Thanks to <a href="https://lobste.rs/s/bengjo/drawing_isometric_boxes_correct_order/comments/rzgvnc#c_rzgvnc">Mark Nelson</a> for extra context on painter's algorithm and z-buffering.
	</p>

	<hr>

	<figure>
		<canvas id="figure5" width="700" height="200"></canvas>
		
	</figure>



</div>]]>
            </description>
            <link>http://shaunlebron.github.io/IsometricBlocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270042</guid>
            <pubDate>Fri, 26 Feb 2021 00:08:02 GMT</pubDate>
        </item>
    </channel>
</rss>
