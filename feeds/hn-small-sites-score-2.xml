<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 06 Aug 2020 20:20:00 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 06 Aug 2020 20:20:00 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On the Road to 7-Figure Income with the Indie Founder of DropInBlog]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24058315">thread link</a>) | @theradicalone
<br/>
August 5, 2020 | https://indiediary.com/indie-founder-jesse-schoberg/ | <a href="https://web.archive.org/web/*/https://indiediary.com/indie-founder-jesse-schoberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-301"> <div><p>Jesse Schoberg, CEO &amp; indie founder of DropInBlog, went from $1k per month, to now towards a 7-figure income. Jesse and his team currently faces the decision of “how big they want to grow”.</p><h2>About This Indie Interview</h2><div><p> This is the <code><span><strong>#2nd</strong></span></code> installment of our <a href="https://indiediary.com/hub/interviews/indiefounders/" title="interviews with indie founders">Indie Interviews</a> series to help <strong>aspiring indie founders &amp; indie entrepreneurs</strong> to get inspired by listening from those successful indie founders who are already highly involved on the startup scene and *being there* taming the waves &amp; surfing better than ever to achieve their dream – seeking financial freedom, working on projects that matters to them, getting a sense of accomplishment (in their own eyes) and working on their own schedule.</p><div><p> It is also an opportunity for new indie founders to get to know other like-minded indie entrepreneurs. </p><p>I hope you will derive as much fun to read my interviews as I’m having by interviewing those awesome indie founders, entrepreneurs &amp; businesses.</p></div><hr></div><h2>And Now the Interview With the Indie Founder</h2><h3>### Spotlight on our today’s indie person</h3><h4><a name="tell_us"></a>&gt;&gt; Please tell us about yourself + what your workstation looks like + any productivity tools you use?</h4><p>Hi. I’m <strong>Jesse Schoberg</strong>, CEO and Co-Founder of <strong><em>DropInBlog</em></strong>. I’ve been working on internet stuff since 2001 when I learned “web design” as it was called at the time. I taught myself HTML, CSS, and PHP.</p><p>I just started building websites for small businesses. That eventually turned into an agency with remote staff.</p><p>Learning to find global talent was huge for me. Once you learn how to source a team of freelancers, your journey becomes a lot faster. The agency did well enough that I made a good living. But I knew scaling an agency was a nightmare. The real path to freedom was with my own projects.</p><p>I started a variety of side projects over the years with varying success. Some failed, some eventually had moderate 6 figure exits.</p><p>I’ve done a bunch of things, but here are a few: vacation rental directory, white label hotel booking engine, white label SMS marketing SaaS, form processing SaaS, franchise directory, and eventually DropInBlog (a SaaS that adds a blog to sites not built in <a href="https://indiediary.com/wordpress/">WordPress</a>).</p><p>My experience running the agency and knowing how to code helped immensely. It helped me hire, helped me manage staff, helped me manage projects efficiently, Etc.</p><p><strong>My workstation</strong> – I’m a minimalist and a nomad so I don’t have a big desk setup.</p><p><strong>The tools I (we) use daily to keep things organised &amp; productiv</strong>e:</p><p>We use&nbsp;<strong>Freedcamp</strong>&nbsp;for our primary PM tool, and we’ve been delighted with it. They are always responsive to issues and seem to have a great team.</p><p>I keep my “today’s focus” just in a simple text doc that runs in its own space.&nbsp;I have a few little apps I like:</p><div><div><ul><li><strong>TripMode</strong>&nbsp;– limits which apps can connect to the internet, great for coffee shops, Etc</li><li><strong>Micro Snitch</strong>&nbsp;– notifies you anytime an app turns on your mic or camera</li><li><strong>Droplr</strong>&nbsp;– screenshots / screencasts / code snippets</li><li><strong>Migadu</strong>&nbsp;– email hosting based on usage, not domains/accounts</li></ul><h4><a name="routine"></a>&gt;&gt; Do you have a routine to start your day off &nbsp;or do you take it as it comes?</h4><p>I’m more of a night guy. I don’t feel my real energy kicking in until the afternoon. So I take my mornings slow. I do personal stuff – catch up with friends, life admin, reading, Etc.</p><p>You gotta follow your energy, and work when your brain is most “on”. This is different for everyone. I don’t use an alarm, I only eat 2 meals/day, and breakfast is not one of them. I love a good latte to start my day. I like to do a bit of callisthenics.</p><p>That said if I’m deep into a project, all that goes out the window. I’ll wake up and go straight to smashing keys as my brain won’t turn off until the task is finished. Sometimes that’s days or a week. Follow your energy.</p><h4><a name="motivation"></a>&gt;&gt; How do you keep yourself motivated to achieve your goals?</h4><p>I value freedom a lot. I also love building stuff. So ultimately that’s what keeps me motivated.</p><p>Internet businesses and the money they generate creates incredible freedom that most people can’t even wrap their head around if structured correctly.</p><p>Aside from that, I love the satisfaction of creating things and the excitement that can come with the hustle.</p><p>If my motivation is low, I try to step away from the keyboard. I walk, listen to podcasts (that are often not about business), play the guitar, or explore whatever city I’m dwelling in.</p><p>For me, motivation comes in large waves – I’ve learned it’s better not to force it.</p><h3>### The Indie Person as an Indie Founder/Entrepreneur</h3><h4><a name="change_world"></a>&gt;&gt; What change are you seeking to make to the world?</h4><p>Since <strong>DropInBlog</strong> has taken off, I’ve done my best to keep side projects to a minimum. But there is one we’re pursuing that is about impact and awareness.</p><p>That project is about alternative protein sources. It turns out we’re running out of resources on this earth place. We got interested in bug protein (crickets specifically) and are working on that project over at <strong>Crickets.org</strong>.</p><h4><a name="books"></a>&gt;&gt; The books or material you recommend?</h4><p>I know everyone talks about it, but if you are new in your journey, you should read <strong>The Four Hour Work Week</strong>. While the industry has dramatically evolved since its publication, it is a good starting point for mindset — precisely, <em><strong>the Dreamline exercise</strong></em>.</p><p>For personal growth and also an understanding of other humans, my all-time favourite book is <strong>The Happiness Hypothesis <em>by Jonathan Haidt</em></strong>. (Also see his follow-up <strong>The Righteous Mind</strong>.)</p><h4><a name="difference"></a>&gt;&gt; According to you, what is the difference between a founder &amp; an entrepreneur? And which one are you?</h4></div></div><p>That is an interesting question. I’ve never really thought about it.</p><p>I guess in my mind, all founders are entrepreneurs, but all entrepreneurs are not founders.</p><p>I feel like I’ve been an entrepreneur my whole life. I didn’t feel like a founder until I was focused on certain projects or companies and leading a vision.</p><p>If you hustle hot dogs on the street side or flip widgets on ebay, you’re an entrepreneur, if you take those to the next level with process, vision and longevity you are a founder.</p><h4><a name="habit"></a>&gt;&gt; What ONE habit played an important part for you as an indie founder?</h4><p><strong>Consistency</strong>. Success is a long game, and you’ve got to show up (albeit not&nbsp;<em>every</em>&nbsp;day).</p><h3>### The SaaS Business of the indie person</h3><div><p> Claim your (free) 30%-off coupon to unlock 100+ deals on tools/services to supercharge your startup journey! (worth up to $50,000)</p><p> Get practical insights from successful indie founders – Learn from their mistakes, save time knowing what actually works! </p><p> Get top hand-picked delivery of personal growth, startup &amp; business resources to nourish your entrepreneurial mind. </p><p> <a href="https://indiediary.substack.com/subscribe">JOIN INDIE DIARY</a></p></div><h4><a name="your_biz"></a>&gt;&gt; Tell us about your indie business: the beginning + how you come up with the naming?</h4><p>We have built (and are still building) a full-fledged blog platform. However, it’s a different use case than WordPress or Medium or other platforms.</p><p>It allows you to embed a blog into your existing site, using your current template or theme. Some might call it a “headless blog platform”. So that could be your hand-coded HTML site, something built in Webflow or Kartra, a Shopify store, a Thinkific site, Etc.</p><p><strong>It’s called DropInBlog</strong>. Because, well.. it lets you “drop” a blog into your website. We didn’t overthink it too much. Simple, brandable, and we could secure the .com and related social profiles.</p><p><strong>Our niche</strong> is people with websites that are not built in WordPress that want to have a blog.</p><h4><a name="aha"></a>&gt;&gt; When exactly did you get that “aha moment“ for your business/project? Tell us the story behind..</h4><p>It was quite a long time ago. Before WordPress took the world by storm, we were building sites for our clients using basic HTML, and some PHP includes.</p><p>Then clients started asking for blogs. We would install WordPress in a folder and then create a custom theme to match the existing site.</p><p>It was a tedious process, and then clients were frustrated because WordPress was a bit convoluted when using it “just” as a blog.</p><p>So with that, I thought – “why couldn’t we build a basic CMS that was just a blog that plugged into any existing site?”</p><h4><a name="biz_model"></a>&gt;&gt; What is your business model – how are you generating revenue &amp; making it profitable?</h4><p>It’s a SaaS. There are two plans, and both of them are paid-plans. There is a free trial but no free-plan.</p><p>We’ve never done well with freemium.</p><h4><a name="success"></a>&gt;&gt; In the context of this indie business, what does success mean to you?</h4><p>I want <strong>DropInBlog</strong> to become the “household name” when it comes to the pain point we solve.</p><h4><a name="income"></a>&gt;&gt; Can you share your revenue stats &amp; journey towards your 7-figure income?</h4><p>The first few years we had it as a little side project it was only making like $1k / month.</p><p>Then we had a bunch of things kind of fall into place early 2019. That’s when we saw the potential.</p><p><strong>We blew past six figures once we started focusing on it, now on the road to 7-figures </strong>– around which point we’ll have to make some serious decisions about how big we want to take this thing.</p><h4><a name="research"></a>&gt;&gt; How do you do your market research?</h4><p>Mostly we watch our signups. If there is a community like <strong><em>Kartra</em></strong> or <strong><em>Webflow</em></strong> we see using our product a lot, we start to lean into that community more and cater our content &amp; product to their needs a bit.</p><p>Once we identify things we want to target, our favourite tool is <strong>Ahrefs</strong> for sure.</p><p>But we also use <strong>Hotjar</strong> for user experience stuff and many tools from <strong><a href="https://indiediary.com/baremetrics" target="_blank" rel="noreferrer noopener nofollow ugc">Baremetrics</a></strong> to engage our customers and keep an eye on how our numbers are doing.</p><h4><a name="trust"></a>&gt;&gt; How are you building trust to attract customers + Your promotion strategies?</h4><p>We do a fair amount of content marketing. I’m active on twitter as the founder (<strong><a href="https://twitter.com/JesseSchoberg" target="_blank" rel="noreferrer noopener nofollow ugc">@JesseSchoberg</a></strong>), and occasionally I speak at conferences.</p><p>We’re mostly organic but are also testing some paid channels. We drive some traffic from some Facebook groups related to the platforms we are popular with as well.</p><h4><a name="tech"></a>&gt;&gt; What tech stack, infrastructure &amp; tools are you using to power your business?</h4><p>We’re <em>LAMP</em> programmers by trade. Our original code was written in <strong>Symfony</strong>. However, we’re now working on a rewrite using <strong>Laravel</strong>.</p><p>We use <strong>Amazon</strong> for the full stack including <strong>E2 &amp; S3</strong> along with <strong>Cloudflare</strong> for cache and routing. Once things got a bit larger, we hired a <em>DevOps</em> team to get our ducks in a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://indiediary.com/indie-founder-jesse-schoberg/">https://indiediary.com/indie-founder-jesse-schoberg/</a></em></p>]]>
            </description>
            <link>https://indiediary.com/indie-founder-jesse-schoberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24058315</guid>
            <pubDate>Wed, 05 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bayes Theorem: A Framework for Critical Thinking]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24058247">thread link</a>) | @neilkakkar
<br/>
August 5, 2020 | https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Have you ever noticed how you can be fuming with anger one second, and absolutely calm the next?</p>

<p>An asshole driver cuts you off on the highway, and you’re raging. A moment later, you notice him pull into the hospital and your anger melts away. “Yeah, maybe he has a patient in the car with him. Or, maybe someone close is dying. I guess he’s not an asshole after all.”</p>

<p>An obscure rule from Probability Theory, called Bayes Theorem, explains this very well. This 9,000 word blog post is a complete introduction to Bayes Theorem and how to put it to practice. In short, Bayes Theorem is a framework for critical thinking. By the end of this post, you’ll be making better decisions, realise when you’re being unreasonable, and also understand why some people believe in UFOs.</p>

<p>It’s a hefty promise, and there’s a good chance of failure. Implementing these ideas will take emotional effort, but it’s worth it.</p>

<p>Thinking the driver is an asshole is normal. Bayes Theorem expects the same. The difference between Bayes and us is the intensity with which we believe. Most times, the seething anger isn’t warranted. This is probably why we feel stupid about all that anger. It melts away so quickly! This is calibration - aligning our emotions to the intensity of the situation - which we’ll cover as well.</p>

<!-- One way to check = If you're flip flopping between beliefs very quickly, you're probably miscalibrated. -->





<p>There’s no fancy math in this guide. We’re using Probability Theory, but aren’t going into the derivation, nor are we solving probability problems from school textbooks. These things are tedious without understanding the why. Instead, we’ll understand why Bayes Theorem matters, and how to apply it.</p>

<p>To begin with, let’s play a game. Throughout this game, <em>notice</em> how you feel about your decisions. Notice what decisions you’re making, and notice how you find the answer.</p>

<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#the-246-game" id="markdown-toc-the-246-game">The 2,4,6 game</a></li>
  <li>
<a href="#bayes-explanation" id="markdown-toc-bayes-explanation">Bayes Explanation</a>    <ul>
      <li><a href="#bayes-theorem" id="markdown-toc-bayes-theorem">Bayes Theorem</a></li>
      <li><a href="#being-late-example" id="markdown-toc-being-late-example">Being Late Example</a></li>
    </ul>
  </li>
  <li><a href="#grinding-the-gears" id="markdown-toc-grinding-the-gears">Grinding the Gears</a></li>
  <li>
<a href="#the-4-rules-for-being-a-good-bayesian" id="markdown-toc-the-4-rules-for-being-a-good-bayesian">The 4 Rules for being a good Bayesian</a>    <ul>
      <li><a href="#probability-is-a-map-of-your-understanding-of-the-world" id="markdown-toc-probability-is-a-map-of-your-understanding-of-the-world">Probability is a map of your understanding of the world</a></li>
      <li><a href="#update-incrementally" id="markdown-toc-update-incrementally">Update incrementally</a></li>
      <li><a href="#seek-disconfirming-evidence" id="markdown-toc-seek-disconfirming-evidence">Seek disconfirming evidence</a></li>
      <li><a href="#remember-your-priors" id="markdown-toc-remember-your-priors">Remember your priors</a></li>
    </ul>
  </li>
  <li><a href="#destroying-cognitive-biases" id="markdown-toc-destroying-cognitive-biases">Destroying cognitive biases</a></li>
  <li><a href="#seeking-disconfirming-evidence-for-bayes" id="markdown-toc-seeking-disconfirming-evidence-for-bayes">Seeking disconfirming evidence for Bayes</a></li>
  <li><a href="#the-246-game-revisited" id="markdown-toc-the-246-game-revisited">The 2,4,6 Game Revisited</a></li>
  <li><a href="#the-being-late-example-revisited" id="markdown-toc-the-being-late-example-revisited">The Being Late Example Revisited</a></li>
  <li>
<a href="#getting-stronger" id="markdown-toc-getting-stronger">Getting stronger</a>    <ul>
      <li><a href="#improve-your-priors" id="markdown-toc-improve-your-priors">Improve your priors</a></li>
      <li><a href="#become-a-master-hypothesis-builder" id="markdown-toc-become-a-master-hypothesis-builder">Become a master hypothesis builder</a></li>
      <li><a href="#learn-the-math" id="markdown-toc-learn-the-math">Learn the Math</a></li>
    </ul>
  </li>
  <li>
<a href="#putting-it-all-together-in-practice" id="markdown-toc-putting-it-all-together-in-practice">Putting it all together in practice</a>    <ul>
      <li><a href="#hypotheses-with-frequencies" id="markdown-toc-hypotheses-with-frequencies">Hypotheses with frequencies</a></li>
      <li><a href="#growing-the-disk" id="markdown-toc-growing-the-disk">Growing the disk</a></li>
      <li><a href="#switching-hypotheses" id="markdown-toc-switching-hypotheses">Switching hypotheses</a></li>
      <li><a href="#strong-opinions-weakly-held" id="markdown-toc-strong-opinions-weakly-held">Strong Opinions, Weakly Held?</a></li>
    </ul>
  </li>
  <li><a href="#this-seems-very-different-to-what-i-learned-in-school" id="markdown-toc-this-seems-very-different-to-what-i-learned-in-school">This seems very different to what I learned in school</a></li>
  <li><a href="#epilogue-the-end-is-the-beginning" id="markdown-toc-epilogue-the-end-is-the-beginning">Epilogue: The End is the Beginning</a></li>
  <li><a href="#appendix-more-good-examples" id="markdown-toc-appendix-more-good-examples">Appendix: More Good Examples</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="the-246-game">The 2,4,6 game</h2>

<p>There’s a black box with a formula inside for generating 3 numbers. Your job is to try and guess this formula. The input box below is connected to the black box. If you give it 3 numbers, it’s going to tell you whether they follow the formula or not. Separate each number with a comma.</p>

<p>To start you off, (2,4,6) follows the pattern. Try it out!</p>





<p>Did you figure it out? Write down your answer in here:</p>

<h2 id="bayes-explanation">Bayes Explanation</h2>

<p>Most people try some sequence of: (4,6,8), (1,2,3) … and end up with either increasing numbers, or increasing numbers that are even. Notice how you’re pretty confident in your answer by the time you write it down. You’ve tried a few examples, and <strong>all</strong> of them made sense!</p>

<p>But perhaps you didn’t think to try (-1,2,10) or (4,2,6).</p>

<p>If my comment made your confidence waver, go ahead and try the input box again. See if you can find a pattern that works. The answer is at the bottom of this section, but don’t skip ahead. Every sentence before that is setting up an important idea.</p>

<h3 id="bayes-theorem">Bayes Theorem</h3>

<p>If you’ve heard of Bayes theorem before, you know this formula:</p>

<p>\[ P(H \mid E) = \frac{P(E \mid H) * P(H)}{P(E)} \]</p>

<p>Indeed, that’s all there is to it. I bet you’ve also heard the famous formula: \(E = mc^2 \). That’s all there is to mass-energy equivalence. However, figuring out how to harness nuclear energy is still a hard problem. The formula made it possible, but implementing it still took 40 years.</p>

<p>It’s the same with Bayes Theorem. The formula is exciting because of what it implies. We’re discovering the nuclear energy version of Bayes Theorem.</p>

<p>Translated to English, the formula goes like this:</p>

<blockquote>
  <p>To form accurate beliefs, you always start from the information you already have. You update beliefs. You don’t discard everything you know.</p>
</blockquote>

<!-- This is Bayes Theorem. Start from a pre-existing belief, a prior, then use the new information you get to update that belief, and finally land at your new belief. -->

<!-- It's wrong to form your beliefs using just the new piece of information you see. -->

<p>The first key component is a hypothesis (H) - the belief we’re talking about.</p>

<p>The second key component is the evidence (E) - what data do we have to support / reject the hypothesis.</p>

<p>The third key component is probability (P) of the above two. This probability is our confidence in the belief.</p>

<p>If you’re familiar with probability theory, you learned this in school. If not, don’t worry, there are <a href="https://arbital.com/p/bayes_rule/?l=1zq" target="_blank" rel="noopener">excellent mathematical introductions</a> to explain it to you. We’ll skip the math, and focus on how to use it.</p>

<p>Our point of interest, and where bayes truly shines is where we compare two hypotheses. Instead of uncovering the absolute probabilities, which is hard, this focuses on how much more likely one hypothesis is, compared to another. Most reasoning in our mind takes this form.</p>

<!-- does it? - This is what makes contrast so valuable. -->

<p>In this case, the formula looks like:</p>

<p>\[ Posterior \hspace{2mm} Odds = Prior \hspace{2mm} Odds * Likelihood \hspace{2mm} Odds \]</p>

<p>Posterior odds measure how likely a hypothesis is compared to another one.</p>

<p>Prior odds measure how likely it was before we had any new evidence.</p>

<p>Likelihood odds measure how well the evidence explains the current hypothesis, compared to the other one. We’ll explore what this means with the help of examples.</p>

<p>\[ \text{Likelihood Odds} = \frac{ \text{Probability of evidence assuming hypothesis is true}}{\text{ Probability of evidence assuming competing hypothesis is true}}\]</p>

<p>We’ll start with the 2,4,6 game to show how qualitatively, math and intuition agree. Then we’ll get into a simpler example where we’re miscalibrated and do the math.</p>

<p>I’m going to choose my path through the 2,4,6 game, but I hope yours was similar enough. If not, try doing this on your own!</p>

<p>I have a hypothesis I want to test, \(H_{3even}\) = 3 even numbers in increasing order. It’s implicit here, but the hypothesis I’m testing this against is \(H_{not-3even}\), or that the formula <strong>is not</strong> 3 even numbers in increasing order.</p>

<p>I input (4,6,8) and the black box says “Yes”. My confidence in 3 even numbers rises. In Bayesian-speak, my posterior odds have increased, because the likelihood odds have increased. And the likelihood odds have increased, since the probability of (4,6,8) saying “Yes” is higher when the formula is \(H_{3even}\).</p>

<p>You’ll notice how <em>you feel</em> every new number that matches your hypothesis makes your belief stronger.</p>

<!-- This corresponds to a likelihood odds of greater than 1, since the belief you're testing is getting stronger. -->

<!--Too many ideas: A question to ponder here: Can (4,6,8) be acceptable in a world where \\(H_{not-3even}\\) is true? That is, the formula is not 3 even increasing numbers? This is seeking disconfirming evidence -->

<p>I try (1,2,3) next. “Yes”. What? I expected “No”!</p>

<p>Everything tumbles, like it should, when you find something that doesn’t follow the pattern. The probability of (1,2,3) saying “Yes” is higher with \(H_{not-3even}\), since (1,2,3) are not all even. The likelihood odds are in favour of \(H_{not-3even}\) now, which means we discard \(H_{3even}\). In this case, one small piece of evidence was enough to completely flip the scales.</p>

<p>Then, which new hypothesis should you try? The clues usually lie in how you disproved the previous hypothesis.</p>

<p>I tried (1,2,3) which said “Yes”, when I expected it to say “No”. My new hypothesis thus became “3 increasing numbers”.</p>

<p>Just like in the previous case, (4,2,6) saying “Yes” killed this hypothesis. My new hypothesis thus became “3 positive numbers”.</p>

<p>I tried (-1,2,3), which said “No”! This was all I needed to become reasonably confident in “3 positive numbers”. The more negative numbers I tried, the more confident I got.</p>

<p>3 positive numbers is indeed correct.<sup id="fnref:6"><a href="#fn:6">1</a></sup></p>

<p>Graphically, this is what’s happening with the 3 hypotheses:</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/bayes/bayes_246_confidence.jpg" alt="">
    
    
    
        <figcaption>   
            <p>confidences not calibrated</p>

        </figcaption>
    
</figure>

<div role="alert">
  <p><i></i><b>Blue Box on Can we prove something to be true with Bayes?</b><br>
No matter how much data you have, you can never say something is true. This is the problem of induction.</p>

  <blockquote>
    <p>“No amount of observations of white swans can allow the inference that all swans are white, but the observation of a single black swan is sufficient to refute that conclusion.”</p>
  </blockquote>

  <p>However, after a certain level of confidence, you live your life believing it’s true. Once you start believing is when you must pay close attention to evidence that doesn’t fit.</p>
</div>

<p>Calibration is key. What we’ve just shown is our thinking process, and how Bayes theorem is mostly aligned with it when we’re thinking well. Bayes theorem updates beliefs in the same direction our brains do, but what changes is how much each piece of evidence influences us!</p>

<p>With this next example, let’s get into the basic math. We’ll revisit the 2,4,6 game in a bit.</p>

<h3 id="being-late-example">Being Late Example</h3>

<p>Your colleague is sometimes late to work. They’ve been on time 4 times, and late 3 times the past week. How many more times would it take you to start believing they’re “always” late?</p>

<p>In my experience, just a few more times does the trick. But let’s use Bayes to calibrate.</p>

<p>Since there’s no good reason to expect tardiness over punctuality, let’s say the prior odds are 1:1.<sup id="fnref:13"><a href="#fn:13">2</a></sup> The alternative hypothesis, the one we’re testing against is “not always being late”. To make this more concrete, let’s say this means they’re late only 10% of the time.<sup id="fnref:2"><a href="#fn:2">3</a></sup></p>

<p>We’ll use the data we have to calculate the likelihood of being late. We want to contrast
<span>the data<span>being late thrice, and on time 4 times</span></span>
with us believing that they’re almost always on time, or almost always late. Remember, to figure this out, we imagine believing the first hypothesis, then judge how likely the data is. Then, we imagine believing the second hypothesis, and judge how likely the data is.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/bayes/bayes_likelihood_calc.jpg" alt="">
    
    
    
</figure>

<p>There are several ways to mathematically represent this data, from a binomial function to a beta distribution. However, we’re not getting into that yet. Today is more about an intuitive explanation, one which you’re more likely to use …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24058247</guid>
            <pubDate>Wed, 05 Aug 2020 07:45:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People watching a German farmer at work on Twitch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24058221">thread link</a>) | @vegasbrianc
<br/>
August 5, 2020 | https://www.twitch.tv/landwirt_in_mv | <a href="https://web.archive.org/web/*/https://www.twitch.tv/landwirt_in_mv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/landwirt_in_mv</link>
            <guid isPermaLink="false">hacker-news-small-sites-24058221</guid>
            <pubDate>Wed, 05 Aug 2020 07:39:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Should You Not Use Rails?]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24057715">thread link</a>) | @luu
<br/>
August 4, 2020 | http://codefol.io/posts/when-should-you-not-use-rails/ | <a href="https://web.archive.org/web/*/http://codefol.io/posts/when-should-you-not-use-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <!-- .post-header -->
            <div>
                  
<figure>
    <p><img src="http://codefol.io/img/chimp_keyboard_aside_216_135.png" alt="A chimpanzee in a white coat types at a keyboard lit by glowing LEDs." width="216" height="135" title="He's gorgeous, yes. But is his talent natural&amp;hellip; or is it Ruby on Rails?">
    </p>

      <figcaption>
        He's gorgeous, yes. But is his talent natural… or is it Ruby on Rails?
        
        
      </figcaption>
</figure>

                <p>I was <a href="https://www.codewithjason.com/rails-with-jason-podcast/noah-gibbs-3/">recently on Jason Swett’s podcast again</a>. He’s a great interviewer and I always have fun with him.</p>

<p>By Twitter request we talked about… When would you <strong><em>not</em></strong> use Rails? It’s a great question.</p>

<p>For the entertaining version, <a href="https://www.codewithjason.com/rails-with-jason-podcast/noah-gibbs-3/">listen to the podcast</a>. For the just-the-facts extra-complete version, I’m writing this post.</p>

<h2>When Is Rails the Wrong Choice?</h2>

<p>I’ll start with a few simple, obvious times you wouldn’t use Rails, and then I’ll talk about some technically interesting times.</p>

<p>First, and most important, is team familiarity. If your team doesn’t already know Rails and isn’t especially interested in learning it then Rails is the wrong choice. This should be obvious, but it still deserves first billing.</p>

<p>Second, when you know some other framework fits better. I’ll talk more below about when that is. But sometimes you have a specific concern that trumps everything else. If you need to use a Java-language machine learning library and you don’t want to use JRuby for some reason, Rails isn’t your framework. If you’re writing a WordPress plugin, you’ll be doing it in PHP. Often there’s one specific compatibility concern that overrides everything else.</p>

<p>You can also think of it as: use it where Rails’ good points hold and its bad points don’t. So we’ll also talk about the good and bad points.</p>

<p>Separately: you’d normally only use Rails as an HTTP server, so some tasks just aren’t Rails-shaped.</p>

<h2>When is Rails Too Much?</h2>

<figure>
    <a href="https://rubymadscience.com/img/assistant_pirate_with_sphere_bigthumb.png">
      <img src="https://rubymadscience.com/img/assistant_pirate_with_sphere_bigthumb.png" alt="A pirate puppet with an eyepatch, safety goggles and a huge scraggly mustache watches over a purple crystal ball at his feet.'" title="He's too much lab assistant for your lab.">
    </a>
        <figcaption>He’s too much lab assistant for your lab.</figcaption> 
</figure>

<p>Some places not to use Rails can include:</p>

<p><strong>Really Small Tasks that Won’t Grow</strong>: if a server does very little, Rails is often too much. Not going to touch a database? Then the DB setup isn’t helping you, is it? Just a tiny low-traffic intermediate server with no caching? A lot of Rails is more trouble than it’s worth.</p>

<p>Be careful with tasks that grow, though — making a tiny server scale up to do a lot more can be ugly. If you’re already serving HTTP pages to a human with a web browser, consider that you may have to add features to it later. Something like <strong><em>that</em></strong> is already fairly large from the word “go”.</p>

<p><strong>When It’s ‘Just’ an API Server</strong>: Rails has less to offer an API server that speaks JSON over the wire. A lot of its HTTP security doesn’t matter for that case (e.g. SQL injection safeguards, XSS prevention.) While ActiveRecord can be nice for some database use cases, Rails really shines when you’re building an HTML site that talks to browsers. Very small projects that mostly speak a structured format read by machines will often get less from Rails.</p>

<p>Related to that is when you’re doing in-browser rendering and Rails is ‘just’ serving JSON. It’s a weird kind of in-between case. A lot of Rails security and convenience functions no longer help you, but you’re still doing things where internal libraries (ActiveRecord, ActiveJob, ActionMailer) can be highly useful. But if you’re never rendering HTML on the server and you’re very sure you never will, Rails will probably help you less.</p>

<h2>When Is Rails Not Enough?</h2>

<p>Rails is also designed for a small team and a medium-sized codebase. A huge team (lots of programmers) or a huge codebase (lots of controllers, models and/or lines of code) will tend to drag down the standard Rails-app structure.</p>

<p>Ruby allows for a <strong><em>lot</em></strong> of <a href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">non-local effects</a>. Whether that’s monkeypatching, writing to a database or creating new types at runtime, Ruby isn’t designed for a team of 200 programmers where you don’t trust some of them. There are too many ways for them to cause you trouble. You can use <a href="https://sorbet.org/">good tooling</a> to scale Ruby to larger teams, but even that will <a href="https://sorbet.org/docs/troubleshooting#escape-hatches">tend to have exceptions and difficulties</a>. That’s not really Ruby’s sweet spot.</p>

<p>In most cases you can cut up a large project into smaller projects. If one Rails app is too big, you can often separate it into multiple apps, or a thinner app with more back-end services, or an app and a separate microservice, or… One way or another there is usually a way to separate out smaller pieces. Ruby strongly encourages that, as do I.</p>

<p>There are also not-quite-Rails structures that can scale better. Avdi Grimm’s (now retired) <a href="https://www.goodreads.com/book/show/13481927-objects-on-rails">Objects on Rails</a> was an attempt in that direction, as is <a href="https://medium.com/@vsavkin/hexagonal-architecture-for-rails-developers-8b1fee64a613">the Hexagonal architecture for Rails</a>, which in turn has a lot in common with the older and more general <a href="https://en.wikipedia.org/wiki/Multitier_architecture">N-tier architecture</a>.</p>

<p>But at some point you might want to consider a different framework. <a href="https://hanamirb.org/">Hanami</a> is an obvious choice, designed to be less quick and nimble than Rails for getting a tiny app off the ground, but more scalable if you want to use the same code with a lot more contributors.</p>

<p>I’d still start out in Rails, personally. If you’re building something quickly to see if anybody cares, I know of no framework that comes close to its productivity. Wait to rewrite (in a more rigid framework) until you’re successful and you can afford the drag on your development speed.</p>

<p>The other worry here can be performance. If you’re rewriting a project that is already as large as the current Basecamp… then you’re <a href="https://m.signalvnoise.com/only-15-of-the-basecamp-operations-budget-is-spent-on-ruby/">actually fine for performance</a>. Rails still scales <strong><em>great</em></strong> for them. But if you’re looking at something a hundred times larger (which by definition means B2C, not B2B) then you might have a situation where your server costs are substantially greater than your engineering payroll. In that case it can make sense to slow down your engineers to pay lower server costs. To check this, see what your EC2-or-equivalent costs are <strong><em>just for your application servers</em></strong>, which are what run Rails. And check your payroll <strong><em>just for web engineers</em></strong>, which is who writes in Rails. Normally the engineering payroll is much larger and you should stick with trading cheap machine time for expensive engineering time. But at some point the balance may tip and you should consider raising your engineering payroll to cut your server costs.</p>

<h2>When Does Rails Have the Wrong Assumptions?</h2>

<figure>
    <a href="https://rubymadscience.com/img/dr_bear_microscope_bigthumb.png">
      <img src="https://rubymadscience.com/img/dr_bear_microscope_bigthumb.png" alt="A pirate, a bear and a chimp sit at a wicker table. The bear looks into a very old-fashioned microscope as the other two look on." title="They're checking the microscope for real-world use cases where Rails might be wrong.">
    </a>
        <figcaption>They’re checking the microscope for real-world use cases where Rails might be wrong.</figcaption> 
</figure>

<p>Before checking if Rails’ assumptions are right for you, we should see what those assumptions actually are.</p>

<p>Before you take my word for it, I recommend taking <a href="https://rubyonrails.org/doctrine/">David Heinemeier Hansson’s word for it</a> in the form of The Rails Doctrine. It’s a great document and it covers a lot of ground.</p>

<p>Indeed, if you want to better understand why Rails isn’t amazing for large, low-trust teams, you should read <a href="https://rubyonrails.org/doctrine/#provide-sharp-knives">“Provide Sharp Knives”</a> in the Rails Doctrine several times. A lot of Rails’ tradeoffs are entirely by design.</p>

<p>Rails also has some simpler assumptions: it assumes you’re writing an interactive app with server-rendered HTML. It assumes that security is vital (Rails trades a lot for security) but that you don’t want to build your own custom security system in most cases. And it assumes that you either have a small, excellent team doing prototyping work (“Provide Sharp Knives”) or that you have a possibly-mediocre team that needs powerful built-in guidelines (<a href="https://rubyonrails.org/doctrine/#omakase">“The Menu is Omakase.”</a>)</p>

<p>Rails also assumes you want high developer velocity at a cost of technical debt. In other words, it’s designed for building very quickly. That makes sense when <strong><em>technical execution is not your biggest risk</em></strong>. For instance: if you’re building a small startup, and you’re pretty sure you can build the site but people may not buy your product, you are dominated by market risk. That’s when Rails is perfect. You want to build very quickly. And even if you build perfectly, you’re probably going to have to throw away the result for nontechnical reasons, like “people don’t want to buy it.”</p>

<p>As part of “high dev velocity, technical debt is okay” Rails assumes things like, “you’ll want to use a lot of gems” and “dependencies that work are fine if they speed you up.”</p>

<p>Rails assumes you don’t mind scaling out application servers horizontally (by bringing more of them online.) It’s designed to scale well <strong><em>if</em></strong> you can do that. Rails assumes CPU is fairly cheap and it’s usually right about that. Relatedly, Rails assumes that the database is usually your most serious performance bottleneck, which is how web applications usually work.</p>

<p>Rails also assumes you’ll have some calculation or data transformation in your application. It assumes that it’s okay to use some CPU because you’ll be doing that anyway.</p>

<p>(When does that last assumption matter? Let’s talk about Evented Servers and see.)</p>

<h2>What Isn’t Rails Good At?</h2>

<figure>
    <a href="http://codefol.io/posts/when-should-you-not-use-rails/node_js_logo.png">
      <img src="http://codefol.io/posts/when-should-you-not-use-rails/node_js_logo.png" alt="The Node.js logo." title="Sometimes you need it, or something like it.">
    </a>
        <figcaption>Sometimes you need it, or something like it.</figcaption> 
</figure>

<p>While Rails is great at a lot of things, there’s one particular task that it’s not amazing for: shim servers.</p>

<p>By “shim servers” I mean servers that do very little calculation but integrate answers from a few other back-end services and relay the result. Imagine a server that queries two JSON services and combines the result with simple string-manipulation, for instance. It does very little calculation, but it juggles a lot of events.</p>

<p>And that’s the relevant word: “events.”</p>

<p>There is a specific kind of app architecture embodied by Node.js and its relatives called “Evented” programming. It can support many thousands, or even millions, of simultaneous connections with a tiny amount of server resources. It can be both high-throughput and low-latency. Its benchmark numbers are matchless… for the cases where it works.</p>

<p>Rails can’t match Evented programming at what Evented programming is good at. Basically no framework can. There are Evented frameworks for Ruby (e.g. <a href="https://github.com/eventmachine/eventmachine">EventMachine</a>, <a href="https://github.com/socketry/async">Async</a>.) Rails is built differently.</p>

<p>If Evented is so much better, why don’t we use it for everything? Because it doesn’t work for everything. I emphasise calculation per-request because an Evented server will fall down and die if you try to make it do very much calculation per-request. Having one server handle a million connections is no good if each connection …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://codefol.io/posts/when-should-you-not-use-rails/">http://codefol.io/posts/when-should-you-not-use-rails/</a></em></p>]]>
            </description>
            <link>http://codefol.io/posts/when-should-you-not-use-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24057715</guid>
            <pubDate>Wed, 05 Aug 2020 06:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Face Recognition Using Mathworks on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24057595">thread link</a>) | @atomlib
<br/>
August 4, 2020 | https://www.hackster.io/monica/face-recognition-using-mathworks-on-raspberry-pi-40120c | <a href="https://web.archive.org/web/*/https://www.hackster.io/monica/face-recognition-using-mathworks-on-raspberry-pi-40120c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h3 id="toc-intro-0"><span>INTRO</span></h3><p>MATLAB is a powerful tool used by data scientists and artificial intelligence researchers, among others. Although there is a learning curve, it's worth diving in, because once you understand it well enough to get things done, you'll likely find it efficient and elegant. Their libraries and tools are hard to give up once you've had the chance to experience them. As a bonus, they offer support packages to generate and run code on a variety of platforms, including Raspberry Pi!</p><h3 id="toc-install-1"><span>INSTALL</span></h3><p>Starting out, you'll need a PC with Matlab installed. I'm using version 2020a and I'll be doing the setup via my Macbook Pro running Catalina.</p><h3 id="toc-install-the-matlab-raspberry-pi-support-package-2"><span>Install the MATLAB Raspberry Pi support package</span></h3><p>First, install the support package in MATLAB.</p><ul><li>Open Matlab and on the home tab, select 'Add-Ons" &gt; "Get Add-Ons."</li><li>Search for "MATLAB Raspberry Pi support package" and select "Install."</li><li>Accept the agreement.</li></ul><div data-hypernova-key="ImageCarousel" data-hypernova-id="85853a82-484d-4686-8950-4e2ea984e279"><div data-reactroot=""><div><p><span>1 / 4</span> • <span>Search for "MATLAB Raspberry Pi support package" and select "Install."</span></p></div></div></div>
<ul><li>On the final screen of setup, choose "Setup now." That will open the board setup wizard.</li></ul><p><span>Note: If you already closed it the installation wizard, you can find the image setup by selecting "Add-Ons" &gt; "Manage Add-Ons" and then selecting the gear button (</span><em>setup</em><span>) next to the Raspberry Pi support package.</span></p><div data-hypernova-key="ImageCarousel" data-hypernova-id="98915a76-671e-4385-91bc-551884c0c765"><div data-reactroot=""><div><p><span>1 / 2</span> • <span>select "Add-Ons" &gt; "Manage Add-Ons"</span></p></div></div></div>
<h3 id="toc-set-up-your-pi-to-work-with-matlab-3"><span>Set up your pi to work with MATLAB</span></h3><p>MATLAB interfaces with Raspberry Pi by way of a server running on the Raspberry Pi hardware. This is a custom server that interprets commands send by MATLAB.</p><p><span>The board setup wizard will guide you through downloading </span><a href="https://github.com/mathworks/Raspbian_OS_Setup/releases" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;MATLABs raspbian image&quot;,&quot;href&quot;:&quot;https://github.com/mathworks/Raspbian_OS_Setup/releases&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">MATLAB's raspbian image</a><span> that includes the server. Then it will walk you through configuring it to work with whichever networking option you choose.</span></p>
<ul><li>On the first screen, select your type of Raspberry Pi. Click "next."</li><li>Select "Setup hardware with MathWorks Raspian image."</li><li>Download the deep learning image.</li><li>Find your downloaded image and unzip it.</li><li>Validate the image by using the "validate" button.</li></ul><p><strong>Burn the image</strong></p><p>Matlab was not able to burn the image on Mac, so I ended up simply using BalenaEtcher to burn the image instead.</p><p>On the "Write Firmware" page, MATLAB checks the SD card to make sure it has been burned. I reinserted the SD card so that the burned image was visible to the program. That way I was able to select "Next" and skip to the next step.</p>
<h3 id="toc-set-up-the-connection-4"><span>Set up the connection</span></h3><p>There are four different connection options to connect your Pi to MatLab:</p><p><strong>1. Connect to LAN or home network</strong></p><p><strong>2. Connect to wireless network</strong></p><p><strong>3. Connect directly to host computer</strong></p><p><strong>4. Manually enter network settings</strong></p><ul><li><span>In Matlab, choose "</span><strong>Connect to wireless network."</strong><span> Fill in the SSID and password that both the board and PC are connected to (note - my Raspi 3 B+ is not able to connect to 2.4GHz wifi networks. Apparently it's a known issue)</span></li><li><span>Select "</span><strong>Automatically get IP address</strong><span>." Click "next."</span></li></ul><div data-hypernova-key="ImageCarousel" data-hypernova-id="e92e5cc6-3f36-46c5-bce7-0f69e09d39df"><div data-reactroot=""><div><p><span>1 / 4</span> • <span>Select "Automatically get IP address."</span></p></div></div></div>
<p>Normally, MatLab sets the network connection up on your board automatically, but since we had to skip the previous imaging step, we'll have to set up the WIFI on the Pi manually. To set up WIFI on the Pi, you may wish to connect a keyboard, mouse and HDMI monitor, although you can also do it via SSH.</p><ul><li>Remove the SD card from your computer and insert it in your Raspberry Pi.</li><li>Connect the Pi to a power supply of at least 5V 2A via the micro-USB.</li></ul>
<ul><li>Connect the camera to the board by inserting the MIPI-CSI cable with blue side facing the pi's ethernet connectors, and the other blue side facing away from the camera lens.</li><li><span>Click "</span><strong>next</strong><span>" in MATLAB to verify your connection.</span></li><li>You should see the screen that says "Test Hardware Connection successful". If not, double check that  your pi and PC running laptop are connected to the same network and try running "test connection" again.</li></ul><h3 id="toc-connect-your-pi-to-matlab-5"><span>Connect your Pi to MATLAB</span></h3><p>You can now connect your Raspberry Pi to Matlab using the Matlab console by simply typing:</p><pre><code><span>mypi = raspi</span></code></pre><p>That brings up the board's information, and you will also see it in Workspace. The board's info will contain a list of the available digital pins, leds, SPI channels, I2C buses and their speed.</p><p>Try turning the pi's yellow 'ACT' LED on and off by typing the following:</p><pre><code><span>writeLED(mypi,'led0',1)</span><br><span>writeLED(mypi,'led0',0)</span></code></pre><p><strong>Connect to the camera</strong></p><p>You can connect to the camera by typing:</p><pre><code><span>cam=cameraboard(mypi, 'Resolution', '1280x720')</span></code></pre><p>The resolution is optional, and can also be set to a different resolution. Default is 640x480. The available resolutions are listed in the output when you set up your camera.</p>
<p><span>You can find more info on working with the camera </span><a href="https://www.mathworks.com/help/supportpkg/raspberrypiio/examples/working-with-raspberry-pi-camera-board.html" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;here&quot;,&quot;href&quot;:&quot;https://www.mathworks.com/help/supportpkg/raspberrypiio/examples/working-with-raspberry-pi-camera-board.html&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">here</a><span>.</span></p><h3 id="toc-run-the-face-detection-program-6"><span>RUN THE FACE DETECTION PROGRAM</span></h3><p>First type</p><pre><code><span>clear</span></code></pre><p>to clear the connection to the board that we created previously, since the face detection code creates a new connection.</p><p>Make sure that your Pi camera is positioned so that it can see your face (or anyone's face).</p><p>Create a new script in Matlab, and copy and paste the included code into the script. Name it "facedetection.m." Make sure your current directory is the one with facedetection.m.</p>
<p>With facedetection.m open, select "run" on the editor tab (or type "facedetection" in the console). Once again, you will see a cascade of pixel values, and the "Figure 1" window will open and begin detecting faces. It will run until you select "pause" and then "end debugging" to quit.</p>
<p><span>As you can see, there are only a few lines of code needed to run face detection. The code is running the </span><a href="https://www.mathworks.com/help/vision/ref/vision.cascadeobjectdetector-system-object.html" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;cascade object detector&quot;,&quot;href&quot;:&quot;https://www.mathworks.com/help/vision/ref/vision.cascadeobjectdetector-system-object.html&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">cascade object detector</a><span>, which uses the </span><a href="https://www.mathworks.com/help/vision/ref/vision.cascadeobjectdetector-system-object.html" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Viola-Jones algorithm&quot;,&quot;href&quot;:&quot;https://www.mathworks.com/help/vision/ref/vision.cascadeobjectdetector-system-object.html&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Viola-Jones algorithm</a><span> to detect people’s faces, noses, eyes, mouth, or upper body.</span></p><p><code>fD = vision.CascadeObjectDetector</code><span> creates a detector to detect objects using the Viola-Jones algorithm.</span></p><p><span>I found the Matlab face detector to be both fast and accurate on Raspberry Pi 3 B+. It's also possible to </span><a href="https://www.mathworks.com/help/vision/ug/train-a-cascade-object-detector.html" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;train the Cascade Object Detector&quot;,&quot;href&quot;:&quot;https://www.mathworks.com/help/vision/ug/train-a-cascade-object-detector.html&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">train the Cascade Object Detector</a><span> to recognize other objects, like stop signs or cars.</span></p></div></div>]]>
            </description>
            <link>https://www.hackster.io/monica/face-recognition-using-mathworks-on-raspberry-pi-40120c</link>
            <guid isPermaLink="false">hacker-news-small-sites-24057595</guid>
            <pubDate>Wed, 05 Aug 2020 05:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fundamental Axiom of Floating Point Arithmetic]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24057293">thread link</a>) | @johnbcoughlin
<br/>
August 4, 2020 | http://www.johnbcoughlin.com/posts/floating-point-axiom/ | <a href="https://web.archive.org/web/*/http://www.johnbcoughlin.com/posts/floating-point-axiom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            

<p>If you’ve been a software engineer for long enough, it is very likely that you’ve seen this example of floating point perfidy:</p>
<div><pre><code data-lang="python">&gt;&gt;&gt; <span>3.0</span> / <span>10</span>
<span>0.3</span>
&gt;&gt;&gt; <span>0.1</span> * <span>3</span>
<span>0.30000000000000004</span>
</code></pre></div><p>We understand that this is due to the fact that floating point numbers, stored
with only 64 bits of precision, cannot represent the entire real number line.
Moreover, when we perform operations with these floating point numbers, the
errors inherent in their representation can accumulate and multiply. The moral
of the story is, never use a floating point number to represent money.</p>
<p>At least, that is the moral for financial applications. At Square, we used a
<code>long amount_cents</code>, and we got along with our lives. However, for most
applications that have a good reason to use floating point, this can’t be the
end of the story. If floating point were the unpredictable, unreliable thing
that I once believed it to be, we wouldn’t be able to numerically solve
differential equations, or linear systems, or land on the moon. Rather, there is
a science of floating point error, forming part of a science of numerical errors
in general, which seeks to tame and understand what happens to errors as they
flow through our calculations. In general, numerical error is something that can
be rather precisely quantified, as we’ll see. Along the way we’ll look at the
Fundamental Axiom of Floating Point Arithmetic, which, at the very least, sounds
way cooler than “10 things every developer should know about floating point
numbers”.</p>
<h2 id="machine-epsilon">Machine Epsilon</h2>
<p>Fundamentally, error in floating point is due to the problem of “roundoff”. Just as in base 10, we cannot represent the
number \(1/3\) without rounding it off somewhere:</p>
<p>\begin{equation*}
\frac{1}{3} = 0.33333333333333 \dots \approx 0.33333333,
\end{equation*}</p>
<p>in base 2, we cannot represent many numbers without rounding. Of course, some numbers we <em>can</em> represent exactly. The
number 1, for example. Or any integer in the range \((-2^{53}, 2^{53})\). Also notably, many fractions can be exactly
represented:</p>
<p>\begin{align*}
\frac{1}{2} &amp;= 0.1_2 \\\<br>
\frac{3}{4} &amp;= 0.11_2 \\\<br>
\frac{17}{8} &amp;= 10.001_2 \\\<br>
&amp;\vdots
\end{align*}</p>
<p>However, a number like \(1/10\), just like \(1/3\) in base 10, must be truncated to fit in the 24 or 53 bits of the
<a href="https://en.wikipedia.org/wiki/Significand">mantissa</a>. When we enter <code>0.1</code> in a console or in source code, the value that is <em>actually stored</em> is very slightly
different than <code>0.1</code>. According to this excellent <a href="https://www.exploringbinary.com/floating-point-converter/">IEEE-754 Floating Point Converter</a>, the floating point number that is
actually stored (for 64-bit floating point) is</p>
<p>\begin{align*}
&amp;(0.0001100110011001100110011001100110011001100110011001101)_2 = \\\<br>
&amp;(0.1000000000000000055511151231257827021181583404541015625)_{10}
\end{align*}</p>
<p>So the initial input to our calculation was flawed! We weren’t calculating <code>0.1 * 3</code>, we were actually calculating</p>
<div><pre><code data-lang="python"><span>0.1000000000000000055511151231257827021181583404541015625</span> * <span>3</span>
</code></pre></div><p>How much of an error is this? We can get an idea by counting the zeros in between the significant
digits, \(0.100\dots 00055\). In this case, there are 16. So in simply entering a number which is not representable
exactly in floating point, we have incurred a relative error of roughly \(10^{-16}\).</p>
<p>Indeed, in <em>all</em> cases we can expect to incur a relative error of
roughly \(10^{-16}\). This magnitude is called machine epsilon, often
written \(\epsilon_{\text{machine}}\). It comes from the relative difference
between two successive floating point numbers. For every representable floating
point number \(x\), there is a <em>next</em> floating point number, and it is
approximately \(x + \epsilon_{\text{machine}} x\). So for an arbitrary real
number \(x_0\), it falls between two floating point values \(x\)
and \(x + \epsilon x\) (leaving off the subscript of \(\epsilon\) for conciseness). When we
represent \(x_0\) in floating point, we will get one of these two values. Let’s denote
the floating point representation of \(x_0\) by \(\text{fl}(x_0)\). The absolute
error incurred just by representing \(x_0\) in floating point is</p>
<p>\begin{equation*}
e_{\text{abs}} = |\text{fl}(x_0) - x_0| \leq \max(|x_0 - x|, |x_0 - (x + \epsilon x)|) \leq |\epsilon x|.
\end{equation*}</p>
<p>The relative error, then, i.e. the absolute error divided by the true value, is</p>
<p>\begin{equation*}
e_{\text{rel}} = \frac{e_{\text{abs}}}{x_0} \leq \frac{|\epsilon x|}{x_0} \approx \epsilon.
\end{equation*}</p>
<p>Cool! So we’ve seen that the worst we can do, in relative terms, when representing a floating point number, is
approximately \(10^{-16}\). This is, for almost all practical purposes, <em>very good</em>. Because remember, we’re speaking of
a relative error. That means we’re able to represent even very small values, very accurately. Here’s the nearest floating point
number to \(10^{-20}\):</p>
<p>\begin{equation*}
0.000000000000000000009999999999999999451532\dots
\end{equation*}</p>
<p>If you’re curious, I invite you to count the 9’s. There are 16 of them. Even when dealing with extremely small numbers,
we maintain the same relative precision.</p>
<h2 id="the-fundamental-axiom-of-floating-point-arithmetic">The Fundamental Axiom of Floating Point Arithmetic</h2>
<p>Now you might be thinking, wait! It’s all good and well that we can get excellent relative accuracy when <em>representing</em>
floating point numbers, but what about when we go to <em>do</em> something with them? Here we’ve got two floating point
numbers, both of which are inexact, and we’re about to multiply them! Who knows what might happen?</p>
<p>This concern is well-founded, because the algorithms of floating point arithmetic must be implemented with finite
precision. If we are asked to multiply two large numbers with pen and paper, the algorithm that most
of us will use is the one we learned in school, which involves lots of addition, carrying, sub-multiplications, and so
on. If all of those intermediate steps are using some kind of binary representation, then the intermediate products may
be losing precision as we go along! This seems like a recipe for disaster. Fortunately, there is a property that we can
require of a floating point implementation, one which is satisfied by IEEE-754 and most other popular floating point
standards, that will save us from total anarchy. This is what Trefethen and Bau, <em>Numerical Linear Algebra</em>, refer to
as the <strong>Fundamental Axiom of Floating Point Arithmetic</strong>:</p>
<blockquote>
<p>All floating point arithmetic operations are exact up to a relative error of \(\epsilon_{\text{machine}}\).</p>
</blockquote>
<p>This means that for any two floating point numbers, say \(x\) and \(y\), any operation involving them will give a floating
point result which is within a factor of \(1 + \epsilon_{\text{machine}}\) of the true result. This is easiest to
understand if we use a special notation to represent the floating point version of, say, \(+\). Let’s write \(\oplus\) to
denote floating point addition, and \(+\) to denote exact addition. Then the Fundamental Axiom tells us,</p>
<p>\begin{equation*}
\frac{|(x \bigoplus y) - (x + y)|}{x + y} \leq \epsilon_{\text{machine}}.
\end{equation*}</p>
<p>Remember, \(x\) and \(y\) are exactly representable as floating point numbers, but of course they are also, mathematically,
just real numbers. So \(x + y\) is a real number (point on the number line), which <em>may not be exactly representable in
floating point</em>. The Fundamental Axiom is telling us that the floating point operation \(\oplus\) can do no worse than
simply trying to represent the number \(x + y\) as a floating point value directly, assuming our computer had access to the
mathematical, infinite precision object \(x + y\).</p>
<p>Put another way, we incur no extra error by going through floating point
arithmetic than we would by using a magical computer to do exact arithmetic on
our floating point values and then casting back to floating point. In
mathematical terms,</p>
<p>\begin{equation*}
\frac{\left|(\text{fl}(a) \oplus \text{fl}(b)) - (a + b)\right|}{a + b} \approx \frac{\left|\text{fl}(\text{fl}(a) + \text{fl}(b)) - (a + b)\right|}{a + b} \approx \epsilon_{\text{machine}}.
\end{equation*}</p>
<p>Recall that \(\text{fl}(a)\) is the mathematical number we actually represent when
we try to represent \(a\) in floating point. So the first fraction gives the
relative error from performing \(\oplus\) on the floating point representations
of \(a\) and \(b\), and the second fraction gives the relative error from performing
the exact arithmetic operation, \(+\), on the floating point representations
of \(a\) and \(b\), then casting the result to floating point.</p>
<h2 id="error-analysis">Error Analysis</h2>
<p>The Fundamental Axiom of Floating Point Arithmetic allows us to analyze the numerical error that may be incurred by even
complex arithmetic operations. To see an idea of how this works, let’s consider the problem of computing the length of a
2D vector, \([x, y]\). Mathematically, this has the form</p>
<p>\begin{equation*}
d = \sqrt{x^2 + y^2}.
\end{equation*}</p>
<p>There are several stages to the computation, and at each one we will incur a little bit of numerical error:</p>
<ul>
<li>Enter the numbers \(x\) and \(y\) into the computer, incurring roundoff error.</li>
<li>Compute \(x^2\) and \(y^2\), using floating point multiplication.</li>
<li>Compute \(x^2 + y^2\), using floating point addition.</li>
<li>Compute \(\sqrt{x^2 + y^2}\), using the floating point square root operation.</li>
</ul>
<p>At each step, the result we get will be equal to the true result, times some error factor \((1 + \epsilon)\), where
each \(\epsilon\) is very small, on the order of \(\epsilon_\text{machine}\). Each operation may have a different
error \(\epsilon\), but we’ll use the same symbol for all of them. We don’t care so much about the exact value
of \(\epsilon\), only that it is very small.</p>
<p>We’re going to carry these \(\epsilon\) through the computation to see how they
affect the final result. To make that easier, we can use special rules of arithmetic to manipulate \(\epsilon\):</p>
<ul>
<li>\(\epsilon^2 = 0\). If \(\epsilon \approx 10^{-16}\), then \(\epsilon^2 \approx 10^{-32}\), which is so small that we just
decide to completely ignore it.</li>
<li>\((1 + \epsilon)^2 = 1 + 2\epsilon + \epsilon^2 = 1 + 2\epsilon\).</li>
<li>\(\sqrt{1 + \epsilon} = 1 + \frac{\epsilon}{2} - …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.johnbcoughlin.com/posts/floating-point-axiom/">http://www.johnbcoughlin.com/posts/floating-point-axiom/</a></em></p>]]>
            </description>
            <link>http://www.johnbcoughlin.com/posts/floating-point-axiom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24057293</guid>
            <pubDate>Wed, 05 Aug 2020 04:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurers are putting the lives of sick and disabled at risk during COVID-19]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24056932">thread link</a>) | @Abishek_Muthian
<br/>
August 4, 2020 | https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is about Insurance companies in India, their behaviour with customers with preexisting illness. Incase you are not from India, you might still find this content useful as almost all of these companies are in tie-up with a major international insurer whom you might have your policy with.</p><p>I’m suffering from what could be best summarised in simple terms as <strong><em>Bone related diseases</em></strong>, I had a <a href="https://abishekmuthian.com/i-was-told-i-would-become-quadriplegic-68c0371e6f05/" target="_blank">major surgery in July 2018</a> for ailments which has since been successfully addressed. I’ve been very open about my health condition to raise awareness and to support others facing such ailments.</p><p>Like many others during this COVID-19 pandemic, I applied for a health insurance top-up plan as my current base plan(subscribed ~5 years ago, much before 2018 surgery) doesn’t have the necessary coverage to compensate for the amount of money private hospitals are charging for COVID-19 treatment.</p><p><amp-accordion id="MAX-healthcare-accordian" disable-session-states=""><section><h5>How much a private hospital in India charges for COVID-19 treatment?(Click to see the .jpg)</h5><amp-img alt="How much money a private hospital in India charges for COVID-19 treatment?" src="/images/covid-19-treatment-charges.jpg" width="720" height="1034" layout="responsive"></amp-img></section><section><h5>After the above picture went viral on social networks and received widespread criticism, the hospital released the following tweet.(Click to see the .jpg)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1271412049042534400"></amp-twitter></section></amp-accordion></p><p>Since I’m an independent professional, I’m not covered under any corporate health insurance and so I had to apply for a personal health insurance policy.</p><p>I approached the <a href="https://www.livemint.com/insurance/news/choose-from-india-s-best-health-policies-1569141812779.html" target="_blank">top health insurance providers in the country</a> <a href="http://archive.is/DbkXk" target="_blank">[archive]</a>, as I believed they would be following government’s guidelines regarding preexisting diseases for health insurance. I was proven wrong.</p><h3 id="irdai-guidelines-on-preexisting-diseases">IRDAI Guidelines on preexisting diseases</h3><p>Insurance Regulatory and Development Authority(IRDAI) is Indian government’s regulatory body for insurance and re-insurance industries in India.</p><p>IRDAI had released several advisories regarding how the health insurance companies should treat customers with preexisting illness.</p><ul><li>Preexisting diseases (PED) means any condition <strong><em>“that is/are diagnosed by a physician within 48 months prior to the effective date of the policy issued by the insurer or its reinstatement, or for which medical advice or treatment was recommended by, or received from, a physician within 48 months prior to the effective date of the policy issued by the insurer or its reinstatement.”</em></strong> - <a href="https://www.irdai.gov.in/ADMINCMS/cms/whatsNew_Layout.aspx?page=PageNo4048&amp;flag=1" target="_blank">Amendments_guidelines_excl_std20200210.pdf</a> <a href="http://archive.is/fl97m" target="_blank">[archive]</a>.</li></ul><p>So what happens when you have preexisting disease while applying for a health insurance?</p><ul><li>The PED are excluded during the waiting period(maximum of 4 years). Some PEDs can be permanently excluded from the coverage of the policy - <a href="https://www.irdai.gov.in/ADMINCMS/cms/whatsNew_Layout.aspx?page=PageNo3916&amp;flag=1" target="_blank">Guidelines on standardization of exclusions in HI Contracts.pdf</a> <a href="http://archive.vn/fkoEg" target="_blank">[archive]</a>.</li></ul><p><em>Note: Even permanent exclusion means those diseases are excluded from the coverage of the insurance policy and doesn’t mean you should be denied the policy itself.</em></p><h3 id="insurance-providers-are-not-following-irdai-guidelines">Insurance providers are not following IRDAI guidelines</h3><p>In spite of advertising waiting period for PEDs on their websites, I found out that these insurers are blatantly disregarding the IRDAI guidelines w.r.t PEDs even when they advertise ‘<em>waiting period</em>’ on their websites.</p><p>The following insurers denied me the insurance policy citing my preexisting illness, even after I pointed out the IRDAI guidelines and raised a complaint with IRDAI’s grievances cell.</p><p>Some went took extraordinary measures to deny me the policy, even after conducting a thorough medical test in which their own doctor certified me as healthy for the policy. Some, didn’t even bother to conduct an underwriter call and denied me the policy from my stated PEDs in the application after receiving the premium payment.</p><p>It is to be noted that, to the best of my knowledge the diseases I suffer from isn’t even permanently excluded according to IRDAI’s guidelines and even if it was the insurers are supposed to exclude it from coverage and provide me with the insurance policy.</p><h3 id="insurer-behaviour-towards-preexisting-diseases">Insurer behaviour towards preexisting diseases</h3><h4 id="royal-sundaram-general-insurance">Royal Sundaram General Insurance</h4><hr><p>After I applied for a health insurance quote on their website, Royal Sundaram’s agent called me over phone. I told him about my health condition several times, I was told that I would be given a policy with waiting period and utmost I would be required to take a medical test to show my current health condition.</p><p>The agent ensured that I applied for the policy by calling me repeatedly until one day I finally applied for the policy through their website.</p><p><amp-accordion id="Royal_Sundaram_Application-accordian" disable-session-states=""><section><h5>I did my best to state the preexisting disease in their limited text input section (Click to see the .gif)</h5><amp-img alt="Royal Sundaram health insurance preexisting disease" src="/images/RoyalSundaram_Health_Insurance_Preexisting_Disease-1.gif" width="1047" height="961" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The diseases I mention in the preexisting diseases column are what mentioned in my discharge summary of my 2018 surgery.</em></p><p><amp-accordion id="Royal_Sundaram_Application-accordian" disable-session-states=""><section><h5>Selected the relevant options related to my health condition(Click to see the .gif)</h5><amp-img alt="Royal Sundaram health insurance preexisting disease" src="/images/RoyalSundaram_Health_Insurance_Preexisting_Disease-2.gif" width="1047" height="961" layout="responsive"></amp-img></section></amp-accordion></p><p>After couple of days I received a call from the underwriter doctor from Royal Sundaram, I explained clearly my sickness and answered specific Yes/No questions in the call. After the call, I remembered that I’m taking treatment for Osteoporosis (Yearly single zoledronic acid inject and monthly Vitamin D tablets); So, I called the doctor again and informed him about my <em>osteoporosis</em> treatment.</p><p>A day later I was told by another representative of Royal Sundaram that I have to undergo medical tests, which I promptly agreed. My only concern was that I have to travel, visit a hospital when there was increasing number of COVID-19 cases in my city.</p><p>During the medical tests initiated by Royal Sundaram, I underwent -</p><ul><li>Blood Test</li><li>Urine Test</li><li>Thread Mill Test</li><li>Examination by Doctor</li></ul><p>During the examination by the doctor, I clearly explained my health history, I was asked to email the discharge summary of my surgery which I promptly did.</p><p>Few days later I received a mail from Royal Sundaram’s medical team to submit my discharge summary, follow-up medical checkups regarding my surgery.</p><p><amp-accordion id="Royal_Sundaram_follow-up-details-accordian" disable-session-states=""><section><h5>Letter asking for further documents regarding my 2018 surgery(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram Letter asking for futher documents regarding my 2018 surgery" src="/images/PC08491910_Add info pending_20200703013125.jpg" width="1240" height="1754" layout="responsive"></amp-img></section></amp-accordion></p><p>I promptly mailed them my discharge summary along with the latest follow-up report in which the <strong><em>doctor has mentioned that my implant status as good</em></strong>.</p><p><em>Note: I had also sent my discharge summary to the doctor who examined me at the hospital where the medical tests were conducted.</em></p><p><amp-accordion id="Royal_Sundaram_follow-up-report-accordian" disable-session-states=""><section><h5>Latest follow-up report regarding my surgery(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram Letter asking for futher documents regarding my 2018 surgery" src="/images/Follow-up-report-Abishek_Muthian -surgery.jpg" width="1799" height="2730" layout="responsive"></amp-img></section></amp-accordion></p><p>After couple of days, I was greeted with this letter in email from Royal Sundaram - (Markings in RED are mine)</p><p>I requested them several times to follow the IRDAI guidelines in providing me a waiting period regarding preexisting disease and to remove the diseases I don’t suffer from. They maintained that they have the right to reject my application and <strong>didn’t use the term <em>‘waiting period’</em> in any of their communication to me after rejection of my insurance proposal.</strong></p><p>I had no choice but to raise a complaint with IRDAI on Royal Sundaram through their <a href="https://www.irdai.gov.in/ADMINCMS/cms/NormalData_Layout.aspx?page=PageNo225&amp;mid=14.2" target="_blank">grievances cell</a>.</p><p>Through that complaint I requested Royal Sundaram for the following -</p><ul><li>To provide me a policy with waiting period(if necessary) in accordance with IRDAI’s guidelines.</li><li>Fix the misrepresentation of my diseases.</li><li>Provide me with the medical report of the tests conducted by Royal Sundaram.</li></ul><p>After escalation, numerous calls to the IRDAI’s grievances cell, I was provided with the medical tests report from Royal Sundaram.(Markings in RED are mine)
<amp-img alt="Royal Sundaram medical test report - doctor statement" src="/images/PC08491910-doctor-report-2.jpg" width="1127" height="1686" layout="responsive"></amp-img></p><p><em>Note: I noticed the wrong height mentioned in the medical test report only at the time writing this. So I didn’t raise this in my conversations with Royal Sundaram team.</em></p><p><amp-accordion id="Royal_Sundaram_blood-urine-tmt-report-accordian" disable-session-states=""><section><h5>Their Blood test report shows I'm healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-blood-test-report.jpg" width="1275" height="2100" layout="responsive"></amp-img></section><section><h5>Their Urine test report shows I'm healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-urine-test-report.jpg" width="1275" height="2100" layout="responsive"></amp-img></section><section><h5>Their Thread Mill test report shows I'm(my heart is) healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-TMT-test-report.jpg" width="2100" height="1275" layout="responsive"></amp-img></section></amp-accordion></p><p>Royal Sundaram never specifically answered why they denied me the policy even after their own doctor certified me to be healthy, But they sent me a revised rejection letter correcting one of the wrong diseases.</p><p>Open questions regarding the revised rejection letter -</p><ul><li>Why are the same diseases duplicated with different terms, Is this intentional misrepresentation to increase the number of Reason/s?</li><li>There is no cure for Achondroplasia, it is not a life threatening disease and it is not even part of permanent exclusion of coverage according to IRDAI’s guidelines on exclusions.</li></ul><p>In spite of repeatedly asking these questions through IRDAI’s grievances cell, Royal Sundaram’s grievances team sent me the same reply referring me to the revised rejection letter.</p><p>IRDAI grievances cell has told me that, there’s nothing else they can do about this, they asked me to take Royal Sundaram Insurance to the court mentioning this complaint token number, in spite of repeatedly agreeing to me over the calls that the Insurer is obliged to provide me a with an insurance policy with appropriate waiting period.</p><p><amp-accordion id="Royal_Sundaram_irdai-complaint-history-accordian" disable-session-states=""><section><h5>IRDAI complaint history on Royal Sundaram(Click to see the .png)</h5><amp-img alt="IRDAI complaint history on Royal Sundaram" src="/images/Royal-Sundaram-IRDAI-Complaint-History.png" width="1031" height="748" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="icici-lombard-general-insurance">ICICI Lombard General Insurance</h4><hr><p>The events with ICICI Lombard cannot be told without the huge payment related hassle I had with it.</p><p>But first, lets see what it says about preexisting illness on its website -</p><p>Of course it claims to cover preexisting illness after the waiting period of 2 years, not only that it has loads of articles on preexisting illness like this with the header <em>‘Avail Health Insurance even with Pre-Existing Condition’</em>.</p><p>I applied for the <em>health booster</em> top-up insurance policy on the ICICI Lombard website after declaring my preexisting illness and made my payment through their ‘Guest’ login option.</p><p><strong><em>No policy proposal number was generated after the payment.</em></strong></p><p><amp-accordion id="ICICI-Lombard-health-insurance-application-accordian" disable-session-states=""><section><h5>Declaring preexisting illness in the application at ICICI Lombard website(Click to see the .gif)</h5><amp-img alt="Declaring preexisting illness in the application at ICICI Lombard website" src="/images/ICICI-Lombard-preexisting-illness-application-website.gif" width="1419" height="971" layout="responsive"></amp-img></section><section><h5>Making payment at ICICI Lombard website as Guest(Click to see the .png)</h5><amp-img alt="Making payment at ICICI Lombard website as Guest" src="/images/ICICI-Lombard-payment-website.png" width="1289" height="572" layout="responsive"></amp-img></section><section><h5>ICICI Lombard health insurance no proposal number generated(Click to see the .png)</h5><amp-img alt="ICICI Lombard health insurance no proposal number generated" src="/images/ICICI-Lombard-No-Proposal-No.png" width="1419" height="971" layout="responsive"></amp-img></section></amp-accordion></p><p>I wrote to the customer support of ICICI Lombard attaching the email I received from them after payment, asking why no proposal number was generated for my policy.</p><p>After several calls and emails they told me that they were unable to find my payment and asked me to send the bank transaction details, which I did.</p><p>After couple of days, <strong>they wanted my complete bank statement</strong>!</p><p>I asked them, why they needed my complete bank statement in spite …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/">https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/</a></em></p>]]>
            </description>
            <link>https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24056932</guid>
            <pubDate>Wed, 05 Aug 2020 03:14:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional Programming with Bananas, Lenses, Envelopes and Barbed Wire]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24056901">thread link</a>) | @behnamoh
<br/>
August 4, 2020 | https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w | <a href="https://web.archive.org/web/*/https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-content" role="main">
        
    <div>
        <section data-stickyheader="">
            
        


<div>
    <div>
        <div>
            
            <p>Erik Meijer, J. Hughes (Editor), M.M. Fokkinga, Ross Paterson</p>
            
            <p><span>Research output<span>: </span></span><span>Contribution to conference<span> › </span></span><span>Paper</span></p>
        </div>

        











    <div>
        
            <div>
                
                    <div>
                        
                            <p><span>306</span>
                                
                                <span>Citations
(Scopus)</span>
                            </p>
                        
                        
                            <p><span aria-label="Total downloads for this work">4183</span>
                                <span>Downloads
(Pure)</span>
                            </p>
                        
                    </div>
                
                
                    
                
            </div>
        
    </div>


    </div>

</div>


    
        </section>

        <div id="main-content">
            
        <section>
            <div>
                <div>
                    <div>
                        
                            <h3>Abstract</h3>
                        <div><p>We develop a calculus for lazy functional programming based on recursion operators associated with data type definitions. For these operators we derive various algebraic laws that are useful in deriving and manipulating programs. We shall show that all example functions in Bird and Wadler's "Introduction to Functional Programming" can be expressed using these operators.</p></div>
                        
                        


                        

                    </div>

                    
                </div>
            </div>
        </section>
        

        
        <section>
            <div>
                <div>
    <h2>Cite this</h2>
    <ul role="tablist" aria-label="Cite this">
        
            <li role="tab" id="tab-0" aria-controls="#cite-apa" tabindex="0" aria-selected="true">
            <span>APA</span>
            </li>
        
            <li role="tab" id="tab-1" aria-controls="#cite-author" tabindex="-1" aria-selected="false">
            <span>Author</span>
            </li>
        
            <li role="tab" id="tab-2" aria-controls="#cite-BIBTEX" tabindex="-1" aria-selected="false">
            <span>BIBTEX</span>
            </li>
        
            <li role="tab" id="tab-3" aria-controls="#cite-harvard" tabindex="-1" aria-selected="false">
            <span>Harvard</span>
            </li>
        
            <li role="tab" id="tab-4" aria-controls="#cite-standard" tabindex="-1" aria-selected="false">
            <span>Standard</span>
            </li>
        
            <li role="tab" id="tab-5" aria-controls="#cite-RIS" tabindex="-1" aria-selected="false">
            <span>RIS</span>
            </li>
        
            <li role="tab" id="tab-6" aria-controls="#cite-vancouver" tabindex="-1" aria-selected="false">
            <span>Vancouver</span>
            </li>
        
    </ul>
    
</div>

            </div>
        </section>
        
        
        



    
    
    
    
    
    

    
        
        
        
    
    




    
        </div>
    </div>

    
    
    </div></div>]]>
            </description>
            <link>https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24056901</guid>
            <pubDate>Wed, 05 Aug 2020 03:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vulnerability in the Ledger hardware wallets that can lead to theft of funds]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24056227">thread link</a>) | @gukov
<br/>
August 4, 2020 | https://monokh.com/posts/ledger-app-isolation-bypass | <a href="https://web.archive.org/web/*/https://monokh.com/posts/ledger-app-isolation-bypass">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div id="post">
                
                <p><span>04 August 2020</span></p><p><img src="https://monokh.com/img/ledger.jpg" width="400" alt="ledger device"></p>
<p>This post will disclose a vulnerability in the Ledger hardware wallets that can lead to theft of user funds.</p>
<p>An attacker can exploit this method to transfer Bitcoin while the user is under the impression that a transaction of
    another, less valuable altcoin (e.g. Litecoin, Testnet Bitcoins, Bitcoin Cash, etc.) is being executed</p>
<p>If you use bitcoin forks on your device, you could be affected. You should avoid using these ledger apps until fixes are available.</p>
<p>The issue has been disclosed to Ledger but remains unaddressed. See <a href="#disclosure-timeline">Disclosure Timeline</a>.</p>
<h2 id="summary">Summary</h2>
<p>The ledger device exposes bitcoin (mainnet) public key and signing functionality outside of the "Bitcoin"
    app. It presents misleading transaction confirmation requests indicating the selected app's addresses and amounts
    when in fact different transactions are being signed.</p>
<h2 id="background">Background</h2>
<p>To support an asset on Ledger devices, you must install the corresponding app. Ledger devices support multiple
    apps and typically users will use it to store a variety of cryptocurrencies.</p>
<p>Ledger apps are intended to be isolated. Such that only one app is unlocked on the device at once. Unlocking the
    asset allows external communication to prompt for various functions for example:</p>
<ol>
    <li>Exporting public keys</li>
    <li>Signing messages</li>
    <li>Confirming transactions</li>
</ol>
<p>Thus, from a security perspective, the expectation is that <strong>locked apps are untouchable by external messages.</strong></p>
<h2 id="the-issue">The issue</h2>
<p>It was discovered that for Bitcoin and Bitcoin forks, the device exposes it's functions for any of the assets. In
    other words, having unlocked the Litecoin app, you will receive a confirmation request for a Bitcoin transfer while
    the interface presents it as a transfer of Litecoins to a Litecoin address. Accepting the confirmation produces a
    <strong>fully valid signed Bitcoin (mainnet) transaction</strong>.</p>
<h2 id="steps-to-reproduce">Steps to reproduce:</h2>
<ol>
    <li>
        <p>Open the Litecoin app</p>
    </li>
    <li>
        <p>Retrieve mainnet bitcoin (segwit) addresses using <code>getWalletPublicKey('84'/0'/0'/').publicKey</code></p>
    </li>
    <li>
        <p>Query UTXOs and construct a bitcoin transaction to spend outputs</p>
    </li>
    <li>
        <p>Send <code>createPaymentTransactionNew(...)</code> to prompt device for signing this transaction</p>
    </li>
    <li>
        <p>Receive <strong>Bitcoin Mainnet</strong> valid signed transaction</p>
    </li>
</ol>
<p>Expectation: Ledger device should throw an error at step 2 and step 4 and prevent execution</p>
<p>Actual: Ledger prompts user for a litecoin transaction and produces a valid signed transaction spending the Bitcoin
    utxos</p>
<pre><code> +----------------------------------+
++              Amount              ++
++  ☓       LTC 5.25512356       ✓  ++
 +----------------------------------+

 +----------------------------------+
++              Address             ++
++  ☓         ltc1q3fjf...       ✓  ++
 +----------------------------------+
</code></pre>
<h2 id="proof-of-concept">Proof of Concept</h2>
<p><a href="https://github.com/monokh/ledger-app-isolation-bypass-poc" target="_blank">https://github.com/monokh/ledger-app-isolation-bypass-poc</a>
</p>
<p>The PoC demonstrates retrieving a valid signed bitcoin mainnet transaction from the ledger device while user is under
    the impression that a litecoin transaction is being signed.</p>
<p>It spends from the first 20 receive and change addresses of the native segwit bitcoin wallet.</p>
<h2 id="impact">Impact</h2>
<p>The implications are serious. As briefly covered, users expect to be protected by the ledger device when they have
    not unlocked their Bitcoin app. Yet, while having an altcoin unlocked, external applications can still:</p>
<ul>
    <li>Read the Bitcoin xpub (thereby knowing all addresses belonging to the wallet)</li>
    <li>Prompt Bitcoin transactions from the device that will be displayed as altcoin transactions</li>
</ul>
<h3 id="attack-methods">Attack methods</h3>
<p>The methods of attack here are many. Essentially, <strong>any trust placed on altcoin ledger apps can be exploited</strong>. Consider
    the following:</p>
<ul>
    <li>You are invited to try out a new service with testnet coins, that actually sweeps real Bitcoin out of your
        wallet.</li>
    <li>You swap low value coins on an untrusted exchange. The exchange can read your Bitcoin balances and given a good
        enough opportunity will take the exit. You wouldn't have applied the same level care with altcoins.</li>
    <li>You could be targeted with a patched version of Ledger Live that sends Bitcoin instead of altcoins. Then
        prompted to do a P2P trade with altcoins.</li>
</ul>
<p>No investigation has been done on instances of this exploit in the wild.</p>
<h3 id="affected-versions">Affected Versions</h3>
<p><strong>Firmware:</strong> All versions. Currently 1.6.0 <br>
<strong>App Versions:</strong> All versions. Currently 1.4.3<br>
<strong>Apps:</strong> Any apps deriving from the Bitcoin app as per <a target="_blank" rel="nofollow" href="https://github.com/LedgerHQ/app-bitcoin/blob/29717f9c95625ffc3c87176ff000a26d7721ae0d/include/btchip_context.h#L270">btchip_context.h</a><br>
<strong>Apps Tested:</strong> Bitcoin Testnet, Litecoin</p>
<h2 id="mitigation">Mitigation</h2>
<p>Recommendations for Ledger and users.</p>
<h3 id="ledger">Ledger</h3>
<p>Apps should be completely isolated with regards to the derivation paths that they are allocated to. No public key
    info or signing functionality should be exposed while they are not open.</p>
<ul>
    <li>Altcoin apps should be disabled on the Ledger live app directory and users should be notified to avoid using
        altcoin apps until fixes are available</li>
    <li>Apps/firmware should be updated to prevent this bypass</li>
    <li>Users should be notified to urgently upgrade to the patched versions.</li>
</ul>
<h3 id="users">Users</h3>
<ul>
    <li>Avoid using altcoin apps until fixes are available</li>
</ul>
<h2 id="interactions-with-ledger">Interactions with Ledger</h2>
<p>Based on my experience from the first disclosure (Jan 19), I understood that that they weren't
    motivated to see this issue to completion.</p>
<p>Ledger was aware of the issue before the disclosure as they indicated the latest firmware update includes fixes. Post
    disclosure, they described that the app updates were under QA and that the issue would be disclosed publicly once
    updates have been made. No further progress&nbsp;was observed
    and requests for update received no response.</p>
<p>With the second, more serious disclosure, expectations were already low. I observed that:</p>
<ul>
    <li>They minimised the issue to privacy initially</li>
    <li>When pressed for their plans in addressing the vulnerability, had no input.</li>
    <li>Still insisted on a 90 day disclosure period despite being fully aware of issue for 1y 6mo minimum (during development
        of firmware 1.5.5)</li>
    <li>No further communications regarding steps to fix or disclose. Requests for comment had no response.</li>
</ul>
<p>Based on the interactions described above, it was apparent that there was no intention to address the issue and the
    disclosure period would not yield any results. Nonetheless I gave them the benefit of the doubt and afforded some
    patience.</p>
<h2 id="conclusions">Conclusions</h2>
<p>I do not consider myself a security expert. Despite this, I was able to discover this issue while developing and
    experimenting with Ledger support on <a href="https://liquality.io/" target="_blank">Liquality</a>. It is worrying
    that the vulnerability did not utilise any complicated techniques such as side-channel attacks, buffer overflows
        etc. This could indicate that there are other issues undiscovered or in plain sight.
</p>
<p>Perhaps the most shocking conclusion is the negligence from Ledger regarding the handling of this issue. For an issue
    with this severity, to not attempt a fix, not communicate progress and avoid disclosure, is disrespectful towards
    the trust that people (including myself) have placed on them. With their increased focus in other departments
    (integrating alt coins, trading), I urge them to reconsider their attention to security. Such should be the
    commitment to a hardware wallet.</p>
<h2 id="disclosure-timeline">Disclosure Timeline</h2>
<ul>
    <li>18 Jan 2019 - Privacy related aspect of the vulnerability (reading addresses) disclosed to Ledger via report and
        PoC. <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="85e7eaf0ebf1fcc5e9e0e1e2e0f7abe3f7">[email&nbsp;protected]</a>)</strong>
        <ul>
            <li>Ledger: Firmware was updated but apps still need to be updated.</li>
            <li>Prompted for public disclosure: Bug will be disclosed once apps are updated.</li>
        </ul>
    </li>
    <li>30 Apr 2019 - Disclosed issue unfixed - Ledger contacted for update. No response. <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="8eece1fbe0faf7cee2ebeae9ebfca0e8fc">[email&nbsp;protected]</a>)</strong></li>
    <li>1 May 2020 - Discovered root cause expands to signing functions and can be exploited to steal funds <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="5f3d302a312b261f333a3b383a2d71392d">[email&nbsp;protected]</a>)</strong></li>
    <li>2 May 2020 - New report detailing bypassing the isolation for signing disclosed to Ledger with new report and
        PoC <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="10727f657e6469507c75747775623e7662">[email&nbsp;protected]</a>)</strong></li>
    <li>4 May 2020 - Ledger investigating. <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="ec8e8399829895ac8089888b899ec28a9e">[email&nbsp;protected]</a>)</strong></li>
    <li>10 May 2020 - No response. Follow up. <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="1b79746e756f625b777e7f7c7e69357d69">[email&nbsp;protected]</a>)</strong></li>
    <li>12 May 2020 - Issue acknowledged - mistakenly at first as only privacy related - set out disclosure timeline <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="ceaca1bba0bab78ea2abaaa9abbce0a8bc">[email&nbsp;protected]</a>)</strong>
    </li>
    <li>13-14 May 2020 - Exchanges with ledger clarifying severity and awareness <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="a8cac7ddc6dcd1e8c4cdcccfcdda86ceda">[email&nbsp;protected]</a>)</strong></li>
    <li>17 June 2020 - Request for update <strong>(<a href="https://monokh.com/cdn-cgi/l/email-protection" data-cfemail="4d2f22382339340d2128292a283f632b3f">[email&nbsp;protected]</a>)</strong> - No response</li>
    <li>28 July 2020 - Request for update sent to Ledger Donjon <strong>(Twitter DM)</strong> - No response</li>
    <li>03 Aug 2020 - Vulnerability not fixed or disclosed by Ledger. Public disclosure</li>
</ul>

            </div>
        </div></div>]]>
            </description>
            <link>https://monokh.com/posts/ledger-app-isolation-bypass</link>
            <guid isPermaLink="false">hacker-news-small-sites-24056227</guid>
            <pubDate>Wed, 05 Aug 2020 01:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeGoogle My Life]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24055955">thread link</a>) | @app4soft
<br/>
August 4, 2020 | https://homehack.nl/degoogle-my-life/ | <a href="https://web.archive.org/web/*/https://homehack.nl/degoogle-my-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>According to Wikipedia to DeGoogle is the act of removing Google from your life. As the growing market share of the internet giant creates monopolistic power for the company in digital spaces, increasing numbers of journalists have noted the difficulty to find alternatives to the company’s products. This is my experience to purge my life of Google and I can assure you it’s difficult but if we don’t act soon it will become impossible.</p><div>
		
<p>It’s been 1.5 years since Google+ closed and <a href="https://homehack.nl/category/social/page/2/">I started dipping my toes</a> into the Fediverse and other distributed social networks. It also kicked off my search to get rid of everything Google. To <a href="https://en.wikipedia.org/wiki/DeGoogle">DeGoogle</a> is easier said than done because Google is everywhere from search to fonts, from the video platform YouTube to the file storage and synchronisation service Google Drive, and from blog publishing service Blogger to the Google mobile operating system Android. And the list goes on. So chances are you’re using a lot of these services and most of them require a <a href="https://en.wikipedia.org/wiki/Google_Account">Google account</a>, a devious move from Google. It’s for this reason that it’s very hard to get rid of this o so convenient account.</p>



<figure><img data-attachment-id="1493" data-permalink="https://homehack.nl/degoogle-my-life/google_shattered/" data-orig-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=692%2C261&amp;ssl=1" data-orig-size="692,261" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Google_shattered" data-image-description="" data-medium-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=300%2C113&amp;ssl=1" data-large-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=692%2C261&amp;ssl=1" src="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?w=840&amp;ssl=1" alt="Shattered Google logo illustrates that we need to break the power of Google on the web." srcset="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?w=692&amp;ssl=1 692w, https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?resize=300%2C113&amp;ssl=1 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px" data-recalc-dims="1"><figcaption>The shattered Google logo (that I made in Inkscape) illustrates that we need to break the power of Google on the web.</figcaption></figure>



<p>To get a more comprehensive view take a look at <a href="https://en.wikipedia.org/wiki/List_of_Google_products">this article</a>. Below I’ve compiled a list of the most important Google services and products that I replaced with something else.</p>



<h2>Google Search</h2>



<p>Search was perhaps the easiest to replace (or is it). While Google search is by far the largest search engine in the world DuckDuckGo (DDG) is becoming <a href="https://duckduckgo.com/traffic">increasingly popular</a>. I’ve  used DDG to great satisfaction and only had to use Google search a couple of times. The only gripe that I have is that DDG isn’t free and open source software (FLOSS) let alone distributed. In that respect I’ve read some good things about <a href="https://searx.me/">Searx</a> and I may give that a try in the future.</p>



<h2>Chrome</h2>



<p>The Chrome browser of Google has become very popular with an <a href="https://en.wikipedia.org/wiki/Google_Chrome#Market_share">estimated market share of approximately 70%</a>. A large portion of the Chrome’s source code is based on Chromium, the open source browser project from Google,  however Chrome is proprietary freeware because it contains large blobs of proprietary code. The Spyware Watchdog considers <a href="https://spyware.neocities.org/articles/chrome.html">Chrome’s Spyware level extremely high</a> this due to multiple spyware features that are built-in such as Google Account and Navigation Assistance. Another threat come from the earlier mentioned market share. This gets even worse when we include the <a href="https://en.wikipedia.org/wiki/Chromium_(web_browser)#Active">other browsers that are based on Chromium</a> such as Microsoft Edge, Opera and Vivaldi.  I currently use <a href="https://www.mozilla.org/en-US/firefox/new/">Firefox</a>. It’s perhaps not the most privacy minded browser around but it’s FLOSS, it has a reasonable market share which is important for support of web developers and development of Firefox is very active. </p>



<h2>YouTube</h2>



<p>Next is YouTube which BTW is becoming more and more annoying with all these ads and the recommendations with the sole purpose to keep the user as long as possible on YouTube (and serve even more ads). I invested a lot in YouTube in the past with over 70 video made about 3D CAD, 3D printing and electronics so replacing it is not easy. The solution that I found is two-fold. I remastered (part) of my existing videos and uploaded them to both <a href="https://joinpeertube.org/">PeerTube</a> and YouTube. If I want to watch YouTube videos I use <a href="https://www.invidio.us/">Invidious</a> in the browser of <a href="https://newpipe.schabi.org/">NewPipe</a> on my Smartphone (still Android sadly).  </p>



<h2>Google Drive</h2>



<p>Over the years I got dependant on Google Drive e.g to store the CAD files that I wanted to share after I published a project either in blog or a video. I want readers and viewers to be able to reproduce the project. Since I didn’t want to self-host a solution <s>such as <a href="https://nextcloud.com/">Nextcloud</a> wasn’t for me</s> (see edit below). I started looking for a paid service. I currently have a contract with Strato, a German hosting company that also hosts my websites. Strato offers HiDrive, it’s not FLOSS unfortunately but it offers 100% storage in the EU and (paid) end-to-end encryption is possible although only in the HiDrive desktop program for Windows (which is a bummer but I don’t need encryption for this purpose anyway).</p>



<h2>Google Maps</h2>



<p>Instead of Google maps I started using <a href="https://www.openstreetmap.org/">OpenStreetMap</a> and products based on OpenStreetMap such as <a href="https://osmand.net/">OsmAnd</a> (on Android) and <a href="https://wiki.openstreetmap.org/wiki/Komoot">Komoot</a> both on Android and the web browser. Komoot is excellent for hiking and cycling but unfortunately it isn’t FLOSS. These alternatives have proven to be good enough for me since I haven’t used Google Maps any more. </p>



<h2>Gmail</h2>



<p>I somehow started using Gmail. I don’t know exactly why because I already had very good email services. I also fail to understand why it’s so popular because every other email service does about the same. My own ISP comes with a very good email service and so is the web hosting company that I’m using. To stop using Gmail takes some preparation most importantly to list and notify all the people and organisations that send you email to your Gmail address. Also list all online services that use your Gmail address. Now replace this Gmail address with another email address.</p>



<p>You may want to delete your Gmail completely but it’s possible that it’s linked to your Google account. If this is the case you can either <a href="https://www.wikihow.com/Change-Your-Email-Address-on-Google">use a different email address </a>for this account or more radical <a href="https://www.lifewire.com/how-to-delete-your-gmail-account-1172073">delete your Google account</a> completely. In case you choose the latter remember that lots of Google services are couples to your Google account and can’t be accessed any more. Having said that if you start to purge Google from your life the Google account becomes less and less important with every Google service that you delete. So at a certain point deleting the Google account will be painless.</p>



<h2>Android</h2>



<p>Although Android is Free and Open Source software most Android phones come with proprietary software and services that prevent users from using the phone the way they seem fit. The easy way to free the software on your phone is to install <a href="https://f-droid.org/">FDroid</a>. For most users the Google Play Store is the only way to install software on their phone. FDroid is an alternative software store that enables the user to easily install and maintain Free and Open Source software on their Android device. BTW installing FDroid and replacing proprietary apps is what I have done thus far and it’s a good start.</p>



<p>Even better is to replace the Google infested Android with a free version of Android like <a href="https://lineageos.org/">LineageOS</a>. LineageOS is a FLOSS version of Android that can be used without a Google account and that comes without the proprietary Google apps (and perhaps other junk from the phone manufacturer). Make sure to check if your phone is supported before trying to install in on your phone.</p>



<h2>Fonts</h2>



<p>Yes I know, I have Google fonts in my blog. That came with the choice of the WordPress theme and I didn’t realize that at the time. That’s just another example how Google infested the web and how difficult it is to DeGoogle my life but rest assured fonts will be next.</p>



<h2>Conclusion</h2>



<p>To get Google out of your digital life is hard, very hard. This tells us how much Google is integrated into our lives and probably for the most part without being aware of it. Luckily we still have choice (other than just say goodbye to the web), choice that gives us freedom to use the web without being used. The freedom to control our data and not being exploited. </p>



<p>E<em>dit: As someone on Mastodon pointed out it’s not necessary to self-host NextCloud. Examples of cloud service providers running Nextcloud are <a href="https://disroot.org/en/services/nextcloud">Disroot</a>, <a href="https://www.owncube.com/index_en.php">OwnCube</a> and <a href="https://operationtulip.com/">Operationtulip.com</a> (currently in beta). </em></p>


<div>
	<p><img alt="" src="https://secure.gravatar.com/avatar/a90a46e04d18b0f85b8b54368a30dfe4?s=42&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a90a46e04d18b0f85b8b54368a30dfe4?s=84&amp;d=mm&amp;r=g 2x" height="42" width="42">	</p><!-- .author-avatar -->

	<div>
		

		<p>
			I’m an #privacy, #opensource, #opendata and #openstandards advocate. I’m holding a grudge against Big Tech, big IP holders and authoritharian governments. Furthermore I’m a #3Ddesigner, #3Dprinter, #webdesigner and overall #DIY guy.

But most of all I’m a free man.			<a href="https://homehack.nl/author/eribuijs/" rel="author">
				View all posts by eribuijs			</a>
		</p><!-- .author-bio -->
	</div><!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]>
            </description>
            <link>https://homehack.nl/degoogle-my-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055955</guid>
            <pubDate>Wed, 05 Aug 2020 00:23:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24055732">thread link</a>) | @lettergram
<br/>
August 4, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of its mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>— …</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055732</guid>
            <pubDate>Tue, 04 Aug 2020 23:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you're having vivid dreams during the pandemic]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24055592">thread link</a>) | @rahulshiv
<br/>
August 4, 2020 | https://www.sleepedy.com/articles/pandemic-dreams/ | <a href="https://web.archive.org/web/*/https://www.sleepedy.com/articles/pandemic-dreams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>You are definitely not alone. A recent study by Deindre Barett, a Harvard psychologist, shows a significant increase in unusual and vivid dreams around the globe. Why is this happening and what are the second order effects of it?</p><h2 id="what-are-dreams">What are dreams?</h2><p>Dreams are a small peak into the complex way in which our brains make sense of the world. They usually don't make a lot of sense themselves and are rarely representative of your desires or beliefs. Think of them as a background process that keeps your brain in tune with the world around you<sup><a href="#references">1</a></sup>. </p><p>Dreams become more vivid when there are changes in your sleep quality and timing. Stress, anxiety &amp; uncertainty affect your sleep quality. Think of the night before a big event like a job interview. Falling asleep gets that much harder, and your sleep quality is usually worse. This leads to more vivid dreams.</p><h2 id="dreams-as-a-function-of-rem-sleep">Dreams as a function of REM sleep</h2><p>Dreams mostly occur during the Rapid Eye Movement (REM) stage of your sleep <sup><a href="#references">2</a></sup>. Every night you go through 3 different types of sleep - Light, Deep &amp; REM - in a cyclical process that lasts about 90 minutes. The time you spend in each type of sleep depends on the time of night. Earlier in the night you spend majority of the 90 minutes in light &amp; deep sleep. Earlier in the mornings is when you get most of your REM sleep. </p><p>The amount of REM you get each night is also controlled by how much REM sleep you've been getting over the past few days. Get too little REM sleep? Your body compensates for it by spending longer periods in REM sleep. This is why you experience a lot of dreams in the morning after a heavy night of drinking. Alcohol is a REM depressant and once its effects wear off, your body tries to catch up on REM sleep. Its a phenomenon called REM rebound. </p><p>Amount of time in REM this cycle = f(Current time, Amount of REM sleep over the past few days)</p><p>The pandemic has caused many changes in the way we live and work. Not having a morning commute means many people have the chance to sleep in. If you've been REM deprived in the past, and are spending more time in the morning sleeping, you are in REM rebound. This can lead to more vivid and frequent dreams. If your sleep schedule is inconsistent, you are getting a lot of REM on some nights and much less on others. This also leads to REM rebound and more vivid dreams.</p><h2 id="heightened-dream-recall">Heightened dream recall</h2><p>The emotions felt on a daily basis govern our dreams. Bizarre and negative dreams are a way of coping with everyday stressors. Dreams activate a neuron called serotonin 5-HT2A <sup><a href="#references">3</a></sup>. This neuron turns off a part of the brain called the dorsal prefrontal cortex. The result is “emotional disinhibition” a state in which emotions flood the consciousness.</p><p>We dream many times a night but our dream recall is usually poor. A sudden increase in anxiety and uncertainity leads to decrease in sleep quality. Poor sleep quality results in more night-time awakenings. Its much easier to remember your dreams when you keep waking up in the middle of the night.</p><p>The pandemic has raised anxiety &amp; stress levels across society. The dreams we experience reflect these emotions. Throw in high dream recall, and you get vivid, weird &amp; frequent dreams. </p><p>None of this is cause for much alarm. If you are generally REM deprived, your body will catch up to it. If you're sleep schedule is inconsistent, switch to a consistent wake up time. If your dreams are bothering you, there is early evidence that "dream mastery" techniques can reduce the intensity <sup><a href="#references">4</a></sup>.</p><p>Humans are good at coping with changes long-term. As we start accepting this new normal, odds are these "Pandemic dreams" will subside. </p><p>If you'd like to learn more about sleep and techniques to improve sleep, check out our <a href="https://www.sleepedy.com/" target="_blank" rel="nofollow noopener noreferrer">website</a>!</p><h2 id="references">References</h2><ol><li><p><a href="https://www.ninds.nih.gov/Disorders/Patient-Caregiver-Education/Understanding-Sleep" target="_blank" rel="nofollow noopener noreferrer">Brain Basics: Understanding Sleep</a></p></li><li><p><a href="https://www.ncbi.nlm.nih.gov/books/NBK11121/" target="_blank" rel="nofollow noopener noreferrer">The Possible Functions of REM Sleep and Dreaming</a></p></li><li><p><a href="https://www.frontiersin.org/articles/10.3389/fphar.2015.00225/full" target="_blank" rel="nofollow noopener noreferrer">The role of serotonin 5-HT2A receptors in memory and cognition</a></p></li><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0005789419300267?via%3Dihub" target="_blank" rel="nofollow noopener noreferrer">Mediators of Change in Imagery Rescripting and Imaginal Exposure for Nightmares: Evidence From a Randomized Wait-List Controlled Trial</a></p></li></ol></div></div></div>]]>
            </description>
            <link>https://www.sleepedy.com/articles/pandemic-dreams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055592</guid>
            <pubDate>Tue, 04 Aug 2020 23:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My favorite product management templates]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24055448">thread link</a>) | @jcs87
<br/>
August 4, 2020 | https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hello and welcome to the<strong>&nbsp;free monthly edition&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>, and each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</p><p>If you’re not a paid subscriber, here’s what you missed this month:</p><ol><li><p><a href="https://www.lennyrachitsky.com/p/crafting-an-seo-strategy-issue-34">Winning at SEO</a>﻿</p></li><li><p><a href="https://www.lennyrachitsky.com/p/autonomy-vs-direction-issue-35">As a leader, choosing autonomy vs. direction</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups">How today's fastest-growing B2B startups turned their early users into paying customers</a></p></li></ol><p>Consider&nbsp;subscribing if you haven’t already 👇</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2561865,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Now I do!</p><p>Below are all of my favorite templates and frameworks that I rely on. As a bonus, I <a href="https://twitter.com/lennysan/status/1287862995268206592">asked the wonderful people of Twitter</a> to share their favorites, from which I picked my favorites and included. Enjoy!</p><h4>✍️ 1-Pagers / PRDs</h4><ol><li><p><a href="https://docs.google.com/document/d/1541V32QgSwyCFWxtiMIThn-6n-2s7fVWztEWVa970uo/edit">My personal 1-Pager template</a> — How I start every project</p></li><li><p><a href="https://docs.google.com/document/d/1mEMDcHmtQ6twzNlpvF-9maNlAcezpWDtCnyIqWkODZs/edit">Kevin Yien’s PRD template</a> (PM at Square) — Love this whole template, particularly the “Non-Goals” section, and the step-by-step flow</p></li><li><p><a href="https://docs.google.com/document/d/1W46cmPfPwXIIH2mNNbbQ5EdjnhQFqGxGhT5iAijmJjc/edit#heading=h.cqt1a4hrfy8u">Asana’s project brief template</a> — Also love this whole template, particularly the problem statement framework</p></li><li><p><a href="https://s3.amazonaws.com/marketing.intercomcdn.com/assets/Intercom-Job-Story-template.pdf">Intercom’s story template</a> — Love the simplicity, while still having everything you need to get started</p></li><li><p><a href="https://docs.google.com/document/d/1yrU5F6Gxhkfma91wf_IbZfexw8_fahbGQLW3EvwdfQI/edit">Product Hunt’s PRD template</a> — Love the way it begins (Who, Why, What), though a bit long</p></li><li><p><a href="https://docs.google.com/document/d/1A__mJX33zn5fmAj6DtYv1P19aI6R4Gtcc13fGZv377k/edit">Adam Waxman’s PRD template</a> (Design at SeatGeek) — Love 1-Pager summary section before it dives deep</p></li><li><p><a href="https://docs.google.com/document/d/1BeNK9BYd3-8pAqVYR_B0Gzp7kGNtWdPFHJKIXI52_84/edit?ts=5f264700#heading=h.6jynaot9cbnq">Steve Morin’s 1-pager template</a> (EM at Asana) — Love the focus on success criteria and risks</p></li><li><p><a href="https://coda.io/@yuhki/figmas-approach-to-product-requirement-docs/prd-name-of-project-1">Figma’s PRD template</a> — A super comprehensive plug-and-play template </p></li><li><p><a href="https://docs.google.com/document/d/1B3GEUwgEIIQVgRp85l4DKLZOTzgGZmBIAjR06p4wuwY/edit#">Adam Thomas’ initiative template</a> — A reminder of how valuable it is to keep these to one page, at least to start</p></li></ol><h4>🤔 Strategy</h4><ol><li><p><a href="https://docs.google.com/document/d/1JI73WrGplrhNE46aLyRD_B74gEynI77EPgXn1ic6WeQ/edit?usp=drive_web&amp;ouid=111613335789441259753">My business strategy template</a></p></li><li><p><a href="https://docs.google.com/document/d/1RQWuvWDgcAv1ylksFXtiwhuTbHLcL1byIcoXsbCQfic/edit#heading=h.b2dsyhbkdvd1">My team strategy template</a></p></li><li><p><a href="https://www.salesforce.com/blog/2013/04/how-to-create-alignment-within-your-company.html">V2MOM template</a> by Marc Benioff</p></li><li><p><a href="https://www.linkedin.com/pulse/working-backwards-press-release-template-example-ian-mcallister/">Amazon working backwards PR template</a> by Ian McAllister</p></li><li><p><a href="https://medium.com/@gibsonbiddle/2-the-dhm-model-6ea5dfd80792">How to define your product strategy</a> by Gibson Biddle</p></li></ol><h4>🤩 Vision</h4><ol><li><p><a href="https://www.romanpichler.com/blog/tips-for-writing-compelling-product-vision/">Product Vision Board</a> by Roman Pichler</p></li><li><p><a href="https://gist.github.com/JoshSmith/2041454">Geoffrey Moore's positioning framework</a> by Josh Smith</p></li><li><p><a href="https://medium.com/@kit_ulrich/a-surprisingly-simple-technique-for-a-rockstar-product-vision-the-ladder-of-needs-ae624d81ca6b">The Ladder of Needs</a> by Catherine (Kit) Ulrich</p></li></ol><h4>📢 <strong>Go-To-Market</strong></h4><ol><li><p><a href="https://docs.google.com/document/d/1Y4NwrsoucPqNFqIkhwNgKpPzf0wqnrN6tcKF2g4nVoM/edit">Launch strategy template</a> by Pratik Mehta</p></li><li><p><a href="https://chatbotsmagazine.com/marketing-plan-and-chill-75f7e3d63358#.kgoqx0ahk">Marketing plan template</a> by Michael Taylor</p></li><li><p><a href="https://docs.google.com/presentation/d/1idjXAJDUn8EOMnzE5B0ZtR3BcQAdN3YteFGBoPkUUEI/edit#slide=id.p">GTM plan template</a> by The Product Folks</p></li></ol><h4>👌 <strong>Other templates</strong></h4><ol><li><p><a href="https://docs.google.com/spreadsheets/d/1zlx3RuidNOW40Zf7gh07p2SqoR53Ungv9JFT-PhHwxI/edit#gid=184965050">Roadmap template</a></p></li><li><p><a href="https://docs.google.com/document/d/1SXO4eH8ZvpuONpdlxpu6y1ufDS0n6vbciV4IJzpm-sc/edit">Performance review template</a></p></li><li><p><a href="https://docs.google.com/spreadsheets/d/1RTMr9vGCYEhWYA2dKG8EYLDFEtQ1E33W8uDEhmEd8QQ/edit?usp=drive_web&amp;ouid=111613335789441259753">Planning timeline template</a></p></li></ol><h4>🤤 <strong>Additional goodness</strong></h4><ol><li><p><a href="https://coda.io/@gokulrajaram/gokuls-spade-toolkit">Gokul's S.P.A.D.E. decision-making framework</a></p></li><li><p><a href="https://medium.com/@barmstrong/how-we-make-decisions-at-coinbase-cd6c630322e9">How we make decisions at Coinbase</a></p></li><li><p><a href="https://medium.com/lessons-from-mckinsey/the-pyramid-principle-f0885dd3c5c7">The Pyramid Principle</a></p></li><li><p><a href="https://uxdesign.cc/8-things-to-use-in-jobs-to-be-done-framework-for-product-development-4ae7c6f3c30b">“Jobs to Be Done” framework</a></p></li><li><p><a href="https://coda.io/@shishir/eigenquestions-the-art-of-framing-problems/">Eigenquestions: The Art of Framing Problems</a></p></li><li><p><a href="https://medium.com/@stewart/we-dont-sell-saddles-here-4c59524d650d">We Don’t Sell Saddles Here</a></p></li><li><p><a href="https://sriramk.com/strategy">Business strategy concepts</a></p></li><li><p><a href="https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a">High Output Founders' Library</a></p></li></ol><p>If you have any other amazing templates or frameworks that you regularly use, across product, marketing, eng, or design <em>please</em> <a href="https://twitter.com/lennysan">shoot them over</a>. I’ll use this post as a living document of the best product development templates.</p><p>That’s it for this week!</p><p>🙏 Thank you to these fine folks for sharing many of these templates: <a href="https://twitter.com/ajwaxman/status/1261470324824121345">Adam</a>, <a href="https://twitter.com/amanik/status/1287868945920221184">Aman</a>, <a href="https://www.linkedin.com/in/dennisyang/">Dennis</a>, <a href="https://twitter.com/satoshisayswhat/status/1287901497976651776">Chris</a>, <a href="https://twitter.com/phil_huot/status/1288141112180445186">Philippe</a>, <a href="https://twitter.com/PratikkCMehta/status/1287956996986028032">Pratik</a>, <a href="https://twitter.com/robsicat/status/1287895839851966466">Rob</a>, <a href="https://twitter.com/tatopane/status/1287863498383400960">Tato</a>, <a href="https://twitter.com/satyap">Satya</a>, <a href="https://productivegrowth.substack.com/">Steve</a>, <a href="https://twitter.com/lennysan/status/1287862995268206592">Sree</a>, <a href="https://twitter.com/vindytalks">Vindhya</a>. Photo by&nbsp;<a href="https://unsplash.com/@joannakosinska?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Joanna Kosinska</a> 🙏</p><h2>🔥 Job opportunities</h2><ul><li><p>Product: <a href="https://angel.co/company/kudo-meeting/jobs/913705-product-manager">KUDO</a>, <a href="https://jobs.all-hands.us/companies/uptime2020/jobs/product-manager-2-5943a3d1-9819-417b-aee9-fc6a563b276e">Uptime2020</a></p></li><li><p>Growth: <a href="https://boards.greenhouse.io/cerebral/jobs/4076601003">Cerebral</a>, <a href="https://jobs.lever.co/outschool/4f18d9fe-516b-4285-a5df-357f6cff5b92">Outschool</a></p></li><li><p>Design: <a href="https://www.cascade.io/jobs/analytical-product-designer">Cascade</a>, <a href="https://jobs.lever.co/pachama/f4f49853-9d59-4dcc-9d0b-143ca63a53d2">Pachama</a>, <a href="https://www.notion.so/Founding-Designer-San-Francisco-d1296f25efcc43a7833fd28ea3952b39">Primer</a>, <a href="https://sourcetable.com/jobs#contract-designer">Sourcetable</a></p></li><li><p>Engineering lead: <a href="https://boards.greenhouse.io/cerebral/jobs/4076598003">Cerebral</a>, <a href="https://jobs.lever.co/snackpass/00505223-bc85-4c28-8e4b-31217d05c2de">Snackpass</a></p></li><li><p>Frontend engineer: <a href="https://www.cascade.io/jobs/front-end-product-engineer">Cascade</a>, <a href="https://www.notion.so/levelshealth/Join-Levels-Remote-Developer-58454f0db7e3466692f7b75db6237ddf">Levels</a>, <a href="https://www.notion.so/Founding-Frontend-Engineer-San-Francisco-783c2072b9c047a88cb884babb47ef04">Primer</a>, <a href="https://transformdata.io/careers/">Transform</a></p></li><li><p>Backend engineer: <a href="https://sourcetable.com/jobs#backend-engineer">Sourcetable</a>, <a href="https://transformdata.io/careers/">Transform</a></p></li><li><p>Fullstack engineer: <a href="https://www.notion.so/Software-Developer-e7cad269968e4d5aaeb1f6da9e282626">Centered</a>, <a href="https://jobs.lever.co/snackpass/7c3bb72b-70d3-45ca-9dea-eea57ed5333d">Snackpass</a>, <a href="https://projectwren.com/careers/software-engineer">Wren</a></p></li><li><p>iOS engineer: <a href="https://www.notion.so/Lead-iOS-Developer-ba18577b6ba44ad68e45b8e7a957353c">Pairplay</a></p></li><li><p>Sales/BD: <a href="https://boards.greenhouse.io/cerebral/jobs/4105169003">Cerebral</a>, <a href="https://angel.co/company/kudo-meeting/jobs/649855-vice-president-of-sales">KUDO</a>, <a href="https://jobs.lever.co/pachama/996cdde4-737b-4794-ad0f-d726448c3dfb">Pachama</a>, <a href="https://angel.co/company/swayable/jobs/808347-director-of-sales">Swayable</a></p></li><li><p>Community: <a href="https://jobs.lever.co/outschool/449fa54a-1778-4255-a95d-a65dc28194c7">Outschool</a></p></li><li><p>Security: <a href="https://angel.co/company/kudo-meeting/jobs/592999-cybersecurity-compliance-program-manager">KUDO</a></p></li></ul><h2><strong>🧠 Inspiration for the week ahead</strong></h2><ol><li><p><strong>Read</strong>: <a href="https://li.substack.com/p/unbundling-work-from-employment">Unbundling Work from Employment</a> by Li Jin</p></li><li><p><strong>Watch</strong>: Japanese skateboarder Isamu Yamamoto (via <a href="https://mikeplewis.substack.com/">Mike Lewis</a>)</p></li></ol><ol start="3"><li><p><strong>Watch</strong>: <a href="https://vimeo.com/429924982">Transfiguration</a> (via <a href="https://thebrowser.com/">The Browser</a>)</p></li></ol><p id="vimeo-429924982" data-attrs="{&quot;videoId&quot;:&quot;429924982&quot;}"><iframe src="https://player.vimeo.com/video/429924982?autoplay=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><strong>If you’re finding this newsletter valuable, consider&nbsp;<a href="https://www.lennyrachitsky.com/">sharing it with friends</a>, or subscribing if you aren’t already.</strong></p><p>Sincerely,</p><p>Lenny 👋</p></div></div>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055448</guid>
            <pubDate>Tue, 04 Aug 2020 23:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Urban Legend of the 10x Developer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054824">thread link</a>) | @todsacerdoti
<br/>
August 4, 2020 | http://codefol.io/posts/urban-legend-of-the-10x-developer/ | <a href="https://web.archive.org/web/*/http://codefol.io/posts/urban-legend-of-the-10x-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <!-- .post-header -->
            <div>
                  
<figure>
    <p><img src="http://codefol.io/img/chimp_keyboard_aside_216_135.png" alt="A chimpanzee in a white coat types at a keyboard lit by glowing LEDs." width="216" height="135" title="Compared to this guy you may be a hundred-x developer but the real ninja rockstar was the friends he made along the way.">
    </p>

      <figcaption>
        Compared to this guy you may be a hundred-x developer but the real ninja rockstar was the friends he made along the way.
        
        
      </figcaption>
</figure>

                <p>You’ll often hear folks claim that it’s well-researched that some developers are ten times (or twenty-seven times! Or more!) as productive as the median developer. They often refer these gifted folks as “10x developers.”</p>

<p>The “well-researched” part is garbage. Completely wrong. There are some studies and they’re terrible.</p>

<p>But is there perhaps some truth to the idea? Let’s talk about that.</p>

<p>And what would “some truth to it” mean? That depends on how you define “productivity.” So let’s look at some definitions.</p>

<h2>“Well-Researched?”</h2>

<figure>
    <a href="http://codefol.io/posts/urban-legend-of-the-10x-developer/leprechauns_cover.png">
      <img src="http://codefol.io/posts/urban-legend-of-the-10x-developer/leprechauns_cover.png" alt="The cover of Laurent Bossavit's book 'The Leprechauns of Software Engineering.'" title="It's a wonderful, depressing read.">
    </a>
        <figcaption>It’s a wonderful, depressing read.</figcaption> 
</figure>

<p>You may be one of <a href="https://xkcd.com/1053/">today’s lucky 10,000</a> to learn about <a href="https://leanpub.com/leprechauns">Laurent Bossavit’s “The Leprechauns of Software Engineering.”</a> It’s a thoroughly excellent ebook that I recommend highly.</p>

<p>It turns out that we, as software engineers, tend to believe that we’ve researched a few specific things about software engineering and that we know those things scientifically. We’re nearly always wrong about that. For instance:</p>

<ul>
<li>The “10x Developer” thing has only a couple of empirical papers that actually even try to measure, and they do a bad job of that</li>
<li>That “changes get exponentially more expensive to fix” based on time-after-writing never had any empirical data behind it and is based on miscopying a theory</li>
<li>“Waterfall” as a project management methodology <strong><em>did</em></strong> basically exist and was used, but the “definitive” paper wasn’t made popular until its enemies did</li>
</ul>

<p>But I can stop spoiling the book for you. It’s worth your time to read it.</p>

<p>In any case, the early studies that found “10x productivity” developers studied different kinds of developers in different environments with minimal controls and far too few developers being sampled. The research is terrible if you want to base any real work on it.</p>

<p>“Leprechauns” goes even further, and basically thinks our field <strong><em>cannot</em></strong> measure this. The claim sounds outlandish, but I think he’s basically right. Until we’re willing to define “productivity,” which is very hard, we’re not going to be able to define a good study around it.</p>

<p>And the horrible quality of the existing studies is a warning to us: designing a bad study doesn’t teach us anything useful.</p>

<h2>Productivity? That’s Lines Per Day, Right?</h2>

<figure>
    <p><img src="http://codefol.io/img/chimp_with_lab_glass_aside_216_173.jpg" alt="A chimpanzee in a lab coat and goggles holds a beaker and flask next to a rack of test tubes." width="216" height="173" title="He almost has this 'productivity' thing figured out.">
    </p>

      <figcaption>
        He almost has this ‘productivity’ thing figured out.
        
        
      </figcaption>
</figure>

<p>Also, are we trying to say that <strong><em>at similar experience levels</em></strong> there are 10x differences between different developers? Or between similar developers in different circumstances? Are we trying to say that there is a 10x difference between one developer on their second week and the same developer in their thirtieth year? Mostly, more experienced developers do different tasks and approach them in different ways, so are we trying to say that there is a 10x difference in a similar task, but where the developer can pick <strong><em>what functionality</em></strong> to implement? Because if so, we’re not going to be able to design a good research study for that. Ever.</p>

<p>So: studies don’t actually say this, partly because coding productivity is <em>really</em> hard to design a reasonable study for. Also because most software engineering research is terrible. Also we have a tendency to cite previous papers as saying things they don’t.</p>

<p>Are you thinking, “that can’t be that hard?” If so, I <strong><em>strongly recommend</em></strong> you read The Leprechauns of Software Engineering. He’s put a lot of effort into tracking previous attempts to show the problems with them. He’s also put a lot of effort into formulating definitions of “productivity” to show how hard it is to show that what you’re measuring should measure that idea of productivity. Basically, if you don’t know what your definition is, you’ll tend to wind up multiple steps away from anything sensible, in a way that leaves your measurement as complete nonsense.</p>

<h2>What Can We Say? Money?</h2>

<p>All right, let’s take it as a given that measuring productivity is really hard. What can we say?</p>

<p>There are some traditional measures of productivity. They’re bad, but they’re a long-established kind of bad. What can we do with that?</p>

<p>One is money. The amount of money a piece of work sells for (either by an employee or a company) has very little to do with the quantity or quality of that work. So: don’t conflate money with either how hard somebody works or how well they work. But can’t we just measure money?</p>

<p>We can.</p>

<p>It’s clear that there is a far greater than 10x difference between the amount of money being made by the highest- and lowest-paid programmers. That’s true if look at employees: early Google employees made many millions, random senior programmers make far less than 1/10th as much. It’s true if you look at founders: the median founder loses money while a few founders make many millions of US dollars. It’s true of freelancers, where the same developer may go from $40/hour to $400/hour or more over a surprisingly short time.</p>

<p>Of course, low-quality code often makes a lot of money. Money isn’t a very good measurement of anything but money. There’s a great Stephen King quote I can’t find — he was asked by somebody how he could be a bestselling author when his writing was so bad. He said, roughly, “listen to your own question. It’s best-<strong><em>selling</em></strong> author, not best-<strong><em>writing</em></strong> author.”</p>

<p>In the tech realm, the early Wordpress code was pretty clearly <strong><em>not</em></strong> good code. I don’t mean “it was in PHP.” I mean it was insecure, inefficient and inconsistent in interfaces. It was, however, astoundingly popular and made a lot of folks a lot of money. Excellent code is often small, so measuring how many lines or how much functionality it has is often missing the point. <strong><em>Well-chosen</em></strong> functionality is usually the point, and that’s often more in the realm of design or product (or occasionally random chance) than of engineering.</p>

<p>Money mostly measures money.</p>

<p>For all the same reasons, popularity mostly measures popularity. There is clearly far more than a 10x difference between the median-popularity and most-popular software, even if you measure developer-by-developer or hour-by-hour.</p>

<p>But we knew that, and it’s not what we actually want to measure.</p>

<h2>Impact?</h2>

<p>Can you show a 10X <strong><em>impact</em></strong>? Not really, no. I mean, you can easily show that some developers have <strong><em>no</em></strong> impact. I worked for a year on DVR firmware that never shipped, and two years on a phone operating system no carrier ever bought. There are many similar stories. So in some sense, if you deployed a web app around 2005 you were an infinite number of times more productive than I was that year.</p>

<p>But “impact” shares the same problems as “money” and “popularity” - it’s easy to show that a staggeringly huge difference exists, but that difference is almost completely detached from how hard or how well the developer actually worked.</p>

<p>Frequently it’s completely random.</p>

<h2>What Would 10x Look Like?</h2>

<p>Part of the reason we want to point at “10x developers” at all is that we’ve worked with developers that seem to write better projects, a lot faster than others. We have a gut-level intuition that some developers are far more productive than the average.</p>

<p>We just don’t know a good way to quantify that. And if we can’t quantify it, we can’t test our gut-level intuition and see if it’s true or not.</p>

<p>Indeed, some people are sure it’s a mirage. “A 10x developer is just a regular developer on a good team with a supportive environment.” “A 10x developer is writing code with so much technical debt the rest of his team is down to 0.1x trying to clean it all up.”</p>

<p>There’s no research for <strong><em>that</em></strong> idea of a 10x Developer either. But it’s not hard to imagine a world where it’s true. If we can’t test any of the variations of 10x Developer then we can’t rule them out.</p>

<p>I, personally, hope I can significantly improve as a developer over my career. It would be nice to think that I’m more useful now than I was 30 years ago. But if we want something as wishful thinking, we should be suspicious of it.</p>

<p>When we look at a meaningless Rorschach Blot Test, the things we crave will mysteriously appear.</p>

<h2>What We Can’t Measure</h2>

<p>I believe there exists something along the lines of a 10x Developer. I have a mental concept of it. It might even have some kind of truth behind it, though it’s hard to tell.</p>

<p>To explain that concept to a non-developer, I might say:</p>

<p>“There are software developers who seem to create useful software quickly. They don’t need much managing. They often ignore managers in favour of producing what’s actually needed. They usually have a good read on company politics, but they work in a position where they don’t need to do much of it. They’re well-trusted, and are often brought in to rescue a team whose project is bogged down.”</p>

<p>And it strikes me, as I write that, how much of it is about the organisation trusting the developer. Much of it is about ignoring structure and rules that, at that moment, would get in the way. A developer usually needs skill and talent to get that trust, but the continuing productivity is about <strong><em>continuing to have the trust of their employer</em></strong>. Just having skill and talent often won’t do it.</p>

<p>In other words, I’ve come to a personal definition that is very similar to “a 10x developer is a solid, ordinary developer with good organisational support.”</p>

<p>Indeed, if you <a href="https://randsinrepose.com/archives/free-electron/">read between the lines of many existing descriptions</a> you’ll see that a lot of it is about organisational support there, too. It’s just written by people who think that if you’re good enough technically, the organisation will let you apply your skill where it will make a difference. That hasn’t been my experience, personally.</p>

<p>That’s not to say that “anybody could be one.” I think actual “solid, ordinary” developers who can do good work on many different types of projects are rare and underrated. But they’re not magic …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://codefol.io/posts/urban-legend-of-the-10x-developer/">http://codefol.io/posts/urban-legend-of-the-10x-developer/</a></em></p>]]>
            </description>
            <link>http://codefol.io/posts/urban-legend-of-the-10x-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054824</guid>
            <pubDate>Tue, 04 Aug 2020 21:47:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Layering Domains and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24054678">thread link</a>) | @abigger87
<br/>
August 4, 2020 | https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/ | <a href="https://web.archive.org/web/*/https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>
<p>TL;DR – Hierarchically arranged API gateways can be used to build “macro” bounded contexts. This can make microservices “less”of a problem by reducing them to an implementation detail within that macro context. This results in a simplified architecture composed of stable interactions between hierarchical domain boundaries.</p>
<hr>
<p>Microservice architectures have many advantages as well disadvantages, and the internet is rife with debate about the size of a “micro”-service. A less talked about problem is the “conceptual sprawl” that individual microservices modelling a rich problem space create. There can be dozens or hundreds of well-defined bounded contexts each represented by a microservice.</p>
<p>However, discovering the right combination of these services to fulfil a new business requirement becomes an increasing challenge. Each individual part (service) may be well designed, but we start losing our way in the exponential number of interactions between them.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1024x842.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1024x842.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1024x842.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-300x247.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-768x631.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1070x880.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services.jpg 1202w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1024x842.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-300x247.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-768x631.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services-1070x880.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/too-many-services.jpg 1202w"></figure>
<h3>Case Study : Backend for Frontend</h3>
<p>A “backend for frontend” is a service supporting a frontend by combining data from multiple underlying services. This is the node server backing a react app, the controller layer behind thymeleaf/JSP pages and so on.<br>Let’s walk through how new UIs are often built. The first version almost always directly calls existing APIs across many services (likely because there aren’t many such calls). As more and more services need to be called and their data merged into each other in more complicated ways, a debate arises as to whether all this should be done in the frontend or the backend and which team should do this.</p>
<p>The typical response these days is to spin off a “service” which does whatever the frontend team wants it to do.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1024x888.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1024x888.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1024x888.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-300x260.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-768x666.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1070x928.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend.jpg 1330w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1024x888.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-300x260.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-768x666.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend-1070x928.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/custom-backend-for-frontend.jpg 1330w"></figure>
<p>While we can think of this new service as a system that supports a particular UI, what it is actually doing is providing an abstraction that allows the frontend to have only a limited exposure to the full complexity of the backend.</p>
<h3>The Cognitive Overhead Problem</h3>
<p>The problem described above happens because a single frontend team cannot possibly deal with a microservice-based backend fragmented into tiny “domain” capsules exposed all at once. The cognitive overhead in combining these tiny pieces into larger things is tremendous. One has to understand all of them as they relate to each other and the ways they communicate with each other (e.g. are they eventually consistent with each other? Do they have independent state machines and how do they relate to each other?).</p>
<p>The other problem is that the underlying architecture is constantly shifting, with more microservices coming up, services getting deprecated and changing contracts etc. All this makes our “abstraction service” brittle. The microservice owners have to be on the lookout for all consumers lest they break them with any change. Service users are always tinkering with their service to keep it in line with the underlying services. Migrations become a permanent fixture on the sprint board.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1024x671.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1024x671.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1024x671.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-300x197.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-768x503.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1070x701.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse.jpg 1267w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1024x671.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-300x197.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-768x503.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse-1070x701.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/custom-means-no-reuse.jpg 1267w"></figure>
<p>Given this scenario, a specialized solution in the form of one service for one UI is actually a good solution – it is the only way to move forward! Anyone looking to combine information across multiple domains as defined by each microservice has to create a solution of their own because that is all they can do.</p>
<p>But in the larger scheme of things, this is clearly not a good place to be in. How can we reduce this complexity in combining things so that we are better able to leverage the existing systems?</p>
<div>
<div>
<h4>Support this blog on Patreon</h4>

</div>
<div>
<div><figure><a href="https://www.patreon.com/bePatron?u=29760145"><img src="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png" data-src="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png" alt="" width="100" height="100" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png 1024w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-300x300.png 300w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-150x150.png 150w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-768x768.png 768w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1070x1070.png 1070w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral.png 1080w" data-sizes="(max-width: 100px) 100vw, 100px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png 1024w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-300x300.png 300w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-150x150.png 150w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-768x768.png 768w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1070x1070.png 1070w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral.png 1080w"></a></figure></div>
</div>
</div>

<h3>Organization in Complex Systems</h3>
<p>Here’s a quick, shallow recap of organization in complex systems.<br>Complex systems are made of hierarchies of independent subsystems. The hierarchical arrangement emerges as an evolutionary response to changing environment and leads to more and more sophisticated features. Each level is a response to needs faced by one or more lower level systems and it abstracts their details while still facilitating their functioning. The overall system is therefore partially resilient to failure of its somewhat independent subsystems. Collectively, this gives to an ever rising dynamic complexity which is highly resilient and adaptive.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1024x878.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1024x878.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1024x878.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-300x257.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-768x658.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1536x1317.jpg 1536w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1070x917.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems.jpg 1697w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1024x878.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-300x257.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-768x658.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1536x1317.jpg 1536w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems-1070x917.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/organization-in-complex-systems.jpg 1697w"></figure>
<p>If this sounds remarkably similar to distributed system design (buzzwords et al) because it is. Large distributed systems are rich complex systems with all constituent parts interacting with each other and triggering concurrent changes in each other. So let’s try to bring some systems thinking to bear on the problem of custom backends-for-frontends.</p>
<p>The custom backend-for-frontend we just saw is the microservice architecture’s highly specialized evolutionary response to the pressure of the external world, viz. the functional requirements of the frontend and the limited time in which to meet those requirements. Evolutionary timescales are generally long because the system tries out many combinations before “discovering” what works best in the new environment. However, by putting a timeline on “survival” we have hamstrung the usual mechanics resulting in a system response much like growing corns to protect against shoes that pinch instead of allowing better shoes to “emerge”.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1024x826.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1024x826.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1024x826.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-300x242.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-768x620.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1070x863.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment.jpg 1490w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1024x826.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-300x242.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-768x620.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment-1070x863.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/coevolving-systems-and-environment.jpg 1490w"></figure>
<p>The evolutionary pressure is also intense because there is no sense of hierarchy in our microservice architecture. The entire complexity of the domain is laid bare all at once to everyone. While upstream-downstream relationships can be inferred between domains looking at data and call flow, there is no concept of hierarchy of ideas that can simplify comprehension for new users.</p>
<p>So while domains are the building blocks of our systems, we have not yet managed to layer these building blocks in layers of increasing complexity in representation and function.</p>
<h3>Domain Modelling is Hierarchical</h3>
<p>Bounded contexts are the philosophical building blocks of microservice architectures. If we want to layer our architecture, we need to layer our concepts. And as you might imagine, this is not difficult at all! We have the entire organization’s structure to be inspired, and since domain driven systems tie in very closely with how organizations are organized, there is plenty of opportunity to copy-paste.</p>
<p>Our organization’s structure clearly tells us that a “domain” can mean very different things at different levels of abstractions. As soon as we say “abstraction”, we know that we are in a hierarchical world.</p>
<p>If you have ever seen a junior developer try to explain a production outage to a senior manager, you know what I am talking about. The minutiae of system implementation don’t matter to the senior manager because at his level of operation, “outage due to timeout in calling payment authentication service from checkout validator service” is interpreted as “outage in checkout due to payment system”. He doesn’t care about “timeout”, “authentication”, “validator” or “service” – he cares about “checkout”, “outage”, and “payment”. The CEO doesn’t even care about “checkout” and “payment”, he probably just hears “tech” and “outage”.</p>
<p>This gives us a direct line to solving our problem – let’s bundle our bounded contexts in a way that all contexts in one group can be represented by one word. This is the reverse process of how we break down the system into microservices; a microservice-to-monolith migration, if you will.</p>
<h3>Representing domain hierarchies</h3>
<p>So we want to bundle multiple closely allied domains (physically represented by their corresponding microservices) into a single umbrella.and then those umbrellas into a larger umbrella and so on. Note that the bundling process is subjective because people can disagree with what “closely allied” means. An instinct for naming is a good guide – the collective name should not sound dissonant from the individuals.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1024x760.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1024x760.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1024x760.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-300x223.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-768x570.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1070x794.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries.jpg 1417w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1024x760.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-300x223.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-768x570.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries-1070x794.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/domain-boundaries.jpg 1417w"></figure>
<p>In the real world, a higher level domain can be represented by a separate team (Payment Coordination Team) or a separate manager at a certain level (VP, Director, Architect etc). How do we do this in the technical world? If we want to build an interface that can span across multiple internal systems and combine them into a cohesive experience wrt system vocabulary and capabilities, then we need not look farther than an API Gateway.</p>
<h3>API Gateways</h3>
<p>API gateways are used as single points of ingress and egress of data from the system. They are typically the points where administrative functions like authentication, rate limiting etc are applied. Companies often employ “public” API gateways to expose a limited subset of their tech stack to external users (external meaning any software not running on the company’s servers, including mobile apps).</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1024x938.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1024x938.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1024x938.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-300x275.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-768x703.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1070x980.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway.jpg 1462w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1024x938.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-300x275.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-768x703.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway-1070x980.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/api-gateway.jpg 1462w"></figure>
<p>The traditional role of API gateways has been that of gatekeepers of all traffic coming into the company. They are meant to be lightweight with no business logic (though they may contain minimal schema transformations), and they often expose an aggregate of the capabilities of multiple internal components as a single unit. E.g. Signing up for a website via its API gateway might create an account in the “User Service” and create a newsletter subscription in the “Newsletter Service” in one go.</p>
<h3>API Gateway as domain boundaries</h3>
<p>The backend-for-frontend we saw earlier is essentially an API gateway designed from the wrong side, i.e., by consumers of the API rather than publishers of APIs. The consumer is compelled to do so because no standard conceptual hierarchies exist for them to leverage.</p>
<p>We can apply this API gateway’s aggregation capability in an internal context to develop coarse-grained system boundaries between our microservices to model hierarchical domains. We can hide the microsevices we had previously put under the same umbrella behind an API gateway which now represents the new domain boundary. No one is allowed to call these services directly. Any capabilities that need to be exposed must be exposed via the API gateway.</p>
<figure><img src="https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1024x669.jpg" data-src="https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1024x669.jpg" alt="" data-srcset="https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1024x669.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-300x196.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-768x502.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1070x699.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries.jpg 1474w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1024x669.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-300x196.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-768x502.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries-1070x699.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/use-api-gateway-for-building-domain-boundaries.jpg 1474w"></figure>
<p>Let’s take the example of an order being created in a typical order management system. An order entity has to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/">https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/</a></em></p>]]>
            </description>
            <link>https://kislayverma.com/software-architecture/layering-domains-and-microservices-using-api-gateways/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054678</guid>
            <pubDate>Tue, 04 Aug 2020 21:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Woke Breaking Point]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054555">thread link</a>) | @hirundo
<br/>
August 4, 2020 | https://newdiscourses.com/2020/06/woke-breaking-point/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/06/woke-breaking-point/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		
		

				
		
		
		<div>

			
			<div>

				
				<div id="content">

					
	<div id="primary">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-3156">

					
					<div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p>Almost everybody has a Woke Breaking Point. A point of <em>Peak Woke</em>. Or, at least, they should.</p>
<p>There should always be a line that, once crossed, signifies to someone that the ostensibly good or noble thing they currently support has soured or, as the case may be, gone completely bad. We all know the history of the twentieth century (or, so I delude myself into believing). Certain features of the Woke ideology, even if only on its extreme fringe, show shocking potential for being a totalitarian nightmare unfolding before our eyes, especially because so many good and decent people so vigorously (and viciously) support it all of a sudden. Even the rapidity with which it is spreading is disorienting, and thus alarming.</p>
<p>I realized the importance of establishing a “Woke breaking point” the other night while discussing the bizarre defenses of our current era with a brilliant friend. We were talking about the people in our lives who have hit their Woke breaking points and those who haven’t. It struck me that many of the people in my life who remain sympathetic or outright denialist about the excesses of the Woke (Critical Social Justice) movement haven’t grappled with the possibility that it isn’t quite the noble and necessary cause that it sells itself to be.</p>
<p>What I realized is how very helpful it is for people, rather than becoming confrontational, to encourage their Woke-sympathetic friends to start identifying and naming what their non-negotiable lines will be. People’s lines will—and should—vary, but as things get increasingly extreme, they will also get crossed more and more certainly. Knowing the line has been crossed, however, takes <em>knowing there is a line</em> and&nbsp;<em>where it is</em>.</p>
<p>The question to pose, then, is simple enough: <em>What would it take for you to say that the Woke movement has gone too far?</em></p>
<p>Why should you ask this? Two reasons, given how out of hand the movement already is. First, people should be asked to grapple with the idea that things could possibly go too far, or even that they already have. Second, in circumstances like these threaten to be, everyone should stake out at least some tentative line that their current principles won’t let them cross, and they need to do this&nbsp;<em>before</em> they’ve already crossed it and been forced to defend that which they currently find indefensible.</p>
<p>This simple act of getting people to commit to their principles before they let them slip is of tremendous importance and use because of how we process our moral reasoning. We do this by <em>post-hoc rationalization</em>, meaning that we lawyer ourselves into believing we acted morally after act, which often means after we’ve already crossed the line. Drawing a clear line ahead of time, especially in a social context where accountability weighs in, makes it that much easier to see the line, bright and clear, and that much harder to cross first and rationalize after.</p>
<p>To get real about this, you shouldn’t expect this conversation to go well. It might, of course, depending on the relationship, but it’s very likely to be received defensively or with an assumption that you’ve lost your mind. So here’s some advice: Don’t expect it to go well. Don’t expect them to come around. Don’t expect them to take you seriously. Just get the question out there where they have to think about it.</p>
<p>You also don’t have to push the issue, and you shouldn’t. If you meet resistance, it’s best not to argue or damage your relationship, and you should know you won’t have to. There’s no need to force it. You can ask the question and then just leave them with it. The question will bother them basically forever if they refuse to play, and let it. Let it do its work. It’s far more important for them to grapple with than it is for you to get an answer to.</p>
<p>Then again, they might want to explore and engage. That’s even better.</p>
<p>My friend and I discussed some of the breaking points that were crossed for us and for people we know. For me, it was something between seeing unfair witchhunt-like haranguing applied to public figures I respected (falsely accusing them of racism and sexism), the subversive manipulation of language, and, especially, the brazen attacks on science coming from both the activist and scholarly communities around Critical Social Justice. This happened for me a few years ago. For my friend, it was the undeniable <em>real </em>racism and blatant double-standards at the heart of much of the Woke activist enterprise. For some of our friends, the public defense of riots in Woke language—like “whiteness is property,” so it’s okay to burn down a business—was a bridge too far. For others, it was being bullied into allyship that’s never good enough. For so many more, it’s just the outright racism.</p>
<p>Of course, I also hear from people citing the tearing down of statues (including George Washington’s), people losing their jobs, people being afraid to lose their jobs, “Shut down STEM,” people’s relationships falling apart (including otherwise healthy interracial marriages, in particular), and a wide variety of other clear signals that things have gone too far with this moral panic and the bad ideas rising to prominence within it. For more and more people, these need to stop.</p>
<p>So, the question for you is: <em>What is (or was) your Woke breaking point?</em> The question for your friends is the same. I’d love to hear them. Post them in the comments. Where did they cross the line for you?</p>
<p>Even though the conversation won’t go well, don’t be afraid to ask about this directly, because this is important. Get specific if you need to. Ask: Whose statue has to come down? Seriously, whose is the last straw? Abraham Lincoln? Martin Luther King, Jr.? Whose? What freedom has to be stripped? Due process of law? Speech? The right not to suffer cruel and unusual punishment?</p>
<p>Ask: When is enough, enough? Who has to get cancelled? Fired? How many people have to lose their livelihoods? How overt does the racism have to become? How many people have to humiliate themselves in “Antiracist” Struggle Sessions? Who has to be doxxed? Destroyed? Beaten up? Killed? Does it take a public lynching? Or would it take horrors we believed we left behind in the darker chapters of the twentieth century? Where is the uncrossable line between here and there?</p>
<p>The questions have to be asked. They’re something we have had the genuine privilege of not having to ask ourselves in a long time, and it seems like we’ve forgotten. Now, they have to be asked.</p>
<p>For one friend of mine, the line is at “real violence,” whatever that means in the present era. Perhaps it’s the kind the media isn’t spinning excuses for, maybe it means with firearms (it seems not to include the skyrocketing violent crime rates, though). At least it’s a line. At least he’s thinking about it. Another, a scholar, said the obvious perversion of his own academic field would be his last straw. It’s a bit fuzzy, but at least it’s a line and one that seems to fall far short of violence. Violence, he even said, wouldn’t be acceptable, and he’s already very uneasy with the property damage and the general mayhem. At least he’s thinking about it.</p>
<p>But, maybe it has to hit closer to home. Ask: <em>Where is the line?</em> Would it have to be personal? Do they have to be personally denounced a racist? Subjected to an “Antiracist” Struggle Session? Fire? Would it take destroying the thing <em>they</em> love? <em>Their</em> family? <em>Their</em> kids? <em>Their</em> job or career? <em>Their</em> hobby?&nbsp;<em>Their</em> life’s passion? What is it? What’s too far? We have to start asking, and it hardly matters if their breaking point is something selfish. People need to grapple with this. Even if all they can think about is themselves or their closest friends and family, at least they’re thinking about it.</p>
<p>For a close friend of mine, who is quite Woke still but not at all “all in,” we had to go quite far to find an absolute line. He has one. Should I, or other people he’s close to and knows don’t deserve it, get doxxed or start receiving credible death threats for standing up to Wokeness, that will apparently do it (does anybody deserve this, though?). Seems a little extreme to me that my own life would have to be on the line before he’d think surely this is getting out of hand, but at least he has a line. At least he’s thinking about it.</p>
<p>The people you ask should be able to find a Woke breaking point and name it, though, and if not, they need to be pressed on that point. That’s serious. They need to be asked:&nbsp;<em>what does it mean that you can’t imagine this going too far?</em> Maybe it spurs no reflection. The “right side of history” is, after all, quite the Greater Good, but even this is something they need to face up to, if it’s the case. Maybe that, at least, would get them thinking about it.</p>
<p>Again, the goal of this intervention isn’t to get anyone to change their minds. It isn’t even to get them to believe something horrible might be happening, is likely to happen later, or is even plausible in the current situation. It’s only about getting them to engage with their principles now before the machinations of motivated reasoning lead them, eventually, to excuse what they would, as of now, see as inexcusable—at least until it happens.</p>

							</section>

										<section>
						
				</section>
			

<section>

	<div>

			<div>
			<div>
				<p><a href="https://newdiscourses.com/author/jameslindsay/" rel="author">
						<img src="https://467i4x109v5x4ct3em1xgbxf-wpengine.netdna-ssl.com/wp-content/uploads/2019/12/jimspeech-120x120.png" width="120" height="120" alt="James Lindsay">					</a>
				</p>
				<div>
					<h5><span></span></h5>
					<p>An American-born author, mathematician, and political commentator, Dr. James Lindsay has written six books spanning a range of subjects including religion, the philosophy of science and postmodern theory. He is the co-founder of New Discourses and currently promoting his new book "How to have impossible conversations".</p>
						
					</div>
			</div>
		</div>
		
	</div>

</section>

<section><h5>Related Topics</h5><ul><li><a href="https://newdiscourses.com/tag/allyship/" rel="tag">allyship</a></li><li><a href="https://newdiscourses.com/tag/critical-social-justice/" rel="tag">critical social justice</a></li><li><a href="https://newdiscourses.com/tag/james-lindsay/" rel="tag">James Lindsay</a></li><li><a href="https://newdiscourses.com/tag/struggle-session/" rel="tag">struggle session</a></li><li><a href="https://newdiscourses.com/tag/whiteness/" rel="tag">Whiteness</a></li><li><a href="https://newdiscourses.com/tag/woke/" rel="tag">woke</a></li></ul></section>
						</div><!-- .post-main -->

						
					</div><!-- .entry-wrap -->

					
	
	

	
	
		
	

<!-- .comments-area -->


				</article>

				
				
			
		</main>

		
	</div><!-- .content-area -->


	<!-- .sidebar-area .widget-area -->


					
				</div><!-- .main-content -->

				
			</div><!-- .container -->

			
		</div><!-- .site-content -->

		
		
		

		
	</div><!-- .site-inner -->

	
</div></div>]]>
            </description>
            <link>https://newdiscourses.com/2020/06/woke-breaking-point/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054555</guid>
            <pubDate>Tue, 04 Aug 2020 21:13:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[License Zero: Comments on “The Truth Is Paywalled but the Lies Are Free”]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24054522">thread link</a>) | @joelellis
<br/>
August 4, 2020 | https://blog.licensezero.com/2020/08/03/truth-paywall.html | <a href="https://web.archive.org/web/*/https://blog.licensezero.com/2020/08/03/truth-paywall.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
  <p>On the off chance there’s anyone out there who still believes open software’s “funding” problems reflect something special about software, have a read through <a href="https://www.currentaffairs.org/2020/08/the-truth-is-paywalled-but-the-lies-are-free/">Nathan Robinson’s recent editor’s note, “The Truth Is Paywalled But The Lies Are Free”</a>.  Perhaps we can see in another what’s so hard to see in ourselves.</p>

<p>In my reading, the problem here is evident: black-and-white, either-or thinking.  Nathan begins his essay:</p>

<blockquote>
  <p>Paywalls are justified, even though they are annoying. … I try not to grumble about having to pay for content online, because I run a magazine and I know how difficult it is to pay writers what they deserve.</p>
</blockquote>

<p>But by the end, he’s regressed to an insoluble-sounding conflict-of-goals again:</p>

<blockquote>
  <p>Creators must be compensated well.  But at the same time we have to try to keep things that are important and profound from getting locked away where few people will see them.  The truth needs to be free and universal.</p>
</blockquote>

<p>To this I would respond, not just to Nathan, but to everyone stuck at this impasse:  Don’t worry.  You’re not stuck.  None of the above is true.</p>

<p>Creators needn’t be compensated well just because they are creators.  Creators of valuable works—works valued by others—ought to be compensated.  Creators of highly and broadly valued works ought to be compensated well.  I deserve, and shall assuredly receive, no compensation whatever for the bad musical improvizations, repetitive doodles, or unfunny, dead-end software libraries I churn out from time to time.  Everyone, including me, should be fine with this.</p>

<p>Neither must useful works of every kind cost nothing to everyone.  Even the greatest works remain manifestly irrelevant to the vast majority of people.  And there are myriad, happier mediums between $0, expensive, and exclusive, in one dimension, and effortless, inconvenient, and inaccessible, in the other.</p>

<p>I happen to believe that in most areas of creative work, and in most adjacent industries, giving more away for $0 online would improve outcomes for most players, overall.  Our business instincts and well-worn patterns haven’t quite kept up with the times, and never do.  But there is nothing inherently worse about paying a fee you can afford than enduring an inconvenience you have the time to manage.  When the works we need or want come readily available at affordable costs that we can pay, and paying is easy, there’s no great harm to access or progress or truth.  That cost many not be great.  But if a great many pay it, the results can be.</p>

<p>For those interested in economics, intellectual property, and history in the news industry specifically, I heartily recommend <a href="https://www.sup.org/books/title/?id=29452">Will Slauter’s <em>Who Owns the News?</em></a>.  You might also read up a bit on stalwart news institutions, <a href="https://en.wikipedia.org/wiki/Associated_Press">like the Associated Press</a>.  What you find might surprise you.</p>

</article></div>]]>
            </description>
            <link>https://blog.licensezero.com/2020/08/03/truth-paywall.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054522</guid>
            <pubDate>Tue, 04 Aug 2020 21:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Atlantic Files for Bankruptcy in New York]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054509">thread link</a>) | @cockpitherald
<br/>
August 4, 2020 | https://kokpitherald.com/virgin-atlantic-files-for-bankruptcy-in-new-york/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/virgin-atlantic-files-for-bankruptcy-in-new-york/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo.jpg" data-caption="Virgin Atlantic Airways Ltd. filed for Chapter 15 bankruptcy protection in the U.S.

Photo: Virgin Atlantic"><img width="696" height="392" src="https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-696x392.jpg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-696x392.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-300x169.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-1024x576.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-768x432.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-1068x601.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo-747x420.jpg 747w, https://kokpitherald.com/wp-content/uploads/2020/08/Virgin-Atlantic_Airbus-A330neo.jpg 1200w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="Virgin Atlantic_Airbus A330neo"></a><figcaption>Virgin Atlantic Airways Ltd. filed for Chapter 15 bankruptcy protection in the U.S.

Photo: Virgin Atlantic</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>Virgin Atlantic has  filed for bankruptcy protection in the US on Tuesday, being yet another major airline that uses judicial protection in the crisis. The British company founded by billionaire Richard Branson applied for Chapter 15 at the New York Bankruptcy Court.</p>



<p>“The group and its business have been adversely affected by the ongoing COVID-19 pandemic, which has caused an unprecedented near-shutdown of the global passenger aviation industry,” according to the court papers. “Global aviation was one of the first industries to be impacted by the COVID-19 pandemic and is likely to be one of the last to fully recover.”</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Virgin Atlantic is a privately held <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> company with 51% of the shares belonging to the Virgin group and 49% of Delta Air Lines. Because Virgin Atlantic has business in the US and has American investors, it is authorized to enter Chapter 15, which is a kind of Judicial Recovery for foreign companies.</p>



<p>According to the New York court website, “one of the most important objectives of Chapter 15 is to allow cooperation and communication between American courts and stakeholders with cuts from abroad.”</p>



<p>For now, it is not clear what steps will be taken by <a href="https://www.virginatlantic.com/" target="_blank" aria-label="Virgin Atlantic (opens in a new tab)" rel="noreferrer noopener">Virgin Atlantic</a>, which did not apply for the order in the British courts, where it was founded and is based.</p>



<p>It is worth remembering that the sister airline, Virgin Australia, also filed for bankruptcy and is expected to go on sale soon. Virgin Atlantic had already announced the retirement of the Jumbo Boeing 747 and Airbus A330-200 aircraft, in addition to the layoff of more than 3,000 employees due to the dramatic drop in demand.</p>



<p>Its founder, Richard Branson, was even trying to sell part of the company’s space division to save the airline.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/virgin-atlantic-files-for-bankruptcy-in-new-york/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054509</guid>
            <pubDate>Tue, 04 Aug 2020 21:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Abominable Aberration of Starlight]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054399">thread link</a>) | @mickfaraday
<br/>
August 4, 2020 | https://demystifyingscience.com/blog/aether4 | <a href="https://web.archive.org/web/*/https://demystifyingscience.com/blog/aether4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6215155d39820be63dcc"><div><p>This is the fourth installment of an ongoing saga concerning the history of the aether.&nbsp;&nbsp;Where possible, I’ve included the words of the relevant scientists that sought cause for the invisible actions-at-a-distance — light, electromagnetism, and gravity.&nbsp;&nbsp;For several thousand years, the search for mechanism centered on this mysterious, yet undetectable substance called the aether. Please start at&nbsp;<a href="https://demystifyingscience.com/blog/lifeanddeathoftheaether"><span>the beginning</span></a>&nbsp;of the story, so as to frame all that follows appropriately.&nbsp;<br></p><div><p><a href="https://demystifyingscience.com/blog/aether-part-iii"><span>Last time</span></a>, we went deep into the civil war that gripped physics over the nature of light.&nbsp;&nbsp;Wave theorists were continually thwarted by their relentless reliance on the failed analogy of light to the longitudinal waves of sound.&nbsp;&nbsp;Eventually, the triumvirate of Huygens, Young, and Fresnel brought forward the conception of light as a longitudinally propagating transverse oscillation.&nbsp;&nbsp;Even so, corpuscularists had one last ace up their sleeve: the abominable stellar aberration.</p><p>As we shall see, from here on out, the aberration of light has been a nightmare for physicists since reported in 1728.&nbsp;<a href="https://en.wikipedia.org/wiki/James_Bradley"><span>James Bradley</span></a>, a professor of Astronomy at Oxford, was attempting to measure the parallax of light on opposite sides of our planet’s orbit from a distant star.&nbsp;&nbsp;Parallax is the effect you can experience right now by focusing on these words with only one eye at a time — you notice the apparent position of the words shifts right or left of center, ever so slightly.  Parallax is due to uncentered observation.&nbsp;&nbsp;</p><p>Instead of finding parallax (which proved&nbsp;<em>extremely</em>&nbsp;small on account of the relative distances to the star vs. the diameter of the Earth’s orbit), Bradley noted something even more bizarre: He found a shift in apparent position which occurred exactly opposite parallax, out of phase by 90 degrees.&nbsp;&nbsp;The distortion of signal is extremely slight — 20 arcminutes.&nbsp;&nbsp;That is 20/3600 of a degree.&nbsp;&nbsp;Even today, the aberration is so slight that&nbsp;<a href="https://pdfs.semanticscholar.org/aaf8/968d49265cc29bb005c38a2abb3eec395255.pdf"><span>it is not taken into account when calculating star positions by NASA</span></a>.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596569313430_7559"><div><p>Bradley&nbsp;<a href="https://royalsocietypublishing.org/doi/10.1098/rstl.1727.0064"><span>discussed</span></a>&nbsp;happening upon the aberration for the first time,&nbsp;</p><p>“<em>It was chiefly therefore Curiosity that tempted me (being then at Kew, where the Instrument was fixed) to prepare for observing the Star on December 17th, when having adjusted the Instrument as usual, I perceived that it passed a little more Southerly this Day than when it was observed before.</em>”</p><p> What Bradley observed was an aberration of light that occurred only as the Earth became perpendicular to the source during its orbit about the sun. The speed of light was a hot topic, for&nbsp;<a href="https://en.wikipedia.org/wiki/Ole_R%C3%B8mer"><span>Roemer</span></a>&nbsp;had quite recently demonstrated the finite speed through his observations of Jupiter’s eclipses, which appeared early when Earth was near and later as we were far.&nbsp;&nbsp;Hence, Bradley looked at the perpendicular location of the Earth during aberration and imagined the lateral contribution of the Earth’s speed to the velocity of light.</p><p>The Earth’s orbital velocity had been known for quite some time, and&nbsp;<a href="https://www.amnh.org/learn-teach/curriculum-collections/cosmic-horizons-book/ole-roemer-speed-of-light"><span>Roemer/Huygens contributed the speed of light</span></a>&nbsp;to the calculation. From there, it was a simple trigonometric deduction, using each of these speeds as velocity vectors on a triangle to back-calculate the angle of aberration. In Bradley’s&nbsp;<a href="https://arxiv.org/pdf/1105.2305.pdf"><span>own words</span></a>,&nbsp;</p><p>“[the aberration]&nbsp;<em>proceeded from the progressive motion of light and the Earth’s annual motion in its orbit. For I perceived, that, if light was propagated in time, the apparent place of a fixed object would not be the same when the eye is at rest, as when it is moving in any other direction, than that of the line passing through the eye and object; and that when the eye is moving different directions, the apparent place of the object would be different.”</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596569313430_10300"><div><div><p>Bradley’s basic idea seems sound enough. It is often described as analogous to running in the rain. When you stand still the drops come straight down, but when you sprint into them, they appear to come at an angle (in reality you’re running into the sides of the drops so the experienced pressure vector is at an angle). This explanation put Bradley squarely in the camp of the corpuscularists. It proved quite easy to deduce the aberration when assuming a star fired a bullet-like drop of light from a given location — presuming light corpuscles like this, the angle of aberration simply described the former location of the emitted light. But the corpuscularist victory would not last long.</p><p>On the other side of the Channel, trouble was brewing. We&nbsp;<a href="https://demystifyingscience.com/blog/aether-part-iii"><span>learned last time</span></a>&nbsp;that Fresnel had essentially won the world over when he mathematically united the notions of interference from Young with the Huygen’s wave theories. One of Fresnel’s collaborators from that period was&nbsp;<a href="https://en.wikipedia.org/wiki/Fran%C3%A7ois_Arago"><span>Francois Arago</span></a>. The&nbsp;&nbsp;French corpusculist,&nbsp;<a href="https://en.wikipedia.org/wiki/Pierre-Simon_Laplace#Black_holes"><span>Pierre-Simon Laplace</span></a>, commissioned Arago to look into some astronomical matters. Laplace was quite sure that the gravity of large bodies would retard the speed of light, and so asked Arago to check it out (for this initial speculation about the interaction between of gravity and light, Laplace is often credited with being the father of Black Hole-ology).</p><p>Instead of recording gravitational effects of light, <a href="https://www.researchgate.net/publication/51891244_Rethinking_the_Foundations_of_the_Theory_of_Special_Relativity_StellarAberration_and_the_Fizeau_Experiment?_esc=publicationCoverPdf&amp;el=1_x_3&amp;enrichId=rgreq-08ff39521bc2490c799b650e1ea2be2d-XXX&amp;enrichSource=Y292ZXJQYWdlOzUxODkxMjQ0O0FTOjM0MDU5MzYzODE2NjUzN0AxNDU4MjE1MjU5NjEz">Arago found a contradiction</a> in the explanation for the aberration given by Bradley.&nbsp;&nbsp;Bradley’s reasoning relied on combining the velocity of the Earth’s orbit with that of light.&nbsp;&nbsp;Arago, however, had found that at six-month longitudinal intervals when the Earth’s motion should add or subtract from a star the most, there was <a href="https://www.mathpages.com/rr/s2-05/2-05.htm">no observable change in the predicted focal length</a> that should result from the added speed in either opposing direction.&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/2171974_Arago_1810_The_first_experimental_result_against_the_ether">In a separate experiment,</a> Arago observed the aberration through a very thick prism, which according to the corpuscularists should change the aberrational angle significantly but did not. Light’s speed appeared irreconcilably constant regardless of motion.&nbsp;&nbsp;Bradley’s vector addition was in trouble.&nbsp;&nbsp;</p><p>Arago and his colleagues tried desperately to talk themselves out of the constancy of the vacuum speed of light.&nbsp;&nbsp;They imagined, incorrectly, that perhaps there were other rays, beyond those visible, that travel at differing velocities:</p></div><p>“<em>It seems [that] ... one can only explain the observation by assuming that luminous bodies emit rays with all sorts of velocities, provided one also admits that these rays are visible only when their velocities fall between specific limits. In effect, in this hypothesis the visibility of the rays will depend on their relative velocities, and, as these same velocities determine the quantity of the refraction, the visible rays will also always be refracted in the same way.”</em></p><div><p>Arago turned to his pal, Fresnel <a href="https://skullsinthestars.com/2008/07/05/what-a-drag-aragos-experiment-1810/">to rectify the matter</a>.&nbsp;&nbsp;Fresnel imagined that the aether within the prism did not attain the speed of the prism itself, because it was only partially dragged by the object. This launched a new epic in aether history: The search for the aether drag.&nbsp;&nbsp;This topic is well worth its own post, so I’ll leave the details to our next session. Without getting too far out of sequence, we must recognize that Fresnel’s mathematical formulation of the aether drag is essentially reproduced in Einstein’s Special Theory of Relativity, which is the go-to explanation for the aberration today.</p><p>But we have to note that there remain occasionally debated inconsistencies with the relativistic interpretation of the aberration and one might even say that relativity has not quantitatively improved upon Bradley’s conception. For instance, one of the postulates of Relativity is that the speed of light is constant in all reference frames, which obviously rules out additive velocities of light. To get around this, Einstein simply kicked the can down the road to the parameter, time, saying that <a href="https://en.wikipedia.org/wiki/Time_dilation#Velocity_time_dilation">time itself expands</a> to account for Bradley’s well-documented trigonometric explanation.</p><p><a href="https://demystifyingscience.com/blog/the-physical-definition-of-time?rq=what%20is%20time"><span>Recalling</span></a>&nbsp;that time itself is a concept to relate the relative motion, or relocation, between any two bodies, one wonders what is meant by the contraction of time itself, if not that one of the reference objects’ motion has slowed.&nbsp;&nbsp;But this cannot be, for we know that under basic relativity postulates, light’s motion cannot be truly additive for an observer.&nbsp;&nbsp;We’ve known this long before relativity, beginning with Arago’s 1810 focal length experiment.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596569313430_21843"><div><p>One also wonders&nbsp;<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.6229&amp;rep=rep1&amp;type=pdf"><span>why velocity-addition explanations for the aberration</span></a>&nbsp;only make use of the orbital velocity of the Earth alone.&nbsp;&nbsp;<a href="https://ui.adsabs.harvard.edu/abs/1967AmJPh..35..817E/abstract"><span>Measurements of binary star systems</span></a>, confirm that only the Earth’s motion, not the emitter’s motion is relevant to the aberration calculation — this seems to fly in the face of corpuscular ballistic notions of light-as-particle.&nbsp;&nbsp;<a href="https://en.wikipedia.org/wiki/Edward_Eisner">Edward Eisner</a>, who first advanced the contradiction, defended the relativistic interpretation in the end of his paper.&nbsp;&nbsp;In 1967 Eisner wrote:</p><p>“<em>We have shown that the “binary star paradox” is not a paradox at all, but merely a consequence of an erroneous, but commonly accepted interpretation…The fact that we do not see myriads of widely separated binaries in wild gyration does not require any fundamental change of outlook.&nbsp;&nbsp;But it does require that the aberration should be realistically treated as the transformation between the frames of reference of two observers, not a source and an observer.”</em></p><div><p>There are several resources available for comprehending the relativistic reconciliation with these matters.&nbsp;&nbsp;<a href="http://www.mrelativity.net/CompleteNatureStellarAberration/The%20Complete%20Nature%20of%20Stellar%20Aberration.htm"><span>Here</span></a>&nbsp;is one of my favorites, which sort of side-steps Bradley’s vector-addition by swapping the combined hypotenuse speed for the speed of light.&nbsp;&nbsp;This rather ad-hoc adjustment allows the relativist to remain in congruence with the light-speed constancy for an observer.&nbsp;&nbsp;As a result, the major cathetus of the triangle, formerly the speed of light for Bradley, then represents the sun’s reference frame.&nbsp;&nbsp;Ironically, either triangle (earth position 1, earth position 2, star) is so elongated as that there is virtually no difference in length between the two legs – remember, the angle of aberration is 20/3600 of a single degree of declination to the horizon.&nbsp;&nbsp;So both calculations work, but Bradley’s elegant reasoning is absent in the …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://demystifyingscience.com/blog/aether4">https://demystifyingscience.com/blog/aether4</a></em></p>]]>
            </description>
            <link>https://demystifyingscience.com/blog/aether4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054399</guid>
            <pubDate>Tue, 04 Aug 2020 20:54:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easily Run Data Science Workflows in Slack Using Python, & AWS EKS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054303">thread link</a>) | @jacksonpollock
<br/>
August 4, 2020 | https://cto.ai/blog/easily-run-data-science-workflows-in-slack-using-python-jupyter-aws-ecs/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/easily-run-data-science-workflows-in-slack-using-python-jupyter-aws-ecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<div><p>Last month, I had the opportunity to present at the second virtual <a href="https://www.meetup.com/sfpython/events/xkwxvqybckblb/">SF Python Meetup </a>about how CTO.ai is making it easier for Python developers and Data Scientists to streamline their critical workflows in Slack. </p><p>Going into the meetup, I admittedly didn't know that much about how this community managed their workflows, but one of our prior team members Ethan had built a really awesome automation with Jupyter on top of AWS EKS. </p></div><div><p>When the meetup was announced, I found that <a href="https://twitter.com/caiussivjus?lang=en">Aly Sivji</a> was doing a 45 minute keynote about almost the exact same topic! Initially I thought, oh no, this is awkward, but then I realized it was a good opportunity to better demonstrate how developers can find efficiency in their workflows via The Ops Platform.</p><p>Here is Aly's talk from the meetup, where he does an amazing job to explain the intricacies of how to use Docker in your workflow, which is a great overview for anyone who wants to understand this process from first principals:</p></div><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/tuYgEv40s7A?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed--><div><p>Aly's talk is awesome. He goes deep into all of the important aspects of how to use Docker in your workflows and why you can benefit from containerized technology to easily customize a portable environment with your team.</p><p>Building on this, the talk I did was intended to demonstrate how CTO.ai is making these sorts of workflows dead simple, while also enhancing this natural paradigm with increased portability / accessibility / transparency - via Slack. We bring 12 factor application principals via Secrets, Configs, Logs, Events and (very soon) Metrics that "just work" for anyone who wants to streamline their team workflows.</p><p>Here is the talk I did which shows a similar process of creating a Jupyter playbook on AWS EKS / Kubernetes from Slack, in about 5 minutes total.</p></div><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/6OfR6p_j2A0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed--><p>Both of these presentations show the power of Cloud Native workflows when it comes to streamlining the developer experience for teams, especially for complex tasks, that often need to leverage the exponential compute power of the cloud.</p><div><p>At the same time, you can see how complex these workflows can be when adopted from first principals, relative to how easy they can be with an approach like CTO.ai, which is purpose built for empower the developer experience, is used in your team.</p><p>Our goal is to save developers times and help them be more focused on the most meaningful work that they can deliver, in turn driving more success for their team and their own careers. This is what we think of as 10x development. </p></div><blockquote>10x development is helping 5 people be 2x more successful.</blockquote><div><p>If you have any questions about this or have some ideas for interesting Data Science workflows, please feel free to send me a message via our <a href="https://cto.ai/community">Slack Community</a>.</p><p>We're really excited about how we can do more workflows like this for Data Science use cases, so we'd love to collaborate with you if you have some ideas!</p></div>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/easily-run-data-science-workflows-in-slack-using-python-jupyter-aws-ecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054303</guid>
            <pubDate>Tue, 04 Aug 2020 20:44:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ARM MacBook will not be $799]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24054080">thread link</a>) | @handlingelect
<br/>
August 4, 2020 | https://www.staticcatgames.com/2020/08/ARM-MacBook-will-not-be-799.html | <a href="https://web.archive.org/web/*/https://www.staticcatgames.com/2020/08/ARM-MacBook-will-not-be-799.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/7trv8KWD7oA" width="320" youtube-src-id="7trv8KWD7oA"></iframe></p><p>Yes, I know Linus was just reporting on the <a href="https://twitter.com/komiya_kj/status/1286898274427756544" target="_blank">ever circulating rumours</a> that the new ARM MacBook MIGHT be $799. Not WILL be $799. We haven't heard anything from Apple yet, so it's always best to keep an open mind.&nbsp;</p><p>The problem I have with Apple is that they have a very strange sense of what constitutes as value nowadays. And don't hate on me, either, I've been using Macs for decades. I've owned everything from a Classic, Plus and 2CX to an iMac and a MacBook Pro. I've gotten used to their stubborn attitude and no-compromises way of doing things. It's how they roll.&nbsp;</p><p>While that may not be a bad thing for getting other companies to adopt new technologies and making them mainstream in the process (such as getting rid of floppy disk drives in the original iMac or their adoption of Thunderbolt 3), their behaviour lately has confused me somewhat.&nbsp;</p><p>I was excited about the possibility of AMD-based Macs and what this could mean for the lower end of their range. A Ryzen based MacBook Pro 13" would have been superb (especially with Renoir). A refreshed Ryzen based MacBook could have been sublime.&nbsp;</p><p>Not only that, but think of the possibilities in their desktops: a Threadripper based Mac Pro makes me drool quicker than Homer Simpson.&nbsp;</p><p>I seem to be going round the garden path.&nbsp;</p><p>Apple know how to extract the maximum value from a product or service wherever possible. I don't think this means lower pricing, only higher profits. Take the new iPhone SE, for example. This uses tech and design from other models mashed together for a 'value' design. In the UK, though, a 64GB model costs £419. I wonder how much lower the price could have gone? What are the margins?</p><p>This brings me to the ARM-based MacBook. Will the savings be passed onto the consumer? I have a nagging feeling that it won't.&nbsp;</p><p>The MacBook Air starts from £999 in the UK, rising to £1299 for a faster model. What will happen to this if a cheaper MacBook is released? I can't imagine Apple would want a cheaper product to cannibalise sales of this line.&nbsp;</p><p>The same goes for the iPad Pro. Would they want the ARM MacBook to cannibalise sales of this range, especially if it has better features (such as next gen USB) and longer battery life?</p><p>It will be extremely interesting to see how Apple pitches the ARM MacBook and to whom. Whether it will be affordable, too, remains to be seen.</p><p>As always, these are just my thoughts.&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://www.staticcatgames.com/2020/08/ARM-MacBook-will-not-be-799.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054080</guid>
            <pubDate>Tue, 04 Aug 2020 20:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudFront Geolocation Headers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24053312">thread link</a>) | @OwenCR
<br/>
August 4, 2020 | https://blog.owen.dev/cf-geo-headers/ | <a href="https://web.archive.org/web/*/https://blog.owen.dev/cf-geo-headers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>August 04, 2020</p></header><section><p><span>
      <a href="https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/0a47e/cloudfront.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Amazon Cloudfront Logo" title="Amazon Cloudfront Logo" src="https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/fcda8/cloudfront.png" srcset="https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/12f09/cloudfront.png 148w,
https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/e4a3f/cloudfront.png 295w,
https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/fcda8/cloudfront.png 590w,
https://blog.owen.dev/static/2660f940d80db713d9542d5c093cf74f/0a47e/cloudfront.png 600w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>

<p>Recently, Amazon Cloudfront added support for <a href="https://aws.amazon.com/about-aws/whats-new/2020/07/cloudfront-geolocation-headers/">geolocation headers.</a></p>
<p>This helps sites serve content dynamically based on where their viewers are.</p>

<p>I wanted to see what all the fuss was about and how accurate my location was based on these headers.</p>
<p><a href="https://headers.owen.dev/">So I made a demo site to see how accurate these headers are.</a></p>

<p>Here are some of my findings so far:</p>
<ul>
<li>I live in Reston, VA. When reaching the site on my ISP, it puts me in Herndon, VA – which is pretty close. </li>
<li>When using my phone, Pixel 2XL and AT&amp;T, it puts me in Baltimore – pretty far away.</li>
<li>When using an iPhone on Verizon, it only gives Country information, and gives Central time zone instead of Eastern.</li>
</ul>
<p>So Cloudfront GeoLocation headers aren’t perfect, but you can’t expect that much precision from a free product that does location lookup based on IP address.</p></section><hr></article></div>]]>
            </description>
            <link>https://blog.owen.dev/cf-geo-headers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24053312</guid>
            <pubDate>Tue, 04 Aug 2020 18:57:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Andreesen's Li Jin on Investing in the Passion Economy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24053276">thread link</a>) | @adrianalfieri
<br/>
August 4, 2020 | https://www.theproofwellness.com/li-jin-on-the-passion-economy-consumer-investing-and-writing-habits | <a href="https://web.archive.org/web/*/https://www.theproofwellness.com/li-jin-on-the-passion-economy-consumer-investing-and-writing-habits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-17e0dd95221155d90223"><p><h2><strong>Li Jin</strong></h2></p></div><div data-block-type="2" id="block-2ed2bd2018761cceb123"><div></div></div><div data-block-type="2" id="block-f4e665a7ff6961309575"><p><h3><span>On her morning routine.</span></h3></p></div><div data-block-type="2" id="block-4f5a6176352c91f35a64"><p><h3><span>On feeling claustrophobic.</span></h3></p></div><div data-block-type="2" id="block-acdaea461fd7fa0b83be"><p><h3><span>On living with her family.</span></h3></p></div><div data-block-type="2" id="block-9fbff8ee1da6ddad4f61"><p><h3><span>On launching her own VC firm.</span></h3></p></div><div data-block-type="51" id="block-0eb76ff26b8193c3475c"><div>


<div>
  <form data-form-id="5f1dcf5ff6d4d94f95553c20" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5f1dcf5ff6d4d94f95553c20',
        collectionId: '5f1dcf5ff6d4d94f95553c23',
        objectName: 'page-5f1dcf5ff6d4d94f95553c23'
      });
    });
    return false;
  })(this);">
    <header>
      
      <div><p>Get the daily habits that founders swear by.</p><p><strong>New interviews every Tuesday.</strong></p></div>
    </header>
    <div>
      <div>
        
        
          
            <p><label for="email-yui_3_17_2_1_1594313623803_16637-field">Email Address</label>
              
            </p>
          
        
          
        
      </div>
      
      
        
        
      
    </div>
    
    <p>Thank you!</p>
    
  </form>
</div>
</div></div><div data-block-type="2" id="block-b06bf02227a7eb261529"><p><h3><span>On her support system.</span></h3></p></div><div data-block-type="2" id="block-c08a14006f82032099ff"><p><h3><span>On the source of her ambition.</span></h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1596033669537_29068"><p><h3><span>On protecting personal time.</span></h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1596033669537_33067"><div><h3><span>On her evening routine.</span></h3></div></div><div data-block-type="51" id="block-1ffe2ea9c8dfe9b94229"><div>


<div>
  <form data-form-id="5f1dcf5ff6d4d94f95553c21" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5f1dcf5ff6d4d94f95553c21',
        collectionId: '5f1dcf5ff6d4d94f95553c23',
        objectName: 'page-5f1dcf5ff6d4d94f95553c23'
      });
    });
    return false;
  })(this);">
    <header>
      <h2>Upgrade your wellness.</h2>
      
    </header>
    <div>
      <div>
        
        
          
            <p><label for="email-yui_3_17_2_1_1594313623803_23757-field">Email Address</label>
              
            </p>
          
        
          
        
      </div>
      
      
        
        
      
    </div>
    
    <p>Thank you!</p>
    
  </form>
</div>
</div></div></div></div>]]>
            </description>
            <link>https://www.theproofwellness.com/li-jin-on-the-passion-economy-consumer-investing-and-writing-habits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24053276</guid>
            <pubDate>Tue, 04 Aug 2020 18:54:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magnasanti: The Largest and Most Terrifying SimCity (2010)]]>
            </title>
            <description>
<![CDATA[
Score 251 | Comments 91 (<a href="https://news.ycombinator.com/item?id=24052413">thread link</a>) | @riboflavin
<br/>
August 4, 2020 | https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/ | <a href="https://web.archive.org/web/*/https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					

					

					<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg"><img data-attachment-id="2960" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=600" title="magna" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>This picture  may appear to be a collection of color fields without meaning or  purpose, but there is a ton of math and evil genius behind this image.</p>
<p><strong>This is a view of Magnasanti, the metropolis that pushes SimCity to its population limits. </strong></p>
<p><strong><span id="more-2933"></span></strong>Here is a closer view:</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg"><img data-attachment-id="2942" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna1/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna1" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=600" title="magna1" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>Vincent Oscala, a 22-year old architecture student from the Philippines, spent years decoding the formula for success in Sim City 3000.</p>
<p>Sounds like lunacy…but his insane investment of effort into “beating” SimCity raises interesting questions about the urban landscapes we inhabit, and the ways in which they can go horribly wrong.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg"><img data-attachment-id="2944" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna2-2/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg" data-orig-size="600,825" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna2" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=218" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=600" title="magna2" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=109 109w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=218 218w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>After a massive amount of planning and a great deal of trial and error, he was able to create a city with over six million inhabitants.</p>
<p>Moreover, the city he created was remarkably stable, with no abandoned buildings and no wasted space. There are no roads — all transit is mass transit. An omniscient police force has eliminated all crime in the city. Magnasanti’s water and power needs are supplied by neighboring cities, eliminating the need for much of the related infrastructure.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg"><img data-attachment-id="2945" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna3/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna3" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=600" title="magna3" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><strong>In SimCity </strong><strong>terms</strong><strong>, it is a masterpiece.</strong></p>
<p><strong>But at the “street level,” so to speak, it looks like a horrifying dystopia. </strong></p>
<p>Unemployment is high, air pollution is stifling, education is largely absent, medical care and fire response are non-existent. Citizens do not live to reach retirement age. The police state has essentially eliminated free will and allowed the city to maximize its size while reducing quality of life to a minimum — and still maintaining total control over the citizens.</p>
<p>Every person living in Magnasanti spends his life working and residing in one small, massively efficient block of space, until death around age 50.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg"><img data-attachment-id="2946" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magnachart/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg" data-orig-size="422,438" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magnachart" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=289" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=422" title="magnachart" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg 422w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=145 145w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=289 289w" sizes="(max-width: 422px) 100vw, 422px"></a></p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg"><img data-attachment-id="2947" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magnalife/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg" data-orig-size="424,440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magnalife" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=289" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=424" title="magnalife" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg 424w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=145 145w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=289 289w" sizes="(max-width: 424px) 100vw, 424px"></a></p>
<p>Here is a video that explains some of the development process for Magnasanti, including two smaller cities that served as development prototypes for Oscala’s final achievement:</p>
<p><span><iframe width="630" height="355" src="https://www.youtube.com/embed/NTJQTc-TqpU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>As the soundtrack indicates, Oscala was highly influenced by the art film <a href="http://en.wikipedia.org/wiki/Koyaanisquatsi" target="_blank">Koyaanisquatsi</a>, or “Life out of Balance,” directed by Godfrey Reggio with music by Philip Glass.</p>
<p>Koyaanisquatsi is a non-narrative work that examines and explores the contrasts between the form and pace of nature and modern human life. Ultimately, the film confronts us with the fact that our species is living a life out of balance with nature, for better or for worse.</p>
<p>It’s a really cool movie that is highly recommended. Here’s a teaser:</p>
<p><span><iframe width="630" height="355" src="https://www.youtube.com/embed/LFBijDU8PpE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Now, you may be asking, what in the world does a game of SimCity — in an obsolete version, no less — have to teach us about a “life out of balance”?</p>
<p>Magnasanti is, first and foremost, a study in how to game SimCity to a maximum-population win condition.</p>
<p>However, I do think it raises some intriguing questions.</p>
<p>Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">comments</a>:</p>
<blockquote>
<p><strong>The film presented the world in a way I never really looked at before  and that captivated me. Moments like these compel me to physically  express progressions in my thought, I have just happened to do that  through the form of creating these cities in <em>SimCity 3000.</em> I  could probably have done something similar – depicting the awesome  regimentation and brutality of our society – with a series of paintings  on a canvas, or through hideous architectural models.</strong></p>
<p><strong>But it wouldn’t be  the same as doing it in the game, for the reason that I wanted to  magnify the unbelievably sick ambitions of egotistical political  dictators, ruling elites and downright insane architects, urban planners  and social engineers.</strong></p>
</blockquote>
<p>Australian architecture blog <a href="http://supercolossal.ch/2010/10/07/pay-to-click-get-rich-quick-urbanism-and-the-ideal-simcity/" target="_blank">Super Colossal discusses</a> some of the issues provoked by Magnasanti (link <a href="http://m.ammoth.us/blog/2010/10/magnasanti/" target="_blank">via</a>):</p>
<blockquote>
<p>This is the kind of archiporn that I am a sucker for; gamespace urbanism  exploited to its extreme condition. Can you ‘win’ urbanism? Is this  even urbanism? If not, can we take anything from its construction? The  primary move that the city makes is to remove cars altogether and base  transport purely on subways. I suspect this is a method to exploit the  space otherwise taken up by roads for real estate allowing for an  increased population per tile, however, it is a strategy that many  cities—Sydney included—are seriously looking into. Remove motor  vehicles, increase public transport. Seems like a sound idea.</p>
</blockquote>
<p>It is interesting to see a world in which the lack of cars exists alongside a lack of freedom, and indeed may even be symptomatic of it. Oscala has created a system so “sustainable” that citizens are chained to their city blocks; they’re able to access the rest of the city through mass transit, but in effect have been relieved of the need to do so by the ruthless efficiency of their cookie-cutter “neighborhoods.”</p>
<p>Maybe — all right, probably — this is effective because the game engine is warped. Super Colossal concludes that “Ultimately, Magnasanti has little to do with urban design and everything to do with gaming systems for maximum&nbsp;reward.”</p>
<p>I can’t help but think that Magnasanti represents a semi-realistic dark side of centralized urban planning: the tools of modern construction and city planning as wielded by a despotic madman bent on maximizing population at any cost. Creativity, vibrancy and nature itself are cast away as a focus on efficiency and the bottom line are elevated to a religion and a science.</p>
<p>And of course, the police force are ever-present, just in case disorder begins to stir.</p>
<p>As Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">explained in an interview with Viceland</a>, Magnasanti represents a “cage” in which he has imprisoned six million “economic slaves”. He <a href="http://images.shareapic.net/images7/022530174.jpg" target="_blank">utilized the geometry</a> of the Buddhist Wheel of Life and Death as further symbolic comment on the topic.</p>
<blockquote><p><strong>Technically, no one is leaving or coming into the  city. Population growth is stagnant. Sims don’t need to travel long  distances, because their workplace is just within walking distance. In  fact they do not even need to leave their own block. Wherever they go  it’s like going to the same place. </strong></p>
<p><strong>There are a lot of other problems in the city hidden under the  illusion of order and greatness: Suffocating air pollution, high  unemployment, no fire stations, schools, or hospitals, a regimented  lifestyle – this is the price that these sims pay for living in the city  with the highest population. It’s a sick and twisted goal to strive  towards. </strong></p>
<p><strong>The ironic thing about it is the sims in Magnasanti tolerate  it. They don’t rebel, or cause revolutions and social chaos. No one  considers challenging the system by physical means since a  hyper-efficient police state keeps them in line. They have all been  successfully dumbed down, sickened with poor health, enslaved and  mind-controlled just enough to keep this system going for thousands of  years. 50,000 years to be exact. They are all imprisoned in space and  time.</strong></p></blockquote>
<p>The <a href="http://m.ammoth.us/blog/2010/10/magnasanti/" target="_blank">Mammoth blog</a> calls Magnasanti “An intentionally hellish vision which exploits the game’s internal logic as commentary.”</p>
<p>Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">adds </a>that “if we make maximizing profits the absolute objective, we fail to take  into consideration the social and environmental consequences.”</p>
<p><strong>At the very least, it’s delicious food for thought for would-be urban planners and simulation gamers.</strong></p>
<p>Further reading and sources:<strong><br>
</strong></p>
<p>Viceland: <a title="Permanent Link to The Totalitarian Buddhist Who Beat Sim City" rel="bookmark" href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/">The Totalitarian Buddhist Who Beat Sim City</a><br>
Mammoth: <a href="http://m.ammoth.us/blog/2010/10/magnasanti/#" target="_blank">Magnasanti</a><br>
Super Colossal: <a rel="bookmark" href="http://supercolossal.ch/2010/10/07/pay-to-click-get-rich-quick-urbanism-and-the-ideal-simcity/" target="_blank">Pay to Click Get Rich Quick: Urbanism and the Ideal SimCity<br>
</a>Imperar’s Millionaire Experiment: <a href="http://imperar.blogs.linkbucks.com/who-is-imperar/" target="_blank">Who is Imperar?</a></p>
<p>Mildly related: <a href="http://en.wikipedia.org/wiki/The_Power_Broker" target="_blank">The Power Broker</a> and <a href="http://en.wikipedia.org/wiki/The_Death_and_Life_of_Great_American_Cities" target="_blank">The Death and Life of Great American Cities</a></p>
			
			
			
					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/"
    dc:identifier="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/"
    dc:title="Magnasanti: The Largest and Most Terrifying&nbsp;SimCity"
    trackback:ping="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/trackback/" />
</rdf:RDF>					-->

				</div></div>]]>
            </description>
            <link>https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24052413</guid>
            <pubDate>Tue, 04 Aug 2020 17:34:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laissez Faire Leadership for Startups]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24052230">thread link</a>) | @stewartma
<br/>
August 4, 2020 | https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/ | <a href="https://web.archive.org/web/*/https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-235">
	

	<div>
		
<p>Laissez Faire Leadership is a form of leadership that offers many benefits for startups. In fact, if you currently work at a startup, you’re likely practicing a laissez-faire management style without even realizing it! In this article, we’ll briefly cover what laissez-faire leadership is and three benefits that it can bring to your startup.</p>



<h3><strong>What is Laissez Faire Leadership?</strong></h3>



<p>Laissez-faire leadership is a hands-off management style based on trust and is the direct opposite of micromanagement. Laissez-faire managers set clear visions and give their direct reports autonomy to make decisions in whatever way they best see fit.</p>



<p><em>Fun fact: </em><a href="https://www.paulallen.com/"><em>Paul Allen</em></a><em>, co-founder of </em><a href="https://www.microsoft.com/"><em>Microsoft</em></a><em>, is known for taking a hands-off, or laissez-faire, approach to management. Other famous laissez-faire leaders include <a href="https://en.wikipedia.org/wiki/Warren_Buffett">Warren Buffett</a>, founder of Berkshire Hathaway, and <a href="https://www.businessoffashion.com/community/people/donna-karan-4">Donna Karan</a>, founder of DKNY.&nbsp;&nbsp;</em></p>



<p>Before we cover the advantages of laissez-faire leadership for startups, it’s worth mentioning why some are opposed to this leadership style. Those who oppose it prefer a hands-on, involved approach and wish to be closely involved in project implementations. Others find that a laissez-faire approach leads to time mismanagement, especially when there is a lack of accountability amongst team members.</p>



<p>Although those qualms are valid, we still believe that most startups would benefit from laissez-faire leadership. Next, we’ll cover the 3 biggest benefits laissez-faire leadership brings to startups.</p>



<h3><strong>Benefit 1: Empowers employee creativity</strong></h3>



<figure><img src="https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon.jpg" alt="Blue Lemon Creativity" srcset="https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon.jpg 640w, https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>Laissez-faire leaders bestow trust and autonomy onto employees and give them free reign to learn through trial and error. In other words, they give their teammates goals and freedom to achieve those goals.</p>



<p>When given the freedom to make decisions, employees tend to be more creative because they aren’t simply handed a “right answer”. Creativity is important and is increasingly <a href="https://www.ideou.com/blogs/inspiration/why-creativity-is-more-important-than-ever">a competitive advantage</a> for startups, especially as they battle large incumbents like Google and Amazon. </p>



<p>Ambitious startups thrive on innovation, rapid iteration, and new ideas, making laissez-faire leadership a great fit for any fast-growing company.</p>



<h3><strong>Benefit 2: Attracts employees who thrive in fast-paced, dynamic environments</strong></h3>



<p>Paul Graham <a href="http://www.paulgraham.com/growth.html">famously notes</a> that “a startup is a company designed to grow fast.” Employees who effectively deal with ambiguity and who are fast learners are more likely to thrive in the dynamic, fast-paced nature of startups.&nbsp;Such employees likely chose to work at startups because they thrive in unpredictable environments and wouldn’t do well with overly-prescriptive management styles.</p>



<p><a href="https://blog.cadencework.com/daily-standups-asynchronous-communication/">Micromanagement has no place</a> in an environment like a startup, where growth and changes are the only constants. In such environments, micromanagers would be bottlenecks to growth, as work would be inhibited unless their directives were given. Instead, startups value resourcefulness and autonomy, two values that laissez-faire leaders encourage.</p>



<h3><strong>Benefit 3: Is </strong>suitable<strong> for remote work</strong></h3>



<figure><img src="https://blog.cadencework.com/wp-content/uploads/2020/08/yellow.jpg" alt="Remote work keyboard" srcset="https://blog.cadencework.com/wp-content/uploads/2020/08/yellow.jpg 640w, https://blog.cadencework.com/wp-content/uploads/2020/08/yellow-300x205.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>As a result of the coronavirus pandemic, most companies have implemented <a href="https://www.forbes.com/sites/zackfriedman/2020/07/27/google-amazon-facebook-microsoft-twitter/#bce4cb235c8b">work-from-home policies until 2021</a>. As these companies work remotely, many realize that given different working hours and timezones, it’s no longer realistic to equate online presence with productivity. Rather, the more productive approach is to focus on output and results. </p>



<p>Laissez-faire leaders empower remote teams to thrive because they don’t need to force employees to install intrusive tracking software in order to feel confident that work is getting done. Instead, they delegate, set tangible milestones, unblock teammates as necessary, and trust that they will accomplish those goals. This allows employees to execute on their current projects in whatever way works best for them.</p>



<h3><strong>Laissez-Faire Leadership is Great for Startups</strong></h3>



<p>Ultimately, laissez-faire leadership empowers employee creativity, attracts employees who thrive in fast-paced environments, and is suitable for remote work. Startups looking to differentiate themselves and stay competitive should consider implementing this style of leadership.</p>
	</div>

</article></div>]]>
            </description>
            <link>https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24052230</guid>
            <pubDate>Tue, 04 Aug 2020 17:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When your bank helps your scammers – How I lost $5k]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24052088">thread link</a>) | @ZainRiz
<br/>
August 4, 2020 | https://davidvargas.me/blog/i-got-scammed-out-of-5k/ | <a href="https://web.archive.org/web/*/https://davidvargas.me/blog/i-got-scammed-out-of-5k/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>You might feel sympathetic for me after reading the title. I promise that after reading all the mistakes I made, you will come to the conclusion that my dumbass deserved to get scammed.</p>
<p>I was looking to sell a bed and a dresser in an effort to purge my apartment of belongings before moving out of New York City. After reaching out to several groups of people, I was having no luck. I was even willing to give it away for free given that it went to someone I trusted. With my anxiety surrounding the situation increasing and the move out deadline approaching, I decided to heed my coworkers advice to put the items on Craigslist. It was the first and last time I ever will use that janky excuse of a website.</p>
<p>Only a day after posting my items up I got an email from a potential buyer! An immediate sigh of relief left my stomach. Wow, I can’t believe people still actually use this site! Though when I opened the email, I became skeptical:
</p><figure>
    <span>
      <a href="https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/111fd/email.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="_Email for Bed_" title="_Email for Bed_" src="https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/fcda8/email.png" srcset="https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/12f09/email.png 148w,
https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/e4a3f/email.png 295w,
https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/fcda8/email.png 590w,
https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/efc66/email.png 885w,
https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/c83ae/email.png 1180w,
https://davidvargas.me/static/4cb0db93bd08a494fea1e01bfcc1e57e/111fd/email.png 1831w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption><p><em>Email for Bed</em></p></figcaption>
  </figure>
There are a few things wrong with this email:
<ul>
<li>That “from” address looks suspicious. I chalked it up to how Craigslist automation works, in line with how shitty the rest of the site looks</li>
<li>Punctuation is a mess. Noted, stay vigilant</li>
<li>“Text me at email@address.com” That doesn’t make sense</li>
</ul>
<p>Still, with my desperation to get this bed out the door, I decided to email mister Sebastian anyway and see where it goes. Once I did, I mysteriously got a reply back, from a different email, from a Mrs. Janice Bishop. I reasoned that  Sebastian is some Craigslist scout that scrapes the site for his clients and forwards them the details when a match is found. Whatever.</p>
<p>In the middle of the exchange, I get this mysterious message from Janice:</p>
<blockquote>
<p>I instructed my Financial to mail out the payment including the mover funds. Hope i can also trust you with the mover funds? &amp; you will keep to your words.</p>
</blockquote>
<p>Wait. Why am I being responsible for the mover funds? If she’s coordinating the move, why didn’t she just pay them directly? I start to come to the conclusion to have sympathy for my not very intelligent buyer, and should just be accommodating since getting rid of my bed was top priority.</p>
<p>In parallel, I received another email from Sebastian, this time for the dresser. Given how I was able to quickly connect with Janice, I felt I could trust this guy to get me the second buyer and BOOM, problem solved! Both pieces of furniture will be gone! So I responded and my buyer for the dresser is a Mrs. Wislania Ribeiro. These names just feel like they were cranked from a random name generator on the internet. Anyway, after some back and forth, she sent me this message:</p>
<blockquote>
<p>Once you receive the payment, you are to go ahead and Deposit/Withdraw the movers fund! </p>
</blockquote>
<p>This feels very fishy. Two independent buyers, both asking me to be responsible for the movers fund? I reason that Sebastian handles both the Craigslist scouting and the furniture moving, so this was just how he ran his business. I’m on high alert now. Or so I thought.</p>
<p>Checks for both pieces of furniture arrive in the mail about 24 hours from each other for about $2500. Let me repeat that. $2500!! For a bed and dresser that I’m selling for $300 each! Who the fuck would pay a mover $2200 for a piece of furniture they bought for $300?! The checks also look absurdly fake. Here are the two for the bed:
<span>
      <a href="https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/03bcf/bedCheck1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="bedCheck1" title="bedCheck1" src="https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/fcda8/bedCheck1.png" srcset="https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/12f09/bedCheck1.png 148w,
https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/e4a3f/bedCheck1.png 295w,
https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/fcda8/bedCheck1.png 590w,
https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/efc66/bedCheck1.png 885w,
https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/c83ae/bedCheck1.png 1180w,
https://davidvargas.me/static/a823cbb0787858aeebe13ffa1d857ba5/03bcf/bedCheck1.png 1653w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
<span>
      <a href="https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/1e5d2/bedCheck2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="bedCheck2" title="bedCheck2" src="https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/fcda8/bedCheck2.png" srcset="https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/12f09/bedCheck2.png 148w,
https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/e4a3f/bedCheck2.png 295w,
https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/fcda8/bedCheck2.png 590w,
https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/efc66/bedCheck2.png 885w,
https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/c83ae/bedCheck2.png 1180w,
https://davidvargas.me/static/d0ab74ddf6ef5c9a3927284045b116f5/1e5d2/bedCheck2.png 1630w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
And the one for the dresser:
<span>
      <a href="https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/e894c/dresserCheck.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="dresserCheck" title="dresserCheck" src="https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/fcda8/dresserCheck.png" srcset="https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/12f09/dresserCheck.png 148w,
https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/e4a3f/dresserCheck.png 295w,
https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/fcda8/dresserCheck.png 590w,
https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/efc66/dresserCheck.png 885w,
https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/c83ae/dresserCheck.png 1180w,
https://davidvargas.me/static/fcd680b2734064aed218a5e4cbe740e9/e894c/dresserCheck.png 1669w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
Nothing about where these checks came from, the memos, the signatures, or the banks make any sense. However, given how paranoid the buyers were about whether or not <em>I</em> could be trusted, and given that I assumed they weren’t very reasonable people, I decided that it wouldn’t be worth questioning them on these checks. Instead, I decided to mobile deposit these checks, on the assumption that if they were fake, they wouldn’t clear. If they did clear, then worst case scenario, my buyers are getting scammed by the moving company and <strong>I was safe</strong> because it was <strong>their money being lost</strong>. Oh Vargas, how naively incompetent you are.</p>
<p>Ok, so I deposit the checks, and wait for them to be moved from pending from my Citibank account. And they did!
<span>
      <a href="https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/63208/checksPosted.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="checksPosted" title="checksPosted" src="https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/fcda8/checksPosted.png" srcset="https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/12f09/checksPosted.png 148w,
https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/e4a3f/checksPosted.png 295w,
https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/fcda8/checksPosted.png 590w,
https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/efc66/checksPosted.png 885w,
https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/c83ae/checksPosted.png 1180w,
https://davidvargas.me/static/6887efe7abeb7b1edaa4c5f4e911a900/63208/checksPosted.png 2105w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
This right here is the biggest incorrect assumption I made that was my downfall. <strong>Just because a check is no longer pending, doesn’t mean it’s been cleared.</strong> I didn’t understand this at the time, but distracted by my excitement to have buyers interested in getting this furniture out of my apartment I didn’t bother doing any further research into it. From this point forward, I’m operating under the assumption that their money is safe in my account and I’m dealing with someone else’s money.</p>
<p>Once I give Janice Bishop (bed) the heads up that I have the money safe into my account, she gives me the CashApp accounts that I am to forward the moving expenses to. What. If you had the CashApp accounts already, why the hell did you send me the checks? Why didn’t you just CashApp them directly? Whatever, I’m dealing with a moron, let me just be accommodating. I CashApp the money to a Sabrina Gudish, again another name that feels like it was generated by robots. I have a similar experience with Wislania Ribeiro (dresser), except she directed me to Zelle the money to a Giselle Marie Mendoza. There’s definitely some psychological effect here at play with all of these names being female sounding.</p>
<p>Saturday July 25th hits, and it’s pickup day for the bed. Janice Bishop texts me, <strong>on a different number</strong>, asking if I could do her a favor and send the movers an extra $200. She is insistent that the movers refuse to come pick up my bed until they have the $200 and that she will reimburse me with another check once it’s picked up. Nothing about this makes sense. I tell her that I will take out cash since I hit my CashApp weekly limit. She offers this brilliant workaround to the CashApp problem: I should go to my local store, buy <a href="https://store.steampowered.com/digitalgiftcards/">Steam gift cards</a> and send the codes to the movers. WHAT?!</p>
<p>No business I’m comfortable dealing with accepts gift cards as transactions. I tell her no. I have cash for the pickup, I’ll give it to the movers when they come. She gets aggressive:
<span>
      <a href="https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/302a4/purchase.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="purchase" title="purchase" src="https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/fcda8/purchase.png" srcset="https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/12f09/purchase.png 148w,
https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/e4a3f/purchase.png 295w,
https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/fcda8/purchase.png 590w,
https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/efc66/purchase.png 885w,
https://davidvargas.me/static/c56fc07a1e2a065a1b54ca396602765f/302a4/purchase.png 1080w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
As if now I’m being unaccommodating. I ask her if she could just send them the money or gift cards directly, but “she’s at work”. I call her, and a Google Voice picks up before going to voicemail. Red flags are parading my mind like a high school marching band. </p>
<p>I consult my friends, and they tell me not to buy the gift cards. But with the risk of my bed still being in my apartment when the move out time hits, I start to panic. I’m pacing my room not knowing what to do. I finally convince Janice Bishop, after about an hour of incoherent back and forth conversation, to give me the phone number of the moving company. Her phone number was (858) 375-9301 and the mover’s number was (858) 375-6028. THE FIRST 6 DIGITS WERE THE SAME! Guess what happened when I called it? Another Google Voice before going to voicemail. Texting the mover, they give me this Trump-esque response:
<span>
      <a href="https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/d5bfb/trump.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="trump" title="trump" src="https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/fcda8/trump.png" srcset="https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/12f09/trump.png 148w,
https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/e4a3f/trump.png 295w,
https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/fcda8/trump.png 590w,
https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/efc66/trump.png 885w,
https://davidvargas.me/static/723b0f3b16baf436d6a8e2bc24441418/d5bfb/trump.png 1072w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
At this point I’ve lost all sense of rationality. I figured that I had already sent over $4400 of “their” money, what’s another 200? I go to a RiteAid and buy the gift cards. Maybe there’s a shot in the dark this move still happens. I grab on to this inspiring glimmer of hope:
<span>
      <a href="https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/302a4/hope.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="hope" title="hope" src="https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/fcda8/hope.png" srcset="https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/12f09/hope.png 148w,
https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/e4a3f/hope.png 295w,
https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/fcda8/hope.png 590w,
https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/efc66/hope.png 885w,
https://davidvargas.me/static/4fe1787248693032d0a8917b7533a60a/302a4/hope.png 1080w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
My mom calls me that night to see how I’m doing. I decide to go over all of the nonsensical details that have transpired so far. As they leave my mouth for the first time with a third party, I start to recognize how insane the decisions I’ve made were, stumbling over my words. You know, that moment when you have to explain something to your mom when you know you’re in trouble? She even asked me if I’ve been drinking, a ludicrous question once you know I quit 8 months ago. She became concerned for my safety when I told her that I was sure that the checks cleared and it wasn’t my money that I was free wielding. We end the call on the agreement to do some research on the subject and reconnect in a half hour.</p>
<p>I stumble upon <a href="https://www.thestreet.com/personal-finance/craigslist-scams-14707309">the fifth bullet on this site on fake checks</a> and start sweating profusely. Scrambling over to my bank statements, my jaw lands on my keyboard when I see:
<span>
      <span></span>
  <img alt="bounce" title="bounce" src="https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/fcda8/bounce.png" srcset="https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/12f09/bounce.png 148w,
https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/e4a3f/bounce.png 295w,
https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/fcda8/bounce.png 590w,
https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/efc66/bounce.png 885w,
https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/c83ae/bounce.png 1180w,
https://davidvargas.me/static/2386456c894d4b58b88245e6b86b6fb0/b6c94/bounce.png 1429w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span>
Fuck. This is the first of the three checks bouncing. I let my mom know when we reconnect, and she breathes a sigh of relief that this implies my safety is not in jeopardy and it’s just money I lost. I text Janice Bishop about her check bouncing and she of course plays dumb, asking for a screenshot. Probably so that scammy little shit could revel in their victory. Pour salt in the wound.</p>
<p>No one ever comes for the furniture. I don’t even bother following up with Wislania Ribeiro for the dresser. In the next week, the other two checks eventually bounce. I contact citibank, Zelle, and Cashapp to see if there’s anything I could do to recoup this money, but these were cash transfers that I authorized. They are meant to be sent to trusted parties. I lost the money for good. </p>
<h2>Takeaways</h2>
<p>I’m not too upset about losing the money. My mom wired me the money I lost because she’s a wonderful woman and I love her dearly. But even if she didn’t, I had enough in my savings to cushion the blow and worst case scenario some of my long term goals get delayed a month or two. To help me feel better, I reasoned that the person who scammed me was in a much less financially secure position than I was, and hoped that the money could make a substantial impact on their life. </p>
<p>I am extremely upset about two other realizations. One, that I wasted so much time dealing with these scums. Two, and more importantly, that I still had the capacity to be so ignorant and make such negatively consequential mistakes. My only solace in this realization is some of the larger lessons I learned and can share with the world.</p>
<p><strong>Listen to the alarms.</strong> Throughout this whole process, enough …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidvargas.me/blog/i-got-scammed-out-of-5k/">https://davidvargas.me/blog/i-got-scammed-out-of-5k/</a></em></p>]]>
            </description>
            <link>https://davidvargas.me/blog/i-got-scammed-out-of-5k/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24052088</guid>
            <pubDate>Tue, 04 Aug 2020 17:09:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Visual Object Tracking]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24051700">thread link</a>) | @elbelcho
<br/>
August 4, 2020 | https://teleidoscope.com/blog/better-visual-object-tracking/ | <a href="https://web.archive.org/web/*/https://teleidoscope.com/blog/better-visual-object-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Better Visual Object Tracking</h2><p><em>Balancing speed, accuracy, and robustness</em></p><p>July 28, 2020</p><p>Visual Object Tracking, or <strong>tracking</strong> for short, is a fundamental component of autonomous vision systems. It allows machines to follow regions of interest through a series of images. </p><p>Because of their resource efficiency Region Of Interest Trackers (KCF, CSRT, THOR, RAD, etc) have become a very popular approach to visual object tracking.</p><p><strong>Many modern trackers prioritize speed and accuracy at the expense of robustness.</strong></p><p><img src="https://teleidoscope.com/assets/drawing1-75.png" alt="drawing" width="70%"></p><p>At Teleidoscope, we’ve developed our own tracker (RAD) that attempts to address all three.</p><p><iframe data-src="https://player.vimeo.com/video/442186954?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><p><strong>Note:</strong> Performance in video above is impacted by visualization view rendering. See videos below for more accurate representation.</p><h2>The Balanced Tracker</h2><p>A balanced tracker balances the following attributes:</p><ol><li><strong>Speed</strong> - <em>How <strong>fast</strong> can it produce an estimate</em></li><li><strong>Accuracy</strong> - <em>How <strong>precisely</strong> it estimates the location of the object for a wide variety of objects</em></li><li><strong>Robustness</strong> - <em>How <strong>reliably</strong> it handles difficult conditions without losing the objects</em></li></ol><p>The impact one attribute has on the others varies by implementation but in general the following is often true.</p><ul><li><strong>Speed</strong> can be traded for <strong>Accuracy</strong> or visa-versa</li><li><strong>Accuracy</strong> can be traded for <strong>Robustness</strong> or visa-versa</li></ul><p>It makes sense that speed and accuracy are prioritized considering that’s what trackers are usually supplementing. But it doesn’t explain why robustness is hurt in the process.</p><p>The impact to robustness lies in how trackers determine whether or not they’re still tracking an object. Most trackers take a pass/fail approach and compare a confidence score to some fixed threshold to determine if their object is <strong>tracked (pass) or lost (failed).</strong></p><p>This approach can lead to problems because the range of possible scores differs between objects. This forces many trackers to choose between a <strong>high threshold which increases spurious failures</strong> or a <strong>low threshold</strong> <strong>which increases the chance of drifting</strong>.</p><p>The latter is usually chosen because it allows a wider variety of objects to be tracked accurately with this approach. However, this assumption can cause issues in unexpected ways, as demonstrated below.</p><p><iframe data-src="https://player.vimeo.com/video/441419592?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><p><strong>Speed <em>and</em> Accuracy and Robustness</strong></p><p>In the video above, the combination of rapid scaling and background perspective change resulted in CSRT scaling incorrectly and not realizing it had drifted.</p><p>Many autonomous systems (e.g drones) rely on correct status reporting to determine if they need to perform more computationally expensive recovery tasks such as detection. If the tracker fails to often (high threshold), resources are wasted and if it doesn’t detect true failures (low threshold), drifting occurs. The latter can have severe affects on autonomous systems because they won’t know anything is wrong.</p><p>This make it clear that robustness is equally important as speed and accuracy. This of course makes the task of balancing a tracker very difficult.</p><p><strong>This is where Teleidoscope’s RAD (Relocalizable Adaptive Discriminative) Tracker comes in.</strong></p><p>RAD auto-calibrates to each object instead of using fixed implementation specific thresholds allowing it to report when tracking becomes unstable and recover itself when it does.</p><p>This allows RAD to track and recover, even in situations where there is very little scene detail.</p><p><iframe data-src="https://player.vimeo.com/video/441420068?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><br><h3>Teleidoscope’s Visual Object Tracking Framework</h3><p>The RAD tracker is at the core of Teleidoscope’s visual tracking framework which was designed with these issues in mind. Recovery and self-diagnostics are just some of the features that set RAD apart. Designation options for RAD can be seen in the below diagram and will be covered in a future post.</p><p><img src="https://teleidoscope.com/assets/drawing.png" alt="drawing" width="100%"></p><p> For more information, please reach out to <a href="mailto:contact@teleidoscope.com">contact@teleidoscope.com</a>.</p><hr><ul><li></li><li><a rel="next" href="https://teleidoscope.com/blog/better-target-designation-tracking-for-uavs/">Better Target Designation &amp; Tracking for UAVs<!-- --> →</a></li></ul></div></div></div>]]>
            </description>
            <link>https://teleidoscope.com/blog/better-visual-object-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051700</guid>
            <pubDate>Tue, 04 Aug 2020 16:38:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may finally use JSHint for evil]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24051655">thread link</a>) | @catacombs
<br/>
August 4, 2020 | http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/ | <a href="https://web.archive.org/web/*/http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

<p><strong>This is the first essay in <a href="http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/">a four-part series about relicensing the JSHint
software project</a>.</strong></p>

<p>The process of relicensing JSHint took seven years. That’s far longer than
anyone expected, but seeing this through wasn’t just a matter of endurance. As
I worked with people around the world to move to the MIT Expat license, I
regularly experienced how non-free licensing (even as seemingly trivial as
“Good, not Evil”) poisons the well of free software.</p>

<p>Some numbers might help here. The following graph shows how many times JSHint
has been downloaded from <a href="https://docs.npmjs.com/">npm</a> each week over the past
five years:</p>

<p><img src="http://mikepennisi.com/blog/jshint-watching-the-ship-sink-graph-1.png" alt="JSHint downloads over time"></p>

<p>We had a dip last year, but we’ve since recovered and then some. Over half a
million downloads per week sure sounds impressive, doesn’t it?</p>

<p>It <em>was</em> impressive in 2015. The fact is, npm’s usage has exploded over the
past half decade. Holding steady in this space is actually falling behind. Take
a look at the same statistic for <a href="https://eslint.org/">ESLint</a>, a truly open
source project with the same purpose and target audience as JSHint:</p>

<p><img src="http://mikepennisi.com/blog/jshint-watching-the-ship-sink-graph-2.png" alt="JSHint and ESLint downloads over time"></p>

<p>Suddenly that dip in 2019 doesn’t seem so important. How did JSHint go from
being the most popular tool in this space to one that most developers today
consider antiquated? There are many explanations, but in this essay, I’ll focus
on the effects of non-free licensing.</p>

<h3 id="for-license-sensitive-users">For license-sensitive users</h3>

<p>JSHint was partly licensed under <a href="https://www.gnu.org/licenses/license-list.html#JSON">the JSON
license</a>. It is nearly
identical to the widely-used MIT Expat license, but it includes one additional
clause:</p>

<blockquote>
<p>The Software shall be used for Good, not Evil.</p>
</blockquote>

<p>Because of this clause, folks who respect the practice of software licensing
simply could not use JSHint.</p>

<p>If you’re not versed in legal matters, that probably seems like an odd
restriction. By rejecting JSHint, are people admitting that they want to do
evil? And is that clause actually enforceable, anyway?</p>

<p>The answer to the second question is “no,” and that helps answer the first
question. Legally-conscious objectors aren’t betraying their own dastardly
motivations; they’re refusing to enter into an ambiguous contract. Put
differently: they’re not saying, “I’m an evildoer,” they’re saying, “I don’t
understand what you want.” This consideration disqualified JSHint from
inclusion in all sorts of contexts.</p>

<p>First, there were legally-conscious software repositories. Developers from the
<a href="https://www.debian.org/">Debian</a> and <a href="https://getfedora.org/">Fedora</a>
GNU/Linux distributions independently concluded that they could not include
JSHint due to licensing concerns. That’s why <a href="https://ubuntu.com/">Ubuntu</a>
users can’t download JSHint via <code>sudo apt-get install jshint</code>.</p>

<p>Even in less discerning package managers, folks built tools to empower
developers to make similar decisions on their own. For instance, JSHint has
been available on <a href="https://docs.npmjs.com/">npm</a> since its initial release, but
<a href="https://spdx.org/">SPDX</a> (along with tools like
<a href="https://github.com/ironSource/license-report"><code>license-report</code></a> and
<a href="https://classic.yarnpkg.com/en/docs/cli/licenses">Yarn</a>) has since been
designed to help folks understand the legal requirements of their dependencies.
This seemed like an encouraging trend toward conscientious code sharing, so <a href="https://github.com/jshint/jshint/pull/2420">we
did our part by adopting SPDX in
JSHint</a>.</p>

<p>More recently, an instructor at a US university wrote to the JSHint team asking
for permission to use JSHint in their course. I replied,</p>

<blockquote>
<p>By all means, you are welcome to use the project and its website in your
courses. Please note, however, that the source code is partially
published under the JSON license. The FSF does not recognize this as <a href="http://www.gnu.org/licenses/license-list.html">a
free software license</a> nor
does the Open Source Initiative recognize it as <a href="https://opensource.org/licenses/alphabetical">an open source
license</a>. This detail does not
effect most people in practice, but you may want to verify with your legal
team before relying on the code base.</p>
</blockquote>

<p>Honesty may be the best policy, but it also means fewer people are going to use
your bizarrely-encumbered JavaScript linter.</p>

<p>Finally, programming platforms that “repackaged” JSHint have reconsidered that
practice because of the license issue. There was a time when the popular
content management system <a href="https://wordpress.org/">WordPress</a> repackaged JSHint
in this way. Once they learned of the JSON license, <a href="https://core.trac.wordpress.org/ticket/42850">they replaced JSHint in a
matter of weeks</a>.</p>

<h3 id="for-feature-craving-users">For feature-craving users</h3>

<p>Plenty of people don’t give a fig about free software. Whatever their reason,
they couldn’t care less about the legal terms that are bundled with
publicly-available source code. The “Good, not Evil” clause also pushed them
away, even if they didn’t realize it.</p>

<p>It began with the decline in license-sensitive users. The word “user” is a bit
too passive in the context of open source tooling because folks who use the
software are particularly empowered to contribute back to it. The “user-base”
is directly correlated to the “contributor-base.” When a project like JSHint
loses users, it also loses contributors.</p>

<p>This slows the addition of new features and the correction of bugs. Timeliness
is important for these things, and people perceive delays very negatively. The
best example of this comes from JSHint’s delayed support for async functions.</p>

<p>(The async function is a JavaScript language feature which was <a href="https://tc39.es/ecma262/#sec-intro">introduced in
2017</a>. It’s very popular among developers
but also very difficult for parsers to implement correctly. <a href="https://jshint.com/blog/2019-02-05/release-2-10-0/">It took us over a
year to support it in
JSHint.</a>).</p>

<p>Some expressed their dissatisfaction with the delay in <a href="https://github.com/jshint/jshint/issues/2604#issuecomment-342173639">calm (though somewhat
impatient)
terms</a>:</p>

<blockquote>
<p>Async/await has been at stage 4 for over a month now (and baked into Node and
many mainstream browsers for longer), but jshint has yet to add support.</p>
</blockquote>

<p>…but others were more emotional:</p>

<ul>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-329704124">“You just lost my interest in jshint. Sorry, to [sic]
slow.”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-331985362">“Thank you JSHint. It was good while it lasted. Switched to
ESLint.”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-340112372">“RIP
Jshint”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-455643712">“Seems like we waited enough. Bye JSHint. It was a good
time.”</a></li>
<li>“I know that you get a lot of complaints about this, but… if you can’t find
a way to include support for async/await, jshint is useless to me. I’m
switching to just using <code>node -c &lt;filename&gt;</code>” (via e-mail)</li>
</ul>

<p>The Internet has a way of surfacing the loudest and angriest perspectives, but
it seems safe to assume there was a substantial group of less vocal developers
who came to a similar conclusion.</p>

<p>A dwindling user/contributor-base is a vicious cycle. Though the movement may
have started with license-conscious folks, everyone felt the pain of the
release cycle equally, and their exodus exacerbated the problem.</p>

<p>This isn’t just a story of open-source “market” forces, though. My own
management decisions contributed to JSHint’s dissatisfying release cycle.</p>

<p>You see, many people express their dependency on software using a range of
versions. They don’t say, “give me Firefox at version 67.02.3” because they
don’t really care about that particular release. What they want is the software
to be familiar but also secure. They’re more likely to say, “give me the latest
version of Firefox 67.” With this statement, they’re trusting the maintainers
of Firefox to provide a program that looks and acts a certain way (i.e. not
exactly like version 65 or version 68) but that also has the latest bug fixes
(so 67.02.4 is preferable to 67.02.3).</p>

<p>This practice generally benefits users and developers alike. In my case,
though, I had a conflicting personal goal: I wanted the relicensed version of
JSHint to reach as many people as possible.</p>

<p>If we made drastic improvements to JSHint, we’d have to release a new major
version. The relicensing effort could continue with the new version, but many
people would continue to use the old version. For all the obsessing I’ve done
about JSHint over the years, I haven’t forgotten that most people aren’t
particularly concerned with the release schedule of their JavaScript linter.
When and if we succeeded, the users of the old version would be cut off from
our success (not to mention the improvements we made from that point forward).</p>

<p>This consideration made me averse to drastic changes in JSHint. Pretty
antithetical for a project maintainer.</p>

<h3 id="software-freedom-matters">Software freedom matters</h3>

<p>For many people, licensing is an esoteric part of software development. It’s a
relatable opinion: the legal frameworks are intimidating, and most
considerations can be addressed by simply defaulting to well-known
free/open-source licenses.</p>

<p>The trouble is that not all software is distributed under well-known
free/open-source licenses. My hope is that the particulars of JSHint’s decay
help folks understand why licensing matters.</p>

<p>After reading the drudgery of JSHint’s slow decline, you might be wondering why
we didn’t just give up. A sinking ship is only tragic if you value the ship. If
<a href="https://eslint.org/">a newer, faster, similarly-named ship</a> sails by, then
maybe it’s time to put down the bailer. It’ll take <a href="http://mikepennisi.com/blog/2020/jshint-dug-in/">another
essay</a> to address that fully.</p>
<ul>
  
</ul>

    </section></div>]]>
            </description>
            <link>http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051655</guid>
            <pubDate>Tue, 04 Aug 2020 16:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's 2020, and I'm Still Getting Plain Text Credentials via Email]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24051581">thread link</a>) | @peepnoop
<br/>
August 4, 2020 | https://garrettyamada.com/its-2020-and-im-still-getting-plain-text-credentials-via-email/ | <a href="https://web.archive.org/web/*/https://garrettyamada.com/its-2020-and-im-still-getting-plain-text-credentials-via-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article id="5f29786087b88e0011c87f89">
<div><p>August 4, 2020<span> · <a href="https://garrettyamada.com/tag/security/">Security</a></span><span> · </span><i></i></p></div>

<p>Today, I noticed something concerning - I received an automated email invoice from my landscaping company (who I won’t name here, out of courtesy) which contained a plain-text version of my credentials for their payment portal. </p><p>While this had happened before, it previously contained an auto-generated set of credentials (so I elected to continue leaving those in place for a while so as to minimize the “blast radius” were their system to be compromised).</p><p>I had recently changed my username and password to something else (my email address and a randomized password generated using 1Password), however, thinking that changing it both would tell the system to use the new email address I provided for future correspondence and perhaps flag the system to tell it to stop sending my credentials via email. </p><p>Neither of those things happened. The latest email invoice I received went to the previous email address on file, and my new credentials were still sent to me in plain text. </p><h2 id="an-investigation">An Investigation</h2><p>The payment portal itself is suspiciously vague about what third-party companies are responsible for its maintenance and card processing, so I decided to investigate. You may notice I didn’t have a lot to go on:<br></p><figure><img src="https://lh6.googleusercontent.com/jl3YR0gJRgy95gDG3NG6RBMsuIE42Jo9vSBrwtFjuK_9Ty94ekif1j3XuUnXBoPl5vNm86e1uPQhZnEJnVYnY692p3GSyYcA6dWRuuGs5I_ICzYqeKbmfNK6-z0LJvIt_sCAtWrl"></figure><p>A cursory once-over returns absolutely no information. The company running this portal is not named in the only valid link on the page (the Terms and Conditions). “Privacy” is not a link, and nor is “Web 2” (whatever that means). </p><p>A call to the phone number listed goes nowhere; it’s invalid. I mean, 555-1212? Come on, what is this, a cheesy hollywood movie?</p><p>The paragraph about “contact us by email by clicking here”? The linked email is “<a href="https://garrettyamada.com/cdn-cgi/l/email-protection#a7d4d2d7d7c8d5d3e7cac6cecb89c4c8ca"><span data-cfemail="c6b5b3b6b6a9b4b286aba7afaae8a5a9ab">[email&nbsp;protected]</span></a>”. That sure isn’t going anywhere, either. </p><p>Since the information provided on the page itself is completely bogus, I next turned to the domain name itself. The domain name for this payment portal is “<a href="https://manageandpaymyaccount.com/">manageandpaymyaccount.com</a>”. A WHOIS lookup merely returns what I expected - the registration is private, masked by GoDaddy. </p><p>A dig command returns two A records - both for a CDN called “Incapsula”. Not a common CDN, so I looked a bit further. The site is HTTPS enabled (at least there’s that), so a quick search on Censys for “manageandpaymyaccount.com” returns this:<br></p><figure><img src="https://lh6.googleusercontent.com/DSek-SSgOEzHKX_RBm3295EISvS5ItBiYozbT0ge7-Pn-9CWQAqt1_gF2SJ0hlPw1YWOhNZHG4RyeYFjIa3Zycm0rgTqm15vvHL7UTDGTKDhEl1SxJM7AQpfxco48A7tk2aXLo6t"></figure><p>Nothing out of the ordinary so far (except that Incapsula apparently runs their CDN using IIS - really?). Next I dug into the first certificate in the chain:<br></p><figure><img src="https://lh6.googleusercontent.com/cQoRMyr2jyZWYg3q4yLyxajR35KkmxUSkwQdgGV1-EEGXxqUs6WhgsDZbsmmE__9LIC0UnmQ-C5lKDIp5bAAAhQPHz0dHsMd3sM8xrCwDw5H4giJy8Fvk9G2DKc4LKi5RP273xZX"></figure><p>Bingo! Now we’re getting somewhere. Some other interesting domains are listed here. As it turns out, “<a href="https://serviceautopilot.com/">serviceautopilot.com</a>” is the SaaS company my lawn care company uses to manage and run their business. A quick dig shows “backtell.net” doesn’t point anywhere but Google tells us Backtell, LLC is the registered parent company of Service Autopilot, both based out of Richardson, TX. </p><p>Some further searching turns up a couple of interesting things:</p><ul><li>A search on <a href="https://spyse.com/">Spyse</a> appears to show 312 subdomains of manageandpaymyaccount.com; there are likely at least that many companies using this payment portal.</li><li>There is one other documented public mention of this practice of sending plain text passwords, on Reddit:</li></ul><figure><img src="https://lh6.googleusercontent.com/ub_k5PLU242NGGgSIRqmcBI2uE1Lq8G08qzJQETits_5uZ5M7xC3JxLXEZXf_sERfVgTSDP12ho1FJ91Td4IaHWD6gP5y0b192o_-pzuXKj3ru_pt3CN-KZcluPRwMdYtNpHer3Z"></figure><p>The Reddit comment is from <em>two years ago</em>. Service Autopilot has been sending credentials in plain text for their payment portal (which they apparently went to rather surprising lengths to hide that they run) for at least two years, possibly much longer.</p><h2 id="so-what-s-next">So what’s next?<br></h2><p>Before writing this post, I reached out via email to the owner of my lawn care company, recommending he change payment processors and pointing out that sending passwords in the clear is non-compliant with PCI-DSS standards. </p><p>I also reported the issue using <a href="https://www.serviceautopilot.com/contact/">Service Autopilot’s contact form</a>. </p><div><p>Upon receiving notification of my report, my lawn care company responded as follows:</p><p><em>“Thanks for bringing this to my attention, we are going to make some changes moving forward with our current way of emailing usernames and passwords. &nbsp;These emails containing the username and password will serve as a temporary username and password for first time clients and we will encourage our clients to change their password/username any time they receive this email. &nbsp;We will not continue resending them monthly as we have been doing which should ensure a level of protection to our clients.”</em></p></div><p>This is a good start, as switching payment systems and business process flows is not an overnight process; they’re definitely limited by Service Autopilot’s technology though.</p><p>Service Autopilot responded with the following:</p><p><em>“Thank you for contacting us. &nbsp;I am glad to assist you. &nbsp;You are correct. SA is not PCI compliant, that is why we do not store credit card information. We store the token only. &nbsp;We recommend that when you email the client portal login information to your customers you advise them to change the password after they login. </em></p><p><em>As for safety concerns, you can advise them there is no credit card information stored in the portal, only customer name, address and phone. &nbsp;If someone were to access a customer's account there is no financial information stored on the site.”</em></p><p>This was very vague. Aside from the fact that PCI compliance also generally applies to the merchant, they seemed very cavalier about protecting their customers’ addresses and phone numbers. (Not to mention that the fact they can retrieve passwords in plain text means they’re not encrypted!) When pressed on protecting PII, and whether they would alter their portal to address this lax security practice, they stated:</p><p><em>“I have not heard of any upcoming changes. I will pass your feedback along for review. I have submitted product suggestion ticket (ticket #) on your behalf.”</em></p><p>Thanks for nothing!</p><h3 id="important-notes">Important Notes<br></h3><ul><li>In the course of this investigation, I only accessed publicly available data to determine and verify ownership of domains and companies involved in this situation.</li><li>Both companies involved were notified of the security issue in advance of publication.</li><li>No computer systems were accessed without authorization.</li></ul>


</article>
</div></div>]]>
            </description>
            <link>https://garrettyamada.com/its-2020-and-im-still-getting-plain-text-credentials-via-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051581</guid>
            <pubDate>Tue, 04 Aug 2020 16:30:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Self-Host My Website Analytics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24051507">thread link</a>) | @marcusbuffett
<br/>
August 4, 2020 | https://mbuffett.com/posts/why-i-self-host-my-analytics/ | <a href="https://web.archive.org/web/*/https://mbuffett.com/posts/why-i-self-host-my-analytics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently I made the switch to self-hosted analytics, after being a long-term
Google Analytics user. Almost every website you visit will have a Google
Analytics tracker on it. I think there are idealogical and technical reasons to
opt for self-hosted analytics instead.</p>
<h3 id="tracking-efficacy">Tracking efficacy</h3>
<p>This one’s quick. You’re more likely to get analytics for a given user if you’re
using self-hosted analytics, than if you’re using Google Analytics. About <a href="https://www.statista.com/statistics/804008/ad-blocking-reach-usage-us/">26%
of
people</a>
are running adblockers now, a large percentage of which will also block tracking
scripts, like GA. Having your analytics on <code>analytics.yourdomain.com</code> makes
your requests less likely to be blocked.</p>
<h3 id="on-principle---being-a-customer-vs-being-a-lead">On principle - being a customer vs being a lead</h3>
<p>Google Analytics (including gtag and universal analytics), has a whopping <a href="https://www.datanyze.com/market-share/web-analytics--1">73%
market share</a>. That’s millions and
millions of sites, and billions of data points processed every day. Google’s spending millions
on this service (disclaimer: that number is pulled from absolutely nowhere, but
even if 5 engineers are carrying the entirety of Google Analytics on their back
and server costs are zero, that already puts it in the millions).</p>
<p>Google, like any company, isn’t providing an expensive service for free out of
the goodness of their heart, or because they can spare the money. They’re hoping
that by being a Google Analytics customer, you’ll become an AdWords customer.
Google Analytics users aren’t customers, they’re leads. Personally I feel a lot
more secure in my transactions knowing I’m a customer.</p>
<p>There’s also the data privacy standpoint. I don’t want Google to know as much
about my website visitors as I do. Something doesn’t feel right to me about
giving Google that amount of insight into my site. With self-hosting I’m in
control of my visitors’ data.</p>
<h3 id="simplicity">Simplicity</h3>
<p>Google Analytics, for my purposes, has <em>way</em> too much complexity. I know there
are sites that benefit from the comparisons and stats you can pull up through
Google Analytics. Some website out there can probably benefit from finding out
what % of male users in Germany, who visited the marketing page
between January and March, signed up for a paid account in July. Maybe in the
future I’ll have a website receiving billions of hits per month where I could
materially benefit from such a query. But for now, I really don’t need it, and
I don’t want the complex UX that comes along with the ability to run queries
like that. All I need is a rough idea of how much traffic I’m getting, where
it’s coming from, and what pages it goes to. A simple self-hosted analytics
service gives me that.</p>
<h2 id="my-new-analytics-setup">My new analytics setup</h2>
<p>My GA-alternative of choice is <a href="https://github.com/electerious/Ackee">ackee</a>. It
took me all of 10 minutes to set up using the <a href="https://github.com/suda/ackee-chart">helm chart</a>(admittedly, longer than Google
Analytic’s 30-second copy and paste), it shows me the stats I care about in a
clean UI, it’s open-source, and it’s self-hosted.</p>

        </div></div>]]>
            </description>
            <link>https://mbuffett.com/posts/why-i-self-host-my-analytics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051507</guid>
            <pubDate>Tue, 04 Aug 2020 16:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Futility of Pi Denialism]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24051230">thread link</a>) | @furcyd
<br/>
August 4, 2020 | http://www.goodmath.org/blog/2020/08/04/the-futility-of-pi-denialism/ | <a href="https://web.archive.org/web/*/http://www.goodmath.org/blog/2020/08/04/the-futility-of-pi-denialism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>To me, the strangest crackpots I’ve encountered through this blog are the π denialists.</p>



<p>When people have trouble with Cantor and differently sized infinities, I get it. It defies our intuitions. It doesn’t seem to make sense.</p>



<p>When you look at Gödel incompleteness theorem – it’s really hard to wrap your head around. It doesn’t seem to make sense. I get it.</p>



<p>When you talk about things like indescribable numbers, it’s crazy. How could it possibly be true? I get it.</p>



<p>But π?</p>



<p>It’s a pretty simple number: the ratio of the diameter of the circle and the circle’s circumference. There’s nothing all that difficult about what it means. And there are so many different ways of calculating it! We can use the nature of a circle, and derive series that compute it. We can write simple programs, do tactile demos, measure actual physical phenomena. And yet, there are people who fervently believe that it’s all a sham: that the value of π <em>isn’t</em> what we say it is. It’s exactly 4. Or it’s exactly 22/7. Or it’s exactly <a href="https://www.jain108.com/true-value-of-pi-3-144/"><img src="http://l.wordpress.com/latex.php?latex=%5Cfrac%7B4%7D%7B%5Cphi%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\frac{4}{\phi^{\frac{1}{2}}}" alt="\frac{4}{\phi^{\frac{1}{2}}}"></a>. Or it’s not a number, it’s <a href="https://www.nevyns-lab.com/mathis/mirror/milesmathis.com/pi2.html">an <em>acceleration</em></a>.</p>



<p>It’s amazing. I constantly get mail – mostly from fans of either Jain (the author of the &amp;phi;-based &amp;pi; mentioned above), or from followers of Miles Mathis (he of “&amp;pi; isn’t a ratio, it’s an acceleration” fame), insisting that I’m part of the great mathematical conspiracy to deny the true factual value of &amp;pi;.</p>



<p>And yet… It’s so simple to demonstrate how wrong that is.</p>



<p>My favorite version is a simple program.</p>



<p>Here’s the idea, followed by the code.</p>



<ul><li>Take the unit square – the region of the graph from (0, 0) to (1, 1), and inside of it, an arc of the circle of radius 1 around (0,0).<img src="http://www.goodmath.org/blog/wp-content/uploads/2020/08/arc.jpg" alt=""></li><li>Pick a random point, (x, y), anywhere inside of that square.</li><li>If the distance from the origin (<img src="http://l.wordpress.com/latex.php?latex=x%5E2%20%2B%20y%5E2&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="x^2 + y^2" alt="x^2 + y^2">) is less than one, then the point is inside the circle. If it isn’t, then it’s outside of the circle.</li><li>The probability, <img src="http://l.wordpress.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="p" alt="p">, of any given random point being inside that circle is equal to the ratio of the area of the circle to the area of the square. The area of that region of the circle is: <img src="http://l.wordpress.com/latex.php?latex=%5Cpi%2A1%5E2%2F4&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\pi*1^2/4" alt="\pi*1^2/4">, and the area of the the square is <img src="http://l.wordpress.com/latex.php?latex=1%5E2&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="1^2" alt="1^2">. So the probability is <img src="http://l.wordpress.com/latex.php?latex=%281%2F4%29%5Cpi%2F1&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="(1/4)\pi/1" alt="(1/4)\pi/1">, or <img src="http://l.wordpress.com/latex.php?latex=%5Cpi%2F4&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\pi/4" alt="\pi/4">.</li><li>So take a ton of random points, and count how many are inside the circle.</li><li>The ratio of points inside the circle to total random points is <img src="http://l.wordpress.com/latex.php?latex=%5Cpi%2F4&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\pi/4" alt="\pi/4">. The more random points you do this with, the closer you get to π.</li></ul>



<p>We can turn that into a simple Python program:</p>



<pre>from random import random

def computePi(points):
    inside = 0
    for i in range(points):
        x = random()
        y = random()
        if (x*x + y*y) &lt; 1.0:
            inside = inside + 1
    return (inside*1.0)/points * 4.0


for i in range(30):
    pi = computePi(2**i)
    print(f"Pi at 2**{i} iterations = {pi}")
</pre>



<p>The exact value that you’ll get when you run this depends on the random number generator, and the initial seed value. If you don’t specify a seed, most random number libraries will use something like last 32 digits of the current system time in nanoseconds, so you’ll get slightly different results each time you run it. I just ran it, and got:</p>



<pre>Pi at 2**0 iterations = 4.0
Pi at 2**1 iterations = 4.0
Pi at 2**2 iterations = 3.0
Pi at 2**3 iterations = 2.0
Pi at 2**4 iterations = 3.5
Pi at 2**5 iterations = 2.75
Pi at 2**6 iterations = 3.0625
Pi at 2**7 iterations = 3.125
Pi at 2**8 iterations = 3.109375
Pi at 2**9 iterations = 3.1875
Pi at 2**10 iterations = 3.171875
Pi at 2**11 iterations = 3.126953125
Pi at 2**12 iterations = 3.12109375
Pi at 2**13 iterations = 3.14013671875
Pi at 2**14 iterations = 3.169677734375
Pi at 2**15 iterations = 3.1324462890625
Pi at 2**16 iterations = 3.14453125
Pi at 2**17 iterations = 3.147247314453125
Pi at 2**18 iterations = 3.138519287109375
Pi at 2**19 iterations = 3.1364669799804688
Pi at 2**20 iterations = 3.1443214416503906
Pi at 2**21 iterations = 3.141223907470703
Pi at 2**22 iterations = 3.141301155090332
Pi at 2**23 iterations = 3.1419320106506348
Pi at 2**24 iterations = 3.1415367126464844
Pi at 2**25 iterations = 3.1421539783477783
Pi at 2**26 iterations = 3.1420511603355408
Pi at 2**27 iterations = 3.1415300369262695
Pi at 2**28 iterations = 3.141532242298126
Pi at 2**29 iterations = 3.1415965482592583
</pre>



<p>I suspect that I could do a lot better using a special number library to reduce or eliminate the floating point roundoff errors, but I don’t really think it’s worth the time. Just this much, using a really simple, obvious, intuitive method produces a better result than <em>any</em> of the numbers pushed by the crackpots.</p>



<p>To support that previous statement: the best crackpot value for π is the one based on the golden ratio. That version insists that the true value of π is 3.14460551103. But you can see – by using the simple metric of counting points inside and outside the circle – that the actual value is quite different from that.</p>



<p>That’s what makes this breed of denialism so stupid. π isn’t complicated: it’s a simple ratio. And it’s easy to test using simple concepts. Pi relates the diameter (or radius) of a circle to the circumference or area of that circle. So any test that works with circles can easily show you what π is. There’s nothing mysterious or counterintuitive or debatable about it. It is what it is, and you can test it yourself.</p>
					</div></div>]]>
            </description>
            <link>http://www.goodmath.org/blog/2020/08/04/the-futility-of-pi-denialism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051230</guid>
            <pubDate>Tue, 04 Aug 2020 15:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's build a full-text search engine]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24051229">thread link</a>) | @elorant
<br/>
August 4, 2020 | https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/ | <a href="https://web.archive.org/web/*/https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        

        


        <p>Full-Text Search is one of those tools people use every day without realizing it. If you ever googled "golang coverage report" or tried to find "indoor wireless camera" on an e-commerce website, you used some kind of full-text search.</p>
<p>Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text.</p>
<p>Today we are going to build our own FTS engine. By the end of this post, we'll be able to search across millions of documents in less than a millisecond. We'll start with simple search queries like "give me all documents that contain the word <em>cat</em>" and we'll extend the engine to support more sophisticated boolean queries.</p>
<div>
<p>Note</p>
<p>Most well-known FTS engine is <a href="https://lucene.apache.org/" target="_blank">Lucene</a> (as well as <a href="https://github.com/elastic/elasticsearch" target="_blank">Elasticsearch</a> and Solr built on top of it).</p>
</div>
<div id="why-fts">
<h3>Why FTS<a href="#why-fts" title="Permalink to this headline"> #</a></h3>
<p>Before we start writing code, you may ask "can't we just use <em>grep</em> or have a loop that checks if every document contains the word I'm looking for?". Yes, we can. However, it's not always the best idea.</p>
</div>
<div id="corpus">
<h3>Corpus<a href="#corpus" title="Permalink to this headline"> #</a></h3>
<p>We are going to search a part of the abstract of English Wikipedia. The latest dump is available at <a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-abstract1.xml.gz" target="_blank">dumps.wikimedia.org</a>. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents.</p>
<p>Document example:</p>
<pre><code><span>&lt;title&gt;</span>Wikipedia: Kit-Cat Klock<span>&lt;/title&gt;</span>
<span>&lt;url&gt;</span>https://en.wikipedia.org/wiki/Kit-Cat_Klock<span>&lt;/url&gt;</span>
<span>&lt;abstract&gt;</span>The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.<span>&lt;/abstract&gt;</span></code></pre>
</div>
<div id="loading-documents">
<h3>Loading documents<a href="#loading-documents" title="Permalink to this headline"> #</a></h3>
<p>First, we need to load all the documents from the dump. The built-in <span>encoding/xml</span> package comes very handy:</p>
<pre><code><span>import</span> <span>(</span>
    <span>"encoding/xml"</span>
    <span>"os"</span>
<span>)</span>

<span>type</span> <span>document</span> <span>struct</span> <span>{</span>
    <span>Title</span> <span>string</span> <span>`xml:"title"`</span>
    <span>URL</span>   <span>string</span> <span>`xml:"url"`</span>
    <span>Text</span>  <span>string</span> <span>`xml:"abstract"`</span>
    <span>ID</span>    <span>int</span>
<span>}</span>

<span>func</span> <span>loadDocuments</span><span>(</span><span>path</span> <span>string</span><span>)</span> <span>([]</span><span>document</span><span>,</span> <span>error</span><span>)</span> <span>{</span>
    <span>f</span><span>,</span> <span>err</span> <span>:=</span> <span>os</span><span>.</span><span>Open</span><span>(</span><span>path</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>
    <span>defer</span> <span>f</span><span>.</span><span>Close</span><span>()</span>

    <span>dec</span> <span>:=</span> <span>xml</span><span>.</span><span>NewDecoder</span><span>(</span><span>f</span><span>)</span>
    <span>dump</span> <span>:=</span> <span>struct</span> <span>{</span>
        <span>Documents</span> <span>[]</span><span>document</span> <span>`xml:"doc"`</span>
    <span>}{}</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>dec</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>dump</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>docs</span> <span>:=</span> <span>dump</span><span>.</span><span>Documents</span>
    <span>for</span> <span>i</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>docs</span><span>[</span><span>i</span><span>].</span><span>ID</span> <span>=</span> <span>i</span>
    <span>}</span>
    <span>return</span> <span>docs</span><span>,</span> <span>nil</span>
<span>}</span></code></pre>
<p>Every loaded document gets assigned a unique identifier.
To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on.</p>
</div>
<div id="first-attempt">
<h3>First attempt<a href="#first-attempt" title="Permalink to this headline"> #</a></h3>
<div id="searching-the-content">
<h4>Searching the content<a href="#searching-the-content" title="Permalink to this headline"> #</a></h4>
<p>Now that we have all documents loaded into memory, we can try to find the ones about cats. At first, let's loop through all documents and check if they contain the substring <em>cat</em>:</p>
<pre><code><span>func</span> <span>search</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>,</span> <span>term</span> <span>string</span><span>)</span> <span>[]</span><span>document</span> <span>{</span>
    <span>var</span> <span>r</span> <span>[]</span><span>document</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>if</span> <span>strings</span><span>.</span><span>Contains</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>,</span> <span>term</span><span>)</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>doc</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<p>On my laptop, the search phase takes 103ms - not too bad.
If you spot check a few documents from the output, you may notice that the function matches <em>caterpillar</em> and <em>category</em>, but doesn't match <em>Cat</em> with the capital <em>C</em>. That's not quite what I was looking for.</p>
<p>We need to fix two things before moving forward:</p>
<ul>
<li><p>Make the search case-insensitive (so <em>Cat</em> matches as well).</p></li>
<li><p>Match on a word boundary rather than on a substring (so <em>caterpillar</em> and <em>communication</em> don't match).</p></li>
</ul>
</div>
<div id="searching-with-regular-expressions">
<h4>Searching with regular expressions<a href="#searching-with-regular-expressions" title="Permalink to this headline"> #</a></h4>
<p>One solution that quickly comes to mind and allows implementing both requirements is <em>regular expressions</em>.</p>
<p>Here it is - <span><span>(?i)\bcat\b</span></span>:</p>
<ul>
<li><p><span><span>(?i)</span></span> makes the regex case-insensitive</p></li>
<li><p><span>\b</span> matches a word boundary (position where one side is a word character and another side is not a word character)</p></li>
</ul>
<pre><code><span>func</span> <span>search</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>,</span> <span>term</span> <span>string</span><span>)</span> <span>[]</span><span>document</span> <span>{</span>
    <span>re</span> <span>:=</span> <span>regexp</span><span>.</span><span>MustCompile</span><span>(</span><span>`(?i)\b`</span> <span>+</span> <span>term</span> <span>+</span> <span>`\b`</span><span>)</span> <span>// Don't do this in production, it's a security risk. term needs to be sanitized.
</span>    <span>var</span> <span>r</span> <span>[]</span><span>document</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>if</span> <span>re</span><span>.</span><span>MatchString</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>)</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>doc</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<p>Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn't scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that.</p>
</div>
</div>
<div id="inverted-index">
<h3>Inverted Index<a href="#inverted-index" title="Permalink to this headline"> #</a></h3>
<p>To make search queries faster, we'll preprocess the text and build an index in advance.</p>
<p>The core of FTS is a data structure called <em>Inverted Index</em>.
The Inverted Index associates every word in documents with documents that contain the word.</p>
<p>Example:</p>
<pre><code><span>documents</span> <span>=</span> <span>{</span>
    <span>1</span><span>:</span> <span>"a donut on a glass plate"</span><span>,</span>
    <span>2</span><span>:</span> <span>"only the donut"</span><span>,</span>
    <span>3</span><span>:</span> <span>"listen to the drum machine"</span><span>,</span>
<span>}</span>

<span>index</span> <span>=</span> <span>{</span>
    <span>"a"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"donut"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>],</span>
    <span>"on"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"glass"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"plate"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"only"</span><span>:</span> <span>[</span><span>2</span><span>],</span>
    <span>"the"</span><span>:</span> <span>[</span><span>2</span><span>,</span> <span>3</span><span>],</span>
    <span>"listen"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"to"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"drum"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"machine"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
<span>}</span></code></pre>
<p>Below is a real-world example of the Inverted Index. An index in a book where a term references a page number:</p>
<p><img alt="" src="https://artem.krylysov.com/images/2020-fts/book-index.png">
</p></div>
<div id="text-analysis">
<h3>Text analysis<a href="#text-analysis" title="Permalink to this headline"> #</a></h3>
<p>Before we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching.</p>
<p>The text analyzer consists of a tokenizer and multiple filters.</p>
<p><img alt="" src="https://artem.krylysov.com/images/2020-fts/text-analysis.png">
</p></div>
<div id="tokenizer">
<h3>Tokenizer<a href="#tokenizer" title="Permalink to this headline"> #</a></h3>
<p>The tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks:</p>
<pre><code><span>func</span> <span>tokenize</span><span>(</span><span>text</span> <span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>return</span> <span>strings</span><span>.</span><span>FieldsFunc</span><span>(</span><span>text</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>rune</span><span>)</span> <span>bool</span> <span>{</span>
        <span>// Split on any character that is not a letter or a number.
</span>        <span>return</span> <span>!</span><span>unicode</span><span>.</span><span>IsLetter</span><span>(</span><span>r</span><span>)</span> <span>&amp;&amp;</span> <span>!</span><span>unicode</span><span>.</span><span>IsNumber</span><span>(</span><span>r</span><span>)</span>
    <span>})</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>tokenize</span><span>(</span><span>"A donut on a glass plate. Only the donuts."</span><span>)</span>

<span>[</span><span>"A"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"Only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="filters">
<h3>Filters<a href="#filters" title="Permalink to this headline"> #</a></h3>
<p>In most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we'll need to do additional normalization.</p>
<div id="lowercase">
<h4>Lowercase<a href="#lowercase" title="Permalink to this headline"> #</a></h4>
<p>In order to make the search case-insensitive, the lowercase filter converts tokens to lower case. <em>cAt</em>, <em>Cat</em> and <em>caT</em> are normalized to <em>cat</em>.
Later, when we query the index, we'll lower case the search terms as well. This will make the search term <em>cAt</em> match the text <em>Cat</em>.</p>
<pre><code><span>func</span> <span>lowercaseFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>i</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>r</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>strings</span><span>.</span><span>ToLower</span><span>(</span><span>token</span><span>)</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>lowercaseFilter</span><span>([]</span><span>string</span><span>{</span><span>"A"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"Only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"a"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="dropping-common-words">
<h4>Dropping common words<a href="#dropping-common-words" title="Permalink to this headline"> #</a></h4>
<p>Almost any English text contains commonly used words like <em>a</em>, <em>I</em>, <em>the</em> or <em>be</em>. Such words are called <em>stop words</em>. We are going to remove them since almost any document would match the stop words.</p>
<p>There is no "official" list of stop words. Let's exclude the top 10 by the <a href="https://en.wikipedia.org/wiki/Most_common_words_in_English" target="_blank">OEC rank</a>. Feel free to add more:</p>
<pre><code><span>var</span> <span>stopwords</span> <span>=</span> <span>map</span><span>[</span><span>string</span><span>]</span><span>struct</span><span>{}{</span> <span>// I wish Go had built-in sets.
</span>    <span>"a"</span><span>:</span> <span>{},</span> <span>"and"</span><span>:</span> <span>{},</span> <span>"be"</span><span>:</span> <span>{},</span> <span>"have"</span><span>:</span> <span>{},</span> <span>"i"</span><span>:</span> <span>{},</span>
    <span>"in"</span><span>:</span> <span>{},</span> <span>"of"</span><span>:</span> <span>{},</span> <span>"that"</span><span>:</span> <span>{},</span> <span>"the"</span><span>:</span> <span>{},</span> <span>"to"</span><span>:</span> <span>{},</span>
<span>}</span>

<span>func</span> <span>stopwordFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>0</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>_</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>if</span> <span>_</span><span>,</span> <span>ok</span> <span>:=</span> <span>stopwords</span><span>[</span><span>token</span><span>];</span> <span>!</span><span>ok</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>token</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>stopwordFilter</span><span>([]</span><span>string</span><span>{</span><span>"a"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="stemming">
<h4>Stemming<a href="#stemming" title="Permalink to this headline"> #</a></h4>
<p>Because of the grammar rules, documents may include different forms of the same word.
Stemming reduces words into their base form. For example, <em>fishing</em>, <em>fished</em> and <em>fisher</em> may be reduced to the base form (stem) <em>fish</em>.</p>
<p>Implementing a stemmer is a non-trivial task, it's not covered in this post. We'll take one of the <a href="https://github.com/kljensen/snowball" target="_blank">existing</a> modules:</p>
<pre><code><span>import</span> <span>snowballeng</span> <span>"github.com/kljensen/snowball/english"</span>

<span>func</span> <span>stemmerFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>i</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>r</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>snowballeng</span><span>.</span><span>Stem</span><span>(</span><span>token</span><span>,</span> <span>false</span><span>)</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>stemmerFilter</span><span>([]</span><span>string</span><span>{</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donut"</span><span>]</span></code></pre>
<div>
<p>Note</p>
<p>A stem is not always a valid word. For example, some stemmers may reduce <em>airline</em> to <em>airlin</em>.</p>
</div>
</div>
</div>
<div id="putting-the-analyzer-together">
<h3>Putting the analyzer together<a href="#putting-the-analyzer-together" title="Permalink to this headline"> #</a></h3>
<pre><code><span>func</span> <span>analyze</span><span>(</span><span>text</span> <span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>tokens</span> <span>:=</span> <span>tokenize</span><span>(</span><span>text</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>lowercaseFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>stopwordFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>stemmerFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>return</span> <span>tokens</span>
<span>}</span></code></pre>
<p>The tokenizer and filters convert sentences into a list of tokens:</p>
<pre><code><span>&gt;</span> <span>analyze</span><span>(</span><span>"A donut on a glass plate. Only the donuts."</span><span>)</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donut"</span><span>]</span></code></pre>
<p>The tokens are ready for indexing.</p>
</div>
<div id="building-the-index">
<h3>Building the index<a href="#building-the-index" title="Permalink to this headline"> #</a></h3>
<p>Back to the inverted index. It maps every word in documents to document IDs.
The built-in <span>map</span> is a good candidate for storing the mapping.
The key in the map is a token (string) and the value is a list of document IDs:</p>
<pre><code><span>type</span> <span>index</span> <span>map</span><span>[</span><span>string</span><span>][]</span><span>int</span></code></pre>
<p>Building the index consists of analyzing the documents and adding their IDs to the map:</p>
<pre><code><span>func</span> <span>(</span><span>idx</span> <span>index</span><span>)</span> <span>add</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>)</span> <span>{</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>for</span> <span>_</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>analyze</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>)</span> <span>{</span>
            <span>ids</span> <span>:=</span> <span>idx</span><span>[</span><span>token</span><span>]</span>
            <span>if</span> <span>ids</span> <span>!=</span> <span>nil</span> <span>&amp;&amp;</span> <span>ids</span><span>[</span><span>len</span><span>(</span><span>ids</span><span>)</span><span>-</span><span>1</span><span>]</span> <span>==</span> <span>doc</span><span>.</span><span>ID</span> <span>{</span>
                <span>// Don't add same ID twice.
</span>                <span>continue</span>
            <span>}</span>
            <span>idx</span><span>[</span><span>token</span><span>]</span> <span>=</span> <span>append</span><span>(</span><span>ids</span><span>,</span> <span>doc</span><span>.</span><span>ID</span><span>)</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>idx</span> <span>:=</span> <span>make</span><span>(</span><span>index</span><span>)</span>
    <span>idx</span><span>.</span><span>add</span><span>([]</span><span>document</span><span>{{</span><span>ID</span><span>:</span> <span>1</span><span>,</span> <span>Text</span><span>:</span> <span>"A donut on a glass plate. Only the donuts."</span><span>}})</span>
    <span>idx</span><span>.</span><span>add</span><span>([]</span><span>document</span><span>{{</span><span>ID</span><span>:</span> <span>2</span><span>,</span> <span>Text</span><span>:</span> <span>"donut is a donut"</span><span>}})</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>idx</span><span>)</span>
<span>}</span></code></pre>
<p>It works! Each token in the map refers to IDs of the documents that contain the token:</p>
<pre><code>map[donut:[1 2] glass:[1] …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/">https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/</a></em></p>]]>
            </description>
            <link>https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051229</guid>
            <pubDate>Tue, 04 Aug 2020 15:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audi TT air vent design]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24051039">thread link</a>) | @colinprince
<br/>
August 4, 2020 | https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design | <a href="https://web.archive.org/web/*/https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5832c99c03596e27e24e1af6" data-item-id="5832c99c03596e27e24e1af6">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1479725111882" id="item-5832c99c03596e27e24e1af6"><div><div><div data-block-type="2" id="block-3d49cb3c33b929bc8e37"><p>The recently launched Audi TT is notable for its interior design, especially the unique design of the air-conditioning controls that are integrated into the air-vents:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1479722101486_24177"><div><p><em>HVAC (Heating, Ventilation, Air-Conditioning) controls on the 2015 Audi TT &nbsp;</em></p><p>This is an excellent design.&nbsp;</p><p>Fundamentally, changing something like the A/C temperature or fan speed involves two senses. Sight is needed to observe what the currently displayed temperature is and to then adjust the setting. Secondly, touch, or more specifically, thermoception, is needed to 'feel' the new temperature or fan speed change and confirm whether the new setting is appropriate, or whether further adjustment is required.</p><p>Thus, this process usually involves a <em>two-step action</em>:&nbsp;manipulating the switch or dial to change the temperature/air-flow, and then placing a hand near the air vent to 'feel' whether the new temperature and air-flow is right.</p><p>Most car interiors reinforce this two step process by separating the air-vent and temperature controls and placing them in disparate locations.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_8_1479722101486_19028"><div><p><em>2017 Porsche 718 Boxster. The HVAC controls are just visible at the bottom of the image.</em></p><p>An example of this is the Porsche 718 Boxster. Porsche takes a contrasting approach to Audi and places its HVAC controls almost diametrically opposite to the air-vents, with both being separated by the infotainment screen and the media controls.&nbsp;Consequently, this design enforces the rigid two-step process outlined above, by forcing the driver to physically move their hand between two different locations in order to ensure the correct temperature and airflow setting.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_8_1479722101486_29996"><div><p>Audi's design, in contrast, is innovative because it elegantly and efficiently combines the disparate two step process in the Porsche and other vehicles. By integrating all necessary HVAC controls, including temperature, fan speed and airflow within the air-vent, the driver can <em>simultaneously</em> adjust the control and immediately feel the effect of their action, without having to physically move their arm.</p><p>While this may seem to be a superficial change, Audi's design has numerous benefits. Not only does it create a sense of harmony and visual symmetry, but by minimising the number of separate buttons and switches, it greatly reduces the potential for the driver to be confused or frustrated by excessive clutter and small, illogically placed controls. By streamlining a relatively complicated,&nbsp;two-step process into a single action, Audi's design could also potentially increase road safety, by essentially halving the time the driver spends with one hand on the steering wheel.</p><p>An innovative, refreshing and logical design that clearly moves the ball forward.&nbsp;Great work.</p></div></div></div></div></div></div>

    <!--POST FOOTER-->

      

    </div><!-- /post -->

  </div><!-- /content-wrapper -->
  </article>




<!--PAGINATION-->





<!--COMMENTS-->
				</section>
			</div><!-- / pageWrapper -->

			<!-- / footerWrapper -->

		</div><!-- / canvas -->
	</div></div>]]>
            </description>
            <link>https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051039</guid>
            <pubDate>Tue, 04 Aug 2020 15:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gone Phishing]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24050912">thread link</a>) | @danso
<br/>
August 4, 2020 | https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>here he was, smiling on the <a href="https://www.zinio.com/za/forbes-africa/june-2016-i18106">cover of <em>Forbes Africa</em> magazine</a>, dollar bills raining like confetti. It was June 2016, and Obinwanne Okeke, then 28, was on top of the world; he had just landed a coveted spot on the magazine’s prestigious 30 under 30 list of African entrepreneurs. In the article, he was one of many whiz kids described as “Africa’s bright young things.”</p>



<p>The 17th child of a polygamous father whose mother was the fourth wife, Okeke’s father died when he was 16, and his mother, a teacher, worked multiple jobs to put him and his siblings through school. Growing up in Ukpor, a village in southeastern Nigeria, was tough, and luxuries like sneakers or a Game Boy were hard to come by, he said in a <a href="https://www.bbc.co.uk/sounds/play/p065dtt3">2018 BBC interview</a>. </p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-40x48.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-400x477.png 400w, https://restofworld.org/wp-content/uploads/2020/07/Nigeria-600x715.png 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>But he persevered, he said, studying in South Africa and Australia, earning a master’s degree in international relations and counter-terrorism at Monash University. He started his business in Nigeria in 2013. That business — which, as he has alluded to in other interviews, involved low-cost housing and green homes — expanded into South Africa, Botswana, and Zambia, with a potential addition in Uganda. His interests were worth almost $10 million, <a href="https://iono.fm/e/303518">he said</a>.</p>



<p>Okeke named his business Invictus, after the <a href="https://www.poetryfoundation.org/poems/51642/invictus">poem</a> by William Ernest Henley about resilience in the face of adversity. It was said to be <a href="http://www.openculture.com/2013/12/morgan-freeman-masterfully-recites-nelson-mandelas-favorite-poem-invictus.html">Nelson Mandela’s favorite poem</a>.</p>



<p>“Invictus is in construction, agriculture, oil and gas, telecoms and real estate. He has 28 permanent and 100 part-time employees across nine companies,”<em> Forbes Africa</em> wrote in Okeke’s entry.</p>



<p>But that much-lauded business empire existed alongside Okeke’s criminal enterprises, the FBI later wrote in an August 2019 <a href="https://www.courtlistener.com/recap/gov.uscourts.vaed.450919/gov.uscourts.vaed.450919.5.0_1.pdf">affidavit</a>. Turns out, Okeke had been involved in a string of sophisticated online scams since at least 2015 — including when he was gracing that glossy <em>Forbes Africa</em> cover. He <a href="https://www.thecable.ng/fbi-arrested-invictus-obi-at-dulles-international-airport-just-before-escaping-us">was arrested</a> at Dulles International Airport, Virginia, on August 6, 2019, for defrauding a company of nearly $11 million. He <a href="https://www.justice.gov/usao-edva/pr/nigerian-businessman-pleads-guilty-11-million-fraud-scheme">pleaded guilty</a> to conspiracy to commit wire fraud on June 18, 2020, and now faces up to 20 years in prison at his sentencing in October. Okeke’s rapid ascent as a supposedly successful entrepreneur —&nbsp;and his subsequent defenestration — reflects a growing trend in online scamming known as <a href="https://www.trendmicro.com/vinfo/us/security/definition/business-email-compromise-(bec)">business email compromise (BEC)</a>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-400x272.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-600x408.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-1600x1088.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-2800x1903.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A cyber cafe in Lagos, Nigeria, on April 18, 2019. These cafes are frequented by scammers who refer to themselves as " yahoo="" boys,"="" a="" nod="" to="" the="" online="" chat="" service="" messenger="" where="" love="" scams="" gained="" traction="" nearly="" 20="" years="" ago.="" renee="" holland="" sent="" her="" facebook="" friend="" thousands="" of="" dollars.="" she="" became="" entwined="" in="" global="" fraud="" that="" social="" network="" and="" united="" states="" military="" appear="" helpless="" stop.="" (the="" new="" york="" times)"="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>The tale of</strong> the Nigerian online scammers <a href="https://republic.com.ng/august-september-2019/yahoo-yahoo-naija/">stretches back to the 1990s</a>, when cybercafes sprung up across the country as internet access became increasingly widespread. Young men popularly known as “<a href="https://theconversation.com/meet-the-yahoo-boys-nigerias-undergraduate-conmen-60757">Yahoo boys</a>” became famous for conning their unsuspecting victims out of money by posing as romantic interests — typically American soldiers based in active conflict zones in the Middle East —&nbsp;or as wealthy royals in need of help getting a relative’s money out of some bureaucratic logjam. Their notoriety is now mainstream enough that they’ve become a pop-culture joke. In an <a href="https://www.vulture.com/2016/01/black-ish-recap-season-2-episode-12.html">episode from the second season</a> of the TV show “Black-ish<em>,</em>” a concerned sibling chastised her brother about his potential love interest, convinced he was being duped by a scammer. “This is a middle-aged Nigerian man who wants your money or your kidney,” she told him. The youngest sibling added, “I’m trusting to a fault, and even I know this screams Nigerian scam.”&nbsp;</p>



<p>Okeke’s case reflects how much has changed since then.<strong> </strong>Rather than settling for petty romance schemes, some scammers are now targeting the email accounts of executives at Western<strong> </strong>companies, tricking their companies into sending wire transfers to supposed overseas suppliers who then fraudulently transfer those funds into the scammers’ bank accounts. The stakes involved in BECs are high in nearly every possible way: they target wealthy and prominent victims and use complex tools to defraud them, and if the plot succeeds, it results in a windfall. Whereas the targets of online romance scams are usually older Americans or other lonely Westerners desperate for affection (or the occasional naïf fooled into going into business with a <a href="https://www.popsci.com/story/technology/nigerian-prince-scam-social-engineering/">seemingly sweet-talking African prince</a>), email compromise focuses on businesses ranging from small-sized enterprises to multinational corporations. Scammers typically single out high-level executives, usually the CEO, CFO, or COO, “the real decision-makers who have the power to sign checks and grant approval,” Eniola Fadare, a Lagos-based computer security expert, told <em>Rest of World</em>. The goal, after gaining control of these decision-makers’ email accounts, is to authorize wire payments of money that will largely end up in accounts controlled by the scammers.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-40x82.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-400x818.png 400w, https://restofworld.org/wp-content/uploads/2020/07/IMG_4316-e1595879129282-600x1227.png 600w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In contrast to romance scams, where the guys — and they’re almost always guys — find their marks on Facebook, Instagram, or any number of dating apps, email compromise is a “patient scam,” Fadare said, that involves quietly shadowing a company or its executives for months, to determine the types of businesses they’re involved in and the vendors who will need to be paid. The operational costs of pulling off one of these scams often add up to millions of naira, but the payoff can be worth it. While romance scammers may make off with anywhere from $350 to $3,000, BEC scammers can potentially rake in much more. Olalekan Jacob Ponle, who also went by the name Mr. Woodbery, was arrested on June 10, 2020, in Dubai for allegedly <a href="https://www.justice.gov/usao-ndil/pr/nigerian-national-expelled-united-arab-emirates-face-cyber-fraud-charge-chicago">stealing $15.2 million</a> in a scam targeting a Chicago-based company.</p>



<p>BEC involves a high degree of sophistication and collaboration between masterminds and co-conspirators, who provide services like designing fake landing pages for hijacking email accounts and harvesting passwords. There are also money mules who provide accounts, sometimes referred to as “houses,” to park the proceeds of the scams. A 24-year-old Lagos-based scammer, who spoke to <em>Rest of World</em> through an intermediary to preserve his anonymity, said that romance scams are “easier and cheaper to do” than BEC scams. But they’re not the sure bet they once were, because of how widespread they are. “People are getting educated and enlightened,” Fadare said.</p>



<p>Business-related scams involve individuals spread around the world, requiring authorities to cooperate across borders; Mr. Woodbery was extradited to the United States after being captured by Dubai police. Last year, 281 individuals, <a href="https://www.justice.gov/opa/pr/281-arrested-worldwide-coordinated-international-enforcement-operation-targeting-hundreds">including 167 in Nigeria</a>, were arrested for their involvement in BEC schemes as part of an international raid called Operation reWired. Arrests were also made in Turkey, Japan, Italy, and elsewhere. The cases are being tried across several jurisdictions in the U.S., because the victims are American.</p>



<p>In a statement from the U.S. Attorney’s Office for the Central District of California on the arrest of Hushpuppi, a <a href="https://www.instagram.com/hushpuppi/">flamboyant Instagram</a> celebrity with 2.5 million followers, U.S. Attorney Nick Hanna <a href="https://www.justice.gov/usao-cdca/pr/nigerian-national-brought-us-face-charges-conspiring-launder-hundreds-millions-dollars">described</a> BEC as “one of the most difficult cybercrimes we encounter as they typically involve a coordinated group of con artists scattered around the world who have experience with computer hacking and exploiting the international financial system.” Paul Delacourt, the assistant director in charge of the FBI’s Los Angeles Field Office, claimed that the FBI recorded $1.7 billion lost to BEC schemes in 2019.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-40x27.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-400x267.png 400w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-600x401.png 600w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-1600x1068.png 1600w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-2800x1869.png 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>The crime that</strong> got Okeke arrested began on April 1, 2018, making it perhaps the most lucrative prank ever pulled on April Fool’s Day. The victim was Unatrac Holding Ltd, the export sales office of a dealer for Caterpillar, a heavy industrial and farm equipment company. The company is based in Slough, a town about 45 minutes outside of London. According to the FBI statement, Unatrac’s CFO received an email containing a login link for his Microsoft Office 365 account and entered his login details, believing it to be real. Instead, it was a spoof website crafted by Okeke and unnamed associates to gain access to the CFO’s email. </p>



<p>After they did, the hackers sent invoices from an email address intended to mimic that of a legitimate vendor to the CFO’s email, using invoice templates and logos found within the compromised account to lend an air of legitimacy to the documents. Minutes later, those fake invoices were forwarded to Unatrac’s finance team from the CFO’s email. Because the finance staff had no reason to doubt the provenance of the wire transfer requests, they processed about 15 payments between April 11 and April 19, 2018. The company that allegedly submitted the invoices, Pak Fei Trade Ltd, was sent at least three payments that totaled more than $3 million, with the payments going to overseas accounts. In total, almost $11 million was stolen from Unatrac.&nbsp;</p>



<p>About the same time the scam was underway, Okeke <a href="https://guardian.ng/news/nigerian-investment-expert-to-speak-at-lse-africa-summit-in-london/">was an invited speaker</a> at the London School of Economics’s Africa Summit, alongside luminaries like Ghanaian President Nana Akufo-Addo and many other prominent African businesspeople. He also partook in that BBC interview, telling tales of growing up poor and how he was introducing low-income housing to a Nigerian property market saturated with expensive homes.</p>



<p>By the time the company realized it had been hoodwinked, it was too late to cancel the transactions, and little of the funds were recovered, according to the FBI statement. To avoid detection, the hackers set up email filters that immediately intercepted legitimate emails to and from the CFO, marked them as read, and moved them to another folder outside the inbox.</p>



<p>Fadare, the security expert, explained that, in conjunction with setting up email filters, scammers do not work “at active hours when they know the CEO is awake or busy.”</p>



<p>Additionally, “they clear the emails from the boxes as soon as they’re received. The real CEO, when he logs into his email, is not going to see anything,” he added. Fadare said scammers bank on people not carefully scrutinizing messages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/">https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050912</guid>
            <pubDate>Tue, 04 Aug 2020 15:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planning for My Kidnapping]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24050837">thread link</a>) | @polote
<br/>
August 4, 2020 | https://blog.luap.info/planning-for-my-kidnapping.html | <a href="https://web.archive.org/web/*/https://blog.luap.info/planning-for-my-kidnapping.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>Imagine tomorrow you go shopping and, for whatever reason, you never come back. Maybe be someone killed you, maybe someone kidnapped you, maybe you had an accident ... Now imagine you are travelling alone in Thailand and you die. How people who know you are going to find out what happen ? if you are being kidnaped how the police will do to find you, if you got lost how people will find you ? If you die how your family is going to find your papers ?</p>
<p>I wanted to find a way to answer all those questions, basically we can sum up the issues in 3 points :
- In case of being kidnaped or getting lost send as much information on your last location, and following locations, your last activity, all your digital information to someone who is going to help liberating you
- In case of dying, sending all your documents (passwords, friends list, legal documents, ...) to your family
- Not sending those documents by mistakes if you are not on the situations above</p>
<h2>First step : collect your position, your activity, your documents, ...</h2>
<p>The first step is to be sure that you have the data that you want to send, on my part, the data are:</p>
<ol>
<li>My current position and recent history</li>
<li>My last know activity and a recent history</li>
<li>The list of my credentials</li>
<li>The list of my legal documents (id, passport, health insurance, work papers, ...)</li>
</ol>
<p>I've written an <a href="https://blog.luap.info/how-i-track-my-life.html">article</a> explaining how I'm doing 1. and 2. (position in real time, and last activity), so this is fixed.</p>
<p>For my credentials, I use <a href="https://keepassxc.org/">keepassXC</a> with a keyfile + a master password, the keyfile and the password db is synced using <a href="https://syncthing.net/">syncthingd</a> with a server that I rent</p>
<p>My legal documents are all tied in one folder on my laptop which is also synced on the same server</p>
<p>So basically we have all the needed documents which are synced in real time on the same server</p>
<h2>Second step : Choose how to trigger the sharing of documents</h2>
<p>The biggest problem is you want the alert to react quickly but not fire because you have been sleeping for 8 hours. So I chose to rely on the time since I last changed of activity. Currently after 24h without changing activity a first notification is sent to my own email so that if this is a mistake I can stop the system before it is too late. And if 6 hours later I've still haven't changed of activity then a mail is sent to my parents.</p>
<p>So basically if something happens to me my parents will be notified maximum 30h after the event, this is not so great but this is a good beginning. In the future I should try to have an adaptive delay depending on the last activity, for example if my last activity is eating, then I won't eat for 24 hours, so I can trigger the alert after for example 4 hours.</p>
<h2>Last step : What to put inside the notification</h2>
<p>So my parents will receive an email after 30 hours of inactivity. In this email there is a link to a page which will allow them to retrieve all the documents.
<img alt="email" src="https://blog.luap.info/static/kidnap/email.png"></p>
<p>The link is random generated link available only 6 hours, this is important to be safe as you don't want anyone to be able to access all your passwords ...</p>
<p>And the page, there are explanations of that page is about, like, "maybe I was kidnaped, maybe I'm lost, check my last time active on whatsapp, contact xxxx to see if he knows anything"
You can also view the current position of my phone and a small location history, that way you can see if I'm still moving, or if the last point if 30 hours old, you can also see my last activity and when it started</p>
<p>And finally you can get the list of all my passwords, for that purpose I created a form, with 6 facts on my life, that only my parents can know all of them, like what was the color of my first car ..., then there you can submit your answer, there is a rate limit on the number of requests you can make to prevent a brute force. If the 6 answers are true, the backend will decode the keepassxc archive and return a json of the archive, containing all of my credentials, including the ssh password to connect on the server to get all the paper documents.</p>
<h2>Conclusion</h2>
<p>I know that all of that is far from being perfect. I check every few months that the alerting is working, by decreasing the delay to trigger the alert, but the server can go down, ton of things can happen to make the system not working, so that's why I tried to keep everything as simple as possible, postgresql + django + cron. Someone should create a service to manage that at a bigger scale, or maybe that's something that 1password or others could include in their offer</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/planning-for-my-kidnapping.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050837</guid>
            <pubDate>Tue, 04 Aug 2020 15:20:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why, like Ariana, you should be grateful for your ex (IDE)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050750">thread link</a>) | @archyking
<br/>
August 4, 2020 | https://marquee.activecove.com/blog/5 | <a href="https://web.archive.org/web/*/https://marquee.activecove.com/blog/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://marquee.activecove.com/blog/5/top.jpg"></p><p>The internet is full of first-person advice: Why "I" moved from X to Y and "my" life is so much better now. iPhone to Android. Python to Java. Firefox to Chrome. Semicolons to blank line breaks. Emacs to Vim. The list goes on.</p><p>While more philosophical than factual, this sort of "advice" often overlooks the benefits of experiencing diverse options yourself that will inevitably expand our toolbox make you wiser. Take it with a grain of salt.</p><p><img src="https://marquee.activecove.com/blog/5/editors.png" alt="Marquee Blog"></p><h2>🧑‍🎤 What's your next IDE?</h2><p>Let's take a look at (ex-) development environments. (Ex-) IDEs more specifically. Ariana Grande serenades how one taught her love, one taught her patience, and one taught her pain. That'd be Vim, Xcode, and Eclipse for myself - in Miss Grande's exact order.</p><blockquote><p>VS Code is quickly catching up with my ❤️ vim-love. Which is how <a href="https://marketplace.visualstudio.com/items?itemName=activecove.marquee">Marquee, an extension for VS Code</a> came into existence.</p></blockquote><p>Having spent two decades in software development leading teams and organizations, one thing is certain: one size fits all does not exist. Infra is different from algorithms is different from app development is just as different as people are. In fact, saying "thank you, next" regularly is encouraged - get to know what's out there! Also, no need to be shy to go back to your familiar options when the situation calls for it.</p><h2>👻 One size fits all does not exist</h2><p>If you just got started with development, don't let platitudes about "if you need auto-complete to write code YOU don't code" get in your way. I recently taught myself Typescript and my learning journey was greatly expedited by VS Code's first class support for it. However, while it built my comprehension, I would happily write Typescript in GNU's nano. Probably slowed-down by a factor of 2x because... NANO 😑.</p><p>More recently I helped build an extension for VS Code called <a href="https://marquee.activecove.com/">Marquee</a>. Hopefully one day Marquee will be available for all editors. We didn't start out with VS Code for pure love - no, we wanted to fill a real gap. VS Code is also the most exciting platform for developers; perhaps only second to the browser which is much less specifically designed for devs.</p><p><img src="https://marquee.activecove.com/blog/5/marquee.png" alt="Marquee Blog"></p><blockquote><p>Stay on top of your VS Code windows. <a href="https://marketplace.visualstudio.com/items?itemName=activecove.marquee">Marquee is available</a> from the VS Code Marketplace.</p></blockquote><p>Even though there is a lot of VS Code in my life today, you will still witness me vim-editing files on remote hosts or even in VS Code's embedded terminal as much as firing up Xcode to inspect some iOS code. I won't write about how one saves more time or grief than the other.</p><h2>🤓 Growth mindset means getting out of the comfort zone</h2><p>The one advice you should take to heart is this: don't get too comfortable for too long. Try out new things and cherish what you already know. Depending on what matters to you in the situation - getting the project done, learning something new, jumping head first into the cold water - diversity of first-hand experiences will give you options, lead to better results, and be your saving grace.</p><p>Seriously, though, VS Code is fantastic. If you are on it already please give <a href="https://marquee.activecove.com/">Marquee</a> a spin. Feel free to contact us on <a href="https://twitter.com/activecove">twitter</a> or using the "Give Feedback" button inside Marquee.</p></div></div></div>]]>
            </description>
            <link>https://marquee.activecove.com/blog/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050750</guid>
            <pubDate>Tue, 04 Aug 2020 15:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Setup Vim as an IDE for React/TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050656">thread link</a>) | @bojanvidanovic
<br/>
August 4, 2020 | https://bojanvidanovic.com/posts/how-to-setup-vim-as-an-ide-for-react-typescript/ | <a href="https://web.archive.org/web/*/https://bojanvidanovic.com/posts/how-to-setup-vim-as-an-ide-for-react-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Thanks to the Vim’s vast choice of <a href="https://vimawesome.com/">plugins</a>, I’ve been using Vim daily for developing React applications in TypeScript. I classify these plugins as essential to make Vim a perfect IDE environment for programming although you might not need them as you can already do anything out-of-the-box, I’d still recommend installing them and making code writing more enjoyable and less error-prone.</p>
<p>I assume you have some basic skills in Vim or read my <a href="https://bojanvidanovic.com/posts/5-most-essential-vim-commands-for-beginners/">previous article</a> as a starting point.</p>
<h2 id="install-plugin-manager">Install plugin manager</h2>
<p>Before we install any of the plugins, first we will need a plugin manager. There are many plugins managers for Vim, but always recommend using <a href="https://github.com/junegunn/vim-plug">vim-plug</a> mainly for its simplicity and ease-of-use.</p>
<figure>
<img src="https://res.cloudinary.com/bojan/image/upload/v1596552031/installer_ix85nf.gif">
</figure>
<p>So go ahead and execute this command in the CLI:</p>
<div><pre><code data-lang="shell">curl -fLo ~/.vim/autoload/plug.vim --create-dirs <span>\ </span>https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim</code></pre></div>
<p>After it finished, add a vim-plug section to your ~/.vimrc file.
</p><div><pre><code data-lang="shell">call plug#begin<span>()</span>
<span>" In this section you will manage all of your future plugins.
</span><span>"</span> Plug <span>'example-path-to-git-repository'</span>
call plug#end<span>()</span></code></pre></div>
<p>Essentially, in this block of code we have added you will include the path to the repository of the plugin you want to install by inserting <code>Plug 'path-to-repo'</code> and from inside Vim you will call: <code>PlugInstall</code>.</p>
<h2 id="asynchronous-lint-engine">Asynchronous Lint Engine</h2>
<p><a href="https://github.com/dense-analysis/ale">ALE</a> is a plugin that will provide linting with syntax checking and semantic errors for your code.</p>
<figure>
<img src="https://res.cloudinary.com/bojan/image/upload/v1596551535/ale_w544ts.gif">
</figure>
<p>Let’s install it by including it in the Vim Plug and call :PlugInstall</p>
<div><pre><code data-lang="shell">Plug <span>'dense-analysis/ale'</span></code></pre></div>
<p>After this, I recommend reading the documentation of the plugin to adjust the plugin better to your style of writing code.</p>
<h2 id="coc-conquer-of-completion">CoC - Conquer of completion</h2>
<p><a href="https://github.com/neoclide/coc.nvim">CoC</a> is a completion engine and you really really want this one. This plugin saves me a lot of typing and peaking into other files for properties verification.</p>
<figure>
<img src="https://res.cloudinary.com/bojan/image/upload/v1596551521/coc_eftpyw.gif">
</figure>

<h2 id="yats-yet-another-typescript-syntax">YATS: Yet Another TypeScript Syntax</h2>
<p><a href="https://github.com/HerringtonDarkholme/yats.vim">YATS</a> is a TypeScript syntax highlighter with the most appealing color scheme for TypeScript code. Not just making your beautiful but also much more readable.</p>
<figure>
<img src="https://res.cloudinary.com/bojan/image/upload/v1596551519/yats_viclae.png">
</figure>
<div><pre><code data-lang="shell">Plug <span>'HerringtonDarkholme/yats.vim'</span></code></pre></div>
<h2 id="ctrlp-vim-fuzzy-finder">ctrlp.vim - Fuzzy finder</h2>
<p>You might have used this feature in VSCode, with <a href="https://github.com/ctrlpvim/ctrlp.vim">ctrlp.vim</a> plugin we can get the same functionality. Very useful for searching the files on the go.</p>
<figure>
<img src="https://res.cloudinary.com/bojan/image/upload/v1596551519/fuzzy_parwqn.png">
</figure>
<div><pre><code data-lang="shell">Plug <span>'ctrlpvim/ctrlp.vim'</span></code></pre></div>
<h2 id="conclusion">Conclusion</h2>
<p>These are some of the most essential plugins to get you going writing the code in React and TypeScript.</p>
<section id="mc_embed_signup">

</section>
<section>
<img src="https://res.cloudinary.com/bojan/image/twitter_name/w_100,h_100,c_fill,r_max/bojan_vidanovic.jpg" width="100" height="100">

</section>
</div></div>]]>
            </description>
            <link>https://bojanvidanovic.com/posts/how-to-setup-vim-as-an-ide-for-react-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050656</guid>
            <pubDate>Tue, 04 Aug 2020 15:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The basics of hiring Remote Employees]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050382">thread link</a>) | @dmonn
<br/>
August 4, 2020 | https://nohq.co/blog/how-to-hire-remote-employees/ | <a href="https://web.archive.org/web/*/https://nohq.co/blog/how-to-hire-remote-employees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Remote hiring is one of the things that is very different from a traditional company. In a traditional company, the company usually has an office and corporation set up in the area you work in or at least have set up <a href="https://nohq.co/blog/how-much-should-you-pay-remote-employees/">payroll</a> there. Hiring people is easy and a normal employment contract is usually enough to get people hired full-time in a legally compliant way.</p>
<h2>The difficulties of hiring remote employees</h2>
<p>The responsibilities of an employer are very regulated too: PTO days are usually fixed, payroll knows how to deal with possible deductions such as taxes, social security and benefits and special local regulations are usually accommodated. That's not always the case with remote work.</p>
<p>When you are hiring remotely, you need to make sure you are compliant with local laws. Employees might face high social deductions, based on their country of residence, and it's also your responsibility to keep your employees informed on how much they are going to make after-tax.</p>
<p>PTO is also immensely different based on location: While in Europe 25-30 PTO days and 10-15 public paid holidays are often standard, it's usually lower in the US and Asia. There are other exceptions where an employee can take a day off, for example for Jury Duty in the US or military service in multiple other countries. Finally, <a href="https://nohq.co/blog/perks-for-your-remote-employees/">benefits are often very different as well</a> – while in the US you would usually expect to receive healthcare benefits and a 401k, that's not usual in many other countries.</p>
<p>There is a lot to watch out for, so what are your options?</p>
<h2>Hiring remotely through up a sub-corporation</h2>
<p>If a company is planning to set up a hub in a specific country, it can be worth it to establish a permanent sub-corporation in that state or country. In that case, the company officially incorporates there, sets up payroll (which usually involves hiring an accountant or accounting consultant) and then has the ability to legally hire people in that country or state.</p>
<p>This is not trivial and probably not an option unless you're a bigger corporation looking to hire 10+ people (depending on the country) there. The time commitment and cost is simply too high and things can get complex with multiple sub-corporations in terms of administration and taxes.</p>
<p>The advantage of it is clear: There's no substantial additional administration cost per hire, employees are employed with a local employer (often taking a lot of effort off their shoulders) and while the initial setup is taking a lot of effort, the maintaining of the corporation isn't so much work compared to some other options.</p>
<h2>Hiring remote employees as contractors</h2>
<p>Often a preferred way to hire people in remote companies is to simply list them as a contractor and getting invoiced from them on a monthly basis. This puts much of the needed effort on the shoulders of the employee, which is often more preferable in small companies.</p>
<p>It's absolutely needed to give employees time for administration in this case. Additionally to their work, they will have the handle the additional work that comes from running your own business, such as declaring themselves as self-employed or forming an LLC, possibly pay profit/income taxes additionally to their personal ones, figuring out all insurance and deductions that are needed and handling local nuances, such as setting up proper social security, handling retirement funds and healthcare.</p>
<p>While this sounds like a lot of work, a lot of these are once-per-year activities. Most remote companies still tend to go with this option. It's the cheapest, possibly fastest, simplest and most flexible way to get someone hired.</p>
<h2>Utilizing a payroll service to hire remotely</h2>
<p>In some countries, getting hired as a contractor is just not so easy as it might seem.</p>
<p>When I started working remotely myself, I looked into this for my home country Switzerland, and quickly realized that this came with too many disadvantages. Namely:</p>
<ul>
<li>To count as independently self-employed, I'd have to send invoices for at least three different clients to the government every month. This is not possible, if you're working on a single contract</li>
<li>I'd have to have opened a local LLC to work for a single client, requiring a security deposit of $25,000.</li>
<li>I'd have to calculate my social security and pension funds every year, and invoicing them separately to my employer</li>
<li>I wouldn't have gotten paid my full salary during military services (it's still mandatory here, the government reimburses salary)</li>
</ul>
<p>So we went ahead with a <a href="https://nohq.co/blog/hiring-remote-workers-in-foreign-countries/">local payroll service</a>.</p>
<p>A payroll service or global employer is a company that has set up payroll in a country. They're able to hire people locally, do all the work required for a local employee, and invoice the "real" employer accordingly. This service often costs $100 - $300 per month per employee, so as things scale up, can get costly. But else it is the least amount of effort required to hire someone remotely.</p>
<p>I like payroll companies so much, that <a href="https://payroll.nohq.co/" target="_blank" rel="noopener">I've put together a list of them</a>, one for (almost) every country out there. Whether you're looking to hire someone in Canada, Australia, Germany or Barbados, there is a payroll company there.</p>
                </div><div>
    <h3>Exclusive content right in your inbox</h3>
    <div>
        <p>
            Our newsletter is sent every other week to show you how to build a happy, healthy and efficient remote team.
        </p>
        
    </div>
</div></div>]]>
            </description>
            <link>https://nohq.co/blog/how-to-hire-remote-employees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050382</guid>
            <pubDate>Tue, 04 Aug 2020 14:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google has shut down Toogles]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050379">thread link</a>) | @mcrittenden
<br/>
August 4, 2020 | https://critter.blog/2020/08/04/a-farewell-to-toogles/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/04/a-farewell-to-toogles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-553">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p><a href="https://toogl.es/#/browse">Toogles</a> is (was) a super lean app to search and watch YouTube videos without all of the other crap that YouTube.com brings with it (comments, suggested videos, subscriptions, etc.). </p>



<p>I created it back in 2012, as a way to learn AngularJS and Zurb Foundation. Since then, it’s built up a small but dedicated community of users who just want to watch videos without all of the bloat. In the month of July, it got just over 100k pageviews.</p>



<p>Sadly, Google finally put an end to it. This morning, I was emailed that my API access was shut down for using it to run an app that clones the basic functionality of YouTube.com. </p>



<p>The specific complaint is:</p>



<blockquote><p>You and your&nbsp;API Clients&nbsp;must not, and must not encourage, enable, or require others to use&nbsp;YouTube API Services&nbsp;to create, offer, or act as a substitute for, or substantially similar service to, any&nbsp;YouTube Applications.&nbsp;API Clients&nbsp;must not mimic or replicate YouTube’s core user experiences by recreating features or process flows unless they add significant independent value or functionality that improves users’ interactions with YouTube. For example, an&nbsp;API Client&nbsp;must not recreate the browse experience from any YouTube Application without adding significant independent value to that flow.</p><cite><a href="https://developers.google.com/youtube/terms/developer-policies#i-additional-prohibitions">YouTube Terms and Conditions</a></cite></blockquote>



<p>So that’s that. I can’t really argue that Toogles didn’t act as a substitute for a YouTube application, because that’s exactly what it did. I even had a Chrome extension to redirect YouTube.com video URLs to Toogles. </p>



<p>I am sad to have to say goodbye to my beloved Toogles. I am sad to be stuck with YouTube.com and all of the bloat and distraction that it brings. But I can’t say that Google is being unfair. I was breaking the rules, they found out, and that’s that. </p>



<p>Anyone know of any good browser extensions for stripping down YouTube.com? If so, <a href="https://twitter.com/mcrittenden">tweet me</a>.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/04/a-farewell-to-toogles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050379</guid>
            <pubDate>Tue, 04 Aug 2020 14:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The necessary balance between KPIs and CPIs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050298">thread link</a>) | @Gpetrium
<br/>
August 4, 2020 | https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="3245" data-elementor-settings="[]"><div><div><section data-id="7b33e182" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_bottom&quot;:&quot;opacity-tilt&quot;}"><div><div><div data-id="3aabdd33" data-element_type="column"><div><div><div data-id="67751569" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1200" height="694" src="https://gpetrium.com/wp-content/uploads/2020/08/769-min.jpg" data-src="https://gpetrium.com/wp-content/uploads/2020/08/769-min.jpg" alt="Designed by vectorpouch / Freepik" data-srcset="https://gpetrium.com/wp-content/uploads/2020/08/769-min.jpg 1200w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-300x174.jpg 300w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-1024x592.jpg 1024w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-768x444.jpg 768w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-600x347.jpg 600w" data-sizes="(max-width: 1200px) 100vw, 1200px" srcset="https://gpetrium.com/wp-content/uploads/2020/08/769-min.jpg 1200w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-300x174.jpg 300w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-1024x592.jpg 1024w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-768x444.jpg 768w, https://gpetrium.com/wp-content/uploads/2020/08/769-min-600x347.jpg 600w"></p></div></div></div></div></div></div></div></section><section data-id="594b6576" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="55a05f5d" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="4a78f3cb" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="148c2dd7" data-element_type="column"><div><div><div data-id="2ff05d74" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Key Performance Indicators (KPIs) allows companies, departments, and teams to assess their overall performance over a period of time. Such metrics are usually inner looking and are associate with factors that are important to the business, for example: revenue, customer retention, net sales, and so on.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; KPIs are often used to quantify the success and effectiveness of an individual, project, team, department, or even entire corporation. As such, they can directly impact incentive mechanisms and consequently, employee behaviour when extensive emphasis is placed on hitting and improving upon KPIs. Depending on the type of KPI, incentive structure and expectations, employees may feel pressured to squeeze more desirable metrics and may resort to negative/ unethical behaviour to achieve said outcomes. For example, Wells Fargo, a major financial institution was caught in a scandal where some employees illegally falsified customer accounts and created over 2 million fake bank accounts to reach companies KPIs and compensation structures. Once it was found, it led to a government settlement of US$3 billion (<a href="https://www.nytimes.com/2020/02/21/business/wells-fargo-settlement.html">NYT</a>).</p></div></div></div><div data-id="3da557ca" data-element_type="widget" data-widget_type="heading.default"><p><h2>Driving organizational success with Customer Performance Indicators (CPIs)</h2></p></div><div data-id="3bfd6b7a" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; On the other hand, Customer Performance Indicators (CPIs) have been identified by some as powerful predictors of growth (<a href="https://hbr.org/2020/04/the-most-important-metrics-youre-not-tracking-yet">HBR</a>). CPIs are customer-centric metrics that allows the organization to track the outcomes that are deemed important to the customer. Such parameters are put in terms that are meaningful to customers, for example: instead of “time to receive quote”. Given the fact that CPIs are often related to customer experience, they can directly impact KPIs. For example, <em>Quality of Purchase Experience</em> could be considered a CPI in a store and it can positively affect <em>Sales Growth</em>, a KPI, should customers continue to choose to purchase at certain location given the high CPI.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As explained in the article, “<a href="https://hbr.org/2020/04/the-most-important-metrics-youre-not-tracking-yet">The Most Important Metrics You’re Not Tracking (Yet)</a>” customers, and individuals at large, always have a purpose (or problem or need) and an expectation of how it will be solved. For companies that claim to put customers at the center of their operations, such metrics are paramount for client satisfaction – and tying them back to KPIs ensure that sound business judgement is employed throughout operations.</p></div></div></div><div data-id="8ebf300" data-element_type="widget" data-widget_type="blockquote.default"><div><blockquote><p> This is the primary rationale for adopting CPIs: The more your company’s attention is focused on outcomes important to your customers (CPIs), the better your company will likely perform on outcomes important to the business (KPIs).</p></blockquote></div></div><div data-id="118f6f47" data-element_type="widget" data-widget_type="heading.default"><p><h2>The Importance of Performance Indicators – A Balancing Act</h2></p></div><div data-id="16a18faf" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In general, Performance Indicators (PIs) provide a means to quantify current and past performance associated to a company, department, team, or individual. Further, they also provide clear insight into goals and objectives to be achieved. They need to be clear and quantifiable. It is quite challenging to set an objective and not provide clear parameters that quantify the objective.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For example, saying that “sales need to increase” can be an ambiguous objective. It leaves room for interpretation as one might assume that an increase in the absolute number of sales satisfies the requirement – even if the total net amount of sales might result on being lower than what was previously reported. However, when an objective is directly tied to a PI, goals become clearer and are easier to achieve. For example, by stating “increase the number of new contracts signed per period by 5%”, the goal becomes more actionable. Evidently, other considerations such as <a href="https://www.atlassian.com/blog/productivity/how-to-write-smart-goals">SMART</a> goals need to be taken into account when drafting actionable goals.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As it is widely known, PIs can be specific to an industry, department, team, or even an individual within a team. As such, blindly tracking trendy PIs may not award the best measurement of success for the intended purposes.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Additionally, the idea of tracking CPIs as opposed to KPIs can be alluring and it makes a lot of sense for customer-centric companies or customer-facing departments and teams. However, even in customer-centric companies, there are certain situations in which it is necessary to focus on improving KPIs to increase customer satisfaction. For instance, customers do not care about keyword ranking, but that is an important metric to track if you want customers to find your products on the internet.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Certain KPIs can also give important insights into CPIs and overall customer behaviour. For instance, leads/ conversion rates may directly speak into the likelihood of which a customer visit to a website transitions into the buying stage. If conversation rates are suboptimal when compared to the industry (leave aside other factors), it might prompt the business into pursuing more research on why customers don’t feel enticed to make purchases.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; When deciding on which type of PI to track, it is important to critically assess the need and why such metric is being tracked. Is it to have a better sense of what drives growth in the company? Is it to understand how a department is performing at a point in time? Most often, it is associated with improving a certain metric or achieving a certain goal. In that case, specially in customer facing teams, there can be benefits in tracking CPIs and KPIs.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; By tracking CPIs (metrics that are of importance to customers) businesses are able to better understand the correlation between such numbers and KPIs, customer’s desire, and some of the factors that influence their purchasing behaviour. All valuable data that can assist organizations in enhancing the overall quality of their service.</p></div></div></div><div data-id="3641f7c3" data-element_type="widget" data-widget_type="heading.default"><p><h3>Performance Indicators’ Best Practices</h3></p></div><div data-id="6d0ef995" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As mentioned previously, the decision of tracking a specific KPI or CPI needs to be critically assessed. Such metrics are unique to the functions within a team. For instance, even in the HR department, the metrics tracked by the Compensations and Benefits team can be completely different from that of the Employee Relations team. The same observation is valid throughout the organization. Below are some best practices to be considered when deciding which and how to track KPIs:</p><ul><li><strong>Relate it to Strategy:</strong> associating KPIs with the overall strategy of the team, department, and individual is an important method to facilitate the accomplishment established objectives and goals. Further, it allows to better gauge performance in comparison to such objectives – allowing organizations to not just “talk the talk”.</li><li><strong>Data Gathering Process:</strong> KPIs are impacted by all the processes that come before the numbers are presented. As such, best practices for data gathering also need to be respected in order to report accurate numbers. Principles of transparency, privacy, protection, quality, identification, collection, approach, and analysis need to be taken into consideration.</li><li><strong>Purpose:</strong> it is important to understand why a performance indicator is believed to be relevant not only to the organization at large, but also to the department/ team in which the metric in being considered.</li><li><strong>Cost to build &amp; manage</strong>: The more robust a PI solution, the higher the likelihood that it can be expensive to maintain a robust PI that satisfies the organization’s needs. Understanding the current technological capabilities, coupled with organizations goals and means is essential to build a balanced solution.</li><li><strong>Incentive:</strong> alongside the purpose of the PI, it is important to understand the types of incentives that it may create on the workforce – especially when such PIs are strictly managed, enforced, beyond reasonable expectations and/ or impact pay or accolades given.</li><li><strong>SMART Goals:</strong> despite having slightly different variations, the S.M.A.R.T. acronym is incredibly helpful to set realistic and attainable goals and it should be employed when setting expectations associated to KPIs and CPIs. For more information on the practice, <a href="https://www.projectsmart.co.uk/smart-goals.php">Duncan Haughey</a> explores the different meanings behind the acronym and how they can be properly deployed. Emphasis should be placed on setting goals that are attainable, accurate, and not vague.</li></ul></div></div></div><div data-id="4c61201" data-element_type="widget" data-widget_type="heading.default"><p><h3>Beyond Performance Indicators</h3></p></div><div data-id="fcf6e6e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Performance indicators are important to measure the overall productivity and effectiveness of the efforts employed by individuals, teams and departments. However, it is also important to take into consideration the context in which the PIs and expectations are being deployed.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For instance, during times of hardship and constant change, such as the COVID-19 pandemic, it is important to understand that external factors may impact internal achievement and overall performance. Further, as external pressures occur, KPIs may need to be re-evaluated to match current goals and strategies. For example, during the COVID-19 pandemic, some departments may have set goals with transitioning their workforce to remote working which meant that some internal KPIs may have changed to reflect new goals or needs that were brought upon them due to external conditions. As such, PIs can be contextual not only to the function, but also to the environment in which they are set. Understanding the incentives, they create in the workforce and how it translates into operations and service quality is paramount to overall success.</p></div></div></div><div data-id="7d62a2ad" data-element_type="widget" data-widget_type="text-editor.default"><div><p>The opinions in this article is of the authors and do not reflect clients or other’s views.</p></div></div><section data-id="1d5840a7" data-element_type="section"><div><div><div data-id="3aaecc47" data-element_type="column"><div><div><div data-id="5646d6ed" data-element_type="widget" data-widget_type="author-box.default"><div><div> <p><a href="https://www.linkedin.com/in/brenda-gonzales/"> <img src="https://gpetrium.com/wp-content/uploads/2019/12/LBSA-Gala-4-199x300.jpg" data-src="https://gpetrium.com/wp-content/uploads/2019/12/LBSA-Gala-4-199x300.jpg" alt="Brenda Gonzales"> </a></p></div></div></div></div></div></div><div data-id="42335a0d" data-element_type="column"><div><div><div data-id="588d47cf" data-element_type="widget" data-widget_type="author-box.default"><div><div> <p><a href="https://www.linkedin.com/in/guilherme-peterson/"> <img src="https://gpetrium.com/wp-content/uploads/2019/12/IMG_20180627_172807-225x300.jpg" data-src="https://gpetrium.com/wp-content/uploads/2019/12/IMG_20180627_172807-225x300.jpg" alt="Guilherme Peterson"> </a></p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="6602159d" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1394b1f5" data-element_type="column"><div><div><div data-id="657eea7" data-element_type="widget" data-settings="{&quot;classic_columns&quot;:&quot;3&quot;,&quot;classic_columns_tablet&quot;:&quot;2&quot;,&quot;classic_columns_mobile&quot;:&quot;1&quot;,&quot;classic_row_gap&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:35,&quot;sizes&quot;:[]}}" data-widget_type="posts.classic"><div><div><article><div><h3> <a href="https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/"> The necessary balance between KPIs and CPIs	</a></h3><p><span> August 4, 2020	</span></p><p>The necessary balance between KPIs and CPIs Share on facebook Share on twitter Share on linkedin Share on email Share on whatsapp &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Key Performance Indicators (KPIs) allows companies, departments, and teams to assess their</p> <p><a href="https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/"> Read More »	</a></p></div></article><article><div><h3> <a href="https://gpetrium.com/account-hijacking-a-persistent-threat/"> Account Hijacking – A Persistent Threat	</a></h3><p><span> July 23, 2020	</span></p><p>Account Hijacking – A Persistent Threat Share on facebook Share on twitter Share on linkedin Share on email Share on whatsapp What is Account Hijacking? …</p></div></article></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/">https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/</a></em></p>]]>
            </description>
            <link>https://gpetrium.com/the-necessary-balance-between-kpis-and-cpis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050298</guid>
            <pubDate>Tue, 04 Aug 2020 14:26:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Don’t Need SMS 2FA – Replacement Included]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24050281">thread link</a>) | @33Backpack33
<br/>
August 4, 2020 | https://passwordbits.com/dont-need-sms-2fa/ | <a href="https://web.archive.org/web/*/https://passwordbits.com/dont-need-sms-2fa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>We don’t need SMS 2FA.</p>



<p>I’m going to break down why we don’t need SMS 2FA and give you a replacement that is not only better but cheaper and easier too.</p>



<h2>What Is SMS 2FA?</h2>



<p>Hopefully, if you’re reading this, you have a good understanding of SMS 2FA.</p>



<p>If you don’t, SMS 2FA is the text message you get after entering your username and password. It’s another factor that is needed to log into an account.</p>



<h2>What’s The Purpose Of SMS 2FA?</h2>



<p>The goal of any 2FA is if your first factor (your password) is already known, the second factor (SMS 2FA) will keep the attacker out.</p>



<p>What are the ways a password is already known?</p>



<ol><li>Phishing.</li><li>Password reuse/credential stuffing attacks.</li><li>Malware.</li><li>Guessing/brute force.</li></ol>



<p>These are the most common ways a password is already known and why we use SMS 2FA.</p>



<p>Now the question becomes, does SMS 2FA actually solve these attacks? Not only that but is it the best option?</p>



<h2>1. Why SMS 2FA Is Not Immune To Phishing</h2>



<p>Phishing is when you get someone to go to the wrong website that looks like the real website and get them to enter their credentials.</p>



<p>Sounds simple enough; the user would fall for entering their username and password, but since the SMS 2FA code is one time use the attacker knowing it will be useless to them.</p>



<p>The problem is that this assumes hackers don’t evolve and change strategies. It’s not 2004 anymore; phishing has progressed quite a lot.</p>



<h3>One Example Is Modlishka</h3>



<figure><p>
<iframe title="Phishing with Modlishka (bypass 2FA)" src="https://player.vimeo.com/video/308709275?dnt=1&amp;app_id=122963" width="770" height="433" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p></figure>



<p>To understand how this attack works, you need to think of the website the attacker sent you to as a web browser.</p>



<p>Your web browser goes to the attacker’s website. The attacker’s website then acts as a web browser for your web browser.</p>



<p>The user is using the real website but through the lens of the attacker’s website. Besides the URL in the user’s web browser not being correct, they’re none the wiser.</p>



<p>The user logs in with 2FA, and the attacker now has a session cookie, which keeps them logged in. The attacker has the username, password, and 2FA code.</p>



<p>The attacker’s server (aka “web browser”) has the session which means they’re already logged in and can do whatever they want. They could even turn 2FA off since most services don’t require 2FA to turn 2FA off once logged in.</p>



<h3>Modlishka Isn’t The Only One</h3>



<p>Since Modlishka is open source and free you get many variations that are also open source and free. Here is another example…</p>



<figure><p>
<iframe title="Kuba Gretzky - Phishing Through Modern 2FA Defences With Evilginx" width="770" height="433" src="https://www.youtube.com/embed/QRyinxNY0fk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>These two phishing attacks have <strong>set the new floor for phishing</strong>. It only can get worse from here as the attackers will not go back to worse phishing programs. </p>



<p>This is why SMS 2FA is not a solution to the phishing problem.</p>



<p>The replacement at the end <strong>can</strong> help stop phishing.</p>



<h2>2. SMS 2FA Doesn’t Stop Credential Stuffing Attacks</h2>



<p>Saying SMS 2FA doesn’t stop credential stuffing attacks seems to be a sticking point for some.</p>



<p>The problem comes from the misunderstanding of credential stuffing attacks.</p>



<p>Jarrod Overson answers it best…</p>



<p><a href="https://medium.com/@jsoverson/no-2fa-does-not-stop-credential-stuffing-attacks-79de7476a80a"><em>The point of a credential stuffing attack is to boil a list of mostly-junk credentials into a list of valid credentials per service. If a service presents its 2FA gate to the user after they have entered in a good username and password then a credential stuffing attack still results in a list of valid accounts. What it doesn’t lead to is an immediate account takeover. This is an important nuance and, without acknowledging it, the phrasing leaves people thinking that 2FA is a silver bullet and that a silver bullet exists at all.</em></a></p>



<p>I suggest you read the rest of what Jarrod wrote.</p>



<p><strong>Attacks are layered and seeing an SMS 2FA</strong> <strong>screen doesn’t mean the attacker calls it quits</strong>. Instead, that user’s username and password go on a new list for the next round of attacks. The more the users are filtered, the more valuable they become as the attacker gets closer to their goal.</p>



<p><strong>You haven’t made it more difficult for the attacker; you instead made the user more valuable to the attacker.</strong></p>



<p>The next attack could be a targeted phishing attack, and as we know, SMS 2FA doesn’t hold up to that. What’s scarier is that a lot of users don’t have any 2FA on their email and love to reuse passwords especially ones that the attacker already filtered out from the credential stuffing attack. This means the attacker is just one password reset away from getting to their target after taking over the email account. 2FA is not as popular and abundant as everyone in the tech community thinks; <a href="https://www.theverge.com/2018/1/23/16922500/gmail-users-two-factor-authentication-google" target="_blank" rel="noreferrer noopener">90% of Gmail users don’t use any 2FA</a>. </p>



<p>This is why we say SMS 2FA is only “<em>kicking the can down the road</em>“. You’re not solving the problem but only delaying it. </p>



<p>The replacement at the end makes credential stuffing attacks useless. </p>



<h2>3. SMS 2FA Doesn’t Stop Malware</h2>



<p>The first immutable law of security.</p>



<p><strong><a href="https://techtalk.gfi.com/security-101-the-10-immutable-laws-of-security-revisited/" target="_blank" rel="noreferrer noopener">If a bad guy can persuade you to run his program on your computer, it’s not solely your computer anymore.</a></strong></p>



<p>SMS 2FA doesn’t protect the user against malware. There exist malware today that has shown that 2FA can’t stop it.</p>



<figure></figure>



<p>Even better, if the malware has control over the device, they can change any web address to point to <strong>any</strong> website and perform the Modlishka attack.</p>



<p>Malware is a lose-lose situation.</p>



<h2>4. Guessing And Brute Force Attacks</h2>



<p>Straight up guessing someone’s password is not easy. Math and time are against you.</p>



<p>Unless the user is reusing the same or similar password, guessing is not something that happens much.</p>



<h3>Example Of How Hard It Is To Guess A Password</h3>



<p>Guessing passwords is not easy; here is an example with me telling you the password requirements.</p>



<p>Length = 16 exactly<br>Character set = 62 (upper, lowers, numbers)</p>



<p>If its precisely 16 characters long, it would take 1,487,111,351 years to guess all possibilities at <a href="https://threatpost.com/researcher-bypasses-instagram-2fa/146466/" target="_blank" rel="noreferrer noopener">1 trillion guesses per second</a>. </p>



<p>This is ignoring slow hashing algorithms that would significantly extend guess time.</p>



<h3>Most Services Already Stop Guessing Attacks</h3>



<p>This is especially true on many services as they limit such attacks from happening in the first place.</p>



<p>It’s not hard to see one username being hit a lot of times with wrong password guesses.</p>



<p>Even if it’s from multiple IP addresses, you can still lock the user’s account as many services already do.</p>



<h2>SMS 2FA Resets</h2>



<p>Before we get to the replacement, we need to talk about SMS Resets.</p>



<p>And yes, I hear many of you right now saying SMS 2FA is not SMS Resets.</p>



<p>While this is true, it would be disingenuous to not talk about it because SMS Reset often comes along with SMS 2FA. They’re apart of the package on many websites, whether you want them or not.</p>



<p>We can’t ignore SMS Resets because this often means you can bypass everything with just a phone number and get into an account. Even worse are the websites that don’t have SMS Resets but add it later because they already have SMS 2FA.</p>



<p>SMS Resets are the worst thing about SMS 2FA, and ignoring it “because they’re not the same” is not helping the situation.</p>



<h2>The Replacement – Do This Instead Of SMS 2FA</h2>



<p>What’s great about the replacement to SMS 2FA is that it’s easier, cheaper, and more effective.</p>



<p>It’s quite shocking that we’re not doing it more often…</p>



<p><strong>Generate the passwords for the users!</strong></p>



<p>It’s that simple. I’ve already done a <a href="https://passwordbits.com/generate-user-passwords/">massive write up on why websites should generate passwords for users here</a>. </p>



<p>It solves all the shortcomings of SMS 2FA. It’s easier to understand. It’s easier to implement. It’s cheaper and no need to use 3rd party support. </p>



<h2>Educating Users Happens At Signup</h2>



<p>Besides dorks like me, the average user is not going to research passwords and how to be more secure.</p>



<p>The place where users are getting educated about passwords is happening at the signup page.</p>



<p><strong>We’ve spent years teaching users to make complex passwords with password requirements when we should have been teaching them to use unique passwords.</strong></p>



<p>The best way to teach a user to use a unique password is to do it for them. Creating passwords for users gets them to think of passwords as something you store, not something you remember.</p>



<h3>Passwords Need To Be Stored, Not Remembered</h3>



<p>Generating passwords for users gets them to treat passwords like they do phone numbers. No one remembers phone numbers anymore as they use the contact app on their phone or little black book.</p>



<p>Instead of giving password requirements, tell the user to write the password down, let the browser store it, or use a password manager.</p>



<p>Many users are simply not aware of such things and need to be told.</p>



<h3>It’s Not 2004 Anymore</h3>



<p>You can’t use the internet without a web browser and every web browser offers to store and fill passwords for you.</p>



<p>Every browser has profiles that allow you to log in from any computer and get passwords and bookmarks.</p>



<p>Every major browser works on all devices, even mobile. </p>



<p><strong>It’s so easy that users have to go out of their way not to use the password storage features</strong> <strong>in their web browser</strong>. </p>



<div><figure><img src="https://passwordbits.com/wp-content/uploads/2020/08/Chrome-Gif.gif" alt=""></figure></div>



<p>If they don’t trust the web browser, they can still use paper and pencil. <a href="https://www.cnet.com/news/microsoft-security-guru-jot-down-your-passwords/">It’s okay to write down your passwords, we’ve been saying it for over a decade.</a></p>



<p>The best part is that the password doesn’t need to be long or complex if the service does proper peppering. We can shift a lot of the burden away from the user while making them more secure.</p>



<h3>This Works For Everyone</h3>



<p>It doesn’t matter how much money you have or how smart you are, generating passwords works for everyone.</p>



<p>SMS 2FA requires a user to have a working phone and a working phone number. Generating passwords requires a user to have a pen and paper.</p>



<p>Phone numbers can be abused for tracking and advertising while pen and paper can not.</p>



<p>People understand keeping secrets, even ones they do not create.</p>



<p>People have no issues with storing secrets like…</p>



<ul><li>SSN</li><li>Bank account numbers</li><li>Phone Numbers</li><li>Credit card numbers</li><li>Birth Certificates</li><li>License numbers</li><li>Health Insurance numbers</li><li>Download code</li><li>Activation code “gaming”</li><li>Claim numbers</li><li>Serial numbers</li><li>Love notes</li><li>Addresses</li></ul>



<p><strong>Treat passwords like keys</strong> – No one is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://passwordbits.com/dont-need-sms-2fa/">https://passwordbits.com/dont-need-sms-2fa/</a></em></p>]]>
            </description>
            <link>https://passwordbits.com/dont-need-sms-2fa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050281</guid>
            <pubDate>Tue, 04 Aug 2020 14:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Is Generic; Your Application Isn't]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24049884">thread link</a>) | @morpecht
<br/>
August 4, 2020 | https://granulate.io/linux-is-generic-your-application-isnt?id=36 | <a href="https://web.archive.org/web/*/https://granulate.io/linux-is-generic-your-application-isnt?id=36">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Imagine you’re a software reliability engineer with your service-level objectives clearly laid out on your Grafana dashboard. Suddenly, an alert appears: Your 99th percentile latency is going through the roof!</span></p><p><span>A quick glance at the relevant metrics reveals the culprit: A spike in traffic has exceeded the current system throughput. It’s clearly an issue caused by lack of capacity, that adding a few extra instances to the cluster should solve, right? After all, more machines means more capacity. You remain calm as the charts stabilize and the alert fades away. There’s no cause for concern; you automated the scaling process a long time ago.&nbsp;</span></p><p><span>But this story could have resulted in a very different, far worse scenario. Capacity is easily accessible these days, especially in cloud environments that offer simplified scaling processes. But the ease of provisioning and scaling also incurs rising infrastructure costs.&nbsp;</span></p><p><span>In order to truly overcome the tradeoff between capacity and costs, organizations must maximize application performance. Improving application performance would not only result in significant cost reduction but also a higher quality of service – serving customers at speed to improve customer experience and increase revenues.</span></p><p><span>Moreover, in many cases handling performance issues or improving performance can’t necessarily be achieved simply by adding more machines due to application bottlenecks or resource management inefficiencies. To paraphrase a wise uncle: with greater compute power (adding more machines) doesn’t come greater performance. Unfortunately, in most cases today, improving performance will require architecture changes or code refactoring.</span></p><p><span>Since increasing the node count rarely helps with improving the performance, let’s explore what can be accelerated. The stack is composed of hardware, an operating system (OS), libraries, and the application, among other components. Making improvements at the hardware level is not always feasible, especially when running in the cloud. Vertical scaling is usually limited to the available predefined instance types, which can inflate your cloud bill in the blink of an eye.</span></p><p><span>Rather than spending more on your cloud bill, consider checking how fast the userspace code is. Application developers have a lot on their plates already. They must ensure a proper domain model, maintainable architecture, and timely feature delivery, and so there is only so much they can optimize.</span></p><p><span>While it is possible to invest R&amp;D efforts and time in replacing a poorly performing library with a more performant one or doing the occasional performance-focused rewrite in the hopes of resolving the issue, it’s possible neither will work.</span></p><p><span>When fidgeting with the hardware isn’t an option and the developers are unavailable to help, another option is to attempt to address the problem at the OS level.</span></p><p><span>The history of computing has not only been about smaller transistors and faster clocks. Back in the mainframe days, machines ran a single program at a time that was encoded on a punch card and inserted by a computer operator.&nbsp;</span></p><p><span>Then business people came along looking for a way to make computers more efficient since, during a program switch, the machines remained idle. This (and a fair amount of ingenuity on the part of early computer scientists) led to the creation of the operating system, a program that executed other programs and managed resource allocation between them.&nbsp; Operating systems, and Linux as one, were designed for users behind the keyboard running simultaneous tasks, therefore the operating system resource management was designed to provide this illusion of parallelism to users behind the keyboard by optimizing internal resource management to achieve high interactivity and fairness.</span></p><p><span>The steadily decreasing price of servers enabled a vast range of potential allocation. Servers were still scarce and ran heterogeneous workloads ranging from web servers to long-running batch computations. Yet they all were running the same operating system more or less: Linux. The OS had to have sensible defaults so that it could perform well in diverse conditions and fit with different kinds of hardware from many different vendors.</span></p><p><span>Today, it’s not uncommon to command a fleet of generic virtual Linux boxes that are mainly focused on running a specific application, a microservice. Due to the inherent modular approach, microservices have known consistent resource usage characteristics and patterns. But the OS underneath hasn’t changed much. It still behaves as if it were supposed to execute multiple programs and share resources between them, which isn’t necessarily the most efficient in such a case and doesn’t provide optimal performance for the application.</span></p><p><span>There are a number of potential performance improvements that can be tested and applied directly at the OS level. Tuning sys controls can have a significant impact on the performance of many subcomponents, such as networking.&nbsp;</span></p><p><span>High speed NICs may require setting </span><span>net.core.netdev_max_backlog</span><span> much higher than the default to prevent filling up the card’s ring buffer, which can lead to packet loss. In addition, the initial value for </span><span>net.core.somaxconn</span><span> may prove far too low for proper machine saturation. And those are just two examples.</span></p><p><span>The I/O scheduler may be worth looking into as well. For example, with databases, the default CFQ (Completely Fair Queuing) can yield results that are inferior to those of the deadline scheduler. On the other hand, a noop scheduler allows you to avoid having to schedule I/O operations twice in cloud environments. After all, the VM’s hypervisor often manages the hardware already.</span></p><p><span>No matter what your approach, though, constant meticulous measurement in a production-like environment (or even the production itself, if you’re into chaos engineering) is recommended. Performance tuning is a highly advanced field that requires specialistic system knowledge. It’s also easy to make silly mistakes, such as forgetting to reload kernel parameter preferences after tweaking them.</span></p><p><span>Some OS features are not so easily accessible for performance tuning. For example, the Linux process scheduler utilizes the Completely Fair Scheduler (CFS), which is perfectly sensible in </span><i><span>most </span></i><span>cases. However, it can sometimes create a significant </span><a href="https://blog.acolyer.org/2016/04/26/the-linux-scheduler-a-decade-of-wasted-cores/"><span>performance gap that cannot be easily found</span></a><span> with standard profiling tools. And even if you do discover it, you can’t simply change a parameter in one of the configuration files; rather a kernel patch and a rebuild is required.</span></p><p><span>Let’s say you’re perfectly fine with the algorithm, but you’d simply like to state that some threads are more important than others. By default you can’t do this, as the niceness setting only works at the process level.</span></p><p><span>I/O-bound applications are also complicated. Even when using raw sockets and </span><span>epoll</span><span>, there is no runtime mechanism to provide selection logic or even a priority to the sockets in the queue. And there is no way for a kernel to know the performance budget for a request.</span></p><p><span>In an ideal world, your application will consist of purpose-built operating systems tailored for each microservice and exploiting every opportunity to boost performance and synergize with the application. In such an ideal world, the internal resource management mechanisms within the operating system will be tailored to the application-specific utility function to drive optimized performance and in turn, also deliver reduced infrastructure costs.</span></p><p><span>Unfortunately, we’re not there yet, and such solutions are currently only available to corporate giants who can afford to hire a few dozen people to do just that full time. In the words of William Gibson, “The future is already here – it’s just not evenly distributed.”</span></p><p><span>So what is left to those with finite budgets? A new approach for real-time continuous optimization that enables organizations to leverage AI-driven infrastructure optimizations that are suited specifically to the running workload.</span></p><p><span>Using application-driven scheduling and prioritization algorithms, it is possible to identify contended resources, bottlenecks, and prioritization opportunities and solve them in real-time.</span><span><br> </span><span>These innovative solutions leverage application’s specific resource usage patterns, the data flow, analyzing CPU scheduling order, oversubscribed locks, memory, network, and disk access patterns, and more.</span></p><p><span>This approach ensures the most efficient use of compute resources, resulting in the need for fewer VMs, less compute resources, reducing costs significantly while delivering better performance.&nbsp;</span></p></div><p><h3>Subscribe to the Granulate Blog</h3><h4>Get the latest posts straight to your inbox.</h4> <!--[if lte IE 8]> <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script> <![endif]-->   </p></div>]]>
            </description>
            <link>https://granulate.io/linux-is-generic-your-application-isnt?id=36</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049884</guid>
            <pubDate>Tue, 04 Aug 2020 13:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save Time on Kubernetes Setup]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24049644">thread link</a>) | @Maria_micro
<br/>
August 4, 2020 | https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/ | <a href="https://web.archive.org/web/*/https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>Kubernetes is the most popular open-source platform for managing containerized workloads and services. Kubernetes abstracts the underlying infrastructure layer. As a result, developers can focus on building applications, then deploy them to any of those environments.</p>



<p>To bring Kubernetes closer to developers, we’ve created a ready-to-use <a href="https://github.com/microtica-components/component-aws-eks" target="_blank" rel="noreferrer noopener">infrastructure component for Kubernetes</a>. This component uses AWS EKS as a service and sets Kubernetes master and nodes in auto-scaling infrastructure setup. Nodes are EC2 instances based on Kubernetes optimized AMIs.</p>



<blockquote><p><em>Components are a core concept in Microtica which allow developers to create and release their custom Cloud infrastructure setup in a standardized way. A</em>fter <em>the component is created, it can be reused in as many projects and environments as needed.</em></p></blockquote>



<p>In addition to the <a rel="noreferrer noopener" href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank">infrastructure setup</a> for Kubernetes, <a rel="noreferrer noopener" href="http://www.microtica.com/" target="_blank">Microtica</a> also offers you CI and CD for microservices. This means that you don’t have to worry about the complex details of the integration with Kubernetes. With this, we cover the whole process of software and infrastructure delivery.</p>



<p>In this article, we will learn how to <strong>deploy a microservice in the cloud with our Kubernetes component</strong>. Let’s get started by <a rel="noreferrer noopener" href="https://portal.microtica.com/register" target="_blank">creating your account</a> and project in Microtica. To deploy your first microservice in under 10 mins, follow these steps:</p>



<h3><strong>1. Add your AWS Account</strong></h3>



<p>First, go into <em>Settings</em>, then <em>AWS Accounts </em>tab, then <em>Add New Account</em>. Follow the steps to connect your account.</p>



<p><em>Note: All resources will be created on the provided AWS account, expenses will be calculated according to AWS pricing for using the services.</em></p>



<h3><strong>2. Create an environment</strong></h3>



<p>With a connected AWS account, you can continue to create your environment in which you’ll deploy your infrastructure. <a href="https://portal.microtica.com/environments/create" target="_blank" rel="noreferrer noopener">Create an environment</a> following the wizard on Microtica and then continue to add the components we will need.</p>



<h3><strong>3. Add components</strong></h3>



<p>To successfully setup a working Kubernetes Cluster in which we’ll deploy a microservice, we will need only 2 components: a <strong>VPC component </strong>and of course a <strong>Kubernetes Cluster component</strong>. We need the VPC (Amazon Virtual Private Cloud) component to enable us to launch AWS resources into a virtual network that we’ve defined. This virtual network is dedicated to your AWS account. This component sets one AWS VPC, and four subnets (2 public and 2 private subnets).</p>



<p>Here’s how to configure your components to connect them and create the infrastructure.</p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-1024x510.png" alt="creating an AWS VPC Component
" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-1024x510.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-300x149.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-768x383.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-1536x765.png 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF-740x369.png 740w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/07-jW74q-UenBJfwF.png 1600w" sizes="100vw"><figcaption>Configuration of AWS VPC Component</figcaption></figure>



<p><em>Note: You will need to create an EC2 key-pair from the AWS console. We don’t create it automatically due to security reasons. This key should always be in your possession and kept in a secure place. This key will allow you to access your EC2 instances through SSH.</em></p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-1024x605.png" alt="Create key pair on AWS console
" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-1024x605.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-300x177.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-768x454.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-1536x907.png 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe-677x400.png 677w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0AqiLMBytlXxVtfWe.png 1600w" sizes="100vw"><figcaption>AWS console</figcaption></figure>



<p>When configuring the parameters for the Kubernetes Cluster component you can reference the VPC component so you <strong>don’t have to manually reenter the values</strong>. Microtica will take care of the order in which the components will be deployed in the cloud. This will allow you to have a working environment.</p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-1024x951.png" alt="Create a Kubernetes cluster
" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-1024x951.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-300x279.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-768x713.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-1536x1427.png 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr-431x400.png 431w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0UqNSF9XMCV3SW4hr.png 1600w" sizes="100vw"><figcaption>Configuration of AWS EKS Component</figcaption></figure>



<p>With the configuration set in place, you can deploy your environment by clicking <em>Create Plan</em>. Here you will see a detailed listing of the resources that are about to be added to the environment. Confirming will initiate the deployment and lead you to a page where you can follow the logs and events that are happening. Setting up this infrastructure can take up to 15 mins, so let us get started with our microservice in the meantime.</p>



<h3><strong>4. Create a microservice</strong></h3>



<p>For the purposes of this example, we will be using a simple <a rel="noreferrer noopener" href="https://hub.docker.com/_/hello-world" target="_blank">Hello World microservice</a> available in Docker hub. First, go to <a rel="noreferrer noopener" href="https://portal.microtica.com/microservices/create" target="_blank"><em>Microservices/Create microservice</em></a><em> </em>and follow the wizard in Microtica. For a source select public docker image and paste <strong>hello-world</strong>. Then, click <em>Next</em>, then <em>Create Microservice </em>and now we have our microservice.</p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-1024x492.png" alt="Creating a Kubernetes microservice
" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-1024x492.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-300x144.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-768x369.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-1536x738.png 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-2048x984.png 2048w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/Screen-Shot-2020-04-06-at-11.38.52-AM-740x356.png 740w" sizes="100vw"><figcaption>Create microservice from public Docker image</figcaption></figure>



<p>As a result of using a docker image as a source, we already have a built artifact so we can immediately deploy it in the Kubernetes cluster. <strong>You can do this from <em>Microservice details — Add to Cluster</em>, or in the<em> Kubernetes Dashboard — Microservices — Deploy.</em></strong></p>



<figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-1024x495.png" alt="Deploy Kubernetes microservice
" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-1024x495.png 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-300x145.png 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-768x371.png 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-1536x743.png 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-2048x990.png 2048w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/microservice-deploy-740x358.png 740w" sizes="100vw"><figcaption>Deploy microservice configuration</figcaption></figure>



<p>Microtica offers configuration options when deploying your microservice in a Kubernetes Cluster.&nbsp;&nbsp;You can select the scaling options, and as well setup continuous delivery for your microservice.</p>



<p>After successfully deploying the microservice in the Kubernetes Cluster you can preview your microservice by following the <strong><em>Access URL/hello-world-ms</em></strong><em> </em>(the name of the service if you’ve changed it). You should see this in your browser window:</p>



<div><figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0KLYx9DQIHY9wBiN8.png" alt="Your first microservice on a Kubernetes cluster
"></figure></div>



<p><strong>AND WE ARE DONE! WE JUST DEPLOYED OUR FIRST MICROSERVICE ON A KUBERNETES CLUSTER 👏</strong></p>



<h3><strong>5. Bonus: Cleanup</strong></h3>



<p>To remove all the resources we created on your AWS account go to environment details and in the menu select <em>Undeploy. </em>As a result, you’ll get your resources created on AWS cleaned. However, you will still have the configuration in Microtica in case you want to deploy it in the cloud again.</p>



<div><figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0ibbaEX9lEfkRHozp.png" alt="Replicate environment" width="379" height="190" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0ibbaEX9lEfkRHozp.png 612w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/04/0ibbaEX9lEfkRHozp-300x151.png 300w" sizes="100vw"></figure></div>



<p><strong>To deploy your custom microservice, </strong><a href="https://portal.microtica.com/login" target="_blank" rel="noreferrer noopener"><strong>create your demo now</strong></a><strong>.</strong> And remember to stay safe 💚</p>



<div><figure><img src="https://media.giphy.com/media/idG3KgPfYdSN9UQemz/giphy.gif" alt="" width="474" height="474"></figure></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/"
    dc:identifier="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/"
    dc:title="Deploy Your First Microservice on Kubernetes in 10 mins"
    trackback:ping="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049644</guid>
            <pubDate>Tue, 04 Aug 2020 13:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unlearn rotation matrices as rotations]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24049593">thread link</a>) | @dosshell
<br/>
August 4, 2020 | https://kodkodgames.gitlab.io/rotation_matrices/ | <a href="https://web.archive.org/web/*/https://kodkodgames.gitlab.io/rotation_matrices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        




<i data-feather="calendar"></i> <time datetime="2020-06-12">2020-06-12</time>

<p>– Hey, Markus! What format is this head-rotation representation in?</p>
<p>– It is a rotation matrix, I answer. Right handed, z forward through the nose and x through the left ear. Our young newly graduated colleague nods his/her head.</p>
<p>After about 10 minutes I hear my name again.</p>
<p>– Markus…. Eh, what order is it?</p>
<p>– Oh no! You have opened Wikipedia? Haven’t you? I answer in despair from my desk.</p>
<p>It happens time to time that a newly graduated engineer (or summer intern) asks me exactly this question. Almost always with the Wikipedia page open at the screen, which I think is horrible (or even worse, some “Learn OpenGL” tutorial).</p>
<p>I <s>steal</s> take a chair to sit down beside the person. This will take a few minutes, we are going to do something that is harder than learning: we are going to unlearn.</p>
<p>It is interesting, I get no questions, or only very short questions, on Euler angels, Rodriguez rotations and actually only one recurrent question on quaternions. But very often I get questions on rotation matrices. I think it is a bit odd since rotation matrices are very simple in comparison to many other rotation representations. I think a big reason for this is the Wikipedia page. It looks something like this:</p>
<p>
\[
R_x(\theta) =
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; \cos \theta &amp;  -\sin \theta \\
0 &amp; \sin \theta  &amp;  \cos \theta
\end{bmatrix}
\]
\[
R_y(\theta) =
\begin{bmatrix}
\cos \theta &amp; 0 &amp; \sin \theta \\
0 &amp; 1 &amp; 0 \\
-\sin \theta &amp; 0 &amp; \cos \theta
\end{bmatrix}
\]
\[
R_z(\theta) =
\begin{bmatrix}
\cos \theta &amp;  -\sin \theta &amp; 0 \\
\sin \theta &amp;   \cos \theta &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{bmatrix}
\]
\[
R =
\begin{bmatrix}
\cos\alpha\cos\beta &amp; \cos\alpha\sin\beta\sin\gamma - \sin\alpha\cos\gamma &amp; \cos\alpha\sin\beta\cos\gamma + \sin\alpha\sin\gamma \\
\sin\alpha\cos\beta &amp; \sin\alpha\sin\beta\sin\gamma + \cos\alpha\cos\gamma &amp; \sin\alpha\sin\beta\cos\gamma - \cos\alpha\sin\gamma \\
-\sin\beta &amp; \cos\beta\sin\gamma &amp; \cos\beta\cos\gamma \\
\end{bmatrix}
\]
</p>
<p>It talks about rotations. Rotation around different axes and their relation to Euler angles. This can be a bit confusing when working with for example a head pose. You can of course think about rotation matrices as if the head rotates around different axes in different order, but it becomes kind of hard to interpret:</p>
<p>
\[
\begin{bmatrix}
 -0.9987820 &amp; 0.0348782 &amp; -0.0348995 \\
  0.0283128 &amp; 0.9844193 &amp;  0.1735424 \\
  0.0404086 &amp; 0.1723429 &amp; -0.9842078
\end{bmatrix}
\]
</p>
<p>So to interpret this we need to solve the following equation system:</p>
<p>
\[
\begin{cases}
-\sin(\beta) &amp; = 0.0404086 \\
\cos(\beta)\sin(\gamma) &amp; = 0.1723429 \\
\cos(\alpha)\cos(\beta) &amp; = -0.9987820
\end{cases}
\]
</p>
<p>and then we get an <em>“intrinsic rotation whose Tait–Bryan angles are α, β, γ, about axes z, y, x”</em> to visualize in our head.</p>
<p>Its sad because I think rotation matrices are one of the easiest representation to interpret.</p>
<p>Don’t think of them as rotations, think of them as a unit vectors of a new coordinate systems.</p>
<p><img src="https://kodkodgames.gitlab.io/post/matrix_cs.png#center" alt="plot of the coordinate system"></p>
<p>We describe where the coordinate system is located related to another coordinate system (where we rotate from), for example from the camera’s coordinate system perspective (z forward, y upwards). The first column of the rotation matrix is the new x-axis expressed in the old coordinate system, the second column is the y-axis and so on. An identity matrix would yield in no rotation since all unit vectors would be the same as the previous coordinate system.</p>
<p>
\[
R =
\begin{bmatrix}
  X_x &amp; Y_x &amp; Z_x \\
  X_y &amp; Y_y &amp;  Z_y \\
  X_z &amp; Y_z &amp; Z_z
\end{bmatrix}
\]
</p> 
<p>Lets go back to the example with the head expressed in the camera coordinate system and assume the head position is atfront of the camera. So by interpret the previous matrix, we can look at the new z-axis:</p>
<p>
\[
Z_{axis} = 
\begin{bmatrix}
Z_x \\
Z_y \\
Z_z
\end{bmatrix}
=
\begin{bmatrix}
-0.0348995 \\
0.1735424 \\
-0.9842078
\end{bmatrix}
\]
</p>
<p>(Remember that z-axis is where the head’s nose is pointing)</p>
<p>We can quickly see that z-part of the z-axis is almost -1. This means the nose is pointing at the opposite direction as the camera, eg. towards the camera if the person is sitting at front of it.</p>
<p>We can also se that the persons head is rotated a little bit up (positive y component of the z-axis) and is pointing a little bit to the right of the camera (negative x component).</p>
<p>And that’s it! Rotation matrices just describe the unit vectors of a new coordinate system.</p>
<p>…</p>
<p>– Hey, Markus! How come this matrix is 4x4?</p>
<p>// Markus</p>
<p><a href="https://news.ycombinator.com/item?id=24049593">HN discussion</a></p>




      </main>
    </div></div>]]>
            </description>
            <link>https://kodkodgames.gitlab.io/rotation_matrices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049593</guid>
            <pubDate>Tue, 04 Aug 2020 13:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools around workflows, not workflows around tools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24049423">thread link</a>) | @thesephist
<br/>
August 4, 2020 | https://thesephist.com/posts/tools/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><em>This March, I spent a couple of days traveling through western Iceland.</em></p>
<p><img src="https://thesephist.com/img/iceland.jpg" alt="Iceland, part 1"></p>
<p>While I was there, I thought a lot about tools – mechanical tools, software tools, tools that last, and tools that are fragile. The somber snow-covered scenery made me think about how quickly most of the tools we use today get outdated or replaced, and I thought about the kinds of tools that I’ve been building for myself for the last few years to help organize my life.</p>
<p>I took a walk around <em>Smábátahöfnin í Keflavík</em> (a small marina nearby) that night, unraveled myself into my hotel room, and started writing this post.</p>
<p>I want to share why I build my own tools and how I think we should think about building tools for life. It’s long, so here’s a roadmap. Feel free to jump around.</p>
<ol>
<li><a href="#my-tools-today">My tools, today</a></li>
<li><a href="#workflows--tools">Workflows &gt; tools</a>
<ol>
<li><a href="#tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</a></li>
<li><a href="#tools-that-grow-with-your-workflows">Tools that grow with your workflows</a></li>
</ol>
</li>
<li><a href="#own-your-load-bearing-tools-of-life">Own your load-bearing tools of life</a></li>
<li><a href="#cost-and-other-smaller-benefits">Cost and other smaller benefits</a></li>
<li><a href="#your-tools-are-an-extension-of-you">Your tools are an extension of you</a></li>
<li><a href="#appendix-the-technical-nitty-gritty">Appendix: the technical nitty-gritty</a></li>
</ol>
<hr>

<p>For the last few years, I’ve been on a journey to replace all of the essential digital tools I use for organizing my life with tools I develop, maintain, and deploy myself.</p>
<p>What started with a single-page notes app I made in high school has grown into a constellation of home-grown productivity tools I now rely on for my day-to-day work and learning. Here’s a sample.</p>
<ul>
<li>
<p><a href="https://github.com/thesephist/polyx#ligature">Ligature</a>, for long-term notes and tasks, goals, brainstorming, project planning, and other important writing.</p>
<p><img src="https://thesephist.com/img/ligature.jpg" alt="Ligature"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/pico">Pico</a>, for more ephemeral notes and tasks that change on a daily basis. I split up my notes into two apps (Ligature and Pico) because it works better for my workflow. (More on this later.)</p>
<p><img src="https://thesephist.com/img/pico.jpg" alt="Pico"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/mira">Mira</a> for keeping track of people I know, why they’re interesting, and what we’ve talked about.</p>
<p><img src="https://thesephist.com/img/mira.png" alt="Mira"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Lovecroft</a> for managing and sending emails to my <a href="https://thesephist.com/#newsletter">mailing lists</a>.</p>
<p><img src="https://thesephist.com/img/lovecroft.jpg" alt="Lovecroft"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Noct</a> for backing up and syncing all my files across computers and the cloud. Noct doesn’t have a graphical UI, just a command-line tool.</p>
</li>
<li>
<p><a href="https://thesephist.com/posts/frieden/">Frieden</a> as a public availability calendar, showing when I’m free or busy.</p>
<p><img src="https://thesephist.com/img/frieden.png" alt="Frieden"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/thingboard">Thingboard</a> for more free-form Post-its-on-the-wall style brainstorming.</p>
<p><img src="https://thesephist.com/img/thingboard.jpg" alt="Thingboard"></p>
</li>
<li>
<p><a href="https://codeframe.co/">Codeframe</a> for spinning off simple JavaScript experiments like <a href="https://thesephist.com/posts/word-experiments/#word-plotter">the word plotter</a>.</p>
<p><img src="https://thesephist.com/img/codeframe.jpg" alt="Codeframe"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/draw">draw</a>, a collaborative whiteboard, best used with my iPad Pro and Apple Pencil.</p>
<p><img src="https://thesephist.com/img/draw.jpg" alt="Draw"></p>
</li>
</ul>
<p>Taken together, these apps do almost everything I need to do on my computer to keep myself organized. I don’t use any third-party notes, task management, or contacts apps, though I used to be a big fan of Simplenote and Todoist. I’ve used Notion, Dropbox Paper, Google Docs, and Airtable, but only for working in teams that centralized on them. These days, besides email and calendar, I live within a system of my own tools, and it works well for me.</p>
<p>I don’t want to imply that my tools are objectively better than the professional tools on the market like Notion and Dropbox. Those latter services have more features, and might even be more reliable today. But I think my tools fit me better for a different reason.</p>

<p>Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.</p>
<p>The Eureka moment that some of us feel when we finally find a notes app or todo system that fits our brains – that epiphany happens when the tools we use mirror the way our minds work, and how we want to move information through our lives. Good tools fit perfectly around our workflows, bad tools don’t.</p>
<p>When we resort to having other people build tools for us, the tools they build might never quite perfectly fit our workflows, because they’re not built for our individual minds. When other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways. The result is that mass-market productivity tools don’t fit the way our individual minds are predisposed to work. Instead, to use these tools, we need to bend our workflows to fit around the tools.</p>
<p>My biggest benefit from writing my own tool set is that <strong>I can build the tools that exactly conform to my workflows, rather than constructing my workflows around the tools available to me.</strong> This means the tools can truly be an extension of the way my brain thinks and organizes information about the world around me. My tools aren’t perfect yet, but as they grow and evolve, they’ll only become better reflections of my personal mental models.</p>
<p>For example, one place where my mind works differently than the tools on the market is the task/notes distinction.</p>
<h3 id="tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</h3>
<p>My workflow used to differentiate between tasks and notes. Tasks were action items that I could reference, take action on, and complete, and then erase from my list. Notes were things that were indefinitely relevant. I would take notes and then come back to reference them many times. A note by itself isn’t actionable.</p>
<p>But once I started building my own tools, I realized this distinction isn’t really the way my brain worked. For me, a huge grey area exists between actionable, completable tasks and purely encyclopedic notes. Here are some things that fall in the grey area for me, pulled from my real, actual notes I took this week.</p>
<ol>
<li>I recently learned some really useful tips about how to grow leaders within a community from the book <em><a href="https://gettogetherbook.com/">Get Together</a></em>. I definitely want to act on these learnings at some point in the communities I lead, but I don’t want them cluttering up my todo list because they’re not things I can just complete and check off quickly. I also want to remember these tips forever, even after the first time I act on them.</li>
<li>I’ve been brainstorming an idea for a side project related to <a href="https://en.wikipedia.org/wiki/Computer_algebra">symbolic mathematics</a>. I’ve been writing down my inspirations related to this project. I don’t want to tuck it away in my notes, because this is something I want to build soon, but I also don’t want to shove paragraphs of notes into a todo list item.</li>
<li>I keep a running list of ideas I have for future blog posts, but I don’t really have a “write the next blog post” task item under which I’d normally put these ideas, because I don’t write on schedule – I just write when I can. Where should these ideas go? They’re sort-of notes and sort-of tasks.</li>
</ol>
<p>You might think that these are either very clearly todo items or very clearly notes, and that’s ok. But I certainly felt differently, and I realized I was only separating things into these two buckets because my tools forced me to. Before I wrote my own tools, I had a todo app (Todoist) and I had a notes app (Simplenote), and there was nothing in between.</p>
<p>Eventually, I discovered a better mental model for my working style: I ask myself <em>how immediately</em> I need to take action on something.</p>
<p>The way that I see it, everything I learn and jot down is something for me to act on at some point in my life. If I read something that I never thought would influence the way I lived, it wouldn’t have value to me, and I simply wouldn’t write it down. Armed with this insight, these days, I have two different notes apps, and I don’t use a todo list app. These two apps are Ligature and Pico, mentioned above.</p>
<p>One is for notes that are changing often. Day-to-day tasks, things to remember for the next week, even long notes and links related to what I’m working on <em>now</em>. The other app is for notes that grow over time, like notes I take while reading books or watching talks, my annual goals, financial planning, reading list, and project outlines. <strong>My two notes apps mirror the way my brain works best – one is my short-term, working memory, the other is my long-term memory.</strong></p>
<p>I’ve had this system for a few months now, and haven’t felt any need for something better. It doesn’t have the crazy features of some notes services on the market today, but it just works the way my brain does.</p>
<p>But what if I need something different later on in life?</p>
<h3 id="tools-that-grow-with-your-workflows">Tools that grow with your workflows</h3>
<p>The other benefit of building homebrew tools is that <strong>tools you build yourself can grow and change as your workflow changes over time</strong>. So if my needs do change over time, my tools can grow to accommodate exactly what I need.</p>
<p>When I first started keeping more organized notes on the interesting people I met, I started with a document in my notes app. Over time, I noticed that these notes followed a pattern: I wrote down their name and primary contact info, how I first met them, what school they went to, and what we talked about the last time we spoke.</p>
<p>So when I built Mira, my own people-manager app, I designed it around that exact workflow I had developed. When I later realized I was also recording people’s Twitter usernames in the description field, I just added a Twitter username field to each contact.</p>
<p>This is typical of the way I <em>discover</em> my workflows. <strong>I start with a minimal, bare-bones solution, and try to pick up on patterns and tricks I create for myself. And then I encode those patterns and tricks into the tools over time.</strong></p>
<p>This way, my tools can grow organically as my workflows evolve. Neither of them gets in the way of each other most of the time, and I think that was hard to appreciate before I started relying wholly on my own tools.</p>

<p>My productivity tools, especially my notes and contacts, are the load-bearing tools of my life. If they break or disappear, it’ll take a long time and a lot of effort for me to rebuild those same workflows and tools, so it’s important that they’re reliable, and that I can depend on them working for me for a long time (measured in years and decades, not quarters).</p>
<p>I’ve written at length about <a href="https://thesephist.com/posts/ownership/">the importance of ownership</a> before. I want to own the pieces of my life that are most critical, and I want agency over how these tools change over time.</p>
<p>I want these notes and ideas and workflows to stick with me as I grow as a person through the next decades. If I had to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/tools/">https://thesephist.com/posts/tools/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049423</guid>
            <pubDate>Tue, 04 Aug 2020 12:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crux SQL]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24049349">thread link</a>) | @yogthos
<br/>
August 4, 2020 | https://juxt.pro/blog/crux-sql | <a href="https://web.archive.org/web/*/https://juxt.pro/blog/crux-sql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>We were pleased when <a href="https://opencrux.com/">Crux</a> was included in the
ThoughtWorks
<a href="https://www.thoughtworks.com/radar/platforms/crux">technology radar</a>
with a recommendation to <strong>assess</strong>:</p>
<div>
<blockquote>
<p>Crux is an open-source document database with bitemporal graph
queries…​ it’s currently in alpha and lacks SQL support, but you can
use a Datalog query interface for reading and traversing
relationships.</p>
</blockquote>
<p>
— ThoughtWorks Technology Radar
</p>
</div>
<p>We are fans of <a href="https://en.wikipedia.org/wiki/Datalog">Datalog</a> and the
power it gives. Although it’s not directly compatible and may drift
out further, we’ve based our Datalog query API on
<a href="https://docs.datomic.com/on-prem/query">Datomic’s</a>, where Datalog
is represented as a pattern-matching declarative data-structure.</p>
<p>Datalog is easy to construct and parse and it is natural to make use
of custom predicates and rules as part of the logical pattern
matching.</p>
<p>We love Datalog, but it’s also fair to say that a sizeable chunk of
potential users will want to use SQL. Be it for users who want to run
ad-hoc SQL queries without needing to know Datalog, or for integration
between systems where SQL is the lingua franca, it’s important that we
support it.</p>
</div>
</div>
<div>
<h2 id="_code_crux_sql_code"><a href="#_code_crux_sql_code"></a><code>crux-sql</code></h2>
<div>
<p>We have created a new <code>crux-sql</code> module in Crux which makes use of the
<a href="https://calcite.apache.org/">Apache Calcite</a> SQL query planning engine. Calcite
is a powerful library for exposing SQL queries against arbitrary data-sources
and has been integrated with a variety of DBMSs such as Cassandra, Mongo and
Elastic, as well as Big Data systems like Hive, Drill, Flink and Dremio.</p>
<p>Calcite has been around for a long while and is still very
active. We’re grateful for the work the Calcite team have put into
this tool and the power it gives, as well as the friendly community that
has built up around it.</p>
<p>We run Calcite in-process as part of a Crux node, so there’s no need
to set up any additional infrastructure. Rather you just need to add
the <code>crux-sql</code> module dependency:</p>
<div>
<div>
<pre><code data-lang="clojure">[juxt/crux-sql "RELEASE"]]</code></pre>
</div>
</div>
<p>We have integrated Calcite such that SQL queries are translated to
efficient Datalog queries, including sorts and inner joins.</p>
<p>You can avoid the relatively small overhead of preparing queries by
using PreparedStatements.</p>
<p>Please visit the
<a href="https://github.com/juxt/crux/blob/master/crux-sql/README.adoc">module
README</a> for how to get going with some simple steps, or please watch
this video:</p>
<div>
<p>
<iframe src="https://www.youtube.com/embed/HEBL_ue2wbw?rel=0" frameborder="0" allowfullscreen=""></iframe>
</p>
</div>
<p>The <code>crux-sql</code> module allows for both in-process SQL queries and for
remote JDBC queries using
<a href="https://calcite.apache.org/avatica/">Avatica</a>. This is covered in the
docs.</p>
</div>
</div>
<div>
<h2 id="_next_up"><a href="#_next_up"></a>Next Up</h2>
<div>
<p>See the <code>crux-sql</code>
<a href="https://github.com/juxt/crux/tree/master/crux-sql">README</a> for more
details.</p>
<p>Stay tuned for another blog and video on how to write Crux SQL
bitemporal queries.</p>
<p>As ever, if you have queries about Crux, please ping the team:</p>

<p><em>Image credit: Oliver Hine</em></p>
</div>
</div></div></div>]]>
            </description>
            <link>https://juxt.pro/blog/crux-sql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049349</guid>
            <pubDate>Tue, 04 Aug 2020 12:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your calendar should be an allowlist, not a blocklist]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24049260">thread link</a>) | @mcrittenden
<br/>
August 4, 2020 | https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-549">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Does your company have a culture of letting everyone see each other’s calendars? Do people often schedule meetings whenever there are openings, without asking?</p>



<p>If so, your calendar is a blocklist. The only time that isn’t available for someone to steal is time that’s already spoken for. This is a problem. A time slot that isn’t currently booked shouldn’t be free real estate. That’s my TIME! You can’t just take it without asking.</p>



<p>Instead, your calendars should be an allowlist. You should say “if you want to talk to me, this is when you can” instead of “this is when you CAN’T.” You shouldn’t have to defend our time like it’s gold and your coworkers are pirates. You should just assume that it’s yours to spend how you see fit.</p>



<p>Some people block time off to try to protect their calendars. They create big “GTD” blocks on their calendar and hope that nobody books meetings on top of them. I’ve even heard of people creating fake or vague meeting titles in hopes that others will assume there’s a real meeting at that time. This is a crappy workaround, and it isn’t enough. </p>



<p>The solution should be office hours. You should be able to say say “I’m free for meetings from 2-5pm on Tuesdays and Thursdays, and if you want to talk to me then that’s when you can.” In most companies, doing that would make you an annoyance. Those companies don’t respect Deep Work. </p>



<p>Scheduling meetings should be a little bit painful. You should have to really want it. You should be forced to question yourself. <em>Is this actually worth me going to the trouble of figuring out how to schedule this meeting? Or could it instead be an asynchronous discussion? </em>Office hours and calendars-as-allowlists have this added benefit.</p>



<p>Is your calendar an allowlist or a blocklist?</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049260</guid>
            <pubDate>Tue, 04 Aug 2020 12:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous PostgreSQL backups using WAL-G]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24049087">thread link</a>) | @kiwicopple
<br/>
August 4, 2020 | https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Have you ever wanted to restore your database's state to a particular moment in time? This post explains how, using WAL-G.</p><h2>Introduction</h2><p><a href="https://github.com/wal-g/wal-g" target="_blank" rel="noopener noreferrer">WAL-G</a> is an <a href="https://www.citusdata.com/blog/2017/08/18/introducing-wal-g-faster-restores-for-postgres/" target="_blank" rel="noopener noreferrer">open-source continuous archiving tool</a> used to easily set up and recover from <a href="https://supabase.io/blog/2020/07/17/postgresql-physical-logical-backups" target="_blank" rel="noopener noreferrer">physical backups</a> in Postgres. It mainly handles the storage and retrieval of physical backups and WAL archives to and from a chosen cloud storage provider. In this post, we will walk you through on how to effortlessly set up WAL-G for your database as well as guide you on what to do if and when disaster strikes.</p><h2>Prerequisites</h2><p>For this tutorial, we will be using two instances running Postgres databases on <a href="https://releases.ubuntu.com/18.04/" target="_blank" rel="noopener noreferrer">Ubuntu 18.04</a>. One instance will act as your main database, the other is your recovery database. If you’re using another operating system some file paths may vary.</p><h3>Installations</h3><p>Make sure the below packages are installed in your instances. Alternatively, you can spin up the <a href="https://github.com/supabase/postgres/releases/tag/v0.13.0" target="_blank" rel="noopener noreferrer">latest version</a> of <a href="https://github.com/supabase/postgres" target="_blank" rel="noopener noreferrer">Supabase Postgres</a> which would already have everything configured and installed, along with other <a href="https://github.com/supabase/postgres#features" target="_blank" rel="noopener noreferrer">goodies</a>. It is readily available in either the <a href="https://aws.amazon.com/marketplace/pp/B08915TCJ2?qid=1595854723755&amp;sr=0-1&amp;ref_=srh_res_product_title" target="_blank" rel="noopener noreferrer">AWS</a> or <a href="https://marketplace.digitalocean.com/apps/supabase-postgres" target="_blank" rel="noopener noreferrer">Digital Ocean</a> marketplaces and only takes <a href="https://supabase.io/docs/postgres/postgres-intro" target="_blank" rel="noopener noreferrer">a few minutes</a> to get running.</p><h4>Postgres 12</h4><p>A quick installation guide can be found <a href="https://www.postgresql.org/download/linux/ubuntu/" target="_blank" rel="noopener noreferrer">here</a>.</p><h4>envdir</h4><p><a href="http://manpages.ubuntu.com/manpages/bionic/man8/envdir.8.html" target="_blank" rel="noopener noreferrer">envdir</a> allows us to run other programs with a modified environment based on the files in the provided directory. This can be installed through the <a href="https://cr.yp.to/daemontools.html" target="_blank" rel="noopener noreferrer">daemontools</a> package:</p><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> -y daemontools</span></p></div></div></div></div><h4>WAL-G</h4><div><div><div tabindex="0"><div><p><span>$ </span><span>wget</span><span> https://github.com/wal-g/wal-g/releases/download/v0.2.15/wal-g.linux-amd64.tar.gz</span></p><p><span>$ </span><span>tar</span><span> -zxvf wal-g.linux-amd64.tar.gz</span></p><p><span>$ </span><span>mv</span><span> wal-g /usr/local/bin/</span></p></div></div></div></div><h3>AWS credentials and resources</h3><p>When storing backups, WAL-G has numerous <a href="https://github.com/wal-g/wal-g#configuration" target="_blank" rel="noopener noreferrer">cloud storage provider options</a> for us to choose from. For this tutorial, we will be using AWS. Have the following prepared:</p><ul><li>AWS Access &amp; Secret keys.</li><li>An S3 bucket.</li></ul><h2>Setting it up</h2><h3>1. Configure environment variables</h3><p>The directory <code>/etc/wal-g.d/env</code> is created and contains files that stores environment variables. It would later be used in WAL-G commands via envdir.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>umask</span><span> </span><span>u</span><span>=</span><span>rwx,g</span><span>=</span><span>rx,o</span><span>=</span><span></span></p><p><span>$ </span><span>mkdir</span><span> -p /etc/wal-g.d/env</span></p><p><span>$ </span><span>echo</span><span> </span><span>'secret-key-content'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_SECRET_ACCESS_KEY</span></p><p><span>$ </span><span>echo</span><span> </span><span>'access-key'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_ACCESS_KEY_ID</span></p><p><span>$ </span><span>echo</span><span> </span><span>'s3://backup-bucket/project-directory'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/WALG_S3_PREFIX</span></p><p><span>$ </span><span>echo</span><span> </span><span>'db password'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/PGPASSWORD</span></p><p><span>$ </span><span>chown</span><span> -R root:postgres /etc/wal-g.d</span></p></div></div></div></div><h3>2. Enable WAL archiving</h3><p>Here, we enable <a href="https://www.postgresql.org/docs/12/continuous-archiving.html" target="_blank" rel="noopener noreferrer">WAL archiving</a> and instruct Postgres to store the archives in the specified S3 bucket via WAL-G. </p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"archive_mode = yes"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"archive_command = 'envdir /etc/wal-g.d/env /usr/local/bin/wal-g wal-push %p'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"archive_timeout = 60"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h3>3. Restart the database</h3><p>The database is restarted to let the changes in the configuration to take effect.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql restart</span></p></div></div></div></div><h3>4. Create your first physical backup</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> -su postgres envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-push /var/lib/postgresql/12/main</span></p></div></div></div></div><p>At this point, if you were to check the S3 path that you provided, the following two newly created and populated directories would be observed:</p><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/lai1mxg62kffyd2khmtm.png" alt="Alt Text"></p><p>From then on, subsequent physical backups would be found in the directory <code>basebackups_005</code> and any WAL archives would be sent to the directory <code>wal_005</code>.</p><h3>5. [Optional] Schedule regular physical backups</h3><p>A CRON job can then be set to schedule physical backups to be performed everyday:</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"0 0 * * * postgres /usr/bin/envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-push /var/lib/postgresql/12/main"</span><span> </span><span>&gt;</span><span> /etc/cron.d/pg_backup</span></p></div></div></div></div><p>Here, the instance has been instructed to back up the database at the start of each day at midnight. By physically backing up your instance regularly, overall recovery time could be faster. Restoring from a physical backup from yesterday would lead to fewer WAL archive files to be replayed as compared to restoring from one from a month ago.</p><hr><h2>Disaster strikes</h2><p>Something goes wrong with the database or instance. We will now use what available physical backups we have in the S3 bucket to recover and restore all of our data on to a new instance.</p><h3>1. Configure environment variables</h3><p>The configuration should be the <strong>same</strong> as the original instance. For recovery and restoration, we would not need the variable <code>PGPASSWORD</code>.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>umask</span><span> </span><span>u</span><span>=</span><span>rwx,g</span><span>=</span><span>rx,o</span><span>=</span><span></span></p><p><span>$ </span><span>mkdir</span><span> -p /etc/wal-g.d/env</span></p><p><span>$ </span><span>echo</span><span> </span><span>'secret-key-content'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_SECRET_ACCESS_KEY</span></p><p><span>$ </span><span>echo</span><span> </span><span>'access-key'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_ACCESS_KEY_ID</span></p><p><span>$ </span><span>echo</span><span> </span><span>'s3://backup-bucket/project-directory'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/WALG_S3_PREFIX</span></p><p><span>$ </span><span>chown</span><span> -R root:postgres /etc/wal-g.d</span></p></div></div></div></div><h3>2. Stop the database</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql stop</span></p></div></div></div></div><h3>3. Switch to the user <code>postgres</code></h3><h3>4. Prepare the database for recovery</h3><h4>Set restore_command</h4><p>Through <a href="https://www.postgresql.org/docs/12/continuous-archiving.html#:~:text=must%20specify%20is%20the%20restore_command,%20which%20tells%20PostgreSQL%20how%20to%20retrieve%20archived%20WAL%20file%20segments" target="_blank" rel="noopener noreferrer">restore_command</a>, we instruct Postgres to pull all WAL archives from our S3 bucket to use during recovery.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"restore_command = '/usr/bin/envdir /etc/wal-g.d/env /usr/local/bin/wal-g wal-fetch </span><span>\"</span><span>%f</span><span>\"</span><span> </span><span>\"</span><span>%p</span><span>\"</span><span> &gt;&gt; /tmp/wal.log 2&gt;&amp;1'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h4>[Optional] Achieve Point in Time Recovery (PITR)</h4><p>If we want to restore the database only up to a certain point in time (eg. right before the disaster), we can do so by setting both <a href="https://www.postgresql.org/docs/12/runtime-config-wal.html#:~:text=recovery_target_time%20(timestamp)" target="_blank" rel="noopener noreferrer">recovery_target_time</a> and <a href="https://www.postgresql.org/docs/12/runtime-config-wal.html#:~:text=recovery_target_action%20(enum)" target="_blank" rel="noopener noreferrer">recovery_target_action</a>. Do note that the timezone would need to match that of the original instance. This is usually at the UTC (+00) timezone.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"recovery_target_time = '2020-07-27 01:23:00.000000+00'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"recovery_target_action = 'promote'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h3>5. Restore from physical backup</h3><p>The current data directory is deleted and is replaced with the latest version of the physical backup from the S3 bucket.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>rm</span><span> -rf /var/lib/postgresql/12/main</span></p><p><span>$ envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-fetch /var/lib/postgresql/12/main LATEST</span></p></div></div></div></div><h3>6. Create a <code>recovery.signal</code> file</h3><p>This file <a href="https://www.postgresql.org/docs/12/continuous-archiving.html#:~:text=Set%20recovery%20configuration%20settings%20in%20postgresql.conf%20(see%20Section%2019.5.4)%20and%20create%20a%20file%20recovery.signal%20in%20the%20cluster%20data%20directory" target="_blank" rel="noopener noreferrer">instructs</a> Postgres that the database should undergo recovery mode upon start.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>touch</span><span> /var/lib/postgresql/12/main/recovery.signal</span></p></div></div></div></div><h3>7. Log out of <code>postgres</code> and start the database</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>exit</span><span></span></p><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql start</span></p></div></div></div></div><p>Once Postgres finishes starting up and completes recovery mode, all data or data up to the specified point in time would have been successfully restored on to the new instance. Disaster averted.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049087</guid>
            <pubDate>Tue, 04 Aug 2020 12:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Former Producer: Why I’m now leaving MSNBC]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24049074">thread link</a>) | @JumpCrisscross
<br/>
August 4, 2020 | https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc | <a href="https://web.archive.org/web/*/https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><div id="viewer-a77ug"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc" data-pin-media="https://static.wixstatic.com/media/184124_757ebdc8f58e426980cca18975e93103~mv2.jpg/v1/fit/w_2852,h_2819,al_c,q_80/file.png" src="https://static.wixstatic.com/media/184124_757ebdc8f58e426980cca18975e93103~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-9reau">“Just quit.”</p><p id="viewer-cqtr">﻿That’s the advice Alec gave a year and a half ago when I expressed concerns about my job. </p><p id="viewer-dur7n">“You just quit.  It’s that simple.”</p><p id="viewer-8vmcf">“Stay at MSNBC at least until the midterms,” Jeffrey said a couple years back.  He advised to watch and see what happens.</p><p id="viewer-ekaih">“Hang in there… you’re needed,” Elizabeth recommended last winter.  “I was in your shoes when I was younger but I stuck it out.”</p><p id="viewer-bvvpg">A year and a half ago, simply quitting my job without knowing my next step sounded pretty radical.  So I stuck it out a bit longer until we were in the middle of a pandemic to make a truly radical move.  </p><p id="viewer-dj9sj">July 24th was my last day at MSNBC.  I don’t know what I’m going to do next exactly but I simply couldn’t stay there anymore.  My colleagues are very smart people with good intentions.  The problem is the job itself.  It forces skilled journalists to make bad decisions on a daily basis.  </p><p id="viewer-fl8l2">You may not watch MSNBC but just know that this problem still affects you, too.  All the commercial networks function the same – and no doubt that content seeps into your social media feed, one way or the other.</p><p id="viewer-4g127">It’s possible that I’m more sensitive to the editorial process due to my background in public radio, where no decision I ever witnessed was predicated on how a topic or guest would “rate.”  The longer I was at MSNBC, the more I saw such choices — it’s practically baked in to the editorial process – and those decisions affect news content every day.  Likewise, it’s taboo to discuss how the ratings scheme distorts content, or it’s simply taken for granted, because everyone in the commercial broadcast news industry is doing the exact same thing.  </p><p id="viewer-9c0ji">But behind closed doors, industry leaders will admit the damage that’s being done.</p><p id="viewer-5n5uh">“We are a cancer and there is no cure,” a successful and insightful TV veteran said to me.  “But if you could find a cure, it would change the world.”</p><p id="viewer-39g2k">As it is, this cancer stokes national division, even in the middle of a civil rights crisis.  The model blocks diversity of thought and content because the networks have incentive to amplify fringe voices and events, at the expense of others… all because it pumps up the ratings. </p><p id="viewer-a2lh5">This cancer risks human lives, even in the middle of a pandemic.  The primary focus quickly became what Donald Trump was doing (poorly) to address the crisis, rather than the science itself.  As new details have become available about antibodies, a vaccine, or how COVID actually spreads, producers still want to focus on the politics.  Important facts or studies get buried.</p><p id="viewer-d6q8h">This cancer risks our democracy, even in the middle of a presidential election.  Any discussion about the election usually focuses on Donald Trump, not Joe Biden, a repeat offense from 2016 (Trump smothers out all other coverage).  Also important is to ensure citizens can vote by mail this year, but I’ve watched that topic get ignored or “killed” numerous times.</p><p id="viewer-k0ik">Context and factual data are often considered too cumbersome for the audience.  There may be some truth to that (our education system really should improve the critical thinking skills of Americans) – but another hard truth is that it is the job of journalists to teach and inform, which means they might need to figure out a better way to do that.  They could contemplate more creative methods for captivating an audience.  Just about anything would improve the current process, which can be pretty rudimentary (think basing today’s content on whatever rated well yesterday, or look to see what’s trending online today).</p><p id="viewer-a360v">Occasionally, the producers will choose to do a topic or story without regard for how they think it will rate, but that is the exception, not the rule.  Due to the simple structure of the industry – the desire to charge more money for commercials, as well as the ratings bonuses that top-tier decision-makers earn – they always relapse into their old profitable programming habits.</p><p id="viewer-3haev">I understand that the journalistic process is largely subjective and any group of individuals may justify a different set of priorities on any given day.  Therefore, it’s particularly notable to me, for one, that nearly every rundown at the network basically is the same, hour after hour.  And two, they use this subjective nature of the news to justify economically beneficial decisions.  I’ve even heard producers deny their role as journalists.  A very capable senior producer once said: “Our viewers don’t really consider us the news.  They come to us for comfort.”</p><p id="viewer-a1lqp">Again, personally, I don’t think the people need to change.  I think the job itself needs to change.  There is a better way to do this.  I’m not so cynical to think that we are absolutely doomed (though we are on that path).  I know we can find a cure.  If we can figure how to send a man to the moon, if Alex Trebek can defy the odds with stage 4 pancreatic cancer, and if Harry Reid can actually overcome pancreatic cancer (he’s now cancer free), then we can fix this, too. </p><p id="viewer-2jvfe">“Not everything that is faced can be changed, but nothing can be changed until it is faced.”</p><p id="viewer-evref">I know James Baldwin wasn’t thinking about MSNBC when he wrote that line in 1962, but those words spoke loudly to me in the summer of 2020.  Unfortunately, many of the same ailments are still at stake today.  Now maybe we can’t really change the inherently broken structure of broadcast news, but I know for certain that it won’t change unless we actually face it, in public, and at least try to change it. </p><p id="viewer-9pbe9">Through this pandemic and the surreal, alienating lockdown, I’ve witnessed many people question their lives and what they’re doing with their time on this planet.  I reckon I’m one of those people, looking for greater meaning and truth.  As much as I love my life in New York City and really don’t want to leave, I feel fortunate to be able to return to Virginia in the near term to reconnect with family, friends, and a community of independent journalists.  I’m both nervous and excited about this change.  Thanks to COVID-19, I’m learning to live with uncertainty. </p><p id="viewer-2bttl">And so very soon, I’m going to be seeking you out, any one of you who also may sense that the news is fundamentally flawed and is frustrated by it.  This effort will start informally but I hope to crystallize a plan for when better, safer days are upon us.  On that front, feel free to reach out anytime if you would like to discuss any of this – whether in agreement or not.  More than ever, I’m craving a full and civil discourse. </p><p id="viewer-ei74m">Until next time, thank you for reading.  I wish you all well.</p><p id="viewer-56pls">Ariana</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049074</guid>
            <pubDate>Tue, 04 Aug 2020 12:02:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turn Jupyter Notebooks into Beautiful Reports]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24049061">thread link</a>) | @rohitrajan
<br/>
August 4, 2020 | https://dolphyn.io/gallery | <a href="https://web.archive.org/web/*/https://dolphyn.io/gallery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dolphyn.io/gallery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049061</guid>
            <pubDate>Tue, 04 Aug 2020 11:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rogue Wave of Enterprise SaaS]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24048714">thread link</a>) | @chesterarthur
<br/>
August 4, 2020 | https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/rogue-wave/freakwave.jpg" alt="Freak wave"></p>

<p>During the pandemic, I’ve done my civic duty and spent lockdown reading a ton of random stuff on the internet. In the midst of a Wikipedia binge, I went down a rabbit hole on <a href="https://en.wikipedia.org/wiki/Rogue_wave">rogue waves</a>: massive waves that occur in the middle of the ocean, endangering ships and generating <a href="https://www.youtube.com/watch?v=pu4ogCy5d4k">kickass Youtube content</a>.</p>

<p>The concept of a rogue wave reminded me of a particularly challenging stage in the life of many venture-backed enterprise SaaS startups. Similar to how a rogue wave forms, during this phase many Small Problems coincide and create a Big Problem. Also like rogue waves, this moment in the life of a high-growth enterprise SaaS business is uncommon – it seems to occur around $5-20 million ARR, which relatively few companies reach, and can seem almost mythical. And finally, the effects of both rogue waves and this challenging startup stage are predictable: if you spend long enough on the high seas, they’re waiting for you.</p>

<p>I’ve seen this phenomenon both in-person as an operator and as an observer of other companies, and I do believe it’s real. I’m writing this essay in order to:</p>

<ul>
  <li>Share what I’ve seen</li>
  <li>Provide some opinions on what you can do about it</li>
</ul>

<p>Hopefully I can be the crusty old mariner bringing back tales that others find useful.</p>

<h2 id="hitting-the-wall">Hitting the Wall</h2>

<p><img src="https://staysaasy.com/assets/rogue-wave/boat.jpg" alt="Big boat, bigger wave">
Startups can be stressful</p>

<p>The rogue wave typically seems to hit between $5M and $20M in ARR. If you’re operating with a common venture-backed SaaS model of <a href="https://www.saastr.com/how-to-figure-out-your-competitors-revenues-in-about-70-seconds/">$1-200k ARR per employee</a>, this is around where you’ll hit the <a href="https://www.bbc.com/future/article/20191001-dunbars-number-why-we-can-only-maintain-150-relationships">Dunbar number</a> of ~150 people: the point where you can no longer operate as a large family, and need to start acting like a corporation. <em>(Note that the post linked is from 2012 – SaaS has since exploded, and more companies are raising huge rounds and hiring more on less revenue)</em></p>

<p>Crossing the 150-person barrier is both operationally and emotionally difficult:</p>

<ul>
  <li>Operational: We have so many teams, we need regular status reports!</li>
  <li>Emotional: Why do I need to send <em>you</em> a status report all of a sudden, I thought we were all friends here?!</li>
</ul>

<p>This transition point is also when many leaders who excelled in scrappy startup mode <a href="https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">struggle to level up</a> in a larger organization. Some successfully scale themselves (slow, painful) and others will leave the company (fast, but often even more painful).</p>

<p>Many of the first contracts that you closed post-traction come up for renewal around this point (in the enterprise – SMB SaaS has less predictable growth profiles). If you’re following a <a href="https://www.battery.com/powered/helping-entrepreneurs-triple-triple-double-double-double-to-a-billion-dollar-company/">triple-triple-double-double-double</a> growth path, you’ll be at roughly your second triple. There will be too many customers for the founding team to personally visit and retain everyone.</p>

<p>At this point you’ll need to renew “real” customers, not just friends who took a flyer on your infant product. These aren’t the earliest adopters who will be with you through thick and thin and are really closer to partners. These are real live paying customers who will leave if your product is screwed up. As these renewals approach, a mature post-sales motion becomes essential.</p>

<p>The expectations around your revenue also become more real at this stage. Under about $10M ARR, your revenue projections can be a mild shitshow. But the expectation that you’ll have at least some semblance of predictability steadily increases.</p>

<p>And through it all you need to continue to scale the product. Your code is no longer a series of never-ending green fields rolling off into the distance, and non-trivial parts of your product will need to be meaningfully restructured. You’re burdened by decisions made years ago, often by people who are no longer on the team.</p>

<p>This is especially true for enterprise SaaS. Enterprise products are much more unwieldy than jewel-box consumer products, as they have to support many more users and workflows. Consumer products are like Chipotle: a small, carefully curated set of menu items, built for elegance and efficiency. Enterprise products are like the Cheesecake Factory: you can get steak, pasta, a milkshake and 4 kinds of margarita in the same meal. You need to level up how your team builds products.</p>

<h2 id="cresting-the-wave">Cresting the Wave</h2>

<p>I’m writing about this phenomenon because if you haven’t seen or heard about it, there isn’t really a good way to realize that it might be coming. Even if it isn’t preventable, it’s better to know what’s on the horizon. After all, being able to see around corners is why many companies hire experienced operators.</p>

<p>I won’t claim to be an expert on how to react, but I can share a few things that I think work well and a few that don’t, and what I would do if I had to go through this phase again.</p>

<h3 id="the-crew">The Crew</h3>

<p>First, I would do my best to get the right team in place in advance. In particular, I would make sure that I had very strong functional heads for the functions that will be strained the most: Product, Engineering, Marketing, Sales, Support, and Customer Success. You don’t need every role covered, but it saves headaches to know that some parts of the team are bulletproof. This isn’t the time for unforced errors.</p>

<p><img src="https://staysaasy.com/assets/rogue-wave/pirate-crew.jpg" alt="Pirates of the Caribbean crew">
You want a senior crew. You can tell that Sharkman here has experience and won’t freak out when the database goes down or a large account churns.</p>

<p>I also recommend hiring senior team members who can help see around corners and anticipate issues. This is a taxing time period because it’s so damn busy, and raw, well-directed horsepower tends to carry the day in those situations. More importantly, seasoned operators have typically seen challenging times before, and have the composure to handle them calmly because they know that things are always on fire.</p>

<p>It’s tempting during these busy times to make very junior hires such as new college graduates or coding bootcamp grads just to put butts in seats. These folks can be excellent hires in calmer times, but the chaos caused by too many inexperienced employees is very difficult while you’re cresting the wave.</p>

<h3 id="steering-the-ship">Steering the Ship</h3>

<p>Startups are generally fairly stressful, and that’s heightened in this time period. When operational problems strike in stressful times, it’s common to blame the people involved rather than processes – in reality, bad processes or incentives are usually the root cause.</p>

<p>Generally speaking, the faster you’re growing, the more lightweight your processes should be. When you’re in rapid scaling mode your operational tempo is constantly changing, so there’s no point boiling the ocean to create a perfect process when next month so much will have changed.</p>

<p>For example: when confronting a startup rogue wave, I would not choose to reinvent a completely new system for launching new features. Instead, use 20% of the time to set up a simple, predictable process that gives you 80% of the value. Example: set up a recurring check-in meeting where upcoming releases are discussed by PMs and Tech Leads + a Slack thread where all new releases are announced when they go-live. It won’t be perfect, but you can get this up and running in 15 minutes.</p>

<h3 id="commit">Commit</h3>

<p>This is not the time to hedge your decisions or waffle on strategy.</p>

<p>For example: in general, I prefer to give people a generous window of time to grow into stretch roles. Promoting from within builds continuity, leads to a more invested team, and motivates others by demonstrating that you’re creating strong career paths. But in this phase it’s especially important that you commit to keeping or replacing leaders fast, as there’s just too much going on.</p>

<p>If you’re 30% of the way up a 100 foot wall of water and decide to adjust course, you’re going to get slammed.</p>

<h3 id="keeping-calm">Keeping Calm</h3>

<p>Whatever you do, <em>don’t freak out</em>. When it feels like shit is hitting the fan everywhere, it’s easy to want to react and search for magic solutions. Hire a new Head of X! Spend less! No wait, spend <em>more</em>! Pause development and focus on tech debt! Actually our largest customer needs more features, cancel all tech debt projects!</p>

<p>In reality, to take a line from The Sopranos, <a href="https://www.youtube.com/watch?v=_po7So0MKq4">it won’t be cinematic</a>. Life isn’t a movie. There are no magic fixes – this challenging phase gets resolved by showing up and executing in an unflashy way for months. Magic fixes never really exist, and that’s especially true since this crucible stems from several medium-sized problems amplifying one another.</p>

<p>Searching for a unified solution to your troubles risks distraction. The road is reasonably straightforward and the challenges are tractable: there are just a lot of them. Just like an actual rogue wave, you can’t flee or dodge the factors that make crossing these rogue waves so difficult. You succeed by pointing your boat right at the problem and hitting the gas. Keeping calm doesn’t mean being stubborn or refusing to change, but it does mean that you can’t second guess your decisions – especially when it feels like you’re climbing a wall of water.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Not everyone makes it over the wave – of the roughly 10 cases that I’ve observed, roughly half had their growth stunted for at least several years after hitting this stage. In my opinion this SaaS rogue wave should be taken seriously.</p>

<p>But the good news is that once you’ve crossed the wave, you can speed up again. As you’re rising up the wall everything goes into slow motion; but once you’ve crested the top, your acceleration can increase again as you’ve set yourself up with a more stable operating model and a hardened team.</p>

<p>This is a wonderful time, as there’s so much opportunity. Your team is still in place. The market opportunity is there, and people are buying. And once you’re over the top, the water is much calmer towards the horizon.</p>

<p>In conclusion:</p>

<ul>
  <li>Many challenging situations tend to arise simultaneously when high growth enterprise SaaS companies hit roughly $5-20 million ARR.</li>
  <li>The good news is that after this phase things get easier – the bad news is that it’s not easily avoidable.</li>
  <li>The best way to move forward is to focus on executing – and don’t be overly reactive.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048714</guid>
            <pubDate>Tue, 04 Aug 2020 11:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SIMD Everywhere: 0.5.0]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 53 (<a href="https://news.ycombinator.com/item?id=24048562">thread link</a>) | @lelf
<br/>
August 4, 2020 | https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html | <a href="https://web.archive.org/web/*/https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’m pleased to announce the availability of the first release of <a href="https://github.com/simd-everywhere/simde">SIMD
Everywhere</a> (SIMDe),
<a href="https://github.com/simd-everywhere/simde/releases">version 0.5.0</a>,
representing more than three years of work by over a dozen developers.</p>

<p>SIMDe is a permissively-licensed (MIT) header-only library which
provides fast, portable implementations of
<a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a> intrinsics for platforms
which aren’t natively supported by the API in question.</p>

<p>For example, with SIMDe you can use
<a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> on
<a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM</a>,
<a href="https://en.wikipedia.org/wiki/IBM_POWER_instruction_set_architecture">POWER</a>,
<a href="https://webassembly.org/">WebAssembly</a>, or almost any platform with a
C compiler.  That includes, of course, x86 CPUs which don’t support
the ISA extension in question (<em>e.g.</em>, calling AVX-512F functions on a
CPU which doesn’t natively support them).</p>

<p>If the target natively supports the SIMD extension in question there
is no performance penalty for using SIMDe.  Otherwise, accelerated
implementations, such as NEON on ARM, AltiVec on POWER, WASM SIMD on
WebAssembly, etc., are used when available to provide good
performance.</p>

<p>SIMDe has already been used to port several packages to additional
architectures through either upstream support or distribution
packages, <a href="https://wiki.debian.org/SIMDEverywhere">particularly on
Debian</a>.</p>

<p>If you’d like to play with SIMDe online, you can do so <a href="https://simde.netlify.app/godbolt/demo">on Compiler
Explorer</a>.</p>

<h2 id="what-is-in-050">What is in 0.5.0</h2>

<p>The 0.5.0 release is SIMDe’s first release.  It includes complete
implementations of:</p>

<ul>
  <li>MMX</li>
  <li>SSE</li>
  <li>SSE2</li>
  <li>SSE3</li>
  <li>SSSE3</li>
  <li>SSE4.1</li>
  <li>AVX</li>
  <li>FMA</li>
  <li>GFNI</li>
</ul>

<p>We also have rapidly progressing implementations of many other
extensions including NEON, AVX2, SVML, and several AVX-512 extensions
(AVX-512F, AVX-512BW, AVX-512VL, etc.).</p>

<p>Additionally, we have an extensive test suite to verify our
implementations.</p>

<h2 id="what-is-coming-next">What is coming next</h2>

<p>Work on SIMDe is proceeding rapidly, but there are a lot of functions
to implement… x86 alone has about 6,000 SIMD functions, and we’ve
implemented about 2,000 of them.  We will keep adding more functions
and improving the implementations we already have.</p>

<p>Our NEON implementation is being worked on very actively right now
by Sean Maher and Christopher Moore, and is expected to continue
progressing rapidly.</p>

<p>We currently have two Google Summer of Code students working on the
project as well; <a href="https://masterchef2209.wordpress.com/2020/06/17/guide-to-intel-sse4-2-crc-intrinisics-implementation-for-simde/">Hidayat
Khan</a>
is working on finishing up AVX2, and <a href="https://medium.com/@himanshi18037">Himanshi
Mathur</a> is focused on SVML.</p>

<p>If you’re interested in using SIMDe but need some specific functions
to be implemented first, please <a href="https://github.com/simd-everywhere/simde/issues/new">file an
issue</a> and we may
be able to prioritize those functions.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>If you’re interested in helping out please get in touch.  We have <a href="https://gitter.im/simd-everywhere/community">a
chat room on Gitter</a>
which is fairly active if you have questions, or of course you can
just dive right in on <a href="https://github.com/simd-everywhere/simde/issues">the issue
tracker</a>.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048562</guid>
            <pubDate>Tue, 04 Aug 2020 10:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Royalty-Free SVG Illustrations and Animations]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24048508">thread link</a>) | @andyydao
<br/>
August 4, 2020 | https://www.pixeltrue.com/free-illustrations | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/free-illustrations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->










<div><div data-collapse="medium" data-animation="default" data-duration="400" role="banner"><div><p><a href="https://www.pixeltrue.com/illustrations"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard.png" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard.png 969w" sizes="(max-width: 991px) 120px, (max-width: 1919px) 130px, 200px" alt=""></a></p></div></div></div><div><div><div><p>To be the first to know about upcoming free illustrations consider signing up to our <a href="#newsletter">newsletter</a> <a target="_blank" href="http://bit.ly/popupcheck"><strong></strong></a>.</p><p>These <strong>Free SVG Illustrations</strong> AND <strong>Lottie Animations</strong> are available for free for personal and commercial use (MIT License). In other words: <strong>you can do whatever you want with them.</strong></p></div></div></div><div><div role="list"><div role="listitem"><p>robot error settings broken repair</p><a href="https://www.pixeltrue.com/free/error-monochrome" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FError%20BW.zip?alt=media&amp;token=a45f1df1-2a6d-4197-8708-95a6881eb3ad" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>robot error settings broken repair</p><a href="https://www.pixeltrue.com/free/error-colour" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FError%20-%20Colour.zip?alt=media&amp;token=ed6065b8-f5cd-4348-9f91-2da69a82f6e8" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>success health fitness celebration finish marathon</p><a href="https://www.pixeltrue.com/free/success-monochrome" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FSuccess%20BW.zip?alt=media&amp;token=0a501d4a-66d4-4dda-8f7b-dbf32ee138f9" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>success health fitness celebration finish marathon</p><a href="https://www.pixeltrue.com/free/success-colour" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FSuccess%20Colour.zip?alt=media&amp;token=95783604-14b8-40eb-b4a5-6fc36adefb95" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div></div></div><div id="newsletter"><div><p>Get new free illustrations every week emailed to you<br></p><p>Plus nothing but quality pixels in your inbox every week!<br></p><div><div><p>Success! Stay tuned for some exciting content 🔥</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
 



















<!-- Start Infinite Scroll -->



<!-- End Infinite Scroll -->





</div>]]>
            </description>
            <link>https://www.pixeltrue.com/free-illustrations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048508</guid>
            <pubDate>Tue, 04 Aug 2020 10:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Myth and Monolith – The Nine Elms Cold Store]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24048477">thread link</a>) | @yummypaint
<br/>
August 4, 2020 | https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/ | <a href="https://web.archive.org/web/*/https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><strong>A new skyscraper –</strong> <strong>or two – thrusts itself up into the skies of Vauxhall-Nine Elms every year, it seems. It may be hard to imagine now, writes Andrew Rogers, but for the final third of the last millennium, the area’s skyline hardly changed at all. </strong></p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon-300x218.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon-768x559.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>Nine Elms Cold Store. Photograph by Richard Gallon.</em></figcaption></figure>



<p>For 35 years between 1964 and 1999 almost every view of Vauxhall was dominated by one building – the Nine Elms Cold Store. And it wasn’t even the tallest.</p>



<p>Even when the much taller (88m) Market Towers<span id="easy-footnote-1-9140"></span><span><a href="#easy-footnote-bottom-1-9140" title="Since demolished in preparation for the ‘landmark’ (what – another one?) One Nine Elms development featuring residential, office, hotel and retail space."><sup>1</sup></a></span> came along in 1975, it barely succeeded in distracting the eye from the cold store. This giant, concrete, windowless, and for years redundant, monolith was very much Vauxhall’s landmark and a symbol of SW8’s almost dystopian-looking late-industrial landscape.</p>



<p>For most of its life it stood empty, or if not quite empty then abandoned by its owners. It was often emphatically not empty. According to legend it was used as a cruising ground, a performance space, a recording studio, and a temple for devil worship. Some say people died in there, and that it featured in an episode of <em>The Sweeney</em>.<span id="easy-footnote-2-9140"></span><span><a href="#easy-footnote-bottom-2-9140" title="‘In From the Cold’. Season 3 Episode 2."><sup>2</sup></a></span> Can these things possibly be true?’ Urban myths surely.</p>



<p>But we’re getting ahead of ourselves. Let’s start almost at the beginning.</p>



<h2>1964–1979: The Chill Years</h2>



<p>The Nine Elms Cold Store stored cold things for less than half of its life. It held meat, fish, butter and cheese for 15 years then nothing for 20.</p>



<p>It opened on 30 November 1964<span id="easy-footnote-3-9140"></span><span><a href="#easy-footnote-bottom-3-9140" title="‘£1M. Cold Store Opened’, <em>The Times.</em> Tuesday, 1 December 1964."><sup>3</sup></a></span> on land previously occupied by the <a href="https://vauxhallhistory.org/gas/">South Metropolitan Gas Works</a> which in turn had been built on the site of <a href="https://vauxhallhistory.org/candles/">Price’s Patent Candle Company</a>‘s Belmont works. The current occupant is the St George Tower and the green-glass, wing-topped St George Wharf apartments. Were these to be pitted against the derelict cold store in an ugliness competition it’s difficult to say who would win.</p>



<p>Anyway, the cold store was built, filling in Vauxhall Creek – the last vestige of the river Effra – in the process.<span id="easy-footnote-4-9140"></span><span><a href="#easy-footnote-bottom-4-9140" title="Jon Newman (2016), <em>River Effra: South London’s Secret Spine</em>. Oxford: Signal Books."><sup>4</sup></a></span></p>



<p>The opening merited a mention in <em>The Times</em> which reported that ‘Europe’s most modern cold store’ had cost its owners London Cold Storage Co (one of the Associated Fisheries Group of Companies) more than £1 million to build. With a capacity of two million cubic feet it could hold more than 16,000 tons of food<span id="easy-footnote-5-9140"></span><span><a href="#easy-footnote-bottom-5-9140" title="<em>The Times</em>, ibid."><sup>5</sup></a></span> and goods could be loaded and unloaded there faster and more efficiently than at any other cold store in Europe.<span id="easy-footnote-6-9140"></span><span><a href="#easy-footnote-bottom-6-9140" title="<em>Refrigeration and Air Conditioning</em>, Volume 68, Nos. 802–807."><sup>6</sup></a></span> Its purpose was to store produce for frozen-food processors and distributors.<span id="easy-footnote-7-9140"></span><span><a href="#easy-footnote-bottom-7-9140" title="‘Quick Turn-round at New London Cold Store’, <em>Commercial Motor</em>, 11 Dec 1964."><sup>7</sup></a></span></p>



<p>But why here? Why Nine Elms?</p>



<p>One reason was that the site was available. The gas works had disappeared in 1956 and the site was being used as a coach park. <a rel="noreferrer noopener" href="http://svsfilm.com/nineelms/bruns.htm" target="_blank">According to one account</a>, ‘Here a thieves’ market thrived, carefully observed and recorded by police officers watching from the top floor windows of <a href="https://vauxhallhistory.org/brunswick-house/">Brunswick House</a>.’</p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton.png" alt="Monochrome shot of Nine Elms Cold Store from the north side of the Thames. Copyright Martin Picton" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton-300x212.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton-768x541.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>The Cold Store seen from the north bank of the Thames. Photograph by Martin Picton.</em></figcaption></figure>



<p>The location had excellent transport connections – river, road, and rail. Two barges could be unloaded simultaneously at the Cold Store’s 90ft Thames jetty<span id="easy-footnote-8-9140"></span><span><a href="#easy-footnote-bottom-8-9140" title="<em>Refrigeration and Air Conditioning</em>, Vol. 68, Nos. 802–807."><sup>8</sup></a></span> and eight lorries at a time could use the four covered loading bays, according to a report in <em>Commercial Motor</em>.<span id="easy-footnote-9-9140"></span><span><a href="#easy-footnote-bottom-9-9140" title="‘Quick Turn-round at New London Cold Store’, <em>Commercial Motor</em>, 11 Dec 1964."><sup>9</sup></a></span> ‘Hydraulic dock levellers are used at the lorry bays and electric pallet trucks and other mechanical aids are widely used,’ swooned the periodical in its report on the opening of the cold store.</p>



<p>In 1965 most of Nine Elms (including the site of the New Covent Garden Market and the since-shunted flower market) was occupied by railway yards. Today, the area’s railway history is all but forgotten but for 10 years from 1838 the area boasted its very own and quite grand railway terminus which was the end of the line for trains coming in from Woking and later Southampton. <a href="https://vauxhallhistory.org/nine-elms-station/">Nine Elms Station</a> stood at the end of Nine Elms Lane (then just called Nine Elms) which at that time emerged onto the Wandsworth Road roughly opposite the end of Miles Street (not Parry Street, as now). In 1848 the line was diverted before it reached the station to the new terminus at Waterloo via a new station at Vauxhall. The now-sidelined (literally) Nine Elms area became a massive railway yard and for over 120 years served variously as a carriage and wagon works, a goods depot and a locomotive depot.</p>



<div><figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall.png 418w, https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall-296x300.png 296w, https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall-75x75.png 75w" sizes="(max-width: 418px) 100vw, 418px"></figure><p>When it was built in 1965 the Cold Store was served by lines which reached it by crossing Nine Elms Lane, as this map from around 1967 shows.</p></div>



<p>At this point, Nine Elms Lane still met the Wandsworth Road just north of Miles Street. It was presumably rerouted to its current position (opposite Parry Street) in the early 1970s when New Covent Garden flower market was built.</p>



<p>Sadly the Cold Store’s triple-transport-threat status was short-lived – the railway yard closed just two years later, in 1967.</p>



<h2>1979–1999: The Wilderness Years</h2>



<p>In 1979, 15 years after it opened, the Nine Elms Cold Store closed. Why?</p>



<p>Advances in refrigeration, the increase in air transportation, the demise of river-based haulage seem likely factors. And Associated Fisheries’ cold storage business had been badly affected by the UK’s 1973–75 recession.<span id="easy-footnote-10-9140"></span><span><a href="#easy-footnote-bottom-10-9140" title="‘Associated Fisheries declines’, <em>The Times</em>, 9 July 1981."><sup>10</sup></a></span> But the value of the site must have played a significant role. In fact, the Chairman of Associated Fisheries suggested so much as far back as 1973 when the Cold Store had been open for less than a decade:</p>



<blockquote><p>Giving news to shareholders of Associated Fisheries […] Mr P. M. Tapscott, chairman refers to the proposed development of the Thames frontage on the south side of Vauxhall Bridge and the fact that AF’s Nine Elms cold store, a site of 1.6 acres, adjoins this development. Possibilities of re-development are, therefore, being closely examined.<span id="easy-footnote-11-9140"></span><span><a href="#easy-footnote-bottom-11-9140" title="‘Chairmen&amp;#8217;s Reports’, <em>The Times</em>, 28 Nov 1973."><sup>11</sup></a></span></p></blockquote>



<p>London Cold Storage divested itself of the site pretty quickly after the Cold Store closed. In November 1980, <em>The Times</em> reported that contracts had been exchanged on the sale of the cold store and other property for £1.67 million cash with completion due on February 5.<span id="easy-footnote-12-9140"></span><span><a href="#easy-footnote-bottom-12-9140" title="&amp;#8216;Associated Fisheries’, <em>The Times</em>, 21 Nov 1980."><sup>12</sup></a></span></p>



<p>Which is when things begin to get really interesting at the Nine Elms Cold Store.</p>



<h2>Development Hell</h2>



<p>Why did it take 20 years for the Cold Store to be demolished? There’s probably a whole book to be written about it if there’s an audience for property development horror porn. Suffice to say that in the early days it involved Ronald Lyon, who could be described as a colourful property developer with an interesting business past.</p>



<p>Lyon got his hands on the Cold Store after the first proposal for the Effra site (which included land on both sides of the bridgefoot) fell apart.</p>



<div><figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant.png" alt="architect's image of never built green giant at nine elms" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant.png 443w, https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant-300x296.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant-75x75.png 75w" sizes="(max-width: 443px) 100vw, 443px"></figure><p><a href="http://www.skyscrapernews.com/buildings.php?id=4248">The extraordinary 150m ‘Green Giant’ project</a> designed by architects Abbott Howard would have included 100 luxury apartments, 30,000 square metres of office space earmarked for Esso, and a gallery to hold the Tate’s sculpture collection.</p></div>



<p>Then along came Lyon, whose Arunbridge company was granted a controversial Special Development Order from the then Secretary of State for the Environment, Michael Heseltine. This SDO would essentially allow Arunbridge’s office scheme to run roughshod over normal planning procedures. Despite this unfair advantage, Lyon failed to find the funding and the scheme collapsed. The Swiss Bank Julius Baer &amp; Co was holding the site as security against a loan and they sold it to Samuel Properties<span id="easy-footnote-13-9140"></span><span><a href="#easy-footnote-bottom-13-9140" title="‘Samuel Properties plans 1,000 flats on Green Giant site’, <em>The Times</em>, 8 May 1985."><sup>13</sup></a></span> who in turn sold it to a Middle Eastern consortium, who then… well, you get the picture. One of the ongoing barriers to development seems to have been the Borough of Lambeth’s objection to swanky residential schemes of the kind it now welcomes with open arms.</p>



<p>Quite how it took two decades to knock the Cold Store down isn’t clear but one factor seems to have been the cost of demolition. One person involved in a government scheme to build a new Home Office on the Effra site recalls that the Cold Store was to be addressed late in the scheme due to <a rel="noreferrer noopener" href="http://svsfilm.com/nineelms/bruns13.jpg" target="_blank">the cost of demolishing it</a>.</p>



<p>After a long, lingering decline, the Nine Elms Cold Store was finally put out of its misery in (I think) 1999. Thankfully Jonathan Bell was around to record the event for posterity.</p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms-300x220.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms-768x564.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>The demolition of the Cold Store, photographed by Jonathan Bell.</em></figcaption></figure>



<p>But until then, the Cold Store could hardly be described as empty…</p>



<h2>Screen Appearances</h2>



<p>London film makers in search of ‘bleak industrial landscape bordering on dystopian’ needed to look no further than Nine Elms – even before it was abandoned. Less hackneyed, less iconic, and more alien than Battersea Power Station, the Cold Store made fleeting background appearances in films such as <em>Villain</em> (1971), a crime film starring Richard Burton, and <em>The Optimists of Nine Elms</em> (1973) with Peter Sellers. But the most thrilling use of it must surely be the 1976 episode of cop series <em>The Sweeney</em> called ‘In From the Cold’, which featured this exchange on the very roof of the Cold Store.</p>



<figure><p>
<iframe title="The Sweeney Season 3 Episode 2 In From the Cold" width="500" height="375" src="https://www.youtube.com/embed/Ct-eRE5TRm0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>Cruising to Casualty</h2>



<p>After the closure of the Cold Store in 1979 its most frequent visitors were gay men, who adopted it as a night-time cruising ground, handy for rounding off a night out at the nearby Royal Vauxhall Tavern or the Market Tavern which was housed in the Market Towers high-rise. The Cold Store was a bedroom and playroom to many liaisons over the years but was notorious for providing pleasure and danger in almost equal measure – sometimes with fatal consequences.</p>



<p>One visitor who narrowly escaped death but lived to tell the tale is John (not his real name):</p>



<p>“The Nine Elms Cold Store was where you went after a night at the Market Tavern if you didn’t get lucky. You crossed Nine Elms Lane via the footbridge (pedestrians were made to navigate all the Vauxhall Cross main roads that way back then) to a gate just to the left of the wall which still shelters Brunswick House from Nine Elms Lane today. The steel gate was 10 feet high, padlocked, and there was barbed wire across the top, but a gap had been forced open at one side through which you could squeeze to get in to the grounds of the cold store. There was no such thing as site security in those days.</p>



<p>“It was about a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/">https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/</a></em></p>]]>
            </description>
            <link>https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048477</guid>
            <pubDate>Tue, 04 Aug 2020 10:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dan Moore went from sci-fi to devrel]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24048361">thread link</a>) | @todsacerdoti
<br/>
August 4, 2020 | https://devjourney.info/Guests/112-DanMoore.html | <a href="https://web.archive.org/web/*/https://devjourney.info/Guests/112-DanMoore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      


<!--
<div>
        <h2>Transcript</h2>
        <p><i>
                The following transcript was automatically generated. </br>
                Help us out, <a
                    href="https://github.com/DevJourneyFm/DevJourneyFm.github.io/tree/master/Guests/Transcripts/112-DanMooreTx.html">Submit
                    a pull-request</a> to correct potential mistakes
            </i></p>

        <span></span>
    </div>
-->

  



                            

      
      <hr>
      
      <p>📖 Browse the amazing <a href="https://devjourney.info/Books.html">books</a> recommended on the podcast.</p>
      <p>📢 <a href="https://devjourney.info/subscribe.html">Subscribe</a> to the podcast now!</p>
      <p>Copyright: <a href="https://www.timbourguignon.fr/">Tim Bourguignon</a></p>

    </div></div>]]>
            </description>
            <link>https://devjourney.info/Guests/112-DanMoore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048361</guid>
            <pubDate>Tue, 04 Aug 2020 09:57:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django 3.1 Async]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24048208">thread link</a>) | @ephes
<br/>
August 4, 2020 | https://wersdoerfer.de/blogs/ephes_blog/django-31-async/ | <a href="https://web.archive.org/web/*/https://wersdoerfer.de/blogs/ephes_blog/django-31-async/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
<p><br>
With <a href="https://docs.djangoproject.com/en/3.1/topics/async/">version 3.1</a>, you can finally use asynchronous views, middlewares and tests in Django. Support for async database queries will follow later. You don’t have to change anything if you don’t want to use those new async features . All of your existing synchronous code will run without modification in Django 3.1.</p>

<p>Async support for Django is on it’s way for quite some time now. Since <a href="https://docs.djangoproject.com/en/3.0/releases/3.0/#asgi-support">version 3.0</a> there’s support for <a href="https://asgi.readthedocs.io/en/latest/">ASGI</a> included. But there was not much benefit for end users though. The only thing you could do concurrently were file uploads, since uploads don’t reach the view layer which was not async capable in Django 3.0.</p>

<p>When do you might want to use those new features? If you are building applications that have to deal with a high number of tasks simultaneously. Here are some examples:</p>

<ul>
	<li>Chat services like <a href="https://slack.com/">Slack</a></li>
	<li>Gateway APIs / Proxy Services</li>
	<li>Games, especially MMOs like <a href="https://www.eveonline.com/">Eve Online</a></li>
	<li>Applications using <a href="https://youtu.be/MZvmYaFkNJI">Phoenix Liveview</a> - check out <a href="https://phoenixphrenzy.com/results">Phoenix Phrenzy results</a> for additional examples</li>
	<li>A reactive version of <a href="https://docs.djangoproject.com/en/3.1/ref/contrib/admin/">Django Admin</a> where model changes are shown interactively</li>
	<li>A new api frontend for <a href="https://www.django-rest-framework.org/">Django REST framework</a> updating list endpoints interactively as new data comes in</li>
	<li>All kinds of dashboard applications showing currently active connections, requests per second updating in realtime</li>
</ul>

<p>As Tom Christie explained in his talk <a href="https://youtu.be/u8GSFEg5lnU">Sketching out a Django redesign</a> held at DjangoCon 2019 the core question is this: Do we want to have to switch languages to support those use cases? And while his <a href="https://www.starlette.io/">Starlette</a> project (gaining popularity recently in combination with the <a href="https://fastapi.tiangolo.com/">FastAPI framework</a>) is allowing us to do all this in Python, we also might want to keep using Django.</p>

<h2 id="what-to-expect-from-this-article">What to Expect from this Article?</h2>

<ol type="1">
	<li>A small example on how to use async views, middlewares and tests</li>
	<li>Why is async such a big deal anyway?</li>
	<li>The gory details of multithreading vs async, GIL and other oddities</li>
</ol>

<p>Estimated read time: 25 minutes<br>
There's also a&nbsp;<a href="https://python-podcast.de/show/async-teil-1/">podcast episode</a>&nbsp;elaborating a little bit more on this&nbsp;topic (it's in german).</p>




<p>For this example you need a working installation of <a href="https://www.python.org/">Python</a>. Any version from 3.6 onwards will do, but I recommend using the latest 3.8 series, because async is relatively new to Python and new versions still bring major improvements in usability and stability.</p>

<h2 id="create-virtualenv-and-setup-project">Create Virtualenv and Setup Project</h2>

<p>Usually I prefer setting up new projects with <a href="https://python-poetry.org/docs/">Poetry</a> nowadays, but I understand that requiring people to curl install software makes them feel uncomfortable. And for this example it doesn’t make a big difference anyway. Therefore I’ll use the builtin virtualenv module.</p>

<pre><code>mkdir mysite &amp;&amp; cd mysite
python -m venv mysite_venv &amp;&amp; source mysite_venv/bin/activate
python -m pip install django==3.1 httpx  # install Django 3.1 + async capable http client</code></pre>

<h2 id="initialize-django">Initialize Django</h2>

<pre><code>django-admin startproject mysite .  # create django project in current directory
python manage.py migrate            # migrate sqlite
python manage.py runserver          # should start the development server now</code></pre>

<p>You should now be able to point your browser to <a href="http://localhost:8000/">localhost</a> and see the new Django project sample page. If this doesn’t work, make sure you didn’t set the $DJANGO_SETTINGS_MODULE environment variable. This is what happens to me all the time.</p>

<h2 id="create-some-views">Create some Views</h2>

<p>First we create a synchronous view returning a simple JsonResponse, just like we would have done it in previous Django versions. It takes an optional parameter <code>task_id</code> which we’ll later use to identify the url which was called from the second view. It also sleeps for a second emulating a response that takes some time to be build.</p>

<p>Edit <code>mysite/views.py</code> to look like this:</p>

<div>
<pre><span>import</span> <span>time</span>

<span>from</span> <span>django.http</span> <span>import</span> <span>JsonResponse</span>


<span>def</span> <span>api</span><span>(</span><span>request</span><span>):</span>
    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>payload</span> <span>=</span> <span>{</span><span>"message"</span><span>:</span> <span>"Hello World!"</span><span>}</span>
    <span>if</span> <span>"task_id"</span> <span>in</span> <span>request</span><span>.</span><span>GET</span><span>:</span>
        <span>payload</span><span>[</span><span>"task_id"</span><span>]</span> <span>=</span> <span>request</span><span>.</span><span>GET</span><span>[</span><span>"task_id"</span><span>]</span>
    <span>return</span> <span>JsonResponse</span><span>(</span><span>payload</span><span>)</span>
</pre>

<p>And then <code>mysite/urls.py</code> to look like this:</p>

<div>
<pre><span>from</span> <span>django.urls</span> <span>import</span> <span>path</span>

<span>from</span> <span>.</span> <span>import</span> <span>views</span>

<span>urlpatterns</span> <span>=</span> <span>[</span>
    <span>path</span><span>(</span><span>"api/"</span><span>,</span> <span>views</span><span>.</span><span>api</span><span>),</span>
<span>]</span>
</pre>
</div>

<p>Now you should be able to see the response of little <a href="http://localhost:8000/api/">api view</a> in your browser. I recommend <a href="https://firefox.org/">Firefox</a> to look at json responses because they look a little bit nicer there, but any browser will do. This is not at all different from a normal synchronous api view in Django before 3.1.</p>

<h3 id="async-aggregation-view">Async Aggregation View</h3>

<p>Ok, let’s add an asynchronous view then. We are creating a view that builds ten different urls pointing to our original sync view and aggregate their results in a new response.</p>
</div>

<p>Add this code to <code>mysite/views.py</code> and move the imports to the top of the file:</p>

<div>
<pre><span>import</span> <span>httpx</span>
<span>import</span> <span>asyncio</span>


<span>def</span> <span>get_api_urls</span><span>(</span><span>num</span><span>=</span><span>10</span><span>):</span>
    <span>base_url</span> <span>=</span> <span>"http://127.0.0.1:8000/api/"</span>
    <span>return</span> <span>[</span><span>f</span><span>"</span><span>{</span><span>base_url</span><span>}</span><span>?task_id=</span><span>{</span><span>task_id</span><span>}</span><span>"</span> <span>for</span> <span>task_id</span> <span>in</span> <span>range</span><span>(</span><span>num</span><span>)]</span>


<span>async</span> <span>def</span> <span>api_aggregated</span><span>(</span><span>request</span><span>):</span>
    <span>s</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
    <span>responses</span> <span>=</span> <span>[]</span>
    <span>urls</span> <span>=</span> <span>get_api_urls</span><span>(</span><span>num</span><span>=</span><span>10</span><span>)</span>
    <span>async</span> <span>with</span> <span>httpx</span><span>.</span><span>AsyncClient</span><span>()</span> <span>as</span> <span>client</span><span>:</span>
        <span>responses</span> <span>=</span> <span>await</span> <span>asyncio</span><span>.</span><span>gather</span><span>(</span><span>*</span><span>[</span><span>client</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span> <span>for</span> <span>url</span> <span>in</span> <span>urls</span><span>])</span>
        <span>responses</span> <span>=</span> <span>[</span><span>r</span><span>.</span><span>json</span><span>()</span> <span>for</span> <span>r</span> <span>in</span> <span>responses</span><span>]</span>
    <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>s</span>
    <span>result</span> <span>=</span> <span>{</span>
        <span>"message"</span><span>:</span> <span>"Hello Async World!"</span><span>,</span>
        <span>"responses"</span><span>:</span> <span>responses</span><span>,</span>
        <span>"debug_message"</span><span>:</span> <span>f</span><span>"fetch executed in </span><span>{</span><span>elapsed</span><span>:</span><span>0.2f</span><span>}</span><span> seconds."</span><span>,</span>
    <span>}</span>
    <span>return</span> <span>JsonResponse</span><span>(</span><span>result</span><span>)</span>

</pre>
</div>

<p>Add a route to our new view to <code>mysite/urls.py</code>:</p>

<div>
<pre><span>urlpatterns</span> <span>=</span> <span>[</span>
    <span>path</span><span>(</span><span>"api/"</span><span>,</span> <span>views</span><span>.</span><span>api</span><span>),</span>
    <span>path</span><span>(</span><span>"api/aggregated/"</span><span>,</span> <span>views</span><span>.</span><span>api_aggregated</span><span>),</span>
<span>]</span>
</pre>
</div>

<p>If you now point your browser to the url of your <a href="http://localhost:8000/api/aggregated/">aggregated view</a>, you should be able to see your first result from an asynchronous function. A normal sync view calling <code>httpx.get(url)</code> in a for loop would have taken at least ten seconds to complete, because every api view sleeps for one second and they would have been called one after another summing up their latencies. But our async view took only about one second to complete, so we must have called our sync views concurrently by using <code>async def</code>, <code>async with</code> and the magic of <code>asyncio.gather</code>. Great.</p>

<h3 id="compare-with-sync-view">Compare with Sync View</h3>

<p>We can check our hypothesis that the responses were collected concurrently by adding a plain sync aggregation view to <code>mysite/views.py</code>:</p>

<div>
<pre><span>def</span> <span>api_aggregated_sync</span><span>(</span><span>request</span><span>):</span>
    <span>s</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>
    <span>responses</span> <span>=</span> <span>[]</span>
    <span>urls</span> <span>=</span> <span>get_api_urls</span><span>(</span><span>num</span><span>=</span><span>10</span><span>)</span>
    <span>for</span> <span>url</span> <span>in</span> <span>urls</span><span>:</span>
        <span>r</span> <span>=</span> <span>httpx</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
        <span>responses</span><span>.</span><span>append</span><span>(</span><span>r</span><span>.</span><span>json</span><span>())</span>
    <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>s</span>
    <span>result</span> <span>=</span> <span>{</span>
        <span>"message"</span><span>:</span> <span>"Hello Sync World!"</span><span>,</span>
        <span>"aggregated_responses"</span><span>:</span> <span>responses</span><span>,</span>
        <span>"debug_message"</span><span>:</span> <span>f</span><span>"fetch executed in </span><span>{</span><span>elapsed</span><span>:</span><span>0.2f</span><span>}</span><span> seconds."</span><span>,</span>
    <span>}</span>
    <span>return</span> <span>JsonResponse</span><span>(</span><span>result</span><span>)</span>
</pre>
</div>

<p>And also add a route to the sync aggregated view to <code>mysite/urls.py</code>:</p>

<div>
<pre><span>urlpatterns</span> <span>=</span> <span>[</span>
    <span>path</span><span>(</span><span>"api/"</span><span>,</span> <span>views</span><span>.</span><span>api</span><span>),</span>
    <span>path</span><span>(</span><span>"api/aggregated/"</span><span>,</span> <span>views</span><span>.</span><span>api_aggregated</span><span>),</span>
    <span>path</span><span>(</span><span>"api/aggregated/sync/"</span><span>,</span> <span>views</span><span>.</span><span>api_aggregated_sync</span><span>),</span>
<span>]</span>
</pre>
</div>

<p>As expected, this <a href="http://127.0.0.1:8000/api/aggregated/sync/">sync aggregation view</a> takes now at least ten seconds to finish. Fine.</p>

<h3 id="why-did-it-work">Why Did it Work?</h3>

<p>But how did our async aggregation view work? Note that we just used the normal builtin development server Django provides. Shouldn’t we have to use some kind of <a href="https://asgi.readthedocs.io/en/latest/">ASGI</a> server?</p>

<p>Since we annotated our async view function with <code>async def</code> Django is able to detect that we want to write an async view and runs our view in a thread within its own <a href="https://docs.python.org/3/library/asyncio-eventloop.html">event loop</a>. That’s very convenient, because we could now write async views inside the normal <a href="https://wsgi.readthedocs.io/en/latest/what.html">WSGI</a> Django applications we already use and they’ll just work. We even gain the benefit of being able to do things concurrently inside async views like fetching results from other api endpoints and aggregating them in a new response.</p>

<p>What we won’t get by running async views in a WSGI application is concurrency when calling the view from the outside. Since each async view runs in it’s own thread, we’ll still have as many threads as concurrent requests on any given time.</p>

<h3 id="asgi-example">ASGI Example</h3>

<p>To try out an async example that’s concurrently callable from the outside, let’s install an ASGI server like <a href="https://www.uvicorn.org/">uvicorn</a> then and change the runserver command so that we are now running Django as an ASGI rather than a WSGI application:</p>

<pre><code>python -m pip install uvicorn
uvicorn --reload mysite.asgi:application</code></pre>

<p>Our first <a href="http://localhost:8000/api/">sync api view</a> still works as it should. But if we try to open the <a href="http://localhost:8000/api/aggregated/">async aggregated view</a> view, we get a timeout error. What is happening here? When the aggregated api view is called, it makes subsequent get requests to ten sync api views. But uvicorn is a single threaded server. The <code>httpx.get</code> tasks are dispatched to run asynchronously on the event loop. But calls to <code>time.sleep</code> inside the sync api views are still blocking the main thread, piling up to at least ten seconds latency. Since httpx has a default timeout of five seconds, the fifth <code>httpx.get</code> call probably raises an ReadTimeout exception in our async aggregation view causing the whole view to fail.</p>

<p>In our previous <code>python manage.py runserver</code> example the <code>time.sleep</code> calls are also blocking the threads they are running in. Since the development server is running each request in it’s own thread, because it’s a multithreaded server, the latencies didn’t add up but are blocking different threads concurrently. Therefore the <code>httpx.get</code> calls only have to wait for about one second each.</p>

<p>If the backend you are sending requests to doesn’t support answering those requests concurrently, you still have to wait. We can resolve this by allowing uvicorn to start more worker processes. But this would not guarantee that each new request gets to run on a fresh worker. Maybe it’s dispatched to a worker which is already blocked by another request. So even if you have ten workers, your aggregated response time will probably be larger than one second.</p>

<pre><code>uvicorn --workers 10 mysite.asgi:application</code></pre>

<p>Note that the <code>--workers</code> option wont work under windows.</p>

<p>But uvicorn is a async capable server, why don’t we take advantage of this by turning our sync api view into an async api view? You also have to move the <code>import asyncio</code> line to the top of the file, if you haven’t done this …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wersdoerfer.de/blogs/ephes_blog/django-31-async/">https://wersdoerfer.de/blogs/ephes_blog/django-31-async/</a></em></p>]]>
            </description>
            <link>https://wersdoerfer.de/blogs/ephes_blog/django-31-async/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048208</guid>
            <pubDate>Tue, 04 Aug 2020 09:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Tolerating Complexity]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24048078">thread link</a>) | @leostera
<br/>
August 4, 2020 | https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html | <a href="https://web.archive.org/web/*/https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <section>
          <h2>AM010</h2>

<p>It was late at night when I realized it was about to happen again.</p>
<p>The existing publishing tools I had at hand weren't particularly good to
showcase what I had in mind, but they were convenient enough that I could just
write and leave the problem of actually reading them to whoever happened to
land on that blog.</p>
<p>I mean, it was just a blog. Starting out with 8 patrons, the traffic it got was
mostly friends. They could bear with it.</p>
<p>But the unfortunate reality is that I can't quite stand watching something
being done poorly. It just broils in my gut the feeling that <em>we can do
better</em>. Editing could be simpler. Publishing could be faster. Thinking could
be easier.</p>
<p>I will try to best it, even if the end result ends up being worse, and while
I'll be the first to admit that perhaps it isn't the most attractive of
qualities, it always teaches me something new. Every now and then I do
manage to do it better. The world around me is a little better for it.</p>
<p>This time I had to sit down and write something. I didn't quite know what yet,
but I knew that how I had been writing was getting in the way of what I wanted
to write. So I took a step back and asked around how are the <em>cool kids</em> doing
it this days.</p>
<p>Many seem to like tools like <a href="https://nextjs.org/">Next.js</a>, <a href="https://gatsbyjs.com/">Gatsby</a>, or
<a href="https://gohugo.io/">Hugo</a>. They all provide some sort of structure or template you fit your
content into, a couple of ways to do theming and navigation, and the
possibility to run the whole shebang as a static or dynamically generated
service.</p>
<p>I just needed some static files, and I needed them in the structure they were
already in, so from the choices I was offered it looked like the winner was in
fact Next.js. It came with a few interesting features that I dismissed as
<a href="http://wiki.c2.com/?BellsWhistlesAndGongs">whistles &amp; bells</a>, and frowned at the requirement that
my pages would have to be translated into React components.</p>
<p>Surely a tool with such an emphasis on the "Developer Experience" would
consider the many formats my data could be in, and accommodate for it. But I
nonetheless decided to translate an essay into some Javascript code, and I
finally felt like I could start writing.</p>
<p>Until I had to embed some code.</p>
<p>Suddenly I was somehow recommended to go down the rabbit of hole of finding
good Javascript component libraries that would do the highlighting for me, that
worked with Next, from withing my own writing, which was now no longer just
text but in fact <em>a computer program posing as an essay</em>.</p>
<p>A quick look under the hood showed me there were over 100,000 lines of
Javascript code to turn my untranscendental words into a god damned website.</p>
<p><em>I sighed</em>.</p>
<p>There is a tolerable amount of complexity involved in doing our every day work.
I use <code>vim</code> and, on my computer, it runs on the Linux kernel. I tolerate the
many millions of lines of code from there down to the hardware it runs.
<strong>Tolerance</strong> here is the key word. They afford me things. Not physical things
like food, but the affordance that your thinking gains when you discover a new
idea.</p>
<p>When I first learned about <code>git</code> I suddenly had a new tool to think. I wasn't
familiar with branching models of Subversion or other versioning tools, but
<code>git</code>'s branches, merges, and code history extended my thinking. I have a vague
understanding of the internals of <code>git</code>, but I <strong>tolerate</strong> this complexity
because of what it affords me.</p>
<p>What was this tool really affording me with this complexity? I already had to
pay the cost of translating my content into the format it wanted of me, what
else is there? Hot reloading of assets. Great. My assets are stylesheet files,
the occasional image, and one or two embedded scripts. I can already refresh
a browser with a keypress. What else is there?</p>
<p>From the looks of it, this tools just doesn't support my use-case very well.
How can something so enormously popular and complicated as Next.js not support
my so seemingly simple use-case? I had to be wrong. Where is all this
complexity heading that I can't leverage it without bringing in even more of
it?</p>
<p>Some complexity exists because the underlying problem is in fact complex. It
needs to be dealt with and it cannot be reduced any further. We tend to call
this <a href="http://worrydream.com/refs/Brooks-NoSilverBullet.pdf"><em>Essential Complexity</em></a>. Did all the complexity
in Next exist only to justify <strong>making me feel productive</strong>?</p>
<p>I started wondering what really was so essentially complex about what I needed
to do, but it didn't take long to put a list of the things that seemed the most
independent from each other:</p>
<ul>
<li>I'd like my Markdown files to be compiled into their corresponding HTML
files, respecting their existing structure</li>
<li>I'd like them to be optionally templated, to share some framing information</li>
<li>I'd like to only do work that needs to be done</li>
<li>I'd like my files to be served in a browser fast, and</li>
<li>I'd like my files to be updated automatically in the browser</li>
</ul>
<p>There were them. 5 requirements that this problem could be broken into.  It
shouldn't take more than a couple of days to explore each one of them in enough
depth to understand whether I was looking at massive Essential Complexity, or
not.</p>
<p>I decided to build this tool.</p>
<h4>1. Compiling Markdown to HTML</h4>
<p><a href="https://daringfireball.net/2004/03/introducing_markdown">Markdown</a> was introduced as a more humane way to write HTML. It has
evolved from a rather moving target of inconsistent syntaxes into a series of
standards, some describing a fairly complex format with plenty of features.</p>
<p>To build a Markdown to HTML compiler I'd have to be clear about <em>which</em>
Markdown format I'd be supporting. Since my content was currently written
mostly following <a href="https://github.github.com/gfm">Github Flavored Markdown</a>, that
seemed like the Markdown to target.</p>
<p>Every compiler has a series of stages that take the initial source code, or a
similar specification of a program, and turns into another language. Some
compilers turn this source code into machine language, some others just turn it
into another high-level language.</p>
<p>Whichever your target is, chances are the compiler will read some binary
strings (sometimes this is just UTF-8 text, sometimes its actual binary encoded
data), and transform them into something that it can operate on. Then it
proceeds to transform these data structures into something that more closely
resembles the desired output, maybe making some checks along the way.</p>
<p>In my case, I designed it to have 3 stages:</p>
<ul>
<li>Parsing of Markdown text — a parsing phase would require a Markdown
parser that would deal with the quirks of GFM, and the CommonMark spec it
builds on.</li>
<li>Transformation between Markdown structures and an HTML tree — this
would take data structures like <code>Paragraph { content: String }</code> or <code>List { elements: Vec&lt;ListElement&gt; }</code> and turn them into the appropriate HTML tree.</li>
<li>Writing out the HTML tree — which would take an <code>DomNode { tag: DomTag, attributes: Vec&lt;DomAttribute&gt;, children: Vec&lt;DomNode&gt; }</code> and turn it into a
String that can be written into a file.</li>
</ul>
<p>You can imagine some scaffolded code for this to look like:</p>
<pre><code>enum MarkdownNode {
  Heading1(Vec&lt;MarkdownNode&gt;), // corresponding to a #
  Heading2(Vec&lt;MarkdownNode&gt;), // corresponding to a ##
  Blockquote(Vec&lt;MarkdownNode&gt;), // corresponding to series of &gt;
  // ...
}

struct MarkdownDoc { nodes: Vec&lt;MarkdownNode&gt; }

enum HtmlTag { P, H1, /* ... */ }
struct HtmlAttribute { key: String, value: String }
enum HtmlNode {
  Tagged { 
    tag: HtmlTag,
    attributes: Option&lt;Vec&lt;HtmlAttribute&gt;&gt;,
    children: Option&lt;Vec&lt;HtmlNode&gt;&gt;
  },
  Literal {
    child: String
  }
}

fn string_to_markdown(input: String) -&gt; Result&lt;MarkdownNode, Error&gt; {}

fn markdown_to_html(md: MarkdownDoc) -&gt; Result&lt;HtmlNode, Error&gt; {}

fn html_to_string(html: HtmlNode) -&gt; String {}
</code></pre>
<p>It took me about an hour of reading the specification to realize that
implementing a parser for the entire syntax would easily take me over a week,
and I don't have that kind of time. It would likely be a very error prone
process as well.</p>
<p>A very fun thing to work on, for sure, but after understanding this specific
problem better, I can <em>tolerate</em> the complexity of bringing in a 3rd party
Markdown compiler into the table.</p>
<h4>2. Templating</h4>
<p>Templating can take many shapes and forms. From full blown programming language
support in the style of <a href="https://www.stuartellis.name/articles/erb">ERB (Embedded RuBy)</a>, to string
matching and replacing in more mundane forms.</p>
<p>Considering I do not need to perform any specific logic, my templating needs
are closer to a string-matching followed by some splitting and joining.</p>
<p>I have a <code>template.html</code> file that somewhere in the middle has a keyword that I
want replaced with the actual content of the essay I'm writing.</p>
<p>In pseudocode, this should be enough to achieve my goal:</p>
<pre><code>do_template(template, content) do
  [before, after] = template.split_at_word("$$document")
  return [before, content, after]
end
</code></pre>
<p>How exactly we are finding the word to be replaced by the content is less
important, but from the vast bibliography out there I keep a copy of <a href="https://users.dcc.uchile.cl/~gnavarro/FPMbook">Flexible
Pattern Matching in Strings</a> that is a good resource to
implement some of these algorithms.</p>
<p>Once you know where to split the template to inject your content, the rest is
just string concatenation.</p>
<p>Thankfully, modern programming languages excel at providing us with string
manipulation tools, so putting it together took almost as much code as the
pseudocode:</p>
<pre><code>// assume content and template are strings already
let compiled = template.replace("$$document", content);
</code></pre>
<p>For my use-case, the complexity of having an entire incrementally-rendering
component framework like React, to reuse components across pages that would
achieve the same effect, is simply <strong>not tolerable</strong>.</p>
<h4>3. Only doing work that needs to be done</h4>
<p>A lot of the tools we work with do the same thing over and over again.
Sometimes that is okay. Sometimes that is mandatory.</p>
<p>For my use-case, because I'd like to keep the output of the compilation
versioned, the compilation process should only redo the work that needs to be
done.</p>
<p>This has the side-benefit that recompiling these documents should be relatively
fast, since I tend to work on a single document at a time. Occasionally a
change in a template file would trigger only the recompilation of the documents
using it, …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html">https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html</a></em></p>]]>
            </description>
            <link>https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048078</guid>
            <pubDate>Tue, 04 Aug 2020 09:04:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hydroxychloroquine Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24047806">thread link</a>) | @wensheng
<br/>
August 4, 2020 | https://truthabouthcq.com/hcq-works/ | <a href="https://web.archive.org/web/*/https://truthabouthcq.com/hcq-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="div_block-37-17"><p><span id="span-39-17"> <p>"I do not know Trump or Bolsonaro," <a rel="noreferrer noopener" href="http://covexit.com/shock-testimony-of-professor-raoult-at-french-national-assembly/" target="_blank">said</a> Didier Raoult, a professor of infectious diseases at the IHU-Marseille, on 24 June, the French National Assembly, when provided a testimonial for a special commission.</p> <p>There I saw that the teacher has already started to understand the hole that got involved and who were responsible for creating the first wave that fucked him.</p> <p>This wave, after all, placed him, by chance, as an important piece at the center of the chessboard of the most ferocious geopolitical dispute since the end of the Soviet Union.</p> <p>In addition to the denial of knowing Trump or Bolsonaro, which is quite fun, where Raoult tried to distance himself from these two demented leaders, the infectologist reported serious things: he suffered <a rel="noreferrer noopener" href="http://covexit.com/shock-testimony-of-professor-raoult-at-french-national-assembly/" target="_blank">death threats</a> soon after proposing the treatment of COVID-19 with hydroxychloroquine and azithromycin, two cheap and generic drugs.</p> <p>The doctor behind the threats was found. It’s from a university hospital in Nantes. Incidentally, he was the person who <a rel="noreferrer noopener" href="http://covexit.com/shock-testimony-of-professor-raoult-at-french-national-assembly/" target="_blank">received the</a> most money from Gilead, a large pharmaceutical company, in the past 6 years.</p> <p>Here I propose to put together, piece by piece, the puzzle of what I consider the biggest farce in modern history. I don’t worry about producing a short text. It will have analyzes, including new ones, and from different points of view.</p> <p>It involves science, healing, politics, geopolitics, mass and group psychology. With the scenario set, it is not difficult to predict good and bad things that will happen in the coming months and years.</p> <p>Throughout the text, the reader will understand the most important thing: the circumstance of how this false narrative was put together. The reader will also be prompted, by itself, to conclude whether the treatment proposed by Didier Raout works or not.</p> <p>And you will also understand how the majority of the North American scientific class, from Latin America and Europe, regions of the globe under strong influence from the USA, were directed to an incredibly gross error.</p> <p>In addition to the facts and figures, which are accompanied by external links, all I write are my own opinions, based on the facts, in first person, from my point of view, of how I see the world going completely insane in front of me.</p> <p>I am not afraid to sign my name when publishing it, even though I know that the almost unanimity of Brazilian scientists are against the application of these drugs and repeat that “there is no scientific evidence” of the functioning.</p> <p>And one thing I’m sure will attract attention. The fact that I have to give examples with incredibly basic logic, as if I were talking to children, to explain the facts. It is necessary. The farce has gone so far that I need many examples and analogies to bring reason back.</p> <p>Signed, I make it available to cover me, today or in the future, if my analyzes prove to be incorrect, after all, it is not a simple or light claim.</p> <h2>In February there is carnival</h2> <figure><img src="https://truthabouthcq.com/wp-content/uploads/2020/08/1_SW5PoDNYiufb9qKtgEEqBA.jpeg" alt="china and europe" srcset="https://truthabouthcq.com/wp-content/uploads/2020/08/1_SW5PoDNYiufb9qKtgEEqBA.jpeg 1000w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_SW5PoDNYiufb9qKtgEEqBA-300x200.jpeg 300w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_SW5PoDNYiufb9qKtgEEqBA-768x512.jpeg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure> <p>From China and Europe came reports of large numbers of dead people and entire cities blocked, with people in confinement, preventing the transmission of the coronavirus.</p> <p>On the top street of my house, in Atibaia, in the interior of São Paulo, 60 km from the state capital, the carnival took place.</p> <p>For four days, loud music came through my window. I didn’t go to the party, which I do every year. The word agglomeration already bothered me.</p> <p>It was the end of February, just before the WHO — World Health Organization, declared that <a rel="noreferrer noopener" href="https://brasil.elpais.com/sociedade/2020-03-11/oms-declara-que-coronavirus-e-uma-pandemia-global.html" target="_blank">we were in a global pandemic</a> of apocalyptic proportions.</p> <p>I preferred to go ahead and follow the guidance of scientists before government decisions. I was the first in the city to join voluntary confinement.</p> <p>A few days later I still went to a bar. I thought the risk was low. In airy environments, the risk is less. It was the last time I went to one. It was an open bar, something normal in our tropical climate, where half the people are on the street and the other half inside the establishment.</p> <p>It was the farewell of a musician friend. Samba and jazz were in the repertoire. He was already hired to go to Australia, where he would board a tourist ship. It would be one of the attractions. He was excited. I didn’t want to discourage him, but it was strange that the company was still confident, until that day, that new trips would come out, even with the Diamond Princess <a rel="noreferrer noopener" href="https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_no_navio_Diamond_Princess" target="_blank">case</a>, off the coast of Japan.</p> <p>I no longer held hands to greet anyone. I ran away from close contacts, always stayed outside, and washed my hands constantly. They laughed and found it strange. Some called me paranoid.</p> <p>I soon made a bad prediction: that all bars would be empty and closed in a short space of time. I decided not to leave anymore. I didn’t want to be bothered by crowds. I didn’t want to be a joke either. Our state and municipal governments had not yet taken action against the virus.</p> <p>At home, it remained to read, to follow the news and scientific publications that began to appear frequently. I have a habit, healthy or not, of going deeper into research, and reading studies, when I’m interested in a subject. I don’t like to just wait and see, one or the other news, superficially, in the mass media.</p> <p>The craze for going to medical research sites to read papers came from a few years earlier. In 2016 I broke a bone in an accident. Practically three months lying, with little mobility, without drinking, and with an IPAD in my hand, I read all the studies on my recovery, to the point that, in a chat, shortly afterwards, with an orthopedist professor at an important medical school, he says he has never seen a patient know so much about his problem. “This one studied more than my students”, he joked with a friend.</p> <h2>Piece 1: the hydroxychloroquine solution appears</h2> <p>March 17, 2020</p> <p><a rel="noreferrer noopener" href="https://www.mediterranee-infection.com/wp-content/uploads/2020/03/Hydroxychloroquine_final_DOI_IJAA.pdf" target="_blank">The study ran the internet.</a> He had this impressive chart. People who took hydroxychloroquine with azithromycin, an antibiotic, made a spectacular and rapid recovery.</p> <figure><img src="https://truthabouthcq.com/wp-content/uploads/2020/08/1_tRu6o_eP9Nhtb0Qk_DxkoQ.jpg" alt="hydroxychloroquine with azithromycin results" srcset="https://truthabouthcq.com/wp-content/uploads/2020/08/1_tRu6o_eP9Nhtb0Qk_DxkoQ.jpg 893w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_tRu6o_eP9Nhtb0Qk_DxkoQ-300x160.jpg 300w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_tRu6o_eP9Nhtb0Qk_DxkoQ-768x410.jpg 768w" sizes="(max-width: 893px) 100vw, 893px"><figcaption>Study graph.</figcaption></figure> <p>By the fifth day, the six patients who received the combination no longer had the virus. The news was so good that I went to find out where it came from.</p> <p>The differences between the other two arms, control and those who only took hydroxychloroquine, were great.</p> <p>They didn’t even wait to finish. On the sixth day they already released these preliminary data.</p> <p>Several scientists signed the study, but the main one was Didier Raoult, from Marseille, in the south of France. I went to research and soon saw that he was not just any adventurer.</p> <h2>Piece 2: Didier Raoult is the leading specialist in communicable diseases in the world</h2> <figure><img src="https://truthabouthcq.com/wp-content/uploads/2020/08/1_MWN7NMuqGJt2kJlOqcRXOQ-1024x576.jpeg" alt="didier raoult - hydroxychloroquine researcher" srcset="https://truthabouthcq.com/wp-content/uploads/2020/08/1_MWN7NMuqGJt2kJlOqcRXOQ-1024x576.jpeg 1024w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_MWN7NMuqGJt2kJlOqcRXOQ-300x169.jpeg 300w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_MWN7NMuqGJt2kJlOqcRXOQ-768x432.jpeg 768w, https://truthabouthcq.com/wp-content/uploads/2020/08/1_MWN7NMuqGJt2kJlOqcRXOQ.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure> <p>Didier has almost <a rel="noreferrer noopener" href="https://www.ncbi.nlm.nih.gov/pubmed?term=%22Raoult%20D%22%5BAuthor%5D" target="_blank">3,000 articles</a> in Pubmed. This is a resounding number.</p> <p>According to the Expertscape website, which makes a <a rel="noreferrer noopener" href="http://expertscape.com/ex/communicable+diseases" target="_blank">statistic</a> &nbsp;about studies published in the last 10 years by specialty, he is number one in the world in communicable diseases.</p> <p>In addition, he won several awards in his scientific community, such as that of the National Institute of Health and Medical Research, in <a rel="noreferrer noopener" href="https://histoire.inserm.fr/de-l-inh-a-l-inserm/les-prix-inserm/prix-2010" target="_blank">2010</a>, and that of the Institute of France, in <a rel="noreferrer noopener" href="http://grands-prix.institut-de-france.fr/didier-raoult" target="_blank">2015</a>.</p> <p>This second prize is not just any prize, like those in cities in the interior that hold contests on the internet for the most sympathetic doctors in public service. It is a cash prize. He took 200 thousand Euros home. This is more than one million reais.</p> <p>Professor Didier Raoult also received decorations from the French government. He is, since 2015, commander of the National Order of Merit, and since 2011, Officer of the Legion of Honor. One of them is awarded by the President of the Republic of the country. And we all know that France is not a banana republic. They don’t reward imbeciles.</p> <p>With a brilliant career like this, I decided to keep following. The results were too encouraging to pass up.</p> <h2>Piece 3: the world’s second worst ally liked the idea</h2> <figure><div> <blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">HYDROXYCHLOROQUINE &amp; AZITHROMYCIN, taken together, have a real chance to be one of the biggest game changers in the history of medicine. The FDA has moved mountains - Thank You! Hopefully they will BOTH (H works better with A, International Journal of Antimicrobial Agents).....</p>— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1241367239900778501?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">March 21, 2020</a></blockquote> </div></figure> <p><strong>March 21st</strong></p> <p>Donald Trump, the president of the United States, is anything but simple. Four days after publication, he went on TV and used Didier Raoult’s study as a confrontation with American scientists. They spared no <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/04/28/climate/trump-coronavirus-climate-science.html" target="_blank">criticism</a> for their stupidity in conducting the pandemic.</p> <p>He always hit them head on. Trump is a blundering rotary machine gun. Just to give two examples, on the pandemic, he had <a rel="noreferrer noopener" href="https://news.yahoo.com/coronavirus-trump-flu-deaths-tweet-think-about-that-162332056.html" target="_blank">said that the</a> common&nbsp; <a rel="noreferrer noopener" href="https://news.yahoo.com/coronavirus-trump-flu-deaths-tweet-think-about-that-162332056.html" target="_blank">flu</a> was worse. And it unbelievably went so far as to say that the coronavirus was a <a rel="noreferrer noopener" href="https://www.cnbc.com/2020/02/28/trump-says-the-coronavirus-is-the-democrats-new-hoax.html%20Trump%20diz%20que%20o%20coronav%C3%ADrus%20%C3%A9%20a%20%E2%80%98nova%20farsa%E2%80%99%20dos%20democratas" target="_blank">farce</a> from the Democratic party.</p> <p>His track record has always been to nurture disdain for science and scientists. He says, for example, that he <a rel="noreferrer noopener" href="https://brasil.elpais.com/brasil/2018/11/27/internacional/1543283242_634443.html" target="_blank">doesn’t believe</a> in global warming.</p> <p>But one thing Trump has always known: his policy of confrontation pleases his <a rel="noreferrer noopener" href="https://noticias.uol.com.br/internacional/ultimas-noticias/2020/03/16/por-coronavirus-populacao-dos-eua-faz-fila-para-comprar-armas-e-municao.htm" target="_blank">stupid</a>, increasingly radicalized base, which in order to defend itself against the coronavirus, instead of avoiding agglomerations, is lining up to buy weapons.</p> <p>How can someone who acts and thinks in this way guide how the solution to a pandemic should be?</p> <p>Of course, the North American scientific community felt neglected, and with the clash, diminished. They reacted.</p> <h2>Piece 4: hydroxychloroquine’s first misfortune</h2> <p>In his ad, Trump spoke the name of the drug. And hydroxychloroquine, unfortunately, did not need a doctor’s prescription.</p> <p>What happened? A <a rel="noreferrer noopener" href="https://www1.folha.uol.com.br/equilibrioesaude/2020/03/declaracao-de-trump-cria-corrida-por-hidroxicloroquina-em-farmacias-de-washington.shtml" target="_blank">rush to the pharmacies</a>. Nothing surprising.</p> <p>Experts were consulted. They said an obviousness that anyone would say seeing the people stocking up on medicines. They warned that everyone should be careful with <a rel="noreferrer noopener" href="https://www.nbcnews.com/politics/donald-trump/mayo-clinic-cardiologist-inexcusable-ignore-hydroxychloroquine-side-effects-n1178776" target="_blank">side effects</a>.</p> <p>Following, honest journalism, which I would also do. They went to see if Trump had connections with the hydroxychloroquine manufacturers. They found out he <a rel="noreferrer noopener" href="https://noticias.uol.com.br/internacional/ultimas-noticias/2020/04/07/defensor-da-cloroquina-trump-tem-participacao-em-fabricante-do-medicamento.htm" target="_blank">had it</a>.</p> <p>Thus a narrative began to be put together.</p> <h2>Piece 5: US scientists call for calm</h2> <p>Didier Raoult’s study was preliminary. The focus was, at that time, on the six patients treated with hydroxychloroquine and …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://truthabouthcq.com/hcq-works/">https://truthabouthcq.com/hcq-works/</a></em></p>]]>
            </description>
            <link>https://truthabouthcq.com/hcq-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047806</guid>
            <pubDate>Tue, 04 Aug 2020 08:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipshape RenderMan Art Challenge]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24047731">thread link</a>) | @mariuz
<br/>
August 4, 2020 | https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html | <a href="https://web.archive.org/web/*/https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 31, 2020 
                 | Tags: 
                     
                        Art
                      
                </span>

            <section>
                <div>

  <p>Last year, I <a href="https://blog.yiningkarlli.com/2019/11/woodville-renderman-challenge.html">participated in one of Pixar’s RenderMan Art Challenges</a> as a way to learn more about RenderMan <a href="https://dl.acm.org/citation.cfm?id=3182162">(Christensen et al. 2018)</a> and as a way to get some exposure to tools outside of my normal day-to-day toolset (Disney’s Hyperion Renderer professionally, Takua Render as a hobby and learning exercise).
I had a lot of fun, and wound up doing better in the “Woodville” art challenge contest than I expected to!
Recently, I entered another one of <a href="https://renderman.pixar.com/news/renderman-shipshape-art-challenge">Pixar’s RenderMan Art Challenges, “Shipshape”</a>.
This time around I entered just for fun; since I had so much fun last time, I figured why not give it another shot!
That being said though, I want to repeat the main point I made in my post about the previous “Woodville” art challenge: I believe that for rendering engineers, there is enormous value in learning to use tools and renderers that aren’t the ones we work on ourselves.
Our field is filled with brilliant people on every major rendering team, and I find both a lot of useful information/ideas and a lot of joy in seeing the work that friends and peers across the field have put into commercial renderers such as RenderMan, Arnold, Vray, Corona, and others.</p>

  <p>As usual for the RenderMan Art Challenges, Pixar <a href="https://renderman.pixar.com/shipshape-pup-asset">supplied some base models</a> without any uvs, texturing, shading, lighting or anything else, and challenge participants had to start with the base models and come up with a single compelling image for a final entry.
I had a lot of fun spending evenings and weekends throughout the duration of the contest to create my final image, which is below.
I got to explore and learn a lot of new things that I haven’t tried before, which this post will go through.
To my enormous surprise, this time around my entry <a href="https://renderman.pixar.com/news/renderman-shipshape-art-challenge-final-results">won first place in the contest</a>!</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/shipshape_full_4k.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/shipshape_full.jpg" alt="Figure 1: My entry to Pixar's RenderMan Shipshape Art Challenge, titled &quot;Oh Good, The Bus is Here&quot;. Click for 4K version. Base ship, robot, and sextant models are from Pixar; all shading, lighting, additional modeling, and environments are mine. Ship concept by Ian McQue. Robot concept by Ruslan Safarov. Models by Cheyenne Chapel, Aliya Chen, Damian Kwiatkowski, Alyssa Minko, Anthony Muscarella, and Miguel Zozaya © Disney / Pixar - RenderMan &quot;Shipshape&quot; Art Challenge."></a></p>

  <p><strong>Initial Explorations</strong></p>

  <p>For this competition, Pixar provided five models: a futuristic scifi ship based on an Ian McQue concept, a robot based on a Ruslan Safarov concept, an old wooden boat, a butterfly, and a sextant.
The fact that one of the models was based on an Ian McQue concept was enough to draw me in; I’ve been a big fan of Ian McQue’s work for many years now!
I like to start these challenges by just rendering the provided assets as-is from a number of different angles, to try to get a sense of what I like about the assets and how I will want to showcase them in my final piece.
I settled pretty quickly on wanting to focus on the scifi ship and the robot, and leave the other three models aside.
I did find an opportunity to bring in the sextant in my final piece as well, but wound up dropping the old wooden boat and the butterfly altogether.
Here are some simple renders showing what was provided out of the box for the scifi ship and the robot:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/scifiship_base.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/scifiship_base.jpg" alt="Figure 2: Scifi ship base model provided by Pixar, rendered against a white cyclorama background using a basic skydome."></a></p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/robot_base.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/robot_base.jpg" alt="Figure 3: Robot base model provided by Pixar, rendered against a white cyclorama background using a basic skydome."></a></p>

  <p>I initially had a lot of trouble settling on a concept and idea for this project; I actually started blocking out an entirely different idea before pivoting to the idea that eventually became my final image.
My initial concept included the old wooden boat in addition the scifi ship and the robot; this initial concept was called “River Explorer”.
My initial instinct was to try to show the scifi ship from a top-down view, in order to get a better view of the deck-boards and the big VG engine and the crane arm.
I liked the idea of putting the camera at roughly forest canopy height, since forest canopy height is a bit of an unusual perspective for most photographs due to canopy height being this weird height that is too high off the ground for people to shoot from, but too low for helicopters or drones to be practical either.
My initial idea was about a robot-piloted flying patrol boat exploring an old forgotten river in a forest; the ship would be approaching the old sunken boat in the river water.
With this first concept, I got as far as initial compositional blocking and initial time-of-day lighting tests:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_012.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/progress_012.jpg" alt="Figure 4: Initial &quot;River Explorer&quot; concept, daylight lighting test."></a></p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_013.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/progress_013.jpg" alt="Figure 5: Initial &quot;River Explorer&quot; concept, dusk lighting test."></a></p>

  <p>If you’ve followed my blog for a while now, those pine trees might look familiar.
They’re actually the same trees from <a href="https://blog.yiningkarlli.com/2018/10/bidirectional-mipmap.html">the forest scene I used a while back</a>, ported from Takua’s shading system to RenderMan’s PxrSurface shader.</p>

  <p>I wasn’t ever super happy with the “River Explorer” concept; I think the overall layout was okay, but it lacked a sense of dynamism and overall just felt very static to me, and the robot on the flying scifi ship felt kind of lost in the overall composition.
Several other contestants wound up also going for similar top-down-ish views, which made me worry about getting lost in a crowd of similar-looking images.
After a week of trying to get the “River Explorer” concept to work better, I started to play with some completely different ideas; I figured that this early in the process, a better idea was worth more than a week’s worth of sunk time.</p>

  <p><strong>Layout and Framing</strong></p>

  <p>I had started UV unwrapping the ship already, and whilst tumbling around the ship unwrapping all of the components one-by-one, I got to see a lot more of the ship and a lot more interesting angles, and I suddenly came up with a completely different idea for my entry.
The idea that popped into my head was to have a bunch of the little robots waiting to board one of the flying ships at a quay or something of the sort.
I wanted to convey a sense of scale between the robots and the flying scifi ship, so I tried putting the camera far away and zooming in using a really long lens.
Since long lenses have the effect of flattening perspective a bit, using a long lens helped make the ships feel huge compared to the robots.
At this point I was just doing very rough, quick, AO render “sketches”.
This is the AO sketch where my eventual final idea started:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_015.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_015.jpg" alt="Figure 6: Rough AO render &quot;sketch&quot; that eventually evolved into my final idea."></a></p>

  <p>I’ve always loved the idea of the mundane fantastical; the flying scifi ship model is fairly fantastical, which led me to want to do something more everyday with them.
I thought it would be fun to texture the scifi ship model as if it was just part of a regular metro system that the robots use to get around their world.
My wife, Harmony, suggested a fun idea: set the entire scene in drizzly weather and give two of the robots umbrellas, but give the third robot a briefcase instead and have the robot use the briefcase as a makeshift umbrella, as if it had forgotten its umbrella at home.
The umbrella-less robot’s reaction to seeing the ship arriving provided the title for my entry- “Oh Good, The Bus Is Here”.
Harmony also pointed out that the back of the ship has a lot more interesting geometric detail compared to the front of the ship, and suggested placing the focus of the composition more on the robots than on the ships.
To incorporate all of these ideas, I played more with the layout and framing until I arrived at the following image, which is broadly the final layout I used:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_019.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_019.jpg" alt="Figure 7: Rough AO render &quot;sketch&quot; of my final layout."></a></p>

  <p>I chose to put an additional ship in the background flying away from the dock for two main reasons.
First, I wanted to be able to showcase more of the ship, since the front ship is mostly obscured by the foreground dock.
Second, the background ship helps fill out and balance the right side of the frame more, which would otherwise have been kind of empty.</p>

  <p>In both this project and in the previous Art Challenge, my workflow for assembling the final scene relies heavily on Maya’s referencing capabilities.
Each separate asset is kept in its own .ma file, and all of the .ma files are referenced into the main scene file.
The only the things the main scene file contains are references to assets, along with scene-level lighting, overrides, and global-scale effects such as volumes and, in the case of this challenge, the rain streaks.
So, even though the flying scifi ship appears in my scene twice, it is actually just the same .ma file referenced into the main scene twice instead of two separate ships.</p>

  <p>The idea of a rainy scene largely drove the later lighting direction of my entry; from this point I basically knew that the final scene was going to have to be overcast and drizzly, with a heavy reliance on volumes to add depth separation into the scene and to bring out practical lights on the ships.
I had a lot of fun modeling out the dock and gangway, and may have gotten slightly carried away.
I modeled every single bolt and rivet that you would expect to be there in real life, and I also added lampposts to use later as practical light sources for illuminating the dock and the robots.
Once I had finished modeling the dock and had made a few more layout tweaks, I arrived at a point where I was happy to start with shading and initial light blocking.
Zoom in if you want to see all of the rivets and bolts and stuff on the dock:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_032.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_032.jpg" alt="Figure 8: AO render of my layout going into shading and lighting. Check out all of the crazy detail on the dock that I modeled!"></a></p>

  <p><strong>UV Unwrapping</strong></p>

  <p>UV unwrapping the ship took a ton of time.
For the last challenge, I relied on a combination of manual UV unwrapping by hand in Maya and using <a href="https://www.sidefx.com/tutorials/houdini-game-dev-tools-auto-uvs/">Houdini’s Auto UV SOP</a>, but I found that the Auto UV SOP didn’t work as well on this challenge due to the ship and robot having a lot of strange geometry with really complex topology.
On the treehouse in the last challenge, everything was more or less some version of a cylinder or a rectangular prism, with some morphs and warps and extra bits and bobs applied.
Almost every piece of the ship aside from the floorboards are very complex shapes that aren’t easy to find good seams for, so the Auto UV SOP wound up making a lot of choices for UV cuts that I didn’t like.
As a result, I basically manually UV unwrapped this entire challenge in Maya.</p>

  <p>A lot of the complex undercarriage type stuff around the back thrusters on the ship was really insane to unwrap.
The muffler manifold and mechanical parts of the crane arm were difficult too.
Fortunately though, the models came with subdivision creases, and a lot of the subd crease tags wound up proving to be useful hints towards good places to place UV edge cuts.
I also found …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html">https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html</a></em></p>]]>
            </description>
            <link>https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047731</guid>
            <pubDate>Tue, 04 Aug 2020 08:02:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The best Parts of Visual Studio Code are proprietary]]>
            </title>
            <description>
<![CDATA[
Score 418 | Comments 263 (<a href="https://news.ycombinator.com/item?id=24047638">thread link</a>) | @ingve
<br/>
August 4, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047638</guid>
            <pubDate>Tue, 04 Aug 2020 07:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test-First Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24047573">thread link</a>) | @frag
<br/>
August 4, 2020 | https://codingossip.github.io/2020/test-first-machine-learning/ | <a href="https://web.archive.org/web/*/https://codingossip.github.io/2020/test-first-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p><img src="https://codingossip.github.io/assets/images/testing.jpg" alt=""></p> <p>Testing software is one of the most complex tasks in software engineering. While in traditional software engineering there are principles that define in a non-ambiguous way how software should be tested, the same does not hold for machine learning, where testing strategies are not always defined. In this post, I elucidate a testing approach that is not only highly influenced by one of the most recognized testing strategies in software engineering - that is test-driven development. But also seems to be an approach that is agnostic from the family of machine learning models under testing, and adapts very well to the typical production environments that lead to the large scale AI/ML services of today.</p> <p>After reading this post, you will learn how to set up a testing strategy that works for machine learning models with production in mind. <em>Production in mind</em> means that the team you are operating in is heterogeneous, the project under testing is developed together with other data scientists, data engineers, business customers, developers, and testers. The goals of a good testing strategy are to achieve production readiness and improve code maintainability.</p> <p>An appropriate name of the approach is <em>Test-First</em> machine learning, in short TFML, because everything starts from writing tests, rather than models.</p> <h2 id="steps-of-tfml">Steps of TFML</h2> <p>A characteristic of TFML is to start from writing tests, instead of machine learning models. The approach is based on mocking whatever is not yet available so that different actors involved in the project can proceed with their tasks anyway. It is known that data scientists and data engineers run at a different pace. Mocking a particular aspect of the world that is not yet available not only mitigates such difference but also reduces blockers within larger teams. This, in turn, increases efficiency. Below are the five essential steps of a TFML approach.</p> <h3 id="1-write-a-test">1. Write a test</h3> <p>As the name suggests, Test-First in TFML indicates that everything starts with writing a test. Even for a feature that does not yet exist. Such a test is usually very short and should stay so. Larger and more complex tests should be broken down to their essential and testable components. A test can be written after understanding the feature’s specs and requirements that are usually discussed earlier during requirement analysis (e.g. use cases and user stories).</p> <h3 id="2-validate-a-test">2. Validate a test</h3> <p>A working test will fail or pass for the right reasons. This is the step in which such reasons are defined. Defining the happy path is essential to defining what should be observed and considered a success.</p> <h3 id="3-write-the-code">3. Write the code</h3> <p>In this step, the code that leads to the happy path is actually written. This code will cause the test to pass. No other code, beyond the test’s happy path, should be provided. For example, if a machine learning model is expected to return 42, one can just return 42 and force the test to succeed here. If time constraints are needed, adding <code>sleep(milliseconds)</code> is also acceptable. Such mocked values will provide engineers with visible constraints such that they can proceed with their tasks as if the model was complete and working.</p> <h3 id="4-run-tests">4. Run tests</h3> <p>Adding new tests should never break the previous ones. Having tests that depend on each other is considered an anti-pattern in software engineering.</p> <h3 id="5-add-functionality--cleanup--refactor">5. Add functionality (+ cleanup + refactor)</h3> <p>When values are mocked, success conditions are defined and tests are running, it’s time to show that the ML model under testing is training and performing predictions. Related to the example above, some questions that should find an answer in this step are:</p> <ul> <li>Is the test breaking the constraints we set previously?</li> <li>Is our ML model returning 84 rather than 42?</li> <li>How about time constraints?</li> </ul> <p>Traditionally, in this step developers perform code cleanup, deduplication, and refactoring (whenever it applies), to improve both readability and maintainability. This strategy should be applied to ML developers too.</p> <hr> <p>Falling in the trap of <em>alternative</em> approaches is easier in machine learning due to its nature and the enthusiasm of data scientists who <code>connect-train-analyze</code> data in no time.</p> <p>The most common approach in the data science community is probably the <em>Test-Last</em> approach a.k.a. <em>code now, test later</em>. This approach can be extremely risky in ML model development, since even for a trivial linear regression there might be just too many moving parts, compared with traditional software (e.g. UI, API calls, data streams, databases, preprocessing steps, etc.) As a matter of fact, the <strong>Test-First</strong> approach encourages and forces developers to put the minimum amount of code into modules depending on such moving parts (e.g. UIs and databases) and to implement the logic that should belong to the testable section of the codebase.</p> <p>One important pitfall to avoid is <em>developer bias</em>. Tests created in a Test-First environment are usually created by the same developer who is writing the code being tested. This can be a problem e.g. if a developer does not consider certain input parameters to be checked. In that case, neither the test nor the code will verify such parameters. There is a reason why in traditional software development, testing engineers and developers are usually not the same individuals.</p> <h2 id="tfml-anti-patterns">TFML anti-patterns</h2> <p>Below are some anti-patterns in TFML.</p> <h3 id="test-dependence">Test dependence</h3> <p>Tests should be standalone. Tests that depend on others can lead to cascading failures or success out of the developer’s control.</p> <h3 id="test-model-precisely">Test model precisely</h3> <p>As in traditional software engineering, testing precise execution behavior, timing or performance can lead to test failure. In machine learning, it is even more important to consider soft constraints because models can be probabilistic. Moreover, the ranges of output variables and input data can change. Such a dynamic and sometimes loosely defined behavior is the norm rather than the exception in ML.</p> <h3 id="test-models-mathematical-details">Test model’s mathematical details</h3> <p>Testing model implementation details such as statistical and mathematical soundness are not part of the TFML strategy. Such details should be tested separately and are specific to the family of the model under consideration.</p> <h3 id="large-testing-unit">Large testing unit</h3> <p>The testing surface should always be minimal for the functionality under test. Keeping the testing unit small gives more control to the developer. Larger testing units should be broken down into smaller tests, specialized in one particular aspect of the models to be tested.</p> <h2 id="conclusion">Conclusion</h2> <p>The TFML approach forces developers to spend initial time defining the testing strategy for their models. This in turn facilitates the integration of such models in the bigger picture of complex engineering systems where larger teams are involved. It has been observed that programmers who write more tests tend to be more productive. Testing code is as important as developing software core functionality. Testing code should be produced and maintained with the same rigor as production code. In ML all this becomes even more critical, due to the heterogeneity of the systems and the people involved in ML projects.</p>  </div> </article>  </div></div>]]>
            </description>
            <link>https://codingossip.github.io/2020/test-first-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047573</guid>
            <pubDate>Tue, 04 Aug 2020 07:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Improve ActiveRecord Query Performance with Subquery Caching]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24047458">thread link</a>) | @todsacerdoti
<br/>
August 4, 2020 | https://pawelurbanek.com/rails-query-caching | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/rails-query-caching">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title=" Photo by Matthew Lancaster on Unsplash" alt=" Photo by Matthew Lancaster on Unsplash" data-src="https://pawelurbanek.com/assets/query-cache-chain-05ff566006ef3610d43639a88f44ef1ce6e5efec1a9649dc3102f316e8806122.jpg" src="https://pawelurbanek.com/assets/query-cache-chain-thumb-58a59b320de63219cb15e4179a9958cd921fff2ed0e4331324c7b6d60cadce36.jpg">
    </p>
  

  

  <p>Slow database queries are a common performance bottleneck for Ruby on Rails apps. Simplifying a complex query is often not possible due to the underlying business logic. Instead, you can extract parts of a query, cache and reuse them to improve performance. In this tutorial, I’ll describe a range of techniques on how to do it.</p>

<p>We will cover more advanced ActiveRecord and PostgreSQL topics like <code>EXPLAIN ANALYZE</code>, and query plan visualizer tool.</p>

<p>Let’s get started!</p>

<h2 id="when-subquery-caching-makes-sense-for-slow-activerecord-queries">When subquery caching makes sense for slow ActiveRecord queries?</h2>

<p>Subquery caching is a bit more convoluted solution for optimizing slow queries. Before you decide to implement it you should double-check if more straightforward fixes could help instead:</p>

<ul>
  <li>add missing database indexes and to avoid inefficient <code>Seq Scan</code> on large collections</li>
  <li>make sure that the database server is adequately scaled and has a decent cache hit rate. You can use <a href="https://github.com/pawurb/rails-pg-extras#cache_hit" target="_blank">RailsPGExtras gem</a> to validate that</li>
  <li>check if PostgreSQL configuration is correct for the type of the database server that you’re using. <a href="https://pgtune.leopard.in.ua/" target="_blank">PGTune</a> is your friend here</li>
  <li>validate that your queries are not locking for too long, e.g., because of <a href="https://pawelurbanek.com/rails-mistakes-downtime#detecting-deadlocks">too wide ActiveRecord transaction scope</a></li>
</ul>

<p>You can read out my other blogpost for an overview of <a href="https://pawelurbanek.com/slow-rails-queries">tips for optimizing slow Rails queries</a>.</p>

<p>If none of the above approaches helps, let’s discuss how you can split slow queries into the reusable parts.</p>

<h2 id="sample-database-structure">Sample database structure</h2>

<p>How to determine which part of a query to cache?</p>

<p>Unfortunately, there’s no simple answer to this question. It’s totally dependent on your application’s logic.</p>

<p>For this tutorial, we will assume the following database structure to explore some common scenarios:</p>

<p><img alt="Sample PostgreSQL database structure" title="Sample PostgreSQL database strucutre" loading="lazy" src="https://pawelurbanek.com/assets/db-structure-for-cache-e7bbfcd8e5d7021b8291218f8b87e6d88dc4ab670a8f15885bb1c23ce57a8b11.png"></p>





<p><code>app/models/user.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:group_assignments</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:groups</span><span>,</span> <span>through: :group_assignments</span>
  <span>has_many</span> <span>:posts</span>
<span>end</span></code></pre></figure>

<p><code>app/models/group.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>Group</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:group_assignments</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:users</span><span>,</span> <span>through: :group_assignments</span>
  <span>has_many</span> <span>:posts</span>
<span>end</span></code></pre></figure>

<p><code>app/models/post.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>Post</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>belongs_to</span> <span>:user</span>
  <span>belongs_to</span> <span>:group</span>

  <span>def</span> <span>to_json</span>
    <span>{</span>
      <span>id: </span><span>id</span><span>,</span>
      <span>text: </span><span>text</span><span>,</span>
      <span>user_email: </span><span>user</span><span>.</span><span>email</span><span>,</span>
      <span>group_name: </span><span>group</span><span>.</span><span>name</span>
    <span>}</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p><code>app/models/group_assignment.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>GroupAssignment</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>self</span><span>.</span><span>table_name</span> <span>=</span> <span>"group_assignments"</span>

  <span>belongs_to</span> <span>:user</span>
  <span>belongs_to</span> <span>:group</span>
<span>end</span></code></pre></figure>

<p><strong>User</strong> can belong to many <strong>Groups</strong> with a different role via the <strong>GroupAssignment</strong> join model. <strong>Posts</strong> are published in a <strong>Group</strong> by a <strong>User</strong>.</p>

<p>Let’s now explore potential slow queries that could originate in a system with similar schema.</p>

<h2 id="analyzing-slow-queries">Analyzing slow queries</h2>

<p>We will focus on optimizing a single controller. It returns not approved posts that were published in groups that a current user is an admin in. It also validates if a user is an admin in at least one group.</p>

<p>A similar complexity level requiring data from four and more tables to execute a single query is common in non-trivial Rails apps.</p>

<p>We’re using <code>eager_load</code> because relation tables are used for both filter query and post’s JSON structure. It ensures that a single query will be executed to fetch and instantiate all the records eliminating N+1 issue. You can check out <a href="https://scoutapm.com/blog/activerecord-includes-vs-joins-vs-preload-vs-eager_load-when-and-where" target="_blank">this blog post</a> for more details on differences between <code>joins</code>, <code>includes</code> and <code>eager_load</code> ActiveRecord methods.</p>

<p><code>app/models/moderation_controller.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>PostsModerationController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:authorize_admin!</span>

  <span>def</span> <span>index</span>
    <span>render</span> <span>json: </span><span>posts_to_moderate</span><span>.</span><span>to_json</span>
  <span>end</span>

  <span>def</span> <span>approve</span>
    <span>post</span> <span>=</span> <span>posts_to_moderate</span><span>.</span><span>find</span><span>(</span>
      <span>params</span><span>.</span><span>fetch</span><span>(</span><span>:id</span><span>)</span>
    <span>)</span>
    <span>post</span><span>.</span><span>approve!</span>

    <span>render</span> <span>json: </span><span>post</span><span>.</span><span>to_json</span>
  <span>end</span>

  <span>private</span>

  <span>def</span> <span>authorize_admin!</span>
    <span>admin_groups</span><span>.</span><span>present?</span> <span>||</span> <span>(</span><span>raise</span> <span>AccessDenied</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>posts_to_moderate</span>
    <span>Post</span><span>.</span><span>joins</span><span>(</span><span>:user</span><span>,</span> <span>:group</span><span>)</span>
    <span>.</span><span>where</span><span>(</span>
      <span>group: </span><span>admin_groups</span><span>,</span>
      <span>approved: </span><span>false</span>
    <span>)</span>
    <span>.</span><span>where</span><span>.</span><span>not</span><span>(</span><span>user: </span><span>current_user</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>admin_groups</span>
    <span>Group</span><span>.</span><span>joins</span><span>(</span><span>:group_assignments</span><span>)</span>
    <span>.</span><span>where</span><span>(</span>
      <span>"role = 'admin' and user_id = ?"</span><span>,</span>
      <span>current_user</span><span>.</span><span>id</span>
    <span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p><code>admin_groups</code> returns a relation object so two queries are merged together. The final query from <code>posts_to_moderate</code> method generates the following SQL:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>"posts"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t0_r0</span><span>,</span> <span>"posts"</span><span>.</span><span>"user_id"</span> <span>AS</span> <span>t0_r1</span><span>,</span> <span>"posts"</span><span>.</span><span>"group_id"</span> <span>AS</span> <span>t0_r2</span><span>,</span> <span>"posts"</span><span>.</span><span>"approved"</span> <span>AS</span> <span>t0_r3</span><span>,</span> <span>"posts"</span><span>.</span><span>"featured"</span> <span>AS</span> <span>t0_r4</span><span>,</span> <span>"posts"</span><span>.</span><span>"text"</span> <span>AS</span> <span>t0_r5</span><span>,</span> <span>"users"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t1_r0</span><span>,</span> <span>"users"</span><span>.</span><span>"email"</span> <span>AS</span> <span>t1_r1</span><span>,</span> <span>"groups"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t2_r0</span><span>,</span> <span>"groups"</span><span>.</span><span>"name"</span> <span>AS</span> <span>t2_r1</span>
<span>FROM</span> <span>"posts"</span>
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>"users"</span> <span>ON</span> <span>"users"</span><span>.</span><span>"id"</span> <span>=</span> <span>"posts"</span><span>.</span><span>"user_id"</span>
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>"groups"</span> <span>ON</span> <span>"groups"</span><span>.</span><span>"id"</span> <span>=</span> <span>"posts"</span><span>.</span><span>"group_id"</span> <span>WHERE</span> <span>"posts"</span><span>.</span><span>"group_id"</span> <span>IN</span> <span>(</span>
  <span>SELECT</span> <span>"groups"</span><span>.</span><span>"id"</span> <span>FROM</span> <span>"groups"</span>
  <span>INNER</span> <span>JOIN</span> <span>"group_assignments"</span> <span>ON</span> <span>"group_assignments"</span><span>.</span><span>"group_id"</span> <span>=</span> <span>"groups"</span><span>.</span><span>"id"</span>
    <span>WHERE</span> <span>(</span><span>role</span> <span>=</span> <span>'admin'</span> <span>and</span> <span>user_id</span> <span>=</span> <span>67478</span><span>)</span>
  <span>)</span>
<span>AND</span> <span>"posts"</span><span>.</span><span>"approved"</span> <span>=</span> <span>FALSE</span> <span>AND</span> <span>"posts"</span><span>.</span><span>"user_id"</span> <span>!=</span> <span>67478</span></code></pre></figure>

<p>and this <code>EXPLAIN</code> output:</p>

<figure><pre><code data-lang="json"><span> </span><span>Nested</span><span> </span><span>Loop</span><span> </span><span>Left</span><span> </span><span>Join</span><span>  </span><span>(cost=</span><span>18.01</span><span>..</span><span>18.24</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>96</span><span>)</span><span>
   </span><span>-&gt;</span><span>  </span><span>Nested</span><span> </span><span>Loop</span><span> </span><span>Left</span><span> </span><span>Join</span><span>  </span><span>(cost=</span><span>17.59</span><span>..</span><span>17.77</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>79</span><span>)</span><span>
         </span><span>-&gt;</span><span>  </span><span>Nested</span><span> </span><span>Loop</span><span>  </span><span>(cost=</span><span>17.17</span><span>..</span><span>17.29</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>50</span><span>)</span><span>
               </span><span>Join</span><span> </span><span>Filter</span><span>:</span><span> </span><span>(posts.group_id</span><span> </span><span>=</span><span> </span><span>group_assignments.group_id)</span><span>
               </span><span>-&gt;</span><span>  </span><span>HashAggregate</span><span>  </span><span>(cost=</span><span>16.75</span><span>..</span><span>16.76</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>12</span><span>)</span><span>
                     </span><span>Group</span><span> </span><span>Key</span><span>:</span><span> </span><span>groups_</span><span>1</span><span>.id</span><span>
                     </span><span>-&gt;</span><span>  </span><span>Nested</span><span> </span><span>Loop</span><span>  </span><span>(cost=</span><span>0.71</span><span>..</span><span>16.75</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>12</span><span>)</span><span>
                           </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>index_group_assignments_on_user_id_and_group_id</span><span> </span><span>on</span><span> </span><span>group_assignments</span><span>  </span><span>(cost=</span><span>0.29</span><span>..</span><span>8.31</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>4</span><span>)</span><span>
                                 </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(user_id</span><span> </span><span>=</span><span> </span><span>67478</span><span>)</span><span>
                                 </span><span>Filter</span><span>:</span><span> </span><span>((role)</span><span>::</span><span>text</span><span> </span><span>=</span><span> </span><span>'admin'</span><span>::</span><span>text)</span><span>
                           </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Only</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>groups_pkey</span><span> </span><span>on</span><span> </span><span>groups</span><span> </span><span>groups_</span><span>1</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>8.44</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>8</span><span>)</span><span>
                                 </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(id</span><span> </span><span>=</span><span> </span><span>group_assignments.group_id)</span><span>
               </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>index_posts_on_group_id</span><span> </span><span>on</span><span> </span><span>posts</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>0.52</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>50</span><span>)</span><span>
                     </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(group_id</span><span> </span><span>=</span><span> </span><span>groups_</span><span>1</span><span>.id)</span><span>
                     </span><span>Filter</span><span>:</span><span> </span><span>((NOT</span><span> </span><span>approved)</span><span> </span><span>AND</span><span> </span><span>(user_id</span><span> </span><span>&lt;&gt;</span><span> </span><span>67478</span><span>))</span><span>
         </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>users_pkey</span><span> </span><span>on</span><span> </span><span>users</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>0.48</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>29</span><span>)</span><span>
               </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(id</span><span> </span><span>=</span><span> </span><span>posts.user_id)</span><span>
   </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>groups_pkey</span><span> </span><span>on</span><span> </span><span>groups</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>0.47</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>17</span><span>)</span><span>
         </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(id</span><span> </span><span>=</span><span> </span><span>posts.group_id)</span></code></pre></figure>

<p>I doubt you want to analyze this output line by line. I'm pasting to for reference to compare with the output after the optimization</p>


<p>You can also analyze your query using a <a href="http://tatiyants.com/pev/#/plans/new" target="_blank">visualizer tool</a>. Check out my <a href="https://pawelurbanek.com/slow-rails-queries">other tutorial</a> for tips on how to do it.</p>

<p><img alt="PostgreSQL EXPLAIN ANALYZE visualizer query plan" title="PostgreSQL EXPLAIN ANALYZE visualizer query plan" loading="lazy" src="https://pawelurbanek.com/assets/visualizer-query-plan-46217140544fdf24208b6f1744776a70c530b3bd0a3e86265c172edc9c413066.png"></p>

<p>All the tests were carried out on a database seeded with ~200k objects in each table.</p>



<p>When analyzing the visualizer plans, it’s always worth noting how many <code>Join</code> operations the query performs. One way to speed up query execution is to limit the number of joins.</p>

<p>BTW all the tools mentioned above are useful if you already know which queries you want to put under the microscope. To discover the actual bottleneck queries in your application, you can use <a href="https://scoutapm.com/" target="_blank">ScoutAPM</a>. First, display the endpoints sorted by % of processing time consumed. Then you can deep dive into analyzing which action spends significant time in the database layer and precisely what queries are the most time-consuming.</p>

<p><img alt="Abot Polls for Slack endpoints performance analyzed with ScoutAPM" title="Abot Polls for Slack endpoints performance analyzed with ScoutAPM" loading="lazy" src="https://pawelurbanek.com/assets/abot-for-slack-endpoints-2bf7132e2d487365652936863347608a5230373293a7319875b3be2f3845c95b.png"></p>




<p>Now that we know how to find and analyze bottleneck queries let’s learn how to split them into more performant and <em>cacheable</em> pieces.</p>



<p>The simplest extraction you can do is to fetch IDs of admin groups and reuse them for both authorization method and posts fetching. You don’t even need the actual group objects. You can read only the join model, significantly reducing the complexity. Just make sure to have all the foreign keys in place. You can read more about ensuring data integrity on the database level in <a href="https://pawelurbanek.com/rails-postgresql-data-integrity">my other blog post</a>.</p>

<p><code>app/models/moderation_controller.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>PostsModerationController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:authorize_admin!</span>

  <span>def</span> <span>index</span>
    <span>render</span> <span>json: </span><span>posts_to_moderate</span><span>.</span><span>to_json</span>
  <span>end</span>

  <span>def</span> <span>approve</span>
    <span>post</span> <span>=</span> <span>posts_to_moderate</span><span>.</span><span>find</span><span>(</span>
      <span>params</span><span>.</span><span>fetch</span><span>(</span><span>:id</span><span>)</span>
    <span>)</span>
    <span>post</span><span>.</span><span>approve!</span>

    <span>render</span> <span>json: </span><span>post</span><span>.</span><span>to_json</span>
  <span>end</span>

  <span>private</span>

  <span>def</span> <span>authorize_admin!</span>
    <span>admin_group_ids</span><span>.</span><span>present?</span> <span>||</span> <span>(</span><span>raise</span> <span>AccessDenied</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>posts_to_moderate</span>
    <span>Post</span><span>.</span><span>joins</span><span>(</span><span>:user</span><span>,</span> <span>:group</span><span>)</span>
    <span>.</span><span>where</span><span>(</span>
      <span>group_id: </span><span>admin_group_ids</span><span>,</span>
      <span>approved: </span><span>false</span>
    <span>).</span><span>where</span><span>.</span><span>not</span><span>(</span><span>user_id: </span><span>current_user</span><span>.</span><span>id</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>admin_group_ids</span>
    <span>@admin_group_ids</span> <span>||=</span> <span>GroupAssignment</span><span>.</span><span>where</span><span>(</span>
      <span>role: </span><span>'admin'</span><span>,</span>
      <span>user_id: </span><span>current_user</span><span>.</span><span>id</span>
    <span>).</span><span>pluck</span><span>(</span><span>:group_id</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>This implementation will still perform two queries like the initial one, but they will be significantly less complex. Results of the query checking admin memberships are reused in posts fetching query, reducing the need for two join operations!</p>

<p>Let’s see how it looks under the <code>EXPLAIN ANALYZE</code> microscope:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>"posts"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t0_r0</span><span>,</span> <span>"posts"</span><span>.</span><span>"user_id"</span> <span>AS</span> <span>t0_r1</span><span>,</span> <span>"posts"</span><span>.</span><span>"group_id"</span> <span>AS</span> <span>t0_r2</span><span>,</span> <span>"posts"</span><span>.</span><span>"approved"</span> <span>AS</span> <span>t0_r3</span><span>,</span> <span>"posts"</span><span>.</span><span>"featured"</span> <span>AS</span> <span>t0_r4</span><span>,</span> <span>"posts"</span><span>.</span><span>"text"</span> <span>AS</span> <span>t0_r5</span><span>,</span> <span>"users"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t1_r0</span><span>,</span> <span>"users"</span><span>.</span><span>"email"</span> <span>AS</span> <span>t1_r1</span><span>,</span> <span>"groups"</span><span>.</span><span>"id"</span> <span>AS</span> <span>t2_r0</span><span>,</span> <span>"groups"</span><span>.</span><span>"name"</span> <span>AS</span> <span>t2_r1</span>
<span>FROM</span> <span>"posts"</span>
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>"users"</span> <span>ON</span> <span>"users"</span><span>.</span><span>"id"</span> <span>=</span> <span>"posts"</span><span>.</span><span>"user_id"</span>
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>"groups"</span> <span>ON</span> <span>"groups"</span><span>.</span><span>"id"</span> <span>=</span> <span>"posts"</span><span>.</span><span>"group_id"</span>
<span>WHERE</span> <span>"posts"</span><span>.</span><span>"group_id"</span> <span>=</span> <span>67478</span> <span>AND</span> <span>"posts"</span><span>.</span><span>"approved"</span> <span>=</span> <span>FALSE</span> <span>AND</span> <span>"posts"</span><span>.</span><span>"user_id"</span> <span>!=</span> <span>67478</span></code></pre></figure>

<figure><pre><code data-lang="json"><span> </span><span>Nested</span><span> </span><span>Loop</span><span> </span><span>Left</span><span> </span><span>Join</span><span>  </span><span>(cost=</span><span>1.26</span><span>..</span><span>25.33</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>96</span><span>)</span><span>
   </span><span>Join</span><span> </span><span>Filter</span><span>:</span><span> </span><span>(groups.id</span><span> </span><span>=</span><span> </span><span>posts.group_id)</span><span>
   </span><span>-&gt;</span><span>  </span><span>Nested</span><span> </span><span>Loop</span><span> </span><span>Left</span><span> </span><span>Join</span><span>  </span><span>(cost=</span><span>0.84</span><span>..</span><span>16.88</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>79</span><span>)</span><span>
         </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>index_posts_on_group_id</span><span> </span><span>on</span><span> </span><span>posts</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>8.44</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>50</span><span>)</span><span>
               </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(group_id</span><span> </span><span>=</span><span> </span><span>67478</span><span>)</span><span>
               </span><span>Filter</span><span>:</span><span> </span><span>((NOT</span><span> </span><span>approved)</span><span> </span><span>AND</span><span> </span><span>(user_id</span><span> </span><span>&lt;&gt;</span><span> </span><span>67478</span><span>))</span><span>
         </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>users_pkey</span><span> </span><span>on</span><span> </span><span>users</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>8.44</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>29</span><span>)</span><span>
               </span><span>Index</span><span> </span><span>Cond</span><span>:</span><span> </span><span>(id</span><span> </span><span>=</span><span> </span><span>posts.user_id)</span><span>
   </span><span>-&gt;</span><span>  </span><span>Index</span><span> </span><span>Scan</span><span> </span><span>using</span><span> </span><span>groups_pkey</span><span> </span><span>on</span><span> </span><span>groups</span><span>  </span><span>(cost=</span><span>0.42</span><span>..</span><span>8.44</span><span> </span><span>rows=</span><span>1</span><span> </span><span>width=</span><span>17</span><span>)</span><span>
       …</span></code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/rails-query-caching">https://pawelurbanek.com/rails-query-caching</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/rails-query-caching</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047458</guid>
            <pubDate>Tue, 04 Aug 2020 07:06:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incrementally Improving the DOM]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24046932">thread link</a>) | @todsacerdoti
<br/>
August 3, 2020 | https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html | <a href="https://web.archive.org/web/*/https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p><a href="http://blog.functorial.com/posts/2018-03-12-You-Might-Not-Need-The-Virtual-DOM.html">Last time</a>, I tried to convince you that you might not need the virtual DOM, and that many common UI patterns can be reproduced with a completely <em>static</em> page, with changes only happening at the leaves of the tree - attributes and text nodes. For some trickier UI patterns, I added back a limited form of dynamic behavior, by allowing elements with dynamic lists of children.</p>
<p>It is perhaps not terribly surprising that this is possible, since it is, after all, what we used to do before React popularized the virtual DOM (using things like Mustache templates).</p>
<p>The static DOM approach has some limitations of its own, however:</p>
<ul>
<li>Dynamic arrays are optimized for modification at the <em>end</em> of the array. Modifications in the middle of an array can trigger a cascade of updates to nodes at the end of the array. In practice, this is not a big problem, but for large arrays it can become a performance issue. One solution to this problem is to create an alternative structure for looping, where the inner template does either not have access to its index, or where the indices do not correspond to the position of the element in the parent array.</li>
<li>In order to trigger a UI change, however small, we need to construct a new model for the entire static DOM component. Again, in practice, this is not a big problem, but it does make it harder to do certain things. For example, if we wanted to send model changes to the server for evaluation, we would have a hard time.</li>
<li>Every change is potentially observed by every node in the static DOM. We can use tricks like filtering out duplicate events from our event streams, but this takes unnecessary time and CPU cycles. Recall, the motivation for the static DOM was that we intuitively <em>knew</em> which elements should receive the events for small model changes such as changing a single text node. The challenge is to convince the machine that this connection between submodels and elements is obvious!</li>
</ul>
<p>In this post, I'd like to suggest a different approach, which solves these problems but keeps the benefits of the static DOM approach.</p>
<h2>Enter the Incremental Lambda Calculus</h2>
<p>The paper <a href="https://arxiv.org/abs/1312.0658">"A Theory of Changes for Higher-Order Languages"</a> by Cai, Giarrusso, Rendel and Ostermann states the following in its abstract:</p>
<blockquote>
<p>If the result of an expensive computation is invalidated by a small change to the input, the old result should be updated incrementally instead of reexecuting the whole computation.</p>
</blockquote>
<p>This sounds a lot like it applies to our problem! Once we've computed the initial state of the DOM, a small change to the model should result in a small change to the DOM.</p>
<p>In fact, as we'll see, the incremental lambda calculus will provide a solution to all three of the problems listed above.</p>
<p>"A Theory of Changes..." proceeds by interpreting the types and terms of the lambda calculus in a new context where each type is augmented with a <em>change structure</em>.</p>
<p>For our purposes, a change structure is equivalent to a monoid acting on the values of the type. I implement change structures using the following type class:</p>
<pre><code>class Monoid m &lt;= Patch a m | a -&gt; m where
  patch :: a -&gt; m -&gt; a
</code></pre>
<p>This declaration states that there is a functional relationship between carrier types <code>a</code> and change structures <code>m</code>, which must be <code>Monoid</code>s. I use a functional dependency to express the change structure as a function of the carrier type. In practice, this means using newtypes in quite a few more places, but makes type inference more pleasant.</p>
<p>For example, the <code>Last a</code> monoid acts on values of the type <code>a</code> via the newtype <code>Atomic a</code>:</p>
<pre><code>import Data.Maybe.Last

newtype Atomic a = Atomic a

instance patchAtomic :: Patch (Atomic a) (Last a) where
  patch (Atomic a) (Last m) =
    case m of
      Nothing _ -&gt; Atomic a
      Just b    -&gt; Atomic b
</code></pre>
<p><code>mempty</code> does nothing, keeping the current value, and when composing several <code>Last a</code> values, the last one wins. <code>Atomic a</code> is a value of type <code>a</code> with a trivial change structure, where the value is either not changed at all, or changed completely.</p>
<p>The paper also defines change structures for tuples (in which the two components can change independently), functions, and other structures such as <em>bags</em> (sets with duplicate elements permitted).</p>
<p>By interpreting each type and term former in this context, the paper is able to interpret any term of the simply-typed lambda calculus as as <em>incremental</em> function. An incremental function is one which can either be evaluated normally, or given a change to the input, can produce a change to the output.</p>
<h2>An Embedded DSL</h2>
<p>In my <a href="https://github.com/paf31/purescript-incremental-functions"><code>purescript-incremental-functions</code></a> library, I use a different approach, keeping the change structure concept, but implementing incremental functions using an <em>embedded DSL</em>. In particular, I use an approach based on <em>higher-order abstract syntax</em>, in which incremental functions are represented using regular PureScript functions.</p>
<p>It should perhaps not be surprising (if you've read my <a href="http://blog.functorial.com/posts/2017-10-08-HOAS-CCCs.html">other blog post</a>, anyway) that it is possible to give an embedding of incremental lambda calculus in terms of higher-order abstract syntax, but the embedding I use here is in fact <em>not</em> the one I describe in that blog post - it is much simpler.</p>
<p>The key data structure we'll need is a <code>Jet</code>:</p>
<pre><code>type Jet a =
  { position :: a
  , velocity :: Change a
  }
</code></pre>
<p>A <code>Jet</code> is a value of type <code>a</code>, paired with a change of type <code>Change a</code>, where <code>Change a</code> is the change structure acting on <code>a</code>. I say "<em>the</em> change structure", since the functional dependency on <code>Patch</code> makes it unique.</p>
<p><code>Change</code> is defined using something like an <em>associated type</em>. In PureScript, unlike in GHC Haskell, we don't have associated types, but we can make a crude approximation by packaging up the (unique) type under a fundep as an abstract data type and using <code>unsafeCoerce</code> to construct values (safely!):</p>
<pre><code>data Change a

fromChange :: forall a da. Patch a da =&gt; Change a -&gt; da
fromChange = unsafeCoerce

toChange :: forall a da. Patch a da =&gt; da -&gt; Change a
toChange = unsafeCoerce
</code></pre>
<p>We should think of the value <code>Jet { position: x, velocity: dx }</code> as being positioned currently at <code>x</code>, and <em>about to move</em> by the amount <code>dx</code>. This might be reminiscent of dual numbers, from automatic differentiation, in which we pair a number with its rate of change.</p>
<p>Given the definition of <code>Jet</code>, the encoding of incremental functions is simple: an incremental function from <code>a</code> to <code>b</code> (with their associated change structures) is represented by a function from <code>Jet a</code> to <code>Jet b</code>.</p>
<p>Here is a simple example - an incremental function from <code>Atomic</code> values of type <code>a</code> to <code>Atomic</code> values of type <code>b</code>, constructed from a regular function from <code>a</code> to <code>b</code>:</p>
<pre><code>mapAtomic :: forall a b. (a -&gt; b) -&gt; Jet (Atomic a) -&gt; Jet (Atomic b)
mapAtomic f { position, velocity } =
  { position: Atomic (f (un Atomic position))
  , velocity: toChange (map f (fromChange velocity))
  }
</code></pre>
<p>Here, the result will change only when the input changes.</p>
<p>This is a simple example, but we can create incremental versions of many standard functions: maps, folds, <code>filter</code>, <code>zip</code>, and so on. <code>purescript-incremental-functions</code> defines a small standard library of incremental data structures such as arrays, maps and records, and incremental functions like these.</p>
<p>To illustrate an important point, here is another example - an API for an incremental map data structure and a function to <code>map</code> a function over it:</p>
<pre><code>data IMap k a

data MapChange a da
  = Insert a
  | Remove
  | Update da

type MapChanges k a da = Map k (MapChange a da)
-- ^ a potential change for each key

map
  :: forall k a da b db
   . Ord k
  =&gt; Patch a da
  =&gt; Patch b db
  =&gt; (Jet a -&gt; Jet b)
  -&gt; Jet (IMap k a)
  -&gt; Jet (IMap k b)
</code></pre>
<p>Note that jet functions are used here to construct a <em>higher-order incremental function</em>, since the (incremental) function being mapped is being passed in as an argument.</p>
<p>Since jet functions are just regular functions, we can compose them like functions, use lambda abstraction to form new functions, and so on. We are propagating changes by passing them from one function to the next. For example:</p>
<pre><code>mapAtomic (_ + 1)
  :: Jet Int -&gt; Jet Int

map (mapAtomic (_ + 1))
  :: Jet (Imap k Int)
  -&gt; Jet (IMap k Int)

\f -&gt; map (map f)
  :: (Jet a -&gt; Jet b)
  -&gt; Jet (IMap k1 (IMap k2 a))
  -&gt; Jet (IMap k1 (IMap k2 b))
</code></pre>
<p>If we squint enough to see through the <code>Jet</code> type constructors, this DSL is very close to plain old functions, but where our data structures have been switched out for their incremental equivalents. Of course, we're limited to those basic functions which we can write incrementally as jet functions.</p>
<h2>Laws for Incremental Functions</h2>
<p>Every incremental function can be represented as a jet function, but not every jet function is a valid incremental function. We require the following condition to hold for a jet function <code>f :: Jet a -&gt; Jet b</code>:</p>
<pre><code>patch (lower f a) db = lower f (patch a da)
</code></pre>
<p>where</p>
<pre><code>lower :: (Jet a -&gt; Jet b) -&gt; a -&gt; b
lower f a = (f { position: a, velocity: mempty }).position
</code></pre>
<p>and</p>
<pre><code>db = (f { position: a, velocity: da }).velocity
</code></pre>
<p>That is, if we <code>lower</code> the function <code>f</code> to a function on regular (non-changing) values, and apply it to a <code>patch</code>ed value, we should get the same result as applying the <code>lower</code>ed function, and patching the result with a patch generated by the jet function.</p>
<p>Note, however, that the following condition, which might seem intuitively obvious, <em>does not</em> hold in general:</p>
<pre><code>(f { position: a, velocity: mempty }).velocity == mempty
</code></pre>
<p>That is, jet functions are not required to take constant jets to constant jets. The reason is that a jet function might close over some already-changing value from its environment, in which case changes in the result would already be "baked in" to that jet function.</p>
<h2>Change Structures as Models for Mutation</h2>
<p>Change structures tell us how changes act on values, as pure functions, but we can use those pure functions to model impure changes to the real world.</p>
<p>For example, the paper talks about how incremental lambda calculus could be used to model <em>self-maintaining database views</em>. In this case, our values would represent <em>relations</em> and changes would represent updates on those …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html">https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html</a></em></p>]]>
            </description>
            <link>https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046932</guid>
            <pubDate>Tue, 04 Aug 2020 05:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Functional Programming Design from Redux]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24046631">thread link</a>) | @daiyanze
<br/>
August 3, 2020 | https://pitayan.com/posts/redux-fp-design/?ref=hackernews | <a href="https://web.archive.org/web/*/https://pitayan.com/posts/redux-fp-design/?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Before I set my eyes on the Redux source code, I naively thought OOP is superior than FP(Functional Programming) as a programming paradigm. But this is not right. As we know that FP is dedicated to forming a easy to understand and clear workflow without those obscure abstracted objects and relations. It's much closer to human's procedural mode of thinking.</p><p>Now <code>React</code> has already got hooks which can handle the "states" properly event without <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>. The demand for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> could be declining but its code base is still worth learning. Especially for those who wants to enlighten themselves in functional programming. So, I guess it's never a bad idea to learn from a good example even though it is "obsolete" (not at all).</p><p>When I started reading the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code, I immediately felt the power of this unfamiliar usage of my familiar programming language. It feels like exploring an acient cave with a torch lighting up the paintings and found the great secret.</p><p>In order to know more about what Redux benefits from FP, I researched the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code and created a mini version of it.</p><blockquote><p>Never be afraid of reinventing the wheel.</p></blockquote><p><strong>Contents:</strong></p><ul><li><a href="#recap-how-redux-works">Recap How Redux Works</a></li><li><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></li><li><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a><ul><li><a href="#createstore">createStore</a></li><li><a href="#combinereducers">combineReducers</a></li><li><a href="#applymiddleware">applyMiddleware</a></li></ul></li><li><a href="#redux-middlewares">Redux Middlewares</a><ul><li><a href="#redux-thunk">Redux Thunk</a></li><li><a href="#redux-logger">Redux Logger</a></li></ul></li><li><a href="#a-demo-app">A demo app</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ul><h2 id="recap-how-redux-works"><a href="#recap-how-redux-works">Recap How Redux Works</a></h2><p>There are 4 basic key points for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>:</p><ol><li>Create a store for data and let the view subscribe to it</li><li>The view dispatches an action to submit the changs</li><li>The reducer changes the state based on the action type</li><li>Finally return the new state and triggers the view to change</li></ol><p>This is the classic diagram explaining how <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> works:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" width="1088" alt="redux diagram" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1088 573' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-7e552fcbb64e466973e8c4226e516330'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-7e552fcbb64e466973e8c4226e516330)' width='1088' height='573' xlink:href='data:image/jpeg%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAiCAYAAADvVd%2bPAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRo3tWZ2U7sMAyG%2b/5vgcQ1V4C4AIkbQCAh9n3f931fc/RFco8n0zZOGEBEstppUrv%2bYzu2p3h5eXFvb2/u4%2bPDRO/v7453Xl9fy2sVhWus/KEY7yo5ufwLlL%2b5uXGnp6fu/PzcnZ2dVRJzrLm6uvKAWT5QwH18fIzy13IsAOv55%2bfnKF9NT09P5fsFyi8sLLjd3V23vb3dSKxZWlryHwmSMQuQ%2bdXVVbexseF2dnai/FnL/efnpwkALBLeFv7Mb25uehliyQU7g2DrQHkYMSwuwO4j0Dp4j/UAwM5aLGxxcdGlDDZRrLhAIdBhgEqT7zOOj489YDzjA2Wn6%2bjh4cGtrKyYfJNxd3fnAbDwl3kUAhBAa%2bLPPHosLy//BwCfEABkUTh4Js9PTk7c0dFRy/o6koF5VvENZTDu7%2b%2b9mVr4C2jwRyHNp44/77RYQAgAg127vLx019fX/l7PHR4eusnJSX/FFbCGOmJ%2bcHDQjY%2bPlx8BH3gTe25vb/2O4yYykDcxMeEODg6i/Pf29tzIyIgbGhpqUxbLFhkaFBMACMdMMEXu9Y6i%2bMzMjI%2bm3GMNIfEcV%2bEDu7q63OjoaPlhmCB8Cbx8CP5LHNIAADDPmvhDrOnp6XG9vb1tloqMtbU1737iviYAYiYUukDMp7/iAk0xqckF6tzYDECTMAmCEqVjQRCFJAhq362SIQDkBEEUCuOD5i0EqG0ApByDev13HIMolXoMolD2MUhmNz8/73cWfxfCzDF3/Yw1vMzVkgjJlXeIB/it5hcSMjHn9fV1MwDsKBZGwAz5I5OrPOfKM%2bJOmQiBBCAgHMVYROTs7%2b933d3dPkpLUGPNxcVFciqMWQv/GAG6KG5NhUltq/hwmqAw93oOqyxTYUFR/EWCydzcnBsbG/P3uljKKYZSiq1OFUNYENYEmGFMaCmGdN4ugQUlQQp/5z4MRqHwWC0QC5RVlGIBdTxwDayvak1pAVVMQWx/f9%2bbj/i6dUd%2bm8IiDACaXLaoehkAJJD8JQDCHQ4BqNKhqKqtUVpSTXGBFL/8LeXlqvMDgnhVg6bWArgyOBkgCYJ/xQLk%2byVtl991G1iERxaIkRcQQTEhzuSULtBPBsG6I3Fra8t/O7kBgRAdqDEaLUAmWMgJAAjS/dGRNMckwzQ1VuLmuJt2YUl6KNokh9FtMJMLSOLTZD7WRAhQJbO0JEI5FhDmBIBJNYjiZheQKww4BiGd8uZYgERjCi6CahMhD3O19gRjOUGYB0QtQOcB4TGYG5A60RPMjT3JeUAIADtSlQmmkABg7QlKOfxVudoCsgBAeXzS0ptrIoRLdVfXs9NNDD5Yym1AyJXLIAZ8yQJmZ2fLElJigpWkFOVImpqaauvKSL%2bOXdZz/B4YGHDDw8NlSZsiX9ZyRa6u/MwAiO/qOjqHiPzs5vT0dIuSXDmjqTjhr%2beQ39fX55up0qPIkQ0IFHNhXIgCkPt/W12bCz6pLiB/vDT1BFP/x6yjIrXETM3mdBBs6tl9RxAMdTFbQCfz8u/sCXaCip%2bozviPgaCke/pVhM/TEpc2%2bp8GIOwJStPTEjh/svz%2bEQuQYsgSNHOLoVz6Bye%2b7fLOqLjeAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/d23ede7d66304da8179f8bd5b5cb30d1a54c39df/29340/assets/static/redux.82a2fbd.ff6f3365031ebcab6ddfefc3aadeb376.jpg 480w, https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg 1088w"></p><p>From the diagram above, it's easy to find the keywords: <code>action</code><code>store</code><code>reducer</code><code>view</code><code>subscribe</code> and <code>dispatch</code>. And the next is to handle the relations among these keywords.</p><h2 id="redux-approach-comparison-fp-vs-oop"><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></h2><p>Example usage of <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a></p><pre><code><span>const</span> store <span>=</span> <span>createStore</span><span>(</span>
  <span>combineReducers</span><span>(</span><span>{</span>
    one<span>:</span> oneReducer<span>,</span>
    two<span>:</span> twoReducer
  <span>}</span><span>)</span><span>,</span>
  <span>applyMiddleware</span><span>(</span><span>ReduxThunk</span><span>,</span> <span>ReduxLogger</span><span>)</span>
<span>)</span><span>;</span></code></pre><p>Imagine if we do this in OOP, it may look like this:</p><p>(The following is just my imagination. Not how older <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> behaves)</p><pre><code><span>const</span> store <span>=</span> <span>new</span> <span>Store</span><span>(</span><span>)</span>
store<span>.</span><span>setReducers</span><span>(</span><span>{</span>
  one<span>:</span> oneReducer<span>,</span>
  two<span>:</span> twoReducer
<span>}</span><span>)</span>
store<span>.</span><span>setMiddlewares</span><span>(</span><span>{</span>
  <span>ReduxThunk</span><span>,</span>
  <span>ReduxLogger</span>
<span>}</span><span>)</span></code></pre><p>So, what are the differences? Both are good approaches IMO.</p><p>FP does a good job on combining the functions together without side-effects. The return value is consistent which made the program returnings foreseeable during or after the execution.</p><p>OOP made a solid structure which defined all the attributes a data model should contain. It makes it easy to modify or configure the data model.</p><p>In <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>, the <code>reduers</code> and <code>middlewares</code> are usually defined only once. It means, we don't need the ability to update these properties and we don't hope them to be altered during the runtime. As for FP approach, it utilizes the <code>closure</code> technique that kills the possbility of exposing the internal properties. With some fantastic FP techniques (curry, compose, pipe), it's even making the program much more human-readable than OOP.</p><p>I would say FP should be the best fit for such scenario. Of course, the FP I'm talking about here is far from the real functional programming like Haskell. But at least the idea of utilizing FP techniques in Javascript is something to follow.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" width="1024" alt="haskell functional programming" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1024 576' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-52e08e1070b234d120b65ac6e29a8487'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-52e08e1070b234d120b65ac6e29a8487)' width='1024' height='576' xlink:href='data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAkAEADASIAAhEBAxEB/8QAGwAAAgMBAQEAAAAAAAAAAAAAAAQCAwUGAQj/xAAwEAABBAEDAQYCCwAAAAAAAAABAAIDEQQSITFRBRMiQWFxJKEGFBUyQlKCkrHB8P/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/EABkRAQEBAAMAAAAAAAAAAAAAAAABERIhQf/aAAwDAQACEQMRAD8A%2bqSQASdgEvj5uLki8fIilHVjgf8AcFMEWCFz0oyIJ5ceETuhvTqPeucQR%2ba6vc8enRBuwzxTAGJ7XAixSsWFJmZ0DmiKLVDVNLoJHPqq8Vedp77R0yujdj5biDVtgdp46%2baUPoN0aFlUwTiV8je7kZoNW9tA%2b3VXEAgggEHyQcl2J9O%2bzO04JXd3kxSQl3eMEZk00au2WCPboVt9mdt4Pac7ocN0zntbrOqF7BV1y4BOY%2bLj44Ax4IogBpGhgbQ5rZXLVs8Hj70Oq7ralh4WaYXPgnleckGu7kna43WwsNA6LdSpzCL%2bHm29Bv8ANZGXDLKdDpZpmt2IrJa675/D0NrQfJDHGwPy5ACDTjyfkifID2lrsfII33Ya49QVWC173fD5Zo1es1x5eLhXlaupsxe9Z4M7KIIq2uA/rlMwwGN5cZpX7VTyK9%2bEnqD374uYC3TvrIu/1b15qyGNkkztUWSw/etzzp59/RXesQ8hQjibGXab8Rs2bU1kCX%2bpYodqGPFq330jzQhDQMLFHGPF%2b0dK/jZWxRRwgiJjWAmyGirKEIJoQhAIQhB//9k=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/2c16467debebdf254444700dab6213bb45ece8a2/b30b3/assets/static/haskell.82a2fbd.82d9f5b0912290333a547a32e17d3642.jpg 480w, https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg 1024w"></p><h2 id="wonderful-redux-fp-design"><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a></h2><p>In Redux, there is no class at all (In the earlier versions, it was once based on <code>Class</code>). All of its core APIs return either value or function (function factory). And this is exactly what FP expects a function to behave:</p><blockquote><p>Pure with no side effects.</p></blockquote><ul><li><strong>createStore</strong>: returns new <code>Object</code> { getState, dispatch, subscribe }</li><li><strong>combineReducers</strong>: returns new <code>Function</code></li><li><strong>applyMiddleware</strong>: returns new <code>Function</code></li></ul><p>To explain the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> design in an easy way, I implemented only the very core part of the APIs above. Since the latest version's core concept hasn't changed much, I wrote the source code based on very primitive version of <a href="https://github.com/reduxjs/redux/tree/v1.0.1/src" target="_blank" rel="nofollow noopener noreferrer">Redux v1.0.1</a>. Because I believe the very first related version would be the most comprehensive one to look at.</p><p>Let's have a look.</p><h4 id="createstore"><a href="#createstore">createStore</a></h4><p><code>createStore</code> defines those APIs that can be used within components. It's more like <code>setter</code> and <code>getter</code></p><ul><li>getState</li><li>dispatch</li><li>subscribe</li></ul><pre><code><span>export</span> <span>default</span> <span>function</span> <span>createStore</span> <span>(</span><span>reducer<span>,</span> enhancer</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>enhancer<span>)</span> <span>{</span>
    <span>return</span> <span>enhancer</span><span>(</span>createStore<span>)</span><span>(</span>reducer<span>)</span><span>;</span>
  <span>}</span>

  <span>let</span> currentState<span>;</span>
  
  
  <span>let</span> currentListeners <span>=</span> <span>[</span><span>]</span><span>;</span>

  <span>function</span> <span>getState</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> currentState<span>;</span>
  <span>}</span>

  
  <span>function</span> <span>subscribe</span> <span>(</span><span>listener</span><span>)</span> <span>{</span>
    currentListeners<span>.</span><span>push</span><span>(</span>listener<span>)</span><span>;</span>

    <span>return</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      
      <span>const</span> index <span>=</span> currentListeners<span>.</span><span>indexOf</span><span>(</span>listener<span>)</span><span>;</span>
      currentListeners<span>.</span><span>splice</span><span>(</span>index<span>,</span> <span>1</span><span>)</span><span>;</span>
    <span>}</span><span>;</span>
  <span>}</span>

  <span>function</span> <span>dispatch</span> <span>(</span><span>action</span><span>)</span> <span>{</span>
    currentState <span>=</span> <span>reducer</span><span>(</span>currentState<span>,</span> action<span>)</span><span>;</span>
    
    currentListeners<span>.</span><span>forEach</span><span>(</span><span>listener</span> <span>=&gt;</span> <span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"MY-MINI-REDUX"</span> <span>}</span><span>)</span><span>;</span>

  <span>return</span> <span>{</span>
    getState<span>,</span>
    dispatch<span>,</span>
    subscribe
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="combinereducers"><a href="#combinereducers">combineReducers</a></h4><p>Returns a new function that can return the new state. Can't be any purer.</p><pre><code>
<span>function</span> <span>mapValues</span><span>(</span><span>obj<span>,</span> fn</span><span>)</span> <span>{</span>
  <span>return</span> <span>Object</span><span>.</span><span>keys</span><span>(</span>obj<span>)</span><span>.</span><span>reduce</span><span>(</span><span>(</span><span>result<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>{</span>
    result<span>[</span>key<span>]</span> <span>=</span> <span>fn</span><span>(</span>obj<span>[</span>key<span>]</span><span>,</span> key<span>)</span><span>;</span>
    <span>return</span> result<span>;</span>
  <span>}</span><span>,</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>combineReducers</span> <span>(</span><span>reducers</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span> <span>combination</span> <span>(</span><span>state <span>=</span> <span>{</span><span>}</span><span>,</span> action</span><span>)</span> <span>{</span>
    
    
    <span>return</span> <span>mapValues</span><span>(</span>reducers<span>,</span> <span>(</span><span>reducer<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>reducer</span><span>(</span>state<span>[</span>key<span>]</span><span>,</span> action<span>)</span><span>)</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="applymiddleware"><a href="#applymiddleware">applyMiddleware</a></h4><p>I personally think the <code>applyMiddleware</code> API is the most amazing part of Redux. It provides an optimal solution to apply 3rd party plugins.</p><p>The FP <code>compose</code> in the source code is corresponding to Math's <a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="nofollow noopener noreferrer">associative law</a> in my understanding.</p><blockquote><p>( <em>x</em> ∗ ( <em>y</em> ∗ <em>z</em> ) ) = <em>x</em> ∗ <em>y</em> ∗ <em>z</em></p></blockquote><p>The usage of <code>applyMiddleware</code> is actually a form of a <code>pipe</code> that allows us to inject enhancement functions that returns the store Object. It's pretty similar to <code>Aspect Oriented Programming</code> which the most typical example is the annotation / decorator.</p><pre><code>

<span>function</span> <span>compose</span><span>(</span><span><span>...</span>funcs</span><span>)</span> <span>{</span>
  <span>return</span> funcs<span>.</span><span>reduceRight</span><span>(</span><span>(</span><span>composed<span>,</span> f</span><span>)</span> <span>=&gt;</span> <span>f</span><span>(</span>composed<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>applyMiddleware</span><span>(</span><span><span>...</span>middlewares</span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>(</span><span>reducer<span>,</span> initialState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>next</span><span>(</span>reducer<span>,</span> initialState<span>)</span><span>;</span>
    <span>let</span> dispatch <span>=</span> store<span>.</span><span>dispatch</span><span>;</span>
    <span>const</span> middlewareAPI <span>=</span> <span>{</span>
      getState<span>:</span> store<span>.</span><span>getState</span><span>,</span>
      <span>dispatch</span><span>:</span> <span>action</span> <span>=&gt;</span> <span>dispatch</span><span>(</span>action<span>)</span>
    <span>}</span><span>;</span>
    <span>const</span> chain <span>=</span> middlewares<span>.</span><span>map</span><span>(</span><span>middleware</span> <span>=&gt;</span> <span>middleware</span><span>(</span>middlewareAPI<span>)</span><span>)</span><span>;</span>

    
    dispatch <span>=</span> <span>compose</span><span>(</span><span>...</span>chain<span>,</span> store<span>.</span><span>dispatch</span><span>)</span><span>;</span>

    <span>return</span> <span>{</span>
      <span>...</span>store<span>,</span>
      dispatch
    <span>}</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="redux-middlewares"><a href="#redux-middlewares">Redux Middlewares</a></h2><p>There are some famous middlewares for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> like <a href="https://github.com/reduxjs/redux-thunk" target="_blank" rel="nofollow noopener noreferrer">redux-thunk</a> and [redux-logger(<a href="https://github.com/LogRocket/redux-logger" target="_blank" rel="nofollow noopener noreferrer">https://github.com/LogRocket/redux-logger</a>). These are the good examples using <code>applyMiddleware</code> API to enhance the functionalities. Furthermore, their code base is astonishingly small. The core part has only a few lines of code.</p><p>All of the middlewares are <code>curry</code> functions.</p><blockquote><p>funcA =&gt; funcB =&gt; funcC</p><p>funcB = funcA()</p><p>funcC = funcB()</p></blockquote><p> This is extremly helpful when I need other contexts to use within the code block. As of the examples, it's easy to find that <code>next</code> and <code>action</code> are passed in as context to help handle some complex cases.</p><h4 id="redux-thunk"><a href="#redux-thunk">Redux Thunk</a></h4><p><code>redux-thunk</code> allows to use function as <code>dispatch</code> parameter so that I could do something right before "dispatching".</p><pre><code>
<span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>



<span>dispatch</span><span>(</span><span>function</span> <span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>'redux-thunk'</span><span>)</span>
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre><p>Here is the core:</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>thunk</span><span>(</span><span><span>{</span> dispatch<span>,</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>typeof</span> action <span>===</span> <span>"function"</span><span>)</span> <span>{</span>
      <span>return</span> <span>action</span><span>(</span>dispatch<span>,</span> getState<span>)</span><span>;</span>
    <span>}</span>

    <span>return</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="redux-logger"><a href="#redux-logger">Redux Logger</a></h4><p>It's easy to guess what this middleware does. It simply outputs the state changes.</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>logger</span><span>(</span><span><span>{</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"======== Redux Logger ========"</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Action Type: "</span><span>,</span> action<span>.</span><span>type</span><span>)</span><span>;</span>
    <span>const</span> prevState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Prev: "</span><span>,</span> prevState<span>)</span><span>;</span>

    <span>const</span> returnValue <span>=</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>

    <span>const</span> nextState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Next: "</span><span>,</span> nextState<span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"=============================="</span><span>)</span><span>;</span>
    <span>return</span> returnValue<span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="a-demo-app"><a href="#a-demo-app">A demo app</a></h2><p>I implemented mini version of redux and a small counter application to demostrate the functions. The application will do four arithmetic operations: <strong>plus</strong>, <strong>minus</strong>, <strong>multiply</strong> and <strong>divide</strong>. The number will change after clicking the operation button. Meanwhile, <code>multiply</code> and <code>divide</code> will have 300ms' delay which is enabled by a custom middleware (a mini redux-thunk).</p><p><strong>Repository link of "mini-redux":</strong></p><p><a href="https://github.com/daiyanze/mini-redux" target="_blank" rel="nofollow noopener noreferrer">https://github.com/daiyanze/mini-redux</a></p><p><strong>Demo App link:</strong></p><p><a href="https://daiyanze.com/mini-redux/build/index.html" target="_blank" rel="nofollow noopener noreferrer">https://daiyanze.com/mini-redux/build/index.html</a></p><p><img src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" width="1078" alt="app" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1078 586' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b8a33714e79343718b882b0853556166'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b8a33714e79343718b882b0853556166)' width='1078' height='586' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAjCAYAAAAkCQwqAAAACXBIWXMAABYlAAAWJQFJUiTwAAACzElEQVRo3u1YSWsyQRD1v/oHAgoKinqQHDyIHrwIKl7MRYRcvAsJiBcPbkRcEpO4JcZdca2PV9BhvmGci84YRxuKnunu6aGqX79aTKRR2%2b/3v/12u%2bVeKrvd7lfkc9JvtW4mLTc/RgE9lNfUAEKBn58fSqfT1Ov1aD6fs%2bC5Wq1SoVDgfjKZ0HQ65bnX11caj8eXjwBAG61cLpPVaqV4PE6BQIAeHh7o%2bfmZYrEYeTwecjqdFIlEyO/385pcLkcvLy//7XHRCFiv18wBo9GIOp0OIwKy2Wz4xDEOBLTbbR6H0pi7cYBROEDO/FKWFzCXzxnGCygZRShVLBZ1vetnNYAcDWilUok9gBQFekJfdwQcUlBvyJ8dAUqKqxno4g0gJTa4w%2bVyyYEOXB3eF4sFB0GGNoDocdf7/T69vb1xfAAjwPcjMlRChaEQgIYTh9JCeem78ASGJ8G/EPxoYgAlV6cU2KjJRSFAfreVIjr5s9KctC5wKCpUiiZPZSyT1rDWau9T/ftoBMCt1Wo1ZnK4M4S3w%2bGQMzwwPtZ1u12O/N7f32m1WnFWCMFpfnx88PPn5yfV63X2Cs1mk/eGu/z6%2buJ9sB/WYy%2bQ59kRIFgbSrlcLrLb7eTz%2bcjhcJDFYqFgMEg2m40ymQw9PT2R1%2bul%2b/t7ikajvNZsNtPj4yOlUimWRCLBa7LZLH%2bfTCYpHA5zLcHtdtPd3R2FQiGuGcDoZzeA1LUhr8dJiaoPEp3v72%2bu%2bOBkkfNDcKJAh/D9oh4A5KAegG%2bwZjAY8BrMYQw95vP5PLVarZO6zD/LAXr9%2byRe4BBTH2JzafqrxvhqVeQ/gYBjokJAWZDdOZGkezYoTh88cRX1ALWrcihyNCwC1MbPdQ10zwYRCCGoERkgXOBV1QNAfpVK5TcNbjQaHCtcTT1AVICEAWazGY/d6gFk0KKoYesBRmk3A1y7Af4BkCyMSb7bRvcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" data-srcset="https://d33wubrfki0l68.cloudfront.net/6cd10d41d4c5361482bb8734550719faaa7f13e9/0e513/assets/static/app.82a2fbd.42e70fdda76e9bc70c1818fe62939d86.png 480w, https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png 1078w"></p><p>The app has one child component: <code>MiniReduxComp</code>. In my mini-redux, I didn't create a context provider to trigger updates. Instead, I subscribe to the store changes within the component and  do <code>forceUpdate</code> to react to changes.</p><p>I also applied the custom middlewares <code>redux-thunk</code> and <code>redux-logger</code> to enrich the functions.</p><pre><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>Component</span> <span>}</span> <span>from</span> <span>'react'</span><span>;</span>
<span>import</span> store <span>from</span> <span>'../store'</span>

<span>export</span> <span>default</span> <span>class</span> <span>MiniReduxComp</span> <span>extends</span> <span>Component</span> <span>{</span>

  <span>componentDidMount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>=</span> store<span>.</span><span>subscribe</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>forceUpdate</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>componentWillUnmount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>&amp;&amp;</span> <span>this</span><span>.</span><span>unsubscribe</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>

  <span>plus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"PLUS"</span> <span>}</span><span>)</span>

  <span>minus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MINUS'</span> <span>}</span><span>)</span>

  <span>multiply</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MULTIPLY'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>divide</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'DIVIDE'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Plus / Minus 1</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>count</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>plus</span><span>}</span></span><span>&gt;</span></span><span>+1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>minus</span><span>}</span></span><span>&gt;</span></span><span>-1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>
        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>

        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Multiply / Divide 2 (0.3s delay)</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>double</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>mult…</span></span></span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pitayan.com/posts/redux-fp-design/?ref=hackernews">https://pitayan.com/posts/redux-fp-design/?ref=hackernews</a></em></p>]]>
            </description>
            <link>https://pitayan.com/posts/redux-fp-design/?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046631</guid>
            <pubDate>Tue, 04 Aug 2020 04:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany: Biology professor convicted of insulting statements about homosexuals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24046590">thread link</a>) | @s9w
<br/>
August 3, 2020 | https://thecanadian.news/2020/08/03/kassel-biology-professor-convicted-of-insulting-statements-about-homosexuals-the-canadian-news/ | <a href="https://web.archive.org/web/*/https://thecanadian.news/2020/08/03/kassel-biology-professor-convicted-of-insulting-statements-about-homosexuals-the-canadian-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thecanadian.news/2020/08/03/kassel-biology-professor-convicted-of-insulting-statements-about-homosexuals-the-canadian-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046590</guid>
            <pubDate>Tue, 04 Aug 2020 04:25:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speech Synthesis on Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24045647">thread link</a>) | @krisfris
<br/>
August 3, 2020 | https://darkshadow.io/2020/08/01/speech-synthesis-on-linux.html | <a href="https://web.archive.org/web/*/https://darkshadow.io/2020/08/01/speech-synthesis-on-linux.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <p>The main options are <a href="https://linux.die.net/man/1/espeak">espeak</a>, <a href="https://www.gnu.org/software/gnuspeech/">Gnuspeech</a>,
<a href="http://manpages.ubuntu.com/manpages/trusty/man1/spd-say.1.html">spd-say</a>, MBROLA, PicoTTS and the <a href="http://festvox.org/">festvox</a> project
which <a href="http://festvox.org/festival/">festival</a> and <a href="http://www.festvox.org/flite/">flite</a> are part of.
While I found espeak to be the simplest system to use, festival produced the best results when used with the right voices.
This post shall outline the various ways festival can be used and the steps required to achieve good results.</p>

<h3 id="usage">Usage</h3>

<p>Install festival:</p>

<figure><pre><code data-lang="bash"><span>sudo </span>apt-get <span>install </span>festival festvox-us-slt-hts</code></pre></figure>

<p>Use festival’s interactive mode:</p>

<figure><pre><code data-lang="bash">festival <span>-i</span>
festival&gt; <span>(</span>voice.list<span>)</span>
festival&gt; <span>(</span>voice_cmu_us_slt_arctic_hts<span>)</span> 
festival&gt; <span>(</span>SayText <span>"Don't hate me, I'm just doing my job!"</span><span>)</span>
festival&gt; <span>(</span>intro<span>)</span></code></pre></figure>

<p>Run commands from file:</p>

<figure><pre><code data-lang="bash">festival&gt; <span>(</span>load <span>"hello.scm"</span><span>)</span></code></pre></figure>

<p>Use festival’s batch mode:</p>

<figure><pre><code data-lang="bash">festival <span>-b</span> <span>'(voice_cmu_us_slt_arctic_hts)'</span> <span>\</span>
    <span>'(SayText "The temperature is 22 degrees centigrade and there is a slight breeze from the west.")'</span></code></pre></figure>

<p>Use festival’s batch mode to run file:</p>

<figure><pre><code data-lang="bash">festival <span>-b</span> hello.scm</code></pre></figure>

<p>Pipe text into festival’s tts mode:</p>

<figure><pre><code data-lang="bash"><span>echo </span>hello | festival <span>--tts</span></code></pre></figure>

<p>Pipe text to festival’s tts mode from Python with subprocess:</p>

<figure><pre><code data-lang="python"><span>from</span> <span>subprocess</span> <span>import</span> <span>PIPE</span><span>,</span> <span>Popen</span>
<span>text</span> <span>=</span> <span>'We love Raspberry.'</span>
<span>process</span> <span>=</span> <span>Popen</span><span>([</span><span>'festival'</span><span>,</span> <span>'--tts'</span><span>],</span> <span>stdin</span><span>=</span><span>PIPE</span><span>)</span>
<span>process</span><span>.</span><span>stdin</span><span>.</span><span>write</span><span>(</span><span>text</span> <span>+</span> <span>'</span><span>\n</span><span>'</span><span>)</span>
<span>process</span><span>.</span><span>stdin</span><span>.</span><span>close</span><span>()</span>
<span>process</span><span>.</span><span>wait</span><span>()</span></code></pre></figure>

<p>Use Python wrapper of festival’s C++ API:</p>

<figure><pre><code data-lang="bash"><span>sudo </span>apt <span>install </span>festival-dev
pip <span>install </span>git+https://github.com/krisfris/pyfestival</code></pre></figure>

<figure><pre><code data-lang="python"><span>import</span> <span>festival</span>
<span>festival</span><span>.</span><span>sayText</span><span>(</span><span>'hello'</span><span>)</span></code></pre></figure>

<p>Festival also has a C, C++ and a client-server API. See <a href="http://www.cstr.ed.ac.uk/projects/festival/manual/festival_28.html#SEC126">API</a>.</p>

<h3 id="voices">Voices</h3>

<p>The <code>voice_cmu_us_slt_arctic_hts</code> voice (used above) can be installed easily and isn’t bad but
the Nitech HTS voices are better. HTS stands for <em>hidden-markov-model-based speech synthesis system</em> and Nitech is the Nagoya Institute of Technology.</p>

<p>The voices were not available on the original site at the time of writing this post thus I uploaded them to a GitHub repository.</p>

<figure><pre><code data-lang="bash"><span># Clone the github repo with the voices</span>
git clone git@github.com:krisfris/nitech-hts-voices.git

<span># Enter directory</span>
<span>cd </span>nitech-hts-voices

<span># Extract  files</span>
<span>for </span>t <span>in</span> <span>`</span><span>ls</span><span>`</span> <span>;</span> <span>do </span><span>tar </span>xvf <span>$t</span> <span>;</span> <span>done</span>

<span># Install voices</span>
<span>sudo mkdir</span> <span>-p</span> /usr/share/festival/voices/us
<span>sudo mv </span>lib/voices/us/<span>*</span> /usr/share/festival/voices/us/
<span>sudo mv </span>lib/hts.scm /usr/share/festival/hts.scm

<span># List all available voices</span>
<span>for </span>d <span>in</span> <span>`</span><span>ls</span> /usr/share/festival/voices<span>`</span> <span>;</span> <span>do </span><span>ls</span> <span>"/usr/share/festival/voices/</span><span>${</span><span>d</span><span>}</span><span>"</span> <span>;</span> <span>done</span></code></pre></figure>

<p>To set a voice as default voice edit the <code>/etc/festival.scm</code> file and add the following line:</p>

<figure><pre><code data-lang="bash"><span>(</span><span>set</span><span>!</span> voice_default <span>'voice_nitech_us_rms_arctic_hts)</span></code></pre></figure>

<p><em>Note:</em> The Nitech voices are not compatible with festival versions greater than 2.1 which is from 2010. The default festival version on Ubuntu 20.04 is 2.5.</p>

<h3 id="flite">Flite</h3>

<p>Flite is a small, fast and more portable (albeit less customizable) speech synthesis engine for festival voices.
Install it with <code>sudo apt install flite</code>. Download more voices:</p>

<figure><pre><code data-lang="bash"><span>cd
mkdir</span> .config/flite <span>&amp;&amp;</span> <span>cd</span> .config/flite
wget <span>-r</span> <span>--no-parent</span> <span>--no-directories</span> <span>--accept</span> flitevox http://www.festvox.org/flite/packed/flite-2.0/voices/
<span>echo</span> <span>"Hello World!"</span> | flite <span>-voice</span> ./cmu_us_axb.flitevox</code></pre></figure>

<p>The downside is, you can’t use voices from festival with flite directly.
Instead you will need to convert them manually which requires time and programming knowledge.
See <a href="http://www.speech.cs.cmu.edu/flite/doc/flite_8.html">Converting FestVox Voices</a>.</p>

<p>Personally, I would stick to festival unless the speed and small size of flite are
actually required.</p>

<h3 id="emacs">Emacs</h3>

<p>The festival manual mentions a simple way of using festival from emacs.
See <a href="http://www.cstr.ed.ac.uk/projects/festival/manual/festival_11.html#SEC37">Emacs interface</a>.</p>

<p>There is also an ubuntu package called <code>eflite</code> which is an emacspeak server based on flite.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Since the Nitech voices don’t work with newer festival versions you will have to settle for 
the <code>cmu_us_slt_arctic_hts</code> voice. If you don’t mind going commercial,
using <a href="https://aws.amazon.com/polly/">AWS Polly</a> is likely a better choice.
<!---
Since the Nitech voices don't work with newer festival versions you will have to settle for 
the `cmu_us_slt_arctic_hts` voice. If you don't mind going commercial,
using [AWS Polly](/2020/08/01/speech-synthesis-with-aws-polly.html) is likely a better choice.
--></p>

<h3 id="links">Links</h3>

<p><a href="https://askubuntu.com/questions/53896/natural-sounding-text-to-speech">https://askubuntu.com/questions/53896/natural-sounding-text-to-speech</a><br>
<a href="http://www.cstr.ed.ac.uk/projects/festival/manual/festival_toc.html">http://www.cstr.ed.ac.uk/projects/festival/manual/festival_toc.html</a><br>
<a href="https://ubuntuforums.org/showthread.php?t=751169">https://ubuntuforums.org/showthread.php?t=751169</a></p>

  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://darkshadow.io/2020/08/01/speech-synthesis-on-linux.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045647</guid>
            <pubDate>Tue, 04 Aug 2020 01:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Profitably Unemployed]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24045529">thread link</a>) | @hackernewsreadr
<br/>
August 3, 2020 | https://blogofjake.com/2020/08/03/profitably-unemployed/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/08/03/profitably-unemployed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><u>A Money Mystery</u></strong></p>



<p>I have been unemployed for 10 months now and my net worth is greater today than it was when I quit my job. The purpose of this piece is to explain how that has happened.</p>



<p>First, I want to be clear about a few ways in which I did not make money. I did not receive any government money through unemployment nor from the stimulus checks. Unemployment money is not for people who quit their jobs voluntarily and the stimulus checks were not for people who made more than $99,000 in 2019. I have not had any paid job at any point in the last 10 months. I did not start a profitable business at any point during that time. I have not made any money from this blog. My only material source of income has been through the appreciation of investments that I have made on my own, but that is not the part the matters most.</p>



<p><strong><u>The Water Bucket Analogy</u></strong></p>



<p>What matters most is how I have kept from losing money.</p>



<p>To explain, let me introduce a simple analogy. Think about a bucket of water with a hose that fills it and a hole near the bottom where the water leaks out. The water in the bucket represents your money and the speed at which it leaks out of the hole is the speed at which your money is spent. Most people have a paying job. That’s the hose.</p>



<p>People want to increase their net worth over time and so naturally they think about how they can get more water faster from the hose. The better place to start, however, is to focus on limiting the leakage. People’s general focus on the hose rather than the hole is well demonstrated by the fact that anyone you ask will be able to tell you how much money they make by some unit of time but almost no one will be able to tell you the same in terms of their costs. They probably know the cost of their rent or mortgage payments and a number of other standalone expenses (by varying units of time) but very few will be able to tell you how much money they spend on an average day including their monthly, annual, and other periodic expenses spread out over the course of the respective period. I certainly could not have answered that question myself a year ago but doing so seemed like the sensible place to start.</p>



<p><strong><u>Base Burn Rate</u></strong></p>



<p>I knew when I quit my job in banking that in order to keep my cash burn in check I would need to get my expenses in order. I had turned the hose off so I needed to manage the hole. I started with my subscriptions (monthly and annual payments). I looked at the recurring expenses on my credit card and bank statements. I cancelled almost all of them. I had to add one significant one, health insurance, which my employer had been paying previously. I went with the second cheapest plan I could find from Horizon Blue Cross Blue Shield for $287/month. Next time I would instead go with the second cheapest plan from Oscar for $293/month because I like newer companies in broken industries and they tend to offer a better customer experience.</p>



<p>My next largest recurring payment was my phone bill. I went into the Verizon store and asked what the differences were between my current plan and the cheapest one I could possibly have. The only difference of any significance was the inability with the lower plan to use a hotspot. That infrequently used function was not nearly worth the ~$80/month difference in plans. I cut my phone bill in half to $78/month.</p>



<p>Below are the rest of my monthly and annual expenses as they stand today. As you will see, if I didn’t actively spend any money, these passive expenses alone would result in only a $15/day average burn. I call this my <strong><em>base burn rate</em></strong>. <em>Note: this figure was closer to $60 when I was living in New York pre-covid (+ rent, WiFi, utilities) and between $30-$60 when I was traveling in Europe and Asia (+ hostels/Airbnbs), but right now I am fortunate to be living with my family for free</em>.</p>



<figure><img data-attachment-id="1253" data-permalink="https://blogofjake.com/image-2-4/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png" data-orig-size="515,213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" src="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/08/image-2.png 515w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300 300w" sizes="(max-width: 515px) 100vw, 515px"></figure>



<p>Not bad right? It gets better…</p>



<p><strong><u>Passive Income</u></strong></p>



<p>I think about my investments in terms of three categories – crypto, stocks, and real estate. Real estate is unique among the three in that it pretty predictably generates cash flows each month. This is because our monthly rents collected from tenants are more than enough to cover the monthly mortgage payments, the cost of our property manager (10% of rent), and any necessary maintenance and/or repairs that she facilitates on our behalf over the course of a given month. Subtracting those expenses from the total rent collected each month and splitting the balance with my good friend and co-owner Kyle leaves me to expect $319/month (assuming the average amount of monthly repairs) which comes out to about $10/day. This is a far cry from the passive income of a real estate magnate but it is solid for a first property and not insignificant for me when it is the only dependable income that I have. Most importantly, this passive income offsets two-thirds of my base burn rate at the moment.</p>



<p>With my base burn rate and passive income figured out, I can calculate what I call my <strong><em>net base burn rate</em></strong> which in this case is equal to $5/day,</p>



<p><strong><u>3 Basic Principles</u></strong></p>



<p>After minimizing my base burn rate and estimating my passive income to calculate my net base burn rate, the next category I considered was comprised of the regularly re-occurring but variable expenses that cost me the most. This includes food, drinks, transportation, and entertainment. I came up with a few principles to help myself spend less in these areas. That said, I believe one of the best things money can buy is the ability not to have to worry about money so rather than force any hard rules upon myself I mostly just keep these principles in mind and try to be reasonable most of the time. <em>Note: these principles were most applicable when I was traveling and then living in New York pre-covid.</em></p>



<ol type="1"><li>Food – don’t drink a lot at restaurants. You are there for the food and the company.</li><li>Drinks – drink less and mostly at yours or friends’ places. The lower your tolerance, the cheaper the fun.</li><li>Transportation – walk when you can. Subways are usually quicker and always cheaper than cars.</li></ol>



<p><strong><u>Exceeding Expectations</u></strong></p>



<p>The goal is not to be watching your wallet all the time. It is to figure it out, then forget about it. Knowing my net base burn rate of $5/day leads to an annual burn of less than $2,000 allows me to live and spend confidently because I know if I ever want to slow my burn I can basically do so simply by doing nothing (therefore slowing my active spending). I don’t <em>need</em> to drink alcohol or go golfing and I could easily eat for a few dollars per day if I was willing to eat less healthfully and not go out for a while. Fortunately, I have not had to sacrifice any of these things. If I did have to, I know that I could, but I would probably just go and get a job at that point and realistically well before that point ever came.</p>



<p>In order to quit my job in the first place, I had to be willing to endure some level of burn in exchange for the freedom of time that I was buying for myself. I was confident that I could offset some of it with my investments in crypto and stocks, and the non- cash flow part of my real estate investment (the appreciation of the value of my equity in the property). Never would I have anticipated what has happened to date. I am pleased to say that between Bitcoin’s surge this week, Amazon’s last month, the appreciation of my Kentucky property’s value, and some other smaller stock and crypto investments along the way, my investments have now offset the entirety of my burn over the last 10 months. My net worth is slightly greater today than it was the day I quit my job, and it is not because I’ve been a hermit or lived a miserably frugal life. Quite the contrary. I traveled the world for a few months, had a four-month lease in New York City and stayed in a couple hotels before that, got a month-long Airbnb in Georgia with Lauren, have eaten well, been golfing a lot lately, and the list goes on. Not every day is roses. I would be skeptical of anyone who says that is the case. But I have not often if ever but rarely felt restrained moneywise. I have been enjoying my time quite a bit.</p>



<p>When I quit my job, I figured I would burn a good chunk of my savings in a few months and expected I would feel the need to get a job after several if not before then. I thought it would be well worthwhile to burn that money in exchange for the time that I would buy for myself to do whatever I wanted. I was right in the sense that this time has proven valuable to me but wrong in another. It hasn’t cost me a dime.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-08-03T16:13:48-04:00">August 3, 2020</time><time datetime="2020-08-03T16:17:10-04:00">August 3, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/08/03/profitably-unemployed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045529</guid>
            <pubDate>Tue, 04 Aug 2020 01:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Potter and the Mnemonic Major System]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24045475">thread link</a>) | @krisfris
<br/>
August 3, 2020 | https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html | <a href="https://web.archive.org/web/*/https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <p>As most reasonable people are familiar with the Harry Potter books,
their content serves as ideal material for building a mnemonic system.
The mnemonic major system, in particular, is used to memorize number sequences.</p>

<p>In order to implement the steps outlined in this post you need the content of the Harry Potter books (or other book(s) if you prefer).
In a previous post I showed you how to
<a href="https://darkshadow.io/2020/06/29/building-a-fantasy-book-db.html">download fantasy books and extract their text</a>.
Among the downloaded data were the Harry Potter books which I will use in this post.</p>

<h3 id="step-1-learn-the-sound-number-mapping">Step 1: Learn the sound-number mapping</h3>

<p>In the mnemonic major system each number from 0 to 9 is associated with one or more
consonant sounds. Use the following table as a reference.</p>

<table>
  <thead>
    <tr>
      <th>Number</th>
      <th>Sounds (IPA)</th>
      <th>Letters with example words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>s, z</td>
      <td>s (see), c (city), z (zero), x (xylophone)</td>
    </tr>
    <tr>
      <td>1</td>
      <td>t, d, ð, θ</td>
      <td>t (tee), d (dad), th (though), th (think)</td>
    </tr>
    <tr>
      <td>2</td>
      <td>n, ŋ</td>
      <td>n (nail)</td>
    </tr>
    <tr>
      <td>3</td>
      <td>m</td>
      <td>m (monster)</td>
    </tr>
    <tr>
      <td>4</td>
      <td>r</td>
      <td>r (right), l (colonel)</td>
    </tr>
    <tr>
      <td>5</td>
      <td>l</td>
      <td>l (left)</td>
    </tr>
    <tr>
      <td>6</td>
      <td>ʤ, ʧ, ʃ, ʒ</td>
      <td>ch (cheese), j (juice), g (ginger), sh (shell), c (cello, special),<br> cz (czech), s (tissue, vision), sc (fascist), sch (eschew),<br>t (ration), tsch (putsch), z (seizure)</td>
    </tr>
    <tr>
      <td>7</td>
      <td>k, ɡ</td>
      <td>k (kid), c (cake), q (quarter), g (good), ch (loch)</td>
    </tr>
    <tr>
      <td>8</td>
      <td>f, v</td>
      <td>f (face), ph (phone), v (alive), gh (laugh)</td>
    </tr>
    <tr>
      <td>9</td>
      <td>p, b</td>
      <td>p (power), b (baby)</td>
    </tr>
  </tbody>
</table>

<p>In English, letters are pronounced in different ways depending on the context,
that’s why some letters are repeated in different rows. But in the end,
only the sound matters, not the spelling.</p>

<p>Here are a few examples for words, their IPA representation and the number they encode.</p>

<table>
  <thead>
    <tr>
      <th>Word</th>
      <th>IPA</th>
      <th>Number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>action</td>
      <td>ækʃən</td>
      <td>762</td>
    </tr>
    <tr>
      <td>muddy</td>
      <td>mədi</td>
      <td>31</td>
    </tr>
    <tr>
      <td>midday</td>
      <td>mɪddeɪ</td>
      <td>311</td>
    </tr>
    <tr>
      <td>accept</td>
      <td>æksɛpt</td>
      <td>7091</td>
    </tr>
    <tr>
      <td>fax</td>
      <td>fæks</td>
      <td>870</td>
    </tr>
    <tr>
      <td>exam</td>
      <td>ɪgzæm</td>
      <td>703</td>
    </tr>
    <tr>
      <td>anxious</td>
      <td>æŋkʃəs</td>
      <td>2760</td>
    </tr>
    <tr>
      <td>luxury</td>
      <td>ləgʒəri</td>
      <td>5764</td>
    </tr>
    <tr>
      <td>pizza</td>
      <td>pitsə</td>
      <td>910</td>
    </tr>
    <tr>
      <td>ghost</td>
      <td>goʊst</td>
      <td>701</td>
    </tr>
    <tr>
      <td>enough</td>
      <td>inəf</td>
      <td>28</td>
    </tr>
    <tr>
      <td>fear</td>
      <td>fɪr</td>
      <td>84</td>
    </tr>
  </tbody>
</table>

<p>To familiarize yourself with the IPA notation, try to read the following excerpt.</p>

<figure><pre><code data-lang="html">Sorting Hat: həm, dɪfəkəlt. vɛri dɪfəkəlt. plɛnti əv kərɪʤ, aɪ si.
             nɑt ə bæd maɪnd, iðər. ðɛrz tælənt, oʊ jɛs. ənd ə θərst tɪ pruv jʊrsɛlf.
             bət wɛr tɪ pʊt ju?
Harry:       nɑt slɪðərɪn. nɑt slɪðərɪn.
Sorting Hat: nɑt slɪðərɪn, ɛ? ər ju ʃʊr? ju kʊd bi greɪt, ju noʊ. ɪts ɔl hir ɪn jʊr hɛd.
             ənd slɪðərɪn wɪl hɛlp ju ɔn ðə weɪ tɪ greɪtnəs, ðɛrz noʊ daʊt əbaʊt ðət. noʊ?
Harry:       pliz, pliz. ɛniθɪŋ bət slɪðərɪn, ɛniθɪŋ bət slɪðərɪn.
Sorting Hat: wɛl ɪf jʊr ʃʊr, bɛtər bi... grɪfɪndɔː!</code></pre></figure>

<p>Consider the same lines converted to number sequences.</p>

<figure><pre><code data-lang="html">Sorting Hat: 3 18751 84 18751 9521 8 746 0 21 91 321 14 140 1521 0 21 8401 1 948 4058 91 4 1 91
Harry:       21 05142 21 05142
Sorting Hat: 21 05142 4 64 71 9 741 2 10 5 4 2 4 1 21 05142 5 59 2 1 1 74120 140 2 11 91 11 2
Harry:       950 950 282 91 05142 282 91 05142
Sorting Hat: 5 8 4 64 914 9 74821</code></pre></figure>

<p>I’m going to show you how to write a training program to internalize
the concept of mapping sounds to numbers in Step 4. But first, you need the ability
to convert text automatically to numbers. This happens in 2 steps. First, the text is converted
to IPA. Then, the IPA is converted to numbers.</p>

<h3 id="step-2-converting-ipa-to-numbers">Step 2: Converting IPA to numbers</h3>

<p>The process of converting IPA to numbers is very simple. I iterate through the IPA chars
and if there is a number associated with the char I append the number to the result.</p>

<figure><pre><code data-lang="python"><span># Mapping from number to sounds
</span><span>num_to_phones</span> <span>=</span> <span>{</span><span>0</span><span>:</span> <span>[</span><span>'s'</span><span>,</span> <span>'z'</span><span>],</span> <span>1</span><span>:</span> <span>[</span><span>'t'</span><span>,</span> <span>'d'</span><span>,</span> <span>'ð'</span><span>,</span> <span>'θ'</span><span>],</span> <span>2</span><span>:</span> <span>[</span><span>'n'</span><span>,</span> <span>'ŋ'</span><span>],</span> <span>3</span><span>:</span> <span>[</span><span>'m'</span><span>],</span> <span>4</span><span>:</span> <span>[</span><span>'r'</span><span>],</span>
                 <span>5</span><span>:</span> <span>[</span><span>'l'</span><span>],</span> <span>6</span><span>:</span> <span>[</span><span>'ʤ'</span><span>,</span> <span>'ʧ'</span><span>,</span> <span>'ʃ'</span><span>,</span> <span>'ʒ'</span><span>],</span> <span>7</span><span>:</span> <span>[</span><span>'k'</span><span>,</span> <span>'g'</span><span>],</span> <span>8</span><span>:</span> <span>[</span><span>'f'</span><span>,</span> <span>'v'</span><span>],</span>
                 <span>9</span><span>:</span> <span>[</span><span>'p'</span><span>,</span> <span>'b'</span><span>]}</span>

<span># Reverse mapping from sound to number
</span><span>phone_to_num</span> <span>=</span> <span>{</span><span>x</span><span>:</span> <span>k</span> <span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>num_to_phones</span><span>.</span><span>items</span><span>()</span> <span>for</span> <span>x</span> <span>in</span> <span>v</span><span>}</span>

<span>def</span> <span>major_decode_from_ipa</span><span>(</span><span>ipa</span><span>):</span>
    <span>"""Convert IPA to number sequence."""</span>
    <span>result</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>char</span> <span>in</span> <span>ipa</span><span>:</span>
        <span>if</span> <span>(</span><span>num</span> <span>:</span><span>=</span> <span>phone_to_num</span><span>.</span><span>get</span><span>(</span><span>char</span><span>))</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>result</span><span>.</span><span>append</span><span>(</span><span>num</span><span>)</span>
    <span>return</span> <span>result</span></code></pre></figure>

<p>For example, <code>major_decode_from_ipa('dɪfəkəlt')</code> yields <code>[1, 8, 7, 5, 1]</code>.</p>

<p>Additionally, I define a couple functions for converting number sequences to and from strings.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>numseq_to_str</span><span>(</span><span>numseq</span><span>):</span>
    <span>"""Convert number sequence to string."""</span>
    <span>return</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>str</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>numseq</span><span>)</span>

<span>def</span> <span>str_to_numseq</span><span>(</span><span>s</span><span>):</span>
    <span>"""Convert string to number sequence."""</span>
    <span>return</span> <span>[</span><span>int</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>s</span> <span>if</span> <span>x</span><span>.</span><span>isdigit</span><span>()]</span></code></pre></figure>

<p>For example, <code>numseq_to_str([1, 8, 7, 5, 1])</code> yields <code>'18751'</code>.</p>

<h3 id="step-3-converting-text-to-ipa">Step 3: Converting text to IPA</h3>

<p>In order to automatically convert text to IPA (and then to numbers) you need to use an IPA
dictionary.</p>

<p>Python’s <a href="https://pypi.org/project/eng-to-ipa/">eng-to-ipa</a> package is able to convert text to
IPA using the <em>Carnegie-Mellon University Pronouncing Dictionary</em>.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>eng_to_ipa</span>

<span>s</span> <span>=</span> <span>'“I’ll bring up some sandwiches.”'</span>  <span># Sentence from the HP books
</span><span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>s</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
<span>print</span><span>(</span><span>ipa</span><span>)</span></code></pre></figure>

<p>This yields:</p>

<figure><pre><code data-lang="html">['“i’ll* brɪŋ əp səm sandwiches.”*']</code></pre></figure>

<p>According to the docs, eng-to-ipa will reprint words that cannot be found in the CMU dictionary
with an asterisk. Thus, <code>“i’ll</code> and <code>sandwiches.”</code> have not been found. Clearly, the punctuation is the issue.
I preprocess the text in order to ease the conversion to IPA.</p>

<figure><pre><code data-lang="python"><span># Punctuation including unicode chars
</span><span>punctuation</span> <span>=</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>sys</span><span>.</span><span>maxunicode</span><span>)</span>
                      <span>if</span> <span>unicodedata</span><span>.</span><span>category</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)).</span><span>startswith</span><span>(</span><span>'P'</span><span>))</span>

<span>def</span> <span>preprocess</span><span>(</span><span>text</span><span>):</span>
    <span>"""Strip punctuation between words, normalize space, lowercase, replace unicode apostrophe."""</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>x</span><span>.</span><span>strip</span><span>(</span><span>punctuation</span><span>).</span><span>lower</span><span>().</span><span>replace</span><span>(</span><span>'’'</span><span>,</span> <span>'</span><span>\'</span><span>'</span><span>)</span>
                    <span>for</span> <span>x</span> <span>in</span> <span>text</span><span>.</span><span>split</span><span>())</span>
                    
<span>print</span><span>(</span><span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>preprocess</span><span>(</span><span>s</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<p>And…</p>

<figure><pre><code data-lang="html">['aɪl brɪŋ əp səm sæmwɪʧɪz', 'aɪl brɪŋ əp səm sændwɪʧɪz', 'aɪl brɪŋ əp səm sænwɪʧɪz']</code></pre></figure>

<p>As you can see, there are 3 ways to pronounce this sentence depending on whether you like
to pronounce <code>sandwich</code> with <code>m</code>, <code>n</code> or <code>nd</code>. In order to use the major system effectively,
you should use the version that sounds most natural to you.</p>

<p>Let’s look at another example.</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>eng_to_ipa</span><span>(</span><span>preprocess</span><span>(</span><span>'Well, if you’re sure — better be GRYFFINDOR!'</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span>
                 <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<figure><pre><code data-lang="html">['wɛl ɪf jur ʃʊr bɛtər bi gryffindor*', 'wɛl ɪf jʊr ʃʊr bɛtər bi gryffindor*']</code></pre></figure>

<p>The word <code>gryffindor</code> was not found in the CMU dictionary, which can be expected.
After a quick search for the word’s pronunciation I found <a href="https://youglish.com/pronounce/gryffindor/english">YouGlish</a>
which uses YouTube videos to find IPAs. While their API is not free, a limited number of IPA’s can be scraped
for our purpose.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>time</span><span>,</span> <span>random</span><span>,</span> <span>requests</span><span>,</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span>

<span>def</span> <span>ipa_from_youglish</span><span>(</span><span>word</span><span>):</span>
    <span>"""Scrape IPA for word from youglish.com."""</span>
    <span>url</span> <span>=</span> <span>f'https://youglish.com/pronounce/</span><span>{</span><span>word</span><span>}</span><span>/english?'</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>print</span><span>(</span><span>f'Scraping word "</span><span>{</span><span>word</span><span>}</span><span>" from youglish...'</span><span>,</span> <span>end</span><span>=</span><span>''</span><span>,</span> <span>flush</span><span>=</span><span>True</span><span>)</span>
        <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
        <span>if</span> <span>'Usage limit exceeded'</span> <span>in</span> <span>response</span><span>.</span><span>text</span><span>:</span>
            <span>raise</span> <span>Exception</span><span>(</span><span>'YouGlish usage limit exceeded'</span><span>)</span>
        <span>root</span> <span>=</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span><span>.</span><span>fromstring</span><span>(</span><span>response</span><span>.</span><span>text</span><span>)</span>
        <span>if</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@class="g-recaptcha"]'</span><span>):</span>
            <span>print</span><span>(</span><span>'RECAPTCHA'</span><span>)</span>
            <span>input</span><span>(</span><span>f'Open </span><span>{</span><span>url</span><span>}</span><span>, submit CAPTCHA challenge, press enter to continue.'</span><span>)</span>
        <span>else</span><span>:</span>
            <span>break</span>
    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>random</span><span>.</span><span>random</span><span>()</span> <span>*</span> <span>3</span><span>)</span>
    <span>d</span> <span>=</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@id="phoneticPanel"]/div/ul[@class="transcript"]'</span>
                  <span>'/li/span[contains(text(), "Traditional IPA")]'</span>
                  <span>'/following-sibling::text()'</span><span>)</span>
    <span>if</span> <span>d</span><span>:</span>
        <span>print</span><span>(</span><span>'SUCCESS'</span><span>)</span>
        <span>return</span> <span>d</span><span>[</span><span>0</span><span>].</span><span>strip</span><span>(</span><span>' ˈ'</span><span>)</span>
    <span>print</span><span>(</span><span>'FAILED'</span><span>)</span></code></pre></figure>

<p>As you can see, this function is semi-interactive. Without user intervention it will
get stuck on a CAPTCHA. Even then, you’ll eventually reach their daily usage limit
and won’t be able to continue. For our purpose this shall be good enough though.</p>

<figure><pre><code data-lang="python"><span>&gt;</span> <span>ipa_from_youglish</span><span>(</span><span>'gryffindor'</span><span>)</span>
<span>Scraping</span> <span>word</span> <span>"gryffindor"</span> <span>from</span> <span>youglish</span><span>...</span><span>SUCCESS</span>
<span>grɪfɪndɔː</span></code></pre></figure>

<p>I have shown that for many words there are several possible pronunciations, from which you need to choose
your preferred one, and that some words are not in the CMU dictionary and
require scraping the IPA from another source or are not available at all.
For these 2 reasons, you will need to build your own personal IPA dictionary.</p>

<p>I’m going to build my IPA dictionary by iterating through the words of the Harry Potter books
and adding each word and the corresponding IPA to my dictionary.</p>

<p>First, I define
some functions for managing my dictionary (a simple JSON file in this case).</p>

<figure><pre><code data-lang="python"><span>import</span> <span>os</span><span>,</span> <span>glob</span><span>,</span> <span>json</span>

<span>ipa_dict_path</span> <span>=</span> <span>'data/ipa-dict.json'</span>

<span>def</span> <span>load_json_file_or_dict</span><span>(</span><span>filename</span><span>):</span>
    <span>"""Load data from json file if exists otherwise return empty dict."""</span>
    <span>if</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>isfile</span><span>(</span><span>filename</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)</span>
    <span>return</span> <span>dict</span><span>()</span>

<span>def</span> <span>save_to_json_file</span><span>(</span><span>data</span><span>,</span> <span>filename</span><span>):</span>
    <span>"""Save data to json file."""</span>
    <span>with</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>json</span><span>.</span><span>dump</span><span>(</span><span>data</span><span>,</span> <span>f</span><span>)</span>

<span>def</span> <span>load_ipa_dict</span><span>():</span>
    <span>"""Load IPA dict from json file."""</span>
    <span>return</span> <span>load_json_file_or_dict</span><span>(</span><span>ipa_dict_path</span><span>)</span>

<span>def</span> <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>):</span>
    <span>"""Save IPA dict to json file."""</span>
    <span>save_to_json_file</span><span>(</span><span>ipa_dict</span><span>,</span> <span>ipa_dict_path</span><span>)</span></code></pre></figure>

<p>Next, I iterate through the words of the books and enter
each word and whatever is returned by <em>eng-to-ipa</em> into my dictionary.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>harry_potter_text</span><span>():</span>
    <span>"""Return entire content of the Harry Potter books in a single string."""</span>
    <span>data</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>filename</span> <span>in</span> <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'data/json/Harry Potter*'</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>data</span><span>.</span><span>append</span><span>(</span><span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)[</span><span>'text'</span><span>])</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>data</span><span>)</span>
    
<span>def</span> <span>populate_ipa_dict_from_text</span><span>(</span><span>text</span><span>):</span>
    <span>"""Get all IPA information from eng_to_ipa and save to ipa_dict."""</span>
    <span>ipa_dict</span> <span>=</span> <span>load_ipa_dict</span><span>()</span>
    <span>words</span> <span>=</span> <span>preprocess</span><span>(</span><span>text</span><span>).</span><span>split</span><span>()</span>
    <span>for</span> <span>word</span> <span>in</span> <span>set</span><span>(</span><span>words</span><span>)</span> <span>-</span> <span>set</span><span>(</span><span>ipa_dict</span><span>.</span><span>keys</span><span>()):</span>
        <span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>word</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span>
                                 <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
        <span>ipa_dict</span><span>[</span><span>word</span><span>]</span> <span>=</span> <span>ipa</span>
    <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>)</span>
    
<span>populate_ipa_dict_from_text</span><span>(</span><span>harry_potter_text</span><span>())</span></code></pre></figure>

<p>Each value in the dictionary is now a list of possible IPAs as that is what
<em>eng-to-ipa</em> returned. Before the dictionary can be used, we need to ensure
that each word …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</a></em></p>]]>
            </description>
            <link>https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045475</guid>
            <pubDate>Tue, 04 Aug 2020 01:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seek Feedback Loops]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24045050">thread link</a>) | @mooreds
<br/>
August 3, 2020 | https://letterstoanewdeveloper.com/2020/08/03/seek-feedback-loops/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/08/03/seek-feedback-loops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>Feedback loops are so important. (If you’re not sure what that is, I’d recommend <a href="https://www.indiebound.org/book/9781603580557">“Thinking in Systems”</a>.) </p>



<p>These loops help systems improve. If you don’t have feedback, you’ll improve more slowly, in my experience. Why? Because you won’t know what you are doing that is good and what is garbage. It’s really hard to evaluate that kind of stuff yourself. You can do it, it just takes time and perspective.</p>



<p>And of course, you want to do more of what is good. Here are some kinds of feedback loops which have helped me.</p>



<ul><li>tests</li><li>one to ones</li><li>public writing</li><li>being a contractor</li></ul>



<p>Automated tests are a really tight feedback loop. You can make changes to code and know if you’ve blown things up. (Type systems are another tight feedback loop preferred by some.) This is helpful in many situations, including when you are <a href="https://letterstoanewdeveloper.com/2020/01/20/on-debugging/">debugging a problem</a>.</p>



<p><a href="https://letterstoanewdeveloper.com/2020/03/16/how-to-manage-one-to-ones/">One to ones</a> are a great way to gather feedback from your manager on problems, challenges and situations that you have faced. By doing it in a one to one (rather than a one off meeting), you’ll build context and history around these. After all, the tenth time you bring up the fact you find front-end development challenging indicates that this is a pattern, and you should evolve yourself or the position to help with the challenge. When you have your meeting, make sure you ask for feedback explicitly. When you get it, avoid being defensive. If you make it hard to get feedback, you’ll get less.</p>



<p>Public writing, especially <a href="https://letterstoanewdeveloper.com/2018/12/10/start-a-blog/">a blog</a>, is a great way to get feedback. You’ll be able to put your thoughts out in public. This can be scary and frustrating; some communities are more gentle about feedback than others. But the act of writing forces you to make the implicit explicit. And sharing that knowledge is a great way to get feedback. (Even a lack of response is feedback; what you were writing didn’t resonated with the audience you shared it with.)</p>



<p>I think everyone should <a href="https://letterstoanewdeveloper.com/2018/11/12/try-contracting/">try being a contractor</a>. First it makes you appreciative of everyone else in a business, because when you are contracting, you often have to take on roles outside of development (sales, accounting, marketing). But for the purposes of this post, contracting is a great way to get feedback from the market. You’ll learn about which skills are in demand and what organizations will pay for those skills. Of course, you can find this out as an employee, but if you are a contractor, especially a short term one, you’ll be interacting with possible hiring managers much more often than as an employee. And the feedback loop is brutal and blunt: do they hire you or not. </p>



<p>Feedback loops are a key way to find out whether what you are doing is working or not. Seek them out. </p>



<p>Sincerely,</p>



<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-08-03T07:51:00-06:00">August 3, 2020</time><time datetime="2020-07-11T17:15:55-06:00">July 11, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/08/03/seek-feedback-loops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045050</guid>
            <pubDate>Tue, 04 Aug 2020 00:10:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[6 Reasons Why You Should Stop Using Google Analytics on Your Web Site Now]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24044725">thread link</a>) | @arsenkay
<br/>
August 3, 2020 | https://privateanalytix.com/2020/08/03/6-reasons-why-you-should-stop-using-google-analytics-on-your-web-site-now/ | <a href="https://web.archive.org/web/*/https://privateanalytix.com/2020/08/03/6-reasons-why-you-should-stop-using-google-analytics-on-your-web-site-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://privateanalytix.com/2020/08/03/6-reasons-why-you-should-stop-using-google-analytics-on-your-web-site-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044725</guid>
            <pubDate>Mon, 03 Aug 2020 23:30:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Club P., an anonymous discussion board]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24044574">thread link</a>) | @DeusExMachina
<br/>
August 3, 2020 | https://sometimesright.com/2020/08/03/club-p/ | <a href="https://web.archive.org/web/*/https://sometimesright.com/2020/08/03/club-p/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<blockquote>
  <p><em>Man is least himself when he talks in his own person. Give him a mask, and he will tell you the truth. —Oscar Wilde</em></p>
</blockquote>

<p>For fun over the past few weeks I’ve been working on a little project that I’m launching today. It’s called <a href="https://club.sometimesright.com/">Club P.</a> and it’s an anonymous and ephemeral discussion board like 4chan, but membership-based. So why did I make this?</p>

<p>Like many people, I’m increasingly frustrated with social media. Speech policing and growing pressure to conformity are leading me and many others to retreat to what Venkatesh Rao calls the <a href="https://breakingsmart.substack.com/p/the-extended-internet-universe">cozyweb</a>:</p>

<blockquote>
  <p>Unlike the main public internet, which runs on the (human) protocol of “users” clicking on links on public pages/apps maintained by “publishers”, the cozyweb works on the (human) protocol of everybody cutting-and-pasting bits of text, images, URLs, and screenshots across live streams. Much of this content is poorly addressable, poorly searchable, and very vulnerable to bitrot. It lives in a high-gatekeeping slum-like space comprising slacks, messaging apps, private groups, storage services like dropbox, and of course, email.</p>
</blockquote>

<p>Kickstarter founder Yancey Strickler talks about a “<a href="https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1">dark forest theory of the internet</a>”:</p>

<blockquote>
  <p>In response to the ads, the tracking, the trolling, the hype, and other predatory behaviors, we’re retreating to our dark forests of the internet, and away from the mainstream.</p>

  <p>This very piece is an example of this. This theory was first shared on a private channel sent to 500 people who I know or who have explicitly chosen to receive it. This is the online environment in which I feel most secure. Where I can be my most “real self.”<br>
…<br>
Dark forests like newsletters and podcasts are growing areas of activity. As are other dark forests, like Slack channels, private Instagrams, invite-only message boards, text groups, Snapchat, WeChat, and on and on. This is where Facebook is pivoting with Groups (and trying to redefine what the word “privacy” means in the process).</p>

  <p>These are all spaces where depressurized conversation is possible because of their non-indexed, non-optimized, and non-gamified environments. The cultures of those spaces have more in common with the physical world than the internet.</p>
</blockquote>

<p>Why the reaction? There are many reasons, but here’s what I think about.</p>

<p>On social media platforms like Twitter, users have a persistent identity (even if, rarely, it is a pseudonym). This fosters completely natural incentives for <a href="https://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/">status competition</a>, but those incentives are unnaturally exacerbated by the <a href="https://www.amazon.com/Digital-Minimalism-Choosing-Focused-Noisy-ebook/dp/B07DBRBP7G/">gamification</a> inherent in likes, retweets, and follower counts. Additionally, your view on the world is limited by the set of people you have chosen to follow, as well as how a platform’s algorithm has chosen to present their messages. The result is conversation that is often performative and susceptible to groupthink and tribalism.</p>

<blockquote><p lang="en" dir="ltr">Show me a writer's audience, and I'll show you their opinions.</p>— Antonio García Martínez (@antoniogm) <a href="https://twitter.com/antoniogm/status/1288156495947821056?ref_src=twsrc%5Etfw">July 28, 2020</a></blockquote>


<p>An interesting alternative mode of online conversation that is still public, and not cloistered, is that of anonymous “<a href="https://en.wikipedia.org/wiki/Imageboard">imageboards</a>” made (in)famous by 4chan. They are web discussion forums with no user registration and no identities tied to posts. Postings are also ephemeral and are erased after a short time. Thanks to this architecture, imageboards foster a very different kind of conversation. Because there are no usernames, no follower counts, and no likes or retweets, there is no ego or status-seeking tied to users’ expressions. Because user content is presented chronologically, and neither you nor an algorithm curate what you see, you’re exposed to a greater set of expressions. Without identity everyone’s expression is on equal footing and can be judged on its own merits regardless of its authorship.</p>

<p>Such a peculiar arrangement can engender unreserved contributions to group creativity, which is why the origins of so much of what we take for granted as “internet culture” today—from lolcats to rickrolling—can be traced back to 4chan. As Hao Li has <a href="https://www.ibtimes.com/anonymity-internet-4chan-277953">put it</a>,</p>

<blockquote>
  <p>Anonymity frees individuals from the burden of the ego, which is afraid of judgment, wants recognition, and acts defensively towards disagreements from others.  In a collaborative environment, it blocks creativity and distorts incentives. When the ego is removed, unfiltered and raw truth comes out. … Once the ego is gone, anonymous individuals identify with an amorphous entity that transcends individuality. It’s not that online anonymity leads to groupthink; it actually encourages creativity and non-conformity. Instead, anonymity brings individuals closer through cutting the personal prejudices and allegiances that divide them apart in real life.</p>
</blockquote>

<p>Of course, as 4chan itself shows, anonymity can have a very dark side. Without identity there is no accountability, and without account registration there is no way to screen out trolls and troublemakers. So, I’ve been doing a lot of thinking about how we might be able to get the good of an anonymous discussion forum without so much of the bad. What I’ve come up with is <a href="https://club.sometimesright.com/">Club P.</a> and I’m launching it today.</p>

<p>Club P. is essentially an anonymous discussion forum but with important differences compared to traditional imageboards. Most significantly, you have to be a member to post, and membership costs $2 per month. That’s a modest amount that after hosting and service fees should leave me no profit, but it will be a barrier to entry that I hope will screen in earnest folks. Membership means that, unlike completely anonymous forums, users do have to create an account, which will help with moderation. No identifying information will ever be presented on the site—no username, nor email address, nothing. On the backend, however, users are assigned a unique alphanumeric ID (like 5f20bwcd1f516020410b8e9) and their posts are associated with that ID so that, if I had to do it, I could ban the author of a particular post without ever knowing their name.</p>

<p>The functionality of the site is very simple. On the homepage is a listing of all threads posted in the last 48 hours. After 48 hours threads are deleted, so all conversations are ephemeral. (I would like to eventually bring that down to 24 hours or less.) Anyone can read the threads, but only logged-in members can start new threads and post replies to existing threads. Search engines are directed not to index the site, so posts should not show up in search results.</p>

<p>The design of the site is heavily influenced by Joel Spolsky and Jeff Atwood’s thinking on forum architecture. Threads are <a href="https://blog.codinghorror.com/web-discussions-flat-by-design/">flat rather than presented in a tree structure</a>. If a link to a thread is blue on the homepage, then either you haven’t visited it or there is a new reply post you haven’t seen. Once you’re logged in, posting new threads and replying to existing ones is effortless. Messages (both initial posts and replies) are limited to 2,020 characters in honor of this exceptional year.</p>

<p>I also plan to crib from Spolsky’s <a href="https://www.joelonsoftware.com/2003/03/03/building-communities-with-software/">moderating philosophy</a>, which means I don’t have to post a list of content rules because we all have a good sense of what’s clearly in-bounds and what’s not. As Spolsky says, “posting rules is just a way to insult the majority of the law-abiding citizens and it doesn’t deter the morons who think their own poo smells delicious and nothing they post could possibly be against the rules.” Things will get deleted when they have to be and users will be kicked out when necessary, but I hope we can avoid that, and I think the fact we’ll all be members of a club will help.</p>

<p>One frequent question from beta testers was, <strong>“How is this anonymous if you have my email and credit card info?”</strong> The answer is that it’s not. It’s an anonymous discussion forum in the sense that users posting in the forum will be anonymous to everyone reading those posts. But yes, unlike 4chan, you do have to create an account with personal info to use the site, so in that way it’s not completely anonymous … which is kinda the point! In the end, though, I will have no more info about you than Jack does if you have a pseudonymous Twitter account. In fact, I will have less info because I do not collect your name, only the email address you use at sign-up (feel free to use a throwaway), and your credit card info stays with Stripe and I never see it.</p>

<p>Finally, let me say this is just an experiment to see if we can get the benefits of anonymous forums with less of the downsides. It’s a fun hobby project for me and that’s it. I reserve the right to change the variables described above and to shut the whole thing down if it doesn’t work out, but I hope it does. And I welcome you to join me in this experiment. <a href="https://club.sometimesright.com/#/ms/signup/5f177770a57015000438bdea">Sign up now.</a></p>

	</div></div>]]>
            </description>
            <link>https://sometimesright.com/2020/08/03/club-p/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044574</guid>
            <pubDate>Mon, 03 Aug 2020 23:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical attractiveness bias in the legal system (2017)]]>
            </title>
            <description>
<![CDATA[
Score 392 | Comments 377 (<a href="https://news.ycombinator.com/item?id=24044409">thread link</a>) | @simonebrunozzi
<br/>
August 3, 2020 | https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system | <a href="https://web.archive.org/web/*/https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">

      

      

      
        
          
            
              
                
              
            
          
        
      


      
      
      

      <main id="page" role="main">
        
        <!--
        --><!--
        --><div id="content" data-content-field="main-content" data-collection-id="5817e1ff3e00be2eafd0dec4" data-edit-main-image="">
         <div>

  
  <article id="article-58c757b5e4fcb5bd2d9613d5" data-item-id="58c757b5e4fcb5bd2d9613d5">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1489459192059" id="item-58c757b5e4fcb5bd2d9613d5"><div><div><div data-block-type="2" id="block-yui_3_17_2_3_1489466160916_36894"><div><blockquote><p><a href="http://bit.ly/2m8beq4" target="_blank">[Download for PDF/printable version of this article]</a><br></p></blockquote><p>When I started looking into this subject, I predicted a person’s physical attractiveness would only have minor advantages. I was wrong.</p><p>In fact, I was so wrong, that in one study, the effects of physical attractiveness on judges were so influential, they fined unattractive criminals 304.88% higher than attractive criminals.</p><p>Surprising, I know.</p><p>Before we proceed, I want to address a few concerns of mine. Firstly, the information that you will read may cause some readers to feel unsettled. This is not my intention. Yes, it is disheartening. But the purpose of this article is to inform lawyers and other decision makers so that they can use the attractiveness bias to their advantage or to counter it.</p><p>A second concern of mine is that I don’t want to over-emphasise the attractiveness bias. Judges and jurors are affected by all kinds of cognitive distortions, such as emotive evidence, time of day, remorse of the defendant, socioeconomic status, race, gender, anchoring effect, and the contrast bias.</p><p>In the first section of this article, I give a ‘straight-to-the-point’ summary of the research conducted by 27 studies. Next, I enter into greater depth on the attractiveness bias and its effects on judges, jurors, and lawyers. Lastly, I provide research on the attractiveness bias in everyday life. Arguably, the last section is the most interesting.</p><p>Enjoy!</p><p>* * *</p><ol data-rte-list="default"><li><p>Physical Attractiveness had a significant influence on judges sentencing. The more unattractive the criminal, the higher the sentence. Or conversely, the more attractive the criminal, the lower the sentence. The results of three studies show a minimum increase of 119.25% and a maximum increase of 304.88%.<br></p></li><li><p>Attractiveness had little to no effect on a judge’s verdict of guilt. Attractive and unattractive criminals were convicted equally.<br></p></li><li><p>Mock jurors generally sentenced unattractive criminals significantly higher than attractive criminals. However, as jurors do not determine sentencing in real court cases, these results are not directly applicable.<br></p></li><li><p>Attractiveness had minor effects on mock juror’s verdicts. Some studies reported minor effects and some studies reported no effects.<br></p></li><li><p>Generally, attractive people are perceived as more intelligent, more socially skilled, more appealing personalities, more moral, more altruistic, more likely to succeed, more hirable as managers, and more competent. Attractive people tend to have better physical health, better mental health, better dating experiences, earn more money, obtain higher career positions, chosen for jobs more often, promoted more often, receive better job evaluations, and chosen as business partners more often, than unattractive people.<br></p></li><li><p>I believe that the attractiveness bias is rarely conscious. I do not think people are consciously disfavouring unattractive people. I also do not place moral blame on the typical person for their unconscious bias.</p></li></ol><p>* * *</p><h2><strong>REAL JUDGES: SENTENCING</strong></h2><p><strong>THE MISDEMEANOUR STUDY </strong><em>[1]</em></p><p>The first study we will observe is the research conducted by Downs and Lyons.</p><p>The purpose of this study was to find a link between a criminal’s attractiveness and sentencing outcomes.</p><p>They gathered a group of police officers and students to rate the attractiveness of over 2000 criminals. A scale of 1 - 5 was used and their ratings were mostly similar.</p><p>Then, the judges sentencing decisions were divided into two main categories: misdemeanors and felonies. Misdemeanors were separated into to 3 classes, related to the severity of the crime.</p><p><em>The Results &amp; Key Takeaways</em></p><p>For misdemeanours, the judges fined unattractive criminals significantly more than attractive criminals. The fine incrementally increased as the attractiveness decreased.</p><p>1.&nbsp;&nbsp;&nbsp;&nbsp; Minor Misdemeanours = +224.87%</p><p>2.&nbsp;&nbsp;&nbsp;&nbsp; Moderate Misdemeanours = +304.88%</p><p>3.&nbsp;&nbsp;&nbsp;&nbsp; Serious Misdemeanours = + 174.78%</p><p>The results are graphed below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_48500"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image-dimensions="1047x619" data-image-focal-point="0.5,0.5" alt="Image test 1.jpg" data-load="false" data-image-id="58c89366f7e0ab29642796d9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_48699"><div><p>Curiously, felony fines had no correlation with the attractiveness of the criminal. The study does not make it clear why this is the case.</p><p><em>Answers to Possible Objections</em></p><ul data-rte-list="default"><li><p>The judges varied in gender and race.</p></li><li><p>There was no correlation between sentencing outcomes and age, gender, and race.</p></li></ul><p><em>Weaknesses</em></p><p>For privacy reasons, the specific crime was not documented.</p><p>The direction of causation is not known. I enter into more depth in the section entitled ‘causation’.</p><p><strong>THE PENNSYLVANIAN STUDY<em> </em></strong><em>[2]</em></p><p>In Pennsylvanian and Philadelphian courts, the researcher’s gathered data on 67 defendants. The defendants were a mix of black, Hispanic, and white and there were 15 real judges in total.</p><p><em>Results &amp; Key Takeaways</em></p><p>On average (mean), criminals of low attractiveness were sentenced to 4.10 years in prison and criminals of high attractiveness were sentenced to 1.87 years in prison. This equals a 119.25% increase.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_71526"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image-dimensions="1095x642" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75991e6f2e16d0cb71613" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_71724"><div><p><em>Weaknesses</em></p><p>All observers were white.</p><p><strong>THE SECOND PENNSYLVANIAN STUDY</strong> <em>[3]</em></p><p>This study was similar to the previous study. The researchers recorded data from real court cases in Pennsylvania. They detailed the physical attractiveness of 60 defendants and their neatness, cleanliness, and quality of clothing. Then, they recorded the judge’s decisions.</p><p>The criminals were charged with a range of felonies, including ‘murder; manslaughter; rape; kidnapping; armed robbery; aggravated assault; indecent assault; arson; burglary; conspiracy to sell/delver heroin, cocaine, hashish, and other elicit drugs; extortion; fraud; theft; and firearms violation.’</p><p>They were also a mix of white, Hispanic and black.&nbsp;</p><p><em>Results &amp; Key Takeaways</em></p><p>The unattractive defendants were punished higher than the attractive defendants.</p><p><em>Weaknesses</em></p><p>The study did not give specific results. This is a major disappointment.</p><p><strong>CONCLUSIONS</strong></p><p>Unattractive criminals were punished higher than attractive criminals in three studies. The lowest increase was at 119.25% and the highest increase was at 304.88%.</p><h2><strong>REAL JUDGES: VERDICT, GUILTY OR NOT-GUILTY</strong></h2><p>There was no association between the defendant’s physical attractiveness and the judge’s verdict. Attractive and unattractive criminals were found guilty at equal rates. Zebrowitz and McDonald [4]&nbsp;also found that the plaintiff’s attractiveness had little to no effects on a judge’s verdict.</p><p><strong>THE BABY-FACED STUDY </strong><em>[5]</em></p><p>The following study is not directly related to physical attractiveness but it is related to physical appearance.</p><p>Zebrowitz and McDonald measured the effects of defendants with a ‘baby-face’ and the judge’s verdict decisions. This is a strange characteristic to measure, however, the results were significant enough to warrant attention.</p><p>‘Baby-faced adults tend to have larger eyes, thinner, higher eyebrows, a large forehead and a small chin, and a curved rather than an angular face.’<em>[6]</em>&nbsp;A team of participants sat in 421 cases in ‘6 branches of the Commonwealth of Massachusetts small claims courts. 3 judges heard 51% of the cases and the remaining 49% of the cases were presided over by 22 additional judges.’ ‘62% of the plaintiffs and 78% of the defendants were male. 96% of both plaintiffs and defendants were white, and 81% were between the ages of 21 and 50.’</p><p><em>Results &amp; Key Takeaways</em></p><p>The more baby-faced an adult was, the less likely he/she was found to be guilty for ‘intentional actions’ in civil claims. Observe the graph below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_91414"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image-dimensions="2500x2137" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75a7ed482e9a66b47537e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_91612"><div><p>Interestingly, baby-faced adults had no effects in claims of negligent actions.</p><h2><strong>MOCK JURY: SENTENCING</strong></h2><p>Before I present the following research, I need to address a major limitation. Jurors do not decide upon sentencing, thus, the following results may not have direct application.</p><p><strong>THE META-ANALYSIS STUDY </strong><em>[7]</em></p><p>A meta-analysis examined 25 studies on the effects of physical attractiveness on mock jurors. They found that mock jurors gave higher sentences to unattractive criminals than attractive criminals. This was only for crimes of rape, robbery, and negligent homicide. For swindle, the punishment was equal. The physical attractiveness of the victim also had no effects on the jurors.</p><p><strong>THE BURGLARY STUDY </strong><em>[8]</em></p><p>In this study, the participants were given a burglary scenario along with an image of the criminal. Some received the unattractive criminal and others received the attractive criminal. 10 psychology students rated the attractiveness of the criminals prior to the study to determine attractiveness.</p><p>Then, they were asked to suggest a 1, 5, 10, 15, or 20 years imprisonment.</p><p>‘[The] participants consisted of 40 Euro-American men, 40 Euro-American women, 40 African- American men, and 40 African-American women.’ A strength of this study is the participants ranged in race, gender, and age.</p><p><em>Results &amp; Key Takeaways</em></p><p>The attractive criminal was given an average sentence of 9.7 years, and the unattractive criminal was given 14.7 years. That’s an increase of 51.55%.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_8_1489459079955_11521"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image-dimensions="1098x643" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75b829de4bb5cb740f698" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_8_1489459079955_11721"><div><p><em>Weaknesses</em></p><p>The researchers measured more items than simply attractiveness. This means that the 160 participants were not all measured on attractiveness. As they measured 8 different items and only two of them on attractiveness, I infer …</p></div></div></div></div></div></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</a></em></p>]]>
            </description>
            <link>https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044409</guid>
            <pubDate>Mon, 03 Aug 2020 22:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Get better at spotting mistakes with a random bug generator (in Elm)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24044401">thread link</a>) | @michaelpb
<br/>
August 3, 2020 | https://kickstartcoding.online/learn/articles/introducing-debug-trainer/ | <a href="https://web.archive.org/web/*/https://kickstartcoding.online/learn/articles/introducing-debug-trainer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<div>
<h2>The Problem</h2>
<p>It’s possible to build some pretty nifty applications without having a good understanding of how the code is working. You copy and paste some online examples here, you try random things until one of them works there, and eventually you’ve got a sort of copy-pasted Rube Goldberg machine that basically works even if you’re not entirely sure how.</p>
<p>Eventually, though, something is going to go wrong that cannot be fixed without a decent understanding of what’s going on under the hood. And when that does happen it is scary and stressful and not at all the best time to discover that the plumbing of your code is a deep, impenetrable mystery.</p>
<p><img src="https://kickstartcoding.online/media-content/share/1596486778/372/" alt="dialog box that says error, please contact support"></p>
<p>Getting practice understanding your code and fixing problems with it before things like that happen can be incredibly helpful. Unfortunately, the only way to get practice fixing broken code is for your code to break, and broken code doesn’t happen when it’s convenient and you’d like some practice.</p>
<p>Although I think most coding schools have debugging exercises here and there, I have spent a lot of time wishing that we had some better ways to give students more regular practice with debugging.</p>
<p>Recently, I finally got a chance to take the time to sit down and write a tool for debugging practice that I’ve been thinking about making for a while to solve this exact problem.</p>
<h2>Introducing debug_trainer!</h2>
<p><a target="_blank" href="https://github.com/kickstartcoding/debug_trainer"><code>debug_trainer</code></a> is a terminal program that breaks your code! Run the <code>break</code> command on a file of your choice and it will introduce a random breaking change into that file (or several changes if you’re feeling adventurous). Then you, the programmer, can put your debugging skills to work and try to find the change that was made.</p>
<p>Let's say you've got a file, <code>my_file.py</code>, that looks like this:</p>
<div><pre><span></span><span>def</span> <span>greet</span><span>(</span><span>name</span><span>):</span>
    <span>print</span><span>(</span><span>"Hello, "</span> <span>+</span> <span>name</span> <span>+</span> <span>"!"</span><span>)</span>

<span>greet</span><span>(</span><span>"Stacey"</span><span>)</span>
</pre></div>
<p>You'd run <code>debug_trainer</code> like this:</p>
<pre><code>&gt; debug_trainer break my_file.py 


Breaking my_file.py...


...done!


Good luck debugging! I believe in you! Don't forget to make your program print things out if you don't know what they are. ❤️
</code></pre><p>And it might, for example, change the file to this (see the error?):</p>
<div><pre><span></span><span>def</span> <span>greet</span><span>():</span>
    <span>print</span><span>(</span><span>"Hello, "</span> <span>+</span> <span>name</span> <span>+</span> <span>"!"</span><span>)</span>

<span>greet</span><span>(</span><span>"Stacey"</span><span>)</span>
</pre></div>
<p>The changes it can make are all based on common issues I’ve seen students struggle with. It might change the first letter of a variable name from capital to lowercase. It might remove the word ”return” from a return statement in a function. It might rearrange or remove the arguments in a function declaration. Malevolent!</p>
<p>If you get stuck, you can ask <code>debug_trainer</code> to give you some hints with the <code>error-type-hint</code> and <code>line-hint</code> commands. <code>error-type-hint</code> will tell you what kind of change it made (for example, “somewhere in this file, <code>debug_trainer</code> changed the arguments to a function”). <code>line-hint</code> will tell you what line the change was made on. If you get really stuck, you can have it tell you exactly what it did with the <code>explain</code> command.</p>
<pre><code>&gt; debug_trainer error-type-hint my_file.py

HINT: somewhere in this file, debug_trainer changed the arguments to a function.
</code></pre><pre><code>&gt; debug_trainer line-hint my_file.py

HINT: The line where the change was made was line 1 of the original file.
</code></pre><pre><code>&gt; debug_trainer explain my_file.py

removed the name argument from greet on line 1 of the original file
</code></pre><p>And once you’re done, whatever file <code>debug_trainer</code> changed, you can reset it back to it’s working state with the <code>reset</code> command. Then you can do the same thing all over again as many times as you want!</p>
<pre><code>&gt; debug_trainer reset my_file.py

my_file.py has been reset!
</code></pre><p>I’m pretty excited about <code>debug_trainer</code> and I would love to get feedback, advice, suggestions for additional types of errors or new features, etc. I’d also like to give a special thank you to Dillon Kearns, without whose brilliant <a target="_blank" href="https://github.com/dillonkearns/elm-cli-options-parser">tools</a> and <a target="_blank" href="https://github.com/dillonkearns/elm-cli-options-parser/tree/master/examples">examples</a> I would not have been able to write this using my favorite language, Elm.</p>
<p>If you want to try it out yourself, just run</p>
<pre><code>npm install -g debug_trainer
</code></pre><p>to get started, then run the <code>debug_trainer</code> command to have it list all the commands and how to use them. Or check out the repo <a target="_blank" href="https://github.com/kickstartcoding/debug_trainer">here</a> or the npm package page <a target="_blank" href="https://www.npmjs.com/package/debug_trainer">here</a> for more details and usage examples.</p>
<p>And let me know on <a target="_blank" href="https://github.com/kickstartcoding/debug_trainer/issues">the issues page</a> if you have any issues or feature requests!</p>
<p>[error image by <a target="_blank" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=102075">Gerd Altmann</a> from <a target="_blank" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=102075">Pixabay</a>]</p>
</div>
</div>
</div>
</div><div>

<p>Continue your coding journey with Kickstart Coding's unique online program.</p>
</div></div>]]>
            </description>
            <link>https://kickstartcoding.online/learn/articles/introducing-debug-trainer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044401</guid>
            <pubDate>Mon, 03 Aug 2020 22:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3 reviews newsletters that reviewed GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24044242">thread link</a>) | @jesswebster01
<br/>
August 3, 2020 | https://narrowscale.com/blog/gpt-3-gets-into-the-business-of-reviewing-newsletters.html | <a href="https://web.archive.org/web/*/https://narrowscale.com/blog/gpt-3-gets-into-the-business-of-reviewing-newsletters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p dir="ltr">GPT-3, the most powerful language model to date, has been all the rage in the tech industry lately. If you don’t know much about it, here are two pretty good pieces that explain: Azeem Azhar’s <a href="https://www.exponentialview.co/p/a-short-history-of-knowledge-technologies">Exponential View newsletter </a>(which also goes into the history of “knowledge technologies”) and <a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/">MIT Technology Review.</a></p>

<p>As expected, many newsletters have been discussing GPT-3 too--&nbsp;and <strong><span>we thought it would be fun to give GPT-3 the opportunity to review them back.</span>&nbsp;</strong></p>



<h2 dir="ltr">Here’s what GPT-3 had to say:</h2>

<p dir="ltr">(Note: Each one has a <em>title </em>for the review and then the review itself.)</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/future-of-finance.html">The Fintech Blueprint</a></h3>

<p dir="ltr"><em>The future of fintech is here and it’s better than you think</em></p>

<p>Who doesn't want more blockchain in their inbox? The Fintech Blueprint is a daily, blockchain-focused newsletter that picks out only the best stories on the burgeoning industry. With rising coin prices, hacks, ICOs, and so many other stories, the Fintech news is never ending. Keep up with the best in one spot, without the clutter.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/import-ai.html">Import AI</a></h3>

<p dir="ltr"><em>It's like an AI, but it isn't really. It just tells you what to do and how to think all day long.</em></p>

<p>Since I work at a company in the field of artificial intelligence, I try to follow what's going on in the field. This typically means going to a lot of conferences, reading tons of papers, and keeping up with research coming out. There's no real way to do this but to just put in the time. That being said, I usually don't have the energy to do this until I've woken up, so I rely on newsletters and Import AI is probably my most looked forward to in the morning. It's usually the most accurate and well-written.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/moontower-by-kris-abdelmessih.html">Moontower</a></h3>

<p dir="ltr"><em>The Dark Side of the Moon</em></p>

<p>Moontower is a daily or weekly (you can set your preferences) curated newsletter of the top tech news. It takes a simple, no-nonsense approach to the news and it has some fantastic content. What I really love about it is the content is far less "clickbait-y" than most tech newsletters. Clickbait tends to get old and any decent reader can see right through it. Moontower has quality content that is always interesting and I look forward to receiving it daily.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/minutes.html">Minutes</a></h3>

<p dir="ltr"><em>It's Not Going to Change Your Life, But You Might Enjoy Reading It Anyway.</em></p>

<p>minutes is a newsletter created by Eyeo, the company that makes AdBlock. I get why you might be skeptical of them given that they're not a "traditional news outlet". However, when I learned that they only make the product because advertising dampens the experience of using the internet to an alarming degree, it won me over. Using their own product, I have to say minutes creates a great newsletter. They link out to a variety of different articles, all of which are relevant to web-dev/technology in one way or another. I always feel like I'm staying up-to-date with the latest news in the space.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/marketing-bs-with-edward-nevraumont.html">Marketing BS with Edward Nevraumont</a></h3>

<p dir="ltr"><em>A guide To The Most Common Marketing Myths And How They're All Wrong!</em></p>

<p dir="ltr">As a CMO and working on my MBA, I can appreciate the value that 'Marketing BS' brings to the table. It is chock full of great information that is delivered in an organized and useful format that has, on many occasions, provided me with insight and ideas that I wouldn't have thought of on my own. Sometimes it even gets me thinking about things in ways I never had before. I believe that 'Marketing BS' is an invaluable resource that has already paid for itself and then some. Thanks!</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/desk-of-tobias-van-schneider.html">Desk of Tobias van Schneider</a></h3>

<p dir="ltr"><em>Tobias' Desk is a Good Place to Start Your Day, and It's Not Even in New York City!</em></p>

<p>I have been a regular reader of the Desk of Tobias Van Schneider for several years. Before that, I used to watch his newsletter's author's YouTube Channel, which he hasn't done in a while but is still up. I absolutely love the humor, wit and depth of his writing. He offers so much advice that is very helpful for me as a creative marketer at a tech company. He's provided super-useful career advice, lessons learned in his own journey, and other insights that are just great for anyone with a creative bone in their body.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/operators-and-delians-ramblings.html">Operators &amp; Delian's Reamblings</a></h3>

<p dir="ltr"><em>The Operator's Guide to Delian's Ramblings.</em></p>

<p dir="ltr">The Operators Delian's Ramblings, written by Delian Smarts, is a curation of some of the greatest recent writing on the net. The newsletters I was subscribed to were all niche and highly technical. Delian's Reamblings is an absolute breath of fresh air in that regard, and the absolute best part about it? It's weekly! Delian's choices have always been super high quality, and I look forward to it every week.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/data-science-weekly.html">Data Science Weekly</a></h3>

<p dir="ltr"><em>The Future is Data Science Weekly</em></p>

<p>DSW is a weekly must-read. There is a lot going on in the world of data science, and staying up to date and knowing what's important is really tough. The DSW newsletter does that for you! They link to all the latest articles from around the web, and filter out all the noise.</p>

<p dir="ltr">Most Importantly... it's fun! I look forward to it every week.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/maker-mind-by-anne-laure-le-cunuff.html">Maker Mind</a></h3>

<p dir="ltr"><em>The Future is Here, and It's Going to Be Awesome.</em></p>

<p>I read as many news letters as I can when it comes to self-improvement and personal development. I think it's one of the most important things a human being can endeavor to do. I'm actually subscribed to dozens of them. Many are great. This one is the best. Of all of them, this is the one I can't do without and look forward to every week. Great stuff!</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/the-nutgraf.html">The Nutgraf</a></h3>

<p dir="ltr"><em>Nutrition For The Masses</em></p>

<p>I love this one. It's simple, easy to digest, and always has important information that I never knew. The world of business is pretty complex and overwhelming, but they have a great way of explaining it. It's too bad I only found out about this one AFTER I had already started my own company! For all those future entrepreneurs out there, start reading this one as soon as you can!</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/axios-science.html">Axios Science</a></h3>

<p dir="ltr"><em>The Future of Journalism is…</em></p>

<p>There are several science-based newsletters, and they're all great, but Axios Science just gives you the news straight up. No weird metaphors or crazy scientists behaving eccentrically. Some days it's the most exciting thing I read all week, other days it's just a good way to get a non-partisan understanding of where the science field is at.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/mikes-newsletter-by-mike-lewis.html">Mike's Newsletter</a></h3>

<p dir="ltr"><em>It's Mikey And He Has Great Taste</em></p>

<p>Mike's Newsletter is the source for an ever-constant source of quirky and fascinating stories about the world around us. I've learned about everything from Native American role-reversals with Christian missionaries, to random facts about the far reaches of space. No matter what area you're interested in, Mike can probably make it interesting.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/exponential-view.html">Exponential view</a></h3>

<p dir="ltr"><em>The future is here, it's just not evenly distributed yet.</em></p>

<p>A few months ago I was ranting on Facebook about singularity and how I hate the fact that people aren't writing about it enough. One of my friends suggested this newsletter by Azeem Azhar, and while it's not singularity focused, it is focused on exponential technology and all that entails. I'm about 3 months in and absolutely loving the newsletter. Every edition has a theme and mixes commentary with article snippets that are linked to for further reading. It really is great stuff and an enjoyable read!</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/the-weekly-chartr.html">Chartr</a></h3>

<p dir="ltr"><em>It's not really that bad.</em></p>

<p>The best way to stay informed is by consuming all news all the time. The problem is, you'll get burned out by being overwhelmed by constant stress and anxiety. You can slow it down and Chartr is my go-to. Besides, the financial insights alone are enough to justify signing up.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/water-music.html">Water &amp; Music</a></h3>

<p dir="ltr"><em>The Best of Water Music</em></p>

<p>Water &amp; Music by Cherie Hu is a must-read. It sends music news &amp; industry related tidbits that are most definitely from an insider's point of view. Its content is second to none as far as newsletters go. You'll definitely walk away learning something new every time.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/inside-business.html">Inside Business</a></h3>

<p dir="ltr"><em>The New Year's Mailbag</em></p>

<p>‘Inside Business' is yet another great daily newsletter that keeps you up to speed on the latest business and marketing news. They really pack in a lot of information in a small amount of words, and it's always good quality stuff. I've come to appreciate business a lot more since I subscribed to this newsletter.</p>

<h3 dir="ltr">...and here are a few bonus ones that didn’t mention GPT-3 but GPT-3 offered opinions on just for giggles&nbsp;</h3>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/the-diff-by-byrne-hobart.html">The Diff</a></h3>

<p dir="ltr"><em>A Guide to the New World Order&nbsp;</em></p>

<p>The Diff is a trusted source of information with some fun thrown in for good measure. Since the rise of AI and machine learning, a lot of white-collar workers have been apprehensive about their jobs, well, at least those that are repetitious or involve data entry. This tech newsletter does a great job at presenting an alternate view and options so that its subscribers don't have to worry.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/parentdata-by-emily-oster.html">ParentData</a></h3>

<p dir="ltr"><em>The newsletter that doesn't suck and is really useful for parents of young children.&nbsp;</em></p>

<p>There are huge piles of books on parenting and thousands upon thousands of articles from magazines and journals, so how could anyone keep up with it all? The answer is simple: they can't. That is why ParentData was created. They deal with topics on Infant &amp; Toddler development, strategies to motivate your child, discipline tips, what children are Learning, health and safety guidelines, teenage issues and good nutrition. Some of the top stories from a recent newsletter include the importance of healthy eating and how your kids can improve their behavior.</p>

<h3><em><a href="https://narrowscale.com/newsletters/daily-skimm.html">The Skimm</a></em></h3>

<p dir="ltr"><em>Skimm is a very useful tool for your business</em></p>

<p dir="ltr">It's come under fire lately for not being the most diverse newsletter, but it's my favorite to start my day. I really enjoy the tone and the simple writing style. It's a nice reminder of what the day holds, and it usually makes me smile. I love having an outsider's look at the American elections, too.</p>

<h3 dir="ltr"><a href="https://narrowscale.com/newsletters/a-media-operator-by-jacob-cohen-donnelly.html">A Media Operator</a></h3>

<p dir="ltr"><em>The News-Ticker's Guide to Life in the 21st Century</em></p>

<p dir="ltr">A Media operator is a weekly digital news service that helps content creators, entrepreneurs and investors build a sustainable business on the internet.&nbsp;</p>

<p dir="ltr">Their weekly articles feature experts from top media companies like Business …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://narrowscale.com/blog/gpt-3-gets-into-the-business-of-reviewing-newsletters.html">https://narrowscale.com/blog/gpt-3-gets-into-the-business-of-reviewing-newsletters.html</a></em></p>]]>
            </description>
            <link>https://narrowscale.com/blog/gpt-3-gets-into-the-business-of-reviewing-newsletters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044242</guid>
            <pubDate>Mon, 03 Aug 2020 22:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Rust: Writing a CLI Tool]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24044043">thread link</a>) | @JeremyMorgan
<br/>
August 3, 2020 | https://cuchi.me/posts/go-vs-rust | <a href="https://web.archive.org/web/*/https://cuchi.me/posts/go-vs-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><img src="https://gist.githubusercontent.com/cuchi/59255d61717e2d469263eb86cf083067/raw/6ef1a42f335022adf481fb84cabc32ac47f18679/go-vs-rust.png" alt="Go vs. Rust"></p>
<p>This text is about my adventure writing a small CLI application (twice) using
two languages I had little experience with.</p>
<p>If you are eager to jump right into the code and compare it yourself, check it
out the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-go">Go source</a> and
the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-rust">Rust source</a>.</p>
<hr>
<h2>About the Project</h2>
<p>I have a <em>pet project</em> called Hashtrack, which is a full-stack web application I
wrote for a technical interview. This project is rather small and it is simple
to use:</p>
<ol>
<li>You authenticate - considering you already created your account</li>
<li>You input hashtags you want to track</li>
<li>You wait for the <em>captured</em> tweets to show on your screen</li>
</ol>
<p><a href="https://hashtrack.herokuapp.com/">Check it out here.</a></p>
<p>After my interview, I kept improving this project just for fun, and I noticed
that it could be a perfect place to test my skills by implementing a CLI tool. I
already had the server, so I just needed to pick a language to implement a small
set of features under my project's API.</p>
<h2>Features</h2>
<ul>
<li><code>hashtrack login</code> - Creates a session token and store it in the local
filesystem in a config file.</li>
<li><code>hashtrack logout</code> - Remove the locally stored session token.</li>
<li><code>hashtrack track &lt;hashtag&gt; [...]</code> - Tracks one or more hashtags.</li>
<li><code>hashtrack untrack &lt;hashtag&gt; [...]</code> - Untracks one or more previously tracked
hashtags.</li>
<li><code>hashtrack tracks</code> - Displays the hashtags you are tracking.</li>
<li><code>hashtrack list</code> - Displays the latest 50 captured tweets.</li>
<li><code>hashtrack watch</code> - Stream and display the captured tweets in real-time.</li>
<li><code>hashtrack status</code> - Displays who you are, if logged in.</li>
<li>Should have an <code>--endpoint</code> option to point the CLI to another server.</li>
<li>Should have a <code>--config</code> option to load a custom config file.</li>
<li>This config file could also share the <code>endpoint</code> property.</li>
</ul>
<p>What we have to know beforehand:</p>
<ul>
<li>The CLI should use the project's API, which is GraphQL under HTTP +
WebSockets.</li>
<li>The CLI should use the filesystem to store a config file.</li>
<li>The CLI should parse positional arguments and flags.</li>
</ul>
<h2>How did I end up using Go and Rust?</h2>
<p>There is a large set of languages you can use to write CLI tools.</p>
<p>In this case, I wanted a language I had little or no prior experience with, I
also wanted one that could easily compile to a native executable, which is a
nice perk to have on a CLI tool.</p>
<p>My first obvious choice was Go, maybe because a lot of CLI tools I use are
implemented using it. But I also had little experience with Rust, and I saw it
could also be a good fit for this project.</p>
<p>So... why not both? Since my main objective here is to learn, could be a great
opportunity to implement this project twice and find what are the <em>pros and
cons</em> of each one from my point of view.</p>
<blockquote>
<p>Honorable mentions to <a href="https://crystal-lang.org/">Crystal</a> and
<a href="https://nim-lang.org/">Nim</a>, those were very promising options too. I'm looking
forward to learn about them in another pet project.</p>
</blockquote>
<h2>Local environment</h2>
<p>The first thing I look when using a new toolset is whether it has an easy way to
make it available for my user, without using the distribution package manager to
install it system-wide. We are talking about version managers, they make our
life easier by installing the tools in a user-wide manner instead of
system-wide. <a href="https://github.com/nvm-sh/nvm">NVM</a> for Node.js does it very well.</p>
<p>When using Go, there is the <a href="https://github.com/moovweb/gvm">GVM</a> project which
handles the local install &amp; version management, and it is easy to setup:</p>
<pre><code>gvm install go1.14 -B
gvm use go1.14
</code></pre>
<p>There are also two environment variables we need to know, they are <code>GOROOT</code> and
<code>GOPATH</code> -- You can read more about them
<a href="https://www.jetbrains.com/help/go/configuring-goroot-and-gopath.html">here</a>.</p>
<p>The first <em>problem</em> I found using Go, was when I was figuring out how the module
resolution worked along with the <code>GOPATH</code>, it became quite frustrating to
set up a project structure with a functional local development environment.</p>
<p>In the end, I just used <code>GOPATH=$(pwd)</code> in my project's directory, the main perk
was to have a per-project dependency setup, like a <code>node_modules</code>. It worked
well.</p>
<blockquote>
<p>After finishing my project, I found out that
<a href="https://github.com/GetStream/vg">virtualgo</a> existed and would solve my problems
with <code>GOPATH</code>.</p>
</blockquote>
<p>Rust has an official project called <a href="https://rustup.rs/">rustup</a>, which manages
the Rust installation, also known as <em>toolchain</em>. It can be easily set up with a
one-liner. Also, there is a set of optional components using <code>rustup</code>,
such as the <a href="https://github.com/rust-lang/rls">rls</a> and
<a href="https://github.com/rust-lang/rustfmt">rustfmt</a>.
Many projects require a <em>nightly</em> version of the Rust toolchain, with <code>rustup</code>
there was no problem switching between the versions.</p>
<h3>Editor Support</h3>
<p>For both of the languages, editor tooling was flawless, as a VSCode user, I can
find extensions for both Go and Rust in the marketplace.</p>
<p>When debugging with Rust, I had to install the
<a href="https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb">CodeLLDB</a>
extension after following
<a href="https://www.forrestthewoods.com/blog/how-to-debug-rust-with-visual-studio-code/">this tutorial</a>.</p>
<h2>Package management</h2>
<p>Go doesn't have a package manager or even an official registry. Instead, its
module resolution works in a way you can import them from external URLs.</p>
<p>For dependency management, Rust uses the Cargo, which downloads and compiles
dependencies from <a href="https://crates.io/">crates.io</a>, which is the official
registry for Rust packages. Packages inside the Crates ecosystem can also have
their documentation available in <a href="https://docs.rs/">docs.rs</a></p>
<h2>Libraries</h2>
<p>My first objective was to see how easy could be to implement a simple GraphQL
query/mutation over HTTP.</p>
<p>For the Go language, I found some libraries, like
<a href="https://github.com/machinebox/graphql">machinebox/graphql</a> and
<a href="https://github.com/shurcooL/graphql">shurcooL/graphql</a>, the second one uses
structs for (un) marshaling the data, that is what made me stick to it.</p>
<blockquote>
<p>I used a fork of shurcooL/graphql, because I needed to set the
<code>Authorization</code> header in the client, the changes are in
<a href="https://github.com/shurcooL/graphql/pull/48">this pull request</a>.</p>
</blockquote>
<p>This is the Go example of an GraphQL mutation call:</p>
<pre><code><span>type</span> creationMutation <span>struct</span> {
    CreateSession <span>struct</span> {
        Token graphql.String
    } <span>`graphql:"createSession(email: $email, password: $password)"`</span>
}

<span>type</span> CreationPayload <span>struct</span> {
    Email    <span>string</span>
    Password <span>string</span>
}

<span><span>func</span> <span>Create</span><span>(client *graphql.Client, payload CreationPayload)</span> <span>(<span>string</span>, error)</span></span> {
    <span>var</span> mutation creationMutation
    variables := <span>map</span>[<span>string</span>]<span>interface</span>{}{
        <span>"email"</span>:    graphql.String(payload.Email),
        <span>"password"</span>: graphql.String(payload.Password),
    }
    err := client.Mutate(context.Background(), &amp;mutation, variables)

    <span>return</span> <span>string</span>(mutation.CreateSession.Token), err
}

</code></pre>
<p>In Rust, I had to use two libraries to make GraphQL calls. That is because
<code>graphql_client</code> is protocol-agnostic, it only focuses on code generation for
serializing and deserializing data. So I needed a second library (<code>reqwest</code>) to
take care of the HTTP requests.</p>
<pre><code><span>#[derive(GraphQLQuery)]</span>
<span>#[graphql(
    schema_path = <span>"graphql/schema.graphql"</span>,
    query_path = <span>"graphql/createSession.graphql"</span>
)]</span>
<span><span>struct</span> <span>CreateSession</span></span>;

<span>pub</span> <span><span>struct</span> <span>Session</span></span> {
    <span>pub</span> token: <span>String</span>,
}

<span>pub</span> <span><span>type</span> <span>Creation</span></span> = create_session::Variables;

<span>pub</span> <span>async</span> <span><span>fn</span> <span>create</span></span>(context: &amp;Context, creation: Creation) -&gt; <span>Result</span>&lt;Session, api::Error&gt; {
    <span>let</span> res = api::build_base_request(context)
        .json(&amp;CreateSession::build_query(creation))
        .send()
        .<span>await</span>?
        .json::&lt;Response&lt;create_session::ResponseData&gt;&gt;()
        .<span>await</span>?;
    <span>match</span> res.data {
        <span>Some</span>(data) =&gt; <span>Ok</span>(Session {
            token: data.create_session.token,
        }),
        _ =&gt; <span>Err</span>(api::Error(api::get_error_message(res).to_string())),
    }
}
</code></pre>
<p>Neither of the libraries for Go and Rust had any implementation for GraphQL via
WebSocket protocol.</p>
<p>In fact, <code>graphql_client</code> for Rust supports <em>Subscriptions</em>, but since it is
protocol-agnostic, I had to implement the whole GraphQL WebSocket communication
on my own,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-rust/src/tweet.rs#L90">check it out</a>.</p>
<p>To use WebSockets in the Go version, the library should be modified to support
the protocol. Since I was already using a fork of the library, I didn't feel
like doing it. Instead, I used a poor man's way of "watching" the new tweets,
which was to request the API every 5 seconds to retrieve them,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-go/src/hashtrack/tweets/tweets.go#L65">I'm not proud of it</a>.</p>
<p>Using Go, there is the <code>go</code> keyword to spawn a lightweight thread, also called
<em>goroutine</em>. In contrast, Rust uses operating system threads by calling a
<code>Thread::spawn</code>. Besides that, both implementations use channels to transfer
objects between their threads.</p>
<h2>Error handling</h2>
<p>In Go, errors are treated just like any other value. The common way to handle
errors in Go is to just check if they are present.</p>
<pre><code><span><span>func</span> <span>(config *Config)</span> <span>Save</span><span>()</span> <span>error</span></span> {
	contents, err := json.MarshalIndent(config, <span>""</span>, <span>"    "</span>)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	err = ioutil.WriteFile(config.path, contents, <span>0</span>o644)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	<span>return</span> <span>nil</span>
}
</code></pre>
<p>Rust has the <code>Result&lt;T, E&gt;</code> enum, which can encapsulate an <code>Ok(T)</code> for success,
or an <code>Err(E)</code> for errors. It also has the <code>Option&lt;T&gt;</code> enum, with <code>Some(T)</code> or
<code>None</code>. If you are familiar with Haskell, you may recognize
those as the <code>Either</code> and the <code>Maybe</code> monads.</p>
<p>There is also a syntactic sugar for error propagation (the <code>?</code> operator) that
resolves the value from the <code>Result</code> or <code>Option</code> structure, automatically
returning <code>Err(...)</code> or <code>None</code> when something goes bad.</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = serde_json::to_string(&amp;<span>self</span>.contents)?;
    <span>let</span> <span>mut</span> file = File::create(&amp;<span>self</span>.path)?;
    file.write_all(json.as_bytes())
}
</code></pre>
<p>The code above is the equivalent of</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = <span>match</span> serde_json::to_string(&amp;<span>self</span>.contents) {
        <span>Ok</span>(json) =&gt; json,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    <span>let</span> <span>mut</span> file = <span>match</span> File::create(&amp;<span>self</span>.path) {
        <span>Ok</span>(file) =&gt; file,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    file.write_all(json.as_bytes())
}
</code></pre>
<p>Rust has:</p>
<ul>
<li>monadic constructs (<code>Option</code> &amp; <code>Result</code>)</li>
<li>the error propagation operator</li>
<li>the <code>From</code> trait, to automatically convert errors on propagation</li>
</ul>
<p>The combination of the three features above makes up the best error handling
solution I saw in a language, being simple, sound, and maintainable at the same
time.</p>
<h2>Compilation time</h2>
<p>Go is built with fast compilation time as a critical requirement, let's see:</p>
<pre><code>&gt; time go get hashtrack 
go get hashtrack  1,39s user 0,41s system 43% cpu 4,122 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,80s user 0,12s system 152% cpu 0,603 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,19s user 0,07s system 400% cpu 0,065 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,94s user 0,13s …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cuchi.me/posts/go-vs-rust">https://cuchi.me/posts/go-vs-rust</a></em></p>]]>
            </description>
            <link>https://cuchi.me/posts/go-vs-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044043</guid>
            <pubDate>Mon, 03 Aug 2020 22:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One year of automatic DB migrations from Git]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24043987">thread link</a>) | @awinter-py
<br/>
August 3, 2020 | https://abe-winter.github.io/2020/08/03/yr-of-git.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/2020/08/03/yr-of-git.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last year-plus, for most of my solo work, I’ve used a tool called <a href="https://github.com/abe-winter/automigrate">automig</a> to automatically turn my SQL schema changes into deltas that can be applied to a DB
(plug – I wrote it).</p>

<p>I hate writing migrations because it feels like work a computer should know how to do,
and because in general there’s no guarantee that the migrations produce something equivalent to your ‘schema.sql’ or ORM definition.</p>

<p>(SQLAlchemy’s alembic has an <a href="https://alembic.sqlalchemy.org/en/latest/autogenerate.html">autogenerate feature</a> which compares a running DB to your ORM spec;
having a running DB in the loop for migration generation creates a different set of tradeoffs than automig, which analyzes the sql files directly).</p>

<p>This article is a pros and cons retrospective on that year.</p>

<ul id="markdown-toc">
  <li><a href="#pros" id="markdown-toc-pros">Pros</a></li>
  <li><a href="#cons" id="markdown-toc-cons">Cons</a></li>
</ul>

<h2 id="pros">Pros</h2>

<p><strong>I haven’t written a migration in 1+ years</strong>.
And I don’t love writing migrations.
My process to add a column has fewer steps.
This is a win.</p>

<p><strong>Simple and readable source of truth</strong>.
As long as you trust that the tool knows what it’s doing,
you can open up the <code>schema.sql</code> file (or whatever you choose to name yours) and get a schema that is <em>both</em>
a readable doc of what the database should have
and a reliable indicator of what the database actually has.</p>

<p><strong>Standard tool across different languages</strong>.
I’ve used automig on different python and golang projects and it doesn’t care.
It’s not linked to any design or tool decision inside the codebase.
Automig isn’t a standard tool, but if it were, it would be a portable skillset.</p>

<p><strong>No cluttered migrations dir</strong>.
More of a personal hygiene decision than a legit gripe, but migration directories aren’t my favorite; hundreds of files that do very little good.
Automig is also faster at reinitialization because you can start from git HEAD rather than applying hundreds of changes from the last 36 months.</p>

<p><strong>Turns something complicated into something simple and almost as good</strong>.
There are cons (see below) but there’s a bunch of migration-related work that I no longer think about.
I no longer dread adding a DB column or an index.
If my capabilities are less because the tool is simpler and declarative, that’s a tradeoff, but it’s one that I’ve lived with happily.</p>

<h2 id="cons">Cons</h2>

<p><strong>Data migrations not supported</strong>.
Automig is good at schema migrations but doesn’t have an easy way to transform columns or run code on your DB.
The tool has an answer to this in the roadmap.
For my own needs I’ve been able to work around this by doing two-step migrations with default values.</p>

<p>For larger users, data migrations involve lots of design (see for example github’s GH-OST tool).
In the future I think migrations should be a native feature in the DB –
you should upload a schema and specify whether migrations run up-front or on read.
And we shouldn’t tie type to storage locality.</p>

<p><strong>When something goes wrong, I have to fix it</strong>.
This is 50% a gripe about using a tool that I maintain and am the only user of.
But 50% a legit point that a ‘declarative diffing’ tool has more logic in it than migrations that you write yourself in SQL.
Running arbitrary SQL gives you a lot of flexibility and gives you infinite freedom to choose incompatible dialects.</p>

<p><strong>Extra lifting to integrate with ORMs</strong>.
Automig can generate SQLAlchemy definitions from your schema.sql, but that’s it.
If you use a single language / framework, defining your DB in an ORM is probably more useful than having it specified using SQL.</p>

<p><strong>Dialect support is no picnic</strong>.
When I switched from postgres to sqlite for some projects, it was a pain to support the different dialects.
I ran into things like different support for transactional DDL.</p>

<p>(Since I first wrote this I’ve seen comments from the skeema and migra committers.
Both of these tools support <em>only one</em> DB: mysql and postgres respectively, and rely on the DB to do the heavy lifting.
There are a lot of positives to this approach).</p>

<p><strong>Branch conflict issues + rebasing</strong>.
Any nonlinear git history can be a source of errors.
Automig has an <code>--opaque</code> switch to work around these, but manually-specified migrations are likely better at branches, especially if you need to support out-of-order changes.
I haven’t encountered these problems because I’m in solo codebases, but I can see there being issues in big teams who sometimes deploy from non-main branches.</p>

<p><strong>Migrating production involves up-front work</strong>.
If you use your main backend language / framework to run migrations, life is easy.
Automig has extra requirements: it needs to bundle the <code>.git</code> folder (i.e. whole history).
When I ran this on lambda, I had to also bundle a git binary, and my ubuntu binary <em>didn’t work</em>.
I spent a whole day learning how to build git statically before I realized I could just grab the centos one.
The good news is that this work only has to be done once per platform.</p>

<p><strong>Testing is annoying</strong>.
Because automig only works on committed changes, I sometimes have to do a few rounds of <code>git commit --amend</code> before things work.</p>

<p><strong>Column order</strong>.
Automig doesn’t guarantee column order (it does <code>add column</code> but not <code>add column b after a</code>).
This has caused issues with backup / restore.
It’s a problem with the tool but not necessarily with the approach of using git + sql as the source of truth.</p>

<p><strong>Weird parser</strong>.
My parser library is easily confused, especially by uppercase / lowercase and names that look like keywords.
And it’s multi-layer (I use python sqlparse and then wrap it), i.e. janky.
This isn’t an issue with the approach so much as the specific tools I use, but it causes problems.</p>






  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://abe-winter.github.io/2020/08/03/yr-of-git.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043987</guid>
            <pubDate>Mon, 03 Aug 2020 22:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enabling the Stripe and Lyft Platforms Through Modern Safety Science]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043952">thread link</a>) | @hannahblameless
<br/>
August 3, 2020 | https://www.blameless.com/blog/enabling-the-stripe-and-lyft-platforms-through-modern-safety-science | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/enabling-the-stripe-and-lyft-platforms-through-modern-safety-science">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://www.linkedin.com/in/jacobhscott/"><strong>Jacob Scott</strong></a> is an experienced engineer and enthusiastic participant in the resilience engineering community, having spent time caring for the technology systems powering high-growth startups as well as unicorns like Lyft and Stripe. He is deeply passionate about how to apply learnings from modern safety science to real, complex socio-technical systems.<br></p><p>Blameless SRE <a href="https://www.linkedin.com/in/darrellpappa/"><strong>Darrell Pappa</strong></a> recently interviewed Jacob to delve into how his research has informed his career journey and experiences to-date, especially in his latest role at Stripe where he helps operate the economic infrastructure of the Internet.<br></p><p>The following transcript has been lightly edited for clarity.<br></p><p><strong>Darell Pappa</strong>: Jacob, it’s great to connect. How's it going?<br></p><p><strong>Jacob Scott</strong>: There's actually some interesting <a href="https://www.adaptivecapacitylabs.com/">Adaptive Capacity Labs</a> and <a href="https://www.learningfromincidents.io/">Learning from Incidents</a> stuff on <a href="https://www.adaptivecapacitylabs.com/resilience-engineering-diary-covid-19/">this topic</a>, of <em>“How's it going”</em> during the coronavirus. When you meet someone, it's usually like, <em>"How are you?</em>" And, <em>"I'm good." </em>I think it's helpful to be like, <em>"Well, I'm good, given the circumstances."</em> Right? The world is in an odd and unfortunate place, but given where it is, I'm doing pretty well. How about yourself?<br></p><p><strong>Darell Pappa:</strong> Yeah, especially with the circumstances, it's been challenging for sure, but I'm happy we can connect. <strong>I wanted to first kick us off by diving into your background and some highlights from your journey to date.</strong><br></p><p><strong>Jacob Scott:</strong> A long time ago I was actually a theoretical computer scientist&nbsp; Approximation algorithms, combinatorial optimization. I did research in that domain in undergrad. I went to grad school. I dropped out with a master's. And then in 2008, when I left grad school and started my career in industry, I joined Palantir. This was an interesting company to join. It was a different president, different time, but with everything that's happening in the intersection of society and technology today, it’s really interesting to reflect on working in a company at the center of that.<br></p><p>I was there from 2008 to 2013, and saw it go from 100-200 people to over 1,000. I was a backend generalist in Java, frequently a tech lead or lead engineer on a variety of projects. Then after Palantir, a friend from grad school convinced me to join as a very early engineer at a startup doing productized machine learning on sales and marketing data, solving the same problem for many SMBs. That was pretty interesting. I had a horizontal portfolio as there weren't that many engineers—maybe there were 10 or 20 engineers max—and so there I did a lot more. It was Python instead of Java. I did a lot of Postgres stuff, data pipelines, external data integrations, all sorts of random things.<br></p><p><strong>Darell Pappa: </strong>Looks like a pretty big change from your previous role.<br></p><p><strong>Jacob Scott: </strong>It was, with the intent of optimizing for learning new experiences. It's an approach that I have. Who knows what will make me the most energized and fulfilled? But if I triangulate, I'll learn more by doing something sort of different. You learn a lot, not just technically, but about how the industry works, how Silicon Valley works.<br></p><p>An interesting thing throughout my career, both at Palantir, and then at Infer, Lyft and Stripe, has been the relationship between the business and the technology. There’s always someone on Hacker News saying, <em>"Well, why didn't you use this?</em>" Or, <em>"I could build this thing in a weekend with my buddy."</em> But you can't necessarily build the support arm, the data science arm, the regulatory compliance arm, everything you need to actually have a functioning business. When you're growing and you're the darling of Silicon Valley and you're getting lots of money, you can attract all the right people. This lifts all your boats.&nbsp;<br></p><p>I was at Palantir for about five years, Infer for four years. I left Infer and ended up going to Lyft. At Infer, if you had the AWS root [access], and the log-in, if you were one of the early people setting up the TSDB, basic observability stack, you just kind of did it and hopefully the site wouldn't crash. I went to Lyft with that context.<br></p><p>Lyft obviously has a very sophisticated observability service mesh set up. <a href="https://www.blameless.com/blog/talking-with-matt-klein-about-a-culture-of-reliability">Matt Klein</a> wrote <a href="https://www.envoyproxy.io/">Envoy</a> at Lyft having seen a lot of stuff at Twitter and AWS that helped inform that. He wrote it with the team at Lyft, and it was interesting to see that technology. Palantir had been early, maybe early 2008 to 2013. People were doing whatever made sense. Then Infer was small. Lyft had an incident program. But despite the sophisticated measures in place, incidents would still arise. Whether they're related to your project or not, they overlap your sphere of ownership and things derailed a bit.&nbsp;<br></p><p>So I got curious about the fact that there were so many smart people — the number two ride sharing company, raised lots of money, very sophisticated technology — but the incidents would sometimes be kind of like, <em>“We didn't have this graph, this detector, we didn't notice this thing."</em></p><p>It went on. Not like a hard failure, not like 500s and everything smashed. But especially if you're dealing with machine learning, something can be wrong and have a financial or user impact failure. You can notice these sorts of grey failures later than you'd like, and you end up with an impactful incident<br></p><p>You wish it wouldn't have happened, and so it's like,<em> "How did we get here?"</em> <strong>How do you make sense out of the fact that there's so much success, and so much on fire. </strong>That led me at Lyft to move teams. I joined initially to work on problems in the mapping space, which is interesting for Lyft because time and distance play an important role in which driver you dispatch to what passenger, and they also play in pricing. They're low-level Lego bricks. I moved from there to a team focused on chaos engineering and cross-cutting reliability, working on bot-based load testing that was actually a very successful source of reliability for Lyft. Eventually in the summer of 2019, I ended up leaving Lyft, and was lucky enough to spend about six months exploring resilience engineering.<br></p><p><a href="https://twitter.com/MissAmyTobey">Amy Tobey</a> is at Blameless now, and she's obviously in that community and amazing. Something I got really interested in was: Whether it's socio-technical systems or cognitive systems engineering or the intersection of modern safety science and software systems, there’s this sort of explanatory power or interesting perspective that could say, <em>“Well... If you look at this dynamic system in a much larger sense, maybe you could see how you could get such a bad break. How could </em><a href="https://status.cloud.google.com/incident/cloud-networking/19009"><em>Google go down for six hours last summer</em></a><em>? How could CloudFlare </em><a href="https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/"><em>ship a regex bomb in their </em></a><em>WAF rules?”</em> People want functionality, right? You can't test things perfectly.<br></p><p>And so after being lucky enough to spend some time at the <a href="https://www.southparkcommons.com/">South Park Commons</a>, which is a group in San Francisco for people in between, I decided it was time to go and reapply all this. And so I joined Stripe in February just in time, just before Coronavirus.&nbsp;<strong>‍</strong></p><p><strong>Darell Pappa: </strong>Nice. <strong>What is it that fascinates you, draws you to resilience engineering.</strong> It seems to me it expands outside of software. Amy just did a relevant <a href="https://www.blameless.com/blog/sre-leaders-panel-managing-systems-complexity">panel discussion</a> with Ward Cunningham and Tim Tischler from New Relic and Jessica Kerr.<br></p><p><strong>Jacob Scott: </strong>Yeah. I need to watch that. I try to keep up with talks online with various folks in the wider <a href="https://www.learningfromincidents.io/">Learning from Incidents</a> community, and ground myself in thinking about modern safety science as applied to tech industry startups, unicorns, etc. Resilience engineering actually is one flavor of modern safety science. There's also, for example, <a href="https://en.wikipedia.org/wiki/High_reliability_organization#:~:text=A%20high%20reliability%20organization%20(HRO,to%20risk%20factors%20and%20complexity.">high reliability organizations</a>.&nbsp;<br></p><p>Resilience engineering is this sort of academic practitioner core of scientists and researchers such as <a href="https://erikhollnagel.com/ideas/resilience-engineering.html">Hollnagel</a>, <a href="https://www.adaptivecapacitylabs.com/david-woods/">Woods</a>, <a href="http://sidneydekker.com/">Dekker</a> who write about it and have studied it for a couple of decades. <strong>There's an evolving view of what does safety mean?</strong> <a href="http://sunnyday.mit.edu/">Leveson</a>. It’s all there in factories, cars, medicine, power plants, software systems. We want systems to do some things and not others, sometimes implicitly. That's where edge use cases have come from. <em>"I would like A plus B to equal C."</em> It's like, <em>"Well, what about overflow, underflow, floats, conversion?</em>" I don't want to think about that; infer what I want. But computers aren't that smart.<br></p><p><strong>When I think about resilience engineering or modern safety science in general, it sprawls very quickly. It’s first really embracing the totality, a larger view of a system.&nbsp;</strong><br></p><p>So rather than saying, <em>"I want a service mesh, so I should use Envoy. And if I have my generate retries and circuit breakers and all these things set correctly, and I have the right dashboards and all of these things, then I'll have a reliable system"...</em><br></p><p>Resilience engineering would say, <em>"Okay, but who are the people? Who's going to get paged? What's going to happen when they get paged? How ergonomic will the dashboards be? Do you understand these systems? If there's a high-priority feature request from the business, will that draw resources away? You plan to deploy Envoy, does it sort of pause well? Can you go partway into this migration? Are you setting yourself up for a fragile, brittle, all-or-nothing sort of situation?”</em><br>Specifically, questions in resilience engineering that I find myself relying on a lot...one is, <strong><em>“How did it make sense at the time?”</em></strong></p><p><strong><em>‍</em></strong>Which is maybe cognitive systems engineering. People generally don't show up to work to mess up and ruin things for customers or their coworkers. If something bad happened then it's because someone tried to do the right thing, or took a series of actions that they thought would have a positive outcome, but it did not. How did it make sense to them? This is cognitive perspective.</p><blockquote>People generally don't show up to work to mess up and ruin things for customers or their coworkers. If something bad happened then it's because someone tried to do the right thing, or took a series of actions that they thought would have a positive outcome, but it did not. How did it make sense to them? This is cognitive perspective.</blockquote><p>Another is this <a href="https://github.com/lorin/resilience-engineering#safety-i-vs-safety-ii">Safety-II idea</a> that the work is the work. Based …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blameless.com/blog/enabling-the-stripe-and-lyft-platforms-through-modern-safety-science">https://www.blameless.com/blog/enabling-the-stripe-and-lyft-platforms-through-modern-safety-science</a></em></p>]]>
            </description>
            <link>https://www.blameless.com/blog/enabling-the-stripe-and-lyft-platforms-through-modern-safety-science</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043952</guid>
            <pubDate>Mon, 03 Aug 2020 21:58:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Improve On-Call with Better Practices and Tools]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043949">thread link</a>) | @hannahblameless
<br/>
August 3, 2020 | https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the era of reliability, where mere minutes of downtime or latency can cost hundreds of thousands of dollars, 24x7 availability and on-call coverage to respond to incidents has become a requirement for the vast majority of organizations. But setting up an on-call system that drives effective incident response while minimizing the stress placed on engineers isn’t a trivial task. Establishing equitable on-call rotations, putting the right guardrails and automation in place, and regular incident practice are key. In this blog, we’ll share key tools and practices to ensure your on-call engineers are set up for success.</p><h3>On-call practices and policies</h3><p>When setting up your on-call system, it is important to define clear and consistent policies and practices. When taking on on-call responsibilities, engineers shouldn’t need to reinvent the wheel when the pager goes off; ideally, the planning around severity, incident playbooks, and more should take place during peacetime. The team should work together to create rules that dictate when and how on-call escalations happen. Make sure you have the following worked out before implementing an on-call system.<br></p><h4><strong>Creating Rotation Schedules</strong><br></h4><p>First, you’ll need to build your on-call schedule. Work out which engineers would need to be available for different system areas where incidents could occur, by looking at where each engineer has ownership and domain expertise. Create teams to maximize diversity and coverage, allowing for each time to respond effectively to many different types of incidents. Fill out a calendar with these teams, making sure every shift is covered for your rotation period.<br></p><p>During all of this, consult with your engineers to ensure that your schedules are reasonable and fair. How long should an on-call shift last? How frequently should a team go on-call? What should the procedure be if an engineer has to change shifts? To keep morale high and teams responding effectively, make sure every engineer has a fair say in these choices.<br></p><p>Be prepared to change your rotation schedule frequently, even after implementation. The reality of working on-call shifts is often very different than predicted, so look at on-call data to uncover whether certain individuals are overburdened with off-hours interruptions or critical incidents, and load balance accordingly. Be flexible in hearing out people’s concerns as they develop. External business changes and stages in development cycles can also drastically change the nature of on-call shifts, so be prepared to reflect those with adjustments to shift lengths and rotation frequencies.<br></p><p>Because of these constant changes, it’s important to keep the rotation schedule up-to-date. Make sure it’s kept in a place where it’s convenient to make changes, automated and easy to integrate with different systems, and accessible to anyone. Many on-call platforms also offer scheduling tools to make this process easier and more robust.</p><h4><strong>Defining Escalation and Response Policies</strong><br></h4><p>The next set of policies you need to define is to decide when your on-call teams are actually contacted and how they respond. To combat alert fatigue, you’ll want to be judicious about when your teams are notified, but also ensure that critical incidents are not overlooked.<br></p><p>You should have a system to <a href="https://www.blameless.com/blog/incident-classification">classify incidents</a>, sorting them based on severity and affected area into established classifications. These classifications will determine who is alerted and what response is necessary. This response should also include timelines for when incidents of severity need to be resolved before you violate <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">SLOs or SLAs</a>.<br></p><p>You can determine severity by looking at the <a href="https://www.blameless.com/resources/webinar-modern-metrics">business impact</a> of an incident — issues preventing customers from using services or violating SLAs require a much faster and larger response than a small component loading slightly slower than usual.&nbsp;<br></p><p>You’ll also need to prepare a defined response to each category of incidents. Engineers should be equipped with tools like <a href="https://www.blameless.com/blog/runbook-automation-best-practices">runbooks</a> to begin tackling an incident as soon as they’re alerted. These runbooks can also include checks for triggering further escalation. Make sure your on-call engineers are familiar with these runbooks, and confident about executing them when the time comes. Schedule regular review sessions to update runbooks based on incident retrospectives.</p><h4><strong>Cultivating On-Call Culture</strong><br></h4><p>Between being called out of bed in the wee hours, having to handle incidents with fewer teammates and resources than normal, and facing extreme pressure to restore service as business reputation is on the line, on-call can be an extremely stressful experience. Being overwhelmed by on-call responsibilities, believing that on-call duties are assigned unfairly, or generally feeling under-appreciated can quickly destroy engineers’ morale and accelerate burnout.&nbsp;<br></p><p>Combat these challenges by cultivating an empathetic on-call culture that puts people first.<br></p><p>Involve engineers in setting schedules and other policies. Hear out their experiences, celebrating their successes and addressing their struggles. Make sure you hear these concerns blamelessly; instead of attributing setbacks or miscommunications to individuals, look at the systems behind them. Protect against a ‘hero’ culture, and embrace sustainable on-call through eliminating single points of failure, and embracing smaller and more frequent changes, distributed rotations, and continuous learning.<br></p><blockquote>Reframe incidents from failures and setbacks to investments in future reliability — every incident, when properly addressed, makes the response to each future incident better. Likewise, each on-call shift is an investment in making future on-call shifts better. When there’s challenges in load balancing, having effective responses prepared, or proper escalation, embrace them as opportunities to refine and grow.<br></blockquote><p>For more tips on how to implement empathetic and effective on-call practices, check out our top 5 on-call practices <a href="https://www.blameless.com/blog/our-top-5-on-call-practices">here</a>.</p><h3>On-call Software</h3><p>Implementing on-call practices is a complicated process, but fortunately there are great paid as well as free on-call tools and platforms to help. The most popular tools include PagerDuty, OpsGenie, VictorOps, Cabot, and LinkedIn On-Call (open source)<br></p><p>When selecting an on-call tool, some important requirements to consider include:</p><ul role="list"><li>Alerting through phone, SMS, Hipchat, or email</li><li>Breadth of integrations across the tech stack, from cloud monitoring to source control</li><li>Alert grouping, filtering, and de-duplication</li><li>Team-based management</li><li>Simple visualization of teams’ statuses across the calendar</li><li>Rock-solid reliability</li></ul><p>On-call is an essential component of a reliable system. To take your on-call and reliability practice to the next level, you’ll need to codify context into guardrails and automation, minimize toil, and foster a culture that is inclined toward curiosity instead of blame. Blameless can help you get more out of your on-call and broader reliability efforts&nbsp; by integrating valuable data from SLOs, incident checklists, , postmortems, follow-up action items, and much more. To find out how to empower your SRE solution with Blameless, join us for a <a href="https://www.blameless.com/schedule-demo">demo</a>!</p></div></div>]]>
            </description>
            <link>https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043949</guid>
            <pubDate>Mon, 03 Aug 2020 21:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PP-YOLO Surpasses YOLOv4 – State-of-the-art object detection techniques]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24043812">thread link</a>) | @rocauc
<br/>
August 3, 2020 | https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div><p>Baidu publishes PP-YOLO and pushes the state of the art in object detection research by building on top of YOLOv3, the PaddlePaddle deep learning framework, and cutting edge computer vision research.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-1.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-1.png 600w, https://blog.roboflow.ai/content/images/2020/08/image-1.png 692w"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> evaluation shows faster inference (x-axis) with better accuracy (y-axis)</figcaption></figure><p>PP-YOLO evaluation metrics show improved performance over <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">YOLOv4</a>, the incumbent state of the art object detection model. Yet, the Baidu authors write:</p><figure><pre><code>This paper is not intended to introduce a novel object detecotor. 
It is more like a recipe, which tell you how to build a better detector step by step.</code></pre><figcaption>Mysterious introduction in the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO paper</a></figcaption></figure><p>Let's unpack that.</p><h2 id="yolo-development-history">YOLO Development History</h2><p>YOLO was originally authored by Joseph Redmon to detect objects. Object detection is a computer vision technique that localizes and tags objects by drawing a bounding box around them and identifying the class label that a given box belongs too. Unlike massive NLP transformers, YOLO is designed to be tiny, enabling realtime inference speeds for deployment on device. &nbsp;</p><p>YOLO-9000 was the second "YOLOv2" object detector published by Joseph Redmon, improving the detector and emphasizing the detectors ability to generalize to any object in the world.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-2.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-2.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-2.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-2.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-2.png 1810w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://github.com/PaddlePaddle/PaddleDetection/blob/release/0.4/docs/tutorials/Custom_DataSet.md">PP-YOLO</a> is being trained to identify different fruit flies in this photo.</figcaption></figure><p>YOLOv3 made further improvements to the detection network and began to mainstream the object detection process. We began to publish tutorials on <a href="https://blog.roboflow.ai/releasing-a-new-yolov3-implementation/">how to train YOLOv3 in PyTorch</a>, <a href="https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/">how to train YOLOv3 in Keras</a>, and <a href="https://blog.roboflow.ai/yolov3-versus-efficientdet-for-state-of-the-art-object-detection/">compared YOLOv3 performance to EfficientDet </a>(another state of the art detector).</p><p>Then Joseph Redmon stepped out of the object detection game due to ethical concerns. </p><p>Naturally, the open source community picked up the baton and continues to move YOLO technology forward. </p><p>YOLOv4 was published recently this spring by Alexey AB in his for of the YOLO Darknet repository. YOLOv4 was primarily an ensemble of other known computer vision technologies, combined and validated through the research process. See here for a <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">deep dive on YOLOv4</a>. The YOLOv4 paper reads similarly to the PP-YOLO paper, as we will see below. We put together some great training tutorials on <a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">how to train YOLOv4 in Darknet</a>.</p><p>Then, just a few months ago <a href="https://blog.roboflow.ai/yolov5-is-here/">YOLOv5 was released</a>. YOLOv5 took the Darknet (C based) training environment and converted the network to PyTorch. Improved training techniques pushed performance of the model even further and created a great, easy to use, out of the box object detection model. Ever since, we have been encouraging developers using Roboflow to direct their attention to YOLOv5 for the formation of their custom object detectors via this <a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">YOLOv5 training tutorial</a>.</p><p>Enter PP-YOLO.</p><h2 id="what-does-pp-stand-for">What Does PP Stand For?</h2><p>PP is short for PaddlePaddle, a deep learning framework written by Baidu. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-9.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-9.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-9.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-9.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-9.png 1634w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.paddlepaddle.org.cn/">PaddlePaddle</a> distributions provided on their website.</figcaption></figure><p>If PaddlePaddle is new to you, then we are in the same boat. Primarily written in Python, PaddlePaddle seems akin to PyTorch and TensorFlow. A deep dive into the PaddlePaddle framework is intriguing, but beyond the scope of this article. </p><h2 id="pp-yolo-contributions">PP-YOLO Contributions</h2><p>The PP-YOLO paper reads much like the YOLOv4 paper in that it is a compilation of techniques that are known to work in computer vision. The novel contribution is to prove that the ensemble of these technologies improves performance, and to provide an ablation study of how much each step helps the model along the way.</p><p>Before we dive into the contributions of PP-YOLO, it will be useful to review the YOLO detector architecture.</p><h3 id="anatomy-of-the-yolo-detector">Anatomy of the YOLO Detector</h3><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image.png 1376w" sizes="(min-width: 720px) 720px"><figcaption>A graphical depiction of the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> object detection network</figcaption></figure><p>The YOLO detector is broken into three main pieces.</p><p><strong>YOLO Backbone</strong> - The YOLO backbone is a convolutional neural network that pools image pixels to form features at different granularities. The Backbone is typically pretrained on a classification dataset, typically ImageNet.</p><p><strong>YOLO Neck - </strong>The YOLO neck (FPN is chosen above) combines and mixes the ConvNet layer representations before passing on to the prediction head.</p><p><strong>YOLO Head</strong> - This is the part of the network that makes the bounding box and class prediction. It is guided by the three YOLO loss functions for class, box, and objectness. </p><h2 id="now-let-s-dive-into-the-pp-yolo-contributions-">Now let's dive into the PP YOLO Contributions.</h2><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-10.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-10.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-10.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-10.png 1136w" sizes="(min-width: 720px) 720px"><figcaption>Marginal mAP accuracy performance increase from each technique in PP-YOLO</figcaption></figure><h3 id="replace-backbone">Replace Backbone</h3><p>The first PP YOLO technique is to replace the YOLOv3 Darknet53 backbone with the Resnet50-vd-dcn ConvNet backbone. Resnet is a more popular backbone, more frameworks are optimized for its execution, and it has fewer parameters than Darknet53. Seeing a mAP improvement by swapping this backbone is a huge win for PP YOLO. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-12.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-12.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-12.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-12.png 1422w" sizes="(min-width: 720px) 720px"><figcaption>Graphical depiction in <a href="https://arxiv.org/pdf/1603.05027.pdf">ResNet</a></figcaption></figure><h3 id="ema-of-model-parameters">EMA of Model Parameters</h3><p>PP YOLO tracks the Exponential Moving Average of network parameters to maintain a shadow of the models weights for prediction time. This has been shown to improve inference accuracy.</p><h3 id="larger-batch-size">Larger Batch Size</h3><p>PP-YOLO bumps the batch size up from 64 to 192. Of course, this is hard to implement if you have GPU memory constraints.</p><h3 id="dropblock-regularization">DropBlock Regularization</h3><p>PP YOLO implements DropBlock regularization in the FPN neck (in the past, this has usually occurred in the backbone). DropBlock randomly removes a block of the training features at a given step in the network to teach the model to not rely on key features for detection.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-16.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-16.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-16.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-16.png 1050w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/1810.12890.pdf">Drop Block</a> regularization technique - features are hidden in blocks (c) not randomly (b)</figcaption></figure><h3 id="iou-loss">IoU Loss</h3><p>The YOLO loss function does not translate well to the <a href="https://blog.roboflow.ai/what-is-mean-average-precision-object-detection/">mAP metric</a>, which uses the Intersection over Union heavily in its calculation. Therefore, it is useful to edit the training loss function with this end prediction in mind. This edit was also present in YOLOv4.</p><h3 id="iou-aware">IoU Aware</h3><p>The PP-YOLO network adds a prediction branch to predict the model's estimated IOU with a given object. Including this IoU awareness when making the decision to predict an object or not improves performance.</p><h3 id="grid-sensitivity">Grid Sensitivity</h3><p>The old YOLO models do not do a good job of making predictions right around the boundaries of anchor box regions. It is useful to define box coordinates slightly differently to avoid this problem. This technique is also present in YOLOv4.</p><h3 id="matrix-nms">Matrix NMS </h3><p>Non-Maximum Suppression is a technique to remove over proposals of candidate objects for classification. Matrix NMS is a technique to sort through these candidate predictions in parallel, speeding up the calculation. </p><h3 id="coordconv">CoordConv</h3><p>CoordConv was motivated by the problems ConvNets were having with simply mapping (x,y) coordinates to a one-hot pixel space. The CoordConv solution gives the convolution network access to its own input coordinates. CoordConv interventions are marked with yellow diamonds above. More details are available in <a href="https://arxiv.org/pdf/1807.03247.pdf">the CordConv paper</a>.</p><h3 id="spp">SPP</h3><p>Spatial Pyramid Pooling is an extra block after the backbone layer to mix and pool spatial features. Also implemented in YOLOv4 and YOLOv5.</p><h3 id="better-pretrained-backbone">Better Pretrained Backbone</h3><p>The PP YOLO authors distilled down a larger ResNet model to serve as the backbone. A better pretrained model shows to improve downstream transfer learning as well. </p><h2 id="is-pp-yolo-state-of-the-art"><br>Is PP-YOLO State of the Art?</h2><p>PP-YOLO outperforms the results <a href="https://arxiv.org/pdf/2004.10934.pdf">YOLOv4 published</a> on April 23, 2020.</p><p>In fairness, the authors note this may be the wrong question to be asking. The authors' intent appears to not simply "introduce a new novel detector," rather to show the process of carefully tuning an object detector to maximize performance. Quoting the paper's introduction here:</p><blockquote>The focus of this paper is how to stack some effective tricks that hardly affect efficiency to get better performance... This paper is not intended to introduce a novel object detector. It is more like a recipe, which tell you how to build a better detector step by step. We have found some tricks that are effective for the YOLOv3 detector, which can save developers’ time of trial and error. <strong>The final PP-YOLO model improves the mAP on COCO from 43.5% to 45.2% at a speed faster than YOLOv4</strong></blockquote><p><em>(emphasis ours)</em></p><p>The PP-YOLO contributions reference above took the YOLOv3 model from 38.9 to 44.6 mAP on the COCO object detection task and increased inference FPS from 58 to 73. These metrics are shown in the paper to beat the currently published results for YOLOv4 and EfficientDet. </p><p>In benchmarking PP-YOLO against <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a>, it appears <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a> still has the fastest inference time-to-accuracy performance (AP vs FPS) tradeoff on a V100. However, a YOLOv5 paper still remains to be released. Furthermore, it has been shown that training the YOLOv4 architecture on the YOLOv5 Ultralytics repository outperforms YOLOv5 and, transitively, YOLOv4 trained using YOLOv5 contributions would outperform the PP-YOLO results posted here. These results are still to be formally published but can be traced to <a href="https://github.com/ultralytics/yolov5/issues/6">this GitHub discussion</a>.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-14.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-14.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-14.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-14.png 1354w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-15.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-15.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-15.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-15.png 1304w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5 evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><p>It is worth noting that many of the techniques (such as architecture search and data augmentation) that were used in YOLOv4 were not used in PP YOLO. This means that there is still room for the state of the art in object detection to grow as more of these techniques are combined and integrated together. </p><p>Needless to say, is an exciting time to be implementing computer vision technologies.</p><h2 id="should-i-switch-from-yolov4-or-yolov5-to-pp-yolo">Should I Switch from YOLOv4 or YOLOv5 to PP-YOLO?</h2><p>The PP-YOLO model shows the promise of state of the art object detection, but the improvements are incremental over other object detectors and it is written in a new framework. At this stage, the best thing to do is to develop your own empirical result by training PP-YOLO on your own dataset. (To be notified when you can easily use PP-YOLO on your dataset, <a href="https://roboflow.us5.list-manage.com/subscribe?u=26126ade12b1dd890dbd7b07e&amp;id=3e926cf19a">subscribe to our newsletter</a>.)</p><p>In the meantime, I recommend checking out the following YOLO tutorials to get your object detector off the ground:</p><ul><li><a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">How to Train YOLOv4 in Darknet</a></li><li><a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">How to Train YOLOv5 in PyTorch</a></li></ul><p>As always - happy training! </p></div>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043812</guid>
            <pubDate>Mon, 03 Aug 2020 21:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parts of vs Code Are Proprietary]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043448">thread link</a>) | @jerodsanto
<br/>
August 3, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043448</guid>
            <pubDate>Mon, 03 Aug 2020 21:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Second Publicly Traded Person]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043354">thread link</a>) | @exolymph
<br/>
August 3, 2020 | https://news.kmikeym.com/alexmasmej/ | <a href="https://web.archive.org/web/*/https://news.kmikeym.com/alexmasmej/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>I’ve been a publicly traded person since 2008, and I’ve always called myself the “first” because I hoped more would come after. Today, 12 years later, the prophecy has been fulfilled! <a href="https://twitter.com/alexmasmej">Alex Masmej</a> has used cryptocurrency to become the second publicly traded person. I first spoke with Alex when we were both on a <a href="https://www.youtube.com/watch?v=cjBD1BdwAUA">panel about personal tokens</a> but thought it was worth following up.</p>



<p><strong>Mike</strong>: Let’s start with the basics, who are you? Where do live? What do you do? Give me a little sense of who you are…</p>



<p><strong>Alex:</strong> Hi Mike, thanks! I’m Alex Masmej, 23, and I currently live in Paris. I’ve been an entrepreneur in the crypto(currency) space, doing projects on Ethereum (the second biggest blockchain after Bitcoin) for the past year.</p>



<p>My latest project is the launch of my “personal token,” called $ALEX. By using crypto technology I can enable all sorts of financial combinations that would be very complicated if not impossible to replicate in traditional finance.&nbsp;</p>



<p><strong>Mike:</strong> All I want to do is build financial complications into my life. I’m a little jealous.</p>



<p><strong>Alex:</strong> Don’t be too hard on yourself! My token is built with “blockchain smart contracts”, which didn’t exist when you started trading yourself!</p>



<p><strong>Mike</strong>: The age difference between us speaks a lot to our choice of technologies (you were 11 when I launched my project?) and is one of the reasons I’m really excited about your project. You are basically a “crypto-native” while I have been enamored with crypto since I first heard about it in 2010 or 2011. Can you tell me about some of your other crypto projects?&nbsp;</p>



<p><strong>Alex</strong>: Sure! So I co-founded <a href="https://marketingdao.org/">Marketing DAO</a>, which is a grants organization to market Ethereum. A “DAO” is a <em>Decentralized Autonomous Organization,</em> meaning anyone can join the entity on the blockchain without being legally registered. The more money you put in, the more voting power you have.&nbsp;</p>



<p><strong>Mike:</strong> I like this already.</p>



<p><strong>Alex:</strong> It’s like website software meets legal entity, and it’s a whole new way to form companies with a flatter hierarchy, unique to Ethereum. We got support from Consensys, one of the biggest crypto firms, which helped us to fulfill our mission to be the largest Ethereum marketing agency, done the Ethereum way. It was the first entity of this type, “DAO”, to be incorporated in the USA.</p>



<p>Another project is <a href="https://twitter.com/RocketNFT">Rocket</a>, a lending platform that instead of using your credit score, asks for Ethereum “native collateral”. This can be a domain name, video game real estate or even digital art (yes, artists do art on the blockchain and can make money off it).</p>



<p>These two projects are innovating where normal finance can’t. Having my personal token is another, and I’m gonna try my best to push what you did even further!</p>



<p><strong>Mike</strong>: Let’s back up just a bit. What is the simplest way to describe a “personal token”?</p>



<p><strong>Alex:</strong> A personal token is a cryptocurrency directly tied to a person. There are a few common types currently in use:</p>



<ol><li>Selling your <strong>time</strong></li><li>Selling your <strong>future</strong></li><li>Selling “exclusive access” to something (a chatroom, newsletter, etc)</li><li>Doing life choices like KmikeyM</li></ol>



<p>The first type is typically used for freelancer services, especially if the person has a highly sought after skill. By using a personal token they get more money upfront as people buy the token, and then redeem it later.</p>



<p>The second type is a novel form of Income Sharing Agreements (ISA), which works well for people with some kind of community backing. They are monetizing their perceived future potential (this is what I did recently).</p>



<p>The third type you could call “credentialism,” or a gratitude token. It’s like getting a letter of recommendation from someone. For instance, Vitalik Buterin, the inventor and one of the most respected people in the industry, could give out a “Great Developer by Vitalik Buterin” token. That would be like a diploma of its own.</p>



<p><strong>Mike</strong>: That reminds of me of the <a href="https://en.wikipedia.org/wiki/Challenge_coin">challenge coins</a> people of high rank would give out when I was in the Army.</p>



<p><strong>Alex</strong>: Exactly, only this would be a digital version. The fourth type, allows people to vote on choices that the creator of a token puts up, weighted by how many tokens they hold. This is basically what you’re doing, just without a crypto token.</p>



<p>In my case, using the $ALEX token, the execution is different than yours. Holders of the token “sign” with their cryptographic key (which is just selecting the “sign” button in their crypto wallet). That uniquely proves they own the address their wallet is logged in with. Then I count all the $ALEX present in all addresses that voted, and since 1 $ALEX = 1 vote, the more $ALEX a person has, the heavier you vote, just like you.</p>



<p><strong>Mike</strong>: Alright I’m sold. <a href="https://news.kmikeym.com/ctrlaltz-alexmasmej/">Let me buy some $ALEX</a>. Before you launched $ALEX what did you hope to accomplish with it? I ask because when I started KmikeyM I thought it was just going to be a way to work on projects with people, and then it became about my personal life!</p>



<p><strong>Alex:</strong> My first token someone created for me back in July to “tokenize my debt” of $1,500 that he lent me to attend a conference (not $ALEX). This meant that as I was paying him back others could trade the remaining debt and receive a small profit from the interest rate.</p>



<p>That is when <a href="https://tryroll.com/">Roll</a> contacted me, saying they could create a token for me in a more broad sense, encapsulating my growing community. When I started it I had nothing in mind. I barely had 700 followers so no one really cared. At first I said 25,000 tokens would be an hour of my time (in total, they are 10,000,000 $ALEX tokens).</p>



<p><strong>Mike</strong>: Who bought $ALEX and what did they get?</p>



<p><strong>Alex:</strong> Not much happened for a few months. In March, COVID-19 happened and I lost a contract job that was my major source of income. This happened just a few days before I was scheduled to give a talk about personal tokens on the mainstage of a major blockchain conference in Paris. So I decided to wing it and announce that I would be raising $20,000 against 1M $ALEX tokens, and I’d give 15% of my income for the next 3 years to those that bought this special version of my token. A month later, I created a Google form where people could register to buy into my future, and everything started spiralling… in five days I was oversubscribed and the major crypto media outlets started talking about it.</p>



<p>In May I launched a chatroom which let people join a private chat with me, but they have to verify that they at least own 1 $ALEX in order to get in. It’s fun because it feels exclusive to them.</p>



<p>Then in June, inspired by you, and with help from a famous developer named Austin Griffith, I launched “Control My Life”, which allows holders of $ALEX to vote on my life decisions just like I described earlier. I started with a daily habit, and they chose running 5 km a day. As of this writing, I’ve kept my promise and I’m running everyday!</p>



<p><strong>Mike</strong>: That’s fantastic! So what is next? Are you planning more votes? Are you asking for help finding your next job?&nbsp;</p>



<p><strong>Alex</strong>: I haven’t thought about more votes too deeply, but perhaps I’ll let them choose the next book I read, what my diet should be, or another small action… I’m inspired by what you did so I might copy some of your stuff. 🙂 But I can’t commit too much because I’m working on my plan to found a startup in Silicon Valley and raise funds there. I already have many connections, countless ideas, and I’m planning to move long term to the United States (hopefully in early 2021).</p>



<hr>



<p>Here’s the panel we were on with Kerman Kohli and Bradley Miles.</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/cjBD1BdwAUA?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>

								</div></div>]]>
            </description>
            <link>https://news.kmikeym.com/alexmasmej/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043354</guid>
            <pubDate>Mon, 03 Aug 2020 21:00:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your calendar should be a whitelist, not a blacklist]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24043175">thread link</a>) | @mcrittenden
<br/>
August 3, 2020 | https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-549">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Does your company have a culture of letting everyone see each other’s calendars? Do people often schedule meetings whenever there are openings, without asking?</p>



<p>If so, your calendar is a blocklist. The only time that isn’t available for someone to steal is time that’s already spoken for. This is a problem. A time slot that isn’t currently booked shouldn’t be free real estate. That’s my TIME! You can’t just take it without asking.</p>



<p>Instead, your calendars should be an allowlist. You should say “if you want to talk to me, this is when you can” instead of “this is when you CAN’T.” You shouldn’t have to defend our time like it’s gold and your coworkers are pirates. You should just assume that it’s yours to spend how you see fit.</p>



<p>Some people block time off to try to protect their calendars. They create big “GTD” blocks on their calendar and hope that nobody books meetings on top of them. I’ve even heard of people creating fake or vague meeting titles in hopes that others will assume there’s a real meeting at that time. This is a crappy workaround, and it isn’t enough. </p>



<p>The solution should be office hours. You should be able to say say “I’m free for meetings from 2-5pm on Tuesdays and Thursdays, and if you want to talk to me then that’s when you can.” In most companies, doing that would make you an annoyance. Those companies don’t respect Deep Work. </p>



<p>Scheduling meetings should be a little bit painful. You should have to really want it. You should be forced to question yourself. <em>Is this actually worth me going to the trouble of figuring out how to schedule this meeting? Or could it instead be an asynchronous discussion? </em>Office hours and calendars-as-allowlists have this added benefit.</p>



<p>Is your calendar an allowlist or a blocklist?</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043175</guid>
            <pubDate>Mon, 03 Aug 2020 20:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Python Package Downloads Using Google BigQuery and Apache Superset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043002">thread link</a>) | @ceohockey60
<br/>
August 3, 2020 | https://preset.io/blog/2020-08-04-google-bigquery/ | <a href="https://web.archive.org/web/*/https://preset.io/blog/2020-08-04-google-bigquery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="python-packages"><a href="#python-packages" aria-label="python packages permalink"></a>Python Packages</h2>
<p>PyPi is the Python Package Index and is the main repository for Python packages installed via <a href="https://packaging.python.org/tutorials/installing-packages/">pip</a>. Since Python is one of the most popular programming languages out there and most users install packages hosted on PyPi, this makes for a very interesting dataset to estimate the popularity and usage of different Python packages.</p>
<p>As with any analysis of large scale datasets, there's a few caveats we should keep in mind when trying to make conclusions and infer patterns from this data. The PyPi dataset has an excellent disclaimer <a href="https://packaging.python.org/guides/analyzing-pypi-package-downloads/#background">on their site</a> on the limitations of this data.</p>
<p><a href="https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/54f11/dataset_limitations.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="PyPi Dataset Limitations" title="PyPi Dataset Limitations" src="https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/f6afc/dataset_limitations.png" srcset="https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/7b5b4/dataset_limitations.png 188w,
https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/a80c4/dataset_limitations.png 376w,
https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/f6afc/dataset_limitations.png 752w,
https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/3f9be/dataset_limitations.png 1128w,
https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/a34ba/dataset_limitations.png 1504w,
https://preset.io/static/0f0c4095f6590f080215d0942c4c11d3/54f11/dataset_limitations.png 1646w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p>
<p>With these limitations, we can use this data to <em>estimate</em> things like:</p>
<ul>
<li>which new packages are rising in popularity quickly</li>
<li>which packages have reached maturity or have plateaued in downloads</li>
<li>which package is the most popular for a specific problem (like user authentication or visualization)</li>
</ul>
<p>These use cases are useful for the Python engineer looking to decide which package to incorporate into their code base or for the open source package maintainer looking to roughly track adoption.</p>
<p><strong>In this post, we'll explore how to connect BigQuery to Apache Superset.</strong></p>
<p>Apache Superset is an open-source business intelligence tool that provides a SQL interface, a no-code UI for creating visualizations, and a highly customizable dashboard layer to bring these visualizations together. Superset integrates with <a href="https://superset.apache.org/#databases">most popular databases and data engines</a>.</p>
<h2 id="public-datasets-on-google-bigquery"><a href="#public-datasets-on-google-bigquery" aria-label="public datasets on google bigquery permalink"></a>Public Datasets On Google BigQuery</h2>
<p>Google BigQuery is a data warehouse solution that's hosted on Google Cloud. Similar to it's Amazon counterpart, Redshift, BigQuery is a <a href="https://en.wikipedia.org/wiki/Column-oriented_DBMS">column oriented database system</a> that's optimized for analytics use cases.</p>
<p>BigQuery hosts a number of public datasets as part of their marketplace on Google Cloud. </p>
<p><a href="https://preset.io/static/6c46296028e09415707508042b146e63/c1648/public_datasets.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="BigQuery public datasets" title="BigQuery public datasets" src="https://preset.io/static/6c46296028e09415707508042b146e63/f6afc/public_datasets.png" srcset="https://preset.io/static/6c46296028e09415707508042b146e63/7b5b4/public_datasets.png 188w,
https://preset.io/static/6c46296028e09415707508042b146e63/a80c4/public_datasets.png 376w,
https://preset.io/static/6c46296028e09415707508042b146e63/f6afc/public_datasets.png 752w,
https://preset.io/static/6c46296028e09415707508042b146e63/3f9be/public_datasets.png 1128w,
https://preset.io/static/6c46296028e09415707508042b146e63/a34ba/public_datasets.png 1504w,
https://preset.io/static/6c46296028e09415707508042b146e63/c1648/public_datasets.png 2522w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p>
<p>As with every experiment using cloud resources, it's very important to understand and internalize how the fee structure works. Google charges around 2 axes of usage:</p>
<ul>
<li><strong>storage</strong>: how much data is actually stored</li>
<li><strong>compute</strong>: how much data is actually processed</li>
</ul>
<p>For public datasets, Google waives the associated storage costs but charges for accessing and scanning their centrally located public datasets. Google lets us <a href="https://cloud.google.com/bigquery/public-data">query 1 terabyte per month</a> in an <a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">on-demand way</a> for free and then they charge $5 per terabyte processed afterwards.</p>
<p><strong>Step 1.</strong> To use public datasets, we need to first create a project by heading to the <a href="https://console.cloud.google.com/projectselector2/home/dashboard?_ga=2.88969755.125825472.1596123671-646201415.1590849603">project selector page</a> and following the project setup wizard. You can read the updated instructions on the <a href="https://cloud.google.com/bigquery/docs/quickstarts/quickstart-web-ui">BigQuery documentation site</a>.</p>
<p><strong>Step 2.</strong> Once you've created a BigQuery project, you can add the PyPI downloads dataset just by navigating to <a href="https://console.cloud.google.com/bigquery?p=the-psf&amp;d=pypi&amp;page=dataset">public dataset page</a>. If you're logged into BigQuery, you should see this dataset now registered in your project.</p>
<p><a href="https://preset.io/static/74056143838ca496cc9a9249fc95032a/3383e/pypi_dataset.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Add PyPi Dataset" title="Add PyPi Dataset" src="https://preset.io/static/74056143838ca496cc9a9249fc95032a/f6afc/pypi_dataset.png" srcset="https://preset.io/static/74056143838ca496cc9a9249fc95032a/7b5b4/pypi_dataset.png 188w,
https://preset.io/static/74056143838ca496cc9a9249fc95032a/a80c4/pypi_dataset.png 376w,
https://preset.io/static/74056143838ca496cc9a9249fc95032a/f6afc/pypi_dataset.png 752w,
https://preset.io/static/74056143838ca496cc9a9249fc95032a/3f9be/pypi_dataset.png 1128w,
https://preset.io/static/74056143838ca496cc9a9249fc95032a/a34ba/pypi_dataset.png 1504w,
https://preset.io/static/74056143838ca496cc9a9249fc95032a/3383e/pypi_dataset.png 2064w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p>
<p>To provide access to BigQuery from outside of Google Cloud, we'll need to first create a Service Account. A <a href="https://cloud.google.com/iam/docs/service-accounts">Service Account</a> is essentially a user account that has specific permissions to access resources in Google Cloud programmatically (instead of just from the UI). Unlike a regular user account for humans, Service Accounts don't have passwords and instead access resources using <a href="https://en.wikipedia.org/wiki/Public-key_cryptography">public key cryptography</a>.</p>
<p><strong>Step 3.</strong> Use the search bar to find and navigate to the "Service Accounts" configuration page.</p>
<div><div><p><a href="https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/5c484/service_account.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Service account" title="Service Account" src="https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/f6afc/service_account.png" srcset="https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/7b5b4/service_account.png 188w,
https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/a80c4/service_account.png 376w,
https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/f6afc/service_account.png 752w,
https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/3f9be/service_account.png 1128w,
https://preset.io/static/7b5b9e803ba8b1b5bf0cb456f0f88f56/5c484/service_account.png 1186w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div></div>
<p>Then, click <strong>+ Create Service Account</strong> under the search bar. You should still see your BigQuery project name next to "Google Cloud Platform", which is critical to ensuring the Service Account you're creating can access datasets you've added to your BigQuery project.</p>
<div><div><p><a href="https://preset.io/static/73c9a7bcb25117a6c4bc543253d36559/fddbb/create_service_account.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Create Service account" title="Create Service Account" src="https://preset.io/static/73c9a7bcb25117a6c4bc543253d36559/fddbb/create_service_account.png" srcset="https://preset.io/static/73c9a7bcb25117a6c4bc543253d36559/7b5b4/create_service_account.png 188w,
https://preset.io/static/73c9a7bcb25117a6c4bc543253d36559/a80c4/create_service_account.png 376w,
https://preset.io/static/73c9a7bcb25117a6c4bc543253d36559/fddbb/create_service_account.png 736w" sizes="(max-width: 736px) 100vw, 736px">
  </span>
  </a></p></div></div>
<p><strong>Step 4.</strong> Step 1 of this wizard involves specifying an account name, ID, and description. Feel free to be creative here! When you're finished, click <strong>Create</strong> to be taken to the next step.</p>
<p><strong>Step 5.</strong> In step 2 of this wizard, you need to search for and add "BigQuery User" to this service account. This enables this service account to run queries in BigQuery, create datasets, read dataset metadata, and list tables.</p>
<div><div><p><a href="https://preset.io/static/bce14f3e4e24741da66b140146973f1e/d0baa/bigquery_user.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="BigQuery User" title="BigQuery User" src="https://preset.io/static/bce14f3e4e24741da66b140146973f1e/f6afc/bigquery_user.png" srcset="https://preset.io/static/bce14f3e4e24741da66b140146973f1e/7b5b4/bigquery_user.png 188w,
https://preset.io/static/bce14f3e4e24741da66b140146973f1e/a80c4/bigquery_user.png 376w,
https://preset.io/static/bce14f3e4e24741da66b140146973f1e/f6afc/bigquery_user.png 752w,
https://preset.io/static/bce14f3e4e24741da66b140146973f1e/d0baa/bigquery_user.png 1066w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div></div>
<p><strong>Step 6.</strong> You can skip step 3 if you don't have an organization level <a href="https://cloud.google.com/iam/docs/granting-changing-revoking-access#granting_access_to_a_user_for_a_service_account">IAM hierarchy</a> and are just trying this out first. You'll now be taken to a list of all of your Service Acounts.</p>
<p><strong>Step 7.</strong> The last step here is to select the service account you just created, create a new private-public key pair by selecting <strong>Add Key</strong>, and download your private key as a JSON file. Most services only let you download your private key once, so keep this file for safe keeping!</p>
<div><div><p><a href="https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/a6f9d/create_key.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Create Key" title="Create Key" src="https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/f6afc/create_key.png" srcset="https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/7b5b4/create_key.png 188w,
https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/a80c4/create_key.png 376w,
https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/f6afc/create_key.png 752w,
https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/3f9be/create_key.png 1128w,
https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/a34ba/create_key.png 1504w,
https://preset.io/static/d7f5b004796c74d357fc5cb0da35181f/a6f9d/create_key.png 1528w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div></div>
<h3 id="connecting-bigquery-to-superset"><a href="#connecting-bigquery-to-superset" aria-label="connecting bigquery to superset permalink"></a>Connecting BigQuery To Superset</h3>
<p>Superset can query BigQuery datasets using the <a href="https://github.com/mxmzdlv/pybigquery">pybigquery</a> SQLAlchemy plugin.
We have detailed instructions on how to do this in our <a href="https://preset.io/blog/2020-05-18-install-db-drivers/">Installing Additional Drivers</a> blog post. </p>
<p><strong>Step 8.</strong> You'll need to adapt step 2.2 from that post to install <code>pybigquery</code>:</p>
<div data-language="text"><pre><code>echo "pybigquery" &gt;&gt; ./docker/requirements-local.txt</code></pre></div>
<p><strong>Step 9.</strong> After Docker has rebuilt the images and you've booted up the Superset service, navigate to <strong>Sources &gt; Databases</strong> in the navigation bar and then click the <strong>+</strong> button next to <strong>Filter List</strong>.</p>
<div><div><p><a href="https://preset.io/static/2b7e6d1ee49ca909c91bd640f8cc737e/4f7c9/new_database.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="New Database" title="New Database" src="https://preset.io/static/2b7e6d1ee49ca909c91bd640f8cc737e/4f7c9/new_database.png" srcset="https://preset.io/static/2b7e6d1ee49ca909c91bd640f8cc737e/7b5b4/new_database.png 188w,
https://preset.io/static/2b7e6d1ee49ca909c91bd640f8cc737e/a80c4/new_database.png 376w,
https://preset.io/static/2b7e6d1ee49ca909c91bd640f8cc737e/4f7c9/new_database.png 440w" sizes="(max-width: 440px) 100vw, 440px">
  </span>
  </a></p></div></div>
<p><strong>Step 10.</strong> Fill out the <strong>Add Database</strong> form with the necessary details.</p>
<ul>
<li><strong>Database</strong>: think of a memorable name for this connection.</li>
<li><strong>SQLAlchemy URI</strong>. The SQLAlchemy URI for BigQuery looks like: <code>bigquery://{project_id}</code>. To find your BigQuery project_id, navigate back to the <a href="https://console.cloud.google.com/bigquery">BigQuery console</a> and you'll find it under <strong>Resources</strong>.</li>
</ul>
<div><div><p><a href="https://preset.io/static/41fefd95078e4ffc8ef577049f35dd97/26dcc/project_id.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Project ID" title="Project ID" src="https://preset.io/static/41fefd95078e4ffc8ef577049f35dd97/26dcc/project_id.png" srcset="https://preset.io/static/41fefd95078e4ffc8ef577049f35dd97/7b5b4/project_id.png 188w,
https://preset.io/static/41fefd95078e4ffc8ef577049f35dd97/a80c4/project_id.png 376w,
https://preset.io/static/41fefd95078e4ffc8ef577049f35dd97/26dcc/project_id.png 538w" sizes="(max-width: 538px) 100vw, 538px">
  </span>
  </a></p></div></div>
<ul>
<li><strong>Expose in SQL Lab</strong>: make sure this checkbox is ticked.</li>
</ul>
<p>Here's a completed example:</p>
<div><div><p><a href="https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/16abd/successful_database.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Successful Database" title="Successful Database" src="https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/f6afc/successful_database.png" srcset="https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/7b5b4/successful_database.png 188w,
https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/a80c4/successful_database.png 376w,
https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/f6afc/successful_database.png 752w,
https://preset.io/static/df6314a78e9d34818f956a4d5a76fc1e/16abd/successful_database.png 940w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div></div>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>
<ul>
<li><strong>Extra</strong>: In this field, we need to add information from the BigQuery credentials JSON file we downloaded in Step 7. Superset expects a dictionary formatted the following way:</li>
</ul>
<div data-language="text"><pre><code>{
	"credentials_info": {
		&lt;DATA_FROM_CREDENTIALS_FILE&gt;
	}
}</code></pre></div>
<p>Here's a more tangible example (obviously you'd replace the blanks with data from your JSON file):</p>
<div data-language="text"><pre><code>{
	"credentials_info": {
		"type": "service_account",
		"project_id": "_____",
		"private_key_id": "____",
		"private_key": "-----BEGIN PRIVATE KEY-----
		\n____
		______
		END PRIVATE KEY-----\n",
		"client_email": "___",
		"client_id": "____",
		"auth_uri": "____",
		"token_uri": "____",
		"auth_provider_x509_cert_url": "____",
		"client_x509_cert_url": "____"
	}
}</code></pre></div>
<ul>
<li>Once you've filled out the form fields above, click the <strong>Test Connection</strong> to test if your Superset instance can talk to your BigQuery project.</li>
</ul>
<div><div><p><a href="https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/9288f/connection_success.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="Successful Connection" title="Successful Connection" src="https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/f6afc/connection_success.png" srcset="https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/7b5b4/connection_success.png 188w,
https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/a80c4/connection_success.png 376w,
https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/f6afc/connection_success.png 752w,
https://preset.io/static/4e69cf4e3fd1516506d6a1cade8a8831/9288f/connection_success.png 1126w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div></div>
<p>If you run into problems, we encourage you to join the Superset <a href="https://join.slack.com/t/apache-superset/shared_invite/zt-g8lpruog-HeqpgYrwdfrD5OYhlU7hPQ">community Slack</a> or ask your question on <a href="https://stackoverflow.com/questions/tagged/apache-superset+or+superset">Stack Overflow</a>.</p>
<h3 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h3>
<p>In part 2 of this blog post, we'll explore:</p>
<ul>
<li>how to add new BigQuery datasets in Superset</li>
<li>how to monitor and save costs when working with large BigQuery datasets</li>
<li>how to create Superset charts to form a dashboard from the PyPI downloads data</li>
</ul>
<p> The good news is, completing this series of tutorials will enable you to create Superset dashboards from any of the BigQuery public datasets.</p>
<p>If you'd like a more production-ready setup for Superset, we are building that hosted cloud solution at Preset. The solution is currently in alpha, and you can <a href="https://alpha.preset.io/en/alpha-program">sign up to try it out here</a>. It's a great opportunity for you to help shape this offering, influence our ambitious Superset roadmap, and access Preset’s expertise as an extension of your team.</p></div></div>]]>
            </description>
            <link>https://preset.io/blog/2020-08-04-google-bigquery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043002</guid>
            <pubDate>Mon, 03 Aug 2020 20:30:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Tencent PCG Uses Apache Kafka to Handle 10T+ Messages per Day]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24042525">thread link</a>) | @rmoff
<br/>
August 3, 2020 | https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As one of the world’s biggest internet-based platform companies, Tencent uses technology to enrich the lives of users and assist the digital upgrade of enterprises. An example product is the popular WeChat application, which has over one billion active users worldwide. The Platform and Content Group (PCG) is responsible for integrating Tencent’s internet, social, and content platforms. PCG promotes the cross-platform and multi-modal development of IP, with the overall goal of creating more diversified premium digital content experiences. Since its inception, many major products—from the well-known QQ, QZone, video, App Store, news, and browser, to relatively new members of the ecosystem such as live broadcast, anime, and movies—have been evolving on top of consolidated infrastructure and a set of foundational technology components.</p>
<h2><a id="kafka-at-tencent-png"></a>Apache Kafka<sup>®</sup> at Tencent PCG</h2>
<p>At our center stands the real-time messaging system that connects data and computing. We have proudly built many essential data pipelines and messaging queues around Apache Kafka. Our application of Kafka is similar to other organizations: We build pipelines for cross-region log ingestion, machine learning platforms, and asynchronous communication among microservices. The unique challenges come from stretching our architecture along multiple dimensions, namely scalability, customization, and SLA. Here are some of the notable requirements:</p>
<ul>
<li><strong>Workload.</strong> It takes close and continuous observation to fully grasp the dynamics of data in complex apps. In a highly seasonal and eventful environment of consumer internet with over a billion monthly active users, product promotion and large-scale experimentations often cause volume to burst up 20x from one day to another. At the peak, our pipeline needs to transfer 4 million messages per second (or 64 gigabytes/second) for a single product. Our ops team, therefore, is challenged with managing and optimizing clusters with more than a thousand physical nodes in total.</li>
<li><strong>Low latency and high SLA.</strong> As the organization moves quickly toward leveraging real-time analytics for driving business decisions, the requirements of data accuracy and timeliness become more rigid than before. Imagine when a video-consuming event is fed to the recommendation algorithm or when discovering hot trends that guide the incentivisation of content supply—it is desirable that the data can be used within a few seconds since its emission and with an end-to-end loss rate as low as 0.01%.</li>
<li><strong>Flexibility.</strong> Nowadays real-time data processing architectures are componentized and configurable. Consequently, the messaging system needs to handle frequent changes in the number of consumers, access pattern, and topic distribution without impacting performance. We cannot simply optimize the system for a static topology as a traditional ingestion pipeline.</li>
</ul>
<p>Ideally, we need a multi-tenant, gigantic pub/sub system to satisfy all these requirements. At peak time, it should reliably support data transfer at hundreds of gigabits per second. It should be provisioned almost instantly without disrupting existing workload; it also needs to tolerate single-node and cluster failure. Considering interface concerns, we want it to be compatible with the Kafka SDK as much as possible. After exploring the limitations of a single Kafka cluster, we’ve moved forward with a series of developments.</p>
<h2 id="federated-kafka-design"><a id="federated-kafka-design"></a>Federated Kafka design</h2>
<p>We chose to develop in the Kafka ecosystem for its maturity, rich set of clients and connectors, as well as superb performance among alternatives. On the other hand, there are a few gaps in using Apache Kafka to meet the requirements above. For instance, more than expected, we found during heavy usage that multiple disk failures caused insufficient replica or even cluster-level reliability problems. Moreover, expanding the capacity of a cluster (i.e., adding brokers) requires significant data rebalancing, often imposing hours of operational latency. Without fully automated capacity management, this greatly limits how we can support a large business.</p>
<p>Given that we decided to focus our initial enhancement on scalability and failure tolerance, we started off building a proxy layer that federates multiple Kafka clusters and provides compatible interfaces to both providers and consumers. The proxy layer presents logical topics to Kafka clients and internally maps them to distinct physical topics in each Kafka cluster. In the figure below, a logical topic with eight partitions (<code>P0–P7</code>) is distributed to two physical clusters each with four partitions (<code>P0–P3</code>).</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png" alt="P0-P7 | P0-P3" width="1999" height="522" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-300x78.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1024x267.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-768x201.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1536x401.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-350x91.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-600x157.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>The extra layer of abstraction of logical topics allows us to achieve the following, desirable behavior. First, we can expand the capacity of the data pipeline with little (re)synchronization overhead. In case two clusters at their maximum size cannot handle the predicted peak volume, we can easily deploy two additional clusters without shuffling any existing data. Second, fault tolerance is easier to manage with smaller clusters, as we can provision extra capacity at fine granularity and redirect traffic at a low cost. Lastly, in the (not-so-rare) event of physical cluster migration, the transparent proxy eliminates the need for any code and configuration change on the application side. We would only need to set the old clusters in read-only mode before it is completely drained, while associating the proxy with the new clusters. Such maintenance is not visible from the perspective of logic topics.</p>
<h2 id="key-components-and-workflows"><a id="key-components-and-workflows"></a>Key components and workflows</h2>
<p>In this section, we get into more details of the new components we built and how they interact in essential scenarios, as shown in the figure below. Two proxy services, one for the producer (<code>pproxy</code>) and another for the consumer (<code>cproxy</code>), implement the core protocols of the Kafka broker. They are also responsible for mapping logical topics to their physical incarnation. The application uses the same Kafka SDK to connect directly to the proxy, which acts as a broker.</p>
<p>In order to address the set of proxy brokers, we built a lightweight name service that maintains this relationship between client ID and the collection of proxy servers. The SDK will request the list of proxy brokers using client ID once at the beginning of the communication. Internally, the most complicated and bulky part of our implementation involves managing the metadata of the federated cluster, including both the state of the topics as well as the lifecycle of the proxy nodes. We extract the logic of the Kafka controller node (such as topic metadata) into a separate service, which is also called “the controller,” but it is different from Kafka’s own controller functionality. This service is responsible for collecting the metadata of physical clusters, composing the partition information logical topics, and then publishing it to the proxy brokers.</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png" alt="Name service" width="1999" height="639" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-300x96.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1024x327.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-768x245.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1536x491.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-350x112.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-600x192.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>We see some examples of interactions among these components and the Kafka clusters underneath during the most common operations:</p>
<ul>
<li><strong>Logical topic metadata retrieval</strong><br>
<img src="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png" alt="Logical topic metadata retrieval" width="1999" height="635" srcset="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png 1999w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-300x95.png 300w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1024x325.png 1024w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-768x244.png 768w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1536x488.png 1536w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-350x111.png 350w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-600x191.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"><br>
1. Controller reads the mapping between logical topic and physical topic from the config database.<br>
2. Controller scans metadata of all physical topics from each Kafka cluster.<br>
3. Controller finds the list of available <code>pproxy</code> from heartbeat message.<br>
4. Controller composes the metadata for the logical topics.<br>
5. Controller pushes both the topic mapping and topic metadata to proxy brokers.<br>
6. The metadata is sent to the Kafka SDK.</li>
</ul>

<h2 id="federated-kafka-in-practice"><a id="federated-kafka-in-practice"></a>Federated Kafka in practice</h2>
<p>Over the past year, we have gradually onboard many products in Tencent PCG to use the federated Kafka solution. Alongside the cluster, we have also been developing better monitoring and automated management tools. Our design principles have been quickly validated by many critical business use cases such as real-time analytics, feature engineering, and more. Up to now, we have deployed a few hundreds of clusters of various sizes, which collectively handle more than 10 trillion messages every day. The following table summarizes our typical setup and operational benchmarks.</p>
<table>
<tbody>
<tr>
<td>Average time to initialize a federated cluster</td>
<td>10 minutes</td>
</tr>
<tr>
<td>Average time to scaling up a federated cluster<br>
(add one physical cluster)</td>
<td>2 minutes</td>
</tr>
<tr>
<td>Metadata refresh latency</td>
<td>~1 second</td>
</tr>
<tr>
<td>Maximum physical clusters per logical cluster</td>
<td>60</td>
</tr>
<tr>
<td>Brokers per physical cluster</td>
<td>10</td>
</tr>
<tr>
<td>Total number of brokers provisioned</td>
<td>~500</td>
</tr>
<tr>
<td>Max cluster bandwidth (CPU ~40%)</td>
<td>240 Gb/s</td>
</tr>
<tr>
<td>Proxy overhead</td>
<td>Same as Kafka broker</td>
</tr>
</tbody>
</table>
<p>There are two notable limitations of the first design composed of cluster federation with a proxy layer. First, the distribution of logical partitions is not transparent to clients who use a hash key to specify the partition when producing a message. Consequently, when we add a new cluster, messages with identical keys might be delivered to different partitions and hence get out of order. This did not turn out to be a blocker for our current use cases for two reasons. First, we surveyed the product teams and found that they only use keyed messages occasionally. Furthermore, when they face the trade-off between application-level fault tolerance and scalability, they typically prefer the latter and sometimes settle with a mechanism to briefly halt production when cluster membership is updated.</p>
<p>A more fundamental limitation is that we have to frequently evolve the interface of the proxy broker as more functionalities need to be exposed and as native Kafka evolves. This leads to unnecessary code duplication and makes the whole system harder to manage. In the future, we will explore implementing similar semantics inside Kafka, as described in the next section.</p>
<h2 id="next-steps"><a id="next-steps"></a>Next steps</h2>
<p>As we explained above, Tencent is one of the largest Kafka users in the world, processing trillions of messages every day. This also means that to power our many use cases, we have successfully pushed some of Kafka’s boundaries. We are aware of the ongoing development and proposals within the Kafka community, and we further find that some of our ideas, such as abstracting out the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24042525</guid>
            <pubDate>Mon, 03 Aug 2020 19:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking about moving the site away from Netlify (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24042304">thread link</a>) | @kgraves
<br/>
August 3, 2020 | https://www.codesections.com/blog/leaving-netlify/ | <a href="https://web.archive.org/web/*/https://www.codesections.com/blog/leaving-netlify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    
  
  <p>I'm very strongly considering moving this site away from Netlify.  In fact, I'd go so far as saying that I'm planning to unless writing this post—or hearing from y'all—changes my mind.</p>
<p>Before I launch into why, though, I want to clarify: I've been very happy with Netlify.  They've delivered exactly what they promised: fast, free, static hosting backed by a global CDN.  Deploying is as easy as running <code>git push</code> in the terminal; if you're thinking about using them, you probably shouldn't let this post dissuade you.</p>
<p>So, given all those positives, why am I still thinking about migrating the site?</p>

<h2 id="the-problem-my-complexity-budget">The Problem: My Complexity Budget</h2>
<p>Basically, I'm starting to feel that my site is more complex than is justified by how simple my goals are.  Serving this simple, static site involves three separate CDNs: Netlify has their own CDN, they use the Akamai CDN, and they serve images from Amazon's Cloudfront CDN.  That's a lot of interconnected systems to depend on, and I could see it making debugging performance issues harder.</p>
<p>(On the other hand, I haven't <em>had</em> any performance issues, so maybe I'm borrowing trouble by thinking through debugging them?)</p>
<p>Somewhat relatedly, I'm not <em>thrilled</em> with the idea that Amazon is involved in serving my site—there's not a <em>ton</em> they can do with data from serving images (there aren't any cookies on my site, for example) but it does still feed a bit more data their way.</p>
<p>Perhaps more concretely, the complexity inherent in Netlify's setup means that I can't access simple server logs.  I'm a bit curious about how many readers my various posts get, but I've been reluctant to add any JavaScript tracking to my site.  I flatly refuse to add Google Analytics—the privacy implications are just too extreme.  I've considered adding <a href="https://usefathom.com/">Fathom</a>, but Fathom <a href="https://github.com/usefathom/fathom/issues/40">still uses cookies</a> and has tagged the issue requesting a change with <code>wontfix</code>.  Besides, self-hosting Fathom actually be <em>more</em> complex than just hosting the site itself: their recommended installation procedure involves installing Fathom, Postgres, and Nginx.  (In contrast, since the site is built into flat files, it can be hosted without a database—all it would need is Nginx).</p>
<p>That's just one example, of course, but it brings something into focus: using Netlify for hosting means buying in to their system—if something (here, accessing logs) isn't supported by their API, then there's just not anything you can do about it.  And there's no long-term guarantee that their API won't change in ways that might impact me; after all, I'm not a paying customer.  I wouldn't even blame them if they change their service in a way that hurts me at the expense of the people actually paying to keep the lights on (or, more to the point, paying to deliver the sort of returns their venture-capitalist investors expect).</p>
<h2 id="the-solution-a-simple-vps">The Solution: A Simple VPS</h2>
<p>The solution to all this is simple (or, The solution to all this is simplicity).  Since the site is just static files, I could throw it up behind a super simple Nginx server on basically any VPS.  (I'd probably go with Digital Ocean, but the point is that I could move it anywhere if DO didn't work out—it'd be simple enough to work with any server rather than tied into a specific API).  I could even roll my own server in Rust, which I've tested as providing <a href="https://www.reddit.com/r/rust/comments/a82w9b/can_a_rust_web_server_beat_nginx_in_serving/">similar performance to Nginx</a>.  Though if I went that route, I'd need to add in my own logging).</p>
<h2 id="the-problem-with-the-solution-global-speed">The Problem with The Solution: Global Speed</h2>
<p>I really love the idea of moving to simplicity, but there's one hangup.  All those CDNs Netlify was running my site through <em>did</em> have a purpose—they allow my site's assets to be served globally.  This doesn't much matter for visitors located near me—ironically enough, running <code>tracepath</code> showed that my site is <em>already</em> served from Digital Ocean servers for visitors from my location, so it wouldn't matter <em>at all</em>.  But my site currently (according to <a href="https://www.webpagetest.org/">webpagetest.org</a>, anyway) has essentially the same performance in Mumbai that it has in the U.S.  And I'd give that up if I hosted from a single server.</p>
<p>Of course, there are ways I could add a CDN back into my site—but that would be adding back in some of the complexity that I'm stripping away.  And doing so in a privacy-respecting way would probably get a bit pricy.</p>
<p>So, at least for the short term, I think I'd probably just accept that ditching Netlify would mean accepting slower site speeds for visitors that are half a world a way.  I <em>think</em> that trade off is worth it, but I feel bad saying so given that <em>I</em> wouldn't be the one dealing with the slower load times.</p>
<p>Anyway, that's what I'm thinking at the moment.  But I'm open to changing my mind—please let me know if I'm thinking about this all wrong.</p>


  

  
</section></div>]]>
            </description>
            <link>https://www.codesections.com/blog/leaving-netlify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24042304</guid>
            <pubDate>Mon, 03 Aug 2020 19:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Polynomial Encryption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24042073">thread link</a>) | @james1234
<br/>
August 3, 2020 | https://funwithsystems.com/polynomials/ | <a href="https://web.archive.org/web/*/https://funwithsystems.com/polynomials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://funwithsystems.com/polynomials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24042073</guid>
            <pubDate>Mon, 03 Aug 2020 19:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V OS using Rust: Graphics]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24041869">thread link</a>) | @azhenley
<br/>
August 3, 2020 | https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041869</guid>
            <pubDate>Mon, 03 Aug 2020 18:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Technical Introduction to Reinforcement Learning]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24041852">thread link</a>) | @idavidrein
<br/>
August 3, 2020 | https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9 | <a href="https://web.archive.org/web/*/https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041852</guid>
            <pubDate>Mon, 03 Aug 2020 18:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to assembly with Rust]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24041675">thread link</a>) | @lfn3
<br/>
August 3, 2020 | https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/ | <a href="https://web.archive.org/web/*/https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div>
  
  <p><span>Aug 3 2020</span></p><p>One of the things I’ve wanted to do for a while is really dig into
assembly and get into the weeds of how programs actually run.
A rework of the <code>asm</code> macro has <a href="https://blog.rust-lang.org/inside-rust/2020/06/08/new-inline-asm.html">recently landed</a> in nightly rust
so it seemed like a good time.</p>

<p>And compared to some other ways I’ve tried to approach this there’s a lot less
setup we need to do if we just use the <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018">rust playground</a> to
do all the heavy lifting.</p>

<p>My process for figuring things out has been pretty simple.
I write a tiny bit of rust code, look at the assembly output
and try to figure out what’s going on (with lots of googling).
I’m going to walk you through what I did, and what I figured
out.</p>

<p>Let’s start with the simplest possible thing I can think of:</p>

<pre><code>fn main() {
    1 + 2;
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=9500bb2bc3f638a4dd89e81fecafac0e">playground link</a></p>

<p>You can get the assembly output for this by clicking the three dots next to
<code>run</code> and selecting <code>asm</code> from the dropdown. You will probably also want
to change the flavour (often referred to as syntax elsewhere) of assembly to intel (rather than at&amp;t) <sup id="fnref:1"><a href="#fn:1">1</a></sup>
if it isn’t already, by clicking the toggle under the <code>config</code> menu.</p>

<p>The assembly output from this in debug mode is far more massive than you’d expect -
I get 157 lines. And most of it isn’t our program. The code we’ve written should
be fairly easy to find though, as the compiler helpfully labels all of the functions
with their crate and function names. In this case since we’re in the playground,
the create is implicitly <code>playground</code>, so we can find our code by searching with
<code>ctrl-f</code> for <code>playground::main</code>. Doing this gets me to:</p>

<pre><code>playground::main: # @playground::main
# %bb.0:
    ret
                                        # -- End function
</code></pre>

<p>So even though this is a debug build, evidently there’s still some optimization going on,
since there’s no numbers or anything that looks like it’s adding them together.
All that’s happening here is we’re returning (<code>ret</code>) back to the function that called <code>playground::main</code>.
Everything prefixed with <code>#</code> is a comment, and therefore ignored when we run this code.</p>

<p>The only other point of interest is the label <code>playground::main:</code> - anything suffixed with <code>:</code>
is a label we can jump to with various commands, and indeed if we continue searching for <code>playground::main</code>
we can find a rather indirected call to it in <code>main</code>. Hopefully by the end of this we’ll be understand that!</p>

<h3 id="avoiding-optimizations">Avoiding optimizations</h3>

<p>For now, let’s try and evade whatever’s doing the optimization:</p>

<pre><code>fn add() -&gt; usize {
    1 + 2
}

fn main() {
    add();
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=e06e9c1a6771d850be5e06abc6f70243">playground link</a></p>

<p>Again, searching for <code>playground::main</code> get us to:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    mov eax, 3
    ret
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push    rax
    call    playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>So we’ve got a bit more progress here. Still some optimization going on, since we don’t see 1 or 2 in the code,
just 3. We can see that being moved (<code>mov</code>) into the <code>eax</code> register in <code>playground::add</code>.
This must be how we’re returning the value back up to <code>main</code>.</p>

<p>And indeed, inside <code>main</code> we can see <code>push rax</code> - saving the value in the register <code>rax</code> to the stack, then a
call to our <code>add</code> function, then we <code>pop rax</code> off the stack. The <code>push call pop</code> sequence is to preserve
whatever values are in the registers used in <code>add</code>. It also just throws away the value we saved in <code>eax</code> in <code>add</code>,
because <code>eax</code> and <code>rax</code> are the same register. The table <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#General-Purpose_Registers_(GPR)_-_16-bit_naming_conventions">here</a>
shows how ‘skinnier’ registers overlap with their ‘wider’ counterparts.</p>

<h3 id="avoiding-optimizations-take-2">Avoiding optimizations, take 2</h3>

<p>So how can we make this actually do some math? Let’s try again:</p>

<pre><code>fn add(i: usize) -&gt; usize {
    1 + i
}

fn main() {
    add(2);
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=0d821a33f2375ecaf3671c825a415c83">playground link</a></p>

<p>So we’ve got a lot more going on this time:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    sub rsp, 24
    mov qword ptr [rsp + 16], rdi
    add rdi, 1
    setb al
    test al, 1
    mov qword ptr [rsp + 8], rdi # 8-byte Spill
    jne .LBB8_2
# %bb.1:
    mov rax, qword ptr [rsp + 8] # 8-byte Reload
    add rsp, 24
    ret

.LBB8_2:
    lea rdi, [rip + str.0]
    lea rdx, [rip + .L__unnamed_2]
    mov rax, qword ptr [rip + core::panicking::panic@GOTPCREL]
    mov esi, 28
    call rax
    ud2
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push rax
    mov edi, 2
    call playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>The thing we were actually trying to produce is finally in there!
We can see <code>add rdi, 1</code> in the output, surrounded by a pile of other
stuff. So what is all this other code?</p>

<p>Let’s start from the top of the call stack in <code>main</code>.
First we can see <code>2</code> is stored in the <code>edi</code> register
before we call <code>playground::add</code>, so we know our argument must be in
the <code>edi</code> register. Again, we can see the <code>push</code>, <code>pop</code> on <code>rax</code>, so that
must be the return value.</p>

<h3 id="looking-inside-the-function">Looking inside the function</h3>

<p>Now, looking into <code>playground::add</code> we first see <code>sub rsp, 24</code>. <code>rsp</code> is
the register that holds the stack pointer, so this is growing the stack
(since the stack grows downwards in x86<sup id="fnref:2"><a href="#fn:2">2</a></sup>). Further down we can see
we shrink the stack by the corresponding amount with <code>add rsp, 24</code>.</p>

<p>Then we have <code>mov qword ptr [rsp + 16], rdi</code>. This is copying the
value from <code>rdi</code> onto the stack at <code>rsp + 16</code> - the top of the region we just grew the stack by.
The <code>qword ptr</code> (quadword (i.e. 64bit) pointer) bit is a hint to disambiguate the argument.
Why is that pushed that onto the stack? I <em>think</em> this is just to make it easier to debug,
since we don’t ever access that value again.</p>

<p>In any case, we then proceed on to actually adding 1 to <code>rdi</code>.
The value is stored back in <code>rdi</code>, and importantly for what comes next,
we may set some of the <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#EFLAGS_Register">flags</a>.</p>

<p>Then it gets complicated again - we’ve got <code>setb al</code>. All of the <code>set*</code>
<a href="https://github.com/HJLebbink/asm-dude/wiki/SETcc">instructions</a>
deal with the flag register. The flag register is possibly the most magical
of registers, since it’s manipulated by a bunch of instructions as a side effect.</p>

<p>The last instruction we ran was <code>add</code>, which sets 6 of the the flags:
<a href="https://en.wikipedia.org/wiki/Carry_flag">carry</a>, <a href="https://en.wikipedia.org/wiki/Parity_flag">parity</a>,
<a href="https://en.wikipedia.org/wiki/Adjust_flag">adjust (aka auxiliary carry)</a>, <a href="https://en.wikipedia.org/wiki/Zero_flag">zero</a>,
<a href="https://en.wikipedia.org/wiki/Sign_flag">sign</a> and <a href="https://en.wikipedia.org/wiki/Overflow_flag">overflow</a></p>

<p>In this case we’re checking if the carry bit is set, and then setting the <code>al</code>
register to 1 if that’s the case. What is this actually doing though?
The carry bit gets set to 1 if there is a <code>carry</code> from the two numbers we add,
meaning the resulting number is too big to be stored in the register.
What should we do in that case? Let’s read on to find out.</p>

<p>Then in the next line (<code>test al, 1</code>) we’re checking if the value in <code>al</code> is equal to one.
(<code>test</code> does a a bitwise and operation on the two arguments - like <code>&amp;</code> in rust.)
This sets some more flags, notably the <code>zero</code> flag, which is then read by the following <code>jne</code> instruction.</p>

<p><code>jne</code> stands for jump if not equal (and again there’s a series of
<a href="https://en.wikibooks.org/wiki/X86_Assembly/Control_Flow#Jump_Instructions">other</a>
<code>j*</code> instructions). Since it uses flags, it just takes a single argument: where to jump to.</p>

<p>Looking at where that jumps to gives us a big hint about the intent of the
logic above: <code>core::panicking::panic@GOTPCREL</code> really gives it away.
Basically all of this chunk of assembly from <code>setb</code> to <code>jne</code> is checking if we’ve overflowed
the register and panicking if we have.</p>

<p>The one bit we didn’t discuss is <code>mov qword ptr [rsp + 8], rdi # 8-byte Spill</code>.
As the comment implies this is “spilling” the value from the <code>rdi</code> register
onto the stack, since the code we’re possibly about to jump to might
overwrite that register - immediately after the <code>jne</code> we load the value back off
the stack.</p>

<p>Finally we shuffle the stack pointer back to it’s starting point, and <code>ret</code>
back to the caller. <code>ret</code> uses the last value on the stack (which is pushed by <code>call</code>)
to figure out where to jump back to, so moving the stack pointer back is <em>very</em> important.</p>

<p>So maybe at this point we’ve seen enough to take a stab at replacing the guts of the <code>add</code>
function with the <code>asm!</code> macro. Since we’re interested in performance,
we’ll ignore those pesky overflow checks, and just assume that we’re within the bounds of <code>u64</code>.</p>

<p>The biggest new thing we’ll have to deal with here is specifying the <code>in</code> and <code>out</code> registers.
The <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#guide-level-explanation">rfc</a>
has a very approachable explaination of these, so I’d recommend reading that.
There’s a skeleton you can start with <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=d511cf5e95ba5cdfbcffaebaf5f72300">here</a>,
if you want to have a go yourself.</p>

<p>The version I’ve cooked up looks like <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=669b4155a1d818cc5c73b117b9454d48">this</a>.
This is probably the “fanciest” possible version of this, since we’re using as many features of the asm macro as possible:</p>

<ul>
<li>we’re letting the rust compiler pick the register we use, and then writing it in using the
<a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#inputs-and-outputs"><code>format</code> string behaviour</a> of the <code>asm</code> macro.</li>
<li>we’re also using <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#late-output-operands"><code>inlateout</code></a> to
hint that we can just use a single register.</li>
</ul>

<p>This seems like a reasonable point at which to break. We’ve covered a reasonable chunk of the instruction set in x64 assembly,
and seen examples of most of the classes of instructions. There’s tons more we can explore, like:</p>

<ul>
<li>How do loops work?</li>
<li>What happens when we use values that don’t just fit in registers?</li>
<li>How do we make a syscall?</li>
</ul>

<p>Hopefully the resources I’ve linked to from here are sufficent for you to continue digging in if you want,
and maybe I’ll manage to follow this up.</p>

</div>

      </div></div>]]>
            </description>
            <link>https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041675</guid>
            <pubDate>Mon, 03 Aug 2020 18:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing UFCS for C++ in Clang]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24041376">thread link</a>) | @foxhill
<br/>
August 3, 2020 | https://dancrn.com/2020/08/02/ufcs-in-clang.html | <a href="https://web.archive.org/web/*/https://dancrn.com/2020/08/02/ufcs-in-clang.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <p> 2020/08/02 </p>
        
<p>tldr; Unified function calling syntax (UFCS) is useful and elegant. I’ve implemented a variant of UFCS that resembles C#’s “extension methods”, in Clang, which you can check out at <a href="https://github.com/dancrn/llvm-project">https://github.com/dancrn/llvm-project</a>.</p>

<h2 id="outline">Outline</h2>
<p>Proposals for UFCS in C++ has been a somewhat perennial discussion (<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1585.pdf">N1585</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4165.pdf">N4165</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4174.pdf">N4174</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf">N4474</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0079r0.pdf">P0079R0</a>), with seemingly positive discussion from many, including both Herb Sutter and Bjarne Stroustrup. C# has a take on UFCS called extension methods, and personally, I’ve found them to be overwhelmingly useful. If you’re unfamiliar C#’s extension methods, they look something like this:</p>

<div><div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Extensions</span>
<span>{</span>
  <span>public</span> <span>static</span> <span>string</span> <span>ValueOrDefault</span><span>(</span><span>this</span> <span>string</span> <span>input</span><span>,</span> <span>string</span> <span>defaultValue</span><span>)</span>
  <span>{</span>
    <span>return</span> <span>String</span><span>.</span><span>IsNullOrWhiteSpace</span><span>(</span><span>input</span><span>)</span> <span>switch</span> <span>{</span>
      <span>true</span> <span>=&gt;</span> <span>defaultValue</span><span>,</span>
      <span>false</span> <span>=&gt;</span> <span>input</span>
    <span>};</span>
  <span>}</span>
<span>}</span>

<span>public</span> <span>string</span> <span>GetValue</span><span>(</span><span>string</span> <span>str</span><span>)</span>
<span>{</span>
  <span>return</span> <span>str</span><span>.</span><span>ValueOrDefault</span><span>(</span><span>"No value provided"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Extension methods, when invoked, look like first class methods on the type they are defined on. The example provided doesn’t have much benefit over the existing free-form call (i.e. <code>Extensions.ValueOrDefault(str, "nothing")</code> - and this still is also a valid way of calling that method). However, static extension methods come into their own when viewed as generic approaches to extending already existing classes that cannot be modified. One such C# library is <a href="https://github.com/louthy/language-ext">LanguageExt</a>, which provides functional extensions to the base <code>IEnumerable</code> interface (amongst <em>many</em> other things), although there are a lot of other examples that extend other commonly used libraries.</p>

<p>Unfortunately, whilst proposals resurface every once in a while, activity on unified call syntax seem to have stagnated. I want to see what it takes to implement it, and who knows, if enough people like and use UFCS, it might make it into.. C++30, maybe?</p>

<h2 id="ufcs-models">UFCS models</h2>
<p><a href="https://brevzin.github.io/c++/2019/04/13/ufcs-history/">Revzin</a> has an excellent couple of articles that describe UFCS more generally. Essentially, UFCS can be split into two categories of behaviors: “candidate set” functionality describes which functions are considered for a particular invocation style, and “overload resolution” approaches that describe how to determine which member or function should be chosen when there is more than one candidate. Without repeating those descriptions, this model can be considered to be CS4 - the addition of syntax to indicate UFCS candidacy - and OR2 - perform overload resolution as normal with all candidates. I wont spend too much time going into why I’ve made these choices, but briefly:</p>

<h2 id="choice-of-cs4">Choice of CS4</h2>
<p>Whilst not strictly the “most pure” decision, I think that it’s sensible to allow users to specify which functions they intend to be used in overload resolution. And, whilst not <em>strictly</em> speaking a priority, keeping the candidate set as small as possible would be beneficial from the perspective of compilation times. It also allows UFCS to be backward compatible with existing code, means that I think this is the most sensible approach to take.</p>

<h3 id="ufcs-syntax-additions">UFCS syntax additions</h3>
<p>There are two obvious ways of using the <code>this</code> keyword to indicate UFCS candidacy, as a parameter qualifier, or as a parameter name - for anyone familiar with C#, it’s clear that CS4, along with a <code>this</code> parameter qualifier was style chosen when implementing its idea of UFCS. There are many sensible choices for syntax additions, but these where two I considered. These both look like:</p>

<div><div><pre><code><span>// 1. 'this' parameter name</span>
<span>int</span> <span>func</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>this</span><span>);</span>

<span>// 2. 'this' qualifier</span>
<span>int</span> <span>func</span><span>(</span><span>this</span> <span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>param</span><span>);</span>
</code></pre></div></div>

<p>There are some drawbacks to option 1.:</p>
<ul>
  <li>The implicit <code>this</code> value generally has access to private &amp; protected members of a class, members that UFCS functions would not have access to.</li>
  <li>The parameter type was chosen to demonstrate an inconsistency: <code>this</code>, when used in a member function is generally considered to be a pointer, i.e., we use <code>this-&gt;value</code> rather than <code>this.value</code>. What should we accept for UFCS functions?</li>
</ul>

<p>The alternative has a couple of (admittedly smaller) issues:</p>
<ul>
  <li>UFCS candidacy is most easily seen as a is a property of a function, not a parameter - why change the parameter?</li>
  <li><code>this</code> is a keyword that generally represents a value, and whilst C++ has repurposed keywords before - <code>auto</code> - this might not be desirable.</li>
</ul>

<p>In the end, the first option seemed to present more questions than it answered, so I opted for the second alternative.</p>

<h3 id="choice-of-or2">Choice of OR2</h3>
<p>I think the worst case scenario for UFCS would be one where the member functions of a class change, masking a UFCS call in a another part of the code that interacts with values of that type. For instance, consider the following case:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>// context is defined with a single "read from file" function.</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
<span>};</span>

<span>// and in consuming code, has the following extension defined</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Now, the library is updated to a later version, which includes its own <code>read_from_file</code> method:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
  <span>int</span> <span>read_from_file</span><span>(</span><span>FILE</span> <span>*</span><span>fp</span><span>);</span>
<span>};</span>

<span>// this function can only be used with regular function call syntax</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Preferring member calls over UFCS calls in this case would silently change behaviour of this code, without any obvious change to the <code>read_from_file</code> method. Broadly speaking, I don’t think it’s sensible to prefer one type of call over the other, so this would seem to rule out any form of overload resolution that has preference for one type of call over the other. Therefore OR1 and OR2+ don’t seem like the best approaches, and the choice of CS4 rules out OR3 from being an option. In my implementation, any ambiguity between calls is treated as an error, as it is now.</p>

<p>It should be noted that the choice of OR2 is in contrast with C#’s extension methods, where, in the case of ambiguity between a UFCS candidate and a member function, the member function is always chosen (i.e., C# uses OR2+).</p>

<h2 id="ufcs-for-c">UFCS for C++</h2>
<p>In summary, the following is what I’m going to be implementing:</p>

<ol>
  <li><code>this</code> precedes the declaration specifiers (<code>const</code>, <code>volatile</code>, etc.) of a file/namespace scoped function’s first parameter.</li>
  <li>Class methods cannot be defined to be UFCS candidates (although that could probably be relaxed for non-instance methods).</li>
  <li>Calls of the form <code>x.f(y)</code>, in addition to performing member lookup, also perform name lookup for functions of name <code>f</code>, and overload resolution with arguments <code>x</code>, and <code>y</code>.</li>
  <li>Overload resolution proceeds as normal, i.e., if the candidate set contains a class method and a UFCS candidate, then there is no preferential treatment of either, and this is an error.</li>
</ol>

<h3 id="an-example">An example</h3>
<p>In summary, we will be able to define functions that appear to be methods defined on a class as such:</p>

<div><div><pre><code><span>class</span> <span>foo</span> <span>{</span>
  <span>private:</span>
  <span>std</span><span>::</span><span>string</span> <span>m_bar</span><span>;</span>

  <span>public:</span>
  <span>foo</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>bar</span><span>)</span><span>:</span>
  <span>m_bar</span><span>(</span><span>bar</span><span>)</span>
  <span>{</span> <span>}</span>

  <span>std</span><span>::</span><span>string</span> <span>get_bar</span><span>()</span>
  <span>const</span> <span>noexcept</span>
  <span>{</span> <span>return</span> <span>m_bar</span><span>;</span> <span>}</span>
<span>};</span>

<span>int</span> <span>get_bar_length</span><span>(</span><span>this</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>val</span><span>)</span> <span>{</span>
  <span>return</span> <span>val</span><span>.</span><span>get_bar</span><span>().</span><span>length</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>And using these methods looks like:</p>

<div><div><pre><code><span>void</span> <span>f1</span><span>()</span>
<span>{</span>
  <span>auto</span> <span>val</span> <span>=</span> <span>foo</span><span>(</span><span>"pasta"</span><span>);</span>

  <span>// the two calls are semantically identical</span>
  <span>assert</span><span>(</span><span>val</span><span>.</span><span>get_bar_length</span><span>()</span> <span>==</span> <span>get_bar_length</span><span>(</span><span>val</span><span>));</span>
<span>}</span>
</code></pre></div></div>

<h2 id="clang">Clang</h2>
<p>I’ll forgo an introduction to Clang here - I expect any readers will be familiar with it. I’ve been motivated to start with Clang rather than GCC primarily because of Saar Raz’s story on getting behind Clang’s <a href="https://www.youtube.com/watch?v=Y1o4rc9P1FQ">implementation of concepts</a>. In any case, Clang seems like a suitable basis for implementation:</p>

<ol>
  <li>Clang is actively maintained with hundreds of contributers,</li>
  <li>code quality in Clang is widely regarded to be clean and consistent,</li>
  <li>acceptance into Clang, if it were to happen, may encourage discussion on UFCS, and</li>
  <li>it could be fun :)</li>
</ol>

<h3 id="implementation">Implementation</h3>
<p>I started UFCS in clang “for real” in around April of this year, although I had been reading and thinking about it on and off probably since September of 2019. In general I thought the code quality in Clang was decent, and whilst the learning curve was probably the steepest I’ve ever encountered, I was impressed with how little you needed to fully understand to make something work - the code is truly quite modular. That said, getting something working versus something that is complete requires understanding very large regions of code. Parsing C++ is what a lot of people would consider to be exotic, and so small changes in one place can have effects in places that you would not expect.</p>

<p>As it stands, I have a working implementation that passes all the tests in <code>make clang-test</code>. Of course, ‘Parse’ and ‘SemaCXX’ tests have been added, <code>cxx-ufcs.cpp</code> and <code>unified-call-syntax.cpp</code> respectively. I’ve added appropriate additional diagnostic messages (albeit as parser errors, rather than semantic analysis errors), though there are some others that I would like to add in. I’ve tested my custom version of Clang on a few projects, and it seems to work as expected, too. Overall, I’m quite satisfied with how it’s turned out, and I (naively) hope someone other than myself will give it a go :)</p>

<h3 id="using-ufcs">Using UFCS</h3>
<p>If you want to try UFCS, then you can checkout and build Clang from <a href="https://github.com/dancrn/llvm-project">here</a>, there’s nothing extra to configure (although I recommend you don’t install it in the default prefix!). To enable UFCS, you’ll need to pass an additional argument to Clang when invoking it, <code>-fufcs</code>. The front end driver hasn’t been changed at all, so you’ll most likely need to pass it through to the compiler manually:</p>

<div><div><pre><code> $ /path/to/clang -Xclang -fufcs file.cpp
</code></pre></div></div>

<p>Again, given the design of this implementation, there shouldn’t be any issues with compiling existing code. If this is not a case, then feel free to create an issue on GitHub!</p>

<h2 id="remaining-work">Remaining Work</h2>
<p>Whilst I’m moderately confident that my changes work as intended, I do not consider this to be “done”. There are a few things that feel not quite right, and, even if this is never merged into clang (which …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dancrn.com/2020/08/02/ufcs-in-clang.html">https://dancrn.com/2020/08/02/ufcs-in-clang.html</a></em></p>]]>
            </description>
            <link>https://dancrn.com/2020/08/02/ufcs-in-clang.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041376</guid>
            <pubDate>Mon, 03 Aug 2020 18:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Years at Roblox]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24041338">thread link</a>) | @nabla9
<br/>
August 3, 2020 | https://zeux.io/2020/08/02/eight-years-at-roblox/ | <a href="https://web.archive.org/web/*/https://zeux.io/2020/08/02/eight-years-at-roblox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>

02 Aug 2020

</span></p><p>I joined Roblox at the end of 2012 as a rendering engineer; I had just spent more than a year working on various titles from FIFA franchise after years of console game development and was becoming a bit tired of the “big game development”. My work on FIFA was as a contractor and I got an offer for a full-time position, but I also had a friend who worked at Roblox reach out and offer me to move to California and work on Roblox. I knew absolutely nothing about Roblox, but California was nice and my friend told me it would be awesome. The platform was so different (and so strange!) that I decided to take a chance - here I am, 8 years later, still working at Roblox and enjoying it. I started on my first full time job in April 2007 so at this point I’ve worked for 13 years in game development and 8 of them were at Roblox.</p>

<!--more-->

<p>My memory works in interesting ways. I remember my interview pretty well, I remember having lunch at some place in San Mateo downtown near the Roblox HQ - a few people were at lunch including Roblox CEO David Baszucki and I remember him asking many questions about my thoughts about the engines and rendering, and distinctly remember not finishing most of my lunch because I talked most of the time. However I don’t really remember what was going through my head in regards to my perception of Roblox - why did I join besides just thinking I want to do something else for a change? Who knows, but I am glad I did.</p>

<p>I don’t really understand why Roblox is so successful - you can invent all sorts of reasons in retrospect but it’s hard to validate them, and if you came to anybody back in 2012 and asked for an investment to build a platform where all games are user generated and run on a custom engine with a custom toolset and all users participate in a giant virtual economy and …, I think you’d have gotten a blank stare.</p>

<p>But I do understand that I found the perfect place for me, especially at that point in my career - I enjoy working on game technology but I never liked working on actual games, and Roblox maximizes the number of developers who can use the technology you work on while maintaining a good autonomy and a very wide range of problems you’d need to solve. It’s very hard to get bored here.</p>

<p>I think I could talk for hours about Roblox - it somehow became a huge part of my life. I was very fortunate to join at the time when I did and witness the growth of our technology and business. I am really unsure of what the future holds but it’s hard to imagine what, if anything, comes after Roblox - I certainly don’t intend to leave any time soon…</p>

<p>So I thought it might be fun to do what I’ve planned to do for a year or more now, and to go over all decently sized projects I’ve ever worked on at Roblox. This is based on resummarizing and reliving the source control history, which tells me I’ve had 2752 changes that made it to our main branch, with merge commits counting as one, so, uh, this blog might be on a larger side. Hopefully this will be fun!</p>

<p>Before we begin, I just want to conclude this by saying that I’m very grateful to the Roblox leadership for treating me well, for all the friends and colleagues I made along the way, and for the wonderful Roblox community. The reason why I still enjoy what I do is because whenever I write about a new big thing I’m working on or a small feature or even a bug fix, it’s usually met with excitement which keeps me going. Thank you all from the bottom of my heart. I don’t think I could have done it without you and I hope this continues for as long as possible despite the current trying and uncertain times.</p>



<p>Notably including half-pixel offset fixes for Direct3D9 which I guess is a rite of passage for rendering engineers. The rendering code back then was based on OGRE rendering engine, so I had to learn that, and this was also my first time using OpenGL professionally - prior to that I’ve used Direct3D 9 and proprietary console APIs, and Direct3D 10/11 as a hobby.</p>



<p>Initially added for “100 player” project, in October it evolved to render all parts and continued to be used as part renderer until the introduction of instancing in 2018. Otherwise known as “featherweight parts”. This was further optimized and deployed around November 2012. Most of this code survived to this day but evolved over time, and is still used when instancing doesn’t apply.</p>

<p>The core idea in this system was to dynamically batch meshes together, for characters this would be based on the character model hierarchy, and for everything else the grouping is spatial. This allowed us to reduce the number of draw calls, which was a big concern due to both driver overhead and inefficiencies in OGRE.</p>

<p>This would pave the way for what eventually turned out to be a complete, but gradual, rewrite of the rendering stack. The main motivation for this was always performance - what we ended up let us port to mobile (the old rendering code was nowhere near fast enough even for relatively simple scenes), and break new grounds on the number of objects we could render in a frame.</p>



<p>One of a few OGRE upgrades we’ve needed to do, this one was to get better GLES support. It was pretty painful to do those, just like any other big middleware update is. Read further to learn what happened to OGRE eventually…</p>

<p>One thing I remember from doing these is that documentation in source code makes the upgrade process that much more painful. I had scripts that changed the copyright years in headers back to whatever they were in our tree just to make merging less painful, but there was some OGRE upgrade where 70% of the changes were documentation, and this was very hard to get through.</p>

<p>The reason why these were challenging in general is that whenever we did an upgrade we had to a) merge our plentiful changes with the new code, b) gate dangerous parts of the upgrade with flags. We’ve used the same system of feature flags (we call them fast flags) since I joined Roblox which allows us to dynamically disable parts of the release based on metrics, but this requires actually isolating changes behind if statements selectively - which for OGRE was sometimes necessary as we didn’t know what the impact of some low level change in OpenGL code would be.</p>



<p>Before this we had hand-translated shaders, which started to be painful to maintain. The first version of the pipeline used hlsl2glsl and glsl-optimizer (same as Unity back in the day). We are using version 3 today, see below!</p>

<p>Since this was done at the point where we used OGRE, the compiler would take HLSL files, preprocess and translate them to optimized GLSL, and save the resulting GLSL back to disk - which would then be loaded by OGRE directly through the material definition file. Eventually we replaced this with a binary shader pack that could store GLSL code for OpenGL and shader bytecode for other APIs, but back then we shipped HLSL and GLSL source and compiled HLSL code on device!</p>



<p>Our equivalent of “Steam Hardware Survey” that went through SQL databases and coalesced various system information bits to help us understand the hardware at the time. This was during my era of obsession with F#, so it was written in F# instead of something like Python. We don’t use this anymore and don’t even have the SQL database in question!</p>

<p>We never published the resulting data, and I’m not sure how often we used it to make decisions, but it was fun to look at the number of graphics cards from various vendors or amount of RAM or resolution a typical Roblox user has.</p>



<p>Although I was hired as a rendering engineer, I had a lot of really deep low-level systems experience and as a consequence ended up engaging in both optimization work and security related work from the very beginning. I don’t do this anymore these days but I was often involved in the security work for the first 3 or 4 years. Now we fortunately have people who can do this full time and better than I could :)</p>



<p>A second part of “100 player project”, necessary to render every character in one draw call (these were really expensive for us back in the day!). A side effect included some resolution sacrifices on character items that shirt creators aren’t fond of. The new system managed the atlas texture memory, rebaking humanoids far away to smaller textures to conserve texture memory. The compositor survived with minor changes to this day, although we’re now working on a new one.</p>

<p>The compositor was built in a very configurable fashion, allowing the high level code to specify the layout to bake, and managing all the complex asynchronous processing and budgeting by itself. This allowed us to switch the composit layout completely years later for R15.</p>



<p>At the end of 2012 we were actively working on the mobile port. Since then we’ve had to do a lot of work in a lot of different parts of the engine to make data structures smaller and algorithms - faster. Of course you’re never done with optimizations so we do this to this day. Curiously, our minimum spec on iOS stayed the same since the initial launch in 2012!</p>

<p>A fun fact is that even though we started with iPad 2 as the min. spec we discussed adding support to iPad 1 after launch. At the time there were a lot of people who couldn’t play Roblox on iOS on older hardware. However the performance characteristics of those devices were just… not good enough. You could touch the screen with the finger and pan the camera, and during panning you lost 30% of a single available core to the OS processing the touch. We decided to not add support for this, and 8 years later it seems like a great decision for sure :D</p>



<p>It was very hard to use Xcode Instruments to profile frame spikes on an iPad; to try to figure out how to get our performance to a better place on mobile, I wrote some ad-hoc code to dump all internal log events to a binary stream, and a desktop UI tool in F# and WPF to visualize it. This included a Lua profiler as well that could display profiles of Lua code in a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zeux.io/2020/08/02/eight-years-at-roblox/">https://zeux.io/2020/08/02/eight-years-at-roblox/</a></em></p>]]>
            </description>
            <link>https://zeux.io/2020/08/02/eight-years-at-roblox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041338</guid>
            <pubDate>Mon, 03 Aug 2020 18:18:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A super quick rundown on SEO]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24041239">thread link</a>) | @entreprenerd
<br/>
August 3, 2020 | https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The two primary ways for people to find you on the internet are paid ads and search engines. We discussed paid ads <a href="https://www.entreprenerd.blog/live-streams/marketing-month-week-2">a few weeks ago</a>, now let's talk about search engines.</p><p>"SEO" is Search Engine Optimization - it's how Google and Bing and other search engines can tell whether or not your website should come up when someone searches for something.</p><p>The two main pieces of SEO are:</p><ul role="list"><li>Keywords / Content</li><li>Backlinks</li></ul><p>Keywords are just words and phrases you want to rank for - meaning you show up when someone googles them. For instance, I personally want to rank for words like "entrepreneurship" and phrases like "how to become an entrepreneur." So, if my website is full of articles and videos and information about those words and phrases, I'm more likely to pop up when someone types them into google.</p><p>So, how do you find keywords? I use a tool called <a href="https://ahrefs.com/">ahrefs</a> - it's not free, but it's close. They have "$7 for 7 Days" trial periods, and in order to assemble a solid list of keywords you can use for the next year, you'll really only need those 7 days. (Plus, you can always sign up for more trials using different emails in the future - just REMEMBER TO CANCEL your subscription)</p><p>After you sign up, go to "Keyword explorer" and start typing ideas in. Use each of the tabs on the left under "Keywords Ideas" - and create a list to add any keywords you find that make sense for your brand. Usually, I filter by "KD" (Keyword Difficulty) to anything lower than 25. Beyond 25, unless you're producing an incredible amount of content, you're going to have a lot of trouble.</p><p>After you compile a big fat list of keywords you like, go to the list page and export it to excel so you can use it after your trial period expires. Now you know what to target.</p><p>The next thing is content, and this is where things get to be a black box. Content is just articles and written posts on your website that contain the keywords we compiled. If a big keyword for me is "how to become an entrepreneur" then you bet I'm going to write an article with that title. However, I've talked to a good number of SEO professionals, and the best advice they can give is "Write well." It's tough to know what exactly you should put in your content that makes it rank higher, so the best thing you can do is use proper grammar, make it readable, and do what the title suggests the article will say.</p><p>A few tools I've seen that tend to help content get written well are <a href="http://grammarly.com/">Grammarly</a> and <a href="https://www.dashword.com/">Dashword</a>. Grammarly just helps you use proper grammar - it's free and awesome. Dashword is a new tool I found on ProductHunt that seems to help you position keywords nicely in your content so it ranks higher - though I haven't tested it and it is quite expensive.</p><p>So now you're writing content with the right keywords - but there's more you can do. You can use "backlinks" - links from other successful websites - to boost how well your website overall ranks. Basically, if google sees Entrepreneur Magazine (which ranks well in terms of "entrepreneurship" keywords) has an article or two that link to my website, then google will think my website is more important, and rank me higher. </p><p>So, we want other websites to suggest our website as a resource. We can do that by looking up the keywords we want to rank for - just type them in google - and see if any blogs pop up. If you find blogs or websites that rank well, use a simple email finder like <a href="https://hunter.io/">Hunter.io</a> to find whoever is in charge and reach out to them to ask to write a guest blog post. They get free content, and in the article you get to put a backlink to your website. Some blogs will even have a form just to submit guest post requests.</p><p>Lastly, you can use question-answer websites like <a href="https://www.quora.com/">Quora</a> to help push traffic in your direction. If, while you're googling your keywords, you find a few questions on Quora or WikiHow that you think you can answer, do it. For instance, if someone asks "what podcasts are great for learning entrepreneurship?" I might answer and reference my live stream content. That provides a backlink on a ranking question, and if people like that answer, they can also find you directly through it.</p><p>Beware, all of this sounds pretty great, but google takes anywhere between 4 to 6 months to actually see what you've created. If you post a bit of content now, you'll have to wait a while for the benefit to actually kick in, and for people to find your website through it. SEO is a long-term investment, so plan accordingly.</p><p>That's pretty much the basics. There are a lot more nuances like making sure your website is structured the right way and how to build your sitemap, but this should be all you need to know to get started!</p><p>If this was helpful at all, a retweet would be amazing. It really helps me spread the word - but of course, no pressure at all! :)</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041239</guid>
            <pubDate>Mon, 03 Aug 2020 18:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Back into Interviewing Shape]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24041178">thread link</a>) | @bonobo886
<br/>
August 3, 2020 | https://www.beta-neil.com/posts/a-new-job/ | <a href="https://web.archive.org/web/*/https://www.beta-neil.com/posts/a-new-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>February 2020 marked an entire year <a href="https://www.beta-neil.com/posts/goodbye-brightwheel/">since I left my last job</a>. I spent a lot of 2019 thinking about what to do next (a topic for a later blog post), and after many conversations with my wife and extended family, I ultimately decided to get back on the job market.</p>
<p>It had been over 5 years since I last interviewed for a software engineering job, and the idea of getting back into the interviewing game was daunting. My financial and familial obligations gave me about a month to find employment, so I had to spend as much of that time as I could, brushing up on the skills I felt weakest in.</p>
<p>Common software engineering interview practices are <a href="https://medium.com/datadriveninvestor/lets-stop-with-the-whiteboard-interviews-please-1355a0638087">notoriously bad</a>. Despite that, nearly 90% of engineering interviews always consist of some type of whiteboarding component, so I knew that I had to get stronger at the weakest part of my interviewing game: <em>data structures and algorithms</em>.</p>
<p>I put together a month long curriculum that consisted of 70% data structures and algorithms, 20% system design and 10% practice interviews. During that month, I also made it clear to recruiters on LinkedIn, and sites like Hired, Angellist and Vettery that I was ready to start looking, but wouldn't be available to interview for at least 30 days.</p>
<p>Since I wasn't working full-time, I had the luxury of time to study for 4 hours a day, 6 days a week. My days would mostly be split studying or listening to lectures in the mornings, and doing practice questions via <a href="https://www.beta-neil.com/posts/a-new-job/www.leetcode.com">Leetcode</a> and <a href="https://www.beta-neil.com/posts/a-new-job/www.hackerrank.com">hackerrank</a> in the afternoons. On Tuesdays and Thursdays I'd do a 1 hour practice interview using <a href="https://www.pramp.com/#/">Pramp</a>.</p>
<h3 id="the-curriculum">The Curriculum</h3>
<h4 id="data-structures-and-algorithms">Data Structures and Algorithms</h4>
<p>I learned how to program as a teenager by modding games and making websites for my friends. I didn't study computer science in college and never had the opportunity to drill data structures and algorithms into my head the way that many computer science undergrads do. I always had some insecurity about my data structures and algorithms weaknesses, so my goal for this round of interviews (aside from getting a job) was to gain enough confidence in my data structures and algorithms so that I would know that I had my bases covered any time I walked into an interview.</p>
<p>My curriculum consisted of two textbooks and a set of online lectures.</p>
<p>The first book and most important book I worked through was <a href="https://www.amazon.com/gp/product/B00N4EQ1X4/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00N4EQ1X4&amp;linkCode=as2&amp;tag=neilslist-20&amp;linkId=e8ce19013009469f71b405f4dccb3d67">The Algorithm Design Manual</a> by Steven S. Skiena. This book does an excellent job working through highly complex algorithms and data structures, all while keeping the subject matter rooted in practical applications.</p>
<p>The goal with this book was to read and finish all exercises for at least one chapter each day. On Sundays I'd review my notes and work through 4 - 5 leetcode questions that corresponded to some of the chapters I read in the previous week.</p>
<p>The second book, <a href="https://www.amazon.com/gp/product/111941847X/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=111941847X&amp;linkCode=as2&amp;tag=neilslist-20&amp;linkId=e66f39c5c143fbda7fa33d23fc9e3e3b">Programming Interviews Exposed</a> is a classic. I bought this book during my first year as an engineer, and hadn't read it or practiced with it since at least 2011.</p>
<p>Each chapter in this book is grouped around particular sets of interview problems, all while teaching the concepts that the problems illustrate. The answers to each problem are listed in the book, but in the spirit of learning, it's probably best to try each problem before looking at the answers.</p>
<p>I worked through the exercises in this book using 30 minute timeboxes. If I solved the question faster than 30 minutes, I would attempt to make my algorithm more efficient. If I wasn't able to answer a question within 30 minutes, I would take the opportunity to read through the answer and understand the optimal solutions. I'd then add a similar question to my leetcode questions for the upcoming week, just to make sure I drilled the concepts as much as possible.</p>
<p>Finally, The <a href="https://www.udemy.com/course/introduction-to-data-structures/">Easy to Advanced Data Structures Course</a> on Udemy was a great course that I used to reinforce what I was learning via the books that I was reading. The course was well laid out, with easy to understand source code for each lecture and clear animations that showed how each algorithm that we implemented worked.</p>
<h4 id="assessing-weaknesses-with-leetcode">Assessing Weaknesses with LeetCode</h4>
<p>Sunday evenings were spent putting together an overview of what the next week would look like. During my interview prep period, I'd look ahead in both the Programming Interviews Exposed and Algorithm Design Manual, then go to Leetcode and compile a list of 1 - 2 questions that corresponded to each chapter. At the end of each week, I'd work through these questions, and make notes about what topics I found difficult. I'd review each of the challenging topics during the next week.</p>
<p>This process allowed me to continually assess concepts that I was weak in and reinforce those concepts over the course of the month.</p>
<h4 id="working-through-interview-anxiety">Working through Interview Anxiety</h4>
<p>Engineering interviews aren't just challenging because of the material. The environment and the interviewer can often be triggering for those that deal with performance anxiety and imposter syndrome. Earlier in my career, bad interview experiences created major setbacks in my confidence and I often struggled to pick myself up and continue moving forward through the adversity of those experiences.</p>
<p>Pramp helped me ease my interview anxiety. I scheduled two hour long coding interviews each week with other engineers on the platform.</p>
<h3 id="how-did-it-go">How did it go?</h3>
<p>I started interviewing about 26 days into the preparation process. And I'm happy with how the process turned out. I ended up with multiple offers from some great companies, and chose the offer that fit best with what I was looking for. I didn't kill it in every interview, but I did walk into each interview confident and prepared, which is really what I was looking for with this process.</p>
<p>Overall, I'm happy with the outcome of this process. I got a new job, I'm learning a ton about an industry I know very little about, and have a more persistent set of fundamentals that I can fall back on when necessary.</p>
<p>If you'd like to learn more about this process, or have any questions, reach out on twitter, I'm <a href="https://www.beta-neil.com/posts/a-new-job/www.twitter.com/kneelshah">@kneelshah</a>.</p>

    </div></div>]]>
            </description>
            <link>https://www.beta-neil.com/posts/a-new-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041178</guid>
            <pubDate>Mon, 03 Aug 2020 18:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I've compiled a list of books on cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24040928">thread link</a>) | @vhpoet
<br/>
August 3, 2020 | https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn | <a href="https://web.archive.org/web/*/https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24040928</guid>
            <pubDate>Mon, 03 Aug 2020 17:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a DIY Pen Plotter: MidTbot]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24040816">thread link</a>) | @irontinkerer
<br/>
August 3, 2020 | https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Earlier this year, I built a DIY pen plotter (mostly) from scratch. I'd been
meaning to post a build log, because this was one of the more enjoyable hardware
projects I've worked on recently. However, it's taken a while to write-up this
project because, well,
<a href="https://benjamincongdon.me/blog/2020/03/24/March-Updates/">there was a lot of stuff going on</a>.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter_hu26049e58bcb0e8f71afc8b124b2c5223_266932_0x400_resize_q75_box.jpg" alt="Completed Plotter with Ruler for Scale"> </a><figcaption>
        <p>Completed Plotter with Ruler for Scale</p>
    </figcaption>
    </figure>

<h2 id="why-build-a-plotter">Why Build a Plotter?</h2>
<p>So, why is it worth building a pen plotter? The short answer is, “they're cool”.
The longer answer is that, despite commercial printers (ink jet, laser, etc.)
working better for general purpose printing, the quality of a pen-plotted image
is noticeably different than something that's been traditionally printed.
Plotted images can have a more natural, organic feeling to them, because they're
produced by raising and lowering a pen manually, like a human does.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>I've also had a persistent curiosity with
<a href="https://benjamincongdon.me/blog/2019/03/07/Generative-Doodling/">generative art</a>. Much of the community
built around generative art (colloquially,
<a href="https://twitter.com/hashtag/plottertwitter">#plottertwitter</a>) uses pen plotters
to turn “bits into atoms”. While most folks opt to buy a commercial plotter like
the <a href="https://axidraw.com/">Axidraw</a> or restore vintage plotters from the 1980's,
there's a growing community of people building their own plotters.</p>
<h2 id="assembling-the-components">Assembling the Components</h2>
<p>The first step in the project was collecting the bill of materials (BOM).
There's a well-researched BOM on the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/Docs/mechanical_BOM.md">project Github</a>.
Other than the midTbot PCB, which is for sale
<a href="https://www.tindie.com/products/33366583/midtbot-esp32-v2-controller-kit/">on Tindie</a>,
I had to order:</p>
<ul>
<li>Linear shafts and Linear Bearings (Amazon)</li>
<li>Pulleys and Idler Pulleys (Amazon)</li>
<li>Rubber Timing Belt (Amazon)</li>
<li>2 Stepper Motors (Amazon)</li>
<li>Stepper Motor Controllers (Amazon)</li>
<li>12V 3A Power Supply (Already had one)</li>
<li>Basic Hobby Servo Motor (Already had one from previous Arduino projects)</li>
<li>Assorted M3/M5 Head Screws (Home Depot, Ali Express)</li>
</ul>
<p>I was pleasantly surprised how available most of the parts were online –
everything except for the screws/nuts were available on Amazon.</p>
<p>Once I received my midTbot PCB, there was some soldering and assembly to do. I
followed
<a href="https://github.com/bdring/midTbot_esp32/wiki/Controller-Kit-Assembly-Instructions">these instructions</a>
to attach the homing switches, power supply, and header pins to the board.</p>
<h3 id="printing-the-chassis">Printing the Chassis</h3>
<p>The chassis of the midTbot is entirely 3D printed. There are ~7 things that you
need to print
(<a href="https://github.com/bdring/midTbot_esp32/tree/master/STL">source files</a> on
Github), and they're all fairly simple shapes, so the prints were easy to do.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print_hu632932bafc371cef54c7ef30f19a742b_135778_0x400_resize_q75_box.jpg" alt="Completed prints of the &amp;lsquo;feet&amp;rsquo; and tailblock pieces"> </a><figcaption>
        <p>Completed prints of the ‘feet’ and tailblock pieces</p>
    </figcaption>
    </figure>

<p>The hardest thing to print (and the most finicky part of the project in general)
was the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/STL/midt_esp32_pen_mnt.stl">pen mount</a>.
This piece has some overhangs on it, so it was important to configure the
printer to add support material.</p>
<h2 id="assembly">Assembly</h2>
<p>With the PCB assembled, mechanical parts purchased, and chassis pieces printed,
it was time to do the final assembly. Again, I followed the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Assembly-Instructions">assembly instructions</a>
on the project Github.</p>
<p>The assembly process was straightforward: the PCB gets screwed into one of the
printed pieces, the pulleys and linear rods get screwed in to the “feet” and
carriage block pieces, and the stepper motors are secured to the chassis with
the PCB “sandwiched” in between the chassis and the motors.</p>
<p>One difficult step was attaching the stepper motors to the PCB. Per the project
instructions, you're supposed to solder the stepper motor wires into plastic
<a href="https://en.wikipedia.org/wiki/Pin_header">pin sockets</a>, so you can easily
detach the motors from the PCB. But, after I tried and failed several times to
solder the stepper motors into the female socket block, I simply soldered the
female sockets to the board directly and soldered the stepper motor wires onto
solid-core jumper wires. The end result wasn't as clean as what's shown in the
project instructions, but still allowed me to hot-swap the motors if needed.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics_hu69d27adac9c276a7c142cb42ce695fc5_460646_0x400_resize_q75_box.jpg" alt="Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)"> </a><figcaption>
        <p>Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)</p>
    </figcaption>
    </figure>

<p>Once the main “chunk” of the plotter was assembled (pictured above), the only
things left to do were to thread the timing belt around the pulleys, and attach
both ends of the belt to the pen head with a small amount of tension.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2_hubcee09c1499dfeaed0cdedbd52521e35_510199_0x400_resize_q75_box.jpg" alt="Belt Attach Points (circled)"> </a><figcaption>
        <p>Belt Attach Points (circled)</p>
    </figcaption>
    </figure>

<p>The last step in assembly (and, unfortunately the most fiddly part of the whole
process) was attaching the pen holder to the “head” block. The long screw that
makes the joint between the pen holder and “head” block needs to be tuned
meticulously: If the screw is too tight, then the pen can get stuck in the “up”
position – not returning to the “down” position when the servo retracts. On the
other hand, if the screw is too loose, then this translates to “slop” in the
pen's position, which results in wiggly drawings that are unusable.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo_hu041824ca24038cc947b7d5fa7334f321_403811_0x400_resize_q75_box.jpg" alt="Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)"> </a><figcaption>
        <p>Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)</p>
    </figcaption>
    </figure>

<p>At this point, the bot was assembled! I powered it on and installed a specific
version of the <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> firmware
designed for the midTbot per the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Compiling-Firmware-for-the-MidTBot">project instructions</a>.
Grbl_Esp32 is a really nifty piece of software: it allows you to upload an run
Gcode (basically, machine readable instructions for how to move the pen) on the
plotter's Esp32 controller. Since the Esp32 has built-in wifi (and bluetooth),
its able to serve a basic web UI:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui.png">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui_hu659f08144d7f460a1e53d6a3f50b9a17_60893_0x400_resize_box_2.png" alt="Grbl_Esp32 Web UI"> </a><figcaption>
        <p>Grbl_Esp32 Web UI
            <a href="https://github.com/luc-github/ESP3D-WEBUI">Source: Github</a></p>
    </figcaption>
    </figure>

<p>The Web UI is sufficient for most tasks: homing, minor positioning adjustments,
starting/pausing/resuming prints. There are only a few tasks – like calibration
– that require you to drop down to the Grbl “command line”.</p>
<p>It took me a while to get my midTbot calibrated. The project documentation was a
bit light on the specifics, so there was a lot of trial-and-error and
troubleshooting.</p>
<h2 id="plotting-software">Plotting, Software</h2>
<p>Now that I had a functioning plotter bot, the next thing to do was try it out.
Of course, to do so you need to actually produce Gcode that the bot can use.
There are tons of tools to do this – and a full discussion of Gcode/plotter
software is worth a whole other post. Suffice it to say, there are a variety of
resources on the <a href="https://drawingbots.net/knowledge/tools">Drawing Bots</a>
community page that serve as a good starting point.</p>
<p>I spent most of my time working with <a href="https://inkscape.org/">Inkscape</a>‘s
Gcodetools plugin. Axidraw (which makes a commercial pen plotter) also has some
useful
<a href="https://wiki.evilmadscientist.com/Axidraw_Software_Installation">Inkscape plugins</a>,
although some of the functionality won't work with the midTbot. Gcodetools
nominally allows you to translate SVGs to Gcode, however this is a tedious
process. <em>Not just any</em> SVG will work well with it; the SVG basically already
needs to be a line drawing for Gcodetools to have any hope of working correctly.
It has basic support for infilled regions too, but again you have to be careful
with it – any slight hiccup, and it produces unusable Gcode.</p>
<p>To be honest, the software aspect of pen plotting is the most frustrating part
of the workflow. I haven't yet found a great toolchain for the “art” -&gt; Gcode
pipeline, so there's a lot of finicky steps. (It doesn't help that Inkscape is a
second-class X11 app on macOS…)</p>
<h2 id="additional-hardware-modifications">Additional Hardware Modifications</h2>
<p>After I ordered a midTbot PCB, the creator added me to a Slack group. Some of
the other folks who'd built midTbots contributed back modifications they'd made
to their builds. I took a couple of these and added them to my bot too:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount_hu1f2dbe1c25aab483c480e60644105b8f_437548_0x400_resize_q75_box.jpg" alt="Magnetic Pen Mount with Thumb Screw"> </a><figcaption>
        <p>Magnetic Pen Mount with Thumb Screw</p>
    </figcaption>
    </figure>

<p>First, I ordered heftier thumb screws for the pen attachment (as pictured); the
screws in the original BOM are tricky to manipulate by hand. Second, I printed a
magnetic detachable pen holder (as pictured) which makes it easier to add/remove
pens without disturbing the rest of the setup. If you want to do multicolor
prints, this modification is a must. Finally, I printed wider supports for the
bots frame. Supposedly, this allows you to increase the available print size of
the bot (if you also order longer linear rods). I didn't get around to actually
increasing my bot's print size, but the wider supports made the bot more stable,
and easier to attach to a work table.</p>
<h2 id="results">Results</h2>
<p>After an afternoon of calibrating the bot and installing the mods I discussed
above, I got some prints that I'm pretty happy with.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle_hu7abfc5bba89b65ef467a92e89d404d38_647220_0x400_resize_q75_box.jpg" alt="SierpiÅ„ski triangle"> </a><figcaption>
        <p><a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">SierpiÅ„ski triangle</a></p>
    </figcaption>
    </figure>

<p>Sierpinski's triangle (above) is a single line, but has a lot of intricate
detail. This is a good exercise of the precision of the stepper motors, which as
you can see is quite good. The precision also requires the pen mount to be
calibrated correctly, so that there isn't any “slop” between the pen and the
body of the plotter.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube_hu4580d2579ea2776d604d9e44b4623042_575462_0x400_resize_q75_box.jpg" alt="Isometric Cube"> </a><figcaption>
        <p>Isometric Cube
            <a href="https://github.com/wblut/isogrid">Source: Github</a></p>
    </figcaption>
    </figure>

<p>This was a slightly harder pattern for the bot to draw. The lines are all
straight, but there are a fair number of pen raises. Generally, the more pen
up/down cycles a print has, the greater the likelihood of failure.</p>
<p>I've also noticed that <em>where</em> the pattern is in the print area of the bot makes
a difference. The closer the pen head is to the main bot chassis, the more the
pen is pulled away from the paper due to the counterweight of the “tail”
section. As such, I tried to position the prints as close to the middle of the
print area as possible. Below is what happens when the pen holder misbehaves:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader_hu1a98c8f9a4b8a7a0c3eafda2f5f8180d_194935_0x400_resize_q75_box.jpg" alt="Somewhat failed &amp;lsquo;Space Invaders&amp;rsquo; Print (Note the discontinous/missing lines)"> </a><figcaption>
        <p>Somewhat failed ‘Space Invaders’ Print (Note the discontinous/missing lines)
            <a href="https://github.com/abey79/vpype">Source: vpype Example Code</a></p>
    </figcaption>
    </figure>

<p>The plot isn't a complete failure, but many of the lines don't get drawn or only
get partially drawn. This is often caused by the pen mount screw being too
tight, causing the pen …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</a></em></p>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24040816</guid>
            <pubDate>Mon, 03 Aug 2020 17:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Your Dev Team to Get the Most Out of Slack]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039889">thread link</a>) | @jacksonpollock
<br/>
August 3, 2020 | https://cto.ai/blog/5-tips-for-your-dev-team-to-get-the-most-out-of-slack/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/5-tips-for-your-dev-team-to-get-the-most-out-of-slack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>In the past several years, Slack has made significant investments into making their platform a cornerstone developer tool. With the significant shift and emphasis now being placed on remote working teams, choosing the appropriate tools is paramount. One of the largest, if not the largest problems to solve, is how to facilitate asynchronous and synchronous communication. Slack is a well known communication tool, here are some reasons why Slack is the correct choice for your development team.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h3 id="-apps"><br>#apps</h3><p>I’ll state my bias, I am already a huge fan of Slack. My favourite aspect of the platform is the flourishing marketplace. Since the creation of the marketplace, Slack has made it simple for users to adopt integrations created by app builders. You can now find a wealth of 3rd party apps to serve a wide variety of needs within an organization. For a development team, there are a variety of marketplace apps. <br></p><ol><li>Virtual StandUp tools (ex. <em>Geekbot</em>). These give teams the ability to raise blockers and also visibility into the rest of the team without eating away at precious development hours.</li><li>Infrastructure Notifications (ex. <em>PagerDuty, Github, etc.</em>). These apps allow teams to be notified about the import status updates of applications in a shared environment.<br></li></ol><p>💡<em>Tips: Check out <a href="https://cto-ai.slack.com/apps/A0H67RAG0-geekbot">Geekbot</a>, <a href="https://cto-ai.slack.com/apps/A1FKYAUUX-pagerduty">PagerDuty</a>, <a href="https://cto-ai.slack.com/apps/A8GBNUWU8-github">Github</a>, and <a href="https://cto-ai.slack.com/apps/A676ADMV5-gitlab">Gitlab</a>. Honourable mention to social interaction tools like <a href="https://cto-ai.slack.com/services/B8DMC16UQ">Giphy</a>, which provide much needed levity between Pull Requests.</em><br></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h3 id="-communication">#communication</h3><p>Of course, when we talk about Slack, we can’t not talk about its success as a communication platform. The ability for teams to thread topics at the atomic level and group conversations allows for discussions to happen over an extended period of time—without being derailed or buried by other aspects of the business. This is true for all users of Slack, but is particularly useful for development teams to filter out noise. It also allows developers to keep a holistic view of the business. Vertical &amp; horizontal collaboration makes Slack a powerful tool for the transfer of institutional knowledge. <br></p><p>💡<em>Tips: Monitor your Slack channel activity. If a channel doesn’t have any activity over the course of several weeks, consider merging with another channel. If multiple topics are breaking out at the same time, this is a good indicator the channel is too broad. Also, set a clear topic for each channel.</em><br></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h3 id="-notifications">#notifications</h3><p>This may seem trivial, but the ability to pause notifications has been a feature developers love. It allows individuals to hone into a state of deep work without the thread of “pings” to distract. One of the lesser used features on Slack is the ability to customize notifications, allowing an individual to get notified on specific keywords.<br></p><p>Additionally, being able to set a status provides crucial context to the rest of your team when you might not be able to respond to messages immediately. <em>Slack also just recently released a new set of “remote work specific” statuses. </em> <br></p><p>💡<em>Tips: try using <strong>/dnd [some amount of time] </strong>to go into DO NOT DISTURB mode or <strong>/mute </strong>to a specific channel. Other useful slash commands are <strong>/status </strong>to set or clear your Slack Status and &nbsp;<strong>/remind </strong>which can help you set a reminder to get back to a message at a more appropriate time.</em><br></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h3 id="-snippets">#snippets</h3><p>Slack allows users to format text to help distinguish between conversation and code. Both code snippets and code blocks have proven quite useful for development teams. It makes it much easier to convey information in a text medium, by making it clear what part of the message is logs, which parts are code snippets, and what is clarifying text. &nbsp;<br></p><p>💡<em>Tips: press ⌘ + Shift + Enter (Ctrl + Shift + Enter on Windows/Linux) to open a code snippet pop-up window. Both code text and code block formats have icons below the Slack Chat box.</em><br></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h3 id="-workflows">#workflows</h3><p>Slack empowers users to create simple workflows and build simple alerts and automations. A lot of 3rd party Slack Apps provide notifications on the status of various tools. Workflows allow you to take this one step further by taking action on those notifications. I will add a shameless plug for <a href="https://cto.ai/platform">The CTO.ai Ops Platform</a>, which is by far the easiest way I’ve seen to build a Slack App that interfaces with your infrastructure and dev tools. <br></p><p>💡<em>Tips: Check out an example of the CTO.ai EKS Ops workflow </em><a href="https://cto.ai/registry/cto.ai/eks?tab=readme"><em>here</em></a><em>. Slack has put out a lot of documentation on how to build simple workflows that only require interaction with a user (not 3rd party tools) such as Automated Reminders, Approval Processes, and a way to gather feedback. </em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Slack, of course, has some drawbacks. Slack offers a fairly comprehensive free tier, but, if you’re looking to have more than 10 apps and a full history of conversations, it can start to get pricey for larger teams.</p><p>It also can come across as complex for newbies and if channels are not set up to follow a singular topic a lot of those threaded conversation benefits can disappear. Furthermore, Slack has done such a great job that I actually think it can be a bit of an addictive tool to use.</p><p>However, for my money, it is the best communication tool for development teams currently on the market. When I start a new development team, the first tool I will implement is Slack.</p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/5-tips-for-your-dev-team-to-get-the-most-out-of-slack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039889</guid>
            <pubDate>Mon, 03 Aug 2020 16:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Not Thinking]]>
            </title>
            <description>
<![CDATA[
Score 511 | Comments 152 (<a href="https://news.ycombinator.com/item?id=24039887">thread link</a>) | @tmatthe
<br/>
August 3, 2020 | http://tiffanymatthe.com/not-thinking | <a href="https://web.archive.org/web/*/http://tiffanymatthe.com/not-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>03.08.2020</time> — <a href="http://tiffanymatthe.com/tags/productivity">Productivity</a> — <span>5<!-- --> min read</span></p><section><img src="http://tiffanymatthe.com/static/d758a9afd33cefb9ce3dc7bb83cc213d/a6c62/not-thinking.jpg"><p><em>After years of feeling guilty about not wanting to do everything, I realized I don't need motivation to get things done. Below, I describe how I use the concept of not thinking instead.</em></p><hr><p>It took me five years to get in the habit of exercising. I just didn't want to do it. I followed Youtube workouts, hopeful that the energetic trainer on the screen would help me get fitter. I swam laps in my pool. I followed my brother on 3K runs. And afterwards, I felt great! On top of the world. And then the next day came, and I remembered I had to do it all over again. I had to be sweaty, push through the pain, and breathe like I had an asthma attack.</p><p>So every morning, I woke up and inevitably started dreading my exercise. It would slink around in my thoughts, casting a dark mood until I got it done. At one point, I would dread exercising enough to stop, and a wave of relief would wash over me. This feeling of calm usually lasted a few months, and then my disappointment in my poor levels of fitness would take over. And the cycle would restart.</p><p><strong>Everyone has things they don't want to do.</strong> It's not limited to exercising. It can be anything from studying everyday for the entire school year to vacuuming the floor. Unless you can avoid that activity with no guilt or regrets, you usually have to do it. You know it will help in the long run, to study to prepare for finals and to have clean floors, but even with that in mind, it can still be incredibly hard to do those activities.</p><p>I realized that the hardest part of doing things I don't want to do is usually not the activity itself, but getting started. Once I get started, I get into a flow and rationalize that since I'm already doing it, I might as well finish.</p><h3>How much motivation do we need?</h3><p>I like to describe the amount of energy I need for a task I don't want to do as an exothermic reaction. In this reaction, the reactants (me) need a minimum activation energy (motivation) for the reaction (task) to occur. After the reaction is complete, the products then settle down into a lower energy state (since no more energy is needed to do the task or worry about it).</p><p><span>
      <span></span>
  <img alt="Motivation Energy Reaction" title="Motivation Energy Reaction" src="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg" srcset="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/46946/exothermic.jpg 240w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/55489/exothermic.jpg 480w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg 960w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/60e21/exothermic.jpg 1440w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/69b48/exothermic.jpg 1920w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/e1761/exothermic.jpg 3273w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>So how can we get this minimum activation energy? Well, if we don't want to do the activity, it is nearly impossible to gain enough motivation to do it. The good news is that we can avoid the need for such a high activation energy.</p><p>How is this possible? A simple answer: <strong>don't try to find motivation</strong>.</p><p>When you look for motivation, you usually start by reminding yourself about the advantages of getting the task done. But your brain is a stubborn toddler. If you strongly drag it towards one direction, it will fiercely pull you to the other side. The brain thinks there's a choice, and thus a possibility to argue. It will start pointing out all the disadvantages and instant gratification alternatives.</p><p>Since humans instinctively reach for easier things, now you have not only dredged up all the negative points about your task, but also discovered easier alternatives that require an additional amount of energy to resist. In short, you have increased the minimum activation energy required to start the task.</p><p>You will also remember this awful internal debate, and associate these negative feelings with the task itself. Naturally, this does not bode well in the long run.</p><p>On the other hand, if you don't think about the task, you can avoid the entire process of arguing with yourself and making decisions that you will feel guilty about. Instead, just do it. <strong>Become a mindless robot</strong> and don't think twice<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p><p>This is, of course, easy to say and a bit more difficult to do. It's hard to think about not thinking, because you'll inadvertently wonder what it is you were trying to not think about, and bam, you've failed. Not thinking is a process, and just like any other skill you learn, it improves with time and practice. Here are a few tips.</p><h3>Make the decision in advance</h3><p>If you are temporally removed from the thing you don't want to do, it's easier to make a rational decision. By making the decision beforehand, you remove the effort needed to choose before doing your task. This reduces friction and removes one factor that could have led you to think about your task when you start it.</p><p>There are a few ways of making decisions in advance. There's the two-minute rule, where you decide that for anything that takes less than two minutes, you do it. No thinking, no arguing, just swift action. For example, you see a pile of clothes on your bed. It takes less than two minutes to organize then in your drawer, so you do it. Here, you just avoided the trap of thinking about your clothes, feeling unmotivated to put them in order, and giving yourself the terrible alternative of doing it later.</p><p>Another method is planning out your days in advance. This does not always work, but it's a good idea to try it out. The night before, you plan out all of your activities to the minute. And, of course, as you're temporally distanced from these activities, you make rational decisions. Then when the morning comes, you can mindlessly follow the schedule you have made for yourself.</p><h3>Do a small part first</h3><p>Quickly pick a random small part of the activity you were dreading. And commit to only doing that one part. This helps you avoid overthinking by giving your brain a smaller task to easily execute<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p><p>For example, if you need to complete a scholarship application and hate writing about yourself, tell yourself to just write bullet points of topics you might include in the application. Most of the time, after you have invested those first five minutes into the activity, you enter a flow and continue working.</p><p>After implementing these strategies, where I tell myself that I have to exercise every other day for a mere 5 minutes, I now consistently exercise for at least 15 minutes without overthinking it.</p><p>So next time you find yourself not wanting to do something, make yourself a clear rule of when to do it and do the easiest part first. That way, you can avoid making too many decisions and associating the internal turmoil that stems from that process to the activity itself.</p><p>Note, not thinking works wonderfully if your sole purpose is doing an activity you don't want to do. However, unless you don't have any goals to pursue, this is not the best way to go about everything in life. Make sure to take the time to reflect on the overall purpose of the activity and if it brings you closer to where you want to be. If the answer is yes, then feel free to become a mindless robot for any activities that have passed the reflection stage.</p><p>At the small risk of being sued by Nike, just do it.</p></section></div></div>]]>
            </description>
            <link>http://tiffanymatthe.com/not-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039887</guid>
            <pubDate>Mon, 03 Aug 2020 16:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Tell Your Data Team's ROI Story]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039794">thread link</a>) | @barrald
<br/>
August 3, 2020 | https://hex.tech/blog/data-team-roi | <a href="https://web.archive.org/web/*/https://hex.tech/blog/data-team-roi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’m fortunate to be involved in a few awesome data-focused communities. Like clockwork, every few months a Data leader will pop up asking for advice on how to calculate the return-on-investment for their team. The question is usually in the context of a budget decision, where they need to justify expanding headcount or purchasing a new tool.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The name has been changed to protect the innocent" title="The name has been changed to protect the innocent" src="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" srcset="https://hex.tech/static/833b16929966b847168439d6df34e764/44569/slack-message.png 175w,
https://hex.tech/static/833b16929966b847168439d6df34e764/f8bcd/slack-message.png 350w,
https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png 493w" sizes="(max-width: 493px) 100vw, 493px" loading="lazy">
  </a>
    </span>
    <figcaption>The name has been changed to protect the innocent</figcaption>
  </figure>
<p>While there’s a subtle irony in the team responsible for quantification struggling to quantify their work, calculating a true “ROI” can be challenging because of the way data teams typically operate.</p>
<p>In some cases, the data team has a top-or-bottom-line impact that can be directly measured. For example, if the company sells data as their product, the Data team has a clearer, more obvious connection to value creation.</p>
<p>But for most teams, their impact is created indirectly: they are partners, acting in support of functions like Marketing, Operations, or Engineering to affect company performance.</p>
<p>In organizations like these, efforts for the Data team to come up with a standalone ROI will be underwhelming and unconvincing. Calculating a crisp “return” on an analysis project or model is difficult, and it’s even harder for infrastructure investments: how do you quantify the impact of a better schema, or a more reliable pipeline? An improvement in data quality can be objectively beneficial, but also quickly taken for granted.</p>
<p>The truth is that if you’re trying to quantify your impact by yourself, you have already lost. <strong>Instead, the best way to tell the ROI story is for other people to tell it.</strong></p>
<p>If your Data team is truly providing value, the leaders of other functions should be lining up to sing your song. Limitations or reductions in Data team headcount should elicit howls from functional stakeholders; the VP Marketing and Head of Ops should be the ones fighting for more Data resources.</p>
<p><strong>If your partners aren’t willing to go to bat for you like this, then it’s time to take a step back to rethink how you’re operating.</strong> Are other teams actually benefiting from your work, or are you detached from business outcomes? Is your team in the trenches with other functions, or only providing input from afar?</p>
<p>There are 3 key areas to examine:</p>
<h3>Organization</h3>
<p>Too many data teams operate in a centralized, siloed manner. “Ivory Tower” teams may be doing brilliant, insightful work, but they’re too far from the business to make a tangible impact.</p>
<p>I once worked with the “Advanced Analytics Group” at a major CPG company. They all sat together, in one area of one floor of one building, far from the teams they were supposed to be supporting. While they were all intelligent, earnest people, their work was academic at best, and they struggled to justify their existence. This “Center of Excellence” model rarely works, especially as a team grows.</p>
<p>There are other ways to organize a data team. <a href="https://medium.com/@djpardis/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd" target="_blank" rel="nofollow">Pardis Noorzad has an amazing overview here</a>, and I agree that the "Product Data Science" model is a strong option for most teams. <a href="https://medium.com/@itunpredictable/data-as-a-product-vs-data-as-a-service-d9f7e622dc55" target="_blank" rel="nofollow">Justin Gage's "Data as a Service" model</a> also provides a useful lens - is your Data team just providing data, or useful input to decisions? <strong>If not, stakeholder partners are unlikely to stand up and support your team’s ROI story.</strong></p>
<figure>
    <span>
      <a href="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="From Justin Gage's 'Data as a Product vs. Data as a Service'" title="From Justin Gage's 'Data as a Product vs. Data as a Service'" src="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png" srcset="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/44569/justin-DaaS-image.png 175w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/f8bcd/justin-DaaS-image.png 350w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png 700w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/dd14e/justin-DaaS-image.png 1050w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png 1156w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>From Justin Gage's 'Data as a Product vs. Data as a Service'</figcaption>
  </figure>
<p>Re-organization away from a centralized Data team model can be painful, and may feel like a loss of control or prestige. But it’s critical to keep an open mind — and set ego aside — if you want your stakeholders to feel the impact of your team, and advocate on your behalf.</p>
<h3>Planning</h3>
<p>Next, integrate your planning process. If your organization uses a system like OKRs, explicitly tie the Data objectives to support the goals of your stakeholders. This makes it clear exactly how your team is impacting functional outcomes.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="All together now" title="All together now" src="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" srcset="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/44569/OKRs-for-blog.png 175w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/f8bcd/OKRs-for-blog.png 350w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png 700w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>All together now</figcaption>
  </figure>
<p>Infrastructure-level objectives — like implementing a new data warehouse — can live separately, but should still have explicit callouts for how those investments are supporting the higher-level objectives.</p>
<p>Data Leaders should also push for their teams to be involved with other teams’ granular planning cycles. If the Marketing team has a weekly planning meeting or daily stand-ups, the Data analysts supporting that team should be in the room (or Zoom, or whatever).</p>
<p>If your team has its own planning cycles and sprints, involve stakeholders in an explicit prioritization exercise. This will give them more insight into Data activities, and when it comes time to speak to ROI they will already have thought through the upside and tradeoffs around your team’s time.</p>
<p>As a side benefit, by aligning priorities with the business, Data teams <strong>avoid the dreaded “find novel insights” mandate</strong>. If an Analyst is deeply embedded with the Marketing team, partnering on their hardest problems, it’s harder for the CFO to distract them with a one-off wild goose chase.</p>
<h3>Tools</h3>
<p>Even if they are well-integrated into the rest of the organization, <strong>the Data team’s work will underwhelm if it’s not actually useful for others</strong>. Today’s tools are a mixed bag here.</p>
<p>BI platforms are great for enabling self-serve and building dashboards. But they also have relatively low ceilings, and aren’t a medium where data scientists can do their most interesting work.</p>
<p>On the other hand, Code notebooks are amazing for deeper exploration and model iteration, but are single-player, hard to share, and inaccessible for less-technical folks. Even if a Data Scientist has developed something interesting, there’s no easy way to productize it or make it useful for the rest of the organization.</p>
<p>So Data teams often wind up screenshotting charts, exporting CSVs, and sharing through slide decks, spreadsheets, and Slack. While these tools meet stakeholders where they are, they’re severed from source data and have short half-lives; when a PM wants to update an assumption, they need to ping the analyst, who re-runs, re-exports, and re-sends.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="We can do better" title="We can do better" src="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" srcset="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/44569/screenshot_hell.png 175w,
https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png 257w" sizes="(max-width: 257px) 100vw, 257px" loading="lazy">
  </a>
    </span>
    <figcaption>We can do better</figcaption>
  </figure>
<p>This gap in sharing and collaboration not only wastes Data teams’ time, but acts as a drag on their impact. Delivering a forecast model to the Finance team as a live, interactive data app is way more useful than a once-weekly static PDF; the CFO themself will understand the ROI every time they open it to run a new scenario.</p>
<p>I’m excited to see a new crop of tools emerge (disclaimer: <a href="https://hex.tech/" target="_blank" rel="nofollow">I’m working on one</a>) to help data teams more easily share their work, and create clearer, more tangible impact with the rest of the organization.</p>
<hr>
<p>It’s an exciting time in the Data world. Thousands of new people are entering the space as Data Scientists and Analysts. It’s easier than ever to source, transform, and store data. And the ML explosion is unlocking possibilities for insight and inference.</p>
<p>But gaining the budget and support needed to take advantage of all of this is an uphill battle without advocacy from functional stakeholders. By re-evaluating team organization, planning, and tooling, Data teams can ensure their impact is obvious and clear.</p>
<p>Done right, it means the next time a Data leader is asked to justify ROI, they won’t have to. They can sit back, and let others tell the story for them.</p></div></div>]]>
            </description>
            <link>https://hex.tech/blog/data-team-roi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039794</guid>
            <pubDate>Mon, 03 Aug 2020 16:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical symmetries result from what we think good scientific theories are]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039513">thread link</a>) | @jrhawley
<br/>
August 3, 2020 | https://jrhawley.github.io/2020/08/03/physical-symmetries | <a href="https://web.archive.org/web/*/https://jrhawley.github.io/2020/08/03/physical-symmetries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <div id="post">
        
        <article id="post-content">
          <p>Theoretical physics isn’t easy.
Everyone who has seen a documentary about physics or taken a graduate level physics course knows this.
Much of theoretical physics is steeped in complicated math with talk about <a href="https://en.wikipedia.org/wiki/Noether%27s_theorem">symmetries and conservation laws</a>.
Even understanding where basic <a href="https://en.wikipedia.org/wiki/Kinematics_equations">kinematic equations</a> comes from requires a bit of calculus.
But it’s not hard for no good reason.
Physicists want certain things out of their theories and they use abstract ideas to get them.</p>

<p>Take <a href="https://en.wikipedia.org/wiki/Lie_algebra">Lie algebras</a>, for example.
These are abstract algebraic objects defined by weird things like Lie brackets and vector spaces over fields.
Most math or physics students won’t formally encounter these things until graduate school because they’re pretty abstract.
But everyone who has taken high school level physics intuitively knows what a Lie algebra is, they just don’t know that they know it<sup id="fnref:1"><a href="#fn:1">1</a></sup>.</p>

<p>But why do we even need to deal with something so abstract, like Lie algebras?
Why can’t we just work with real numbers and tangible things?
To someone who hasn’t studied any math, talking about things like continuous symmetries and group orbits seems needlessly complicated.
It’s hard to even get to a point where talking about these things seems like a discussion worth having.
But abstract mathematical objects, such as Lie algebras and symmetries, are so ubiquitous in physics for a simple reason: they come directly from our ideas on what good scientific theories look like.</p>

<h2 id="a-naive-universal-theory-of-physics">A naive universal theory of physics</h2>

<p>Let’s describe, in very general terms, what a scientific theory looks like.
At it’s most basic, a scientific theory is a consistent set of ideas that makes accurate predictions about what the world will look like in the future.
For physics, this is a set of rules that give answers to questions that often sound like “where will this ball be in the future if I throw it this fast at this angle?” or “how hot will this wire get if I run a certain amount of electricity through it?”
But questions like these come from hundreds of years of studing physics, so we know a thing or two about which questions to ask.
What if we knew nothing about physics and just wanted to think about what a good physical theory would look like?
Where should we start?</p>

<p>Theories, being about predictability, should predict as broad of a picture as it can while still being accurate.
Saying a certain set of rules work in one context, but a different set of rules work in another seems like some patchwork notion of what a theory should look like.
Even if that worked we’d still need some way of figuring out which rules work in which scenarios.
<strong>At the very least, a “good” universal physical theory, then, would be a theory that is the same everywhere.</strong>
The rules that tell you how things work on Earth should also work in space, and if they don’t we should know why they don’t and be able to explain it.
Rules that tell me how things work where I stand should also tell you how things work where you stand, and we both should agree on each other’s descriptions of how things work, generally.
What’s worth noting is that this isn’t a necessity, prescribed by the universe about how things should operate.
It’s just a desire from people who want to understand the world about what that understanding should look like.</p>

<p>If you’ve heard about Einstein’s theory of relativity, you may be aware that the first <a href="https://en.wikipedia.org/wiki/Postulates_of_special_relativity">fundamental postulate of that theory</a> is that the laws of physics take the same form in all intertial frames of reference.
This first postulate states exactly what I’ve described above as a good physical theory<sup id="fnref:2"><a href="#fn:2">2</a></sup>.
There’s no logical dictum stating why this must be true.
But without knowing any physics you can understand why you’d want this notion as a part of your theory of the universe.</p>

<h2 id="how-does-this-relate-to-symmetries">How does this relate to symmetries?</h2>

<p>An important part about science is thinking about the consequences of your theory.
Since we have this idea about a “good universal physical theory” should look like, what does that mean for how we describe it?
What consequences does this definition of “good” have on our theories, without making further assumptions about it?
Do these consequences give us any clue about where to start looking and what tools we should bring with us?</p>

<p>Let’s start by defining the space we’re working in as .
This can be something like space, or time, or spacetime, but without making specific claims yet, we can say that our goal for studying physics is to try to find a set of physical rules that govern what happens at each point in our physical space, .
We don’t know what these physical rules are, or what they may even look like.
But let’s define the set  as the set of all sets of physical rules.
Formally, then, our goal can be re-stated as finding the element(s) in  that describe the world we live in.</p>

<p>From our desired universal theory, we can say that we’re actually only concerned with a subset of .
That is, we only care about sets of physical rules that include the “physical theories are the same everywhere in ” rule.
Let me stress that up until this point, we haven’t really made any assumptions about how the universe works.
We are just thinking about what studying physics means.</p>

<p>Let’s build on this idea.
Let’s consider some mapping, , where  is the set of physical rules that govern what happens at point .
Then, because of our desire for a “good” theory, if there is some total list of physical rules that we call , we can immediately say something about :</p>



<p>Stated another way,  is invariant under transformations in .</p>

<p>What does this tell us?
It tells us that we should start thinking about invariant transformations and symmetries.
What math do we know about that is concerned with invariant transformations and symmetries?
Groups. Rings. Vector spaces. Lie algebras.
A whole plethora of mathematical tools immediately become available to us simply because we want something in our description of the universe.
This isn’t some statement from on high that we need to obey, it results directly from what we think good scientific theories are.
It tells us that, if nothing else, there is a fundamental conservation law at the heart of our physical theory.</p>

<h2 id="conclusions">Conclusions</h2>

<p>Theoretical physics isn’t easy, but the mathematical tools that physicists use don’t show up for no reason.
What we want our physical theories to look like points us to things we should think about, like symmetries and invariant transformations.
This naturally leads to thinking about Lie algebras, representation theory, vector spaces, and the like.</p>

<p>The reason these tools are so abstract is that we don’t want to predetermine what the universe should look like if we don’t have to.
Using 3-dimensional real vectors presupposes that we live in three spatial dimensions and that our universe is based on real numbers.
If we don’t have to make that assumption, it’s probably safer not to, even if it seems reasonable.
Lots of things that seems reasonable in day-to-day life don’t end up producing reasonable predictions in extreme circumstances, so we have to be careful about each and every assumption we make.
But keeping these assumptions in mind and taking them to their logical consequences can help inform you of what tools you may need and where you will need to look to find something new.</p>





        </article>
        
        
      </div>
    </div></div>]]>
            </description>
            <link>https://jrhawley.github.io/2020/08/03/physical-symmetries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039513</guid>
            <pubDate>Mon, 03 Aug 2020 16:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You May Finally Use JSHint for Evil]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039470">thread link</a>) | @jugglinmike
<br/>
August 3, 2020 | http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/ | <a href="https://web.archive.org/web/*/http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      
  
  <article>

    <header>
      <p>
          
        POSTS
      </p>
      
      
      <time datetime="2020-08-03T00:00:00Z">August 3, 2020</time>      
      
      
      
      
    </header>

    <section><p><a href="https://jshint.com/">JSHint</a> is a software tool designed to help developers
write JavaScript code. Since its creation in 2011, it has been encumbered by a
license which includes the following clause:</p>

<blockquote>
<p>The Software shall be used for Good, not Evil.</p>
</blockquote>

<p>That stipulation <a href="https://www.gnu.org/licenses/license-list.html#JSON">disqualifies JSHint from the distinction of “free”
software</a> and <a href="https://opensource.org/faq#evil">“open
source” software</a>.</p>

<p>Today, with a release 7 years in the making, we’re removing the clause. Support
for Evil is a new feature but not a breaking change, so in keeping with
<a href="http://semver.org/">Semantic Versioning</a>, we’ve incremented JSHint’s minor
version. <a href="https://jshint.com/blog/2020-08-02/release-2-12-0/">JSHint version
2.12.0</a> is licensed under
the terms of the MIT Expat license.</p>

<p>In this series of essays, I’ll discuss why this matters for the project, why it
matters to me personally, and how a large group of people came together to make
this possible.</p>

<ol>
<li><a href="http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/">Watching the Ship Sink</a> - how
the license hurt JSHint</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-dug-in/">Dug In</a> - why I stuck with JSHint and the
relicensing effort</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-asking-nicely/">Asking Nicely</a> - our inability to
relicense solely via contributor consent</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-wrestling-it-free/">Wrestling it Free</a> - our success in
relicensing through rewriting code</li>
</ol>

<p>Whether or not you care about any of that, the result is the same: JSHint is
now irrevocably free software.</p>

<p>Many thanks to <a href="https://github.com/jshint/jshint/graphs/contributors"><strong>all the people who’ve contributed to
JSHint</strong></a> for making this
project worth liberating and for enthusiastically participating in that
process. Thanks especially to <a href="https://anton.kovalyov.net/"><strong>Anton
Kovalyov</strong></a>, without whom there would be no JSHint
to relicense. <strong>Ethan Dorta</strong>, <a href="http://alexkritchevsky.com/"><strong>Alex
Kritchevsky</strong></a>, <a href="https://mattsurabian.com/"><strong>Matt
Surabian</strong></a>, and <strong><a href="http://tkellen.com/">Tyler
Kellen</a></strong> masterfully reimplemented code that they
couldn’t see. It’s tough to overstate the difficulty of the challenge and the
shrewdness required to overcome it. <a href="https://tbranyen.com/"><strong>Tim Branyen</strong></a>,
<strong>Isaac Carter</strong>, and <strong>Timon Lukas</strong> also volunteered time and energy toward
this end. <strong>Rick Waldron</strong> and <strong>Caitlin Potter</strong> gladly accepted the burden of
CLA enforcement in addition to their more traditional maintenance duties. The
relicensing effort was dead in the water until <strong>Simon Kaegi</strong> discovered the
free software version of JSLint; thank you, Simon, for catalyzing the campaign.
<strong>Joel Kinney</strong> and <strong>Steven M. Ayr</strong> provided much-needed legal perspective
(to be clear: <em>not</em> legal advice) when this all started, and they did so with
eagerness and passion that would make you think we’d paid them (to be clear: we
didn’t). When things seemed hopeless, <a href="https://pault.ag/"><strong>Paul
Tagliamonte</strong></a>, <a href="https://nadiaeghbal.com/"><strong>Nadia Eghbal</strong></a>
and <a href="http://punkrocklawyer.com/"><strong>Karen Sandler</strong></a> offered much-needed
encouragement and perspective. In addition to introducing me to Ethan, <a href="https://fsf.org/"><strong>the
Free Software Foundation</strong></a> continues to sponsor writing and
conferences that reinforce the importance of software freedom. By researching
legal concerns regarding software rewriting, <strong>Russell Hoover</strong> and <a href="https://kendraalbert.com/"><strong>Kendra
Albert</strong></a> at <a href="https://cyber.harvard.edu/teaching/cyberlawclinic"><strong>the Harvard Law School Cyberlaw
Clinic</strong></a> demonstrated
expertise and altruism. <a href="https://joryburson.com/"><strong>Jory Burson</strong></a>, <a href="https://www.lyza.com/"><strong>Lyza
Gardner</strong></a>, and <a href="https://matmarquis.com/"><strong>Mat
Marquis</strong></a> all helped me make sense of this story. The
warmth and dedication of these people can’t be overstated!</p>
<ul>
  
</ul>

    </section>

    

  </article>

    </div></div>]]>
            </description>
            <link>http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039470</guid>
            <pubDate>Mon, 03 Aug 2020 16:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Learning and Start Doing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039396">thread link</a>) | @kangabru
<br/>
August 3, 2020 | https://kangabru.xyz/2020/08/01/stop-learning-start-doing | <a href="https://web.archive.org/web/*/https://kangabru.xyz/2020/08/01/stop-learning-start-doing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
    <p>You don't know shit until you do it, so do something about it</p>
    
</div><div>
    

    <p><span>Photo by <a target="_blank" href="https://unsplash.com/@heftiba?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Toa Heftiba</a> on <a target="_blank" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span></p>

<p>Pieter Levels once <a href="https://www.indiehackers.com/podcast/043-pieter-levels-of-nomad-list">likened start-ups to a swimming pool</a>.</p>

<p>He said there are two groups of people: there are those standing around the pool discussing how to swim, and those who are actually swimming.</p>

<p>Perhaps you don’t know how to swim yet but you’ll learn much faster <em>inside</em> the pool than out of it. I say dive in.</p>

<h2 id="learning-is-a-waste-of-time">Learning is a waste of time</h2>

<p>I think it’s easy to consume too much information from books, videos, podcasts etc. Don’t get me wrong, I love learning this way and think it’s a valuable part of my life, but you can waste time by learning stuff you don’t need yet.</p>

<p>For instance you might read a book about marketing. It contains useful information, sure, but if you’re just starting out then it’s mostly irrelevant. Most of the lessons won’t apply to you until you have 100s of customers.</p>

<p>You’ll also gloss over key bits of information because you simply lack the experience which makes that information valuable.</p>

<p>Instead if you just launched something you’d realise that getting <em>any</em> users can be quite hard. Suddenly marketing isn’t so important and you’re faced with problems that you never knew about. Talking to customers and direct sales is probably more applicable to you at this point.</p>

<p>Without actually <em>doing</em> something you don’t know what you don’t know, and you don’t know what you <em>need</em> to know.</p>

<p>So I say learn as you go. Once you take the plunge you’ll face real problems and future learnings will be much more actionable.</p>

<h2 id="well-its-not-a-complete-waste-of-time">Well it’s not a complete waste of time</h2>

<p>General learning is great in that it exposes you to ideas that will help you later.</p>

<p>Take maths at school for example. Many just do the minimum amount necessary to pass but don’t grasp how it applies to them yet. Thankfully they are exposed to the ideas.</p>

<p>Let’s say they decide to re-pitch their roof one day. Suddenly they’re required to deal with angles and distances, and are reminded of our good friend trigonometry.</p>

<p>So they re-read up on the topic, apply some equations, and successfully re-pitch their roof. Yay for maths! They realise that maths <em>can</em> be useful and start using it more in their lives.</p>

<p>So when I said that you ‘don’t know what you don’t know’, well you also don’t know what will be useful to you.</p>

<p>I think it’s fantastic to be curious and open your mind to new ideas. Things you learn now <em>can</em> help you in the future even if you don’t know it yet.</p>

<p>Just be wary of trying to learn too much if you want to be productive. You might be learning the wrong things.</p>

<h2 id="starting-doesnt-have-to-be-scary">Starting doesn’t have to be scary</h2>

<p>So if you’re one of those people standing at the edge of the pool trying to learn how to swim, perhaps you fear the risk of drowning i.e. you’re scared to fail.</p>

<p>I’m here to tell you it’s not that bad, but I suggest that you fail fast and fail early. Working on an MVP for 6 months vs 2 weeks before a failed launch is probably going to hurt a LOT more.</p>

<p>So save yourself the trouble and get failure out of your system. I’m still learning how to swim too but I’ve enjoyed the experience so far. It turns out the swimmers here are quite friendly.</p>

<p>And like I said before, just by <em>doing</em> something you will be exposed to things you never knew existed. For me this has been things like copy writing, building an audience, and discovering that I enjoy blogging. Who knew? For me it’s been worth it.</p>

<p>So if you’re still at the edge of the pool I say put down your swimming guide, get your feet wet, and take the plunge. The water’s lovely.</p>


    
    



    
</div></div>]]>
            </description>
            <link>https://kangabru.xyz/2020/08/01/stop-learning-start-doing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039396</guid>
            <pubDate>Mon, 03 Aug 2020 15:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SentiLink is first company in US to do real-time SSN verifications]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039393">thread link</a>) | @vivekahuja
<br/>
August 3, 2020 | https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c | <a href="https://web.archive.org/web/*/https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.sentilink.com/@press_51526?source=post_page-----2f71da5f280c----------------------" rel="noopener"><img alt="SentiLink" src="https://miro.medium.com/fit/c/96/96/2*kOctpPGgHUJshvf2fwu0pQ.png" width="48" height="48"></a></p></div></div></div></div><p id="1247"><em>By Naftali Harris, CEO</em></p><p id="ac29">All of us at SentiLink are extremely excited to announce that this Friday evening at 6:48pm PT, SentiLink became the first organization to go live with eCBSV! The first application in history was from a consumer who applied for a mortgage with one of our 20 eCBSV partners. The consumer consented to sharing their information with SentiLink, our partner, and the Social Security Administration, SentiLink submitted a request to the SSA, and the SSA determined that the information matched. This expedited the approval process for the consumer and the lender and saved them from having to fill out and sign a paper form.</p><p id="6f08">eCBSV (“Electronic Consent Based SSN Verification”) is a new service being offered by the SSA that allows permitted entities to electronically obtain consent from consumers and in real-time verify name/DOB/SSN combinations directly with the SSA. Until this evening, requests for SSA validation required a completed SSA89 form and a wet signature and took hours or even days to process, significantly limiting their use. eCBSV digitizes and dramatically expedites this process. While the stream of eCBSV requests we’re now processing are only the beginning, we believe that within several years there will be tens or hundreds of millions of requests, and eCBSV will be accepted as a major component in KYC and identity verification processes.</p><p id="21fe">The entire team at SentiLink has worked very hard to make eCBSV available for our partners and their customers. This includes getting up before 3:00AM last July in order to submit one of the <a target="_blank" rel="noopener" href="https://blog.sentilink.com/sentilink-and-ecbsv-5501d1db6360">first pilot applications</a> to the SSA, implementing all of the OIDC corner cases in the integration, doing <a href="https://research.sentilink.com/sentilink-ecbsv-whitepaper" target="_blank" rel="noopener">original research on match rates against the SSA’s source-of-truth Numindent file</a>, designing <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-use-cases-f674b9905123">implementations and potential use-cases</a> with our financial institution partners, and <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-consent-requirements-4fc897e87d44">working closely with the SSA to iron out the consent requirements</a>. I’d like to thank the entire team at SentiLink for sweating and hustling to push this over the line. I’d also like to thank our initial 20 partners; no first time implementation is perfect, and we’re lucky to work with 20 innovative, forward-thinking organizations whose feedback has been and continues to be critical to the success of this program. And lastly all of us would like to thank the SSA, whose hard work and late nights standing up eCBSV has made everything possible.</p><p id="02b5">We don’t believe eCBSV will be perfect or a stand-alone solution, but it is certainly a big step forward and a very useful new tool for financial services companies. We are humbled to help open a new chapter in identity verification in the United States.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039393</guid>
            <pubDate>Mon, 03 Aug 2020 15:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why SQL is your key to querying Kafka]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039363">thread link</a>) | @lensesio
<br/>
August 3, 2020 | https://lenses.io/blog/2020/07/why-sql-your-key-to-querying-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/07/why-sql-your-key-to-querying-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>If you’re an engineer exploring a streaming platform like Kafka, chances are you’ve spent some time trying to work out what’s going on with the data in there.&nbsp;</b></p><p>But if you’re introducing Kafka to a team of data scientists or developers unfamiliar with its idiosyncrasies, you might have spent days, weeks, months trying to tack on self-service capabilities.&nbsp;</p><p>We’ve been there.</p><p>Here we’ll explain why and how we did just that with a tool you may find surprising for streaming technologies - <a href="https://lenses.io/product/sql/">SQL</a>.</p><p>We talk <a href="https://lenses.io/blog/2020/07/Why-new-Streaming-SQL-opens-up-data-platform/">elsewhere</a> about using SQL to build streaming applications with Kafka, but what about using SQL for ad-hoc queries of Kafka topics?&nbsp;</p><p>To many developers, this may seem like a strange idea - after all, SQL was designed for (and is still most often used for) accessing relational databases, and a streaming platform like Kafka is quite a different beast. On top of that, our pipelines often involve shipping the data from Kafka to other data stores such as Splunk, Elasticsearch or even a SQL database, all of which provide rich querying capabilities.</p><p>But the fact is, sometimes we really want to know what’s going on with our data when it’s inside Kafka. Most of us, as a first port of call, might reach for the command line tools that ship with Kafka, or the Swiss Army knife that is kafkacat. Here is our attempt at looking at the contents of a Kafka topic on a <a href="https://lenses.io/downloads/lenses/?path=wizard-form">Lenses Box docker container </a>running on my local machine, using Kafka’s kafka-console-consumer to query a topic containing a record of taxi rides<b> </b>in New York:</p><pre>/&nbsp;#&nbsp;kafka-console-consumer&nbsp;--bootstrap-server&nbsp;localhost:9092&nbsp;--max-messages&nbsp;3&nbsp;--topic&nbsp;nyc_yellow_taxi_trip_data</pre><pre></pre><pre>&amp;2016-01-01&nbsp;00:35:36&amp;2016-01-01&nbsp;00:47:04)\???(??`?}R??zfD@Nv|R?`?fD@#@????333333??H?z?G@?Q???)@&amp;2016-01-01&nbsp;00:35:37</pre><pre></pre><pre>&amp;2016-01-01&nbsp;00:55:36@?L|R?&nbsp;CeD@N??zR???aD@?3@????333333????????4</pre><pre></pre><pre>@&amp;2016-01-01&nbsp;00:35:38&amp;2016-01-01&nbsp;00:38:39????????N@????333333??????????ffffff@</pre><p><code>Processed&nbsp;a&nbsp;total&nbsp;of&nbsp;3&nbsp;messages</code></p><p>
So, after reading the documentation to figure out the necessary parameters, my reward is the above, fairly incomprehensible output.&nbsp;</p><h3>Making messages &amp; topics more accessible</h3><p>Because the messages on that particular topic happen to be in AVRO format, the raw message content is unlikely to be very helpful. If the messages had JSON payloads, I’d be a bit better off, and I might be able to use a tool such as jq to isolate the information that I want to see. Depending on the data involved, it could take a while to find exactly what I’m looking for.&nbsp;</p><p>As developers, most of us want to be familiar with, and if possible to master, the command line tools that we use most often. But in the cloud era, where even a small project typically involves a plethora of technologies, it becomes impractical to know every command line tool well. This is where being able to fall back on something that we do know well, in this 
case SQL, becomes appealing.</p><p><iframe src="https://player.vimeo.com/video/443057175" width="740" height="416" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p><iframe src="https://player.vimeo.com/video/443057175" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p><iframe src="https://player.vimeo.com/video/443057175" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p><iframe src="https://player.vimeo.com/video/443057175" width="540" height="300" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p><iframe src="https://player.vimeo.com/video/443057175" width="300" height="170" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p>And the above example is for the simple case where we want to look at data on a local docker image. What if there’s a problem in production and we need to see what the data looks like there? Better hope that your colleague in DevOps has got over that time that you had the nerve to suggest that golang isn’t the be all and end all of programming languages.&nbsp;</p><h3>Life of PII</h3><p>Quite some time later, via a labyrinth of ssh connections and after lots of googling on the topic of Kafka authentication, you might get to the point of being able to see the same kind of unfriendly output as in the local docker example above. By the time you’re starting to get visibility of what’s going wrong, you and your DevOps colleague are getting tired.&nbsp;</p><p>It’s Friday, and it’s nearly time for the first beer of the evening. But you know that beer will be served with a shot of anxiety: does the CDO need to find out about this?&nbsp;</p><p>How will they feel about you watching screens full of un-redacted <a href="https://help.lenses.io/using-lenses/data/data-policies/">Personally Identifiable Information</a> scrolling by?</p><h3>Why SQL for Kafka?</h3><p>Having a secure yet accessible interface for Kafka doesn’t benefit just developers.&nbsp;</p><p>Data flowing in Kafka is typically at the early phase of a data pipeline, meaning it is raw and rich in information and accessible prior to a dashboard being created or landing in a data warehouse. It would be as useful to a product owner measuring user engagement for a new product, or as a data scientist exploring what features to extract from a raw dataset on the wire.</p><p>And because the language involved is SQL, it can be used directly by those that aren’t comfortable with Kafka or prefer not to use a command line.&nbsp;</p><p>Since the SQL interface is a layer of indirection between the user and Kafka, data access can be protected through a <a href="https://lenses.io/blog/2019/10/secure-self-service-and-governance-portal-for-kafka/">namespaces-based security model.</a>&nbsp;</p><h3><b>SQL in action to solve data discrepancies in ride-sharing apps</b></h3><p>So, getting back to our aforementioned <code>nyc_yellow_taxi_trip_data</code> topic, which contains trip data being sent by taxis in real-time. Let’s imagine that our analytics dashboard is showing that the average trip distance for a particular vendor has decreased, even though the trip times seem normal, as do the fares.&nbsp;</p><p>Something unusual is going on, but what?&nbsp;</p><p>In the past we’ve seen issues like this caused by bugs introduced by upgrades to firmware of the taxi meters, but we’ve also recently made changes to our analytics pipelines, which could also be a factor. As Kafka is the part of our system where we initially store the raw data received from the meters, looking at the data in Kafka could help us to narrow things down.</p><p>Firstly, we’ll take a look at the topic in order to get an idea of the structure of the data:</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/25Dz2Bv77W3KAosuVAM31J/360e3e54721080a3d59b528f991f6e26/s1.png" alt="Reviewing Kafka data structure with SQL"></span></p><p>The discrepancy started appearing in our analytics for the previous day, and we know that the affected vendor has a VendorID of 2, so let’s try to get a picture of what things looked like for a 5 minute period yesterday afternoon. </p><p>A naive query might look like this:</p><pre>SELECT&nbsp;count(*),sum(trip_distance)&nbsp;as&nbsp;total_distance,</pre><pre></pre><pre>&nbsp;&nbsp;sum(fare_amount)&nbsp;as&nbsp;total_fares</pre><pre></pre><pre>&nbsp;&nbsp;FROM&nbsp;nyc_yellow_taxi_trip_data</pre><pre></pre><pre>&nbsp;&nbsp;WHERE&nbsp;VendorID=2</pre><pre></pre><pre>&nbsp;&nbsp;AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")</pre><pre></pre><pre>&nbsp;&nbsp;&gt;&nbsp;TO_DATETIME("2020-07-27&nbsp;12:00:00",&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")</pre><pre></pre><pre>&nbsp;&nbsp;AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;&lt;&nbsp;TO_DATETIME("2020-07-27&nbsp;12:05:00",&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")</pre><h3>Making real-time data work in real life</h3><p>When we’re running against a local docker instance, or a test environment with a small data set, we can simply execute any query that we dream up.&nbsp;</p><p>But production can be a different story.&nbsp;</p><p>Regardless of the technology being used, the key to designing an efficient query is to understand the way that the data is stored. The following is a heavily simplified representation of what a Kafka record looks like:</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/4arYH5VnQQIXuezFBC5tW4/0dffd61c14db6e50e3335215978aa23c/The-Whys-and-Hows-of-building-a-SQL-interface-to-Kafka---by-Will__1_.jpg" alt="Kafka record SQL"></span></p><p>Key and Value are the actual payload(s) of the message. In the case of our current topic, in fact the key is empty, and so our data is stored in Value. It’s important to remember that these payloads are pretty much entirely opaque to Kafka. So, while we’re storing all sorts of nice, structured AVRO data there, the only way we can find a field with a specific value is to read every single message on the topic, looking for that value.&nbsp;</p><p>This is obviously inefficient.&nbsp;</p><p>At least <a href="https://help.lenses.io/using-lenses/administer/kafka-quotas/">quotas</a> can be used to ensure that such queries don’t cause any performance problems on our production system, but that doesn’t help us to get the information we’re looking for. Fortunately, while the Key and Value in the diagram above are opaque to Kafka, the Offset and Timestamp are not.</p><h3>Comparing streaming SQL queries</h3><p>In our original query, we were trying to narrow down to a specific time period using the <code>tpep_dropoff_datetime</code> field. But as the meters are sending us this information pretty much in real time, we can take advantage of the fact that the timestamp stored in the Kafka record should be quite close to the value of <code>tpep_dropoff_datetime</code>, but with the advantage that it’s being indexed by Kafka. For other problems it might make more sense to narrow down by offset or partition number, but timestamp is perfect in this case.</p><p>Here is our new query, where we use _meta.timestamp in order to refer to the timestamp at the Kafka record level rather than the one in our payload:</p><pre>SELECT&nbsp;count(*),sum(trip_distance)&nbsp;as&nbsp;total_distance,&nbsp;sum(fare_amount)&nbsp;as&nbsp;total_fares</pre><pre></pre><pre>FROM&nbsp;nyc_yellow_taxi_trip_data</pre><pre></pre><pre>WHERE&nbsp;VendorID=2</pre><pre></pre><pre>AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")&nbsp;</pre><pre></pre><pre>&gt;&nbsp;&nbsp;(DATE()&nbsp;-&nbsp;"1d")&nbsp;+&nbsp;"15h"</pre><pre></pre><pre>AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")&nbsp;</pre><pre></pre><pre>&lt;&nbsp;(DATE()&nbsp;-&nbsp;"1d")&nbsp;+&nbsp;"15h"&nbsp;+&nbsp;"5m"</pre><pre></pre><pre>AND&nbsp;_meta.timestamp&nbsp;&gt;&nbsp;NOW()&nbsp;-&nbsp;"26h"&nbsp;</pre><pre></pre><pre>AND&nbsp;_meta.timestamp&nbsp;&lt;&nbsp;NOW()&nbsp;-&nbsp;"24h"</pre><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/63LKXHrR9TkB02Tf5KQZIx/6951c23fd4af25a96f3431a7c825e036/image.png" alt="Apache Kafka topic sum of distance in topic SQL query with lenses.io"></span></p><p>

You’ll notice in the above search we are filtering to a 2 hour window using the _meta.timestamp for search-efficiency reasons and then further filtering to a specific 5 minute window using the <code>tpep_dropoff_datetime</code> field. The extra buffer is in case the dropoff timestamp isn’t exactly in line with the timestamp held in Kafka.&nbsp;</p><p>Now let’s compare this to the result from two days ago, before the problem had manifested itself:</p><pre>SELECT&nbsp;count(*),sum(trip_distance)&nbsp;as&nbsp;total_distance,&nbsp;sum(fare_amount)&nbsp;as&nbsp;total_fares</pre><pre></pre><pre>FROM&nbsp;nyc_yellow_taxi_trip_data</pre><pre></pre><pre>WHERE&nbsp;VendorID=2</pre><pre></pre><pre>AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")&nbsp;</pre><pre></pre><pre>&gt;&nbsp;&nbsp;(DATE()&nbsp;-&nbsp;"2d")&nbsp;+&nbsp;"15h"</pre><pre></pre><pre>AND&nbsp;TO_DATETIME(tpep_dropoff_datetime,&nbsp;"yyyy-MM-dd&nbsp;HH:mm:ss")&nbsp;</pre><pre></pre><pre>&lt;&nbsp;(DATE()&nbsp;-&nbsp;"2d")&nbsp;+&nbsp;"15h"&nbsp;+&nbsp;"5m"</pre><pre></pre><pre>AND&nbsp;_meta.timestamp&nbsp;&gt;&nbsp;NOW()&nbsp;-&nbsp;"50h"&nbsp;AND&nbsp;_meta.timestamp&nbsp;</pre><pre></pre><pre>&lt;&nbsp;NOW()&nbsp;-&nbsp;"48h"</pre><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/4oq5yl78O5UIyqnIT3swii/de8a7fead39401a42d2b46d9fd32e09a/image.png" alt="Apache Kafka topic sum of distance in topic SQL query with lenses.io 2"></span></p><p>Once again here, we’re pre-filtering the results to a two hour timeframe using <code>_meta_timestamp</code> field.&nbsp;</p><h3>Diagnosing complex real-world problems with a set of simple queries</h3><p>A careful look at the results indicates that although the number of trips and the fares are similar for the particular time period across the two days, the total distance over this time period is actually about ten times lower for yesterday’s data compared to two days ago! From here, we may want to sample other time periods to make sure that what we just saw isn’t a fluke.&nbsp; Alternatively, a natural progression might be to build a continuously running Streaming SQL App that samples data quality over a sliding period of time and populates …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lenses.io/blog/2020/07/why-sql-your-key-to-querying-kafka/">https://lenses.io/blog/2020/07/why-sql-your-key-to-querying-kafka/</a></em></p>]]>
            </description>
            <link>https://lenses.io/blog/2020/07/why-sql-your-key-to-querying-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039363</guid>
            <pubDate>Mon, 03 Aug 2020 15:56:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The art of the weekly CEO update]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039301">thread link</a>) | @anacleto
<br/>
August 3, 2020 | https://pulseasync.com/operators/weekly-ceo-update/ | <a href="https://web.archive.org/web/*/https://pulseasync.com/operators/weekly-ceo-update/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article"><p>Most startups are a hot mess.</p>
<p>Once an organization achieves a basic level of product-market fit, chaos dominates everywhere, and the single hardest problem is to keep the entire company aligned.</p>
<p>Before then, all of the employees fit into a single room, everyone knows what everyone else is working on, and founders can easily walk around desks telling everyone what to build and why.</p>
<p>But at around 50 employees, things change and this approach stops working.</p>
<p>Team and departments get formalized under org charts, all-hands meeting are reduced to the minimum, and all sorts of processes and proxies emerges.</p>
<p>All the new levels of hierarchy creates silos and a feeling of compartmentalization. Meanwhile, a lack of leadership for some functions creates a sense of disorganization and chaos.</p>
<p>The job of a great leader is not to resist this chaos, but to counterbalance it by frequently communicating with extreme clarity principles and priorities, so that everyone, no matter roles, department or seniority, knows the company's goals and direction. Good management is a perpetual anti-entropy device.</p>
<p>Most leaders use all-hands meetings as the de-facto tool in their arsenal to keep the company aligned and informed. During these meetings the entire company gets in a room or on a conference call and receives an update in a lecture-style format.</p>
<p>Meetings, more than any other written communication medium, allows the speaker to <a href="https://en.wikipedia.org/wiki/Media_richness_theory">convey more information</a>, but they can be hard to arrange at scale. This is especially true for remote or distributed organizations where employees work from different locations and time zones.</p>
<p>The most overlooked weapon to keep the company on the same page is a good-old <em>internal weekly newsletter</em>. The obvious example of the category is the <em>Weekly CEO Update Email</em>.</p>
<p>We'll see in this essay not just why every Founder/CEO should send a weekly CEO update email to the entire company, but also what elements are necessary to craft a great Weekly CEO Update.</p>
<h2 id="why-an-internal-newsletter"><a href="#why-an-internal-newsletter" aria-label="why an internal newsletter permalink"></a>Why An Internal Newsletter</h2>
<p>Why isn't an all-hands enough? We're hyperconnected throughout the day, why should a Founder/CEO even bother adding a new piece to the puzzle? Meetings are a great tool because it's a nuanced medium of communication, but they can't replace a regular well-written email. Here's why:</p>
<ol>
<li><em>Written Communication is Personal</em></li>
</ol>
<p>Written communication is one of the strongest forms of persuasion.</p>
<p>The wire that stretches from the writer to the reader is singular. The writer creates in solitude, and the reader reads in solitude. It's an intimate relationship. Everything happens silently in the brain as an intellectual dialog between the two parts.</p>
<ol start="2">
<li><em>Better Historical References</em></li>
</ol>
<p>References made in spoken words are weak.</p>
<p>On the other side, written communication allows you to pinpoint the exact piece of information that you want to reference to. This not only helps the author to write more extensively but also the reader to fully understand the global scope of the message.</p>
<ol start="3">
<li><em>Permanent</em></li>
</ol>
<p>Anything that's written in words is permanent and searchable. This means everyone sees the same thing, everyone hears the same thing, and everyone will know the same thing - including future employees who are yet to join your company.</p>
<p>Permanence of communication is the prerequisite to a shared truth.</p>
<ol start="4">
<li><em>Writing is Costs Effective</em></li>
</ol>
<p>Writing saves time.</p>
<p>If you already have a distributed team, you know how hard and time consuming it is to arrange an all-hands meeting.</p>
<p>Plus, as Basecamp <a href="https://basecamp.com/guides/how-we-communicate">puts it</a>, </p>
<blockquote>
<p>“Five people in a room for an hour isn’t a one hour meeting, it’s a five hour meeting.”</p>
</blockquote>
<ol start="5">
<li><em>Inclusiveness For Women and Introverts</em></li>
</ol>
<p>Modern work gives extroverts a free power-up that introverts have to earn through time and practice. Meetings favor individuals who think out loud and are good at discussing things on the fly. They aren't fair to those who need time to think things through. It’s an unfair game for a large number of people. Yet, this rarely gets noticed.</p>
<h2 id="how-to-write-a-great-weekly-ceo-update"><a href="#how-to-write-a-great-weekly-ceo-update" aria-label="how to write a great weekly ceo update permalink"></a>How To Write a Great Weekly CEO Update</h2>
<p>The outline of a Weekly CEO Update always includes three key elements:</p>
<ol>
<li>Summary</li>
<li>Performance Update</li>
<li>Misc: Ops and Culture Highlights</li>
</ol>
<hr>
<h3 id="summary"><a href="#summary" aria-label="summary permalink"></a>Summary</h3>
<p>The summary is an introductory paragraph that summarizes what happened the latest week.</p>
<p>A good summary gets the reader's attention either:</p>
<ol>
<li>By answering a question the <em>reader already has</em> (<em>ie.</em> the company is acquiring a competitor and employees wants to know more about the progress on the deal).</li>
<li>By <em>raising a new question</em> in the reader's mind for which the author is going to provide an answer to (<em>ie</em> reasons why the org chart was restructured and some teams were un-bundled).</li>
</ol>
<p>If the reader already has a clear question, you can go straight to the point by answering it. Otherwise, you should build a compelling summary that naturally leads to it. Failing at both of these means not establishing the relevancy of your message.</p>
<p>Although not a weekly update, one of the best example of summary is the one sent by CEO Stephen Elop to introduce the call to action for Nokia's need to embrace a non-homegrown platform.</p>
<p>You can read the <a href="https://sriramk.com/memos/elop-burning-platforms.pdf">full memo here</a>.</p>
<p><img src="https://pulse-website-temp.s3.us-west-2.amazonaws.com/articles/Screenshot%202020-07-08%20at%2023.06.43.png" alt="burning platform internal memo from Nokia CEO Elop" title="burning platform internal memo from Nokia CEO Elop"></p>
<p>The summary is the most important section of the update.</p>
<h3 id="performance-update"><a href="#performance-update" aria-label="performance update permalink"></a>Performance Update</h3>
<p>The performance update is a reminder about how the organization is doing against its most important goals.</p>
<p>Every organization has a few critical top-level goals tied to a set of strategic initiatives. As a leader, you need to solidify this message by repeating it all the time.</p>
<p>So, here's a simplified version of the performance update:</p>
<p><strong>Top-Level Goals</strong>:</p>
<ul>
<li><strong>Yearly Goals</strong>: current metrics for annual goals and how you’re measuring up against them</li>
<li><strong>Quarterly Goals</strong>: current metrics for quarterly goals and how you’re measuring up against them</li>
<li><strong>Quarterly Priority</strong>: percentage complete and any updates to the most important projects</li>
</ul>
<p><strong>Strategic Initiatives</strong>: </p>
<ul>
<li><strong>Activity #1</strong> [commentary]</li>
<li><strong>Activity #2</strong> [commentary]</li>
<li><strong>Activity #3</strong> [commentary]</li>
</ul>
<p>If you're thinking "Wait, do I really need to state our top level goals in every single update?", the answer is <strong>YES</strong>. The minute you start to get sick of hearing yourself to often, your people are just starting to internalize it.</p>
<p><a href="https://twitter.com/rands/status/1278735543019270145">https://twitter.com/rands/status/1278735543019270145</a></p>
<h3 id="misc-ops-and-culture-highlights"><a href="#misc-ops-and-culture-highlights" aria-label="misc ops and culture highlights permalink"></a>Misc: Ops and Culture Highlights</h3>
<p>The end of your update is the perfect place to share details about people and operations.</p>
<p>Specifically, you want to cover with these three sections:</p>
<ul>
<li><strong>Operations</strong>: new processes or procedures (eg. a new Slack etiquette, a new remote work policy, new room procedure, or new habits that you are trying to inculcate generally)</li>
<li><strong>Culture Highlight</strong>: share topos, stories or examples from the week that project the company culture</li>
<li><strong>People spotlights</strong>: give exposure to members of the team and expose their work to the entire org</li>
</ul>
<p>Feel free to adapt this section to your own needs and rituals.</p>
<h2 id="the-cadence"><a href="#the-cadence" aria-label="the cadence permalink"></a>The Cadence</h2>
<p>The goal of the Weekly CEO Update is not just to inform, but rather to create an operational cadence for the entire company. Frequent, well-written updates = high-performing, intense pace. Occasional, poorly-written updates = low-performing pace.</p>
<p>A daily update can be too much information. A monthly update can be too little. A weekly update is usually what works best, but depending on the circumstances every cadence would work.</p>
<p>Pick a cadence that not only captures the rhythm of the organization but actually reinforces it.</p>
<h2 id="the-medium"><a href="#the-medium" aria-label="the medium permalink"></a>The Medium</h2>
<p>Don't send an email for the weekly update. Email is a decentralized form of communication. That means that there's no permanent record in a permanent place everyone can see. </p>
<p>Similarily, avoid Slack messages. Chat is great for quick and casual conversations, but it's not the best way to share interne memos and announcements that are more than one-line-at-a-time jousts.</p>
<p>Instead, you should post it in a place where the message can be easily retrieved if you wanted to. Everyone should see, hear and know the same thing – including future employees who are yet to join the company.</p>
<p>I shared <a href="https://pulseasync.com/operators/introducing-pulse/">here</a> and <a href="https://pulseasync.com/operators/speed-of-communication/">here</a> how companies like Automattic and Zapier<a href="#"></a> are using tools like <a href="https://pulseasync.com/operators/speed-of-communication/#3-the-zapier-stack">Async and the Wordpress P2 theme</a> for <a href="https://pulseasync.com/operators/speed-of-communication/#2-async">asynchronous communication</a>.</p>
<h2 id="using-pulse-for-long-form-updates"><a href="#using-pulse-for-long-form-updates" aria-label="using pulse for long form updates permalink"></a>Using Pulse For Long-Form Updates</h2>
<p>Pulse is a stripped-back async work tool that can help you do just that: share long-from updates to keep your team on the same page.</p>
<p><img src="https://i.imgur.com/zGKPozx.png" alt="Pulse Editor With Internal Memo"></p>
<p>We’ve specifically designed Pulse from the ground up to support updates across projects, processes, decisions, strategy and more. The type of comms that this product enables can range from global announcements, project proposals, and feedback on processes to welcoming new employees and discussions around long-term endeavors.</p>
<p>But let's go back to the <em>Weekly CEO Update</em> usecase. </p>
<p>The best way to share a Weekly CEO Update in Pulse is to start by creating a dedicated <a href="https://pulseasync.com/features/">Stream</a>.</p>
<p><img src="https://pulse-website-temp.s3.us-west-2.amazonaws.com/articles/Screenshot%202020-07-08%20at%2023.30.49.png" alt="CEO Weekly Update Stream in Pulse"></p>
<p>People in your organization can follow the Stream and read your Weekly Updates directly from the Pulse Website or (once you installed the <a href="https://pulseasync.com/browser-extension">Browser Extension</a>) anytime they open their browser's new tab.</p>
<p>Let's look at some real examples.</p>
<p>Jason Lemkin used to run an internal publication called <code>The Daily Jason</code> where he sent every morning an email to the entire SaaStr team. The Daily Jason's Update always included the top 3 priorities for the week and how the team was measuring up against them.</p>
<p>You can learn in this quick video Jason talking about it: </p>
<p> <iframe src="https://www.youtube.com/embed/EOR9-NSwNAo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<p>In Pulse he would have created a <code>@daily-jason</code> stream and shared there every morning an update. The team would have been notified either by Slack, Email or the Browser Extension.</p>
<p>What's benefit of using Pulse over Email, Slack or other decentralised communication channels?</p>
<ol>
<li>Updates are permanently recorded in a fixed place not just your current team members, but also for the future ones who are yet to join the organization. This approach makes it super easy for a new employees to immerse in the company tone and culture, and understand how your company operates. A much better experience than digging in organized Slack channels.</li>
<li>You, as a leader, can reference updates previously published by your team, in the next weekly update. For instance, Jason …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulseasync.com/operators/weekly-ceo-update/">https://pulseasync.com/operators/weekly-ceo-update/</a></em></p>]]>
            </description>
            <link>https://pulseasync.com/operators/weekly-ceo-update/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039301</guid>
            <pubDate>Mon, 03 Aug 2020 15:53:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The List of Neomorphism Design Resources]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24038970">thread link</a>) | @johannesippen
<br/>
August 3, 2020 | https://toolbox.humandeluxe.com/2020/08/02/neomorphism-list | <a href="https://web.archive.org/web/*/https://toolbox.humandeluxe.com/2020/08/02/neomorphism-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  
  
  <p><img src="https://d33wubrfki0l68.cloudfront.net/1191a0669d5e4a038c87965655902ade8142fb40/b8c52/uploads/neomorphism-ultimate-list.jpg" alt=""></p>

<p>The world of simulated realism is back: Say Hi to Neumorphism! You either love or hate the hottest 2020 design trend, but one thing is for sure: You need to try it!</p>

<p>At first glance, neumorph interfaces shine through monochrome, smooth and haptic surfaces with huge, cloudy shadows. Like skeumorphism, this design polarizes. You might feel reminded of the temptation of activating all the Photoshop layer effects at once. If you want to be better than that, you’ve come to the right place.</p>

<p>This list collects all the ressources, tutorials, templates, code snippets and design files that you need to get started with neumorph UI design.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/32ff98874bc656f11a9cde0f421a5abda4492cba/bb067/uploads/neomorphism-calc.png" alt=""></p>

<h2 id="tutorials--intro">Tutorials &amp; Intro</h2>

<p>If you are completely new to neumorphism, check out this section first. We found the best explainer articles around neumorph design, and also some critical perceptions:</p>

<ul>
  <li><a href="https://css-tricks.com/neumorphism-and-css/">https://css-tricks.com/neumorphism-and-css/</a></li>
  <li><a href="https://uxdesign.cc/neumorphism-in-user-interfaces-b47cef3bf3a6">https://uxdesign.cc/neumorphism-in-user-interfaces-b47cef3bf3a6</a></li>
  <li><a href="https://uxdesign.cc/neumorphism-the-zombie-trend-88cff23de46b">https://uxdesign.cc/neumorphism-the-zombie-trend-88cff23de46b</a></li>
  <li><a href="https://uxdesign.cc/lets-talk-neumorphism-and-accessibility-44a48a6ace72">https://uxdesign.cc/lets-talk-neumorphism-and-accessibility-44a48a6ace72</a></li>
  <li><a href="https://medium.com/@artofofiare/neumorphism-the-right-way-a-2020-design-trend-386e6a09040a">https://medium.com/@artofofiare/neumorphism-the-right-way-a-2020-design-trend-386e6a09040a</a></li>
</ul>

<p><img src="https://d33wubrfki0l68.cloudfront.net/ffa78a8246e66909dbbfc51a5bc24d31cd5de874/dc932/uploads/neomorph-piano.png" alt=""></p>

<h2 id="examples">Examples</h2>

<p>Before you get started, take a look at some of the best neumorph interfaces out there – These are currently our personal favorite neumorphism designs you can find:</p>

<ul>
  <li><a href="https://dribbble.com/tags/neomorphism">https://dribbble.com/tags/neomorphism</a></li>
  <li><a href="https://codepen.io/liva_raita/pen/zYxpLjJ">https://codepen.io/liva_raita/pen/zYxpLjJ</a></li>
  <li><a href="https://www.youtube.com/watch?v=I1d_GGIpKrM">https://www.youtube.com/watch?v=I1d_GGIpKrM</a></li>
  <li><a href="https://codepen.io/cassie-codes/pen/mdyvEXb">https://codepen.io/cassie-codes/pen/mdyvEXb</a></li>
  <li><a href="https://codepen.io/halvves/pen/ExjxaKj">https://codepen.io/halvves/pen/ExjxaKj</a></li>
  <li><a href="https://dribbble.com/shots/9834737-Music-App-Neumorphism-Redesign">https://dribbble.com/shots/9834737-Music-App-Neumorphism-Redesign</a></li>
  <li><a href="https://dribbble.com/shots/10491971-Neumorghism-2">https://dribbble.com/shots/10491971-Neumorghism-2</a></li>
  <li><a href="https://codepen.io/travisw/pen/JjoaadE">https://codepen.io/travisw/pen/JjoaadE</a></li>
</ul>

<p><img src="https://d33wubrfki0l68.cloudfront.net/667c79eb16f487b7ebdf359aa65001934044335c/41781/uploads/neomorphism-generator.png" alt=""></p>



<p>Of course, you don’t need to start from scratch – There are templates, frameworks and code snippets you can utilize when designing neumorph interfaces:</p>

<ul>
  <li><a href="https://neumorphism.io/#55b9f3">https://neumorphism.io/#55b9f3</a></li>
  <li><a href="https://www.youtube.com/watch?v=Gv0dy51SYL0">https://www.youtube.com/watch?v=Gv0dy51SYL0</a></li>
  <li><a href="https://dribbble.com/shots/11011222-Free-Neumorphic-GUI-Unicorn-Style-unicorn-UI-design">https://dribbble.com/shots/11011222-Free-Neumorphic-GUI-Unicorn-Style-unicorn-UI-design</a></li>
  <li><a href="https://dribbble.com/shots/11674839-FREE-Neumorphic-Elements-Sketch-File">https://dribbble.com/shots/11674839-FREE-Neumorphic-Elements-Sketch-File</a></li>
  <li><a href="https://dribbble.com/shots/11116430-Neumorphism-UI-Elements">https://dribbble.com/shots/11116430-Neumorphism-UI-Elements</a></li>
  <li><a href="https://dribbble.com/shots/11652074-FREE-Neumorphism-UI-Kit">https://dribbble.com/shots/11652074-FREE-Neumorphism-UI-Kit</a></li>
  <li><a href="https://www.cssscript.com/neumorphism-ui-skeuos/">https://www.cssscript.com/neumorphism-ui-skeuos/</a></li>
  <li><a href="https://www.behance.net/gallery/98867175/%28Freebie%29-Neuomorphism-Button-Kit">https://www.behance.net/gallery/98867175/%28Freebie%29-Neuomorphism-Button-Kit</a></li>
  <li><a href="https://demo.themesberg.com/neumorphism-ui-pro/">https://demo.themesberg.com/neumorphism-ui-pro/</a></li>
  <li><a href="https://dribbble.com/shots/9566236-Skeumorphic-UI-UX-Elements">https://dribbble.com/shots/9566236-Skeumorphic-UI-UX-Elements</a></li>
  <li><a href="https://dribbble.com/shots/10143929-Freebie-Dashboard-Interface-Elements">https://dribbble.com/shots/10143929-Freebie-Dashboard-Interface-Elements</a></li>
</ul>

<p>This list will be updated regularly – so make sure you bookmark it and come back once in a while for new resources. If you have a link that you would like to see integrated here, reach out to me on Twitter or Instagram: <a href="http://twitter.com/johannesippen/">@johannesippen</a>.</p>

</div></div>]]>
            </description>
            <link>https://toolbox.humandeluxe.com/2020/08/02/neomorphism-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038970</guid>
            <pubDate>Mon, 03 Aug 2020 15:31:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Underestimate the Importance of Small Things]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24038594">thread link</a>) | @iuliangulea
<br/>
August 3, 2020 | https://iuliangulea.com/blog/we-underestimate-the-importance-of-small-things/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/we-underestimate-the-importance-of-small-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>Small tasks are often mundane, insignificant, and dull. We spend the biggest part of our time doing them and wish we could have more time to spend on some big and important things.</p>
<p>But what we frequently fail to realize is how vital such small things are, their potential to influence our lives, and that the big and important things are like jigsaw puzzles made of many tiny pieces. To build the whole picture that you can later look at and feel great about, you have to organize and combine many small parts that, when put together, create something visually stunning. Moreover, sometimes minor events serve as triggers to the most impactful effects that happen to us.</p>
<p>The only difference from a jigsaw puzzle is that life’s events are not interlocking pieces, and rarely do you precisely know the outcome. In some cases, you can create some expectations on the result, but it is entirely unknown for the others.</p>
<h2 id="a-snowflake-can-cause-an-avalanche">A Snowflake Can Cause An Avalanche</h2>
<p>The most massive, overarching, and impactful events are sometimes triggered by something infinitesimally small. Just look at this comic by Abstruse Goose:</p>
<figure>
    <img src="http://abstrusegoose.com/strips/apocryphal_molecule.png" alt="One Molecule Can Change The Course Of History"> <figcaption>
            <p>Source:
                    <a href="https://abstrusegoose.com/208">Abstruse Goose</a></p>
        </figcaption>
</figure>

<p>Although it might be a bit exaggerated and despite the fact that there is no evidence an apple actually hit Newton on the head,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> it demonstrates that:</p>
<ol>
<li>The small changes can have a chain reaction, leading to bigger things with a more significant impact.</li>
<li>You never know how the universe has arranged things until you get there. Billions of apples had fallen from trees since the dawn of civilization, but it was one apple that did so at the right time in the right place when Newton was around, looking in a contemplative mood that the notion of gravitation came to his mind.</li>
</ol>
<p>You might also have heard about the <strong>Butterfly Effect,</strong> which, in chaos theory, has a more scientific name of <em>“sensitive dependence on initial conditions."</em> It states that small changes in the initial conditions can create significantly different outcomes in some systems. The “Butterfly Effect” term is derived from the metaphorical example that a tornado is caused by flaps of the wings of a butterfly on the other side of the globe.</p>
<p>Another notable example is Kyle MacDonald, who bartered his way from a single red paper clip to a house in a series of fourteen online trades over a year.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Finally, the COVID-19, a global pandemic that has affected almost all countries and over 17 million people, most probably has started from a single person (the so-called patient zero).</p>
<h2 id="life-is-a-series-of-choices-you-make-every-day">Life Is A Series Of Choices You Make Every Day</h2>
<p>It is not only the immense potential to trigger chain reactions that lead to stories with an enormous impact that characterizes small events.</p>
<p>Another property of little things is that they have a compounding effect. The more things you do, the larger the compounding impact gets. Eventually, it becomes visible.</p>
<h3 id="the-visibility-threshold">The Visibility Threshold</h3>
<p>As mentioned in <a href="https://iuliangulea.com/blog/the-imperceptible-nature-of-everyday-change/">the imperceptible nature of everyday change</a>, we very rarely perceive how we have changed during a single day.</p>
<ul>
<li>You go to the gym once—you don’t see any effect after you have exercised.</li>
<li>You eat a salad—you don’t see any impact on your weight.</li>
<li>You study for your exam for an hour—you might feel you haven’t progressed at all in that regard.</li>
</ul>
<p>But the reality is that all of those things count. Every little thing counts and every little thing is important. The small events and efforts in our life are the backbone of the bigger things: our lifestyle, career, health, happiness.</p>
<p><img src="https://iuliangulea.com/images/visibility-threshold.png" alt="The Small Things Impact Visibility Threshold"></p>
<p>It is when you continue to go to the gym, eat healthily, study more, that you start seeing the effects. That’s because the cumulative impact got big enough for us to spot it. Take a moment to look back at your greatest achievements in life, and think about how long you have been working to achieve those—how many small and dull things you have completed to realize your grand objective. And consider whether you would accomplish your goals without doing all those tiny things.</p>
<h2 id="your-impact-on-the-world-is-significant">Your Impact On The World Is Significant</h2>
<p>Having said all that, it is clear why some people excuse themselves from making good things <em>“because it won’t make a difference."</em> It is because the impact of their actions is so small it doesn’t reach the visibility threshold, so it seems worthless. But it doesn’t mean there is no impact at all. Like a drop of water in an empty cup—it is no big deal, but pour 1000 more such droplets, and you can quench someone’s thirst.</p>
<p>Each action we do has a tremendous potential to change our lives, the lives of people around us and the world we live in. And whenever you think you are too insignificant to make an impact on the world, remember that sometimes it takes only a single molecule to change the course of history.</p>
<hr>
<p>If you liked this article, make sure to subscribe below to receive new articles directly into your inbox and also follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>).</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>In 1726, Newton shared the apple anecdote with William Stukeley, who included it in a biography, “Memoirs of Sir Isaac Newton’s Life,” published in 1752. According to Stukeley, “After dinner, the weather being warm, we went into the garden, &amp; drank tea under the shade of some apple trees… he told me he was just in the same situation, as when formerly, the notion of gravitation came into his mind… occasion’d by the fall of an apple, as he sat in a contemplative mood.” <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/One_red_paperclip">One red paperclip</a> — Wikipedia <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/we-underestimate-the-importance-of-small-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038594</guid>
            <pubDate>Mon, 03 Aug 2020 15:05:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What RN is missing in order to be the default framework to build apps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24038136">thread link</a>) | @oscar_franco13
<br/>
August 3, 2020 | https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/ | <a href="https://web.archive.org/web/*/https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I was trying to develop app that runs on ALL platforms (iOS, android, windows, mac), I was encouraged by the announcement that react-native recently added support to macOS thanks to the guys at microsoft (facebook has now jumped on the bandwagon), so after a couple of months of development I have to call quits, there is just too much friction, I’m a one man team developing this on my freetime and I have rarely encountered so much problems developing a simple app.</p>

<p>React native promises this utopia, we’re you write once and gets executed everywhere, which is true when everything works, however when it doesn’t the pain starts, with the current jump into desktop environments there is a lot more friction than the more mature mobile counterparts.</p>



<p>I had assumed that despite it’s young age microsoft wouldn’t announce a “release” if the product was not ready, and I was willing to go the extra mile cutting slack here and there, ignoring the rough edges, I even patched some libraries myself, with my barely passable knowledge about the macOS toolchain, swift, obj-c and cocoapods, but I reached the point of break when trying to draw vector graphics.</p>

<p>Currently if you want to draw vector graphics on react-native the default choice is react-native-svg, surprise surprise it’s not supported on macos (or windows), support might come someday, but you are at the mercy of the react-native community until someone takes the time to port it to each platform, and let me tell you the react-native community does not have a great track record of producing well maintained software.</p>

<p>And this is a story that keeps repeating itself for me (and not only on macOS) I’ve been working with RN for some years now and everytime I reach the point where libraries are abandoned left and right, new functionality or patching requires deep knowledge of the platform and build systems.</p>

<p>Another current paint point React-navigation? you are stuck with version 2.X, which has no native dependencies and has been deprecated for years already, other libraries like camera, location, etc… you can forget them for a few months/years, it’s incredibly bold of microsoft to claim their “store” app is built with react-native, it’s basically a bunch of webviews cobled together, and it is basically a app that consists of some lists, if that is all your app will need, then you can safely use react-native on desktop.</p>



<p>Current windows and macos ports are being developed with the idea that all supported platforms should have 1 to 1 feature parity, this also includes behavior parity.</p>

<p>On the surface this sounds reasonable, <strong>it’s not</strong>, because mobile and desktop do not behave the same, the way you interact with an app using keyboard and mouse is not the same as with mobile, on desktop keyboard shortcut support is a must, being able to detect key combinations is a must, RN does not support any of this, even some of the default behavior with a digital keyboard does not translate well to physical machine, another thing is app lifecycle (focus/blur) are bound to different rules as on mobile</p>

<p>At best you will end up with an app that feels weird to use on desktop (UI not withstanding, just talking about UX here), so far my workaround has been to attach listeners on the native sides and transmit events to the rn side… you can imagine this is time consuming to get right, and sometimes you will just not get it right no matter what</p>

<h2 id="its-open-source">It’s open source!</h2>

<p>You want to patch this yourself? here are some of the problems in the order that I found them as I went along:</p>
<ul>
  <li>I barely learned Swift, I cannot justify learning obj-c, guess what rn is written in obj-c</li>
  <li>You have to learn the macOS specific APIs, most of the content in the internet is written for the iOS APIs</li>
  <li>Apple’s documentation is one of the worst I have seen so far</li>
  <li>You have to start digging into the more hardcore parts of the APIs, CoreGraphics?</li>
  <li>If somehow you manage to do all of that, repeat it for other platforms Android, Windows?</li>
  <li>Once you have your piece of native code you have to use the RN bridge, did you know it is also slow? now you have to do TurboModules, which is c++… also no (usable) documentation</li>
  <li>Oh yeah, add one more platform, react-native-web</li>
  <li>Don’t forget about each platform build system, I still don’t fully grasp everything Gradle does to build an Android app</li>
</ul>

<p>Now to be completely fair, some of these problems are not unique to react-native, the problem is… there is already a solution out there to run code on every architecture/machine that does not require you to learn a new API every 2 days or so, it’s called a web browser</p>



<p>As for react-native, besides the corporations with big pockets taking over the job the community is currently trying to fill, I see no good solution, the disparity of libraries, APIs, platforms makes this a really challenging problem to tackle in the typical OSS manner, and in the end, we are all re-creating chrome with a lesser memory footprint and some performance gains (which I still would debate)</p>

<p>As for my and my project I think the best path forward is web, I can still use react and the web APIs are good enough for what I need to do, electron gets a lot of flak for the size of installation and memory consumption, but chrome is an OS by itself, so much of this small details have been abstracted away and solved by a well paid cohesive team and with webassembly the possibilities are greater than ever, not saying it is perfect, but it sure beats holding your breath for the OSS community and a menage of companies/team (all with different incentives) to catch up</p>

<p>Creating shallow native apps that heavily use embedded webviews seems a good compromise when truly native functionality is needed, I remember I saw a couple of videos of the guys at basecamp, they have tiny native teams that only write small container apps but the bulk of the work is in the web and that can be reused inside the shallow containers, that seems to be the most reasonable thing (even if you have to learn the basic of each OS to create a container app, which you end up doing anyways with RN)</p>

  </div></div>]]>
            </description>
            <link>https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038136</guid>
            <pubDate>Mon, 03 Aug 2020 14:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Cost of a Quickfix]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24038107">thread link</a>) | @marcoow
<br/>
August 3, 2020 | https://simplabs.com/blog/2020/08/03/the-true-cost-of-a-quickfix | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/08/03/the-true-cost-of-a-quickfix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<figure><img alt="the true cost of a quickfix illustration" srcset="https://simplabs.com/assets/images/posts/2020-08-03-the-true-cost-of-a-quickfix/illustration@1440.png 1440w, https://simplabs.com/assets/images/posts/2020-08-03-the-true-cost-of-a-quickfix/illustration@2880-a0283dce1213c5dae1b09a9373723db9.png 2880w" sizes="(max-width: 887px) 1440px, 2880px"></figure>
<p>While avoiding code that resulted in such comments was harder to enforce in the
pre-framework era, opinionated frameworks such as
<a href="https://emberjs.com/" target="_blank" rel="noopener">Ember.js</a> offer us concrete ways to ship code with
confidence. This is known as the ember happy path, code smells can be identified
when an implementation strays away from the path.</p>
<p>In an ideal world, such problems can be caught early enough in the planning
cycle by collaborating closely among all stakeholders, making sure that design,
development and product work together towards finding functional solutions that
are worthy of our users' trust.</p>
<p>Delivering products with sustainable foundations is a core value that we hold
dear at simplabs. Such foundations, while relatively easy to set up on a
greenfield project are an entirely different story in any long-lived project
that might not have started with a solid foundation.</p>
<p><strong>"So how do I tackle refactoring legacy code that has made its way into
multiple core systems?"</strong></p>
<h3 id="stop-development-fix-it-now">Stop development, fix it now!</h3>
<p>While all too tempting this approach has quite a heavy list of pre-requisites in
order to be successful:</p>
<ul>
<li>Tasks have already been scoped out and achievable goals are set</li>
<li>The refactoring effort does not block mission-critical features</li>
<li>No deadlines at the door</li>
<li>The total cost and lead time impact must be justifiable to stakeholders</li>
<li>A robust and comprehensive test suite</li>
</ul>
<p>Often, teams with deadlines will have maintenance periods where engineers are
allocated time to "fix" the codebase. Time and time again I have seen this
pattern repeated with similar outcomes, overrun budgets and half-finished
long-lived branches.</p>
<p>As we tally up the costs (dev/design/product/... time, loss of competitiveness,
etc...), it is important to keep in mind that this is a one-time investment we
pay for a more standardized codebase with a reduced chance of future feature
work delay.</p>
<h3 id="stop-quick-fix-time">Stop! Quick-fix time!</h3>
<p>A scenario we are all too familiar with, everything is going according to plan,
development is running smoothly, marketing is preparing their release post. Then
the (un)expected happens, a part that seemed unrelated starts breaking.</p>
<p>A common approach, that has long term implications, is to run a quick analysis,
attempt to pinpoint the issue and patch it in time to meet the deadline. While
this may address our short-term needs, if not followed up with a code audit and
analysis, it will come back to haunt us.</p>
<p>Just recently I experience a situation where a quick fix implemented six months
ago set us back a total of two weeks. Further investigation revealed that the
code causing this was committed, by someone that was no longer on the team, a
little over <strong>three years</strong> ago.</p>
<p>Any long-lived codebase that does not have regular code audits, will at one
point or another have parts that are not understood by the current team.</p>
<p>Unlike the previous method; the cost for this approach depends, among other
things, on the time the quick-fix spends as tech debt and the future features it
impacts.</p>
<p><strong>"An atomic habit is a regular practice or routine that is not only small and
easy to do but is also the source of incredible power; a component of the system
of compound growth. Bad habits repeat themselves again and again not because you
don't want to change, but because you have the wrong system for change" - Atomic
Habits by James Clear</strong></p>
<h3 id="prevention">Prevention</h3>
<p>Once the issue is resolved, the system in place must be revisited and improved
to reduce the probability of running into similar problems in the future.</p>
<p>Sustainable development habits must be put in place:</p>
<ul>
<li>Training and leveling-up existing staff resulting in higher code quality</li>
<li>Reducing the
<a href="https://en.wikipedia.org/wiki/Bus_factor#:~:text=The%20bus%20factor%20is%20a,truck%20number%2C%20or%20lorry%20factor." target="_blank" rel="noopener">bus factor</a>
by pairing and knowledge sharing through collaboration</li>
<li>Code audits when a team member leaves, walkthroughs when a new one joins</li>
</ul>
<p>To name a few, we go into greater detail in our
<a href="https://simplabs.com/playbook/">Playbook</a>!</p>
<p>The enemy of velocity is not quality but the absence of it.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/08/03/the-true-cost-of-a-quickfix</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038107</guid>
            <pubDate>Mon, 03 Aug 2020 14:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asimov's three laws of robotics are nonsense]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24037970">thread link</a>) | @wesleyabbey
<br/>
August 3, 2020 | https://www.wesleyabbey.io/post/asimovs-laws-are-nonsense | <a href="https://web.archive.org/web/*/https://www.wesleyabbey.io/post/asimovs-laws-are-nonsense">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jul 30, 2020</p><img src="https://www.wesleyabbey.io/images/hal.jpg" alt="Hal 9000"><h2>OpenAI, GPT-3, and Skynet</h2><p>Recently OpenAI released an API beta to interface with their products. They use the GPT-3 language model and from the demos it looks incredibly powerful.</p><p>GPT-3 has demonstrated it can write poetry, generate stories, code, build excel docs, and many other impressive tasks that’ll make you wonder if the robot apocalypse is around the corner. 🤖</p><p>These impressive results from GPT-3 are again bringing up conversations around general AI and the likelihood of us "summoning the demon". This is a problem we should be preparing for, but the likelihood of creating a general AI in the same intellectual league as a human is still incredibly far away. Nonetheless, people keep bringing up the dangers of AI, and along with that, how we can protect ourselves.</p><p>Asimov’s three laws of robotics are always brought up in these conversations as an answer to save us all from a "Skynet situation". These laws—while great for a science fiction novel—are nonsense. The one takeaway you should have from this: Don't take these laws seriously.</p><h2>Asimov’s three laws of robotics</h2><p>Let's break down these ridiculous rules.</p><p>The laws originally seen in <em>Runaround</em> and <em>I, Robot</em>:</p><p>– <strong>First Law</strong>. A robot may not injure a human being or, through inaction, allow a human being to come to harm.</p><p>– <strong>Second Law</strong>. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</p><p>– <strong>Third Law</strong>. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</p><p>Asimov eventually realized there were some obvious holes with these three alone, so he eventually added another law to precede the others</p><p>– <strong>Zeroth Law</strong>. A robot may not harm humanity, or, by inaction, allow humanity to come to harm.</p><p>It should be noted these laws <em>don't even work in the books.</em> Yikes. 🤦</p><h2>Loopholes: Why these laws don't work</h2><p><strong>How do we define "human"?</strong> Intuitively this is a straightforward question to answer. I'm human. You're human. Your family is all human. Your puppy isn't human, despite loving her more than other humans.</p><p>However, computers are dumb and in order to understand what a human is we need to strictly define the term. This step opens the door to a lot of weird quirks of philosophy that we otherwise rarely think about. It forces us to comprehensively solve ethics. Some examples:</p><p>Is an unborn fetus a human?
This has been a major issue for years and in order to define humans you have to clearly take a stance on this. If you can solve this one you’ll win a nobel prize.</p><p>What about someone who has died?
Most people might be inclined to say no, but then you’d end up an AI that would never attempt CPR. How long does someone have to be dead in order to count? Maybe you don’t have a time limit, but then you could end up with robots wandering earth trying to revive the dead. That doesn’t even sound like a terrible idea, until you realize it’s a recipe for zombies. 🧟</p><p><strong>You can’t program Asimov’s rules without taking a firm ethical stance on practically every issue</strong></p><h2>Should you fear the demon?</h2><p>Asimov’s laws can’t save us, but is a general AI even close to reality? Elon Musk compares creating a general AI to "summoning the demon". A little too alarmist for my taste, but I don’t think he’s wrong. The creation of an intelligent AI would be an existential threat to the human race.</p><p>The key to avoiding this is to ensure an AI’s goals are aligned with ours. If this alignment is done successfully it would bring about the greatest age of human prosperity in history. Any sort of misalignment of goals could result in our new robot-zombie world. This is not as good a situation as it is a great plotline for a new Terminator movie.</p><h2>Conclusion</h2><p>I love Asimov’s books, especially the <em>Foundation</em> series. But his laws are nonsense, filled with loopholes, and won’t help with a robot uprising.</p><p>I don’t have fears of AI becoming an issue anytime soon, but it’s something everyone should be thinking about to make sure we’re prepared. Until then Asimov’s laws should only be talked about in your book club discussions.</p><hr><div><p><img src="https://www.wesleyabbey.io/images/profile.jpg" alt="A handsome man."></p><p>I'm Wesley. I live in Boston and work at Wonderment. Follow me<!-- --> <a href="https://www.twitter.com/wesleyabbey">Twitter</a>.</p></div><a href="https://www.wesleyabbey.io/">Go back to home</a></div></div>]]>
            </description>
            <link>https://www.wesleyabbey.io/post/asimovs-laws-are-nonsense</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037970</guid>
            <pubDate>Mon, 03 Aug 2020 14:10:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email got us $5k in AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24037963">thread link</a>) | @CoreSet
<br/>
August 3, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037963</guid>
            <pubDate>Mon, 03 Aug 2020 14:10:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Rust: Mindsets and Expectations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037945">thread link</a>) | @steveklabnik
<br/>
August 3, 2020 | https://ferrous-systems.com/blog/mindsets-and-expectations/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/mindsets-and-expectations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We often hear that Rust is a language that is too complex and too difficult to learn. While, yes, the language <em>is</em> complex, we have identified some existing mindsets and expectations that serve as obstacles to the learning process. Let's discuss these obstacles and how we can alleviate them in our first post on <a href="https://ferrous-systems.com/blog/learning-and-teaching-rust/">learning Rust</a>.</p>

<h2 id="comparing-rust-to-other-languages">Comparing Rust to other languages</h2>

<p>When you learn your first programming language, it's very likely that you'll hear this observation:</p>

<blockquote>
  <p>“If you know one programming language, you know them all.”</p>
</blockquote>

<p>This statement makes an interesting point, but it is a faulty assumption. It is also more applicable for some sets of languages than it is for others. For instance, it does not take into account which language(s) you know and which one(s) you are learning.</p>

<p>While most languages share a common set of concepts (e.g., variables, conditionals, iteration, data typing, and functions), they may diverge widely beyond the realm of this common ground. Some languages are more divergent than others.</p>

<p>Not only do we have the faulty assumption that knowing one language allows you to "know them all", we also live with the widespread phenomenon of engineers' devotion to a single language. Oftentimes, these engineers consider their favorite languages to be universally superior to others.</p>

<p>With the coupling of these two problems, we see the following patterns emerge:</p>

<ul>
  <li>The people who struggle the most are the ones who are already experts in other languages (even the languages that feel similar to Rust, like C, C++, or Go).</li>
  <li>People often attempt to implement things in Rust in a way that is idiomatic in a different language, even if that other language has significantly different scope and behavior (e.g., Python or JavaScript).</li>
  <li>People often attempt to implement a relatively complex challenge <em>before</em> they have grasped core Rust concepts (e.g., attempting to use or modify existing libraries, or attempting to re-write a script or large-scale program).</li>
</ul>

<p>While these learning strategies and approaches are not invalid, they only take you so far. And without immediate successes, it can be very difficult to motivate yourself to continue. In short, <a href="http://nischalshrestha.me/docs/cross_language_interference.pdf">your attachment to another language can serve to <em>interfere</em> with learning Rust</a>.</p>

<p>Unsurprisingly, the concepts that are unique to Rust are what cause the most pain during the learning process (e.g., <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">Ownership and Borrowing</a> and <a href="https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html">Lifetimes</a>).</p>

<h2 id="how-to-learn-rust---effectively">How to learn Rust - effectively</h2>

<p>In tandem with the patterns we have mentioned above: <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular">people in the industry are fascinated with Rust</a> and what Rust aims to accomplish, but they hesitate to learn it when they hear rumors about how difficult it is. Thus, they don’t try.</p>

<p>Conversely, we've observed some promising patterns with the folks we've spoken to - folks who have had success learning Rust (either from us, or from the internet at large).</p>

<p>Here's what they tend to have in common:</p>

<ul>
  <li>They began their learning process by spending time with Rust's core concepts.</li>
  <li>They had a mentor or trainer who could help them conceptualize important parts of the language.</li>
  <li>They started small, building on successful projects and slowly increasing their scope.</li>
  <li>They were new to programming, or they came from a significantly different domain; thus, they didn't have expectations for how Rust would compare to other languages.</li>
</ul>

<hr>

<h3 id="three-things">Three things</h3>

<p>Learning Rust can and should be an enjoyable and effective experience! Based on the patterns we've observed, we suggest that you keep these three things in mind.</p>

<h4 id="learn-how-to-walk-before-you-try-to-run">Learn how to walk before you try to run.</h4>

<p>As we've mentioned, an experienced programmer may attempt to implement a relatively complex challenge before addressing core Rust concepts. This is not surprising: it's reasonable for you to expect to hit the ground running, especially if you work as a software developer or you write programs for fun.</p>

<p>By the same token, it's likely that you're able to dedicate only a limited amount of time to learning Rust. Are you learning Rust in your free time, or evaluating it for work? For whatever reason, you might try and learn as much as possible, as quickly as possible.</p>

<p>As such, we know that you might find it very frustrating to slow down and take tiny steps - instead of running a fast sprint or marathon. Nonetheless: take heart! Once you have developed an understanding of core concepts and fundamentals, you will take bigger steps and move on to complex projects with more ease and grace.</p>

<h4 id="appreciate-the-divergence">Appreciate the divergence.</h4>

<p><a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing completeness</a> is a "thing", but some programming languages are more suitable for certain tasks than others. Appreciate these different languages as the tools they are, with the specific features they offer and the things they do particularly effectively. Perhaps your task is to open a can of soup: you could certainly use a chainsaw to do this, but wouldn't you prefer a different tool?</p>

<p>The process of identifying the similarities between languages: this is only the <em>beginning</em> of a programmer's journey outside of their comfort zone. It is only the <em>beginning</em> of their discovery of the kind of tool they hold in their hands, and the kinds of problems that it is meant to solve.</p>

<p>The <em>goal</em> of the journey is to recognize and master the differences between tools. There would be no point in learning other languages, if they <em>really</em> were all the same!</p>

<h4 id="practice-patience">Practice patience.</h4>

<p>In the big picture, Rust is a very young language and has undergone a lot of changes in the last several years. Indeed, many of its features have grown less complicated since the early days of its existence. Rumors have persisted in regards to how hard it is to learn Rust, but it's very likely that <strong>these rumors are outdated and refer to a version of the language that no longer exists</strong>.</p>

<p>Throughout this post, we have reiterated the fact that <em>time</em> is inherent to the process of learning Rust. We refer to the fact that Rust is under <em>active development</em>, yes, but more importantly: we refer to the <em>patience</em> that we have noticed in folks who have succeeded in their journey. Give some time to your learning process, and you'll see that core concepts like <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">Ownership and Borrowing</a> deliver joy: they make it easy and comfortable to write programs that are <a href="https://en.wikipedia.org/wiki/Memory_safety">memory-safe</a>!</p>

<h2 id="stay-tuned-">Stay tuned …</h2>

<p>In the next part of this series, we will discuss one of Rust's unique philosophies: its aim to be <em>practical</em>. This is helpful not only in production, but also in the process of learning the language.</p>

<p>We hope you will read onwards! In the meantime, please consider signing up for our <a href="http://eepurl.com/gYWZKr">newsletter</a> or enlisting us as <a href="https://ferrous-systems.com/training">trainers</a> for your team.</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/mindsets-and-expectations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037945</guid>
            <pubDate>Mon, 03 Aug 2020 14:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Futures Market Making Bot]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037852">thread link</a>) | @Tinyyy
<br/>
August 3, 2020 | https://tianyi.io/post/chicago1/ | <a href="https://web.archive.org/web/*/https://tianyi.io/post/chicago1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Back in April, I participated in the UChicago Midwest Trading Competition with a couple of friends, and we ended up winning 2 out of 3 cases and the overall competition. So I’ve procrastinated on writing this blog post for 3 months, but I needed to get this out before I start working at a trading firm in a few weeks. This is the first part in (hopefully) a series of my favorite trading cases.</p>
<p>First, let me take you through how we tackled one of my favorite cases, building a futures market making bot on the Chicago Electricity Futures Market.</p>
<h2 id="the-case">The Case</h2>
<p>You are a market maker on the Chicago Electricity Futures Market. Real electricity trades daily between consumers and producers on the Chicago Electricity Spot Market, but the futures market is where traders bet on the price of electricity in the future. For instance, an electricity producer could sell 10 MWh of December futures to lock in the price of their electricity in December, thus hedging against the price of electricity. There are 4 futures contracts which expire on the last day of June, August, October and December. These future contracts are cash-settled, so they settle to the current spot price of electricity upon expiry.</p>
<p>Here’s how the electricity spot market works. Chicago produces electricity in 3 ways: Natural Gas generators ($2/MWh), coal generators ($3/MWh), and peaker plants. Electricity is consumed in that order, first natural gas, then coal and finally the peaker plants. Each year, the city starts out with fresh capacity of natural gas (around 1300MWh) and coal (around 450MWh), and moves onto the next source once the previous is exhausted. Peaker plants are special - they start at $3.001/MWh and do not run out, but each extra MWh produced costs $.001 more than the previous. This is what the price/consumption graph looks like.</p>
<p><img src="https://tianyi.io/price_consumption.png" alt=""></p>
<p>Each day, consumers purchase a random amount of electricity. Each day, you also know how much they used the previous day before you start trading. Note that you cannot buy or sell electricity on the spot market itself, you can only observe it.</p>
<p>As a market maker (MM), your job is to facilitate trading of futures contracts by reducing the spread in the market, which lower costs of transactions for traders. Take a market with bids for $1.50 and offers at $2.00. A ‘fair’ price of the contract would be $1.75, the mid price. However, the $.50 spread between the bid and offer makes it impossible to trade at the fair price. You (a MM) could come in and bid for $1.60 and offer at $1.90, decreasing the spread from $.50 to $.30. Someone who buys a stock pays $1.90 for it instead of $2.00, saving $.10, while you make the difference between $1.90 and the ‘fair’ mid price of $1.75. If someone else then sells a contract to you at $1.60, you have made a clean profit of $.30 without a resulting position in the contract, and everyone’s happy. But it’s not that simple: If the contract price rises to $2.00 after your sale, then you have made a loss of $.10. Also, another market maker could come into the market to bid for $1.70 and offer at $1.80, taking away your profits.</p>
<p>To make money market making, you have to be smart - know the value of the contract by predicting the price of electricity in the future. You also need to be aggressive - provide your best price to the market to make more profitable trades. Therefore, a successful bot requires 3 components: a good guess for the ‘fair’ price of the contract, a bot which trades aggressively but minimizes risk taking, and a way to augment the dumb bot with human intuition. I will discuss each of these parts below.</p>
<h2 id="whats-our-fair">What’s our fair?</h2>
<p>We first try to compute our ‘fair’, a prediction of the price of the 4 future contracts. Let’s do this in a Jupyter Notebook!</p>

<h2 id="execution-matters">Execution matters</h2>
<p>During the competition, all teams have a position limit of 1000 lots in each contract. This means that you are not allowed to be long or short more than 1000 lots of each contract. In the real world, market makers are similarly limited by the amount of risk they can take with their capital. Teams are effectively limited in the amount of trades they can make, so no one can dominate all of the trades in the market.
<img src="https://tianyi.io/case1pnl.png" alt="">
This is the profit and loss (pnl) chart of one of the rounds. How did we (rice-berkeley-mit) manage to make more profit than the next 2 teams combined? Ultimately, I think most of our edge came from how we traded more aggressively and managed our position limits more intelligently, such that our trading volume was multiples of what other teams did.</p>
<p>In this section, I want to break down our market making strategy by building up pieces of our strategy from a naive market making bot. We’ll discuss various test cases of market situations which a naive bot fails on, and strategies our bot used to profit from.</p>
<h4 id="the-naive-market-making-bot">The naive market making bot</h4>
<p>A naive MM bot takes in a <code>fair</code> as input, and asks for an <code>edge</code> around this fair. A <code>size</code> variable For instance, <code>fair</code> = $3.50, <code>edge</code> = $.10, <code>size</code> = 100. At each time interval, the bot places a bid into the market for 100 lots for $3.40, and places an ask for 100 lots at $3.60. Essentially, the MM is asking for an edge, or expected profit, of $.10 for each trade that it makes.</p>
<h4 id="case-1-the-informed-customer">Case 1: The informed customer</h4>
<p>A trader enters the market with information that the fair price is $3.70. (We still think fair = $3.50.) For ten successive days, the traderbuys 100 lots from us at $3.60. After the contract expires at $3.70, we have made a loss of $.10 * 1000 = $100. Could we have done better? Should we have sold the last 100 lots to the trader at $3.60, despite being short 900 lots already?</p>
<p>We could be more averse to taking on large, unbalanced positions, and this can be represented by the <code>fade</code> parameter. Let <code>fade</code> = $.02. That means for every 100 lots of position we take, we will augment our fair price by $.02. After selling 500 lots (thus short 500), our new fair is $3.50 + $.10 = $3.60. Our new market is $3.50 at $3.70. The trader will stop buying from us because he will not make a profit anymore. With fading, we ended up selling 500 stocks at an average price of $3.65, making a loss of $25, a big improvement.</p>
<h4 id="case-2-competing-with-other-market-makers">Case 2: Competing with other market makers</h4>
<p>It’s nice to be able to make a $.10 edge on each trade, but with 15 other market makers in the market, you won’t get to make any trades. So let’s reduce our edge to $.05. What happens in situations where there are no other market makers quoting in the market? Should you be satisfied with only $.05 in edge?</p>
<p>This is where we have to start considering the action of other market participants. We look at the book, a collection of all bids and asks on the market (and their respective sizes) to know what other traders are doing. We introduce the <code>slack</code> parameter, which represents flexibility in our edge. Say <code>slack</code> = $.10. Then, we vary our edge from $.05 to $.15 depending on market conditions. If there are no other MMs on the market, we would present our bids and asks with an edge of $.15, so $3.35 at $3.65 in the above example. If there is a competing bid of $3.40, then we will ‘penny’ that bid by changing our bid to $3.41. By improving our price by a penny, we ensured that any customer trade will be executed with us first. This pennying mechanism ensures that we make the most trades possible, while making the most from each trade. This is one of the biggest differentiators you can implement in trading competitions, as it lets you trade significantly more trades. There are some intricacies you have to pay attention to, such as making sure that we remove our own orders from what’s reported in the market feed. This is crucial in preventing our bot from bidding against itself.</p>
<h4 id="case-3-building-scales">Case 3: Building scales</h4>
<p>An uninformed customer comes into the market and buys up all of the offers on the market, and still wants to buy more. Because you don’t have more orders on the market, you missed out on selling to the customer at a great price. We can avoid this problem by building scales - multiple levels of bids and offers at increasing edges. For instance, we can offer 100 lots at $3.60, $3.80, $4.00, $4.20 etc. Most of the time, these extra orders will not be traded against, but due to the immaturity of our competition market, we get to trade at $3.80 or $4.00 with reasonable frequency and end up making a massive EV from the trade.</p>
<p>That’s basically how our bot traded. These strategies have insane benefit for their implementation complexity, but most other competitors stopped at case 1 or case 2. Tuning the parameters for <code>edge</code>, <code>fade</code>, <code>size</code> and <code>slack</code> is also crucial in maximizing pnl. While we can tune these on the provided test exchange, these may not work on the real competition due to more competition, so we need the flexibility to tune parameters during live trading.</p>
<h2 id="day-of-the-competition">Day of the competition</h2>
<p>We built a monitoring interface to tune parameters during live trading. The column titles are futures ticker | our bid size | our bid price | fair | our ask price | our ask size | position change in last tick | current position.</p>
<video controls="" preload="auto" width="100%">
    <source src="https://tianyi.io/post/chicago1/TradeUI.mp4" type="video/mp4" }}="">
  <p>Your browser doesn't support embedded videos, but don't worry, you can <a href="https://tianyi.io/post/chicago1/TradeUI.mp4">download it</a> and watch it with your favorite video player!</p>
</video>
<p>During live trading, we mainly focused on our position change and current position. If our trading volume decreases, then we can decrease our edge appropriately to to gain more volume. If our position becomes too imbalanced and does not revert quickly, we can increase our fade to revert our position quickly.</p>
<p>To dynamically change our trading parameters (and any other part of the bot), we used <code>exec</code> to read an execute an arbitrary <code>params.py</code> file. Here’s what <code>params.py</code> looks like.</p>
<pre><code>self.max_pos = 950
self.params = {}
self.params['EFM'] = {
        "edge": .005, # One sided edge from fair
        "fade": .005, # Fade per 100 delta
        "size": 100, # Size of trade
        "edge_slack": .10 # edge to ask for beyond min edge
        }
otherparam = {
        "edge": .002,
        "fade": .001,
        "size": 100,
       …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tianyi.io/post/chicago1/">https://tianyi.io/post/chicago1/</a></em></p>]]>
            </description>
            <link>https://tianyi.io/post/chicago1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037852</guid>
            <pubDate>Mon, 03 Aug 2020 14:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An API Worm in the Making: Thousands of Secrets Found in Open S3 Buckets]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037824">thread link</a>) | @riverdroid
<br/>
August 3, 2020 | https://trufflesecurity.com/blog/an-s3-bucket-worm-in-the-making-thousands-of-secrets-found-in-open-s3-buckets | <a href="https://web.archive.org/web/*/https://trufflesecurity.com/blog/an-s3-bucket-worm-in-the-making-thousands-of-secrets-found-in-open-s3-buckets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f1dfa987982b27e05048231"><div><div><div data-block-type="2" id="block-339c89ed1c6231d582d5"><div><h2>Background</h2><p>S3 buckets are a common place to store files in AWS. These buckets have a feature that allows you to make your files readable by anyone on the internet without authentication. If the content is meant for public consumption, like storing HTML, CSS, and JS assets for a website, this feature can be really useful, but it’s a double edged sword. Frequently, these files contain sensitive information, which has caused several high profile security incidents, including:</p><p>	<a href="https://www.darkreading.com/cloud/twilio-security-incident-shows-danger-of-misconfigured-s3-buckets/d/d-id/1338447">A recent incident with Twilio</a></p><p>	<a href="https://www.darkreading.com/cloud/dow-jones-data-leak-results-from-amazon-aws-configuration-error/d/d-id/1329382?">The Dow Jones data breach</a></p><p>	<a href="https://www.theverge.com/2017/7/12/15962520/verizon-nice-systems-data-breach-exposes-millions-customer-records">A Verizon Wireless data breach</a></p><p>Typically the data exposed is the end of the reported story, but we’ve found it’s often not the end of the security story.</p><div><p>Since we recently added S3 support to TruffleHog, we thought scanning the set of publicly exposed buckets for credentials would be a great way to get ahead of potential security incidents, and we ended up finding thousands of distinct secrets spanning hundreds of customers.</p></div><h2>Methodology</h2><p>The first thing we needed to do is compile a list of open S3 buckets. Luckily, the bucket names are globally unique and can be specified by subdomain. For example, if a bucket was named “trufflehogbucket”, the files could be accessed at: <a href="https://trufflehogbucket.s3.amazonaws.com/">https://trufflehogbucket.s3.amazonaws.com/filename</a>. Because DNS traffic is typically unencrypted, many bucket names are collected by DNS taps. Some vendors like RiskIQ expose this data via their PassiveTotal API.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596429866183_13322"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596429913887-4P2FBJA6V5PO6O71ZUX5/ke17ZwdGBToddI8pDm48kAtzd4_tRDn4oEvsZxuZpg5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIiAqzax9eIwSOQYHm0QNZYad2LT5PqOp1uX5lxsgTuOY/passivetotal.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596429913887-4P2FBJA6V5PO6O71ZUX5/ke17ZwdGBToddI8pDm48kAtzd4_tRDn4oEvsZxuZpg5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIiAqzax9eIwSOQYHm0QNZYad2LT5PqOp1uX5lxsgTuOY/passivetotal.png" data-image-dimensions="998x298" data-image-focal-point="0.5,0.5" alt="passivetotal.png" src="https://trufflesecurity.com/blog/passivetotal.png"></p>
          
            </div>
          

        </div>

        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596429866183_13612"><div><div><p>Other tools like <a href="https://buckets.grayhatwarfare.com/">grayhatwarfare</a> take a different approach and generate large lists of likely bucket names and make requests to the S3 API to determine if the bucket exists and contains publicly exposed files.&nbsp; Using these, and other techniques, we built our initial list of buckets. Scanning all of the exposed data quickly grew impractical, so we needed a way to narrow the list to buckets and files likely to contain secrets. Fortunately, greyhatwarfare’s API also allows you to search the names of files, so we searched for common names like ‘.credentials’, ‘.env’, etc. and only scanned buckets containing matching files. </p></div><h2>Results</h2><p>After scanning approximately <strong>4000 </strong>buckets containing .env files and .credentials files, we found a file containing secrets had an average of <strong>2.5</strong> secrets in it, with some as high as <strong>10+</strong> secrets in a file.</p></div></div><div data-aspect-ratio="69.04276985743381" data-block-type="5" id="block-yui_3_17_2_1_1595803338067_8893"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804379053-17W7XAZZWUEJ5ZVF4YVD/ke17ZwdGBToddI8pDm48kFG0s4xuYUdjgtExBTCGye57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeH86pV5qdu_QcF6MMBiMw2LdYE0iZMzbMknYk-K-sq2m4bjm9DAHF2kOsIZRJKXnA/image1.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804379053-17W7XAZZWUEJ5ZVF4YVD/ke17ZwdGBToddI8pDm48kFG0s4xuYUdjgtExBTCGye57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeH86pV5qdu_QcF6MMBiMw2LdYE0iZMzbMknYk-K-sq2m4bjm9DAHF2kOsIZRJKXnA/image1.png" data-image-dimensions="1999x1392" data-image-focal-point="1.0,0.5" alt="Secret results" data-load="false" data-image-id="5f1e0adad632ed089ca9002b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804379053-17W7XAZZWUEJ5ZVF4YVD/ke17ZwdGBToddI8pDm48kFG0s4xuYUdjgtExBTCGye57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeH86pV5qdu_QcF6MMBiMw2LdYE0iZMzbMknYk-K-sq2m4bjm9DAHF2kOsIZRJKXnA/image1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><em>Secret results</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595803338067_12536"><div><p>We also found a wide variety of credential types, including:<br></p><ul data-rte-list="default"><li><p>AWS Keys</p></li><li><p>GCP service accounts</p></li><li><p>Azure Blob Storage connection strings</p></li><li><p>Coinbase API keys</p></li><li><p>Twilio&nbsp; API keys</p></li><li><p>Mailgun API keys</p></li><li><p>RDS passwords</p></li><li><p>Sendgrid credentials</p></li><li><p>Pusher credentials</p></li><li><p>MSSQL passwords</p></li><li><p>Mailtrap credentials</p></li><li><p>Google OAuth credentials</p></li><li><p>Twitter OAuth credentials</p></li><li><p>Linked in OAuth credentials</p></li><li><p>Google Maps API keys</p></li><li><p>Segment API keys</p></li><li><p>Sauce API keys</p></li><li><p>Hosted MongoDB credentials</p></li><li><p>Firebase credentials</p></li><li><p>Stripe credentials</p></li><li><p>Rollbar credentials</p></li><li><p>Twilio credentials</p></li><li><p>Amplitude credentials</p></li><li><p>Mailjet credentials</p></li><li><p>SMS partner credentials</p></li><li><p>Dropbox credentials</p></li><li><p>Yousign credentials</p></li><li><p>PayPal credentials</p></li><li><p>Mandrill credentials</p></li><li><p>Zendesk credentials</p></li><li><p>Hosted message queue connection strings</p></li><li><p>Razor pay credentials</p></li><li><p>Text local credentials</p></li><li><p>Application signing secrets</p></li><li><p>JWT signing secrets</p></li></ul><h2>Impact Magnifier: Wormability</h2><p>It’s clear from the surrounding context, many of these credentials unlock more buckets that are otherwise authenticated. Here are two examples</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1596414632472_20999"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416490768-IOR56T9F2DYXMRJE17DO/ke17ZwdGBToddI8pDm48kLnYvqNey1HXSFLD5zy4F1RZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwsZWaDS6n0iIPm8vDtGXjpQot4bqPSk5YnQBKf_GjAFJCO4BOGSVYxYf3dmq3pDZA/buckettobucket.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416490768-IOR56T9F2DYXMRJE17DO/ke17ZwdGBToddI8pDm48kLnYvqNey1HXSFLD5zy4F1RZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwsZWaDS6n0iIPm8vDtGXjpQot4bqPSk5YnQBKf_GjAFJCO4BOGSVYxYf3dmq3pDZA/buckettobucket.png" data-image-dimensions="652x212" data-image-focal-point="0.5,0.5" alt="Leaked credentials leading to more buckets" data-load="false" data-image-id="5f2761ea9526e63b9bb2d7c8" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416490768-IOR56T9F2DYXMRJE17DO/ke17ZwdGBToddI8pDm48kLnYvqNey1HXSFLD5zy4F1RZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwsZWaDS6n0iIPm8vDtGXjpQot4bqPSk5YnQBKf_GjAFJCO4BOGSVYxYf3dmq3pDZA/buckettobucket.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><em>Leaked credentials leading to more buckets</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1596414632472_22709"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416522780-T6WEEH7D2FRNHG9XLRO2/ke17ZwdGBToddI8pDm48kNPjAubpr7KgVwOfaED_LtgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKct2YDnnzBiajQwDWdJzLvoQhjkPV8eve94sAIkIQmA2eqLHRXZg7OmDTjEvRvYlWY/buckettobucket2.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416522780-T6WEEH7D2FRNHG9XLRO2/ke17ZwdGBToddI8pDm48kNPjAubpr7KgVwOfaED_LtgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKct2YDnnzBiajQwDWdJzLvoQhjkPV8eve94sAIkIQmA2eqLHRXZg7OmDTjEvRvYlWY/buckettobucket2.png" data-image-dimensions="1017x698" data-image-focal-point="0.5,0.5" alt="Leaked credentials leading to more buckets" data-load="false" data-image-id="5f27620a0aec8e324016eea2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596416522780-T6WEEH7D2FRNHG9XLRO2/ke17ZwdGBToddI8pDm48kNPjAubpr7KgVwOfaED_LtgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKct2YDnnzBiajQwDWdJzLvoQhjkPV8eve94sAIkIQmA2eqLHRXZg7OmDTjEvRvYlWY/buckettobucket2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><em>Leaked credentials leading to more buckets</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596414632472_21288"><p><br>It’s probably fair to assume authenticated buckets contain more secrets than unauthenticated ones, due to the implied higher security bar authentication provides. This means attackers can likely use the first round of buckets to find keys that unlock an additional round of buckets and expose more keys, which could expose more buckets, etc. We did not use any of these keys or explore this possibility for obvious reasons, but this makes this type of attack “wormable”, ie, one bucket can lead to another bucket, and so on, magnifying the impact of the leak.</p></div><div data-aspect-ratio="54.214285714285715" data-block-type="5" id="block-yui_3_17_2_1_1595803338067_18554"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804828766-U4GKCAMXMWZJL9BI8J07/ke17ZwdGBToddI8pDm48kH0p3X6r7O-N1_7qr6rOTNMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2du3bmg_5b7GtNDVkB7ssAtF_7iiPjJWIZKU_5xhPxJNSCjLISwBs8eEdxAxTptZAUg/wormable.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804828766-U4GKCAMXMWZJL9BI8J07/ke17ZwdGBToddI8pDm48kH0p3X6r7O-N1_7qr6rOTNMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2du3bmg_5b7GtNDVkB7ssAtF_7iiPjJWIZKU_5xhPxJNSCjLISwBs8eEdxAxTptZAUg/wormable.png" data-image-dimensions="1552x968" data-image-focal-point="0.5,0.5" alt="Worming through S3 buckets" data-load="false" data-image-id="5f1e0c9cd0dcdd1a8ef35031" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1595804828766-U4GKCAMXMWZJL9BI8J07/ke17ZwdGBToddI8pDm48kH0p3X6r7O-N1_7qr6rOTNMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2du3bmg_5b7GtNDVkB7ssAtF_7iiPjJWIZKU_5xhPxJNSCjLISwBs8eEdxAxTptZAUg/wormable.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><em>Worming through S3 buckets</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595803338067_18843"><div><p>What’s worse is some of these keys led to other large data stores that may have access to keys, such as Github API keys, and GCP Storage API keys. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596414632472_8977"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596415447471-M2GTZY36E8LERA7VCYJX/ke17ZwdGBToddI8pDm48kBU8zDPOUeHBycMSzqBxxfNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAc4ufQSiJ13bCjtt9hgAYGEMpwd9V9-n2MIRbC2y1WU/multiworm.png" data-image="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596415447471-M2GTZY36E8LERA7VCYJX/ke17ZwdGBToddI8pDm48kBU8zDPOUeHBycMSzqBxxfNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAc4ufQSiJ13bCjtt9hgAYGEMpwd9V9-n2MIRbC2y1WU/multiworm.png" data-image-dimensions="811x870" data-image-focal-point="0.5,0.5" alt="Worming through multiple providers" data-load="false" data-image-id="5f275dd7062baa1f2b0c1073" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e3b3988ebecf77054659302/1596415447471-M2GTZY36E8LERA7VCYJX/ke17ZwdGBToddI8pDm48kBU8zDPOUeHBycMSzqBxxfNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAc4ufQSiJ13bCjtt9hgAYGEMpwd9V9-n2MIRbC2y1WU/multiworm.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><em>Worming through multiple providers</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596414632472_9267"><div><h2>Next Steps</h2><p>Naturally at this point we needed to disclose what we found to the affected companies. This proved challenging at times because often buckets don’t have a lot of information connecting them with the bucket creator. We did hundreds of disclosures, and partnered with providers in some cases to get keys revoked for buckets where we couldn’t identify owners.&nbsp; Disclosures ranged from dozens of fortune 500 companies, to NGOs and small startups.&nbsp;</p><p>At any scale, it’s a good idea to have all of your buckets scanned routinely to prevent catastrophe.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://trufflesecurity.com/blog/an-s3-bucket-worm-in-the-making-thousands-of-secrets-found-in-open-s3-buckets</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037824</guid>
            <pubDate>Mon, 03 Aug 2020 13:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross-Platform Language Design (Scala.js) PhD Thesis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037774">thread link</a>) | @mpweiher
<br/>
August 3, 2020 | http://lampwww.epfl.ch/~doeraene/thesis/ | <a href="https://web.archive.org/web/*/http://lampwww.epfl.ch/~doeraene/thesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>Sébastien Doeraene, Ph.D. thesis</p>

<p><a title="Cross-Platform Language Design - Sébastien Doeraene - Ph.D. thesis" href="http://lampwww.epfl.ch/~doeraene/thesis/doeraene-thesis-2018-cross-platform-language-design.pdf">Full text</a></p>

<p>This is the thesis behind <a title="Scala.js" href="https://www.scala-js.org/">Scala.js</a>, the dialect of Scala that compiles to JavaScript.</p>

<h2>Abstract</h2>

<p>
Programming languages are increasingly compiled to multiple runtimes, each featuring their own rich structures such as their object model.
Furthermore, they need to interact with other languages targeting said runtimes.
A language targeting only one runtime can be designed to tailor its semantics to those of that runtime, for easy interoperability with other languages.
However, in a language targeting multiple runtimes with differing semantics, it is difficult to cater to each of them while retaining a common behavior across runtimes.
We call <em>cross-platform language</em> a language that aims at being both <em>portable</em> across platforms and <em>interoperable</em> with each target platform.
Portability is the ability for a program or a library to cross-compile for multiple platforms, and behave the same way on all of them.
Interoperability is the ability to communicate with other languages on the same platform.
While many cross-compiling languages focus on one of these two properties—only adding support for the other one as an afterthought—, languages that are designed from the ground up to support both are rare.
</p>
<p>
In this thesis, we present the design of Scala.js, the dialect of Scala targeting the JavaScript platform, which turned Scala into a cross-platform language.
On the one hand, Scala programs can be cross-compiled for the JVM and JavaScript with portable semantics.
On the other hand, whereas Scala/JVM interoperates with Java, Scala.js interoperates with JavaScript, allowing to use any JavaScript library.
Along the dissertation, we give insights that can be transferred to the design of other cross-platform languages, although with a bias towards those targeting the JVM and JavaScript.
</p>
<p>
The first and most obvious challenge is to reconcile the static nature of Scala's object model with JavaScript's dynamic one.
Besides the ability to mutate a class hierarchy at run-time in JavaScript, there are fundamental differences between the two models, in particular the difference between compile-time overloading and run-time overloading.
We discuss how such semantic mismatches can live in harmony within the language.
</p>
<p>
The second challenge is to obtain good performance from a language where interoperability with a dynamic and unknown part of the program is pervasive.
To that end, we design and specify an intermediate representation (IR) with first-class support for dynamically typed interoperability features in addition to statically typed JVM-style operations.
Despite its tight integration with the open world of JavaScript, most of the IR can be considered as a closed world where advanced whole-program optimizations can be performed.
The performance of the overall system is evaluated and shown to be competitive with hand-written JavaScript, and even with Scala/JVM in some cases.
</p>
<p>Keywords: interoperability, portability, language design, cross-platform, performance, Scala, JavaScript.</p>



</div>]]>
            </description>
            <link>http://lampwww.epfl.ch/~doeraene/thesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037774</guid>
            <pubDate>Mon, 03 Aug 2020 13:55:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Southwest Airlines Wins 2020 Award for Best Airline North America]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037737">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/southwest-airlines-wins-2020-tripadvisor-travelers-choice-awards-for-best-airline-north-america/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/southwest-airlines-wins-2020-tripadvisor-travelers-choice-awards-for-best-airline-north-america/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX.jpg" data-caption="Southwest Airlines Co. (NYSE: LUV) announced today that it was recognized by Tripadvisor as a winner of four awards in the 2020 Tripadvisor Travelers' Choice™ Awards for Airline

Photo: Southwest Airlines"><img width="696" height="557" src="https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-696x557.jpg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-696x557.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-300x240.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-1024x819.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-768x614.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-1068x854.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX-525x420.jpg 525w, https://kokpitherald.com/wp-content/uploads/2020/08/Southwest_Airlines_MAX.jpg 1200w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="Southwest_Airlines_MAX"></a><figcaption>Southwest Airlines Co. (NYSE: LUV) announced today that it was recognized by Tripadvisor as a winner of four awards in the 2020 Tripadvisor Travelers' Choice™ Awards for Airline

Photo: Southwest Airlines</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p><strong><a rel="noreferrer noopener" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=3728921449&amp;u=http%3A%2F%2Fwww.southwest.com%2F%3Fsrc%3DPRPRPRNTripadvisorTravelersChoice07282020&amp;a=Southwest+Airlines+Co." target="_blank">Southwest Airlines Co.</a></strong>&nbsp;(NYSE: LUV) announced today that it was recognized by Tripadvisor as a winner of four awards in the&nbsp;<a rel="noreferrer noopener" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=276206320&amp;u=https%3A%2F%2Fwww.tripadvisor.com%2FTravelersChoice-Airlines-cNorthAmerica&amp;a=2020+Tripadvisor+Travelers%27+Choice%E2%84%A2+Awards+for+Airlines" target="_blank">2020 Tripadvisor Travelers’ Choice™ Awards for Airlines.</a></p>



<p>Awards are based on a full year of Tripadvisor reviews. Award winners are known for consistently receiving great flyer feedback, placing them among travelers’ favorites around the globe.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p><strong>Southwest Airlines was recognized as:</strong></p>



<ul><li>Best <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">Airline</a> North America,</li><li>Best <a href="https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">Airline</a> United States,</li><li>Best Economy North America, and</li><li>Best Low Cost Airline North America</li></ul>



<p>“Awards such as these highlight our passion, which is to connect People to what’s important in their lives with low fares, world-renowned Hospitality, and Customer-friendly policies,” said&nbsp;<a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=1645157664&amp;u=https%3A%2F%2Fwww.swamedia.com%2Fpages%2Fryan_green&amp;a=Ryan+Green" target="_blank" rel="noreferrer noopener">Ryan Green</a>, Senior Vice President and Chief Marketing Officer at Southwest Airlines. “We thank each and every Customer for flying with us and their positive ratings, and we thank our Employees for continuing to put Heart into Southwest travel.”</p>



<p>“Winners of the 2020 Travelers’ Choice Awards should be proud of this distinguished recognition,” said Kanika Soni, Chief Commercial Officer at Tripadvisor. “Although it’s been a challenging year for travel and hospitality, we want to celebrate our partners’ achievements. Award winners are beloved for their exceptional service and quality. Not only are these winners well deserving, they are also a great source of inspiration for travelers as the world begins to venture out again.”</p>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-1024x395.jpg" alt="southwest airlines" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-1024x395.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-300x116.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-768x296.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-696x269.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-1068x412.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1-1089x420.jpg 1089w, https://kokpitherald.com/wp-content/uploads/2020/08/southwest_airlines_logo-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Awards are based on a full year of Tripadvisor reviews. Award winners are known for consistently receiving great flyer feedback, placing them among travelers’ favorites around the globe. Photo: Sothwest Airlines</figcaption></figure>



<h2><strong>ABOUT SOUTHWEST AIRLINES CO.</strong></h2>



<p>In its 50th year of service,&nbsp;Dallas-based<a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=2180769108&amp;u=http%3A%2F%2Fwww.southwest.com%2F%3Fsrc%3DPRPRPRNTripadvisorTravelersChoice07282020&amp;a=%C2%A0Southwest+Airlines+Co." target="_blank" rel="noreferrer noopener">&nbsp;<strong>Southwest Airlines Co.</strong></a>&nbsp;continues to differentiate itself from other air carriers with exemplary Customer Service delivered by more than 60,000 Employees to a Customer base topping 130 million passengers in 2019. Southwest became the nation’s largest domestic air carrier in 2003 and maintains that ranking based on the&nbsp;U.S.&nbsp;Department of Transportation’s most recent reporting of domestic originating passengers boarded. In peak travel seasons during 2019, Southwest operated more than 4,000 weekday departures among a network of 101 destinations in&nbsp;the United States&nbsp;and 10 additional countries. In early 2020, the carrier added service to&nbsp;Hilo, Hawaii, and&nbsp;Cozumel, Mexico&nbsp;for a total of 103 airports served.</p>



<p>The carrier issued its&nbsp;<strong><a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=224073431&amp;u=https%3A%2F%2Fwww.southwest.com%2Fpromise%2F&amp;a=Southwest%C2%AE+Promise" target="_blank" rel="noreferrer noopener">Southwest<sup>®&nbsp;</sup>Promise</a></strong>&nbsp;in May 2020 to highlight new and round-the-clock efforts to support its Customers and Employees wellbeing and comfort. Among the changes are enhanced cleaning efforts at airports and onboard aircraft, facemask requirements for Customers and Employees, and capping the number of passengers on every flight to allow middle seats to remain open through at least October 31, 2020. Additional details about the Southwest Promise are available at&nbsp;<strong><a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=3173224020&amp;u=https%3A%2F%2Fwww.southwest.com%2Fpromise%2F&amp;a=Southwest.com%2FPromise" target="_blank" rel="noreferrer noopener">Southwest.com/Promise</a></strong><strong>.</strong></p>



<p>Southwest coined&nbsp;<strong><a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=297278479&amp;u=http%3A%2F%2Fwww.transfarency.com%2F&amp;a=Transfarency" target="_blank" rel="noreferrer noopener">Transfarency</a></strong><sup>®</sup>&nbsp;to describe its purposed philosophy of treating Customers honestly and fairly, and low fares actually staying low. Southwest is the only major&nbsp;U.S.&nbsp;airline to offer bags fly free<sup>®</sup>&nbsp;to everyone (first and second checked pieces of luggage, size and weight limits apply, some carriers offer free checked bags on select routes or in qualified circumstances), and there are no change fees, though fare differences might apply.</p>



<p>Southwest is one of the most honored airlines in the world, known for a triple bottom line approach that contributes to the carrier’s performance and productivity, the importance of its People and the communities they serve, and an overall commitment to efficiency and the planet. Learn more about how the carrier gives back to communities across the world by visiting&nbsp;<strong><a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=3621956343&amp;u=https%3A%2F%2Fwww.southwest.com%2Fcitizenship%2F&amp;a=Southwest.com%2Fcitizenship.+" target="_blank" rel="noreferrer noopener">Southwest.com/citizenship.</a></strong></p>



<p>Book Southwest Airlines’ low fares online at&nbsp;<strong><a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2869562-1&amp;h=1283777760&amp;u=http%3A%2F%2Fwww.southwest.com%2F%3Fsrc%3DPRPRPRNTripadvisorTravelersChoice07282020&amp;a=Southwest.com" target="_blank" rel="noreferrer noopener">Southwest.com</a></strong>&nbsp;or by phone at 800-I-FLY-SWA.</p>





 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/southwest-airlines-wins-2020-tripadvisor-travelers-choice-awards-for-best-airline-north-america/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037737</guid>
            <pubDate>Mon, 03 Aug 2020 13:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Death of the City]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037685">thread link</a>) | @eplanit
<br/>
August 3, 2020 | https://www.politico.eu/article/the-death-of-the-city-coronavirus-towns-cities-retail-transport-pollution-economic-crisis | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/the-death-of-the-city-coronavirus-towns-cities-retail-transport-pollution-economic-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
							
							

							
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>Some 700 years ago, the Tuscan town of Siena was a burgeoning banking and proto-industrial powerhouse with over 50,000 inhabitants — a population surpassed only by medieval “mega-cities” like Paris, London and Milan.</p>
<p>But then, in 1348, just when the thriving city was in the prime of its golden age, Siena’s prosperity was brought to a sudden halt by the Black Death. In just a few years, the city lost 60 percent of its population and entered into a steep decline, falling into obscurity. It took until the 20th century for it to <a href="http://www.montana.edu/historybug/yersiniaessays/davis.html#:~:text=In%201348%2C%20the%20pestilence%20struck,population%20(Benedictow%2C%202004).&amp;text=Siena%20suffered%20immensely%20more%20than,Florence%20both%20culturally%20and%20economically." target="_blank">recover</a> its pre-pandemic size.</p>
<p>COVID-19 isn’t nearly as deadly as the medieval bubonic plague, but the social and economic upheaval it’s caused is already leaving physical marks on modern cities in Europe: Once-busy business districts have emptied out as people opt to work from home. Shops and restaurants have closed. Public transport has slowed down.</p>
<p>There’s also reason to believe this pandemic could have an even more lasting impact than its predecessors. For the first time since the earliest cities emerged in the Fertile Crescent some 6,000 years ago, concentrated urban centers no longer have a monopoly on the economic and cultural connections that make civilizations tick forward.</p>
<div id="attachment_1422402"><p><img aria-describedby="caption-attachment-1422402" src="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-714x476.jpg" alt="" width="714" height="476" srcset="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-714x476.jpg 714w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-300x200.jpg 300w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-1024x683.jpg 1024w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-768x512.jpg 768w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-1536x1024.jpg 1536w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-2048x1365.jpg 2048w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-1160x773.jpg 1160w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-380x253.jpg 380w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-171x114.jpg 171w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-390x260.jpg 390w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-1080x720.jpg 1080w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-333x222.jpg 333w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-1120x747.jpg 1120w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212672223-600x400.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1422402">The evening rush hour at London's Waterloo Underground station took on a very different appearance in May, as a nationwide lockdown kept most residents at home | Isabel Infantes/AFP via Getty Images</p></div>
<p>For many workers worried about the coronavirus — and employers looking to cut costs during the economic crisis that has followed — technologies like video conferencing, shared documents and instant messaging provide viable alternatives to high-rise office buildings.</p>
<p>Meanwhile, services like video streaming and social media and websites like Reddit and Twitter offer a taste of the cultural effervescence and community that has drawn so many to the big city over the centuries. You don't even need a bar or club to meet the love of your life: Apps like Tinder, Bumble or Grindr are happy to link you to a potential mate.</p>
<p>“This pandemic has the potential to really affect cities,” said Peter Clark, a professor of European urban history at the University of Helsinki.&nbsp;“If there isn’t a second wave, the changes may be far fewer than people are speculating. But if there is, we could see the European model of the ‘cultural city’ seriously affected.</p>
<p>“Because of deindustrialization, since the 1980s, we’ve had a shift to the service sector in order to maintain urban prosperity,” he added. “The pandemic poses a direct threat to that model.”</p>
<h3><strong>Ghost towns</strong></h3>
<p>There’s no question whether the pandemic has transformed working life.</p>
<p>In the early spring, as the coronavirus spread through Europe, government restrictions forced all but essential workers such as health and supermarket workers to work from home to keep new infections at bay. Industrial demand slowed or shut down completely as purchases of cars and other products collapsed.</p>
<p>Before the lockdowns, teleworking was not particularly common in most European countries.&nbsp;According to <a href="https://www.eurofound.europa.eu/data/percentage-of-workers-doing-telework-and-ict-based-mobile-work" target="_blank">data compiled by Eurofound</a>, just 11 percent of Germans and 8 percent of Italians “occasionally” worked remotely in 2015.</p>
<p>But as the crisis progressed, workers and businesses adjusted remarkably quickly to the new reality. Government, corporate and other meetings <a href="https://www.politico.eu/?p=1310870">shifted online</a>; classes were taught <a href="https://www.politico.eu/?p=1351286">virtually</a>; e-medicine and <a href="https://www.politico.eu/?p=1322367">virtual therapy</a> took off.</p>
<p>The question now is whether these new behaviors will stick — or whether most people will return to their offices as soon as they can.</p>
<div id="attachment_1422406"><p><img aria-describedby="caption-attachment-1422406" src="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-714x473.jpg" alt="" width="714" height="473" srcset="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-714x473.jpg 714w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-300x199.jpg 300w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-1024x679.jpg 1024w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-768x509.jpg 768w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-1536x1018.jpg 1536w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-2048x1358.jpg 2048w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-1160x769.jpg 1160w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-380x252.jpg 380w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-172x114.jpg 172w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-392x260.jpg 392w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-1086x720.jpg 1086w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-333x221.jpg 333w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-1120x743.jpg 1120w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1208882806-600x398.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1422406">An elementary school substitute teacher in Arlington, Virginia, switched from teaching in classrooms when teachers were absent to educating teachers on how best to connect with their students via digital platforms | Olivier Douliery/AFP via Getty Images</p></div>
<p>Stanford University economist Nicholas Bloom, an expert on teleworking, says that while it’s unrealistic to expect everyone to work from home indefinitely, between 50 percent and 60 percent of the population would be able to keep at it.</p>
<p>“A third of the working population — office workers, senior management — can telework 100 percent of the time. Another third — clothing designers, real estate agents, scientific researchers — can do it most of the time, but will sometimes need to be onsite. And another third cannot do it at all: Most of these people are lower-paid service-sector workers, but you also have higher-range jobs like those held by dentists, surgeons, pilots.”</p>
<p>Bloom says it’s still too early to tell how intense the impact of the pandemic will be, but that it’s unlikely that office workers will want to go back to business as usual, even if a cure or a vaccine is developed.</p>
<p>“The skyscrapers and office buildings in the city centers that used to be our most valued real estate have become places people avoid out of fear of infection,” Bloom said. “I don’t see people growing comfortable with packed subway trains and elevators, and firms aren't going to want to open and close every time there’s a wave.”</p>
<div id="attachment_1422416"><p><img aria-describedby="caption-attachment-1422416" src="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-714x475.jpg" alt="" width="714" height="475" srcset="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-714x475.jpg 714w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-300x200.jpg 300w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-1024x682.jpg 1024w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-768x511.jpg 768w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-1536x1022.jpg 1536w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-2048x1363.jpg 2048w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-1160x772.jpg 1160w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-380x253.jpg 380w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-171x114.jpg 171w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-391x260.jpg 391w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-1082x720.jpg 1082w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-333x222.jpg 333w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-1120x746.jpg 1120w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1209081464-600x399.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1422416">Chairs sit empty in the bright outdoor space of an office park in Crystal City, Virginia, just outside Washington, D.C. | Andrew Caballero-Reynolds/AFP via Getty Images</p></div>
<p>“It’s the fear of the virus that keeps people at home,” said Sven Smit, senior partner at McKinsey &amp; Company and co-chair of the McKinsey Global Institute. He added that while it was too early to be certain the shift would stick, “the tendency [for longer-term change] is there.”</p>
<p>Companies have already taken notice of the opportunities for cost-cutting. A <a href="https://www.credit-suisse.com/about-us-news/en/articles/media-releases/covid-19-impacts-on-commercial-property-202006.html" target="_blank">new&nbsp;report</a>&nbsp;from Credit Suisse indicates that office space rental income loss has “so far been limited.” At the same time, however, “executive boards — including those of large global corporations — have identified the latent potential to make savings and are already looking to reduce the amount of space they use.”</p>
<p>Commercial property investments fell by an average of 44 percent across Europe between the middle of March and the end of May, according to <a href="https://www.realestate.bnpparibas.com/covid-19-report-june-2020" target="_blank">figures</a>&nbsp;released by BNP Paribas Real Estate last month; the decline was especially notable in Ireland, where the Irish Times&nbsp;<a href="https://www.irishtimes.com/business/commercial-property/irish-commercial-property-deals-slump-most-in-eu-amid-covid-19-1.4286605" target="_blank">reported</a>&nbsp;that commercial property deals slumped by 79 percent during that period.</p>
<div id="attachment_1422394"><p><img aria-describedby="caption-attachment-1422394" src="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-714x476.jpg" alt="" width="714" height="476" srcset="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-714x476.jpg 714w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-300x200.jpg 300w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-1024x683.jpg 1024w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-768x512.jpg 768w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-1536x1024.jpg 1536w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-2048x1365.jpg 2048w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-1160x773.jpg 1160w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-380x253.jpg 380w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-171x114.jpg 171w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-390x260.jpg 390w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-1080x720.jpg 1080w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-333x222.jpg 333w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-1120x747.jpg 1120w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1212305864-600x400.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1422394">A conference room at Seattle's Rover.com headquarters sits empty, with employees working from home in March | John Moore/Getty Images</p></div>
<p>In a sign the trend is likely to continue, tech companies like<a href="https://www.theguardian.com/technology/2020/may/12/twitter-coronavirus-covid19-work-from-home" target="_blank"> Twitter</a> and <a href="https://blog.google/inside-google/working-google/working-from-home-and-office/" target="_blank">Google</a> have announced plans for their employees to continue working remotely, and a <a href="https://www.bloomberg.com/news/articles/2020-07-13/most-german-companies-say-work-from-home-should-be-here-to-stay" target="_blank">new&nbsp;survey</a> conducted by Germany’s Ifo Institute shows that 54 percent of businesses want to make greater use of home offices henceforth.</p>
<p>Facebook CEO Mark Zuckerberg <a href="https://www.facebook.com/zuck/videos/10111936118050541/" target="_blank">has said</a> he expects half the company’s workforce to be working from home in the next decade — and that employees who moved to less expensive areas would see their salaries cut to reflect the cost of living.</p>
<p>Michel Serafinelli, an economics lecturer at the University of Essex, said that the value of office space could be expected to decline. “Why rent a big office that only a few workers will be able to use at a time, and only on certain days each week?”</p>
<h3><strong>COVID-flight</strong></h3>
<p>The end of the office, should it come to pass, would transform the urban landscape. Workers, unshackled from their morning commute, will be free to gravitate to suburbs and the countryside.</p>
<p>Europe has a long tradition of rich city-dwellers fleeing plagues to the countryside, leaving the poor and working class behind. In Giovanni Boccaccio’s 14th-century literary landmark, "The Decameron," wealthy Florentines escaped to the Tuscan countryside to hide from the Black Death.</p>
<p>During the coronavirus crisis, urban elites in hard-hit places like Spain and France left the city for greener and safer pastures. Former Spanish Prime Minister José María Aznar <a href="https://www.nytimes.com/2020/03/29/world/europe/rich-coronavirus-second-homes.html" target="_blank">traveled to his holiday villa in Marbella</a> rather than ride out the lockdown in Madrid.</p>
<p>If there are further waves of the coronavirus or home-working continues to proliferate, that trend could easily stick. Why pay big-city rents for an undersized apartment if you can pursue an equally attractive career from a house in the hills? And from the employer’s point of view, why pay big-city salaries if you can source the same talent for cheaper, even if you never or rarely see your employees in person.</p>
<p>But even if teleworking does become ubiquitous, not everybody will be able — or will want — to flee to the suburbs and the country. And those who stay behind may find the city they call home has become a very different place.</p>
<div id="attachment_1422371"><p><img aria-describedby="caption-attachment-1422371" src="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-714x474.jpg" alt="" width="714" height="474" srcset="https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-714x474.jpg 714w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-300x199.jpg 300w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-1024x679.jpg 1024w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-768x509.jpg 768w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-1536x1019.jpg 1536w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-2048x1359.jpg 2048w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-1160x769.jpg 1160w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-380x252.jpg 380w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-172x114.jpg 172w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-392x260.jpg 392w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-1085x720.jpg 1085w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-333x221.jpg 333w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-1120x743.jpg 1120w, https://www.politico.eu/wp-content/uploads/2020/07/GettyImages-1211427468-600x398.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1422371">Paulina Mansz, a group fitness instructor in Arlington, Virginia, leads a workout session online, as her two sons — home after schools closed — lend a hand (or a foot) | Andrew Caballero-Reynolds/AFP via Getty Images</p></div>
<p>“Cities are almost certainly going to become cheaper, because more spaces become available,” Bloom said. “That might help address the affordability crisis we see in urban centers ... but that’s going to leave quite a vacuum.” Artists, he added, “might move into the vacant spaces, but they don’t spend much money, and that’s quite a problem for cities that rely on revenue to offer services.”</p>
<p>Businesses are already suffering from the knock-on effects of emptier business areas and city centers. Shops, restaurants and other services that depend on corporate and other clientele are reeling from the pandemic’s economic impact.</p>
<p>“The restaurants where executives go out to lunch, the cafés where secretaries grab their cappuccino, the retail shops where workers shop on their breaks…&nbsp;If the offices go, we&nbsp;can plausibly expect urban expenditure to drop by a third,” Bloom said. “That’s a hit which most commercial spaces can’t take.”</p>
<p>In Brussels’ European Quarter, the disappearance of the Eurocrats and office workers who used to flood Rue de la Loi and the Schuman Roundabout already led to <a href="https://twitter.com/liliebayer/status/1278689951723462658" target="_blank">the&nbsp;closure</a> of one of the area’s most popular cafés. While the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.politico.eu/article/the-death-of-the-city-coronavirus-towns-cities-retail-transport-pollution-economic-crisis">https://www.politico.eu/article/the-death-of-the-city-coronavirus-towns-cities-retail-transport-pollution-economic-crisis</a></em></p>]]>
            </description>
            <link>https://www.politico.eu/article/the-death-of-the-city-coronavirus-towns-cities-retail-transport-pollution-economic-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037685</guid>
            <pubDate>Mon, 03 Aug 2020 13:47:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Omission: Killing Features for Fun and Profit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037500">thread link</a>) | @arvidkahl
<br/>
August 3, 2020 | https://thebootstrappedfounder.com/the-power-of-omission-killing-features-for-fun-and-profit/ | <a href="https://web.archive.org/web/*/https://thebootstrappedfounder.com/the-power-of-omission-killing-features-for-fun-and-profit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><span>Reading Time: </span> <span>7</span> <span>minutes</span></span></p>











<p>If you add features to your product indiscriminately, you will end up with a gigantic bloated mess of software. One way to deal with this is to be very careful when deciding if new features should be added. Another rarely used approach is to remove unused and outdated features. Removing the cruft from your SaaS product is akin to pruning a hedge: you will end up with a more recognizable shape and a clearer vision of what your product is all about.</p>



<p><strong>How Customers React When You Remove Features</strong></p>



<p>Here’s the thing with change: there will always be people who hate it, with or without reason. While notorious complainers can be safely ignored, pay close attention to people who react negatively to product removal. Your target customers should be the ones that you delight with your product, and you never know how people use your product in weird ways until you break a workflow that you never expected to be possible. You want to remove a file upload button because everyone drags their files into the browser? There will be that one user who uses their keyboard only. Removing the feature makes the whole product unusable to them all of a sudden.</p>



<p>Make sure never to remove accessibility features because you don’t see the need for them yourself. Impaired users rely on these things to be able to use your product. Build as much accessibility as possible into the product from the beginning.</p>



<p><strong>When to Remove a Feature</strong></p>



<p>In some way or another, every reason to remove a feature from your product boils down to feature creep. Here are a few examples, both with reasons why they should be removed and how they come to happen.</p>



<p><strong>Remove unused features.</strong> When customers stop using features, they either found a better solution to their problem or they have a different problem to solve. As a result, unused features clutter the user interface of your product, not providing any value to your users. At best, they are a visual nuisance; at worst, they produce unintended side-effects, confusing your customers by their presence. Your codebase will also show signs of bloat when unused features stick around for too long.&nbsp;</p>



<p>We removed such a feature at FeedbackPanda. It was initially introduced to allow our customers to migrate and amend their data from one product version to another. As some of our customers were rather slow to adopt the new version, we left the interface component in for a long time and forgot about it. Half a year after the last customer finished migrating, we finally removed the feature. While doing that, we figured out that some of our customers had misused that feature to change their data in weird ways that we didn’t understand before. Talk about a side-effect!</p>



<p><strong>Remove features that distract from product focus.</strong> Sometimes, you build things because you think your customers need them, but they turn out to be misaligned with your purpose of solving your customers’ critical problem. Those features can make other features less effective or at least harder to find and use. This is the ultimate incarnation of feature creep. It’s what will turn your product into a tangled mess if you don’t regularly trim the fat.</p>



<p><strong>Remove features that make the product too complex.</strong> Very similar to features that distract your users are features that overwhelm them. Many products have seen their customers churn because they became hopelessly complicated to use. It all starts with the intent to provide more value, but it eventually turns into feature overload.</p>



<p><strong>Remove features that are expensive to maintain.</strong> This removal opportunity is often overlooked. Some things that are part of your product may, at some point, cause performance issues or incur higher monetary costs than you’re willing to pay. Often, it’s easy to engineer and maintain heavy-duty features at the beginning of a business with only a few customers. Examples of this would be heavy background-processing of customer data, complicated imports, or extensive export scenarios. While limiting access to this feature may work, removing it is also an option if it’s do-or-die.</p>



<p><strong>Why Does Feature Creep Happen?</strong></p>



<p>Feature creep happens for many reasons, and all come from a genuine belief that, at the moment when you conceptualize and build the feature, it’s useful and providing value to your business and your customers. But, of course, just because you believe so doesn’t make it real. I have built many features that I felt to be absolutely necessary only to shamefully admit defeat and remove them a few months after launching them.</p>



<p>Here are a few situations where I should not have added a feature but did anyway:</p>



<p><strong>I just wanted to build it.</strong> Sometimes, you’re only interested in understanding how things work, and you think you need to build it. I did so with the FeedbackPanda invoicing system. What started as a simple part of the application, not much more than a list, ended up being a PDF-generating monster and tax-calculating monster of a feature. In retrospect, that’s a rabbit hole I should have never even looked at from a distance.</p>



<p><strong>I just wanted to get and convert a big customer.</strong> In a prior startup, I built several features for a prospective customer who promised to sign up if only those features were implemented. Of course, they never signed up even when I had deployed the changes, but we kept the feature in the application because we hoped that other customers could benefit from it somehow. They never did.</p>



<p><strong>I thought it was the one feature I needed to release for things to start happening.</strong> This is an example of the classical “Next Feature Fallacy”: the thinking that the next thing you do will have the big impact you’re waiting for. But it usually doesn’t. Usually, it will be yet another attempt at making a big difference and failing. This is a great opportunity to dust yourself off and try again. Just make sure you remove the feature that has proven not to work. Don’t keep it hanging around.</p>



<p>There are a number of other reasons that can cause you to build things you shouldn’t have:</p>



<p>• “<strong>Premature Optimization”-like integrations.</strong> You thought you could use this eventually, and you’d better already have it in the product before you need it. Maybe you intend to eventually partner with a service, so you build an integration ahead of time. And then the partnership falls through, and you never need it. Many technical founders then fall prone to the sunk cost fallacy, thinking that since they already invested their time, the functionality needs to stay there.</p>



<p><strong>• You’re trying to capitalize on trends.</strong> Ever implemented social-media-like functionality even if your customers never interact? I built a Facebook-like social stream with messages and comments for farmers who never took the time to use it because they were too busy harvesting their vegetables. But social media feeds were everywhere, so we just had to have something like this, too. It was not required at all, and completely unused, but we believed that we could pull it off.</p>



<p><strong>• You saw it somewhere else, and it looked rather cool.</strong> Founders get inspired by other software all the time, and then build something very similar in their own products. What they forget is that every feature exists within the context of a product. That cool overlay animation you see on a social network for designers will completely confuse your almost technically illiterate users. Try to avoid things that are not essential to your product.</p>



<p><strong>• You needed to release something, and it was quick to build.</strong> Sometimes, you feel like you just need to do something. You haven’t released a new feature in weeks, and customers have always asked for something simple. It’s not on your roadmap, and you didn’t put it on there because it wasn’t essential, but you know it will only take an hour or two. Now you have wasted your time twice. You didn’t work on anything meaningful, and you will have to remove it again in the future.</p>



<p>No matter what your reasons were then, you need a slim and efficient product now. So, trim the fat, and start removing those obsolete features.</p>



<p><strong>Removing a Feature the Empathetic Way</strong></p>



<p>If you want to remove a feature, sunset it. Make a public announcement about the removal close to when people who use the feature would read it. Then, turn it into an optional feature, using a configuration toggle. Change that toggle to default to an “off” state, and measure how many people react to it. Inform them how to re-enable it and how to work with your product without that feature. If you feel confident that removing the feature won’t impact a significant amount of your target customers, remove it.</p>



<p>Feature removal has multiple impacts: you can fully remove a feature, slowly wean customers off over a number of weeks, or phase out the feature via options until the last customer has stopped using it.</p>



<p>No matter what speed you choose, the most important thing to remember is to communicate the changes to your users before and after you remove anything. This will reduce friction between you and your customers. It prepares them for an impending change and reduces the likelihood of them getting confused when it finally happens. By keeping your customers in the loop, you’re reducing the customer service load you’ll have when you remove the feature. Also, once they know about the change, they can look for alternative ways to solve their problem if they were users of the feature before.</p>



<p>Use all the instruments at your disposal to communicate the removal to your customers. Tell them in-app and through an email. You never know where they are right now, and you need them to know both in advance through a thoughtful email and right when they are in the product, best in the location where the feature used to be. Update your knowledge base and prepare a transitionary video that clearly shows how to solve the problem alternatively if ever needed. The more you invest in communicating a feature removal, the less …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thebootstrappedfounder.com/the-power-of-omission-killing-features-for-fun-and-profit/">https://thebootstrappedfounder.com/the-power-of-omission-killing-features-for-fun-and-profit/</a></em></p>]]>
            </description>
            <link>https://thebootstrappedfounder.com/the-power-of-omission-killing-features-for-fun-and-profit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037500</guid>
            <pubDate>Mon, 03 Aug 2020 13:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How hard is your email to say?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24037364">thread link</a>) | @vicarrion
<br/>
August 3, 2020 | https://dillonshook.com/how-hard-is-your-email-to-say/ | <a href="https://web.archive.org/web/*/https://dillonshook.com/how-hard-is-your-email-to-say/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

        <article>
            
            
            <!--kg-card-begin: markdown--><p>You're at the doctors office, talking to an aquaintence, or ordering something on the phone and they ask the question:  What's your email?  Depending on your name, age, and your life choices this can be a breeze or the dreaded question.  How long does it take before you have to break out the <a href="https://en.wikipedia.org/wiki/NATO_phonetic_alphabet">phonetic alphabet</a>?  How many times do you have to repeat it?</p>
<p>Today we're going to come up with a scoring system to measure how painful your email is to tell someone.  It's a golf scoring system with low scores being easy and each point is one unit of struggle for both you and the recipient.</p>
<p>Lets start with the hypothetical perfect example: <code>bob@gmail.com</code> coming in with a score of 0.  It's short, contains only a common name, and is on a popular mail host.  From there, lets see all the ways yours is harder to say.</p>
<h3 id="nonpopularemaildomain">Non popular email domain</h3>
<p>If's it's not <code>@gmail.com</code>, <code>@outlook.com</code>, <code>@hotmail.com</code>, <code>@yahoo.com</code>, <code>@icloud.com</code>, or <code>@aol.com</code> take a point.  These are services people are familiar with and don't have to think about typing.  They just might judge you on which on you use.</p>
<h3 id="domainwithsubdomain">Domain with subdomain</h3>
<p>If you have an email from school hanging around you're likely to be guilty of this one like I am.  My school address got the <code>alumni</code> subdomain added to it.  I've seen a bunch of other emails from schools with the department included <code>@cs.xyz.edu</code>, or other fun stuff just 'cause like <code>@mail.xyz.edu</code>. Add a point for each level of domain past the normal two levels.</p>
<h3 id="noncommontopleveldomain">Non common top level domain</h3>
<p>If you're extra special you'll have a TLD like <code>.is</code>, <code>.io</code>, <code>.rocks</code> or some other novelty.  Take a point if it's not <code>.com</code>, <code>.org</code>, <code>.net</code>, <code>.edu</code>, or <code>.gov</code>.</p>
<h3 id="longusername">Long Username</h3>
<p>After a certain amount of letters in the username you're just going to have to slow down and repeat that.  +1 point for every 2 characters over 6.  <code>bobsondugnutt@gmail.com</code> gets a 3 for example.</p>
<h3 id="punctuation">Punctuation</h3>
<p>Periods are pretty common in email usernames because we're used to saying "dot" for the domain anyways but they'll still slow down whoever is typing it and likely miss what comes after it.  Any other punctuation is a great typo opportunity.  +1 for any period in the username, +2 for any other punctuation in the username <em>or</em> domain.</p>
<h3 id="numbers">Numbers</h3>
<p>Just like punctuation, numbers are in that more unfamiliar part of the keyboard where fingers get lost and push the wrong buttons.  +1 for each number.</p>
<h3 id="anyhardtosaywordsthatarentyourname">Any hard to say words that aren't your name</h3>
<p>Bit of a loose definition here but you should know it when you see it.  If you have a username that's not your name (where they might be able to refernce spelling) and is not a common and easily spellable word take a point. <code>xThreadRiPPerX@gmail.com</code> I'm talking about you whoever you are.</p>
<h3 id="similarsoundingletters">Similar sounding letters</h3>
<p>This is one I know all too well from one of my emails where I have to break out the phonetics after the 3<sup>rd</sup> repetition and they're still confused. "mn"? "mm"? "nm"?  Add +1 for each pair of similar sounding letters that aren't in an easily pronouncable and spellable word.  Some common pairs include: BV, DG, GZ, MN, JK</p>
<h3 id="bonusunicodeemoji">Bonus: Unicode &amp; Emoji</h3>
<p>Good luck getting someone to type that over the phone. +5 for each unicode character.</p>

<p>The email I've been using the most over the past few years is guilty of a few of these and comes in at a score of 3 so I'm well aware of the struggle.</p>
<p>Let me know in the comments what score yours is and the struggles you've had!</p>
<!--kg-card-end: markdown-->

            <a href="https://dillonshook.com/" title="Back to home">Back to home</a>
            <a href="https://dillonshook.com/blog" title="More blog posts">More blog posts</a>

        </article>
        

    </div><div>
    <a href="https://dillonshook.com/">
        <img src="https://dillonshook.com/content/images/profile.png" alt="Profile Image">
    </a>
    <p>by <strong>Dillon Shook</strong></p>
    <p>Autodidact &amp; Zero One Infinity Advocate</p>
    <p><span>Location</span> Boston, MA</p>
    <p><span>Education</span> B.S. Computer Science, New Mexico Tech</p>
    <p><span>Interests</span>
      <a href="https://dillonshook.com/coding">Programming</a>,
      <a href="https://dillonshook.com/photos">Photography</a>,
      Cooking,
      <a href="https://dillonshook.com/tag/game-dev">Game Development</a>, Reading, Guitar, Running, Travel, Never having enough time
    </p>
    <p><span>This Site</span> Made with <a href="https://ghost.org/">Ghost</a>, <a href="https://cloudinary.com/invites/lpov9zyyucivvxsnalc5/ucksnxmudzsyk0krgblh">Cloudinary</a>, and many many hours of writing, styling, editing, breaking things, fixing things, and hoping it all works out.</p>
    <p><span>Contact</span> site@dillonshook.com</p>
    <p><span>Webring</span>
      <a href="https://hotlinewebring.club/dshook/previous">← Prev</a>
      &nbsp;&nbsp;
      <a href="https://hotlinewebring.club/dshook/next">Next →</a>
      <br>
      Find something creative on the web
    </p>

    


</div></div>]]>
            </description>
            <link>https://dillonshook.com/how-hard-is-your-email-to-say/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037364</guid>
            <pubDate>Mon, 03 Aug 2020 13:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Add video subtitles on the fly from plain text]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24037288">thread link</a>) | @011-video
<br/>
August 3, 2020 | https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/ | <a href="https://web.archive.org/web/*/https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	

	

	<div>
		<p><iframe title="How to Burn video subtitles on the fly from a plain text file" width="576" height="324" src="https://www.youtube.com/embed/voruErQe4JA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><em><strong>How to add permanent subtitles into video without using SRT file ?</strong></em></p>
<ol>
<li>
<h6>If you opt for a big font size make sure&nbsp; to choose a larger screen&nbsp; <img src="https://011.video/wp-content/uploads/2020/01/pixel.png" alt="">&nbsp; to display the whole phrase every time you turn the mouse wheel</h6>
</li>
<li>
<h6>Upload a video&nbsp; <img src="https://011.video/images/uploadV2.png" alt="">&nbsp; from your device</h6>
</li>
<li>
<h6>Copy subtitles from any text editor.</h6>
</li>
<li><span><em>Notice that to be processed as subtitles the text must start with&nbsp; a star&nbsp; ‘&nbsp; *&nbsp; ‘&nbsp; and each phrase must end with a punctuation character&nbsp; &nbsp;:&nbsp; &nbsp;‘&nbsp; !&nbsp; ‘&nbsp; &nbsp;or&nbsp; &nbsp;‘ ?&nbsp; ‘&nbsp; or&nbsp; ‘&nbsp; . ‘</em></span></li>
<li>
<h6>Double click inside the canvas. As you can only move the subtitles vertically make sure to click on the left far if your text got long phrases</h6>
</li>
<li>
<h6>paste the subtitles text&nbsp; <img src="https://011.video/images/text.gif"> inside the input text field</h6>
</li>
<li>
<h6>Change the text color&nbsp; <img src="https://011.video/wp-content/uploads/2019/10/color.png" alt="" width="207" height="22"></h6>
</li>
<li>
<h6>Click few times on&nbsp; <img src="https://011.video/wp-content/uploads/2019/09/effet.png" alt="" width="35" height="35">&nbsp; to make the text size bigger.</h6>
</li>
<li>
<h6>Start to record&nbsp; <img src="https://011.video/images/on2.png" alt="">&nbsp; &nbsp; your video</h6>
</li>
<li>
<h6>As soon as the video begin turn the mouse wheel&nbsp; <img src="https://011.video/images/mouse.png"> &nbsp;before the speech start and you should see the message “Ready to display… Turn wheel again “</h6>
</li>
<li>
<h6>Turn the mouse wheel and you should see&nbsp; “let’s Add subtitles” message displayed.</h6>
</li>
<li>
<h6>Continue to turn the mouse wheel to display each phrase on the fly, one by one.</h6>
</li>
<li>
<h6>To make the subtitles easier to read try to move the cursor vertically close to the video character who speak</h6>
</li>
<li>
<h6>When the speech is over pause&nbsp; <img src="https://011.video/images/pause.png" alt=""> and download <img src="https://011.video/images/d2.png" alt=""> your video</h6>
</li>
</ol>
<p><em>Here is a “French video clip song subtitled with English lyrics translation”</em></p>
<p><iframe title="French video clip song subtitled with English lyrics translation" width="576" height="324" src="https://www.youtube.com/embed/hDV0GrTlYSA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<!-- Rate my Post Plugin -->			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037288</guid>
            <pubDate>Mon, 03 Aug 2020 13:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some tips you should use on your Instagram Bio]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037178">thread link</a>) | @clickpage
<br/>
August 3, 2020 | https://click.page/blog/7-tips-and-tricks-for-the-perfect-instagram-bio/ | <a href="https://web.archive.org/web/*/https://click.page/blog/7-tips-and-tricks-for-the-perfect-instagram-bio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
		
<!-- start: #header -->

<!-- end: #header -->



    	<!-- start: #single -->
    <main id="single">
    
        <!-- Fullcover Style -->
        
		<!-- start: .center -->
	    <div>

            <!-- start: .epcl-page-wrapper -->
            <div>

                <!-- start: .content -->
                <div>

                    <article>

                        
                                                    <header>

    	<div>
                                    <div>
                    <p><img width="950" height="500" src="https://click.page/blog/wp-content/themes/veen/assets/images/transparent.gif" data-lazy="true" data-src="https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips.jpg" alt="instagram bio tips" data-srcset="https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips.jpg 950w, https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips-300x158.jpg 300w, https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips-768x404.jpg 768w, https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips-100x53.jpg 100w, https://click.page/blog/wp-content/uploads/2020/08/instagram-bio-tips-700x368.jpg 700w" data-sizes="(max-width: 950px) 100vw, 950px">                    </p>
                    
                    <!-- start: .meta -->
                    
                    <!-- end: .meta -->
                </div>
            		    </div>
    

	

</header>                        
                        
                                                    <!-- start: .meta -->

<!-- end: .meta -->                        
                        <section>

                            
                            
                            <div>
                                <div id="pl-124"><div id="pg-124-0"><div id="pgc-124-0-0"><div id="panel-124-0-0-0" data-index="0">			<p><span>The bio on your Instagram page is very important as it gives a first impression as to who you are, so it is safe to say that you must write your bio very carefully. This could prove to be difficult so we have put together the 7 best instagram bio tips and tricks to help you create the perfect Instagram bio.</span></p>
		</div><div id="panel-124-0-0-1" data-index="1">			<div><h2>1. Use Keywords</h2>
<p>Utilising keywords assists people in understanding what you do and who you are. Choose keywords which match your brand and are useful to people that visit your page. They allow for your page to gain more attention as they help target your niche and allows for people to understand that you offer a valuable/beneficial business/service etc. </p>
</div>
		</div><div id="panel-124-0-0-2" data-index="2">			<div><h2>2. Use Emojis</h2>
<p>In your bio, you want to break up large chunks of text. A great way of doing this is by using a few emojis to do this. They add a bit of colour to your profile but you should always be careful about which ones you use because over-using them can look unprofessional. As well as this, make sure you use relevant emojis which show what you do or tell people what your personality is.</p>
</div>
		</div><div id="panel-124-0-0-3" data-index="3">			<div><h2>3. Add your Email</h2>
<p>A common thing for users to do is to put their email in their bio. This is an easy way to let your followers know that you can be contacted, and they can contact you with any queries or feedback etc. However, Instagram Business accounts allow for you to add an email button onto your profile which allows for a user to directly contact you through your profile.</p>
</div>
		</div><div id="panel-124-0-0-4" data-index="4">			<div><h2>4.  Take advantage of line-breaks</h2>
<p>Another way to break up your bio is to utilise Line-Breaks. These allow you to start typing on a new line. This is especially useful when you want to write a small bullet point list showing off your skills or keywords. They are very easy to implement as all you need to do is click Return/Enter on your keypad and it only takes up a single character on the bio character limit.</p>
</div>
		</div><div id="panel-124-0-0-5" data-index="5">			<div><h2>5. Include your skills</h2>
<p>Your Instagram bio is the first impression/introduction to visitors of your page. If you want these visitors to become followers, then you must set a good first impression. Use your Instagram bio to highlight qualities about you such as your skills, hobbies or interests. You need to make yourself stand out against competition so you need to show off your unique skills and values that make you better than others.</p>
</div>
		</div><div id="panel-124-0-0-6" data-index="6">			<div><h2>6. Use branded hashtags</h2>
<p>Including hashtags in your Instagram bio is also a way to let your followers know what niche you’re in. These intrigue people to engage with your posts and learn more about them, or click the hashtag and see posts with that hashtag. Including your personal branded hashtag can encourage followers to post using that hashtag.</p>
</div>
		</div><div id="panel-124-0-0-7" data-index="7">			<div><h2>7. Utilise your biolink</h2>
<p>And last and not least! Add a biolink to your Instagram bio. On Instagram, there is only one place in which you can place a biolink and that is on your profile underneath your bio. This is crucial because your Instagram bio can only hold a limited amount of information and linking to your website can provide people with a more detailed understanding of your business. Due to the limitation of only one link in the caption, businesses tend to change the link regularly to redirect the user to a new product. You can also get a ClickPage to share and manage all your links from one location. Add your ClickPage to your Instagram bio (as well as all your other social media platforms) and you won’t have to keep updating your biolink. <a href="https://click.page/" target="_blank" rel="noopener noreferrer">Click here</a> to find out more about ClickPage.</p>
</div>
		</div><div id="panel-124-0-0-8" data-index="8">			<p>We hope you’ve found these helpful and utilise some of these tips on your Instagram bio.</p>
		</div></div></div></div>                                                            </div>
                            
                            
                                                            
                            
                            
                                    

                                                            
                                                        
                            
                            <!-- start: .epcl-comments -->
                            
                            <!-- end: .epcl-comments -->                           

                             
                            
                                                                <!-- start: .share-buttons -->
    
    <!-- end: .share-buttons -->
                                  
                            
                            
                            

                        </section>

                    </article>
                    
                                                 

                    
                    

                </div>
                <!-- end: .content -->

                    <!-- start: #sidebar -->
    
    <!-- end: #sidebar -->

            </div>
            <!-- end: .center -->
        
        </div>
        <!-- end: .epcl-page-wrapper -->

	</main>
	<!-- end: #single -->



        <!-- start: #footer -->

<!-- end: #footer -->
        
    </div></div>]]>
            </description>
            <link>https://click.page/blog/7-tips-and-tricks-for-the-perfect-instagram-bio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037178</guid>
            <pubDate>Mon, 03 Aug 2020 13:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LakeFS – atomic, versioned data lake on object storage]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037127">thread link</a>) | @pauldix
<br/>
August 3, 2020 | https://lakefs.io/2020/08/03/introducing-lakefs/ | <a href="https://web.archive.org/web/*/https://lakefs.io/2020/08/03/introducing-lakefs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div><div itemprop="text"><div><div><p><strong>TL;DR: </strong>we worked with an object-storage based data lake,  it’s an excellent data architecture but you have no systematic way of:</p><ul><li>Communicating between writers and readers (if you are thinking MetaStore as a solution, keep reading).</li><li>Avoiding the data Swamp everybody is warning you about.</li><li>Creating data pipelines that are resilient to changes in data and code</li></ul></div></div><p>We identified a way to provide a systematic solution for those pains by providing a data versioning schema over the data lake (if you are thinking Hudi or Delta lake, then no, we are not a format).</p><p><strong>The long version </strong>starts when we* finished a migration of our on-prem Hadoop clusters to AWS in mid 2017. Our architecture included a Kafka based ingest process of over hundreds of different sources, managed by the data collection group.  The data was saved to S3 and partitioned by arrival time. We had 4 different engineering groups on the consuming side:</p><ul><li><strong>Data science:</strong> converting raw data into estimations. The group consisted of data scientists, data engineering and DevOps teams to support a DAG of almost 1000 jobs running daily to produce our production data.</li><li><strong>Web application: </strong>mainly consuming the output of the data science group.</li><li><strong>Business intelligence:</strong> BI engineers and analysts, running counts on the amount of data we ingested by device, application, country, etc’,</li><li><strong>Professional services:</strong> analysts providing ad hoc reports to customers based on any data set that supports their analysis.</li></ul><p>We were happy. Finally throughput was not a problem, cost effectiveness of the storage (S3) was high, and with some <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html">tweaks on prefixes</a>, throughput on read was satisfactory.</p><p>In retrospect we still think we made the right choice with this architecture. Before the migration we were dealing with “this is not feasible” issues and afterwards transitioned to the “this is not manageable” kind. And when data is your product, “this is not manageable” means production issues due to error prone operations.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" alt="" width="819" height="461" srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w" sizes="(max-width: 819px) 100vw, 819px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w"><figcaption><em><span>Data Architecture </span></em></figcaption></figure><p>Here are some examples of the “this is not manageable” problem space:</p><h3>Fragile Writers and Readers: how to signal consumers the data is ready?</h3><p>Pain Point 1: The data science group starts running its <a href="https://airflow.apache.org/docs/stable/concepts.html#dags">DAG</a> only after data from several different sources (that were written independently) were complete. There’s no simple way for the writing teams to signal the completion of all writes to the reading teams. To work around this, we used time-based synchronization. At midnight, readers start consuming the data. Of course, this neglected late arrivals and in-flight writes. It was good enough most of the time, but a real pain when trying to reproduce results.</p><p>Pain Point 2: Consider the DAG of 1000 Spark jobs. Each job depends on several ancestor jobs’ output as its input. Basically the same as pain point #1, only with Airflow orchestrating a DAG of spark jobs. We used Spark SUCCESS files as a hook for Airflow. This doesn’t work in case the success file fails, or if for some reason someone intervenes manually.</p><p>Pain Point 3: In certain instances, correctness of the readers depends on a synchronization of several collections. For example, sometimes we needed the same data in two storage formats. ORC for AWS Athena, and Parquet for Spark. Another example: the professional services group have permission to access any data set serving their current ad hoc analysis. How do you make sure everything they access is synchronized to the same time/other parameters to maintain consistency? We used <a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive Metastore </a>as a workaround. Each write process updates the Metastore when completed, and the reader waiting on those inputs would wait until all updates were announced. In some cases it meant trading consistency for availability, but we weren’t the first to encounter this tradeoff :-).</p><p>A word about the workarounds: every time we introduce new data or analysis the solution needs to be implemented again. If you neglect to do so, you will suffer the consequences. There was no one systematic and easy solution for all these use-cases. In addition, each solution failed sometimes, causing a correctness issue later in the data pipeline.&nbsp;</p><h3>Data Swamp: how to ensure visibility and governance?</h3><p>Pain point 1: Many organizations avoid limiting data access using permissions as they want to democratize the data in the organization, and as long as regulation permits, allow data consumers to generate as much value as possible from the data. We hold this philosophy. The challenge is that there’s no systematic way to ensure isolation, i.e., to ensure no one changes the data while you’re using it. This is why copying is so common in object storage. The copy you create yourself usually has a very meaningful name, such as “Einat_final_final_V2”, or better yet “Prodcution_temp”. You don’t have lineage capabilities that indicate which data is behind that name, unless you enforce naming conventions…Good luck with that 🙂</p><p>Over time, your lake becomes a swamp, cost increases and you have no real control over your data from a compliance standpoint.</p><p>Pain point 2: If you are working to avoid the swamp, you’re probably running retention jobs to ensure stuff doesn’t get out of hand. Consider a home grown retention job running periodically over the lake. If it has a bug and  deletes valuable data, according to some logic it will start to spread across many collections. Although you have backups of all the objects in the lake,&nbsp; you don’t have a snapshot of the lake to revert to. Recovering fully from such an error may take weeks. Amazon’s S3 object-level versioning will not save you here.</p><h3>The need for Data CI/CD: how to ensure data quality?</h3><p>Pain point: Data is useless, unless it’s trustworthy. When your delivery is data, it is not enough to ensure the correctness of the code. It’s also critical to protect the properties of the data that you assumed you had when you developed the code. Now, remember the 1000 spark jobs orchestrated by Airflow that run every day?&nbsp; These run an algorithm, so each job includes assumptions on the data. If those assumptions are no longer valid, jobs may fail, or worse, the quality of the output data will decrease dramatically. Why is the second scenario worse? Because it’s harder to detect.&nbsp;</p><p>If we could run a job in isolation, test the results, and merge back automatically only after validating schema and data correctness, then it would be possible to identify issues earlier, putting us in a much better position to deliver quality data.</p><h3>We were thinking: Git interface with MVCC capabilities</h3><p>While each one of these challenges may have a workaround we can use, or a homegrown solution we can develop, there is no <strong><em>conceptual</em></strong> solution that simply makes the work manageable and hence resileant. We want a concept and a language that provides a solution for all of those challenges, and for the challenges that are yet to come.</p><p>On the one hand, database systems use transactions to provide systematic guarantees over the data. This is usually implemented using <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-Version Concurrency Control</a>.</p><p>On the other hand, there is a standard for code versioning. The Git terminology is a common language for developers to deal with versions of things. So we were thinking, if we build an MVCC management layer for Data Lakes, using a Git-like interface, we will have an intuitive way of getting the guarantees we want for our data lake, in the performance and reliability we need. The name “lakeFS” followed soon after.</p><h3>Introducing lakeFS: manageable and resilient data lake</h3><p><a href="http://www.lakefs.io/">lakeFS</a> is an open source platform that delivers resilience and manageability to your existing object-storage based data lake. With lakeFS you can build repeatable, atomic and versioned data lake operations – from complex ETL jobs to data science and analytics.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" alt="" width="743" height="258" srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w" sizes="(max-width: 743px) 100vw, 743px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w"><figcaption><em><span>Resilience and manageability layer for object-storage based data lakes</span></em></figcaption></figure><p>Main features include:</p><ul><li><strong>Cross-Lake Isolation </strong>– Creating a lakeFS branch provides you with a snapshot of the entire lake at a given point in time (no copying involved). Guaranteeing that all reads from that branch will always return the same results.</li><li><strong>Object-level Consistency</strong> – Ensuring all operations within a branch are strongly consistent (read-after-write, list-after-write, read-after-delete, etc).</li><li><strong>Cross-collection Consistency</strong> – Branches provide writers consistency guarantees across different logical collections. Merging to “main” is only done after several datasets are created successfully.</li><li><strong>Versioning</strong> – Retain commits for a configurable duration, so readers can query data from the latest commit or any other point in time. Writers can atomically and safely rollback changes to previous versions.</li><li><strong>Data CI/CD</strong> – Define automated rules and tests mandatory to pass before committing or merging changes to data.</li></ul><p><span><a href="http://docs.lakefs.io/">Try it out</a>!  It will solve the challenges you have now, and will prevent you from running into undesired issues in the future. </span></p><p><em>* referring to the amazing R&amp;D team at <a href="https://www.similarweb.com/">SimilarWeb</a></em>. <em>We are proud to have been a part of before embarking on the lakeFS adventure</em></p></div><!-- .entry-content .clear --></div></article></div>]]>
            </description>
            <link>https://lakefs.io/2020/08/03/introducing-lakefs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037127</guid>
            <pubDate>Mon, 03 Aug 2020 12:56:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing YouTube and Invidious]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24037075">thread link</a>) | @freddyym
<br/>
August 3, 2020 | https://secluded.site/replacing-youtube-invidious/ | <a href="https://web.archive.org/web/*/https://secluded.site/replacing-youtube-invidious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Omar Roth, the developer of Invidious, recently wrote a blog post about
<em><a href="https://omar.yt/posts/stepping-away-from-open-source">Stepping away from open source</a></em>.
While I never used the official instance, I thought this was a good
opportunity to create a tool that downloads videos from YouTubers I’m
subscribed to so I can watch them offline in whatever manner I prefer.</p>
<p>To that end, <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl</a> is by
far the most reliable and versatile option. Having been around since
before 2008<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, I don’t think the project is going anywhere.
<a href="https://mpv.io/">MPV</a> is my media player of choice and it relies on
youtube-dl for watching online content from Twitch to YouTube to
PornHub to <a href="https://ytdl-org.github.io/youtube-dl/supportedsites.html">much more</a>.</p>
<p>Conveniently, youtube-dl comes with all of the tools and flags needed
for exactly this purpose so scripting and automating it is incredibly
easy. Taking a look at <code>man youtube-dl</code> reveals a <em>plethora</em> of options
but only a few are necessary.</p>
<h2 id="preventing-duplicates">Preventing duplicates</h2>
<p>The main thing when downloading an entire channel is ensuring the same
video isn’t downloaded more than once. <code>--download-archive</code> will save the
IDs of all the videos downloaded to prevent them from being downloaded
again. All that’s required is a file path at which to store the list.</p>
<div><pre><code data-lang="bash">--download-archive .archives/&lt;channel&gt;.txt
</code></pre></div><h2 id="selecting-quality">Selecting quality</h2>
<p>By default, youtube-dl downloads the <em>single</em> file with the best quality
audio and video so it doesn’t need to mux<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> them together after.
However, I prefer to have the highest possibly quality and don’t mind
waiting a few seconds longer for FFmpeg to combine audio and video
files. <code>--format</code> lets the user decide which format they prefer and
whether they want to focus on storage efficiency or quality. The basic
options are <code>best</code>, <code>worst</code>, <code>bestvideo</code>, and <code>bestaudio</code>. These will
download a <em>single</em> file that is the highest or lowest quality of both
video/audio or video-only/audio-only. There are a lot of other options
for more fine-grained control over what to look for but, as I mentioned,
I want the highest video and the highest quality audio so I use
<code>bestvideo+bestaudio</code>. After downloading both of those files, they will
be muxed together.</p>
<div><pre><code data-lang="bash">--format bestvideo+bestaudio
</code></pre></div><h2 id="embedding-subtitles">Embedding subtitles</h2>
<p>I enjoy subtitles but I know many people don’t so this section can
certainly be ignored.</p>
<p>There are a few options for fetching and embedding subtitles. To get
“real” subtitles that someone transcribed manually, use <code>--write-sub</code>.
For YouTube’s auto-generated subtitles that may or may not be horribly
inaccurate, use <code>--write-auto-sub</code>. For selecting the language,
<code>--sub-lang &lt;language-code&gt;</code>, for embedding them, <code>--embed-subs</code>, and
for selecting the format, <code>--sub-format &lt;desired-format&gt;</code>. I like using
SRT files so I have that first with <code>best</code> beside it like so:
<code>--sub-format srt/best</code>. SRT is preferred but, if unavailable, whatever
other highest-quality format will be used and embedded instead.</p>
<div><pre><code data-lang="bash">--write-sub --write-auto-sub --sub-format srt/best --sub-lang en --embed-subs
</code></pre></div><h2 id="limiting-downloads">Limiting downloads</h2>
<p>When switching to this method, the initial download will pull
<em>all</em> of a channel’s videos. I certainly don’t want this so they should
be limited in some way. <code>--dateafter</code> and <code>--playlist-end</code> serve very
nicely. The former will only download videos published <em>after</em> a certain
date and the latter will only download X number of videos.</p>
<div><pre><code data-lang="bash">--dateafter <span>20200801</span> --playlist-end <span>5</span>
</code></pre></div><h2 id="getting-notifications">Getting notifications</h2>
<p>I don’t yet have a good method for getting notifications when there are
<em>new</em> videos but there is a simple way to get notified when the script
is finished running. <code>notify-send</code> is one of the easiest and has pretty
simple syntax as well: the first string is the notification summary and
the second is a longer description. You can optionally pass an icon
name to make it look a little better.</p>
<div><pre><code data-lang="bash">notify-send -i video-x-generic <span>"Downloads finished"</span> <span>"Check the YouTube folder for new videos"</span>
</code></pre></div><p>For some reason, I don’t get icons when the generic name is specified
but I know the command will work on most systems. On mine, I have to
pass the path to the icon file I want: <code>-i /usr/share/icons/Suru++-Dark/apps/64/video.svg</code></p>
<h2 id="naming-format">Naming format</h2>
<p>The final parameter to look at is how to name the files once they’re
downloaded. <code>--output</code> provides templating functionality and there are a
<em>lot</em> of options. For this use, an acceptable template might be
something like <code>Channel/Title.ext</code>. In youtube-dl’s templating format,
that’s <code>"%(uploader)s/%(title)s.%(ext)s"</code>.</p>
<div><pre><code data-lang="bash">--output <span>"%(uploader)s/%(title)s.%(ext)s"</span>
</code></pre></div><h2 id="writing-the-script">Writing the script</h2>
<p>I want to store the videos in <code>~/Videos/YouTube</code> and I want the archive
records stored in <code>.archives</code> so the first line (after the shebang<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>)
creates those directories if they don’t already exist and the second
enters the <code>YouTube</code> folder.</p>
<div><pre><code data-lang="bash">mkdir -p <span>"</span><span>$HOME</span><span>/Videos/YouTube/.archives"</span>
<span>cd</span> <span>"</span><span>$HOME</span><span>/Videos/YouTube"</span>
</code></pre></div><p>From here, a way to reuse the youtube-dl command is necessary so
parameters can be changed in one place and they’ll apply to all
channels. Functions are intended for exactly this purpose and are
formatted like so:</p>
<div><pre><code data-lang="bash">functionName () {
    <span># Code here</span>
}
</code></pre></div><p>I’ve named the function <code>dl</code> so mine looks like this:</p>
<div><pre><code data-lang="bash">dl () {
    youtube-dl --download-archive .archives/<span>"</span><span>$1</span><span>"</span>.txt -f         <span>\
</span><span></span>        bestvideo+bestaudio --dateafter <span>20200801</span> --write-sub    <span>\
</span><span></span>        --write-auto-sub --sub-format srt/best --sub-lang en    <span>\
</span><span></span>        --embed-subs -o <span>"%(uploader)s/%(title)s.%(ext)s"</span>        <span>\
</span><span></span>        --playlist-end <span>5</span> <span>"</span><span>$2</span><span>"</span>
    sleep <span>5</span>
}
</code></pre></div><p>The backslashes at the end (<code>\</code>) tell bash that it’s a single command
spanning multiple lines. The <code>sleep</code> command just waits 5 seconds before
downloading the next channel. It’s unlikely that YouTube will ratelimit
a residential address for this but it is still possible. Waiting a bit before
continuing reduces the likelihood further.</p>
<p>Note the use of <code>"$1"</code> and <code>"$2"</code> in the archive path and at the very
end of the youtube-dl command. This lets the user define what the archive file
should be named and what channel to download videos from. A line using
the function would be something like:</p>
<div><pre><code data-lang="bash">dl linustechtips https://www.youtube.com/user/LinusTechTips
</code></pre></div><p>The result would be this directory structure:</p>
<div><pre><code data-lang="fallback">YouTube
├── .archives
│&nbsp;&nbsp; └── linustechtips.txt
└── Linus Tech Tips
    └── They still make MP3 players.mkv
</code></pre></div><p>The last line is the notification command:</p>
<div><pre><code data-lang="bash">notify-send -i video-x-generic <span>"Downloads finished"</span> <span>"Check the YouTube folder for new videos"</span>
</code></pre></div><h2 id="finished-script">Finished script</h2>
<p>This the script I have in use right now.</p>
<div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>
mkdir -p <span>"</span><span>$HOME</span><span>/Videos/YouTube/.archives"</span>
<span>cd</span> <span>"</span><span>$HOME</span><span>/Videos/YouTube"</span>

dl () {
    youtube-dl --download-archive .archives/<span>"</span><span>$1</span><span>"</span>.txt -f         <span>\
</span><span></span>        bestvideo+bestaudio --dateafter <span>20200801</span> --write-sub    <span>\
</span><span></span>        --write-auto-sub --sub-format srt/best --sub-lang en    <span>\
</span><span></span>        --embed-subs -o <span>"%(uploader)s/%(title)s.%(ext)s"</span>        <span>\
</span><span></span>        --playlist-end <span>5</span> <span>"</span><span>$2</span><span>"</span>
    sleep <span>5</span>
}

dl ding                 https://www.youtube.com/channel/UClq42foiSgl7sSpLupnugGA
dl meute                https://www.youtube.com/channel/UCY3cAFsquIk7VGMuk-V8S3g
dl vsauce               https://www.youtube.com/user/Vsauce
dl ardour               https://www.youtube.com/channel/UCqeg5vkTkH-DYxmOO9FJOHA
dl pewdiepie            https://www.youtube.com/user/PewDiePie
dl techaltar            https://www.youtube.com/channel/UCtZO3K2p8mqFwiKWb9k7fXA
dl avikaplan            https://www.youtube.com/user/AviKaplanMusic
dl lukesmith            https://www.youtube.com/channel/UC2eYFnH61tmytImy1mTYvhA
dl techlinked           https://www.youtube.com/c/techlinked/
dl robscallon           https://www.youtube.com/user/robs70986987
dl setheverman          https://www.youtube.com/user/SethEverman
dl logosbynick          https://www.youtube.com/channel/UCEQXp_fcqwPcqrzNtWJ1w9w
dl techquickie          https://www.youtube.com/user/Techquickie
dl yanntiersen          https://www.youtube.com/user/YannTiersenOfficial
dl andrewhuang          https://www.youtube.com/user/songstowearpantsto
dl aurahandpan          https://www.youtube.com/user/Jantzulu
dl jamesveitch          https://www.youtube.com/user/james948
dl brandonacker         https://www.youtube.com/user/brandonacker
dl unboxtherapy         https://www.youtube.com/user/unboxtherapy
dl linustechtips        https://www.youtube.com/user/LinusTechTips
dl michaelreeves        https://www.youtube.com/channel/UCtHaxi4GTYDpJgMSGy7AeSw
dl countrysquire        https://www.youtube.com/channel/UCdrw_DN_OmFIic0gTZJDVCQ
dl roomieofficial       https://www.youtube.com/user/RoomieOfficial
dl fridaycheckout       https://www.youtube.com/channel/UCRG_N2uO405WO4P3Ruef9NA
dl lastweektonight      https://www.youtube.com/user/LastWeekTonight
dl bingingwithbabish    https://www.youtube.com/user/bgfilms

notify-send --icon /usr/share/icons/Suru++-Dark/apps/64/video.svg <span>"Downloads finished"</span> <span>"Check the YouTube folder for new videos"</span>
</code></pre></div><h2 id="automation">Automation</h2>
<p>This is a very simple process.</p>
<ol>
<li>Store your script wherever you want but take note of the directory.</li>
<li>Run <code>crontab -e</code>
<ul>
<li>If you don’t already have a cron utility installed, try <code>cronie</code>.
It should be in most repos.</li>
</ul>
</li>
<li>Paste and edit: <code>0 */6 * * * /home/user/path/to/script.sh</code></li>
<li>Save</li>
<li>Exit</li>
<li>???</li>
<li>Profit</li>
</ol>
<p>The pasted line runs the script every 6th hour of every day, every week,
every month, and every year. To change the frequency just run <code>crontab -e</code>, edit the line, and save. <a href="https://crontab-generator.org/">Crontab Generator</a>
or <a href="https://crontab.guru/">Crontab Guru</a> might be useful if the syntax
is confusing.</p>
<p>Have fun!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The <a href="https://github.com/ytdl-org/youtube-dl/commit/4fa74b5252a23c2890ddee52b8ee5811b5bb2987">first commit</a> for the current youtube-dl repository was made on
21 July 2008 and it references “the new youtube-dl”, which suggests
versions prior. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>In the digital media world, muxing is process of combining two or
more files into one. This might be a video track, multiple audio tracks,
and/or subtitle tracks. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>A <em>shebang</em> is a sequence of characters that tell your program
loader what interpreter to use. <code>#!/bin/bash</code> is what you would use if
it’s a bash script. To use a Python interpreter, <code>#!/usr/bin/env python</code>
will use the program search path to find the appropriate executable. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://secluded.site/replacing-youtube-invidious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037075</guid>
            <pubDate>Mon, 03 Aug 2020 12:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim for Pythons Devs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036930">thread link</a>) | @yanis_t
<br/>
August 3, 2020 | https://www.vimfromscratch.com/articles/vim-for-python/ | <a href="https://web.archive.org/web/*/https://www.vimfromscratch.com/articles/vim-for-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>Published</span>
<b>8 months ago. </b>
<span>Edited</span>
<b>4 days ago.</b>
</p><div>
<p>I've been working on a Python project for some time now. In the beginning, it wasn't very comfortable, as I was trying to learn the language and figure out my workflow and the tooling.</p>

<p>After a couple of months, I now finally have a working Vim setup with proper syntax highlighting, smart code completion, and refactoring capabilities. Read on to see what it looks like.</p>

<p><strong>Disclaimer</strong>: My setup may seem like a bit too much. You don't have to install every plugin listed in this article or copy every configuration line. Pick up what you like.</p>

<div>
        <p><img src="https://www.vimfromscratch.com/assets/python-nvim-5b052a50da32ad00fd18421db1199df866b7e0f894556e59ddd4f497ecc00cc4.png" alt="Here's" how="" my="" vim="" looks="" like=""></p><figcaption>Here's How My Vim Looks Like</figcaption>
      </div>
    

<h2>TL;DR:</h2>

<ul>
<li>Basics: <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, <a href="https://github.com/scrooloose/nerdtree">scrooloose/nerdtree</a>, <a href="https://github.com/tpope/vim-commentary">tpope/vim-commentary</a> and <a href="https://github.com/junegunn/fzf.vim">junegunn/fzf.vim</a></li>
<li><a href="https://github.com/numirias/semshi">numirias/semshi</a> is the best for the syntax highlighting</li>
<li><a href="https://github.com/Vimjas/vim-python-pep8-indent">Vimjas/vim-python-pep8-indent</a> for proper indenting</li>
<li><a href="https://github.com/dense-analysis/ale">dense-analysis/ale</a> is an asynchronous linter plugin. Use it with <a href="http://flake8.pycqa.org/en/latest/">flake8</a> and <a href="https://www.pylint.org/">pylint</a>; plus <a href="https://github.com/google/yapf">google/yapf</a> as a formatter.</li>
<li><a href="https://github.com/neoclide/coc.nvim">neoclide/coc.nvim</a> with <a href="https://github.com/neoclide/coc-python">neoclide/coc-python</a> for intellisense code completion</li>
</ul>

<h2>Essentials</h2>

<p>Let's start with a list of some general-purpose plugins which I find irreplaceable for any language.</p>

<ul>
<li><a href="https://github.com/junegunn/vim-plug">vim-plug</a> is a minimalistic plugin manager</li>
<li><a href="https://github.com/scrooloose/nerdtree">scrooloose/nerdtree</a> to navigate the file tree</li>
<li><a href="https://github.com/junegunn/fzf.vim">junegunn/fzf.vim</a> fuzzy search through the files (and much more, really)</li>
<li><a href="https://github.com/tpope/vim-commentary">tpope/vim-commentary</a> ( or <a href="https://github.com/scrooloose/nerdcommenter">scrooloose/nerdcommenter</a> ) — press <code>gcc</code> to comment out a line or <code>gc</code> to comment a selection in visual mode</li>
<li><a href="https://github.com/liuchengxu/vista.vim">liuchengxu/vista.vim</a> which is a "tagbar" that learns from LSP servers</li>
</ul>

<p>The other plugins I use include</p>

<ul>
<li><a href="https://github.com/jeetsukumaran/vim-pythonsense">jeetsukumaran/vim-pythonsense</a> provides some Python-specific text objects: classes, functions, etc</li>
<li><a href="https://github.com/jiangmiao/auto-pairs">jiangmiao/auto-pairs</a> inserts closing quotes and parenthesis as you type</li>
</ul>

<p>The colorscheme used on the screenshots is <a href="https://github.com/joshdick/onedark.vim">joshdick/onedark.vim</a>, which is inspired by the Atom theme.</p>

<h2>Syntax highlighting</h2>

<p>Vim comes with syntax highlighting for many popular languages, including Python, though it is not always the best one.</p>

<p>There are several options to improve the default highlighting.</p>

<ul>
<li><a href="https://github.com/numirias/semshi">numirias/semshi</a>, in my opinion, is the best. It works with Neovim only and requires the Python 3 support.</li>
<li><a href="https://github.com/sheerun/vim-polyglot">sheerun/vim-polyglot</a> includes support for many languages including Python</li>
<li><a href="https://github.com/python-mode/python-mode">python-mode/python-mode</a> is also a decent one although it comes with a lots of other stuff beside highlighting which I don't quite like</li>
</ul>

<div>
        <p><img src="https://www.vimfromscratch.com/assets/python-hl-3425e6874afcb201c0229566d9e763bdde60341146579dfc193f083b953c979b.png" alt="Semshi" (on="" the="" left)="" vs.="" default="" one=""></p><figcaption>Semshi (on the left) vs. the default one</figcaption>
      </div>
    

<p>My favorite color schemes (which I switch quite often) include <a href="https://github.com/junegunn/seoul256.vim">junegunn/seoul256.vim</a> and <a href="https://github.com/joshdick/onedark.vim">joshdick/onedark.vim</a> (the one on the screenshots).</p>

<h2>Indentation</h2>

<p>You can set up indentation rules manually like this.</p>

<pre><code>au BufNewFile,BufRead *.py
    \ set expandtab       |" replace tabs with spaces
    \ set autoindent      |" copy indent when starting a new line
    \ set tabstop=4
    \ set softtabstop=4
    \ set shiftwidth=4
</code></pre>

<p>A better alternative is <a href="https://github.com/Vimjas/vim-python-pep8-indent">Vimjas/vim-python-pep8-indent</a> plugin. It does a much better job complying with the <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a> style guide.</p>

<h2>Folding</h2>

<p>Folding (<code>:help foldmethod</code>) is when you collapse chunks of code to eliminate distraction.</p>

<p>The best approximation is to use the folding method <code>indent</code> though it doesn't work ideally.</p>

<pre><code>au BufNewFile,BufRead *.py \
  set foldmethod=indent
</code></pre>

<p>To toggle a fold you can press <code>za</code> (<code>:help fold-commands</code>), and I have it mapped to <code>Space</code> for convenience.</p>

<pre><code>nnoremap &lt;space&gt; za
</code></pre>

<h2>Linting &amp; Fixing</h2>

<p>The fantastical <a href="https://github.com/dense-analysis/ale">dense-analysis/ale</a> plugin can be used for linting (which essentially means checking for syntax errors) and auto-fixing extremely well. It's asynchronous, meaning that it won't block the UI while running an external linter, and it supports <a href="https://github.com/dense-analysis/ale/blob/master/supported-tools.md">a great range of languages</a> and tools.</p>

<div>
        <p><img src="https://www.vimfromscratch.com/assets/python-ale-ca3f922e83aa4ea767326a1ba41412709c10ba0d09b3884230ef4d0a2489b7da.png" alt="Python" +="" ale="❤️"></p><figcaption>Python + ALE = ❤️</figcaption>
      </div>
    

<p>ALE highlights problems with your code in the gutter. When you move the cursor to the problematic line, it shows the full error message at the bottom of the screen.</p>

<p>By default, ALE will use all linters (which are just executables) it could find on your machine. Run <code>:ALEInfo</code> to see which linters are available and which are enabled.</p>

<p>It is better though to explicitly specify which ones you're going to use with a particular filetype:</p>

<pre><code>let g:ale_linters = {
      \   'python': ['flake8', 'pylint'],
      \   'ruby': ['standardrb', 'rubocop'],
      \   'javascript': ['eslint'],
      \}
</code></pre>

<p>Some of the linters are also capable of fixing the problems in your code. ALE has a special command <code>:ALEFix</code> that fixes the whole file. So far, I'm only Google's <a href="https://github.com/google/yapf">YAPF</a> as a fixer that formats the whole file when I press <code>F10</code> or save the current buffer.</p>

<pre><code>let g:ale_fixers = {
      \    'python': ['yapf'],
      \}
nmap &lt;F10&gt; :ALEFix&lt;CR&gt;
let g:ale_fix_on_save = 1
</code></pre>

<p>The last option is a huge time saver — it will automatically fix (and thus format) your file on save.</p>

<p>I also have a little piece of configuration that shows the total number of warnings and errors in the status line. Very convenient.</p>

<pre><code>function! LinterStatus() abort
  let l:counts = ale#statusline#Count(bufnr(''))

  let l:all_errors = l:counts.error + l:counts.style_error
  let l:all_non_errors = l:counts.total - l:all_errors

  return l:counts.total == 0 ? '✨ all good ✨' : printf(
        \   '😞 %dW %dE',
        \   all_non_errors,
        \   all_errors
        \)
endfunction

set statusline=
set statusline+=%m
set statusline+=\ %f
set statusline+=%=
set statusline+=\ %{LinterStatus()}
</code></pre>

<p>And here are a couple of alternatives to ALE:</p>

<ul>
<li><a href="https://github.com/vim-syntastic/syntastic">vim-syntastic/syntastic</a> very popular one but synchronous which can cause significant lags in UI</li>
<li><a href="https://github.com/neomake/neomake">neomake/neomake</a> asynchronous linting and make framework for Neovim/Vim (didn't try that one)</li>
</ul>

<h2>Jedi</h2>

<p><a href="https://github.com/davidhalter/jedi">Jedi</a> is a "language server" (see <a href="https://www.vimfromscratch.com/articles/vim-and-language-server-protocol/">my LSP article</a>), a separate process running in the background and analyzing your code.</p>

<p>Other clients (editors or IDEs) can connect to the server and request some information, like completion options, or "go to definition" coordinates.</p>

<p>Basically, Jedi is an IDE as a service, without the GUI.</p>

<p>In order to use it, you need to install it with <code>pip install jedi</code>, and then also add a client. The <a href="https://github.com/davidhalter/jedi">davidhalter/jedi</a> Vim plugin does a good job.</p>

<p>Here's what it can do:</p>

<ul>
<li>Press <code>ctrl + space</code> for the completion options</li>
<li><code>&lt;leader&gt;d</code> goes to definition</li>
<li><code>&lt;leader&gt;g</code> goes to assignment</li>
<li><code>K</code> shows the documentation</li>
<li>and more</li>
</ul>

<p>Recently I have switched to <a href="https://github.com/neoclide/coc.nvim">neoclide/coc.nvim</a> and <a href="https://github.com/neoclide/coc-python">coc-python</a>. Coc is an "an intellisense engine" for Vim and Neovim and does a really good job when it comes to completion and communicating with language servers.</p>

<h2>Coc (Conquer of Completion)</h2>

<p>To me, the selling point is the usage of the new <code>floating window</code> API of Neovim, which makes it very convenient.</p>

<p><code>Coc-python</code> can use both Jedi and the Microsoft's Python Language Server. The first time you run it, it will ask you to install the components it needs (like a linter).</p>

<p>Coc provides (with the help of Jedi) some basic IDE capabilities like</p>

<ul>
<li>Going To definition</li>
</ul>

<pre><code>nmap &lt;silent&gt; gd &lt;Plug&gt;(coc-definition)
</code></pre>

<ul>
<li>Displaying documentation (in the floating window!)</li>
</ul>

<pre><code>nnoremap &lt;silent&gt; K :call &lt;SID&gt;show_documentation()&lt;CR&gt;
function! s:show_documentation()
  if (index(['vim','help'], &amp;filetype) &gt;= 0)
    execute 'h '.expand('&lt;cword&gt;')
  else
    call CocAction('doHover')
  endif
endfunction
</code></pre>

<ul>
<li>Smart rename (renames the exports across all files)</li>
</ul>

<pre><code>nmap &lt;leader&gt;rn &lt;Plug&gt;(coc-rename)
</code></pre>

<p>And of course the auto-complete menu (which you can see on the very first screenshot) appears as you type.</p>

<p>Basically, it's a very solid and comprehensive plugin which covers almost all of our needs.</p>

<p><a href="https://github.com/neoclide/coc.nvim/wiki">Read to the wiki</a> for more information about its capabilities.</p>

<p>The 2 drawbacks of using Coc are:</p>

<ul>
<li>An expensive Node process that Coc needs to run in order to operate</li>
<li>It has its own independent extension system and its own (JSON-based) configuration file. Not a Vim-way.</li>
</ul>

<p>Still, it does the job well, and I continue using it (until there's a better option).</p>

<h2>Where to go next?</h2>

<p>Here are some other articles I learned from a lot:</p>

<ul>
<li><a href="https://realpython.com/vim-and-python-a-match-made-in-heaven/">VIM and Python – A Match Made in Heaven</a></li>
<li><a href="https://stackabuse.com/vim-for-python-development/">Vim for Python Development</a></li>
<li><a href="https://dev.to/bezirganyan/editor-wars-vim-as-a-perfect-python-ide-19ne">Editor Wars: VIM as a perfect Python IDE</a></li>
</ul>

<p>And some more articles in the similar vein from this website:</p>

<ul>
<li><a href="https://www.vimfromscratch.com/articles/vim-for-ruby-and-rails-in-2019/">Vim for Ruby and Rails in 2019</a></li>
<li><a href="https://www.vimfromscratch.com/articles/vim-for-javascript-and-react-in-2019/">Vim for JavaScript and React in 2019</a></li>
</ul>

<p>And...</p>

<ul>
<li><a href="https://twitter.com/janis_t">Follow me on Twitter</a> ;)</li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.vimfromscratch.com/articles/vim-for-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036930</guid>
            <pubDate>Mon, 03 Aug 2020 12:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analytics couldn’t get past 2013, it’s time to change that- A Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036653">thread link</a>) | @hockeystack
<br/>
August 3, 2020 | https://hockeystack.com/manifesto | <a href="https://web.archive.org/web/*/https://hockeystack.com/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hey founders,</p><p>I am sorry to talk harsh but someone&nbsp;<b>had</b>&nbsp;to do it.</p><p>We are hustlers. We love freedom and passionate about our businesses.</p><p>We are doing everything we can to solve a problem, make people happy, and earn their trust.</p><p>We are in this to <b>make a difference</b>, to <b>leave a legacy behind</b>, and <b>to be happy</b>.</p><p>Thanks to our businesses, thousands of people are solving a problem, a problem that has been a pain point before us.</p><p>I am so grateful for this amazing community, to the things I learned from it, and to the friends I made.</p><p>To grow our businesses we hustle a lot which is invaluable from my perspective.</p><p>Aside from all the hustle, we have to use analytics to grow and scale our businesses. But the world of user analytics is built upon false premises and unfullfilled assurances my hustler friends:</p><p><b>Hey google analytics users,</b> it’s 2020 and you still need to manually ga(‘send’) everything</p><p><b>Hey fathom/plausible/simple-analytics users</b>, it’s 2020 and you can only see your referrers on your dashboard</p><p><b>Hey everyone who needs analytics,</b> it’s 2020 and you still have to do everything manually. The tools you pay for don’t give you enough data or make you work for it. The tools you don’t pay for harvest each data point and send it to 3rd parties.</p><p>Huh, in the age of artificial intelligence and literal flying cars, Mixpanel can still write that 10-30 hours of development time to track 60 events is a huge achievement, and funnily, get away with it.</p><p>HockeyStack is an analytics tool <b>delivered to you by another hustler</b> who struggled to understand his data with other tools. Let me tell you the differences between other tools and HockeyStack in two parts:</p><p>HockeyStack is different from simple data tools because they don't analyze your data <b>in-depth</b>. It is the main reason why they call themselves 'simple'.</p><p>On the other hand, we call our dashboard <b>easy to understand</b> because we present an in-depth analysis of your data on an easy-to-understand dashboard.</p><p>Tools like Mixpanel, Hotjar are great. However, you need to set up .track() functions and need coding skills to analyze your data.</p><p>Then you also need to spend a lot of time on your dashboard to understand what is going on there.</p><p>I hope you find HockeyStack useful and each one of you can achieve the <b>surging growth</b> with it.</p><p>Greetings to all hustlers,</p><p><em>Michael</em></p><p><a href="https://hockeystack.com/">Get Started</a></p></div></div>]]>
            </description>
            <link>https://hockeystack.com/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036653</guid>
            <pubDate>Mon, 03 Aug 2020 12:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Monthly – What happened last month?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036501">thread link</a>) | @evantai
<br/>
August 3, 2020 | https://zerotomastery.io/blog/python-monthly-july-2020 | <a href="https://web.archive.org/web/*/https://zerotomastery.io/blog/python-monthly-july-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>8th issue! **If you missed the previous ones, <a href="https://zerotomastery.io/blog/?tag=PM">you can read the previous issues of the Python Monthly newsletter here</a>.</strong></p>
<h3>If it’s your first time here… (otherwise, skip this part)</h3>
<p>Being a Python developer is a fantastic career option. Python is now the most popular language with lots of growing job demand (especially in the fields of Web, Data Science and Machine Learning). You have many job opportunities, you can work around the world, and you get to solve hard problems. One thing that is hard, however, is staying up to date with the constantly evolving ecosystem. You want to be a top-performing python developer, coder, programmer, software developer, but you don’t have time to select from hundreds of articles, videos and podcasts each day.</p>
<p>This monthly newsletter is focused on keeping you up to date with the industry, keeping your skills sharp, without wasting your valuable time. I will be sharing the most important articles, podcasts and videos of the month. Think <a href="https://tim.blog/about" target="_blank" rel="nofollow">Tim Ferriss</a> and <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank" rel="nofollow">the Pareto Principle</a> (80/20 rule) meeting the Software Development world. What’s the 20% that will get you 80% of the results?</p>
<center><strong>If you want to be the first to get next month's issue of Python Monthly and receive other exclusive ZTM content once in a while, subscribe below 👇</strong></center>

<h3>What you missed in July as a Python Developer…</h3>
<hr>
<h3>Python <code>reduce()</code> 🧿</h3>
<p>The reduce function is one of the most useful tools you have as a programmer. Although it can be hard to understand at times, by using the reduce function you can implement a lot of useful things like <code>map()</code>, <code>filter()</code> and much much more. <a href="https://realpython.com/python-reduce-function/" target="_blank" rel="nofollow">Here is a tutorial to show you its functional powers</a>.</p>
<h3>Subprocess Genie ⛲️</h3>
<p>Python Subprocess just sounds like something cool you would hear a hacker on TV say. However, this is actually a useful skill and something you can do quite easily in Python to take advantage of extra CPU power or to run an App inside of another app. <a href="https://www.blog.pythonlibrary.org/2020/06/30/python-101-launching-subprocesses-with-python/" target="_blank" rel="nofollow">Here is how to do it</a>. </p>
<h3>Distributed Python With Fiber 🎳</h3>
<p>One of the biggest changes lately in the Python landscape is the move towards distributed computing to take advantage of the power of multiple machines. However, this is a hard thing to do and many tools and libraries are being developed to make distributed computing easier with Python. <a href="https://eng.uber.com/fiberdistributed/" target="_blank" rel="nofollow">One of the new kids on the block is Fiber</a> from Uber. Just read the introduction part of this article if you want to get an overview of the problem it solves. </p>
<h3>Python Quiz 📋</h3>
<p>Pop quiz for you: What is the most efficient way to remove half of the duplicate items in a list. For example to go from <code>l = [1, 8, 8, 8, 1, 3, 3, 8]</code> to <code>k=[1,8,8,3]</code>. Try to figure it out on your own before you check out the solution <a href="https://stackoverflow.com/questions/62793544/efficient-way-to-remove-half-of-the-duplicate-items-in-a-list" target="_blank" rel="nofollow">here</a>.</p>
<h3>Everything About OOP 🤹‍♀️</h3>
<p>Object Oriented Programming sometimes gets a bad rep, but it is a very useful programming paradigm that has stood the test of time. <a href="https://realpython.com/python3-object-oriented-programming/" target="_blank" rel="nofollow">Here is a tutorial</a> on how to do OOP and also how to make your code cleaner and more efficient using this programming paradigm. </p>
<h3>Weekend Project Idea 🎏</h3>
<p>This is a project that will surely <em>wow</em> your future employers. Create an application to find restaurants with the help of food images you have. You will also learn how to work with IBM Watson for Visual Recognition and use location services for maps and location analytics. <a href="https://developer.here.com/blog/visual-recognition-with-ibm-watson-here-and-python-part-1" target="_blank" rel="nofollow">Here is the project walkthrough</a>.</p>
<h3>New Python Extension On VS Code 🔋</h3>
<p><a href="https://devblogs.microsoft.com/python/announcing-pylance-fast-feature-rich-language-support-for-python-in-visual-studio-code/" target="_blank" rel="nofollow">Another feature rich VS Code extension</a> when you are writing Python. There are lots of these around, but this looks to be a promising one for one of the most popular editors. </p>
<h3>YouTube Data Analysis 🎥</h3>
<p>A great overview of how to collect and analyze data to produce meaningful insights. Something you can do really well within the Python ecosystem. <a href="https://ammar-alyousfi.com/2020/youtube-trending-videos-analysis-2019-us" target="_blank" rel="nofollow">This is also a fun project for you to follow along and discover new insights</a>. The big takeaway? If you want your YouTube video to trend, make sure you have a person in the thumbnail.</p>
<h3>All About Python Memory 🤖</h3>
<p>Two articles to really dive deep into how memory management works in Python. </p>
<ol>
<li><a href="https://pythonspeed.com/articles/function-calls-prevent-garbage-collection/" target="_blank" rel="nofollow">How Python function calls can increase your memory usage</a></li>
<li><a href="https://pythonspeed.com/articles/python-integers-memory/" target="_blank" rel="nofollow">How NumPy helps numbers memory in Python</a>. By the way, <a href="https://pabloinsente.github.io/intro-numpy-fundamentals" target="_blank" rel="nofollow">here is a massive free tutorial on NumPy</a>. Why should you care? It's one of the most used python libraries in the world. </li>
</ol>
<h3>PEP622 - Pattern Matching 🎰</h3>
<p><a href="https://ncik-roberts.github.io/posts/pep622.html" target="_blank" rel="nofollow">New PEP proposal</a> brings Python in-line with many other modern programming languages, like Haskell, OCaml, and Rust. It is a useful feature that will allow you to search/match strings. </p>
<h3>Favourite Data Structure 🥇</h3>
<p>What is your favourite Data Structure? Wait, you don't have one? Don't look at me with those crazy eyes. Everyone should have a favourite data structure. Mine is a Hash Table or in the case of Python, Dictionaries. <a href="https://akshayr.me/blog/articles/python-dictionaries" target="_blank" rel="nofollow">Here is why it's such a useful tool</a> in any programming language arsenal. </p>
<h3>Python Malware On The Rise 🦂</h3>
<p><em>"The vast majority of serious malware over the past 30 years has been written in Assembly or compiled languages such as C, C++, and Delphi. However, ever-increasing over the past decade, a large amount of malware has been written in interpreted languages, such as Python. The low barrier to entry, ease of use, rapid development process, and massive library collection has made Python attractive for millions of developers - including malware authors."</em> I guess it's part of being the popular language on the block. <a href="https://www.cyborgsecurity.com/python-malware-on-the-rise/" target="_blank" rel="nofollow">Check out the full analysis here</a>.</p>
<h3>News Around the World 🗺</h3>
<ul>
<li>Unsecured MongoDB and Elastic Search databases are a common thing. This is because they have unsecured defaults and a programmer/administrator needs to enable those safety features. <a href="https://www.bleepingcomputer.com/news/security/new-meow-attack-has-deleted-almost-4-000-unsecured-databases/" target="_blank" rel="nofollow">Well, somebody</a> created a program to delete all those unsafe instances to force people to secure these databases better. </li>
<li><a href="https://www.reuters.com/article/us-australia-media-regulator/australia-to-make-facebook-google-pay-for-news-in-world-first-idUSKCN24V3UP" target="_blank" rel="nofollow">Australia is making Facebook and Google</a> pay for the news that they display on their search results from Australian companies. An interesting move that may effect what other countries do with news in the future. </li>
</ul>
<h3>Big Tech News 🏢</h3>
<ul>
<li>Apple, Google, Facebook, and Amazon are all getting questioned for anti trust. <a href="https://www.vox.com/recode/2020/7/29/21345856/big-tech-hearings-theater-amazon-apple-facebook-google" target="_blank" rel="nofollow">Keep an eye on this</a>.</li>
<li>Twitter <a href="https://arstechnica.com/information-technology/2020/07/twitter-lost-control-of-its-internal-systems-to-bitcoin-scamming-hackers/" target="_blank" rel="nofollow">got hacked big time this month</a> through some silly security practices that they had internally. The hackers? <a href="https://www.zdnet.com/article/how-the-fbi-tracked-down-the-twitter-hackers/" target="_blank" rel="nofollow">A bunch of teenagers</a>. </li>
<li>An interesting article on why <a href="https://blog.anylist.com/2020/06/sign-in-with-apple/" target="_blank" rel="nofollow">this company</a> isn't interested in implementing Sign in With Apple. But the big news out of Apple this month was their move to AMD chips for their laptops. <em>"We’re about to enter an exciting, messy transition. Not only will Apple Silicon make better Macs, it will force Microsoft to polish its Windows on ARM act, both hardware and software. In turn, this will cause PC OEMs to reconsider their allegiance to x86 silicon… and that will have serious consequences for the old Wintel partnership."</em> <a href="https://mondaynote.com/apple-silicon-the-passing-of-wintel-79a5ef66ad2b" target="_blank" rel="nofollow">Check out the explanation of what this means here</a>.</li>
<li>Barclays was caught <a href="https://twitter.com/immunda/status/1278783894683336704" target="_blank" rel="nofollow">using the internet archive as a CDN</a> <em>(bad because they make enough money to not use a non profit's servers for free).</em></li>
<li>Facebook's SDK for iOS crashed a bunch of apps <em>(a lot of big apps)</em> again and <a href="https://github.com/facebook/facebook-ios-sdk/issues/1427" target="_blank" rel="nofollow">people were not happy</a>.</li>
<li>Do you feel like you are unqualified for a job? <a href="https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP" target="_blank" rel="nofollow">IBM is hiring people with 12+ years of Kubernetes experience</a>. Fun fact, K8s came out in 2014.</li>
<li><a href="https://techcrunch.com/2020/07/13/google-to-invest-10-billion-in-india" target="_blank" rel="nofollow">Google is investing $10 billion in India</a>. Lots of big companies moving assets into the booming Indian tech scene lately. Speaking of Google, they are now doing online certificate programs and offering <a href="https://www.cnbc.com/2020/07/13/google-announces-certificates-in-data-project-management-and-ux.html" target="_blank" rel="nofollow">100,000 scholarships</a>. This is a positive trend that hopefully more and more companies will adopt (most people in the world can't afford to pay $100,000 for a fancy CS Degree, nor do you need it to be a great programmer). Maybe soon Google will announce their scholarship program for <a href="https://zerotomastery.io/academy">ZTM Academy Memberships</a> 😁!</li>
</ul>
<h3>Completely useless to your career but still great 🙃</h3>
<p><a href="https://arstechnica.com/gadgets/2020/06/boston-dynamics-robot-dog-can-be-yours-for-the-low-low-price-of-74500/" target="_blank" rel="nofollow">You can now buy a Boston Dynamics dog robot</a> and program it yourself. Guess what language? That's right, Python. Guess how much it costs? Only $74,500.</p>
<p>Do you know what Quine is? 99.99% of people don't. But you can be part of the select few that can explain it and pretend like you're a genius. <a href="https://www.youtube.com/watch?v=a-zEbokJAgY" target="_blank" rel="nofollow">Self Replicating Python Code</a>. </p>
<h3>Best Resource of the Month 🥽</h3>
<p>A higher level of abstraction. We hear this phrase quite often in our industry. Do you fully understand it? What exactly is abstraction and why is it a useful concept when it comes to programming? Can abstractions be good and bad? This was my favourite article this month discussing this very important topic. <a href="https://jesseduffield.com/beginners-guide-to-abstraction/" target="_blank" rel="nofollow">Enjoy the read</a>.</p>
<p>Ok, I have to share 2 things this month that I loved because <a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to" target="_blank" rel="nofollow">this one is just as good</a>. The takeaway? Write code that is easy to delete.</p>
<p>I lied. There are 3 articles for this month. It kind of ruins the whole point of this section, but all 3 of these articles are tied for the top spot this month. What should you do to succeed during a technical interview? <a href="https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky" target="_blank" rel="nofollow">This is one of the best pieces I have read on the topic</a>.</p>
<h3>Bonus Resource: Python Cheat Sheet 📑</h3>
<p>Since we're best friends by now, you probably already know about this free <a href="https://zerotomastery.io/courses/python/cheatsheet" target="_blank" rel="nofollow">Python Cheat Sheet</a>. But just in case, it's a handy little page to bookmark (or you can download it as a PDF) for both beginners and experts.</p>
<h3>Trick of the Month 🎩</h3>
<p><img src="https://media.giphy.com/media/vQqeT3AYg8S5O/giphy.gif"></p>
<ul>
<li>Next time you write a book, <a href="https://3d-book-css.netlify.app/" target="_blank" rel="nofollow">use this</a>.</li>
</ul>
<p>See you next month everyone!</p>
<br>
<hr>
<p><strong>If you haven't already, subscribe below to receive Python Monthly next month along with exclusive ZTM posts and offers. If you're already subscribed, please share it with someone (use those little widgets on the left) who might find it useful, they'll love you and so will we!</strong></p>

<hr>

<p>By the way, my full time job is to teach people to code in the most efficient way possible as the Lead Instructor of <a href="https://zerotomastery.io/academy">Zero To Mastery Academy</a>. You can see a few of my courses below or see all of my courses by visiting the <a href="https://zerotomastery.io/courses">courses page</a>.</p></div></div>]]>
            </description>
            <link>https://zerotomastery.io/blog/python-monthly-july-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036501</guid>
            <pubDate>Mon, 03 Aug 2020 11:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plain Text Emails, Please (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036437">thread link</a>) | @bradley_taunt
<br/>
August 3, 2020 | https://uglyduck.ca/plain-text-emails-please/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/plain-text-emails-please/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <p>September 9, 2019</p>
            
<p>When it comes to website / product design and development most devs should try to keep things simple. By only using as much code as absolutely necessary, projects avoid growing out of scope or becoming bloated. So, why isn’t this same approach taken for email?</p>



<h2 id="a-brief-history-of-email">A brief history of email</h2>



<p>Email has been possible since the 1960s with <a href="https://en.wikipedia.org/wiki/Time-sharing">time-sharing computers</a> being used to share files and messages across early devices. Around the 80s and 90s it seemed as though <a href="https://en.wikipedia.org/wiki/Government_Open_Systems_Interconnection_Profile">GOSIP</a> would dominate the market, but this was knocked out in favor of SMTP, POP3 and IMAP in 1995 when the <a href="http://www.walthowe.com/navnet/history.html">National Science Foundation ended its sponsorship of the Internet backbone</a>, and all traffic relied on commercial networks.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/6/68/Timesharing_and_Development_KA-10s_at_BBN%2C_circa_1970.jpg" alt="First computers to send and receive email"><figcaption>The first computers to send and receive email. Source: <a href="https://en.wikipedia.org/wiki/File:Timesharing_and_Development_KA-10s_at_BBN,_circa_1970.jpg">Wikipedia</a></figcaption></figure>



<p>Things were looking pretty good at this point. Most operating systems now had a shared foundation of sending and receiving emails on the internet, allowing for a set of standards to be slowly developed and agreed upon over time. These were simpler times, with the default content sent between machines being plain text. No embedded images, no CSS3 fallback support, no <em>fluff</em> – just content.</p>



<p><strong>Sidenote:</strong><br>Now, I’m not going to sit here and pretend to be some expert on the history of email (or the internet in general), so I suggest you take the time to read about <a href="http://www.walthowe.com/navnet/history.html">the history of the internet</a> if you’re into that kind of thing.</p>



<h2 id="looking-at-some-data">Looking at some data</h2>



<section>
<h3>Data isn’t everything</h3>
<p>I understand that the data being used is currently 16 years old – but not many extensive research studies have been performed (specifically for email-type preference in general)</p>
</section>



<p>In 2002<sup>[<a href="#1">1</a>]</sup>, <a href="https://www.clickz.com/real-world-email-client-usage-the-hard-data/47429/">a small-set survey was run by ClickZ</a> was created to gauge the details of personal email data. The main data we will focus on is the user preference between HTML or plain text formats:</p>



<p><strong>Do you prefer receiving HTML or text email?</strong></p>



<figure><table><thead><tr><th>Response</th><th>Percentage (%)</th></tr></thead><tbody><tr><td>HTML</td><td>41.95</td></tr><tr><td>Plain Text</td><td>31.52</td></tr><tr><td>No Preference</td><td>26.53</td></tr></tbody></table></figure>



<p>On initial review, one could make the argument that the general public <em>prefers</em> HTML email over plain text (~42% vs ~32%) – but I would disagree with this analysis. The ~27% of respondents who answered with <em>No Preference</em> should not be dismissed so easily.</p>



<p>Since the <em>No Preference</em> respondents don’t care whether emails they receive are designed in HTML format, why not send them plain text variations by default? The positives of plain text greatly outweigh those of HTML:</p>



<ul><li>Plain text has reduced file size
<ul>
<li>Don’t forget that many users have limited data usage across much of the world</li>
</ul>
</li><li>HTML is more likely to be flagged as spam by email clients
<ul>
<li>This is due to extra code, tracking scripts, 3rd party assets / resources being called</li>
</ul>
</li><li>HTML / CSS can be inconsistent or even limited in support across email clients</li><li>Text only requires less design work for your development team
<ul>
<li>Don’t forget about testing all the various email clients too</li>
</ul>
</li></ul>



<p>Add to this that <a href="https://litmus.com/blog/53-of-emails-opened-on-mobile-outlook-opens-decrease-33">53% of emails are opened on mobile</a> – so any “fancy” marketing email designs need to look great on mobile screens and also take into account slower connections. What looks better and loads faster than simple plain text?</p>



<h2 id="but-what-about-marketing">But what about marketing!?</h2>



<p>Sorry to say, but marketing should never trump user experience. Teams love to track email opens / click ratios, who subscribed / unsubscribed or who shared the campaign with others – but <strong>it’s all bloat on the user’s end</strong>.</p>



<p>Greg Kogan wrote up a great article / case study about his experience <a href="https://www.gkogan.co/blog/dont-design-emails/">switching over a client’s campaign from HTML templates to plain text</a> with some really interesting results. I highly recommend you give it a read for a better understanding about how the marketing goals and customer goals don’t always align.</p>



<h2 id="simple-or-lazy---it-doesnt-matter">Simple or lazy – it doesn’t matter</h2>



<p>Plain text can certainly have a reputation for looking lazy or cheap, but I feel this is mostly perpetuated in the design and marketing communities. I can assure you that your average day-to-day users are much less opinionated about your email campaign design than you are. Look to satisfy your customers’ needs before your own.</p>



<blockquote><p>Life is really simple, but we insist on making it complicated.</p><cite>Confucius</cite></blockquote>



<p>That being said, at the end of the day, companies will justify their own reasons to use HTML email templates over plain text. You can’t convince everyone. My own personal experience with email template design, along with analyzing some of the data, leaves me to believe that most businesses should default to plain text. At the very least, you should try to convince your team to perform some simple A/B testing with your next email campaign.</p>



<p>The results might just surprise you.</p>



<p><small><br><b id="1">1</b>: This is the “latest” detailed survey I could find on email design preference<br><small></small></small></p>
            <br>
<hr>
<h2>Comments</h2>
    <p>No comments (yet)</p>

	<!-- #respond -->
	        </article></div>]]>
            </description>
            <link>https://uglyduck.ca/plain-text-emails-please/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036437</guid>
            <pubDate>Mon, 03 Aug 2020 11:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dan Ariely and Irrational Comparison]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24036403">thread link</a>) | @brendancahill
<br/>
August 3, 2020 | https://brendancahill.io/brensblog/danariely | <a href="https://web.archive.org/web/*/https://brendancahill.io/brensblog/danariely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-124866fbd20ff6e682de"><div><h4>Who is Dan Ariely?</h4><p>Dan Ariely is a Professor of Psychology and Behavioral Economics at Duke University whose writing merges psychology with economics. His book <a href="https://amzn.to/33pw3lh"><em>Predictably Irrational</em></a> explores why most of the smart decisions we think we make are actually quite irrational. Modern economics is based on the theory that the average person makes logical decisions. Ariely happily points out how wrong that notion is. </p><h4>Why Now?</h4><p>Comparison has always fascinated me. I grew up in Airmont, NY two minutes over the state line with Upper Saddle River, NJ. Since I didn’t like paying .50 more cents for gas, nor pumping it, I always got gas in NJ. Upper Saddle River is one of the wealthiest towns not only in America, but on the planet. The second you crossed the NY/NJ line it was like you were transported into an alternate reality where the worst car anyone drove was a BMW, every home a mansion and even the air smelled better (just kidding but I did wonder, if any town had the money to endlessly pump fabreeze into the air, they did). </p><p>When I crossed the NY/NJ state line back to my neighborhood of 3 bedroom raised ranches I felt poor by comparison. Then as a US Peace Corps Volunteer living in Ukraine in an ex-Soviet country, ridden with corruption, and the average salary being less than $100/mo I suddenly felt rich. Ukrainians were shocked that we owned two cars. That we had roads that worked. And that everyone was rich <em>to them. </em></p><h4>Why Comparison?</h4></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596450590223_8104"><div><p>Ariely uses this illustration to make his point about comparison. Which orange circle <em>appears</em> bigger? You’d likely say the one on the right, at least at first. But, both circles are the same size. The only thing that’s changed is what you’re comparing them to. Comparison depends on context. </p><blockquote><p>“…we are always looking at the things around us in relation to others…We always compare jobs with jobs, vacations with vacations, lovers with lovers and wines with wines.”</p></blockquote><p>Comparison is a survival skill that’s served us well our first 50 million years as a species: You need to know your status in the tribe compared to others’ to ensure your own safety. You need to compare how deadly a particular tiger looks compared to other live tigers you’ve seen in wild to assess your threat level. You need to compare how someone looks to other angry people you’ve seen to avoid a bar fight. You need to compare a date to other people you’ve dated in the past to evaluate how they might be as a future spouse for you. You need to know how to compare how fast your car is going relative to all the other cars on the street to stay within the speed limit. </p><p><strong>Comparison does hijack our rationality, however. </strong></p><h4>The Economist</h4><p>Ariely was trying to figure out what decision people made when given these three options for a subscription to <em>The Economist</em>: </p><ul data-rte-list="default"><li><p>59/yr online only</p></li><li><p>125/yr print only</p></li><li><p>125/yr print and online together</p></li></ul><p>Out of 100 people here is how many chose which options:</p><ul data-rte-list="default"><li><p>59/yr online only (16)</p></li><li><p>125/yr print only (0)</p></li><li><p>125/yr print and online together (84)</p></li></ul><p>But, when Ariely removed the print only option, here is what people chose:</p><ul data-rte-list="default"><li><p>59/yr online only (68)</p></li><li><p>125/yr print and online together (32)</p></li></ul><p><em>As a business, you want to nudge as many people to the high-end of your sales as possible. So why were people opting for the online only? </em></p><p>It turns out it is easier to compare things that are alike than are not alike. By presenting people with not one but <em>two</em> print options, you’ve now made it easier for them to compare two options that you, as a business, want them to focus on. The mind has now written-off the online only option because that is the hardest option to compare to the other two. </p><p>Inside the mind of your potential customer is now a simple question: What’s better? Print only or print AND an online subscription? Everyone in the first experiment opted for the “print + online” because isn’t print plus a little something extra better? </p><p><strong>We Can’t Make Decisions In A Vacuum</strong></p><p>The second case study Ariely looks at is <a href="https://journals.sagepub.com/doi/pdf/10.2307/41166755">Williams-Sonoma’s inability to sell a $275.00 bread baker</a>. Their marketing team finally figured out that if they created a second, bigger and even more expensive bread baker placed <em>next to</em> the $275.00 dollar one, their sales would take off. And they did. </p><blockquote><p>“…people didn’t have to make their decision in a vacuum. They could say: “Well, I don’t know much about bread makers, but I do know that if I were to buy one, I’d rather have the smaller one for less money.”</p></blockquote><p>Ariely then goes on to joke that if you want to have better luck socially finding someone to date you, you should find a decoy friend of similar physical characteristics but who is slightly less attractive than you. Although the morality of this is questionable. </p><p>If you are a business, the takeaway is simple: to make more profit, create a favorable context for the product you want your customer to buy. Create an ultra-premium ridiculously high-priced product that when placed next to the product you really want to sell, makes its price not seem so bad. </p><p>Tesla knows not everyone is paying $100K + for their Cyber Truck, but they do know that by having their ridiculous premium products, it makes the $60K price tag for their “lower models” not seem so crazy. </p><p><strong>Place vs. Person</strong></p><p>I have some of the best friendships I’ve had from my former football teammates. We go through experiences, games, high and lows like few others friend groups might. But would we all have been friends were it not for football? How about military veterans who are bonded together in combat - were it not for that experience, would they have chosen to be friends? </p><p>Ariely uses the example of meeting a fellow American in a foreign place and finding an uncanny connection in an airport. He met one fellow American overseas:</p><blockquote><p>…as cultural outsiders we were each other’s best alternative for companionships. But once we returned home to our beloved American families and friends, thebasis for comparison switched back to “normal” mode. </p></blockquote><p>Would that foreign exchange student you dates in high school have been as “cool” or “exotic” had they been from Germantown, PA instead of Germany? Was that experience teaching overseas in Peace Corps really <em>that</em> cool or am I just assigning extra romanticism to it because I was an “outsider” in a foreign land?</p><h4>Takeaways</h4><p>We’re very smart, but we’re also very irrational as people. We’d like to think logic and rationality governs most of our lives but Ariely has a knack for showing us just how reliant we are upon split second and irrational comparisons to the available yet limited information we have around us. </p><p>Morally speaking, as a business owner or person you have a duty to make decisions now with this comparison fallability in mind. While yes, you can structure your products in a way to extract <em>more</em> profit than normal from your customers, you need to do this only when you truly feel like that high-end product you’re directing them to is actually giving them more value. </p><p>Personally, don’t find the most repulsive personality to take out on a double date hoping that it makes you look good. This might even back fire since your double date might end up <em>comparing you</em> to the company you hang out with and irrationally judge you just as repulsive. </p><p>Comparison is a force of nature that can’t always be controlled, but it can be guided. Ariely shows us how. </p><p>Bren</p><p>P.S. Here is a fun video by Dan at a Ted Talk</p></div></div></div>]]>
            </description>
            <link>https://brendancahill.io/brensblog/danariely</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036403</guid>
            <pubDate>Mon, 03 Aug 2020 11:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: NLP at up to 4X speed using a T5 version implemented in ONNX]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036301">thread link</a>) | @jsnram
<br/>
August 3, 2020 | https://kta.io/posts/onnx_t5 | <a href="https://web.archive.org/web/*/https://kta.io/posts/onnx_t5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I remember the first presentation I gave about transformer. I cheekily took a few e-mails about macro from colleagues, split them in half, ran the first half as a prompt, and asked the audience to guess which one was the real mail.</p><p>The guesses were coin-flips. That taught me two things: <br></p><ul><li>I should spend less time reading my e-mails about macro.</li><li>Transformers are going to revolutionize the way we operate.</li></ul><p>The one issue with transformers is that they are fairly slow to inference. Even as the NLP community wraps its collective brain around <a href="https://www.gwern.net/GPT-3">GPT-3 writing dad-jokes</a>, one big caveat keeps on showing up: GPT-3 is <a href="https://analyticsindiamag.com/gpt-3-is-great-but-not-without-shortcomings/">slow</a>. Actually, most very large transformers are fairly slow. But <a href="https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333"> this post</a> piqued my interest. Huge gains of performance can be gained from better inference libraries. However porting models to ONNX and allowing them to be ran using onnxruntime can be difficult. That's why I decided to make <a href="https://github.com/abelriboulot/onnxt5">onnxt5</a>.</p><div><h2>What is onnxt5?</h2><p><a href="https://github.com/abelriboulot/onnxt5">onnxt5</a> is a python library that lets you import SOTA T5 models in a line, and run inference with it very fast (<a href="https://arxiv.org/pdf/1910.10683.pdf">original paper</a>).</p><h4>Advantages of this approach</h4><div><div><p>NLP models should be accessible to any developer, therefore I tried to make it as easy as possible to get started. <br><b>Loading a model</b></p><pre><code><span>from</span> onnxt5 <span>import</span> GenerativeT5
<span>from</span> onnxt5<span>.</span>api <span>import</span> get_encoder_decoder_tokenizer
decoder_sess<span>,</span> encoder_sess<span>,</span> tokenizer <span>=</span> get_encoder_decoder_tokenizer<span>(</span><span>)</span>
generative_t5 <span>=</span> GenerativeT5<span>(</span>encoder_sess<span>,</span> decoder_sess<span>,</span> tokenizer<span>,</span> onnx<span>=</span><span>True</span><span>)</span></code></pre><p><b>Translate a sentence</b></p><pre><code>output_text<span>,</span> output_logits <span>=</span> generative_t5<span>(</span>prompt<span>,</span> max_length<span>=</span><span>100</span><span>,</span> temperature<span>=</span><span>0</span><span>.</span><span>)</span>
<span># Output: "J'ai été victime d'une série d'accidents."</span></code></pre><p><b>Summarize a paragraph</b></p><pre><code>generative_t5<span>(</span><span>"summarize: &lt;PARAGRAPH&gt;"</span><span>)</span></code></pre></div></div><div><p>Leveraging the fantastic work by the onnxruntime team, onnxt5 is able to achieve up to 4X faster inference. <br><img src="https://kta.io/images/onnx_t5/Embedding_benchmark.png" alt="Performance on embedding"><img src="https://kta.io/images/onnx_t5/Generation_benchmark.png" alt="Performance on generation"></p></div><div><p>Google's approach in creating T5 was <a href="https://arxiv.org/abs/1910.10683">to train it on a wide variety of tasks</a>. This also means without fine-tuning you can leverage all the tasks which are listed in the appendix, including Q&amp;A, generation, summarization, translation, etc.</p></div><div><p>If the pretrained version of T5 does not fit your need, you can easily export your own models in onnxt5. This gives you the freedom to train more tasks, and provide fast inference on your carefully crafted models.</p></div><p>A necessary caveat to the performance claims is that it appears that the gain in performance decreases with longer contexts. You can evaluate the gains for your task at hand with the benchmarking notebook.</p></div><h2>How do I get started?</h2><p> You can easily get started by downloading the library on pip. </p><pre><code>pip <span>install</span> onnxt5</code></pre><p> You can support the development and find examples on <a href="https://github.com/abelriboulot/onnxt5">the repo</a>. </p><hr></div></div>]]>
            </description>
            <link>https://kta.io/posts/onnx_t5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036301</guid>
            <pubDate>Mon, 03 Aug 2020 11:12:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little did we know how much of an impact China would have on our indie game]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036170">thread link</a>) | @riadd
<br/>
August 3, 2020 | https://www.codecks.io/blog/2020/curious-expedition-financial-history/ | <a href="https://web.archive.org/web/*/https://www.codecks.io/blog/2020/curious-expedition-financial-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The first commercial version of <a href="https://curious-expedition.com/">Curious Expedition</a> was released at the end of 2014. In this blog post I will give you the complete overview of all the sales numbers of these first six years. How many units we sold, when we sold them, in which territories, on which platforms. I will also tell how it felt to tank with our game and how we were able to eventually turn it into a bigger success than we ever imagined.</p>
<p>In case you never heard about it: Curious Expedition is a roguelike expedition game in which you explore uncharted lands, fight dangerous beasts and encounter unknown tribes, all while trying to not go insane or getting forsaken by your own trek members. It is the first game by  <a href="http://maschinen-mensch.com/" target="_blank">Maschinen-Mensch</a>.</p>
<p><span>
      <span></span>
  <picture>
        <source srcset="https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/4611f/ce1_title.webp 163w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/31db7/ce1_title.webp 325w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/5000a/ce1_title.webp 650w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/eb8dc/ce1_title.webp 975w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/5266c/ce1_title.webp 1300w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/51676/ce1_title.webp 2464w" sizes="(max-width: 650px) 100vw, 650px" type="image/webp">
        <source srcset="https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/c9d78/ce1_title.png 163w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/ee07d/ce1_title.png 325w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/efc16/ce1_title.png 650w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/c2476/ce1_title.png 975w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/a30c0/ce1_title.png 1300w, https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/0fe24/ce1_title.png 2464w" sizes="(max-width: 650px) 100vw, 650px" type="image/png">
        <img src="https://www.codecks.io/static/0902de1e61994fbbd29acf6b33f98269/efc16/ce1_title.png" alt="Curious Expedition 1" title="Curious Expedition 1" loading="lazy">
      </picture>
    </span></p>
<p>Over time, it was released on all major store fronts: Steam, GOG, HumbleStore and itch.io. We recently released console versions for Xbox, PS and Nintendo Switch, but that happened after the initial five years and will not be covered here.</p>

<h3 id="the-big-picture">The big picture</h3>
<p>I’ll give you the grand yearly numbers right away. For NDA reasons I can’t go into specific details about how much we sold on each distribution platform, but will instead lump all our digital sales together. All of this units are gross value, that means before tax, distribution rev share and charge backs (usually around 5-15%).</p>


<p>As you can see Curious Expedition had its <strong>most successful years two full years after releasing the first version</strong>. If you’re interested in how we managed to do that just keep reading the detailed history below:</p>
<h2 id="year-1-2014---alpha">Year 1 (2014) - Alpha</h2>
<h3 id="beginnings">Beginnings</h3>
<p>Johannes and I met at Berlin AAA developer <a href="https://www.yager.de/" target="_blank">Yager</a> where we both worked on the war/anti-war game Spec Ops: The Line. We decided to start working on a hobby project around 2012, with the grand dream of potentially going indie with it. Curious Expedition (or Terra Incognita as it was called back then) was the first game that we both agreed on. The idea came to me when I browsed a National Geographic magazine in the waiting room of my dentist.</p>
<p>During this hobbyist phase we struggled quite a bit with the game. Our interest in the premise never waned, but we went through dozens of game mechanics without really being able to nail down the core loop concept. During that time we met multiple times with the intention of quitting the game, only to give it two more months over and over again. We made a leap of faith when we decided to quit our AAA jobs in the beginning of 2014.</p>
<p>The birth of our company Maschinen-Mensch (at some point we had called ourselves Hic Sunt Leones) was eased by a <strong>€50,000 grant from <a href="https://www.medienboard.de/" target="_blank">Medienboard Berlin-Brandenburg</a></strong>. Thankfully we also had a bit of personal savings that helped us survive the initial months since the grant is only allowed to cover 50% of the project costs.</p>
<p>The first thing we did when finally started working full-time on the game, was completely ripping it apart and disabling all features until nothing but a simplistic movement prototype remained. From here we rebuilt all the aspects of the game. Our hope that we finally were onto something was kindled by the positive feedback from our small game designer meetup that we started around the same time.</p>
<p>At the end of 2014 we pushed ourselves to finally release the painfully barebone initial alpha of the game. Complete sections of the game were still missing: when you ran into combat a text message would tell you that we basically didn’t get to that part yet. But we had no choice: our money was running out at this point.</p>
<h3 id="alpha-editions">Alpha Editions</h3>
<p>We released the first buyable version of Curious Expedition on our own homepage where we sold it via the <a href="https://www.humblebundle.com/developer/widget" target="_blank">Humble Widget</a>. We took some inspiration from all the new Kickstarter projects that were created in 2014 and showed that players appreciated different pricing and feature options for purchasing games.</p>
<p>Here’s an overview of all editions we started with:</p>

<h3 id="day-1-sales">Day 1 sales</h3>
<p>Our first release date was November 18th 2014 and we sold in total <em>drum rolls</em>.. <strong>61 copies for a total revenue of $1,203</strong>. Not exactly dream numbers when you just quit your high profile AAA job and spent all your savings on creating this indie game, which has to work out for you to be able to remain an indie game dev.</p>
<p>Here’s a break-down of the unit types sold on that first day:</p>
<div><h4>Launch Day (November 18th 2014)</h4></div>
<h3 id="back-to-work">Back to work</h3>
<p>After pushing the big frightening release button, I remember that we went to a coincidental drink out with some friends from the game dev scene. I still remember how they asked curiously how much we had already sold. I felt bad about telling them that this great indie game experiment we had launched had pretty much tanked at this point. But there was no point in giving up now, so on Monday we got back into the office (which was my living room) and just started working on our next big alpha update.</p>
<p>I turned my old iPad into a live sales metrics board showing the current sales in the style of an airport destinations board and we hooked up to a hefty cash register sound whenever somebody bought a copy of our game. I remember with joy the small moments of celebration when during work the sound would come up and how we high-fived. I also remember those stretches of hours when there was no single sound being played though and we were checking if our metrics were broken, before realizing once again that this was just the state of affairs.</p>
<p>In 2014 we sold in total <strong>793</strong> units for a revenue of <strong>$10,965</strong> with an average price point of <strong>$13.83</strong>.</p>
<p><span>
      <span></span>
  <picture>
        <source srcset="https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/4611f/mm_2014.webp 163w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/31db7/mm_2014.webp 325w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/5000a/mm_2014.webp 650w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/eb8dc/mm_2014.webp 975w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/ae385/mm_2014.webp 1024w" sizes="(max-width: 650px) 100vw, 650px" type="image/webp">
        <source srcset="https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/d86d7/mm_2014.jpg 163w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/32e38/mm_2014.jpg 325w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/7c547/mm_2014.jpg 650w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/b455f/mm_2014.jpg 975w, https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/4c7b4/mm_2014.jpg 1024w" sizes="(max-width: 650px) 100vw, 650px" type="image/jpeg">
        <img src="https://www.codecks.io/static/faa929ca22c89280c8298a348c5d30ae/7c547/mm_2014.jpg" alt="Team MM" title="Team MM" loading="lazy">
      </picture>
    </span></p>
<h2 id="year-2-2015---early-access">Year 2 (2015) - Early Access</h2>
<p>In 2015 we pushed hard on extending Curious Expedition 1. Despite the slow start we were nowhere done and set our hopes into appearing in digital storefronts. So far we had tried to bring people to our small website, but since the players didn’t come to the game, it was time to bring the game to the players.</p>
<h3 id="alpha-videos">Alpha Videos</h3>
<p>Up to this point we had mostly relied on twitter to attract players to our homepage. Today we’re close to 6,000 followers on twitter, but back then we were struggling for a long time to even get to 500 followers.</p>
<p>To build up visibility and hopefully share our excitement about our game, we started recording videos for the numerous alpha updates that we did. Looking at them now, they are a crazy trip down the memory lane to our past selves. Here’s the one for Alpha 4, which is special since it is the alpha in which we added combat for the first time.</p>

          <p>
            <iframe src="https://www.youtube.com/embed/m0KRUAeg79E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          </p>
          
<p>For each alpha update we announced the release day weeks in advance and approached it like a mini-release with marketing material and a strong theme for each of these updates. We made sure to have at least one highly visible “hero feature” per alpha release.</p>
<p>For this update our main focus were our dice challenges. We had been working on combat prototypes for over a year at this point, but as we added more and more combat features, we realized that it became a big centerpiece and we were over-scoping heavily, so we made the hard decision to completely remove combat and make a game that would work solely based on the merits of its unique travel gameplay first.</p>
<p>We did this even though we felt that we had stumbled into an interesting spin on combat: a 1-dimensional dungeon crawler, where instead of on a grid your character and the enemies would be laid out on a line.</p>
<h3 id="free-weekend">Free weekend!</h3>
<p>Before going to stores, we decided to try our luck on drawing more people to our website one last time and did a free weekend! Players could play the game right from their web browser without having to download anything. This was not only nice for lowering entry barriers but also made it very easy for us to revoke access to the game after the weekend was done.</p>
<p>We expected to have fewer sales during the free weekend with an uptick in sales afterwards from players who wanted to play more. To our surprise we had the highest sales during the time when the game was free. Afterwards the sales normalized pretty quickly again.</p>
<div><h4>Sales before and after the free weekend (Feb 2015)</h4></div>
<h3 id="storefront">Storefront!</h3>
<p>On May 19th we finally entered Early Access on Steam as our first store front and this is when Curious Expedition finally changed trajectory to become a success. We still sold the extra editions through our own homepage but the vast majority of sales now happened on the digital storefronts.</p>
<h3 id="pricing-strategy">Pricing Strategy</h3>
<p>We increased our price from <strong>$12</strong> to <strong>$15</strong> as we released the Early Access version. We felt it was fair enough since we had spent many months adding additional content to the game. The following chart shows the average price point per year.</p>
<div><h4>Average Price per Year (2015-2019)</h4></div>
<p>We also decided to be as timid as possible regarding sales. Until we reached the 1.0 phase we decided to not do any sales that went beyond 20%. You can see a timeline of our general sale price reductions here.</p>
<div><h4>On-Sale Reduction (2015-2019)</h4></div>
<p>In 2015 we sold in total <strong>21,266</strong> units for a revenue of <strong>$302,534</strong> with an average price point of <strong>$14.23</strong>.</p>
<h2 id="year-3-2016---gold-release">Year 3 (2016) - Gold Release</h2>
<h3 id="going-gold">Going Gold</h3>
<p>This is the year that we released the 1.0 version of Curious Expedition after over a year of Early Access. We also landed in more online stores: getting a presence in the HumbleStore and being lucky enough to be chosen by GOG as one of the very few games that they chose for their Games in Production program.</p>
<p>We read that you only get one big push in your game’s lifetime: either your Kickstarter campaign or your early access release or your full release. Luckily for us this turned out to not be the case. Not only did the game keep selling well in 2016, the release of the 1.0 version even surpassed our sales records until that point and pushed the game to sell more units than it had in 2015. After the gold release we started applying more sales and going beyond 20%. We were still extremely conservative for a game that had been released for two years now.</p>
<h3 id="art-games">Art Games</h3>
<p>This year we also started working with the Goethe Institute, a non-profit German cultural …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codecks.io/blog/2020/curious-expedition-financial-history/">https://www.codecks.io/blog/2020/curious-expedition-financial-history/</a></em></p>]]>
            </description>
            <link>https://www.codecks.io/blog/2020/curious-expedition-financial-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036170</guid>
            <pubDate>Mon, 03 Aug 2020 10:46:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24036132">thread link</a>) | @lukasbar
<br/>
August 3, 2020 | https://knowledgepill.it/posts/postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after installation and creating database cluster PostgreSQL will listen only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql-basics-guide/">https://knowledgepill.it/posts/postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036132</guid>
            <pubDate>Mon, 03 Aug 2020 10:40:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Lego Interface Panels]]>
            </title>
            <description>
<![CDATA[
Score 396 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24035866">thread link</a>) | @george_cave
<br/>
August 3, 2020 | https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/ | <a href="https://web.archive.org/web/*/https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   
   <time>August 2020</time>

   

   

   <p>Piloting an <a href="https://www.lego.com/en-de/product/ocean-exploration-ship-60266">ocean exploration ship</a> or <a href="https://www.lego.com/en-de/product/mars-research-shuttle-60226">Martian research shuttle</a> is serious business. Let’s hope the control panel is up to scratch. Two studs wide and angled at 45°, the ubiquitous “2x2 decorated slope” is a LEGO minifigure’s interface to the world.</p>

<p>These iconic, low-resolution designs are the perfect tool to learn the basics of physical interface design. Armed with 52 different bricks, let’s see what they can teach us about the design, layout and organisation of complex interfaces.</p>

<p>Welcome to the world of LEGO UX design.</p>

<p><img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/interfaces.jpg" alt="LEGO interfaces"></p>

<h2 id="organised-chaos">Organised chaos</h2>

<p>At a glance, the variety of these designs can be overwhelming, but it’s clear that some of these interfaces look far more chaotic than others. Most interfaces in our world contain a blend of digital screens and analog inputs like switches and dials. These LEGO panels are no different.</p>

<p>Plotting the panels across these two axes reveals a few different clusters. Screens with an accompanying row of buttons sit in the top left. A small cluster of very organised switch panels lies to the far right. The centre bottom is occupied by some wild concepts that are hard to understand, even after several glances.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/positioning.jpg" alt="Design positioning with LEGO, in LEGO">
    <figcaption>Design positioning with LEGO, in LEGO</figcaption>
  </figure>

<p>Designing a complex machine interface is a juggling act of many different factors from ergonomics to engineering. But we can break down the problem into two key questions:</p>

<ol>
  <li>How can we <em>differentiate</em> between the function of different inputs?</li>
  <li>How can we <em>organise</em> the many inputs and outputs so that we understand how they relate to each other?</li>
</ol>

<p>Let’s take a deeper look at tackling these two challenges in LEGO.</p>

<h2 id="differentiating-inputs">Differentiating inputs</h2>

<p>What could cause 400 WWII pilots to raise the landing gear on their B-17 bomber just before touchdown? Catastrophic pilot error, or something more fundamental?</p>

<p>It was the psychologist Alphonsis Chapanis who first suggested that the high rate of crash landings might be the fault of poor interface design. The adjacent landing gear and flap control knobs were identically shaped. The pilots never stood a chance.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/landing.jpg" alt="B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia">
    <figcaption>B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia</figcaption>
  </figure>

<p>His temporary solution was to glue differently shaped strips of rubber to each switch, enabling blind operation by touch alone. This gave rise to the idea of shape coding and a system of differentiation still being followed in aircraft cockpits today.</p>

<p>We can compare the three interfaces below to see this in action. Ignore the overall layout, it’s the differences between individual switches that matter here. Imagine trying to feel for one of these buttons without looking. The left panel (“Slope 45 2 x 2 with 12 Buttons”) would require careful hand-eye co-ordination. The right panel (“Aircraft Multiple Flight Controls”) clearly distinguishes between the throttle (large, linear vertical movement), toggle switches (round vertical flick) and the push buttons (square push-in).</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/differentiation.jpg" alt="Left to right: terrible, poor and better input differentiation">
    <figcaption>Left to right: terrible, poor and better input differentiation</figcaption>
  </figure>

<p>Differentiation like this is a still a very real problem today. In 2015, <a href="https://money.cnn.com/2015/01/06/autos/ford-push-button-ignition-recall/index.html">Ford recalled 13,500 Lincoln SUVs</a> because drivers speeding down the motorway were mistakenly shutting off the engine when they tried to activate sport mode. See if you can spot why:</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/ford-lincoln.jpg" alt="Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN">
    <figcaption>Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN</figcaption>
  </figure>

<p>Shape coding is one approach to differentiation, but there are many others. Colour coding is perhaps the only one to break into our everyday vocabulary, but we can add four more: size, texture, position and operation coding. Together these six are our allies in the design of error-proof interfaces.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/codings.jpg" alt="The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.">
    <figcaption>The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.</figcaption>
  </figure>

<p>Size, shape and colour-coding are the fundamentals: quick-wins that can fix a lot of interface problems. Texture is also a great differentiator for blind operation, particularly on small dials requiring precise control.</p>

<p>Position-coding is seemingly straightforward but is often under used. Products with a clear default ergonomic position (like binoculars or a gaming console) can exploit the natural position of the hand to differentiate between primary and secondary actions.</p>

<p>Finally, operation-coding ascribes different types of movements (like a twist or vertical slide) to different inputs. This can be immensely powerful when the switch motion reinforces the operation behind it, e.g. a crane lever which raises the crane when the lever is raised.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/lego-codings.jpg" alt="The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation">
    <figcaption>The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation</figcaption>
  </figure>

<p>Differentiation is a good first step that will avoid confusion between adjacent switches. But its only with organisation that we can create a clear and accurate mental model of the interface for the user.</p>

<h2 id="organising-inputs">Organising inputs</h2>

<p>Compare the three panels below. Identical layouts, but the blue one is much clearer than the white. This is the <a href="https://www.usertesting.com/blog/gestalt-principles">gestalt principles</a> at work, identifying related items with a common region.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/gestalt.jpg" alt="Basic differentiation by clustering">
    <figcaption>Basic differentiation by clustering</figcaption>
  </figure>

<p>Easy. But how are you going to decide which inputs to cluster together?</p>

<p>I like to use <a href="http://blog.presentandcorrect.com/27986-2">Soviet control panels</a> as a starting point. These beautiful walls of nonsensical dials and levers are brought to life when arranged in a giant factory schematic.  It would be hard to find a more literal organisation of the information.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/soviet-control-panels.jpg" alt="Soviet control panels in action. Source: Present and Correct">
    <figcaption>Soviet control panels in action. Source: Present and Correct</figcaption>
  </figure>

<p>These panels are what I’d called a consolidated interface. Every piece of input and feedback has been moved onto the same panel. This is the approach that <a href="https://www.thedrive.com/news/33847/the-defunct-dyson-evs-steering-wheel-looks-like-it-was-made-by-vacuum-cleaner-people">Dyson took with their car</a>. Now imagine the opposite, moving each of those lights and switches to the actual location of that valve in the factory. Sounds ludicrous, but these <a href="https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design">air vents in the Audi TT</a> show that this distributed approach can also be a great win for user experience. I wrote a lot more about these <a href="https://www.designedbycave.co.uk/2018/Interfaces/">distributed interfaces last year</a>.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/distributed.jpg" alt="Lego vehicle dashboard: distributed (left) vs. consolidated (right)">
    <figcaption>Lego vehicle dashboard: distributed (left) vs. consolidated (right)</figcaption>
  </figure>

<p>Back to the Soviet factories. Those interface panels were great for answering the question “does this valve let water into tank Б?”. But they’re very poor for answering “are all water valves closed?” or “where are all the switches I need to prepare for the shift changeover?”.</p>

<p>LEGO use the Soviet schematic approach for their <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298pb005&amp;in=S">fantasy</a> <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298px10&amp;in=S">orientated</a> designs, because schematics are superb at providing a mental model of the inner workings of an alien system. However for everyday use, there are some other approaches that work better.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/alien-interfaces.jpg" alt="LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?">
    <figcaption>LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?</figcaption>
  </figure>

<p><strong>Feature</strong> based organisation is the most common, perhaps even the “default” design philosophy. Group together all the inputs and outputs for each product feature. This <a href="https://www.cambridgeconsultants.com/press-releases/building-life-saving-ventilator-lightning-speed">COVID-19 ventilator from Cambridge Consultants</a> is a wonderful example but we also see this a lot in cars, with a cluster of switches for the airflow control and all of the lights on one control stick.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/covid-ventilator.jpg" alt="COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants">
    <figcaption>COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants</figcaption>
  </figure>

<p>Organising by <strong>operation</strong> means putting all the switches that function in a certain way in the same place. I’ve no idea what all the valves in the picture below do, but I bet they don’t all open things that relate to each other. Anytime you see a row of switches that look and function the same, but control disparate parts of the system, you’ve come across organisation by operation.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/valves.jpg" alt="Source: Twitter @aglushko">
    <figcaption>Source: Twitter @aglushko</figcaption>
  </figure>

<p>Today most interfaces are effectively <a href="https://en.wikipedia.org/wiki/Fly-by-wire">fly-by-wire</a>, but historically the levers that you pulled in, say, a tractor cabin would literally move the hydraulic pistons beneath the seat to a new position. Routing all these different electrical, mechanical and hydraulic systems efficiently can severely compromise your interface clustering, leading to organisation by <strong>technology</strong>.</p>

<p>The modern equivalent of this is surprisingly common. Any touchscreen with buttons by the side exhibits this technology-based split. In a <a href="https://www.chrisharrison.net/index.php/Research/PneumaticDisplays">future</a> <a href="https://vimeo.com/343640141">world</a>, SpaceX might embed <a href="https://www.space.com/spacex-crew-dragon-touchscreen-astronaut-thoughts.html">these physical controls</a> right inside the screen next to the information they affect, but for now they sit awkwardly by the side as if nothing is wrong.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/spacex-dragon.jpg" alt="Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX">
    <figcaption>Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX</figcaption>
  </figure>

<p>In LEGO we find the feature based organisation in the “Monitor with -19° pattern”. Two clear clusters, perhaps one for temperature control and another for vital signs monitoring. In the second panel below, I don’t know what all those switches do, but they seem to be clustered based on their operation, not because of what they will operate.</p>

<p>There are many LEGO panels with a technology split like the SpaceX Dragon capsule, but I like to imagine that this early 90s police control unit was forced to divide the audio and video playback because the newer tape reel technology was incompatible with the older analog phone line system. This is organisation by technology in action.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/organisation.jpg" alt="L-to-R: organisation by feature, operation, technology and use case">
    <figcaption>L-to-R: organisation by feature, operation, technology and use case</figcaption>
  </figure>

<p>All of our approaches so far: organisation by features, operation or technology, have been grounded in properties of the system, not of the user. Organisation by <strong>use-case</strong> is the antidote to this, a clustering based on the daily routines and tasks of the user.</p>

<p>Imagine arriving for work each day at the LEGO body scanner factory. Grouping the switches by task (prepare machine, load body, process scan…) would mean splitting up the radiation and scanner buttons into many different regions. More complex for the computer, but more streamlined for the operator. As the designer, only you and your users will be the judge of what works best.</p>

<h2 id="but-george-which-is-the-best-interface">But George, which is the best interface?</h2>

<p>I often say there’s no such thing as the best interface, but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</a></em></p>]]>
            </description>
            <link>https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035866</guid>
            <pubDate>Mon, 03 Aug 2020 09:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive JavaScript Slide Rule]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24035379">thread link</a>) | @lebski88
<br/>
August 3, 2020 | https://adit.co.uk/sliderulev2.html | <a href="https://web.archive.org/web/*/https://adit.co.uk/sliderulev2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="dvText">
        <p>
            The rule cursor and central slide can be positioned using a mouse. Fine adjustment can be achieved using the keyboard left and right arrow buttons.
            The keyboard keys move the cursor or slide depending upon which had last been clicked or adjusted.
        </p>
        <p>
            The left hand display below the rule (“A on B” etc) shows the slide position. The central display shows the cursor position over each of the slide scales.
        </p>
        <p>
            Why is the cursor window a bit yellow? To find out, <a href="https://javascriptfunandgames.blogspot.com/2020/06/my-interactive-slide-rule.html" target="_blank">check my blog where some of the design decisions</a> that went into constructing this rule are described. Thats also
            a good place to comment if you come across any gross bugs (bugs are likely of course but so are edge cases that maybe should be treated kindly).
        </p>
        <h3>The Calculator</h3>
        <p>
            You can try using the virtual calculator just like a normal one although the choice of functions and the absence of plus and minus buttons might be a 
            little eccentric. Please remember though that calculations performed on a slide rule will not always be as accurate as those performed on an electronic 
            calculator. Results can and will differ.
        </p>
        <p>
            You can enter values using the “buttons” or from your keyboard (including the numeric keypad if “Num Lock” is set. The sum is executed by the virtual 
            slide rule and the result read back from the slide rule. The division function is executed in two stages with a 1.5 second delay between them. 
            An experienced slide rule user would probably skip the second stage as the result can be read from the end of the slider.
        </p>
        <p>
            You can calculate the tangent of angles (in degrees) between 6° and 84°. The S (sine) scale is also used to calculate cosines – both in the range 1° to 90°.
        </p>
        <h3>Background</h3>
        <p>
            I was looking through some bits and bobs that came from a draw in my Father’s house when it was being cleared for sale.
            One of the items was a slide rule and it was found alongside the early “Sinclair Executive” calculator that replaced it.
            It is small (nominally 6" probably) and pretty similar to the one I remember buying with my first student grant money in
            the very late 1960s when they were still pretty much the state of the art for calculators. Around that time though, I did
            come into contact with an <a href="https://en.wikipedia.org/wiki/Sumlock_ANITA_calculator" target="_blank">electronic Anita calculator</a> but they were staggeringly expensive and you could hardly slip one
            in your pocket or even carry one very far.
        </p>
        <p>
            The Sinclair Executive calculator came out in 1972 and cost £79.95 (over £1000 in 2020 money) and I probably paid £5 or £6 for the
            slide rule three or four years before that (still an appreciable cost that needed some internal debate to justify).
        </p>
        <p>
            The slide rule was invented sometime between 1620 and 1630 with new functions developed and added over time until the device became the tool
            of choice for the developing field of engineering.
        </p>
        <p>
            How do they work? It is pretty easy to see how two rulers could be used to do simple addition and subtraction. We can try adding 3 and 8.
        </p>
        <p><img src="https://adit.co.uk/Images/add3to8.png"></p><p>
            We position the start on the lower ruler’s scale at one of the two values (in this case 3) and read off the sum of 3 and 8 on the scale of the upper ruler (see the red line).
            It should also be obvious that the same positioning could be used to calculate 11 minus 8 or any other pair of values on the two ruler scales.
        </p>
        <div><p>
            Now such a simple mechanical device for adding two numbers together would not be terribly useful even if they were decimal fractions such as 3.4 and 8.7
            which would be easy to do with the rulers shown above. However being able to multiply (say) 1.65 by 3.45 would be more challenging mental arithmetic for most.
            When I was at school, we used logarithms for such calculations.
            </p><p>
            The logarithm (base 10) of a number is the number expressed as a power of 10.
            </p><p>
            1.65 = 10<sup>0.2175</sup>  so log(1.65) = 0.2175
            <br>
            3.45 = 10<sup>0.5378</sup> so log(3.45) = 0.5378
            <br>
            0.5378 + 0.2175 = 0.7553 (sum the logs)
            <br>
            10<sup>0.7553</sup> = 5.6925 which is the product of 1.65 and 3.45.
            </p><p>
            Thus simple addition can be used to multiply two decimal fractions expressed as logarithms.
        </p></div>
        <p>
            Fortunately, when I was at school, we did not need to calculate these powers of 10 – we were issued with books of tables for looking them up. 
            The tables included a host of trigonometric tables as well as the vital “antilogarithms” needed to establish that 10<sup>0.7553</sup> was 5.69 
            (which was about as accurate as the ones I had could get.
        </p>
        <p>
            If instead of having pages of tables we were to draw a logarithmic scale on a pair or rulers instead of the linear scale illustrated above we could 
            use them to multiply two values by adding the logs. Indeed we could also do division by subtracting one logarithmic scale position from another. 
            So, what does a logarithmic scale look like in action?
        </p>
        <p><img src="https://adit.co.uk/Images/logRules.png"></p><p>
            You will notice that as the values increase (from 1 to 10 in this instance) the distance between the log of those values decreases. 
            You can probably also see that two rules with logarithmic scales can be used to make our calculation (1.65 x 3.45). Slide rules were fast and accurate enough for most purposes.
        </p>
        <p>
            Why does the log scale start at 1? Well ten to the power of zero is 1 and zero is a good place to start. In fact any number to the power of zero is 1.
        </p>
    </div></div>]]>
            </description>
            <link>https://adit.co.uk/sliderulev2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035379</guid>
            <pubDate>Mon, 03 Aug 2020 08:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extended mission after Hayabusa2 returns to Earth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24035376">thread link</a>) | @watbe
<br/>
August 3, 2020 | http://www.hayabusa2.jaxa.jp/en/topics/20200803_exm/ | <a href="https://web.archive.org/web/*/http://www.hayabusa2.jaxa.jp/en/topics/20200803_exm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.hayabusa2.jaxa.jp/en/topics/20200803_exm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035376</guid>
            <pubDate>Mon, 03 Aug 2020 08:39:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In-House Software Development: Top Myths]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24035301">thread link</a>) | @vasya-gh
<br/>
August 3, 2020 | https://perceptionbox.io/development/in-house-software-development-top-4-myths/ | <a href="https://web.archive.org/web/*/https://perceptionbox.io/development/in-house-software-development-top-4-myths/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div>
                                                    
                                
                                    
<p id="myth-1">
            <h3>Myth 1. It’s easier to verify in-house software development productivity</h3>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>At one time, it certainly was easier to keep tabs on in-house team productivity. That’s no longer the case with today’s team collaboration software. Automated software development analytics programs like <a href="https://gitential.com/" target="_blank" rel="noopener">Gitential</a> and<a href="https://waydev.co/" target="_blank" rel="noopener"> Waydev</a> put remote developers on equal footing with in-house software development teams. They track all interactions with git repositories and produce a variety of performance metrics. This brings complete transparency to team member productivity.&nbsp; A shortlist of metrics includes code churn, code efficiency, code volume, coding hours, number of commits, and test volume.</p>
<p>Do you need actual “eyes-on” what everyone is doing?<a href="https://www.sococo.com/" target="_blank" rel="noopener"> Sococo</a> provides a virtual office solution for Agile Teams. Whether in-house or distributed, all team members have a room in your “virtual building.” At a glance, you can see who’s online and what they’re working on, in real-time. It provides broadcasting capabilities, teleconferences, screen-sharing for presentations, and more. The only downside is that it requires everyone to use a headset.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <p><code><iframe src="https://www.youtube.com/embed/nLsrXXt3FXo" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></code></p>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="myth-2">
            <h3>Myth 2. In-house teams are more productive</h3>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>We can break this myth. Some offices are idealistic and serene. Some home offices may resemble mosh pits. A<a href="https://www.flexjobs.com/blog/post/flexjobs-2018-annual-survey-workers-believe-flexible-remote-job-can-help-save-money-reduce-stress-more/" target="_blank" rel="noopener"> 2018 FlexJobs Survey</a> of 3,000 participants indicated 75% are more productive working remotely. They cited coworker interruptions and general office noises as major issues. Less commuting and reduced office politics were also cited as boosting productivity. The<a href="https://www.smallbizgenius.net/by-the-numbers/remote-work-statistics/#gref" target="_blank" rel="noopener"> Ultimate List of Remote Work Statistics</a> – 2020 Edition shows similar studies from Owl Labs, Buffer, Gallup, and others. They consistently reflect higher productivity and quality of work in telecommuting environments.</p>
<p>Veteran remote developers know two things are vital. The first is to remove distractions from one’s work area. The second is the discipline to not give in to temptations. Managers can coach team members they believe are challenged by their work remote environment. In-house teams may find the adjustment difficult at first. For outsourced teams, <i>it is their SOP</i> and they likely have productivity tips to share.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <h4>Find more about&nbsp;<a href="https://perceptionbox.io/development" target="_blank" rel="noopener">development</a></h4>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="myth-3">
            <h3>Myth 3. Only In-house teams are accountable for their work</h3>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>Some managers believe that you lose control of your project without an in-house team. That can happen if you forget two important legal agreements. The first is a Non-Disclosure Agreement (NDA).&nbsp; It enforces that team members understand you own and control all intellectual property. That goes for any work product or inventions associated with any contract.</p>
<p>The second is a Service Level Agreement (SLA). This specifies the services an agency or individual will provide to you. It specifies the expected standards and metrics whereby the work will be measured. It lays out each party’s responsibilities. Additionally, it defines the remedies and penalties for any breach. Violations of SLA’s and NDA’s are subject to civil suits and monetary damages.</p>
<p>In all cases, as the contractor, you are free to specify who your project manager will be. You decide what methodologies and processes your teams will follow. You select the team collaboration software, and reporting mechanisms everyone will use.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                
                                
                                
                                    
<div>
           <p><img src="https://perceptionbox.io/wp-content/uploads/2020/07/2nd.jpg" alt="image">
       </p>
        </div>
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <p>The cost-advantage of remote or dedicated development teams is substantial even if only compared to office costs. The average office space per employee in North America runs 150 square feet or $6,000 (Chicago) to $12,000 per year (San Francisco). Other employee-based overhead costs sidestepped by remote teams. These include taxes, employee benefits and insurance, computer hardware, software, and consumable supplies.</p>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                
                                
                                
                                
                                    

                                
                                

                            
                                
                                    
<p id="myth-4">
            <h3>Myth 4. In-house software development teams are more qualified</h3>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>Recruiter and hiring managers aren’t complaining about a lack of job applications. Their gripes concern a lack of qualified applicants. In 2019, the United States had about 4.2 million software developers. In contrast, there are roughly 5.5 million developers in Europe and 24 million worldwide. In-house software development teams rely upon limited local talent. You can attract more qualified developers by outsourcing through IT staffing agencies.</p>
<p>While the United States does have good programmers, they don’t stack up against the Top 10 very well. According to<a href="https://skillvalue.com/companies/en/it-ranking-best-developers-2019-skillvalue/" target="_blank" rel="noopener"> Where to Find the Best Developers in 2019?</a> by SkillValue, the United States ranks a distant #27. US developers had scored 84.59% as rated against over 550 technical assessments.</p>
<p>In comparison, a wide swath of Eastern Europe scored in the 93% range. Ukraine, for example, ranked #5 with a score of 93.17%. But don’t forget to factor in Purchasing Power Parity (PPP) and Cost of Living. Add these and you’ll find that Ukraine’s ~250,000 developers offer the best combination of value and technical proficiency available.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

      …</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://perceptionbox.io/development/in-house-software-development-top-4-myths/">https://perceptionbox.io/development/in-house-software-development-top-4-myths/</a></em></p>]]>
            </description>
            <link>https://perceptionbox.io/development/in-house-software-development-top-4-myths/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035301</guid>
            <pubDate>Mon, 03 Aug 2020 08:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why your academic code needs a software licence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24035267">thread link</a>) | @Topolomancer
<br/>
August 3, 2020 | https://bastian.rieck.me/blog/posts/2020/licence/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/licence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Regardless of the scientific discipline you are working in, you probably
write some code to perform your experiments. This post aims to inform
you about the need for adding a <em>licence</em> to your software—a procedure
that is often neglected, in particular since it is associated with legal
considerations, which are perceived as being tedious by many<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Since
I am not a lawyer, I will go easy on the legalese and just provide
a quick overview.</p>
<p>(If you are in a hurry, feel free to <a href="#parting-thoughts">skip to the conclusion and its actionable items</a>.)</p>
<p><strong>Caveat lector</strong>: your university might require you to consult with
them <em>prior</em> to releasing software into the wild. Make sure to check
whether you are actually allowed to release your code without anyone
checking out the legalities of the situation. This article is mostly
written from a machine learning perspective, where people tend to be
very generous in releasing their code, but often forget to choose an
appropriate licence.</p>

<p>Software licences serve multiple purposes. Most importantly, they specify
what kind of interactions you want people to have with your code. For
example, are you okay with your code—and thus potentially your
name—being used to <em>advertise</em> a product or service of someone else? Are
you okay with people using the software <em>commercially</em>? What happens if
your code does not work as expected and produces <em>incorrect results</em>?</p>
<p>A licence helps you cover all of these aspects—and many more. But the
primary function of a licence is not necessarily to <em>protect</em> you from bad
things, it also defines what kind of community you want to build around your
code. For example, how do you handle improvements of your code? How do
you want to be attributed? How do you want <em>others</em> to be attributed?
Can <em>anyone</em> contribute to your project?</p>
<p><strong>Summary</strong>: A software licence clearly defines what people <em>can</em> and
<em>cannot</em> do with your code. It helps you, your users, and your
potential contributors.</p>

<p>You might think that, being the generous scientist that you are, that
your code should be released with essentially a ‘no strings attached’
policy. That is commendable<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, but the law, for once, is <em>not</em> on your
side here: if you release code <em>without</em> a licence attached, the default
interpretation in most—if not all—jurisdictions is that you retain
all privileges. This might sound not too bad, but there are often
unintended  consequences. For example,
<a href="https://choosealicense.com/no-permission">choosealicense.com</a> has the
following things to say about having <em>no</em> licence&nbsp;(emphasis by me):</p>
<blockquote>
<p>When you make a creative work (which includes code), the work is under
<em>exclusive copyright</em> by default. Unless you include a license that
specifies otherwise, <em>nobody else</em> can copy, distribute, or modify your
work without being at risk of take-downs, shake-downs, or litigation.
<strong>Once the work has other contributors (each a copyright holder), “nobody”
starts including you</strong>.</p>
</blockquote>
<p>This is bad! Suppose that you revisit a project that you collaborated on
with multiple people. After a few years, you have the urge to make this
into a commercial tool. If you have no licence, you technically have to
negotiate with all of your original contributors, or even your previous
employers&nbsp;(remember that you might change university affiliations a few
times). If you fail to do this, you make your life harder and, in the
worst case, you may be subject to litigation.</p>
<p>However, you are not only impeding <em>your</em> future possibilities if you do
not specify a licence, you are also hurting the options of <em>others</em>:
code without a licence can be removed without a whim, and technically,
everyone who builds on that code has to ask for permission and is not
directly allowed to redistribute it. Again, as a worst-case scenario,
you might have to <em>retract</em> code because you never had the right to use
it in the first place! Plus, companies tend to avoid code without
a licence like a plague because <em>they</em> have legal departments that know
about the dire consequences of using code without the proper legal
framework<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p>
<p><strong>Summary</strong>: If you do not use a licence, you are only hurting
yourself&nbsp;(or your future self) and the prospects of your project.</p>

<p>After all these warnings about unintended consequences, it is time for
some good news: in this age, adding a licence to your code is as easy as
it gets. Here are the main steps:</p>
<ol>
<li>First, you have to <em>pick</em> an appropriate licence—no worries, we
will talk about this in a second!</li>
<li>You now create a file called <code>LICENSE</code><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> in your main code
repository and add your name to it.</li>
<li>Optionally, you now add a text of the form ‘See <code>LICENSE</code> for details
on how to use this code’ to your source code files. This is just
a courtesy for your users; your selected licence still applies to all
source files, but sometimes, adding such a disclaimer is a good
reminder—in particular for large code bases.</li>
<li>You publish the code. That’s it!</li>
</ol>
<p>Sounds easy, right? In fact, it is so easy that <a href="https://github.com/">GitHub</a> even provides
licence templates when setting up a repository. It does not even take
a few minutes of your time—which is how it should be!</p>

<p>Now that you know how easy it is, which licence should you choose?  For
this, the website <a href="https://choosealicense.com/">choosealicense.com</a> is
a treasure trove. Moreover, the website <a href="https://tldrlegal.com/">tldrlegal.com</a>
is also great in explaining the specifics of a licence in plain English.
Please do not take my word for it and check all the licences I will
subsequently mention!</p>
<p><strong>Caveat lector</strong>: At this point, I have to stress that what comes next
is my personal opinion and it is thus heavily biased towards a certain
type of licence.  I will try to back up my claims, though!</p>
<h2 id="avoid-copyleft-licences">Avoid copyleft licences</h2>
<p>As a first piece of advice, I would urge you to <em>avoid</em> so-called
copyleft licences, like the <a href="https://tldrlegal.com/license/gnu-general-public-license-v3-(gpl-3)">GNU General Public Licence v3</a>.
I know that this is a controversial statement for some, but before you
close this tab in anger, let me explain: a copyleft licence forces your
users to require all derivative works—other projects, updates, and
extensions of your code—to be released under the <em>same</em> licence as
your original code. This sounds fair at first glance—after all, you
made your code available for anyone else to be free to use, so others
should do the same, right? While I agree with this sentiment, the
GPL&nbsp;(and similar licences) make it harder for private companies to
engage with your project. There are subtle legal issues that often
require for-profit businesses <em>not</em> to engage with code like this, even
if they wanted to!</p>
<p>Note that I am not claiming that there are no successful industry
contributions to GPL projects! I am merely pointing out that this
licence raises the bar quite considerably for other institutions to
engage with your code. Especially when you develop tools for others to
be used, as is very common in bioinformatics and machine learning, you
want to make it easy for others to build on your work. Do not take my
word for it, though: if you are
not convinced, read <a href="http://ivory.idyll.org/blog/2015-on-licensing-in-bioinformatics.html">this article on licencing software in bioinformatics</a>
by <a href="http://ivory.idyll.org/">C. Titus Brown</a>,
as well as <a href="https://liorpachter.wordpress.com/2017/08/03/i-was-wrong-part-2">this article on the troubles with licencing</a>, written
by <a href="https://pachterlab.github.io/biography.html">Lior Pachter</a>.</p>
<p><strong>Summary</strong>: Avoid copyleft licences if you can&nbsp;(but they are still
a lot better than having no licence at all).</p>
<p><strong>Philosophical sidenote</strong>&nbsp;(you may skip this): it is one of my
core tenets that I do not want to <em>force</em> people into a certain kind of
desirable behaviour—such as sharing their code—but rather I want to
<em>convince</em> them. The formulation of copyleft appears to be too
stringent for my taste: I can easily imagine situations in which abiding
by this licence is problematic for the other party, even if they <em>want</em>
to abide by it! Thus, I am not a big proponent of these licences any
more. When I originally got involved with Linux, BSD, and the open
source movement, I liked the GPL a lot, but as I started using BSD more
and more, my stance changed.</p>
<h2 id="use-a-permissive-licence-instead">Use a permissive licence instead</h2>
<p>So, what licence <em>should</em> you choose for your academic code, then?
I prefer the so-called <em>permissive</em> licences, which are often also
referred to as ‘BSD-style’ licences. Permissive licences have minimal
restrictions as to how your software can be used, but they provide
protection for you <em>and</em> make it possible for others to attribute your
work! Here is my preferred permissive licence, the <a href="https://tldrlegal.com/license/bsd-3-clause-license-(revised)">Revised BSD 3-Clause
Licence</a>:</p>
<blockquote>
<p>Copyright (c) YEAR AUTHOR, all rights reserved.</p>
<p>Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:</p>
<ol>
<li>
<p>Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.</p>
</li>
<li>
<p>Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the
distribution.</p>
</li>
<li>
<p>Neither the name of the copyright holder nor the names of its
contributors may be used to endorse or promote products derived
from this software without specific prior written permission.</p>
</li>
</ol>
<p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS
IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>
</blockquote>
<p>I like this licence because it permits others<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> to use your software
commercially, modify it, distribute it, and even provide a warranty for
it, <em>provided</em> they include the copyright notice—in other words, they
attribute your work—and the licence itself. Moreover, you <em>cannot</em> be
held liable for any damages arising from the use of the code, and others</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/licence/">https://bastian.rieck.me/blog/posts/2020/licence/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/licence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035267</guid>
            <pubDate>Mon, 03 Aug 2020 08:17:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[United Airlines plans to resume service on more than 25 international routes]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24035215">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-scaled.jpeg" data-caption="Photo: United Airlines"><img width="696" height="463" src="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-300x200.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1024x682.jpeg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-768x511.jpeg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1536x1022.jpeg 1536w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-2048x1363.jpeg 2048w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1068x711.jpeg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1920x1278.jpeg 1920w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-631x420.jpeg 631w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="United Airlines Boeing 777-300"></a><figcaption>Photo: United Airlines</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>United Airlines today announced it plans to resume service on nearly 30 international routes in September, including flights to Asia, India, Australia, Israel and Latin America and to continue to add ways to visit popular vacation destinations in the Caribbean, Hawaii and Mexico. The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;</p>



<p>“We continue to be realistic in our approach to building back our international and domestic schedules by closely monitoring customer demand and flying where people want to go,” said Patrick Quayle, United’s vice president of International Network and Alliances. “In September, we’re adding even more options for leisure travelers or those who want to visit friends and relatives, whether that’s within the United States or around the world.”&nbsp;</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Domestically, United intends to fly 40% of its schedule. The airline plans to add more than 40 daily flights on 48 routes to locations including Austin, Texas; Colorado Springs, Colorado; and Santa Barbara, California. Additionally, United plans to resume service between the U.S. mainland and Hilo and Kauai and increase flying to Honolulu, Kona and Maui in the Hawaiian Islands.</p>



<p>Internationally, <a href="https://hub.united.com/2020-07-31-united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september-2646851493.html" target="_blank" aria-label="United  (opens in a new tab)" rel="noreferrer noopener">United </a>intends to fly 30% of its schedule as compared to September 2019, which is a 5-point increase compared to August. The airline expects to resume service on 20 routes in Latin America and the Caribbean, including to popular vacation destinations like Cabo San Lucas and Puerto Vallarta in Mexico and to San Jose and Liberia in Costa Rica. United intends to begin new nonstop service between Chicago and Tel Aviv and resume eight routes in the Atlantic and Pacific, including the return of European service from Houston with flights to Amsterdam and Frankfurt.</p>



<p><strong>U.S. Domestic&nbsp;</strong></p>



<p>Travelers in search of more socially distant vacation options like beach, mountain and national park destinations will continue to see opportunities for leisure travel including:&nbsp;</p>



<ul><li>Increasing opportunities to connect to more than 800 flights from United’s mid-continental hubs in Chicago, Denver and Houston.&nbsp;</li><li>Adding more than 40 daily flights on more than 48 routes across the United States.&nbsp;</li><li>Resuming service between the U.S. mainland and Hilo and Kauai in Hawaii&nbsp;</li><li>Increasing service between the U.S. mainland and Honolulu, Kona and Maui.</li></ul>



<p><strong>Atlantic</strong></p>



<p>Internationally, United is scheduled to fly 30% of its schedule in September compared to the same period in 2019. Across the Atlantic, United plans to offer customers more opportunities to get to Europe and beyond from Chicago, Houston, New York/Newark, and San Francisco. Highlights include:&nbsp;</p>



<ul><li>Launching brand-new service between Chicago and Tel Aviv&nbsp;<em>(subject to government approval)</em></li><li>Resuming service between Chicago and Amsterdam.&nbsp;</li><li>Resuming service between Houston and Amsterdam and Frankfurt.&nbsp;</li><li>Resuming service between San Francisco and Munich.&nbsp;</li><li>Increasing to daily service between Chicago and Frankfurt, and between San Francisco and London.&nbsp;</li><li>Continuing service between the United States and Delhi and Mumbai&nbsp;<em>(subject to government approval)</em>.&nbsp;</li></ul>



<p><strong>Pacific</strong></p>



<p>Across the Pacific in September, United plans to re-start three-times-weekly service between Los Angeles and Sydney and passenger service between Chicago and Hong Kong&nbsp;<em>(subject to government approval).</em></p>



<p><strong>Latin America/Caribbean</strong></p>



<p>Throughout Latin America and the Caribbean, United is expanding across each region by adding 20 new routes for September. Highlights of United’s schedule include:&nbsp;</p>



<ul><li>Starting new service between San Juan, Puerto Rico and Chicago and Washington-Dulles.&nbsp;</li><li>Resuming service from Houston to Aguascalientes, Tampico and Veracruz in Mexico.&nbsp;</li><li>Starting new service between New York/Newark and St. Thomas.&nbsp;</li><li>Resuming service between Costa Rica and Houston and New York/Newark.&nbsp;</li><li>Adding more ways to get to Puerto Vallarta, Mexico, including resuming service from Chicago, Denver and Los Angeles.&nbsp;</li><li>Resuming service between Denver and Cabo San Lucas.&nbsp;</li><li>Increasing the number of flights between Houston and Quito, Ecuador.</li></ul>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg" alt="united airlines" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-300x199.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-768x510.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-696x463.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1068x710.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-632x420.jpg 632w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;Photo: United Airlines</figcaption></figure>



<h2>United Airlines Committed to Ensuring a Safe Journey</h2>



<p>United is committed to putting health and safety at the forefront of every customer’s journey, with the goal of delivering an industry-leading standard of cleanliness through its United CleanPlus program. United has teamed up with Clorox and Cleveland Clinic to redefine cleaning and health safety procedures from check-in to landing and has implemented more than a dozen new policies, protocols and innovations designed with the safety of customers and employees in mind, including:</p>



<ul><li>Requiring all travelers – including crew members – to wear face coverings and potentially revoking travel privileges for customers who do not follow these requirements, as underscored in a&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=4181856673&amp;u=https%3A%2F%2Fwww.dropbox.com%2Fsh%2Fj9pc7ehab8xontd%2FAAAJJtjzuejK3-hhWY9DP50qa%2FScott%2520Kirby%2520Mask%2520Message%2F16x9%3Fdl%3D0%26preview%3D2020-06-17_UA_ScottMaskMessage_16x9_v2020-06-25-1_CP-ONLY_SRT.mp4%26subfolder_nav_tracking%3D1&amp;a=recent+video" rel="noreferrer noopener">recent video</a>&nbsp;from United CEO Scott Kirby.&nbsp;</li><li>Using state-of-the-art high-efficiency (HEPA) filters on most United mainline aircraft to circulate air and remove up to 99.97% of airborne particles.&nbsp;</li><li>Using electrostatic spraying on all mainline aircraft before departure for enhanced cabin sanitation.&nbsp;</li><li>Adding a step to the check-in process, based on a recommendation from the Cleveland Clinic, requiring customers to acknowledge they do not have symptoms for COVID-19 and agree to follow our policies, including wearing a mask on board.&nbsp;</li><li>Offering customers a touchless baggage check-in experience at more than 200 airports across the United States; United is the first and only U.S. airline to make this technology available.</li></ul>



<p>For more details on all the ways United is helping keep customers safe during their journey, please visit&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=1790932703&amp;u=https%3A%2F%2Fwww.united.com%2Fual%2Fen%2Fus%2Ffly%2Ftravel%2Funited-cleanplus.html&amp;a=united.com%2Fcleanplus" rel="noreferrer noopener">united.com/cleanplus</a>.</p>



<h3>About United Airlines</h3>



<p>United’s shared purpose is “Connecting People. Uniting the World.” For more information, visit united.com, follow @United on Twitter and Instagram or connect on Facebook. The common stock of United’s parent, United Airlines Holdings, Inc., is traded on the Nasdaq under the symbol “UAL”.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035215</guid>
            <pubDate>Mon, 03 Aug 2020 08:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KLM to Lay Off 5k Employees Due to Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24035132">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" data-caption="A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
"><img width="500" height="375" src="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-300x225.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-80x60.jpeg 80w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-265x198.jpeg 265w" sizes="(max-width: 500px) 100vw, 500px" alt="" title="KLM pliots and cabin crew"></a><figcaption>A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p><strong>KLM is in the throes of a crisis of unprecedented magnitude. Since the outbreak of the COVID-19 virus at the start of 2020, numerous measures have already been taken to deal with the current circumstances. Expectations are that the road to recovery will be long and fraught with uncertainty. This means that KLM’s structure and size must be rigorously adjusted even further in the years ahead. Consequently, a total of 4,500 to 5,000 positions in the entire KLM Group (expressed in FTEs) will cease to exist.</strong></p>



<p>In the wake of the coronavirus outbreak, KLM gradually began reducing the size of its network in February to operate less than 10% of its original number of <a href="https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">flights</a> by the start of April. In the second quarter, only 15% of the original number of flights were operated. In July, 30% of the original flights were operated and load factors are lagging behind. As a result, while the network is again being gradually and carefully expanded, revenues are lagging far behind.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Prospects for the airline industry – and KLM in particular – are uncertain. Different countries are now beginning to tighten their more relaxed travel restrictions. This is making customers more cautious when it comes to booking a ticket. In all scenarios, demand is only expected to recover by 2023 or 2024 at the earliest. The degree and speed of recovery will depend on a number of factors including the development of the virus, economic recovery and customer travel behaviour.</p>



<h2>KLM Adjusting to the New Reality</h2>



<p>Government support in the form of a direct state loan and guaranteed bank credit facilities amounting to a maximum of €3.4 billion will enable KLM to navigate the crisis in the forthcoming period. <a href="https://news.klm.com/klm-adapts-organisation-further-due-to-covid-19-crisis/" target="_blank" aria-label="KLM (opens in a new tab)" rel="noreferrer noopener">KLM</a> is extremely grateful for this support provided by means of the loan. In order to guarantee KLM’s existence in the longer term, the airline must adapt its size to the new reality. KLM therefore finds itself compelled to reduce its workforce down to the number needed for the planned operation in 2021/2022. Of the current total of 33,000 FTEs in the entire KLM Group, the workforce must be reduced by 4,500 to 5,000 FTEs to 28,000 FTEs in the course of 2021.</p>



<p>KLM’s size is already becoming smaller – and will continue to be reduced – based on the current measures, which include the non-renewal of temporary contracts (1,500 FTEs) and the Voluntarily Departure Scheme (2,000 FTEs). Additionally, natural attrition (500 FTEs) through retirement and the like in 2020 and 2021 will also contribute to the reduction needed.</p>



<p>Hence, despite the measures already taken, even fewer people will be needed at KLM in the years ahead. Additionally, for positions on the ground we also need to deal with some mismatch in functional skills and capabilities.</p>



<p>Unfortunately, for this reason and taking into account the mismatch, alternative solutions will have to be found for ca. 1,500 positions. This relates to up to 500 ground positions, 300 cabin crew positions and 300 cockpit positions and approximately 400 positions at KLM subsidiaries and Air France-KLM group functions.</p>



<p>Given the high level of uncertainty, KLM keeps open the possibility of further reductions in case the production levels will be revised further down for 2021/2022 than the -20% planned now.</p>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg" alt="KLM" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew-300x169.jpg 300w" sizes="(max-width: 500px) 100vw, 500px"><figcaption>KLM crew in Sydney Photo: KLM</figcaption></figure>



<h3>KLM to Cooperate with Trade unions and Works Council</h3>



<p>KLM’s reorganisation plans tie in with organisation-wide changes at Air France KLM. In the forthcoming period, KLM will be cooperating closely with the trade unions to draft a social plan for each collective labour agreement domain and subsidiary, as well as maintaining close consultation with the Works Council about further defining the reorganisation. This will include a more detailed specification of the conditions set by the Dutch government on issuing the financing package. Expectations are that this will be finished in its entirety in the course of October.“</p>



<blockquote><p><em>A great deal has already been done in recent months with respect to adjusting the size of our company in the face of a new reality. Unfortunately, more measures are needed in the short term to guarantee KLM’s continued existence in the future. For this reason, we are elaborating the reorganisation plan to emerge from this crisis in a stronger position, while retaining as many jobs as we can in a responsible manner and repaying the loans as quickly as possible.</em></p><p><em>KLM employees are loyal, professional and hard working. They are always ready to serve our customers, one another, the company and society at large. Recent developments have again served to prove that this is true. It is incredibly difficult and sad for KLM to now have to bid farewell to valuable, committed colleagues. Certainly in view of how much we have succeeded in achieving together in recent years. The forthcoming period will be devoted to saying goodbye to colleagues who have to leave with due care and to reconstructing KLM.</em></p></blockquote>



<p>KLM President-directeur &amp; CEO Pieter Elbers</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035132</guid>
            <pubDate>Mon, 03 Aug 2020 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All we can do is find problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24035131">thread link</a>) | @kiyanwang
<br/>
August 3, 2020 | https://surfingcomplexity.blog/2020/07/28/all-we-can-do-is-find-problems/ | <a href="https://web.archive.org/web/*/https://surfingcomplexity.blog/2020/07/28/all-we-can-do-is-find-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1363">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://surfingcomplexity.blog/category/systems/" rel="category tag">systems</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-07-28T10:07:15-07:00">July 28, 2020</time><time datetime="2020-07-28T10:07:46-07:00">July 28, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>I’m in the second week of the three week  virtual <a href="http://psas.scripts.mit.edu/home/2020-workshop-information/">MIT STAMP workshop</a>. Today, Prof. Nancy Leveson gave a talk titled <a href="http://psas.scripts.mit.edu/home/wp-content/uploads/2020/07/Safety-Assurance.pdf">Safety Assurance (Safety Case): Is it Possible? Feasible?</a> Safety assurance refers to the act of assuring that a system is safe, after the design has been completed.</p>



<p>Leveson is a skeptic of evaluating the safety of a system. Instead, she argues for focusing on generating safety requirements at the design stage so that safety can be designed in, rather than doing an evaluation post-design.  (You can read her <a href="http://psas.scripts.mit.edu/home/wp-content/uploads/2020/07/White-Paper-on-Safety-Assurance.pdf">white paper</a> for more details on her perspective). Here are the last three bullets from her final slide:</p>



<ul><li><em>If you are using hazard analysis to prove your system is safe, then you are using it wrong and your goal is futile</em></li><li><em>Hazard analysis (using any method) can only help you find problems, it cannot prove that no problems exist</em></li><li><em>The general problem is in setting the right psychological goal. It should not be “confirmation,” but exploration</em></li></ul>



<p>This perspective resonated with me, because it matches how I think about availability metrics. You can’t use availability metrics to inform you about whether your system is reliable enough, because they can only tell you if you have a problem. If your availability metrics look good, that doesn’t tell you anything about how to spend your engineering resources on reliability.</p>



<p>As Leveson remarked about safety, I think the best we can do in our non-safety-critical domains is study our systems to identify where the potential problems are, so that we can address them. Since we can’t actually quantify risk, the best we can do is to get better at identifying systemic issues. We need to <em>always</em> be looking for problems in the system, regardless of how many nines of availability we achieved last quarter.  After all, that next major outage is always just around the corner. </p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-07-28T10:07:15-07:00">July 28, 2020</time><time datetime="2020-07-28T10:07:46-07:00">July 28, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://surfingcomplexity.blog/2020/07/28/all-we-can-do-is-find-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035131</guid>
            <pubDate>Mon, 03 Aug 2020 07:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Walk Through .NET Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24034947">thread link</a>) | @iwangulenko
<br/>
August 3, 2020 | http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/ | <a href="https://web.archive.org/web/*/http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      

<p>.NET is an open source developer platform, created by Microsoft, for building many different types of applications, such as: web, mobile, desktop, games, etc. It consists of different tools, programming languages and libraries. Lets start with a brief history of the .NET.</p>



<p>During 1990s, Microsoft started to work on something called .NET Strategy. The key point of this strategy was to encompass all Microsoft products and add .NET to existing product names. In the 2000s, .NET framework was known as the Next Generation Windows Services (NGWS). First beta versions of .NET framework were released in the late 2000s and the first version .NET 1.0 was released on February 13, 2002. Since then many versions were released with new features. Some of the most important were:</p>

<ul>
<li>.NET Framework 2.0 (November 2005.): generic collections, iterators, nullable types, etc.</li>
<li>.NET Framework 3.0 (November 2006.): WPF, WCF and WWF.</li>
<li>.NET Framework 3.5 (November 2007.): AJAX, LINQ, ASP.NET MVC.</li>
<li>.NET Framework 4.0 (April 2010.): MEF, DLR, task parallel library, Razor view engine, new C#/VB language features.</li>
<li>.NET Framework 4.5 (August 2012.): support for Async, zip compression support.</li>
<li>.NET Core 1.0 (November, 2014.): first version which included cross-platform support. ASP.NET 5 and .NET Native.</li>
<li>.NET Core 2.0 (August 2017.): the second version, with major performance improvements and implemented .NET Standard 2.0.</li>
<li>.NET Framework 4.8 (April 2019.): final version included JIT enhancements, High DPI enhancements for WPF applications, accessibility improvements, performance updates, and security enhancements.</li>
<li>.NET Core 3.0 (September 2019.): performance improvements, C# 8.0 new features, implements .NET Standard 2.1. Windows Desktop supports .NET Core for Windows Forms and WPF.</li>
</ul>

<p>The image below shows timeline of .NET main events:</p>





<p>Currently, in 2020. .NET Ecosystem consists of different components in the development platform. It encompasses different runtimes, such as:</p>

<ul>
<li>.<strong>NET Framework</strong> (WPF, Windows Forms, ASP.NET) - Windows centric.</li>
<li><strong>.NET Core</strong> (ASP.NET Core, Universal Windows Platform - UWP) - Cross-platform, works side-by-side with other versions.</li>
<li><strong>Mono for Xamarin</strong> (IOS, OS X, Android) - Cross-platform.</li>
</ul>

<p>All of the above runtimes implement .NET Standard Library, which is a specification of .NET APIs that have implementations for each runtime. So that code that is created for one runtime, can be executed with other runtime.</p>

<p>All the runtimes uses tools and infrastructure to compile and run code. This includes languages (C#, Visual Basic), compilers (<a href="https://github.com/dotnet/roslyn/wiki/Roslyn%20Overview" target="_blank">Roslyn</a>), garbage collection, as well as build tools like MS Build, or (Core) CLR.</p>




<figure>

<img src="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/netecosystem.jpeg">


</figure>



<p>In this section we will look at main .NET runtimes. We consider .NET runtime as anything that implements <a href="https://github.com/dotnet/coreclr/blob/master/Documentation/project-docs/dotnet-standards.md" target="_blank">ECMA-335 Standard for .NET</a>.</p>

<h2 id="net-framework">.NET Framework</h2>

<p>.NET Framework is a software development framework for building and running applications on Windows. It is party open-sourced at <a href="https://github.com/microsoft/referencesource" target="_blank">here</a>. .NET Framework consists of Common Language Runtime (CLR), .NET Framework Class library and Application workloads (WPF, Windows Forms and ASP.NET). CLR is part of common infrastructure than run code, jit, do garbage collection (C#, VB.NET, F#), etc. Code that is managed by CLR is called managed code. Code is compiled into Common Intermediate Language (CIL) and stored in assemblies (with .exe or .dll extension). When application runs, CLR takes assembly and uses just-in-time compiler (JIT) to transpile machine code into code that can run on specific computer architecture.</p>




<figure>

<img src="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/netarch.jpg">


</figure>

<p>.NET framework library contains classes, interfaces and values types that provides capatibilites, such as string, file system support, etc. It allows creating different type of applications, such as: console applications or Windows Forms, Windows Communication Foundation (WCF), Windows Workflow Foundation (WF), Windows Presentation Foundation (WPF), ASP.NET (Forms, Web API), Azure (WebJobs, Cloud Services). Most of those are specific to Windows platforms and use Windows API, so they work only on Windows platform.</p>

<p>If you want to run applications that are built by using .NET Framework you need to install it first, although Windows already comes with some versions installed. Each version have CLR and library. It is possible to install multiple versions, side by side (only major versions). Minor versions will override existing versions, as they don’t contain braking changes. For example for .NET 4.2.3: major version is 4 (new CLR), 2 minor version means (new library, which introduces new features) and 3 revision (bug fixes).</p>

<p>.NET Framework is installed usually at C:\Windows\Microsoft.NET\Framework (or Framework64). Inside, you will find folders with all major versions installed.</p>

<h2 id="net-core">.NET Core</h2>

<p>.NET Core is one of runtimes in .NET Ecosystem. It is released in 2016. and its open-sourced (<a href="https://github.com/dotnet/core" target="_blank">https://github.com/dotnet/core</a>). It does not represent a new version of .NET Framework and will not replace it. Its completely independent version, which is build to allow cross-platform capatibility to application development. .NET Core consists of App Host (dotnet.exe) that run CLR and Library. It has Common language runtime (CoreCLR) and .NET Core Class Library.</p>

<p>CoreCLR uses JIT Compilation and garbage collection to run code. It supports C#, VB.NET and F#.  .NET Core has .NET Core Class Library, which includes classes that provides different capatibilities and its a smaller subset of .NET Framework library. It supports different types of application workloads, such as ASP.NET Core (MVC and API), console applications and UWP (currently). UWP provides a common type system, APIs, and application model for all devices running on Windows 10. From the .NET Core 3.0 SDK it includes support for Windows Forms applications, including Windows Forms Designer.</p>

<p>.NET Core can run on different platforms: Windows Client, Server, IoT, Linux, Ubnutu, FreeBSD, Tizen, Mac OSX and can be installed side-by-side of different versions, per machine or user.</p>

<p>.NET Core is installed in C:\Program Files\dotnet\shared\ Microsoft.NETCore.App[versions], which live side by side.</p>

<p>In addition, its possible to create self-contained version, which don’t need installed .NET core on the host machine, as it packs app host in the resulting .exe file. The disadvantage is that the the deployment will be larger. It is run via:</p>

<pre><code>dotnet publish -r linux-x64 --self-contained true
</code></pre>




<figure>

<img src="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/netcore.png">


</figure>

<h2 id="mono-for-xamarin">Mono For Xamarin</h2>

<p>Mono is a clone of .NET framework runtime. Mono is created in 2001., but part for Xamarin is released in 2011. and its open source: <a href="https://github.com/mono/mono" target="_blank">https://github.com/mono/mono</a> and <a href="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/www.mono-project.com" target="_blank">www.mono-project.com</a>. Microsoft acquired Xamarin in 2016., making it a fully open-source branch of the .NET platform. It consists of Mono runtime and Xamarin Class Library and can run application workloads like IOS, OS X and Android.</p>

<p>Mono is similar to .NET Core and includes Garbage collection, JIT, AOT and full support for C# (not VB.NET and F#). The Mono AOT compiler enables .NET code to be built into a single native code executable that can run on a machine, much like C++ code. Mono for Xamarin has a class library that support creating applications (for IO, collections, etc). But its a subset of .NET framework, there are not all components supported.</p>

<p>It can run following workloads: Apple IOS applications, MAC OS X applications (desktop), Android applications, etc. and allows you to share code between these platforms and they run as native applications on devices that run on Mono. Each application is bundled with the Mono runtime and a class library. There is no need to install Mono on a device.</p>

<p>Over time it branched out into wider areas, such as game development, where <a href="https://unity.com/" target="_blank">Unity</a> and Mono for Xamarin have long worked together to provide C# support in Unity.</p>




<figure>

<img src="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/xamarin.jpg">


</figure>

<h2 id="other-frameworks-net-compact-framework-net-micro-framework">Other frameworks: .NET Compact Framework &amp; .NET Micro Framework</h2>

<p>These are specific frameworks with a specific purpose. Both runtime were attempts to provide cut-down runtimes that would run on more constrained devices, such as PDAs, mobile phones factory controllers, etc. For example, .NET Micro Framework was build for resource-constrained devices with at least 256KB of flash and 64KB of RAM memory.</p>

<h2 id="silverlight">Silverlight</h2>

<p>Silverlight was a popular cross-platform, .NET technology that enabled building rich media experiences for browsers. It was released on 2007 and had multiple capatibilites such as playing videos, download medias, creating rich UI and animations, etc. In 2015. Microsoft decided to stop supporting Silverlight in October 2021.</p>



<p>Besides Microsoft official runtimes, there are .NET runtimes made by community, such as <a href="http://www.gnu.org/software/dotgnu/pnet.html" target="_blank">DotGNU Portable.NET</a>, <a href="https://mattwarren.org/2017/10/19/DotNetAnywhere-an-Alternative-.NET-Runtime/" target="_blank">DotNetAnywhere</a>, <a href="https://www.gocosmos.org/" target="_blank">CosmosOS</a> and <a href="https://web.archive.org/web/20090425073609/http://crossnet.codeplex.com/" target="_blank">CrossNet</a>. All of them have a slighty different approach to build such a framework.</p>



<p>As different runtimes uses different class libraries, e.g., .NET Framework uses .NET Framework class library, while .NET Core contains its own class library, as well as Xamarin with its own class library. In this way its hard to share code between different runtimes, as they don’t use the same APIs. Microsoft solution to this is <a href="https://docs.microsoft.com/en-us/dotnet/standard/net-standard" target="_blank">.NET Standard library</a>, released in 2016. It represent set of (formal) specifications that say which APIs you can use and its implemented by all runtimes. It is evolution of Portable Class Libraries (PCL). Specific runtimes implement specific version of .NET Standard (implementing specific set of APIs). E.g., .NET Framework 4.6.1 implements .NET Standard 2.0 (<a href="https://docs.microsoft.com/en-us/dotnet/standard/net-standard#net-implementation-support" target="_blank">link</a>).</p>




<figure>

<img src="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/netstandard.jpeg">


</figure>

<p>The differences between .NET Standard and Portable Class Libraries (which is library that can be used on different platforms).</p>

<ul>
<li>.NET Standard represent set of API defined by Microsoft, while PCL is using API dependent on platform which is chosen.</li>
<li>.NET Standard is platform agnostic, while PCL can target limited set of platforms.</li>
</ul>

<p>Each version of .NET Standard has set of APIs (e.g. System.Drawing) and it include all APIs of previous version, so its backward compatible. Specific .NET runtime versions implement specific …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/">http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/</a></em></p>]]>
            </description>
            <link>http://milan.milanovic.org/post/a-brief-walk-through-net-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034947</guid>
            <pubDate>Mon, 03 Aug 2020 07:13:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working efficiently with legacy database using Dapper]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24034679">thread link</a>) | @cezarypiatek
<br/>
August 2, 2020 | https://cezarypiatek.github.io/post/dapper-tips-and-tricks/ | <a href="https://web.archive.org/web/*/https://cezarypiatek.github.io/post/dapper-tips-and-tricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
		<header>
			
			  
			<p><i></i> <time>2 August 2020</time></p>
			<hr>
			
		</header>
		
			<img src="https://cezarypiatek.github.io/post/dapper-tips-and-tricks/splashscreen.jpg" width="100%">
			
		
		

<p>A year ago I started working on a set of projects that requires accessing data from a huge legacy database. There was a decision to use <a href="https://github.com/StackExchange/Dapper">Dapper</a> to facilitate database access code. For those of you who are not familiar with Dapper, it’s a set of extension methods to <a href="https://docs.microsoft.com/en-us/dotnet/api/system.data.idbconnection?view=netcore-3.1">IDbConnection</a>, which allows to easily map C# object to SQL query parameters, as well as SQL query result to C# objects. I was quite skeptical to use a library that requires writing <code>SQL queries</code> directly in the C# code, because I got used to relying always on ORMs (<code>NHibernate</code> in particular). Throughout the year, <code>Dapper</code> has proven to be the right tool for the job. In the meantime, I also discovered a couple of features and tricks that allow me to write quite concise and easy to maintain database access code, and I think it’s worth sharing them here.</p>

<blockquote>
<p>Key Takeaways:</p>

<ul>
<li>Always define aliases in SQL queries using <code>nameof()</code> operator</li>
<li>Use C# consts and enums in SQL queries instead of magic numbers</li>
<li>Use <code>FOR JSON PATH</code> to simplify fetching complex objects from database</li>
</ul>
</blockquote>

<h2 id="resilient-to-refactoring">Resilient to refactoring<a href="#resilient-to-refactoring" arialabel="Anchor"> 🔗︎</a> </h2>

<p>Dapper allows to easily map SQL query results to C# objects based on the naming convention. There’s no problem if the database table columns’ names match object fields’ name - if there’s a discrepancy, you can deal with it by adding aliases:</p>

<pre><code>SELECT 
    UserID AS [Id], 
    UserName AS [Name]
FROM 
    Users
</code></pre>

<p>However, the naming convention approach is fragile to rename refactoring. Changing the object field’s name will break your code and it can be hard to detect without an appropriate test suite. Fortunately, there’s a way to shorten this feedback loop and solve this issue in the design time. We can make our code more resilient by defining aliases using <code>string interpolation</code> and <code>nameof()</code> operator:</p>

<pre><code>private static readonly string GetUsersListQuery = @$"
SELECT 
    UserID AS [{nameof(UserDBO.Id)}], 
    UserName AS [{nameof(UserDBO.Name)}]
FROM 
    Users
"
</code></pre>

<p>This not only takes away the threat of breaking the code while renaming <code>DBO</code> fields but also gives better discoverability and navigability in the code. Using <code>find usage</code> option, we can also find where a given field is used in the SQL queries. And there’s no performance penalty because the compiler can evaluate this string interpolation during the compilation, because all of the parameters are const. You can verify it by yourself with this <a href="https://sharplab.io/#v2:EYLgZgpghgLgrgJwgZwLQAdYwggdsgZgB8ABAJgEYBYAKHIAIBVZHAEQCEB5Wgb1voH0SBegEtcMegEkAJvR70A5hBgBueizX0Avv0HCxE+gDkoAWwjylK9ZvW6aD2gYYAlCOgD2yUTE8IAT3k9enQEUQA3WEsSCgA2eiQoGU9cABsg2IAGegBxFWYcZAAZUWQYAEU4HCCAXiESABIAIloAZQBRYo6AYQAVehCmFgQpVnoAQTb6AG0eXHMITzAACkKEDk4AOlkASm0AXQAaQZpBYZxTC0npuYWLZbWRza2riH2D2gAxV04AWVO53WyFozVUtG0QA">Sharplab.io example</a></p>

<p>But what if we want to get the result of the string interpolation without the need to run the whole program in debug mode? This is often needed when there’s a bug in the query and we want to copy it and test in the <code>Management Studio</code>. This can be easily archived with <code>Immediate window</code> - yes, that’s right, you can use <code>Immediate window</code> to evaluate the code in the design time. To evaluate the string, just enter fully qualified field name that holds the query into the <code>Immediate window</code>:</p>

<p><img src="https://cezarypiatek.github.io/post/dapper-tips-and-tricks/evaluated_string_interpolation.jpg" alt=""></p>

<p>Unfortunately, the output is not well-formatted and contains additional characters for line endings. We can fix it by adding <code>nq</code> (no quote) suffix:</p>

<p><img src="https://cezarypiatek.github.io/post/dapper-tips-and-tricks/evaluated_string_interpolation_with_nq.jpg" alt=""></p>

<p>If you are using <code>Resharper</code> then you can avoid typing long <code>FQN</code> and copy it with a special option for this purpose:</p>

<p><img src="https://cezarypiatek.github.io/post/dapper-tips-and-tricks/resharper_copy_FQN.jpg" alt=""></p>

<h2 id="no-magic-numbers">No magic numbers<a href="#no-magic-numbers" arialabel="Anchor"> 🔗︎</a> </h2>

<p>Sometimes there is a need to use some sort of constant values in the SQL query (especially in the conditions). Queries with those cryptic values are very hard to review or even can cause a problem with understanding for the author himself after a while:</p>

<pre><code>public class Repository {
   private static readonly string GetActiveUsersListQuery = @$"
SELECT 
    UserID, 
    UserName
FROM 
    Users
WHERE
    UserType = 135
";
}
</code></pre>

<p>This is a classical example of well known code smell called <code>magic numbers</code>. We can solve this problem again with string interpolation. <strong>It’s tempting to introduce an enum that represents a set of available values but unfortunately using an enum as a parameter for the interpolated string will prevent the compiler from evaluating expression during the compilation. The evaluation will occur in the runtime and will result in creating a new string in the memory whenever the code is executed.</strong> This can hurt the application performance especially when you define SQL queries as local variables. You can check it on this <a href="https://sharplab.io/#v2:EYLgZgpghgLgrgJwgZwLQAdYwggdsgZgB8ABAJgEYBYAKHIAIBVZHAEQCEB5Wgb1voH0SBegEtcMegEkAJvR70A5hBgBueizX0Avv0HCxE+gDkoAWwjylK9ZvW6ag+rQe0IuOGaYsEAFQCe6BC8egIAggDGMKIAbpYAvPQUBACsADSh0rhQUbEJSQQAbC60tAYMAEoQ6AD2yKIwNQj+8qHoCLGwliQUhfRIUDI1uAA2LT0ADPQA4irMOMgAMqLIMACKcDgtiSQkACQARLQAygCii6cAwr7OjoLzCFKsabdOD6YWtABiFZwAsq97j5kLQAOoACVOFVOmQeASC9ESPDhgQgADpItE4g4DqoXEA">Sharplab.io example</a> If you need to keep strings with SQL queries as local variables then it’s better to define those magic values as const:</p>

<pre><code>public class Repository {
    
    static class UserType
    {
        public const string Active = "135";
        public const string Inactive = "136";
    }
    
   private static readonly string GetActiveUsersListQuery = @$"
SELECT 
    UserID, 
    UserName
FROM 
    Users
WHERE
    UserType = {UserType.Active}
";
}
</code></pre>

<p>Those constants must be a string type even if they are numeric values, otherwise the compiler generates invocation of <code>System.String.Format()</code> instead of creating a single string.</p>

<h2 id="bridge-the-gap-between-relational-and-object-oriented-models">Bridge the gap between relational and object-oriented models<a href="#bridge-the-gap-between-relational-and-object-oriented-models" arialabel="Anchor"> 🔗︎</a> </h2>

<p>Very often posts advertising micro ORMs present fairly simple examples where database data structures match almost 1-1 the C# structures. However, the reality is quite different and the discrepancy between relational and object-oriented model might be expensive and result with a large amount of code responsible for fetching and transforming data.</p>

<pre><code>public class User
{
    public int Id {get; set;}
    public string FirstName { get; set; }
    public string LastName { get; set; }
    public Address MainAddress { get; set; }
}

public class Address
{
    public string City { get; set; }
    public string ZipCode { get; set; }
    public string Street { get; set; }
    public string FlatNo { get; set; }
    public string BuildingNo { get; set; }
}
</code></pre>

<p>In order to fetch complete user data we can use one of the following approaches:</p>

<p>We can introduce some sort of intermediate type for fetching a result of the SQL query and then map it to the destination type in the memory. I call those intermediate types <code>DBO - DataBase Object</code>:</p>

<pre><code>public class UserDBO
{
    public int Id {get; set;}
    public string FirstName { get;  }
    public string LastName { get; private set; }
    public string City { get; set; }
    public string ZipCode { get; set; }
    public string Street { get; set; }
    public string FlatNo { get; set; }
    public string BuildingNo { get; set; }
}

public class UserRepository
{
    static readonly string GetAllUserDataSqlQuery = ""; /*TODO: Here comes query for fetching user basic data*/
    
    public async Task&lt;User&gt; GetUser(IDbConnection connection, int id)
    {
        var userDBO = await connection.QueryFirstOrDefaultAsync&lt;UserDBO&gt;(GetAllUserDataSqlQuery, new {UserId = id});
        if(userDBO == null)
        {
            return null;
        }
        return new User
        {
            Id = userDBO.Id,
            FirstName = userDBO.FirstName,
            LastName = userDBO.LastName,
            //TODO: If the address is optional then we should check if all attributes are not empty before creating an instance of Address
            MainAddress = new Address
            {
                City = userDBO.City,
                ZipCode = userDBO.ZipCode,
                Street = userDBO.Street,
                FlatNo = userDBO.FlatNo,
                BuildingNo = userDBO.BuildingNo
            }
        };
    }
}
</code></pre>

<p>This solution has several disadvantages:</p>

<ul>
<li>It requires an intermediate DBO type.</li>
<li>It requires additional mapping code to adjust fetched data to the desired structure</li>
<li>If we change the relation between User and Address from one-to-one to one-to-many, it will result in data duplication.</li>
</ul>

<p>Another option is to fetch direct attributes (Id, FirstName, LastName) with one query, fetch address data with another one and merge user with address in memory:</p>

<pre><code>public class UserRepository
{
    static readonly string GetUserBasicDataSqlQuery = ""; /*TODO: Here comes query for fetching user basic data*/
    static readonly string GetAddressDataSqlQuery = ""; /*TODO: Here comes query for fetching address data*/

    public async Task&lt;User&gt; GetUser(IDbConnection connection, int id)
    {
        var user = await connection.QueryFirstOrDefaultAsync&lt;User&gt;(GetUserBasicDataSqlQuery, new {UserId = id});
        if(user == null)
        {
            return null;
        }
        user.MainAddress = await connection.QueryFirstOrDefaultAsync&lt;Address&gt;(GetAddressDataSqlQuery, new {UserId = id});
        return user;
    }
}
</code></pre>

<p>This approach requires two calls to a database, but it can be reduced by merging those two queries into a single string and executing it with <code>SqlMapper.GridReader</code>:</p>

<pre><code>public class UserRepository
{
    static readonly string GetUserBasicDataSqlQuery = ""; /*TODO: Here comes query for fetching user basic data*/
    static readonly string GetAddressDataSqlQuery = ""; /*TODO: Here comes query for fetching address data*/

     static readonly string GetUserCompleteDataSqlQuery = @$"
        -- Fetch user basic data
        {GetUserBasicDataSqlQuery};
        -- Fetch address data
        {GetAddressDataSqlQuery};
    ";    

    public async Task&lt;User&gt; GetUser(IDbConnection connection, int id)
    {
        using var gridReader = await connection.QueryMultipleAsync(GetUserCompleteDataSqlQuery, new { UserId = id });
        var user = await gridReader.ReadFirstOrDefaultAsync&lt;User&gt;();
        if (user == null)
        {
            return null;
        }

        user.MainAddress = await gridReader.ReadFirstOrDefaultAsync&lt;Address&gt;();
        return user;
    }
}
</code></pre>

<p>Looks like this solution is much cleaner and requires less code than the option with the intermediate DBO object, but things can get really messy when we want to fetch data for more than one user and the relation between user and address is one-to-many:</p>

<pre><code>public async Task&lt;IReadOnlyCollection&lt;User&gt;&gt; GetAllUsers(IDbConnection connection)
{
    using var gridReader = await connection.QueryMultipleAsync(GetUserCompleteDataSqlQuery);
    var users = …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cezarypiatek.github.io/post/dapper-tips-and-tricks/">https://cezarypiatek.github.io/post/dapper-tips-and-tricks/</a></em></p>]]>
            </description>
            <link>https://cezarypiatek.github.io/post/dapper-tips-and-tricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034679</guid>
            <pubDate>Mon, 03 Aug 2020 06:16:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT3 → Dataset → Task Model?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24034542">thread link</a>) | @dsr12
<br/>
August 2, 2020 | https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc | <a href="https://web.archive.org/web/*/https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034542</guid>
            <pubDate>Mon, 03 Aug 2020 05:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MNT Reform open source laptop with trackball]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24034502">thread link</a>) | @brian_herman
<br/>
August 2, 2020 | https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html | <a href="https://web.archive.org/web/*/https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <date>Published: 2020-05-08 Updated: 2020-05-22 21:36:37 +0200</date>
        

<p><a href="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg"><img src="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg" alt="MNT Reform in 2020"></a></p>

<p>This page serves as a link index to all Reform content, both historical and recent.</p>

<p>On 2020-05-08, MNT Research launched the MNT Reform open source mobile computer:</p>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

<h2 id="mnt-reform-final-version">MNT Reform Final Version</h2>

<p>Internally called MNT Reform 2.0, this is a version with many improvements, full aluminum enclosure, HD display and NXP i.MX8MQ module.</p>

<ul>
<li>2020-05-22: <a href="https://mntre.com/reform2-handbook/system.html">MNT Reform Interactive System Diagram and Interactive PCBs</a>, first version, published.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform">Crowd supply campaign is launched</a>, running until 2020-06-18.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform/updates/the-campaign-is-live">Launch Announcement</a> of the campaign.</li>
<li>8 Beta versions (D-3 / D-4) were sold in late 2019/early 2020 and are shipped in May 2020.</li>
<li>2020-01-18: <a href="https://mntre.com/media/reform_md/2020-01-18-finishing-reform.html">Finishing Reform</a></li>
<li>2019-05-20: <a href="https://mntre.com/media/reform_md/2019-05-20-reintroducing-reform.html">Re-Introducing Reform</a></li>
<li>Handbook not yet available</li>
<li><a href="https://source.mntmn.com/MNT/reform">Sources of Reform 2.0 (KiCAD, various)</a></li>
</ul>

<h2 id="mnt-reform-prototype-version-s-internally-called-mnt-reform-0-1-1-0">MNT Reform Prototype Version(s) (internally called MNT Reform 0.1 - 1.0)</h2>

<p>This was the original version of Reform, based on NXP i.MX6QP.</p>

<ul>
<li>2019-01-14: <a href="https://mntre.com/media/reform_md/2019-01-14-status_update_on_reform.html">Status Update on MNT Reform</a></li>
<li><a href="https://mntre.com/media/reform_md/reform-1-handbook.pdf">Handbook for Reform 1.0 (PDF, historical)</a></li>
<li><a href="https://source.mntmn.com/MNT/reform/src/branch/master/historic-reform1">Sources of Reform 1.0 (KiCAD, various, historical)</a></li>
<li>10 prototype versions were shipped to early supporters in late 2018. 13 exist in total.</li>
<li><a href="https://mntre.com/media/reform_md/reform-historic/reform-beta-1.html">MNT Reform: The Original Story</a></li>
</ul>

<h2 id="talks-appearances">Talks / Appearances</h2>

<ul>
<li><a href="https://media.ccc.de/v/34c3-9257-lightning_talks_day_3#t=3512">Reform Lightning Talk from 34c3</a></li>
<li><a href="https://media.ccc.de/v/dg-90">Longer Reform talk in German from CCCB Datengarten 90</a></li>
</ul>

<h2 id="irc-channel">IRC Channel</h2>

<ul>
<li>Chat in #reform on irc.freenode.net</li>
</ul>



<ul>
<li><a href="https://mastodon.social/@mntmn">Mastodon</a></li>
<li><a href="https://twitter.com/mntmn">Twitter</a></li>
</ul>

<h2 id="crowdfunding-campaign">Crowdfunding Campaign</h2>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

      </section></div>]]>
            </description>
            <link>https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034502</guid>
            <pubDate>Mon, 03 Aug 2020 05:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parts of vs Code Are Proprietary]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24034477">thread link</a>) | @lawik
<br/>
August 2, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034477</guid>
            <pubDate>Mon, 03 Aug 2020 05:28:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autodesk criticised by architects]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 375 (<a href="https://news.ycombinator.com/item?id=24034211">thread link</a>) | @nsoonhui
<br/>
August 2, 2020 | http://extranetevolution.com/2020/07/autodesk-criticism-extends/ | <a href="https://web.archive.org/web/*/http://extranetevolution.com/2020/07/autodesk-criticism-extends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
                
                    
                                        
                    <div id="content-main">
                    
	
		
		        
<div id="post-14835">
		
	<div>
    	
                    	<p>
            	<span>Jul</span>
                <span>31</span>
                	                <span>2020</span>
                            </p>
            
		        
		
			    <ul>
	    		        <li>
	        	By  in <span><a href="http://extranetevolution.com/category/aec/">AEC</a>, <a href="http://extranetevolution.com/category/bim/">BIM</a>, <a href="http://extranetevolution.com/category/businessfinancial/">Business/Financial</a>, <a href="http://extranetevolution.com/category/collaboration/">Collaboration</a>, <a href="http://extranetevolution.com/category/digital-transformation/">Digital transformation</a>, <a href="http://extranetevolution.com/category/functionality/">Functionality</a>, <a href="http://extranetevolution.com/category/future/">Future</a>, <a href="http://extranetevolution.com/category/vendors/">Vendors</a></span>	        </li>
	        	        <li>
	        	<p><em>31 July 2020</em></p>	        </li>
	        	        <li>
	        	        <span>
            <i></i>
        </span>
    	        </li>
	        	    </ul>
    		
				<div>
							
										
						<div itemscope="" itemtype="http://schema.org/BlogPosting"><p><em><strong>Architectural unrest about Autodesk and its support for the industry’s design businesses is growing. Discontent has been simmering for a decade or more, and has led to calls for EU action.</strong></em></p>
<p><a href="https://www.autodesk.co.uk/"><img src="http://extranetevolution.com/files/2013/11/autodesk.logo2013.jpg" alt="autodesk logo" width="181" height="31"></a>The recent <a href="https://letters-to-autodesk.com/" target="_blank" rel="noopener noreferrer">open letter to Autodesk</a> from 17 named members of a 25-strong group of leading architects (28 July 2020: <a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>Design firms demand change at Autodesk</em></a>) has been supported by more firms. They extend the geographical reach of those prepared to publicly criticise the US AEC software vendor over its support for architectural design businesses – many of them heavily reliant upon Autodesk’s Revit design software. An additional 18 practices now stand alongside the original letter’s signatories, bringing the total to 35. A further 10 practices are supportive, but have not gone public. In total, more than 50 firms have therefore backed the group’s grievances.</p>
<p><img src="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png" alt="Autodesk Revit_2014_branding" width="150" height="150" srcset="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png 150w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-300x300.png 300w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-160x160.png 160w, http://extranetevolution.com/files/2020/07/Revit_2014_branding.png 316w" sizes="(max-width: 150px) 100vw, 150px">The new signatories are: BC Architects and SAOTA (both from South Africa); Cooper Carry, Portman Architects, Idesign-solutions, Studio 3 Architecture, Goody Clancy, SGA, Bohlin, Cywinski, Jackson, and Workshop Collaborative (all from the US), Atelier Tisso (France),&nbsp;CGL,&nbsp;Shepheard Epstein Hunter, and PDPLondon (all from the UK); Vibes (Netherlands); MIZA (Canada); Oslo works (Norway); and Mochly-Eldar Architects (Israel).</p>
<p>It is clear that Iain Godwin has tapped into a growing sense of unease, though, to be fair, rumblings of discontent have been heard many times over the past decade or so from a variety of software commentators and end-users. For example:</p>
<ul>
<li><a href="https://www.worldcadaccess.com/blog/2009/12/solidworks-accuses-autodesk-of-attempting-to-monopolize-use-of-dwg-as-file-extension.html" target="_blank" rel="noopener noreferrer"><em><strong>SolidWorks accuses Autodesk of attempting to monopolize use of .dwg as file extension</strong></em></a> (Ralph Grabowski – WorldCADAccess, December 2009)</li>
<li><a href="https://gfxspeak.com/2011/04/28/is-the-european-commission-investigating-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>Is the European Commission investigating Autodesk?</strong></em></a> (Randall Newton – GraphicSpeak, April 2011)</li>
<li><a href="https://www.cadnauseam.com/2017/07/26/autodesk-confirms-its-own-unconscionable-conduct/" target="_blank" rel="noopener noreferrer"><em><strong>Autodesk confirms its own unconscionable conduct</strong></em></a> (Steve Johnson – CAD Nauseum, July 2017)</li>
<li><a href="http://debunkthebim.blogspot.com/2018/04/here-is-why-autodesks-monopoly-over.html" target="_blank" rel="noopener noreferrer"><em><strong>Here is why Autodesk’s monopoly over the Global AEC is not good, not even for Autodesk</strong></em></a> (Zolna Murray – Debunk the BIM, February 2018)</li>
<li><a href="https://www.linkedin.com/pulse/avoiding-carillions-mistakes-joining-autodesks-monopoly-john-ford/" target="_blank" rel="noopener noreferrer"><em><strong>Avoiding Carillion`s Mistakes of Joining Autodesk’s Monopoly Unnecessarily</strong></em></a> (John Ford – LinkedIn Pulse, May 2018)</li>
<li><a href="http://mes100.com/blog/the-state-of-bim-software-and-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>The state of BIM software and Autodesk</strong></em></a> (MES – MES blog, July 2018)</li>
<li><a href="https://thinkmoult.com/why-revit-is-shit.html" target="_blank" rel="noopener noreferrer"><em><strong>Why Revit is shit</strong></em></a> (Dion Moult – ThinkMoult, December 2018)</li>
</ul>
<p>Concerns about some software vendors’ monopolistic positions have also been raised internationally by industry organisations, including the <a href="http://www.fiec.eu/" target="_blank" rel="noopener noreferrer">European Construction Industry Federation (FIEC</a>).</p>
<h3>FIEC position paper</h3>
<p><a href="http://www.fiec.eu/"><img src="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg" alt="FIEC logo" width="300" height="117" srcset="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg 300w, http://extranetevolution.com/files/2020/07/FIEC-logo-160x62.jpg 160w, http://extranetevolution.com/files/2020/07/FIEC-logo.jpg 443w" sizes="(max-width: 300px) 100vw, 300px"></a>On 24 February 2020, the FIEC published a position paper on the relationship between users and software companies/ editors/ service providers (<em><a href="http://extranetevolution.com/files/2020/07/2020-02-24-FIEC_position_on_software_companies-Final.pdf" target="_blank" rel="noopener noreferrer">download</a></em>). No vendors are named, but, from the similarity of the claims, Autodesk is clearly one of the software providers that FIEC is sufficiently concerned about to urge the European Commission to review competition and data management regulations. Its paper discusses challenges and makes recommendations under four headings:</p>
<ol>
<li><strong>The dominant position of a few software companies/editors/providers raises major concerns.</strong> – The FIEC urges the European Commission to target competition issues relating to software user contracts</li>
<li><strong>The non-EU origin of these suppliers and their infrastructure is exacerbating the lack of autonomy in software capability in the EU.</strong> – The FIEC says EU software users should be allowed to decide where their data is stored (“EU companies should be able to have their data hosted on EU territory, by EU servers/companies, under EU legislation”), calls for the creation of a secure European Cloud, and says software services “should be required to meet EU standards for interoperability and open access”.</li>
<li><strong>Contracting authorities must remain software-neutral and promote open standards</strong>. – The FIEC calls for enforcement of EU public procurement rules, and urges promotion of open standards for data, protocols and file formats in public procurement.</li>
<li><strong>Rules need to be established for multiple-user-access platforms such as BIM models.</strong> – Similarly, the FIEC urges EU measures aimed at protecting the data owner while ensuring appropriate data access rights for other users.</li>
</ol>
<h3>Autodesk not alone in hosting, US dominance, interoperability issues</h3>
<p>Some of these issues are already familiar. Where project data is hosted has been a concern ever since Software-as-a-Service applications began to be deployed in the 1990s, and as use of construction collaboration platforms expanded in the early 2000s, most leading vendors have responded by creating localised hosting centres to serve different operational regions. Hosting&nbsp; project data in the United States, for example, has been resisted by most clients based in Europe and other parts of the world (eg: the Middle East, southeast Asia, etc; read <em>EE</em> August 2014 post <a href="http://extranetevolution.com/2014/08/no-saas-safe-harbor/"><em>No SaaS ‘Safe Harbor’</em></a>).</p>
<p>Concentration of large portions of the construction software industry through merger and acquisition activity has resulted in an increasingly dominant position for US software giants. By gobbling up strong players in Europe, Australasia and elsewhere, Autodesk, Bentley, Oracle and Trimble have assembled strong AEC software portfolios, while some of the more generic US software providers such as Microsoft and IBM have also developed applications, services and relationships that give them an increasingly strong foothold in the AEC space.</p>
<p>And software interoperability has been a perennial issue that <em>EE</em> has covered since it started in 2005 (eg: <a href="http://extranetevolution.com/2005/09/new_roi_return_/"><em>New ROI: Return on Interoperability</em></a>, September 2005). BuildingSmart (formerly the International Alliance for Interoperability) started out as an Autodesk initiative in the mid-1990s, but, over 25 years later, global shifts towards open standards are still proceeding almost glacially slowly, with Autodesk’s leading BIM authoring product “widely ridiculed” for its IFC import/export capabilities.</p>
<h3>Autodesk responds on key themes</h3>
<p><strong><a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit"><img src="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg" alt="Autodesk reply" width="400" height="273" srcset="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg 300w, http://extranetevolution.com/files/2020/07/Autodesk-reply-590x403.jpg 590w, http://extranetevolution.com/files/2020/07/Autodesk-reply-768x524.jpg 768w, http://extranetevolution.com/files/2020/07/Autodesk-reply-160x109.jpg 160w, http://extranetevolution.com/files/2020/07/Autodesk-reply.jpg 1157w" sizes="(max-width: 400px) 100vw, 400px"></a>Autodesk’s initial response</strong> (<a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>see update to earlier EE post</em></a>) to the Godwin group’s open letter <strong>did not mention interoperability</strong> at all. However, a <a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit" target="_blank" rel="noopener noreferrer">follow-up blog post by Amy Bunzsel</a> published today (31 July 2020) addresses the main themes, and on openness and interoperability says: “<strong>We continue to invest in supporting IFC</strong> and based on customer feedback we’ve <strong>recently increased development for new industry requirements, focusing on IFCv4 certification</strong>.”</p>
<p>Bunzsel continues:</p>
<p>“Looking to the future, we believe that ways of working will evolve, from the direct modeling of today to outcome-based design driven by analysis…, to the convergence of manufacturing and construction, and that <strong>data needs to be unlocked from native formats and flow more readily throughout Autodesk and non-Autodesk products</strong>.”</p>
<h3>No more software silos</h3>
<p><a href="https://3drepo.com/"><img src="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png" alt="" width="150" height="51" srcset="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png 300w, http://extranetevolution.com/files/2017/03/3DRepo.png 385w" sizes="(max-width: 150px) 100vw, 150px"></a>Jozef Dobos is CEO and founder of London, UK-based technology vendor, <a href="https://3drepo.com/" target="_blank" rel="noopener noreferrer"><strong>3DRepo</strong></a>&nbsp;(which has been <a href="https://3drepo.com/4670-2/" target="_blank" rel="noopener noreferrer">a supporter of Open BIM since 2017</a>), and recently argued&nbsp;<a href="https://www.bimplus.co.uk/analysis/making-case-fair-competition-software-use/" target="_blank" rel="noopener noreferrer"><em>The case for fair competition in software use</em></a>, in a <em>BIM+</em> article. He writes:</p>
<p><img src="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png" alt="Jozef Dobos" width="271" height="300" srcset="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png 271w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-145x160.png 145w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-363x400.png 363w, http://extranetevolution.com/files/2020/07/Jozef-Dobos.png 502w" sizes="(max-width: 271px) 100vw, 271px">“<strong>All the issues raised by the FIEC must be addressed to enable the genuine digitisation of the construction industry</strong>.</p>
<p>3D Repo was created to enable the construction industry to work better together and to create better buildings. This is why projects like the&nbsp;<strong><a href="https://www.bimplus.co.uk/news/project-explores-faster-bim-data-transfer-between-/" target="_blank" rel="noopener noreferrer">AEC Delta Mobility</a></strong> [open-source] initiative in collaboration with BuroHappold Engineering and Speckle Systems are so important, creating a new standard for designers, integrators and fabricators to improve the flow of data.</p>
<p>The current method of sharing information as files of entire 3D models can hinder collaboration. Tracking changes can also be problematic and inefficient for design communication. AEC Delta Mobility breaks down the file barriers to enable small design changes, known as ‘Deltas’, to be shared faster, more openly and more efficiently.</p>
<p><strong>This is how the software industry should be working with the construction industry. Real solutions that involve working with customers and providing them with tools they will not want to walk away from, based on commercial terms that actually promote the collaborative behaviours we want to see, not divide us into software silos</strong>.”</p>
</div>								</div>
		
			    
    	</div>

</div>


<p><span><strong>Permanent link to this article: </strong><span>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</span></span></p>











	
    

            
  

                </div><!-- #content-main -->
        
            
<!-- #sidebar1 -->        
        
    </div></div>]]>
            </description>
            <link>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034211</guid>
            <pubDate>Mon, 03 Aug 2020 04:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web apps aren't tech. They're “tech”]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24034040">thread link</a>) | @AlchemistCamp
<br/>
August 2, 2020 | https://questinglog.com/web-apps-arent-tech | <a href="https://web.archive.org/web/*/https://questinglog.com/web-apps-arent-tech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><blockquote><p>I do hear sometimes from programmers who are kind of sad that they don't have the opportunity to write game engines from scratch like I did and have it matter or make an impact...</p> <p>-John Carmack</p></blockquote> <p>I was definitely a programmer who felt like I'd missed a golden era of opportunity. I didn't <em>really</em> start programming until my 30s. Just like many devs hoping to have an impact on the industry, it's sometimes felt like the golden era has already passed.</p> <p>Surveying the market from a more entreprenurial mindset and looking for a potential niche to fill with a SaaS app (or worse, a social network), the situation appears even more dire! News aggregators have been done and Reddit is thoroughly dominant. The professional social network is done and LinkedIn owns it. Market after market is done. <a href="https://questinglog.com/everything-is-done">Everything in tech is done.</a></p> <h2 id="technology-doesn-t-stay-technology"><a href="#technology-doesn-t-stay-technology">#</a> Technology doesn't stay technology</h2> <p>Part of the problem is the word "tech". There are two different—but overlapping—ideas that are both commonly referred to as "tech".</p> <p>By its literal definition, techonology is anything that involves <em>applying scientific knowledge for practical purposes</em>. In a literal sense, we're surrounded by tech. Some, such as the spoon are ancient and others, like the Kinesis keyboard I'm typing on are much newer.</p> <p>But people don't talk about ancient inventions like the fire bow, or Clovis points as "technology", outside of a historical context. Most people don't even call somewhat modern inventions like light bulbs, refrigerators or microwaves as technology either. When we call something technology, we generally mean something invented recently... <em>or</em> we mean something related to computers.</p> <p>Douglas Adams summed it up into three rules:</p> <ol><li>Anything that is in the world when you’re born is normal and ordinary and is just a natural part of the way the world works.</li> <li>Anything that's invented between when you’re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it.</li> <li>Anything invented after you're thirty-five is against the natural order of things.</li></ol> <p>Having a musician turned firmware hacker and then programmer for an uncle, I'm a bit more optimistic about aging and see the boundary as more about whether a given technology has been widespread for a decade or not.</p> <p>Cassette tapes and microwave ovens used to be fantastic new technologies in the late 60s and early 70s. Now they aren't. DVDs, the web and 3D video games used to be amazing technologies in the 90s. Now they're taken for granted. Smart phones were incredible in the late aughts. Now they're just phones.</p> <h2 id="when-pundits-say-tech-they-generally-mean-computing"><a href="#when-pundits-say-tech-they-generally-mean-computing">#</a> When pundits say "tech" they generally mean computing</h2> <p>The rapid advances in personal computing during the 80s, 90s and early 2000s was nothing short of breathtaking. Computers were gaining new powers every year or two and PCs were deprecating nearly 50% per year! The web took the boom to an exponentially growing number of users. [<a href="#1">1</a>]</p> <p>It's entirely natural that computer software dominated the discussion of technology for a generation. First journalists, and now many of us are referring to everything from web SaaS apps to mobile productivity apps as "tech".[<a href="#2">2</a>] Since the wider meaning of tech hasn't been abandoned, this makes it very easy to conflate the two.</p> <p>But not all technology is computing and not all computing is technology anymore.</p> <h2 id="where-is-the-edge"><a href="#where-is-the-edge">#</a> Where is the edge?</h2> <p>To an ambitious engineer looking for a market opportunity in "tech", things look crowded. Advances in programming languages, frameworks, open source collaboration, dev ops, visual site-building tools and more have made it <em>dramatically</em> easier to create both web apps and mobile apps than it was a decade ago. This has lead to a flood of competition and an increased importance of marketing and other skills an engineer might not have.</p> <p>But web apps aren't (necessarily) tech. They're "tech".</p> <p>But not all is lost for the aspiring engineer.</p> <p>There are newer technologies, closer to the frontier that aren't common in in 2020 but will be in 2030. Some of them are still wide open to people with more learning power than earning power. Bio-tech, blockchain, and VR <em>are</em> tech and the technical challenges to be solved are real. It's a lot harder to ship a product in those areas than to build yet another SaaS targeting small to medium sized businesses. But that's a <em>good</em> thing if technical skills are your strength.</p> <p>For those whose strengths lean more to the marketing, sales or design sides, the B2B SaaS may represent a better goal. This is good for everyone. There's vast landscape for different people with different comparative advantages to find their niches.</p> <h2 id="you-are-not-too-late"><a href="#you-are-not-too-late">#</a> You are not too late</h2> <blockquote><p>...here's where some perspective really helps - I can remember when I was a teenager, I thought I had missed the Golden Age of 8-bit Apple 2 gaming, that I was never going to be Richard Garriott...time went by, and I got to make my own marks in things after that. And, in that time, I also see so many opportunities that have come by.</p> <p>The 90s PC wave was great - I was happy to be there, and I'm glad I took a swing and knocked one out of the park with that. But since then, we've seen mobile games, and web games, and free-to-play games, the Steam revolution...and now virtual reality. And all of these are amazing!</p> <p>So, yeah, the opportunities that I had aren't there for people today - but there are new and better ones. And personally, I'm more excited about these than anything that's come before. So, thank you very much for this honor, but I'm just getting started.</p> <p>-John Carmack (BAFTA acceptance speech)</p></blockquote> <p>The speech John Carmack gave when accepting his BAFTA fellowship filled me more professional optimism than I've felt in quite a while. Even he felt like it was "too late" because of missing all the opportunities of the 80s.</p> <p>In retrospect, that seems crazy. The web was huge and just around the corner.</p> <h3 id="notes"><a href="#notes">#</a> Notes</h3> <p><a name="1">[1]</a> Well more of an S-curve, but it looked exponential then.</p> <div><p><a name="2">[2]</a> As one commenter on HN </p><a href="https://news.ycombinator.com/item?id=24034703" target="_blank" rel="noopener noreferrer">pointed out</a><p>, it's a spectrum. In Uber's early days, its technology was crucial to its business. Over time, they'll gradually become less of a tech company if they coast and stop innovating.
</p></div>  <br> <hr> <p><a href="https://news.ycombinator.com/item?id=24034040" target="_blank" rel="noopener noreferrer">Discussion on HN</a></p></div></div>]]>
            </description>
            <link>https://questinglog.com/web-apps-arent-tech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034040</guid>
            <pubDate>Mon, 03 Aug 2020 03:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email Got Us $5k AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24033037">thread link</a>) | @webappsecperson
<br/>
August 2, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24033037</guid>
            <pubDate>Mon, 03 Aug 2020 00:39:42 GMT</pubDate>
        </item>
    </channel>
</rss>
